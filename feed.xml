<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="ko"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://sweetlittlebird.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://sweetlittlebird.github.io/" rel="alternate" type="text/html" hreflang="ko" /><updated>2025-08-24T00:54:15+09:00</updated><id>https://sweetlittlebird.github.io/feed.xml</id><title type="html">Sweet Little Bird</title><subtitle>공부 기록과 개발 이야기를 담은 블로그입니다.</subtitle><entry><title type="html">[Cilium] Cilium ServiceMesh</title><link href="https://sweetlittlebird.github.io/posts/2025-08-24-Cilium-Week6/" rel="alternate" type="text/html" title="[Cilium] Cilium ServiceMesh" /><published>2025-08-24T00:10:18+09:00</published><updated>2025-08-24T00:10:18+09:00</updated><id>https://sweetlittlebird.github.io/posts/Cilium%20-%20Week6</id><content type="html" xml:base="https://sweetlittlebird.github.io/posts/2025-08-24-Cilium-Week6/"><![CDATA[<h2 id="들어가며">들어가며</h2>

<p>이번 포스트에서는 ServiceMesh이란 무엇인가와 등장배경을 알아보고,
Cilium에서 제공하는 ServiceMesh의 각 기능들에 대해 실습을 통하여 알아보도록 하겠습니다.</p>

<hr />

<h2 id="실습-환경-구성">실습 환경 구성</h2>

<ul>
  <li>이번 실습에서는 다음의 구성으로 실습 환경을 구성합니다.
    <ul>
      <li><strong>버전</strong> : Kubernetes 1.33.4, Cilium 1.18.1, pwru</li>
      <li><strong>기본 배포 가상 머신</strong> : k8s-ctr, k8s-w1, router
        <ul>
          <li>k8s-ctr spec : vCPU 4, Mem 2560</li>
          <li>k8s-w1 spec : vCPU 4, Mem 2560</li>
        </ul>
      </li>
      <li><strong>router</strong> : router : 192.168.<strong>10</strong>.0/24 ↔ 192.168.<strong>20</strong>.0/24 대역 라우팅 역할, k8s 에 join 되지 않은 서버입니다.</li>
      <li>실습 동작에 필요한 static routing이 설저된 상태로 배포 됩니다.</li>
    </ul>
  </li>
</ul>

<h3 id="실습환경-배포-파일">실습환경 배포 파일</h3>

<ul>
  <li>
    <p><strong>Vagrantfile</strong> : 가상머신 정의, 부팅 시 초기 프로비저닝 설정을 포함하는 Vagrantfile입니다.</p>

    <div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Variables</span>
<span class="no">K8SV</span> <span class="o">=</span> <span class="s1">'1.33.4-1.1'</span> <span class="c1"># Kubernetes Version : apt list -a kubelet , ex) 1.32.5-1.1</span>
<span class="no">CONTAINERDV</span> <span class="o">=</span> <span class="s1">'1.7.27-1'</span> <span class="c1"># Containerd Version : apt list -a containerd.io , ex) 1.6.33-1</span>
<span class="no">CILIUMV</span> <span class="o">=</span> <span class="s1">'1.18.1'</span> <span class="c1"># Cilium CNI Version : https://github.com/cilium/cilium/tags</span>
<span class="no">N</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># max number of worker nodes</span>
  
<span class="c1"># Base Image  https://portal.cloud.hashicorp.com/vagrant/discover/bento/ubuntu-24.04</span>
<span class="no">BOX_IMAGE</span> <span class="o">=</span> <span class="s2">"bento/ubuntu-24.04"</span>
<span class="no">BOX_VERSION</span> <span class="o">=</span> <span class="s2">"202508.03.0"</span>
  
<span class="no">Vagrant</span><span class="p">.</span><span class="nf">configure</span><span class="p">(</span><span class="s2">"2"</span><span class="p">)</span> <span class="k">do</span> <span class="o">|</span><span class="n">config</span><span class="o">|</span>
  <span class="c1">#-ControlPlane Node</span>
  <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">define</span> <span class="s2">"k8s-ctr"</span> <span class="k">do</span> <span class="o">|</span><span class="n">subconfig</span><span class="o">|</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="no">BOX_IMAGE</span>
  
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box_version</span> <span class="o">=</span> <span class="no">BOX_VERSION</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provider</span> <span class="s2">"virtualbox"</span> <span class="k">do</span> <span class="o">|</span><span class="n">vb</span><span class="o">|</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--groups"</span><span class="p">,</span> <span class="s2">"/Cilium-Lab"</span><span class="p">]</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--nicpromisc2"</span><span class="p">,</span> <span class="s2">"allow-all"</span><span class="p">]</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">name</span> <span class="o">=</span> <span class="s2">"k8s-ctr"</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">cpus</span> <span class="o">=</span> <span class="mi">2</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">memory</span> <span class="o">=</span> <span class="mi">2560</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">linked_clone</span> <span class="o">=</span> <span class="kp">true</span>
    <span class="k">end</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">host_name</span> <span class="o">=</span> <span class="s2">"k8s-ctr"</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.10.100"</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="mi">60000</span><span class="p">,</span> <span class="ss">auto_correct: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">id: </span><span class="s2">"ssh"</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">synced_folder</span> <span class="s2">"./"</span><span class="p">,</span> <span class="s2">"/vagrant"</span><span class="p">,</span> <span class="ss">disabled: </span><span class="kp">true</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"init_cfg.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">K8SV</span><span class="p">,</span> <span class="no">CONTAINERDV</span> <span class="p">]</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"k8s-ctr.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">N</span><span class="p">,</span> <span class="no">CILIUMV</span><span class="p">,</span> <span class="no">K8SV</span> <span class="p">]</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"route-add1.sh"</span>
  <span class="k">end</span>
  
  <span class="c1">#-Worker Nodes Subnet1</span>
  <span class="p">(</span><span class="mi">1</span><span class="o">..</span><span class="no">N</span><span class="p">).</span><span class="nf">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">i</span><span class="o">|</span>
    <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">define</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span> <span class="k">do</span> <span class="o">|</span><span class="n">subconfig</span><span class="o">|</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="no">BOX_IMAGE</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box_version</span> <span class="o">=</span> <span class="no">BOX_VERSION</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provider</span> <span class="s2">"virtualbox"</span> <span class="k">do</span> <span class="o">|</span><span class="n">vb</span><span class="o">|</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--groups"</span><span class="p">,</span> <span class="s2">"/Cilium-Lab"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--nicpromisc2"</span><span class="p">,</span> <span class="s2">"allow-all"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">name</span> <span class="o">=</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">cpus</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">memory</span> <span class="o">=</span> <span class="mi">1536</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">linked_clone</span> <span class="o">=</span> <span class="kp">true</span>
      <span class="k">end</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">host_name</span> <span class="o">=</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.10.10</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="s2">"6000</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span> <span class="ss">auto_correct: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">id: </span><span class="s2">"ssh"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">synced_folder</span> <span class="s2">"./"</span><span class="p">,</span> <span class="s2">"/vagrant"</span><span class="p">,</span> <span class="ss">disabled: </span><span class="kp">true</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"init_cfg.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">K8SV</span><span class="p">,</span> <span class="no">CONTAINERDV</span><span class="p">]</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"k8s-w.sh"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"route-add1.sh"</span>
    <span class="k">end</span>
  <span class="k">end</span>
  
  <span class="c1">#-Router Node</span>
  <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">define</span> <span class="s2">"router"</span> <span class="k">do</span> <span class="o">|</span><span class="n">subconfig</span><span class="o">|</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="no">BOX_IMAGE</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box_version</span> <span class="o">=</span> <span class="no">BOX_VERSION</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provider</span> <span class="s2">"virtualbox"</span> <span class="k">do</span> <span class="o">|</span><span class="n">vb</span><span class="o">|</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--groups"</span><span class="p">,</span> <span class="s2">"/Cilium-Lab"</span><span class="p">]</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">name</span> <span class="o">=</span> <span class="s2">"router"</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">cpus</span> <span class="o">=</span> <span class="mi">1</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">memory</span> <span class="o">=</span> <span class="mi">768</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">linked_clone</span> <span class="o">=</span> <span class="kp">true</span>
    <span class="k">end</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">host_name</span> <span class="o">=</span> <span class="s2">"router"</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.10.200"</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="mi">60009</span><span class="p">,</span> <span class="ss">auto_correct: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">id: </span><span class="s2">"ssh"</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.20.200"</span><span class="p">,</span> <span class="ss">auto_config: </span><span class="kp">false</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">synced_folder</span> <span class="s2">"./"</span><span class="p">,</span> <span class="s2">"/vagrant"</span><span class="p">,</span> <span class="ss">disabled: </span><span class="kp">true</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"router.sh"</span>
  <span class="k">end</span>
  
<span class="k">end</span>

</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>init_cfg.sh</strong> : args 참고하여 초기 설정을 수행하는 스크립트입니다. <strong>pwru</strong>도 설치합니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config Start &lt;&lt;&lt;&lt;"</span>
  
<span class="nb">echo</span> <span class="s2">"[TASK 1] Setting Profile &amp; Bashrc"</span>
<span class="nb">echo</span> <span class="s1">'alias vi=vim'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s2">"sudo su -"</span> <span class="o">&gt;&gt;</span> /home/vagrant/.bashrc
<span class="nb">ln</span> <span class="nt">-sf</span> /usr/share/zoneinfo/Asia/Seoul /etc/localtime <span class="c"># Change Timezone</span>
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 2] Disable AppArmor"</span>
systemctl stop ufw <span class="o">&amp;&amp;</span> systemctl disable ufw <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
systemctl stop apparmor <span class="o">&amp;&amp;</span> systemctl disable apparmor <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 3] Disable and turn off SWAP"</span>
swapoff <span class="nt">-a</span> <span class="o">&amp;&amp;</span> <span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'/swap/s/^/#/'</span> /etc/fstab
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 4] Install Packages"</span>
apt update <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
apt-get <span class="nb">install </span>apt-transport-https ca-certificates curl gpg <span class="nt">-y</span> <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="c"># Download the public signing key for the Kubernetes package repositories.</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> <span class="nt">-m</span> 755 /etc/apt/keyrings
<span class="nv">K8SMMV</span><span class="o">=</span><span class="si">$(</span><span class="nb">echo</span> <span class="nv">$1</span> | <span class="nb">sed</span> <span class="nt">-En</span> <span class="s1">'s/^([0-9]+\.[0-9]+)\..*/\1/p'</span><span class="si">)</span>
curl <span class="nt">-fsSL</span> https://pkgs.k8s.io/core:/stable:/v<span class="nv">$K8SMMV</span>/deb/Release.key | <span class="nb">sudo </span>gpg <span class="nt">--dearmor</span> <span class="nt">-o</span> /etc/apt/keyrings/kubernetes-apt-keyring.gpg
<span class="nb">echo</span> <span class="s2">"deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v</span><span class="nv">$K8SMMV</span><span class="s2">/deb/ /"</span> <span class="o">&gt;&gt;</span> /etc/apt/sources.list.d/kubernetes.list
curl <span class="nt">-fsSL</span> https://download.docker.com/linux/ubuntu/gpg <span class="nt">-o</span> /etc/apt/keyrings/docker.asc
<span class="nb">echo</span> <span class="s2">"deb [arch=</span><span class="si">$(</span>dpkg <span class="nt">--print-architecture</span><span class="si">)</span><span class="s2"> signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu </span><span class="si">$(</span><span class="nb">.</span> /etc/os-release <span class="o">&amp;&amp;</span> <span class="nb">echo</span> <span class="s2">"</span><span class="nv">$VERSION_CODENAME</span><span class="s2">"</span><span class="si">)</span><span class="s2"> stable"</span> | <span class="nb">tee</span> /etc/apt/sources.list.d/docker.list <span class="o">&gt;</span> /dev/null
  
<span class="c"># packets traversing the bridge are processed by iptables for filtering</span>
<span class="nb">echo </span>1 <span class="o">&gt;</span> /proc/sys/net/ipv4/ip_forward
<span class="nb">echo</span> <span class="s2">"net.ipv4.ip_forward = 1"</span> <span class="o">&gt;&gt;</span> /etc/sysctl.d/k8s.conf
  
<span class="c"># enable br_netfilter for iptables </span>
modprobe br_netfilter
modprobe overlay
<span class="nb">echo</span> <span class="s2">"br_netfilter"</span> <span class="o">&gt;&gt;</span> /etc/modules-load.d/k8s.conf
<span class="nb">echo</span> <span class="s2">"overlay"</span> <span class="o">&gt;&gt;</span> /etc/modules-load.d/k8s.conf
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 5] Install Kubernetes components (kubeadm, kubelet and kubectl)"</span>
<span class="c"># Update the apt package index, install kubelet, kubeadm and kubectl, and pin their version</span>
apt update <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="c"># apt list -a kubelet ; apt list -a containerd.io</span>
apt-get <span class="nb">install</span> <span class="nt">-y</span> <span class="nv">kubelet</span><span class="o">=</span><span class="nv">$1</span> <span class="nv">kubectl</span><span class="o">=</span><span class="nv">$1</span> <span class="nv">kubeadm</span><span class="o">=</span><span class="nv">$1</span> containerd.io<span class="o">=</span><span class="nv">$2</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
apt-mark hold kubelet kubeadm kubectl <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="c"># containerd configure to default and cgroup managed by systemd</span>
containerd config default <span class="o">&gt;</span> /etc/containerd/config.toml
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'s/SystemdCgroup = false/SystemdCgroup = true/g'</span> /etc/containerd/config.toml
  
<span class="c"># avoid WARN&amp;ERRO(default endpoints) when crictl run  </span>
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; /etc/crictl.yaml
runtime-endpoint: unix:///run/containerd/containerd.sock
image-endpoint: unix:///run/containerd/containerd.sock
</span><span class="no">EOF
  
</span><span class="c"># ready to install for k8s </span>
systemctl restart containerd <span class="o">&amp;&amp;</span> systemctl <span class="nb">enable </span>containerd
systemctl <span class="nb">enable</span> <span class="nt">--now</span> kubelet
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 6] Install Packages &amp; Helm"</span>
<span class="nb">export </span><span class="nv">DEBIAN_FRONTEND</span><span class="o">=</span>noninteractive
apt-get <span class="nb">install</span> <span class="nt">-y</span> bridge-utils sshpass net-tools conntrack ngrep tcpdump ipset arping wireguard jq yq tree bash-completion unzip kubecolor termshark <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
curl <span class="nt">-s</span> https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 7] Install pwru"</span>
<span class="nv">CLI_ARCH</span><span class="o">=</span>amd64
<span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span><span class="si">)</span><span class="s2">"</span> <span class="o">=</span> <span class="s2">"aarch64"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then </span><span class="nv">CLI_ARCH</span><span class="o">=</span>arm64<span class="p">;</span> <span class="k">fi
</span>wget https://github.com/cilium/pwru/releases/download/v1.0.10/pwru-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">tar</span> <span class="nt">-xvzf</span> pwru-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">mv </span>pwru /usr/local/bin/pwru <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="c"># echo "[TASK 8] Change MTU for eth1"</span>
<span class="c"># ip link set dev eth1 mtu 9000</span>
  
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config End &lt;&lt;&lt;&lt;"</span>  
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>k8s-ctr.sh</strong> : kubeadm init를 통하여 kubernetes controlplane 노드를 설정하고 Cilium CNI 설치, 편리성 설정(k, kc, k9s)하는 스크립트입니다. local-path-storageclass와 metrics-server도 설치합니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Controlplane config Start &lt;&lt;&lt;&lt;"</span>
  
<span class="nb">echo</span> <span class="s2">"[TASK 1] Initial Kubernetes"</span>
curl <span class="nt">--silent</span> <span class="nt">-o</span> /root/kubeadm-init-ctr-config.yaml https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/kubeadm-init-ctr-config.yaml
<span class="nv">K8SMMV</span><span class="o">=</span><span class="si">$(</span><span class="nb">echo</span> <span class="nv">$3</span> | <span class="nb">sed</span> <span class="nt">-En</span> <span class="s1">'s/^([0-9]+\.[0-9]+\.[0-9]+).*/\1/p'</span><span class="si">)</span>
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/K8S_VERSION_PLACEHOLDER/v</span><span class="k">${</span><span class="nv">K8SMMV</span><span class="k">}</span><span class="s2">/g"</span> /root/kubeadm-init-ctr-config.yaml
kubeadm init <span class="nt">--config</span><span class="o">=</span><span class="s2">"/root/kubeadm-init-ctr-config.yaml"</span>  <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 2] Setting kube config file"</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> /root/.kube
<span class="nb">cp</span> <span class="nt">-i</span> /etc/kubernetes/admin.conf /root/.kube/config
<span class="nb">chown</span> <span class="si">$(</span><span class="nb">id</span> <span class="nt">-u</span><span class="si">)</span>:<span class="si">$(</span><span class="nb">id</span> <span class="nt">-g</span><span class="si">)</span> /root/.kube/config
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 3] Source the completion"</span>
<span class="nb">echo</span> <span class="s1">'source &lt;(kubectl completion bash)'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'source &lt;(kubeadm completion bash)'</span> <span class="o">&gt;&gt;</span> /etc/profile
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 4] Alias kubectl to k"</span>
<span class="nb">echo</span> <span class="s1">'alias k=kubectl'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'alias kc=kubecolor'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'complete -F __start_kubectl k'</span> <span class="o">&gt;&gt;</span> /etc/profile
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 5] Install Kubectx &amp; Kubens"</span>
git clone https://github.com/ahmetb/kubectx /opt/kubectx <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">ln</span> <span class="nt">-s</span> /opt/kubectx/kubens /usr/local/bin/kubens
<span class="nb">ln</span> <span class="nt">-s</span> /opt/kubectx/kubectx /usr/local/bin/kubectx
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 6] Install Kubeps &amp; Setting PS1"</span>
git clone https://github.com/jonmosco/kube-ps1.git /root/kube-ps1 <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="sh">"</span><span class="no">EOT</span><span class="sh">" &gt;&gt; /root/.bash_profile
source /root/kube-ps1/kube-ps1.sh
KUBE_PS1_SYMBOL_ENABLE=true
function get_cluster_short() {
  echo "</span><span class="nv">$1</span><span class="sh">" | cut -d . -f1
}
KUBE_PS1_CLUSTER_FUNCTION=get_cluster_short
KUBE_PS1_SUFFIX=') '
PS1='</span><span class="si">$(</span>kube_ps1<span class="si">)</span><span class="sh">'</span><span class="nv">$PS1</span><span class="sh">
</span><span class="no">EOT
</span>kubectl config rename-context <span class="s2">"kubernetes-admin@kubernetes"</span> <span class="s2">"HomeLab"</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 7] Install Cilium CNI"</span>
<span class="nv">NODEIP</span><span class="o">=</span><span class="si">$(</span>ip <span class="nt">-4</span> addr show eth1 | <span class="nb">grep</span> <span class="nt">-oP</span> <span class="s1">'(?&lt;=inet\s)\d+(\.\d+){3}'</span><span class="si">)</span>
helm repo add cilium https://helm.cilium.io/ <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
helm repo update <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
helm <span class="nb">install </span>cilium cilium/cilium <span class="nt">--version</span> <span class="nv">$2</span> <span class="nt">--namespace</span> kube-system <span class="se">\</span>
<span class="nt">--set</span> <span class="nv">k8sServiceHost</span><span class="o">=</span>192.168.10.100 <span class="nt">--set</span> <span class="nv">k8sServicePort</span><span class="o">=</span>6443 <span class="se">\</span>
<span class="nt">--set</span> ipam.mode<span class="o">=</span><span class="s2">"cluster-pool"</span> <span class="nt">--set</span> ipam.operator.clusterPoolIPv4PodCIDRList<span class="o">={</span><span class="s2">"172.20.0.0/16"</span><span class="o">}</span> <span class="nt">--set</span> <span class="nv">ipv4NativeRoutingCIDR</span><span class="o">=</span>172.20.0.0/16 <span class="se">\</span>
<span class="nt">--set</span> <span class="nv">routingMode</span><span class="o">=</span>native <span class="nt">--set</span> <span class="nv">autoDirectNodeRoutes</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> endpointRoutes.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> <span class="nv">directRoutingSkipUnreachable</span><span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> <span class="nv">kubeProxyReplacement</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> bpf.masquerade<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> <span class="nv">installNoConntrackIptablesRules</span><span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> endpointHealthChecking.enabled<span class="o">=</span><span class="nb">false</span> <span class="nt">--set</span> <span class="nv">healthChecking</span><span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
<span class="nt">--set</span> hubble.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> hubble.relay.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> hubble.ui.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> hubble.ui.service.type<span class="o">=</span>NodePort <span class="nt">--set</span> hubble.ui.service.nodePort<span class="o">=</span>30003 <span class="se">\</span>
<span class="nt">--set</span> prometheus.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> operator.prometheus.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> hubble.metrics.enableOpenMetrics<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> hubble.metrics.enabled<span class="o">=</span><span class="s2">"{dns,drop,tcp,flow,port-distribution,icmp,httpV2:exemplars=true;labelsContext=source_ip</span><span class="se">\,</span><span class="s2">source_namespace</span><span class="se">\,</span><span class="s2">source_workload</span><span class="se">\,</span><span class="s2">destination_ip</span><span class="se">\,</span><span class="s2">destination_namespace</span><span class="se">\,</span><span class="s2">destination_workload</span><span class="se">\,</span><span class="s2">traffic_direction}"</span> <span class="se">\</span>
<span class="nt">--set</span> ingressController.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> ingressController.loadbalancerMode<span class="o">=</span>shared <span class="nt">--set</span> loadBalancer.l7.backend<span class="o">=</span>envoy <span class="se">\</span>
<span class="nt">--set</span> <span class="nv">localRedirectPolicy</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> l2announcements.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> operator.replicas<span class="o">=</span>1 <span class="nt">--set</span> debug.enabled<span class="o">=</span><span class="nb">true</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 8] Install Cilium / Hubble CLI"</span>
<span class="nv">CILIUM_CLI_VERSION</span><span class="o">=</span><span class="si">$(</span>curl <span class="nt">-s</span> https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt<span class="si">)</span>
<span class="nv">CLI_ARCH</span><span class="o">=</span>amd64
<span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span><span class="si">)</span><span class="s2">"</span> <span class="o">=</span> <span class="s2">"aarch64"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then </span><span class="nv">CLI_ARCH</span><span class="o">=</span>arm64<span class="p">;</span> <span class="k">fi
</span>curl <span class="nt">-L</span> <span class="nt">--fail</span> <span class="nt">--remote-name-all</span> https://github.com/cilium/cilium-cli/releases/download/<span class="k">${</span><span class="nv">CILIUM_CLI_VERSION</span><span class="k">}</span>/cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">tar </span>xzvfC cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz /usr/local/bin
<span class="nb">rm </span>cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz
  
<span class="nv">HUBBLE_VERSION</span><span class="o">=</span><span class="si">$(</span>curl <span class="nt">-s</span> https://raw.githubusercontent.com/cilium/hubble/master/stable.txt<span class="si">)</span>
<span class="nv">HUBBLE_ARCH</span><span class="o">=</span>amd64
<span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span><span class="si">)</span><span class="s2">"</span> <span class="o">=</span> <span class="s2">"aarch64"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then </span><span class="nv">HUBBLE_ARCH</span><span class="o">=</span>arm64<span class="p">;</span> <span class="k">fi
</span>curl <span class="nt">-L</span> <span class="nt">--fail</span> <span class="nt">--remote-name-all</span> https://github.com/cilium/hubble/releases/download/<span class="nv">$HUBBLE_VERSION</span>/hubble-linux-<span class="k">${</span><span class="nv">HUBBLE_ARCH</span><span class="k">}</span>.tar.gz <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">tar </span>xzvfC hubble-linux-<span class="k">${</span><span class="nv">HUBBLE_ARCH</span><span class="k">}</span>.tar.gz /usr/local/bin
<span class="nb">rm </span>hubble-linux-<span class="k">${</span><span class="nv">HUBBLE_ARCH</span><span class="k">}</span>.tar.gz
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 9] Remove node taint"</span>
kubectl taint nodes k8s-ctr node-role.kubernetes.io/control-plane-
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 10] local DNS with hosts file"</span>
<span class="nb">echo</span> <span class="s2">"192.168.10.100 k8s-ctr"</span> <span class="o">&gt;&gt;</span> /etc/hosts
<span class="nb">echo</span> <span class="s2">"192.168.10.200 router"</span> <span class="o">&gt;&gt;</span> /etc/hosts
<span class="nb">echo</span> <span class="s2">"192.168.20.100 k8s-w0"</span> <span class="o">&gt;&gt;</span> /etc/hosts
<span class="k">for</span> <span class="o">((</span> <span class="nv">i</span><span class="o">=</span>1<span class="p">;</span> i&lt;<span class="o">=</span><span class="nv">$1</span><span class="p">;</span> i++  <span class="o">))</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"192.168.10.10</span><span class="nv">$i</span><span class="s2"> k8s-w</span><span class="nv">$i</span><span class="s2">"</span> <span class="o">&gt;&gt;</span> /etc/hosts<span class="p">;</span> <span class="k">done
  
  
</span><span class="nb">echo</span> <span class="s2">"[TASK 11] Dynamically provisioning persistent local storage with Kubernetes"</span>
kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.31/deploy/local-path-storage.yaml <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
kubectl patch storageclass local-path <span class="nt">-p</span> <span class="s1">'{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="c"># echo "[TASK 12] Install Prometheus &amp; Grafana"</span>
<span class="c"># kubectl apply -f https://raw.githubusercontent.com/cilium/cilium/1.18.0/examples/kubernetes/addons/prometheus/monitoring-example.yaml &gt;/dev/null 2&gt;&amp;1</span>
<span class="c"># kubectl patch svc -n cilium-monitoring prometheus -p '{"spec": {"type": "NodePort", "ports": [{"port": 9090, "targetPort": 9090, "nodePort": 30001}]}}' &gt;/dev/null 2&gt;&amp;1</span>
<span class="c"># kubectl patch svc -n cilium-monitoring grafana -p '{"spec": {"type": "NodePort", "ports": [{"port": 3000, "targetPort": 3000, "nodePort": 30002}]}}' &gt;/dev/null 2&gt;&amp;1</span>
  
<span class="c"># echo "[TASK 12] Install Prometheus Stack"</span>
<span class="c"># helm repo add prometheus-community https://prometheus-community.github.io/helm-charts  &gt;/dev/null 2&gt;&amp;1</span>
<span class="c"># cat &lt;&lt;EOT &gt; monitor-values.yaml</span>
<span class="c"># prometheus:</span>
<span class="c">#   prometheusSpec:</span>
<span class="c">#     scrapeInterval: "15s"</span>
<span class="c">#     evaluationInterval: "15s"</span>
<span class="c">#   service:</span>
<span class="c">#     type: NodePort</span>
<span class="c">#     nodePort: 30001</span>
  
<span class="c"># grafana:</span>
<span class="c">#   defaultDashboardsTimezone: Asia/Seoul</span>
<span class="c">#   adminPassword: prom-operator</span>
<span class="c">#   service:</span>
<span class="c">#     type: NodePort</span>
<span class="c">#     nodePort: 30002</span>
  
<span class="c"># alertmanager:</span>
<span class="c">#   enabled: false</span>
<span class="c"># defaultRules:</span>
<span class="c">#   create: false</span>
<span class="c"># prometheus-windows-exporter:</span>
<span class="c">#   prometheus:</span>
<span class="c">#     monitor:</span>
<span class="c">#       enabled: false</span>
<span class="c"># EOT</span>
<span class="c"># helm install kube-prometheus-stack prometheus-community/kube-prometheus-stack --version 75.15.1 \</span>
<span class="c">#   -f monitor-values.yaml --create-namespace --namespace monitoring  &gt;/dev/null 2&gt;&amp;1</span>
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 13] Install Metrics-server"</span>
helm repo add metrics-server https://kubernetes-sigs.github.io/metrics-server/  <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
helm upgrade <span class="nt">--install</span> metrics-server metrics-server/metrics-server <span class="nt">--set</span> <span class="s1">'args[0]=--kubelet-insecure-tls'</span> <span class="nt">-n</span> kube-system  <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 14] Install k9s"</span>
<span class="nv">CLI_ARCH</span><span class="o">=</span>amd64
<span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span><span class="si">)</span><span class="s2">"</span> <span class="o">=</span> <span class="s2">"aarch64"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then </span><span class="nv">CLI_ARCH</span><span class="o">=</span>arm64<span class="p">;</span> <span class="k">fi
</span>wget https://github.com/derailed/k9s/releases/latest/download/k9s_linux_<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.deb <span class="nt">-O</span> /tmp/k9s_linux_<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.deb  <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
apt <span class="nb">install</span> /tmp/k9s_linux_<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.deb  <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Controlplane Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div>    </div>

    <ul>
      <li>
        <p><strong>kubeadm-init-ctr-config.yaml</strong></p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apiVersion: kubeadm.k8s.io/v1beta4
kind: InitConfiguration
bootstrapTokens:
- token: <span class="s2">"123456.1234567890123456"</span>
  ttl: <span class="s2">"0s"</span>
  usages:
  - signing
  - authentication
localAPIEndpoint:
  advertiseAddress: <span class="s2">"192.168.10.100"</span>
nodeRegistration:
  kubeletExtraArgs:
    - name: node-ip
      value: <span class="s2">"192.168.10.100"</span>
  criSocket: <span class="s2">"unix:///run/containerd/containerd.sock"</span>
<span class="nt">---</span>
apiVersion: kubeadm.k8s.io/v1beta4
kind: ClusterConfiguration
kubernetesVersion: <span class="s2">"K8S_VERSION_PLACEHOLDER"</span>
networking:
  podSubnet: <span class="s2">"10.244.0.0/16"</span>
  serviceSubnet: <span class="s2">"10.96.0.0/16"</span>
proxy:
  disabled: <span class="nb">true</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li><strong>k8s-w.sh</strong> : kubernetes worker 노드 설정, kubeadm join 등을 수행하는  스크립트입니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Node config Start &lt;&lt;&lt;&lt;"</span>
  
<span class="nb">echo</span> <span class="s2">"[TASK 1] K8S Controlplane Join"</span>
curl <span class="nt">--silent</span> <span class="nt">-o</span> /root/kubeadm-join-worker-config.yaml https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/2w/kubeadm-join-worker-config.yaml
<span class="nv">NODEIP</span><span class="o">=</span><span class="si">$(</span>ip <span class="nt">-4</span> addr show eth1 | <span class="nb">grep</span> <span class="nt">-oP</span> <span class="s1">'(?&lt;=inet\s)\d+(\.\d+){3}'</span><span class="si">)</span>
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/NODE_IP_PLACEHOLDER/</span><span class="k">${</span><span class="nv">NODEIP</span><span class="k">}</span><span class="s2">/g"</span> /root/kubeadm-join-worker-config.yaml
kubeadm <span class="nb">join</span> <span class="nt">--config</span><span class="o">=</span><span class="s2">"/root/kubeadm-join-worker-config.yaml"</span> <span class="o">&gt;</span> /dev/null 2&gt;&amp;1
    
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Node config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div>    </div>
    <ul>
      <li>
        <p><strong>kubeadm-join-worker-config.yaml</strong></p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apiVersion: kubeadm.k8s.io/v1beta4
kind: JoinConfiguration
discovery:
  bootstrapToken:
    token: <span class="s2">"123456.1234567890123456"</span>
    apiServerEndpoint: <span class="s2">"192.168.10.100:6443"</span>
    unsafeSkipCAVerification: <span class="nb">true
</span>nodeRegistration:
  criSocket: <span class="s2">"unix:///run/containerd/containerd.sock"</span>
  kubeletExtraArgs:
    - name: node-ip
      value: <span class="s2">"NODE_IP_PLACEHOLDER"</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>route-add1.sh</strong> : k8s node 들이 내부망과 통신을 위한 route 설정 스크립트입니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Route Add Config Start &lt;&lt;&lt;&lt;"</span>
  
<span class="nb">chmod </span>600 /etc/netplan/01-netcfg.yaml
<span class="nb">chmod </span>600 /etc/netplan/50-vagrant.yaml
  
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh">&gt;&gt; /etc/netplan/50-vagrant.yaml
      routes:
      - to: 192.168.20.0/24
        via: 192.168.10.200
</span><span class="no">EOT
  
</span>netplan apply
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Route Add Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>router.sh</strong> : router 역할, 간단 웹 서버 역할</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config Start &lt;&lt;&lt;&lt;"</span>
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 0] Setting eth2"</span>
<span class="nb">chmod </span>600 /etc/netplan/01-netcfg.yaml
<span class="nb">chmod </span>600 /etc/netplan/50-vagrant.yaml
  
<span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOT</span><span class="sh"> &gt;&gt; /etc/netplan/50-vagrant.yaml
    eth2:
      addresses:
      - 192.168.20.200/24
</span><span class="no">EOT
  
</span>netplan apply
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 1] Setting Profile &amp; Bashrc"</span>
<span class="nb">echo</span> <span class="s1">'alias vi=vim'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s2">"sudo su -"</span> <span class="o">&gt;&gt;</span> /home/vagrant/.bashrc
<span class="nb">ln</span> <span class="nt">-sf</span> /usr/share/zoneinfo/Asia/Seoul /etc/localtime
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 2] Disable AppArmor"</span>
systemctl stop ufw <span class="o">&amp;&amp;</span> systemctl disable ufw <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
systemctl stop apparmor <span class="o">&amp;&amp;</span> systemctl disable apparmor <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 3] Add Kernel setting - IP Forwarding"</span>
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'s/#net.ipv4.ip_forward=1/net.ipv4.ip_forward=1/g'</span> /etc/sysctl.conf
sysctl <span class="nt">-p</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 5] Install Packages"</span>
<span class="nb">export </span><span class="nv">DEBIAN_FRONTEND</span><span class="o">=</span>noninteractive
apt update <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
apt-get <span class="nb">install </span>net-tools jq yq tree ngrep tcpdump arping termshark <span class="nt">-y</span> <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 6] Install Apache"</span>
apt <span class="nb">install </span>apache2 <span class="nt">-y</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"&lt;h1&gt;Web Server : </span><span class="si">$(</span><span class="nb">hostname</span><span class="si">)</span><span class="s2">&lt;/h1&gt;"</span> <span class="o">&gt;</span> /var/www/html/index.html
  
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div>    </div>
  </li>
</ul>

<h3 id="실습환경-배포">실습환경 배포</h3>

<h5 id="실습환경-배포-1">실습환경 배포</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nv">$ </span>vagrant up
</code></pre></div></div>

<h5 id="기본정보-확인">기본정보 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> /etc/hosts
<span class="c"># =&gt; ...</span>
<span class="c">#    127.0.2.1 k8s-ctr k8s-ctr</span>
<span class="c">#    192.168.10.100 k8s-ctr</span>
<span class="c">#    192.168.10.200 router</span>
<span class="c">#    192.168.20.100 k8s-w0</span>
<span class="c">#    192.168.10.101 k8s-w1</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>k8s-w1 router <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@<span class="nv">$i</span> <span class="nb">hostname</span><span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    k8s-w1</span>
<span class="c">#    &gt;&gt; node : router &lt;&lt;</span>
<span class="c">#    router</span>

<span class="c"># 클러스터 정보 확인</span>
<span class="nv">$ </span>kubectl cluster-info
<span class="c"># =&gt; Kubernetes control plane is running at https://192.168.10.100:6443</span>
<span class="c">#    CoreDNS is running at https://192.168.10.100:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</span>
<span class="nv">$ </span>kubectl cluster-info dump | <span class="nb">grep</span> <span class="nt">-m</span> 2 <span class="nt">-E</span> <span class="s2">"cluster-cidr|service-cluster-ip-range"</span>
<span class="c"># =&gt;                             "--service-cluster-ip-range=10.96.0.0/16",</span>
<span class="c">#                                "--cluster-cidr=10.244.0.0/16",</span>
<span class="nv">$ </span>kubectl describe cm <span class="nt">-n</span> kube-system kubeadm-config
<span class="c"># =&gt; ...</span>
<span class="c">#    networking:</span>
<span class="c">#      dnsDomain: cluster.local</span>
<span class="c">#      podSubnet: 10.244.0.0/16</span>
<span class="c">#      serviceSubnet: 10.96.0.0/16</span>
<span class="nv">$ </span>kubectl describe cm <span class="nt">-n</span> kube-system kubelet-config

<span class="c"># 노드 정보 : 상태, INTERNAL-IP 확인</span>
<span class="nv">$ </span>ifconfig | <span class="nb">grep</span> <span class="nt">-iEA1</span> <span class="s1">'eth[0-9]:'</span>
<span class="c"># =&gt; eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span>
<span class="c">#            inet 10.0.2.15  netmask 255.255.255.0  broadcast 10.0.2.255</span>
<span class="c">#    --</span>
<span class="c">#    eth1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span>
<span class="c">#            inet 192.168.10.100  netmask 255.255.255.0  broadcast 192.168.10.255</span>
<span class="nv">$ </span>kubectl get node <span class="nt">-owide</span>
<span class="c"># =&gt; NAME      STATUS   ROLES           AGE   VERSION   INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION     CONTAINER-RUNTIME</span>
<span class="c">#    k8s-ctr   Ready    control-plane   15m   v1.33.4   192.168.10.100   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-71-generic   containerd://1.7.27</span>
<span class="c">#    k8s-w1    Ready    &lt;none&gt;          12m   v1.33.4   192.168.10.101   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-71-generic   containerd://1.7.27</span>

<span class="c"># 파드 정보 : 상태, 파드 IP 확인</span>
<span class="nv">$ </span>kubectl get nodes <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{range .items[*]}{.metadata.name}{"\t"}{.spec.podCIDR}{"\n"}{end}'</span>
<span class="c"># =&gt; k8s-ctr 10.244.0.0/24</span>
<span class="c">#    k8s-w1  10.244.1.0/24</span>
<span class="nv">$ </span>kubectl get ciliumnode <span class="nt">-o</span> json | <span class="nb">grep </span>podCIDRs <span class="nt">-A2</span>
<span class="c"># =&gt;                     "podCIDRs": [</span>
<span class="c">#                            "172.20.0.0/24"</span>
<span class="c">#                        ],</span>
<span class="c">#    --</span>
<span class="c">#                        "podCIDRs": [</span>
<span class="c">#                            "172.20.1.0/24"</span>
<span class="c">#                        ],</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-A</span> <span class="nt">-owide</span>
<span class="c"># =&gt; NAMESPACE            NAME                                      READY   STATUS    RESTARTS   AGE   IP               NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    kube-system          cilium-2zkt5                              1/1     Running   0          12m   192.168.10.101   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          cilium-8gt4t                              1/1     Running   0          15m   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          cilium-envoy-jhcs2                        1/1     Running   0          12m   192.168.10.101   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          cilium-envoy-txqxb                        1/1     Running   0          15m   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          cilium-operator-7b4884dcdd-j5hnz          1/1     Running   0          15m   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          hubble-relay-fdd49b976-wdn8n              1/1     Running   0          15m   172.20.0.78      k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          hubble-ui-655f947f96-gv9rw                2/2     Running   0          15m   172.20.0.220     k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    local-path-storage   local-path-provisioner-74f9666bc9-c944v   1/1     Running   0          14m   172.20.0.176     k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>kubectl get ciliumendpoints <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE            NAME                                      SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    kube-system          coredns-674b8bbfcf-2qlch                  24463               ready            172.20.0.158</span>
<span class="c">#    kube-system          coredns-674b8bbfcf-ltzx4                  24463               ready            172.20.0.157</span>
<span class="c">#    kube-system          hubble-relay-fdd49b976-wdn8n              16977               ready            172.20.0.78</span>
<span class="c">#    kube-system          hubble-ui-655f947f96-gv9rw                40085               ready            172.20.0.220</span>
<span class="c">#    kube-system          metrics-server-5dd7b49d79-9rlxq           931                 ready            172.20.0.4</span>
<span class="c">#    local-path-storage   local-path-provisioner-74f9666bc9-c944v   9074                ready            172.20.0.176</span>

<span class="c"># ipam 모드 확인</span>
<span class="nv">$ </span>cilium config view | <span class="nb">grep</span> ^ipam
<span class="c"># =&gt; ipam                                              cluster-pool</span>
<span class="c">#    ipam-cilium-node-update-rate                      15s</span>

<span class="c"># iptables 확인 : TPROXY 관련 규칙 찾아보자!</span>
<span class="nv">$ </span>iptables-save
<span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> filter <span class="nt">-S</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> mangle <span class="nt">-S</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> raw <span class="nt">-S</span>

<span class="c"># 아래 iptables 룰들은 Pod ↔ Proxy ↔ 외부/내부 서비스 트래픽이 올바르게 프록시를 거치되, 커널 conntrack에 의해 방해받지 않도록 제어 by ChatGPT</span>

<span class="nv">$ </span>iptables <span class="nt">-t</span> mangle <span class="nt">-S</span> | <span class="nb">grep</span> <span class="nt">-i</span> proxy
<span class="c"># =&gt; # "Pod로 가는 트래픽 중 proxy를 거쳐야 하는 경우" 패킷을 식별하기 위해 마킹. 이후 TPROXY 룰에서 이 마크(0x200)를 보고 프록시로 리다이렉션.</span>
<span class="c">#    -A CILIUM_PRE_mangle ! -o lo -m socket --transparent -m mark ! --mark 0xe00/0xf00 -m mark ! --mark 0x800/0xf00 -m comment --comment "cilium: any-&gt;pod redirect proxied traffic to host proxy" -j MARK --set-xmark 0x200/0xffffffff</span>
<span class="c">#    # Pod에서 나가는 DNS 요청(UDP/TCP 53) 을 Cilium host proxy(Envoy 기반)로 강제로 보내어[TPROXY로 리다이렉션 → 127.0.0.1:38715 (Cilium DNS egress proxy 포트)] L7 정책 적용 가능하게 만듦.</span>
<span class="c">#    -A CILIUM_PRE_mangle -p tcp -m mark --mark 0xd9800200 -m comment --comment "cilium: TPROXY to host cilium-dns-egress proxy" -j TPROXY --on-port 32985 --on-ip 127.0.0.1 --tproxy-mark 0x200/0xffffffff</span>
<span class="c">#    -A CILIUM_PRE_mangle -p udp -m mark --mark 0xd9800200 -m comment --comment "cilium: TPROXY to host cilium-dns-egress proxy" -j TPROXY --on-port 32985 --on-ip 127.0.0.1 --tproxy-mark 0x200/0xffffffff</span>

<span class="nv">$ </span>iptables <span class="nt">-t</span> raw <span class="nt">-S</span> | <span class="nb">grep</span> <span class="nt">-i</span> proxy
<span class="c"># =&gt; # 프록시에서 나가는 리턴 트래픽은 NAT/conntrack이 꼬이지 않게 conntrack에서 제외. 즉, proxy ↔ pod 간 트래픽은 BPF가 직접 상태 관리.</span>
<span class="c">#    -A CILIUM_OUTPUT_raw -o lxc+ -m mark --mark 0xa00/0xfffffeff -m comment --comment "cilium: NOTRACK for proxy return traffic" -j CT --notrack</span>
<span class="c">#    -A CILIUM_OUTPUT_raw -o cilium_host -m mark --mark 0xa00/0xfffffeff -m comment --comment "cilium: NOTRACK for proxy return traffic" -j CT --notrack</span>
<span class="c">#    # L7 proxy(Envoy) → upstream(원래 목적지) 트래픽도 conntrack에서 제외.</span>
<span class="c">#    # 이유: Proxy는 자체적으로 연결 추적을 수행하므로 커널 conntrack과 이중 관리되면 충돌/성능 저하 발생.</span>
<span class="c">#    -A CILIUM_OUTPUT_raw -o lxc+ -m mark --mark 0x800/0xe00 -m comment --comment "cilium: NOTRACK for L7 proxy upstream traffic" -j CT --notrack</span>
<span class="c">#    -A CILIUM_OUTPUT_raw -o cilium_host -m mark --mark 0x800/0xe00 -m comment --comment "cilium: NOTRACK for L7 proxy upstream traffic" -j CT --notrack</span>
<span class="c">#    # 앞에서 설명한 "proxy로 리다이렉션된 트래픽" 자체도 conntrack에서 제외. </span>
<span class="c">#    # Proxy 앞뒤 트래픽 모두 커널 conntrack 대신 Cilium/BPF/Envoy가 관리.</span>
<span class="c">#    -A CILIUM_PRE_raw -m mark --mark 0x200/0xf00 -m comment --comment "cilium: NOTRACK for proxy traffic" -j CT --notrack</span>
</code></pre></div></div>

<h5 id="k8s-ctr-cilium-설치-정보-확인">[k8s-ctr] Cilium 설치 정보 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># cilium 상태 확인</span>
<span class="nv">$ </span>kubectl get cm <span class="nt">-n</span> kube-system cilium-config <span class="nt">-o</span> json | jq
<span class="nv">$ </span>cilium status
<span class="nv">$ </span>cilium config view | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'^loadbalancer|l7'</span>
<span class="c"># =&gt; enable-l7-proxy                                   true</span>
<span class="c">#    loadbalancer-l7                                   envoy</span>
<span class="c">#    loadbalancer-l7-algorithm                         round_robin</span>
<span class="c">#    loadbalancer-l7-ports </span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg status <span class="nt">--verbose</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg metrics list
</code></pre></div></div>

<h3 id="샘플-애플리케이션-배포-및-통신-문제-확인">샘플 애플리케이션 배포 및 통신 문제 확인</h3>

<h5 id="샘플-애플리케이션-배포">샘플 애플리케이션 배포</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 샘플 애플리케이션 배포</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webpod
spec:
  replicas: 2
  selector:
    matchLabels:
      app: webpod
  template:
    metadata:
      labels:
        app: webpod
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - sample-app
            topologyKey: "kubernetes.io/hostname"
      containers:
      - name: webpod
        image: traefik/whoami
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: webpod
  labels:
    app: webpod
spec:
  selector:
    app: webpod
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
  type: ClusterIP
</span><span class="no">EOF
</span><span class="c"># =&gt; deployment.apps/webpod created</span>
<span class="c">#    service/webpod created</span>

<span class="c"># k8s-ctr 노드에 curl-pod 파드 배포</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: curl-pod
  labels:
    app: curl
spec:
  nodeName: k8s-ctr
  containers:
  - name: curl
    image: nicolaka/netshoot
    command: ["tail"]
    args: ["-f", "/dev/null"]
  terminationGracePeriodSeconds: 0
</span><span class="no">EOF
</span><span class="c"># =&gt; pod/curl-pod created</span>
</code></pre></div></div>

<h5 id="통신-확인">통신 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 배포 확인</span>
<span class="nv">$ </span>kubectl get deploy,svc,ep webpod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                     READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES           SELECTOR</span>
<span class="c">#    deployment.apps/webpod   2/2     2            2           27s   webpod       traefik/whoami   app=webpod</span>
<span class="c">#    NAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE   SELECTOR</span>
<span class="c">#    service/webpod   ClusterIP   10.96.234.83   &lt;none&gt;        80/TCP    27s   app=webpod</span>
<span class="c">#    NAME               ENDPOINTS                         AGE</span>
<span class="c">#    endpoints/webpod   172.20.0.111:80,172.20.1.212:80   27s</span>
<span class="nv">$ </span>kubectl get endpointslices <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>webpod
<span class="nv">$ </span>kubectl get ciliumendpoints <span class="c"># IP 확인</span>
<span class="c"># =&gt; NAME                      SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    curl-pod                  10893               ready            172.20.0.209</span>
<span class="c">#    webpod-697b545f57-gsp8r   11530               ready            172.20.1.212</span>
<span class="c">#    webpod-697b545f57-pwvhp   11530               ready            172.20.0.111</span>

<span class="c"># 통신 문제 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 webpod | <span class="nb">grep </span>Hostname
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s --connect-timeout 1 webpod | grep Hostname; echo "---" ; sleep 1; done'</span>
<span class="c"># =&gt; Hostname: webpod-697b545f57-gsp8r</span>
<span class="c">#    ---</span>
<span class="c">#    Hostname: webpod-697b545f57-pwvhp</span>
<span class="c">#    ---</span>
<span class="c">#    Hostname: webpod-697b545f57-pwvhp</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 통신 문제가 없습니다!&lt;/span&gt;</span>

<span class="c"># cilium-dbg, map</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg ip list
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg endpoint list
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg service list
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg bpf lb list
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg bpf nat list
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg map list | <span class="nb">grep</span> <span class="nt">-v</span> <span class="s1">'0             0'</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg map get cilium_lb4_services_v2
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg map get cilium_lb4_backends_v3
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg map get cilium_lb4_reverse_nat
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg map get cilium_ipcache_v2
</code></pre></div></div>

<h5 id="pwru-간단-실습">pwru 간단 실습</h5>

<ul>
  <li>로우레벨의 정보까지 모니터링 가능한 pwru(Packet, Where Are You)를 통해 차단 이유를 확인해 보는 실습을 진행해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 다운로드 https://github.com/cilium/pwru/releases : script 로 다운로드 되어 있음.</span>
<span class="nv">$ </span>wget https://github.com/cilium/pwru/releases/download/v1.0.10/pwru-linux-arm64.tar.gz
<span class="nv">$ </span><span class="nb">tar</span> <span class="nt">-xvzf</span> pwru-linux-arm64.tar.gz
<span class="nv">$ </span><span class="nb">mv </span>pwru /usr/bin
<span class="nv">$ </span>pwru <span class="nt">-h</span>

<span class="c"># 1.1.1.1 목적지 차단 설정</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> filter <span class="nt">-I</span> OUTPUT 1 <span class="nt">-m</span> tcp <span class="nt">--proto</span> tcp <span class="nt">--dst</span> 1.1.1.1/32 <span class="nt">-j</span> DROP

<span class="c"># curl 호출 : 아래 모니터링 후 호출</span>
<span class="nv">$ </span>curl 1.1.1.1 <span class="nt">-v</span>

<span class="c"># pwru 모니터링 : 차단 이유 확인! SKB_DROP_REASON_NETFILTER_DROP </span>
<span class="nv">$ </span>pwru <span class="s1">'dst host 1.1.1.1 and tcp and dst port 80'</span>
<span class="c"># =&gt; 2025/08/21 23:45:36 Attaching kprobes (via kprobe)...</span>
<span class="c">#    1667 / 1667 [----------------------------------------------------------] 100.00% 1270 p/s</span>
<span class="c">#    2025/08/21 23:45:38 Attached (ignored 5)</span>
<span class="c">#    2025/08/21 23:45:38 Listening for events..</span>
<span class="c">#    SKB                CPU PROCESS          NETNS      MARK/x        IFACE       PROTO  MTU   LEN   TUPLE FUNC</span>
<span class="c">#    0xffff000004cb58e8 3   ~r/bin/curl:8493 4026531840 0               0         0x0000 1500  60    10.0.2.15:60880-&gt;1.1.1.1:80(tcp) __ip_local_out</span>
<span class="c">#    0xffff000004cb58e8 3   ~r/bin/curl:8493 4026531840 0               0         0x0800 1500  60    10.0.2.15:60880-&gt;1.1.1.1:80(tcp) nf_hook_slow</span>
<span class="c">#    0xffff000004cb58e8 3   ~r/bin/curl:8493 4026531840 0               0         0x0800 1500  60    10.0.2.15:60880-&gt;1.1.1.1:80(tcp) </span>
<span class="c">#       kfree_skb_reason(&lt;span style="color: green;"&gt;SKB_DROP_REASON_NETFILTER_DROP&lt;/span&gt;)</span>
<span class="c">#       &lt;span style="color: green;"&gt;👉 NETFILER에 의해 차단(DROP)됨을 확인할 수 있습니다.&lt;/span&gt;</span>
<span class="c">#    0xffff000004cb58e8 3   ~r/bin/curl:8493 4026531840 0               0         0x0800 1500  60    10.0.2.15:60880-&gt;1.1.1.1:80(tcp) skb_release_head_state</span>
<span class="c">#    0xffff000004cb58e8 3   ~r/bin/curl:8493 4026531840 0               0         0x0800 0     60    10.0.2.15:60880-&gt;1.1.1.1:80(tcp) tcp_wfree</span>
<span class="c">#    0xffff000004cb58e8 3   ~r/bin/curl:8493 4026531840 0               0         0x0800 0     60    10.0.2.15:60880-&gt;1.1.1.1:80(tcp) skb_release_data</span>
<span class="c">#    0xffff000004cb58e8 3   ~r/bin/curl:8493 4026531840 0               0         0x0800 0     60    10.0.2.15:60880-&gt;1.1.1.1:80(tcp) kfree_skbmem</span>
<span class="c">#    0xffff000004cb58e8 3   &lt;empty&gt;:0        4026531840 0               0         0x0800 0     60    10.0.2.15:60880-&gt;1.1.1.1:80(tcp) __skb_clone</span>
<span class="c">#    0xffff000004cb58e8 3   &lt;empty&gt;:0        0          0               0         0x0800 0     60    10.0.2.15:60880-&gt;1.1.1.1:80(tcp) __copy_skb_header</span>
<span class="c">#    0xffff000004cb58e8 3   &lt;empty&gt;:0        4026531840 0               0         0x0000 1500  60    10.0.2.15:60880-&gt;1.1.1.1:80(tcp) __ip_local_out</span>
<span class="c">#    0xffff000004cb58e8 3   &lt;empty&gt;:0        4026531840 0               0         0x0800 1500  60    10.0.2.15:60880-&gt;1.1.1.1:80(tcp) nf_hook_slow</span>
<span class="c">#    0xffff000004cb58e8 3   &lt;empty&gt;:0        4026531840 0               0         0x0800 1500  60    10.0.2.15:60880-&gt;1.1.1.1:80(tcp) </span>
<span class="c">#       kfree_skb_reason(&lt;span style="color: green;"&gt;SKB_DROP_REASON_NETFILTER_DROP&lt;/span&gt;)</span>
<span class="c">#    0xffff000004cb58e8 3   &lt;empty&gt;:0        4026531840 0               0         0x0800 1500  60    10.0.2.15:60880-&gt;1.1.1.1:80(tcp) skb_release_head_state</span>
<span class="c">#    0xffff000004cb58e8 3   &lt;empty&gt;:0        4026531840 0               0         0x0800 0     60    10.0.2.15:60880-&gt;1.1.1.1:80(tcp) tcp_wfree</span>
<span class="c">#    0xffff000004cb58e8 3   &lt;empty&gt;:0        4026531840 0               0         0x0800 0     60    10.0.2.15:60880-&gt;1.1.1.1:80(tcp) skb_release_data</span>
<span class="c">#    0xffff000004cb58e8 3   &lt;empty&gt;:0        4026531840 0               0         0x0800 0     60    10.0.2.15:60880-&gt;1.1.1.1:80(tcp) kfree_skbmem</span>
<span class="c">#    0xffff000004cb58e8 3   &lt;empty&gt;:0        4026531840 0               0         0x0800 0     60    10.0.2.15:60880-&gt;1.1.1.1:80(tcp) __skb_clone</span>
<span class="c">#    0xffff000004cb58e8 3   &lt;empty&gt;:0        0          0               0         0x0800 0     60    10.0.2.15:60880-&gt;1.1.1.1:80(tcp) __copy_skb_header</span>
<span class="c">#    0xffff000004cb58e8 3   &lt;empty&gt;:0        4026531840 0               0         0x0000 1500  60    10.0.2.15:60880-&gt;1.1.1.1:80(tcp) __ip_local_out</span>
<span class="c">#    0xffff000004cb58e8 3   &lt;empty&gt;:0        4026531840 0               0         0x0800 1500  60    10.0.2.15:60880-&gt;1.1.1.1:80(tcp) nf_hook_slow</span>
<span class="c">#    ^C2025/08/21 23:46:14 Received signal, exiting program..</span>
<span class="c">#    2025/08/21 23:46:14 Detaching kprobes...</span>
<span class="c">#    1662 / 1662 [------------------------------------------------------------------------------------------------------------------------------------------------------] 100.00% 33 p/s</span>
</code></pre></div></div>

<ul>
  <li>통신이 잘 되는것을 확인하였고, 기본적인 점검을 마쳤으니 본격적으로 Cilium의 기능을 살펴보도록 하겠습니다.</li>
</ul>

<hr />

<h2 id="cilium-service-mesh">Cilium Service Mesh</h2>

<h3 id="service-mesh-소개">Service Mesh 소개</h3>

<ul>
  <li>Service Mesh는 마이크로서비스 아키텍처에서 서비스 간의 통신을 관리하고 모니터링하기 위한 인프라 계층입니다. 주로 L7 트래픽 관리, 보안, 모니터링, 로깅 등을 제공합니다.</li>
  <li>등장 배경
    <ul>
      <li>기존에 하나의 모놀리식 애플리케이션이나 소수의 큰 서비스로 구성된 시스템에서는 서비스 간의 통신을 관리하기가 상대적으로 쉬웠습니다.</li>
      <li>하지만 적게는 수십개, 많게는 수천개의 마이크로서비스가 존재하는 Micro Service Architecture 환경에서는 서비스 간의 통신을 관리하고 모니터링하기가 매우 복잡해집니다.</li>
      <li>MSA가 점점 보편화 됨에 따라 서비스 간의 통신을 관리하고 모니터링하기 위해 다음과 같은 기능이 필요하게 되었습니다.
        <ul>
          <li><strong>서비스 디스커버리</strong> : 서비스가 동적으로 생성되고 삭제되기 때문에, 서비스의 IP 주소나 포트등을 자동으로 찾아주는 기능</li>
          <li><strong>모니터링</strong> : 서비스 간의 통신을 모니터링하고 성능을 측정하는 기능</li>
          <li><strong>로깅</strong> : 서비스 간의 통신을 로깅하고 분석</li>
          <li><strong>트래픽 관리</strong> : 서비스 간의 트래픽을 제어하고 관리하는 기능. Traffic Shifting, Circuit Breaker, Rate Limiting, Fault Injection 등의 기능을 포함</li>
          <li><strong>보안</strong> : 서비스 간의 통신을 암호화하고 인증하는 기능</li>
          <li><strong>정책 관리</strong> : 서비스 간의 통신을 제어하고 모니터링하기 위한 정책을 관리하는 기능</li>
        </ul>
      </li>
      <li>이러한 기능들을 서비스 단위로 언어별로 구현해야 했기에 복잡도가 증가하고, 코드 중복이 발생하게 됩니다.</li>
      <li>Service Mesh는 이러한 문제를 해결하기 위해 서비스 간의 통신을 관리하고 모니터링하기 위한 인프라 계층을 제공합니다. 
이를 통해 개발자는 비즈니스 로직에 집중할 수 있고, 운영자는 서비스 간의 통신을 관리하고 모니터링하기가 쉬워집니다.</li>
    </ul>
  </li>
  <li>대표적인 Service Mesh에는 <strong>Istio</strong>, <strong>Linkerd</strong>, <strong>Consul</strong> 등이 있고, Cilium에서도 <strong>Cilium Service Mesh</strong>로 Service Mesh 기능을 제공합니다.</li>
</ul>

<h5 id="기본-동작">기본 동작</h5>

<ul>
  <li>파드간 통신 경로에 프록시를 두고, 트래픽을 모니터링하고 제어하는 방식으로 동작합니다. 따라서 <strong>기존 애플리케이션 코드 변경 없이</strong>도 Service Mesh 기능을 사용할 수 있습니다.
    <ol>
      <li>기존 통신 환경
  <img src="/assets/2025/cilium/w6/20250824_cilium_w6_1.png" alt="img.png" class="image-center w-70 image-bg" /></li>
      <li>Proxy를 도입하여, 애플리케이션 수정없이 모든 애플리케이션 통신을 프록시를 거치도록 합니다.
  <img src="/assets/2025/cilium/w6/20250824_cilium_w6_2.png" alt="img_1.png" class="image-center w-70 image-bg" />
        <ul>
          <li>파드 내에 사이드카 컨테이너로 주입되어서 동작합니다.</li>
          <li>Proxy 컨테이너가 애플리케이션 트래픽을 가로채고, 이를 처리합니다.</li>
        </ul>
      </li>
      <li>Proxy는 DataPlane 역할을 하며, 이를 중앙에서 관리하는 ControlPlane을 두고 중앙에서 정책을 관리합니다.
  <img src="/assets/2025/cilium/w6/20250824_cilium_w6_3.png" alt="img_2.png" class="image-center w-70 image-bg" />
        <ul>
          <li>Proxy는 ControlPlane에서 설정을 관리하며, 설정관리가 유연하고 풍부한 API를 지원합니다.</li>
          <li>대표적인 Service Mesh의 Proxy로는 Google, Ibm, Lyft가 중심이 되어 개발하고있는 Envoy가 있습니다.
            <ul>
              <li>네트워크 투명성을 목표로 하며, 다양한 필터체인 (L3/L4, HTTP L7)을 지원하며, 동적 구성 API, API 기반 hot reload를 제공합니다.</li>
            </ul>
          </li>
        </ul>
      </li>
    </ol>
  </li>
  <li><strong>트래픽 모니터링</strong> : 요청의 에러율, 지연(latency), 컨넥션 개수, 요청 개수 등의 메트릭을 모니터링하며, 특정 서비스간 혹은 특정 요청 경로를 필터링해서 모니터링 할 수 있습니다.</li>
  <li><strong>트래픽 컨트롤</strong>
    <ul>
      <li>트래픽 시프팅(Traffic shifting) : 예시) 99% 기존앱 + 1% 신규앱, 특정 단말/사용자는 신규앱에 전달하여 단계적으로 적용하는 카나리 배포 기능</li>
      <li>서킷 브레이커(Circuit Breaker) : 목적지 마이크로서비스에 문제가 있을 시 접속을 차단하고 출발지 마이크로서비스에 요청 에러를 반환하여 연쇄 장애, 시스템 전제 장애 예방합니다.</li>
      <li>폴트 인젝션(Fault Injection) : 의도적으로 요청을 지연 혹은 실패를 구현합니다.</li>
      <li>속도 제한(Rate Limit) : 요청 개수를 제한하여 서비스가 과부하와 리소스 고갈을 방지합니다.</li>
    </ul>
  </li>
</ul>

<h3 id="cilium-service-mesh-소개">Cilium Service Mesh 소개</h3>

<ul>
  <li><a href="https://docs.cilium.io/en/stable/network/servicemesh/">Docs</a>, <a href="https://www.youtube.com/watch?v=lZskwr3uXn8">Youtube</a>
<img src="/assets/2025/cilium/w6/20250824_cilium_w6_4.png" alt="img.png" /></li>
  <li>Cilium Service Mesh는 Cilium의 eBPF 기반 네트워킹(L3/L4 담당)과 Envoy Proxy(L7 담당)를 결합하여 강력하고 유연한 Service Mesh 솔루션을 제공합니다.</li>
  <li><strong>L3/L4 수준 프로토콜</strong> : eBPF가 수행
    <ul>
      <li>IP, TCP, UDP 등 L3/L4 프로토콜을 지원하며, Cilium의 eBPF 기반 네트워킹 기능을 활용하여 고성능 트래픽 처리를 제공합니다.</li>
      <li>위의 그림에서 보듯이, 기존의 Service Mesh는 L3/L4 트래픽을 처리하기 위해 iptables를 사용하고, 사이드카와 VETH를 통해서 
트래픽을 가로채고 처리합니다. 이렇게 되면 TCP/IP 스택을 파드를 떠나기 전까지만도 3번이나 탐색해야 했습니다.</li>
      <li>Cilium Service Mesh는 eBPF를 통해 Proxy를 Host와 Kernel로 이동하고 사이드카를 제거하여, 
트래픽을 가로채고 처리하는데 필요한 오버헤드를 최소화합니다.</li>
    </ul>
  </li>
  <li><strong>L7 수준 프로토콜</strong> : Envoy Proxy가 수행
    <ul>
      <li>HTTP, Kafka, gRPC, DNS와 같은 애플리케이션 계층 프로토콜은 Envoy Proxy를 통해 처리됩니다.
<img src="/assets/2025/cilium/w6/20250824_cilium_w6_5.png" alt="img.png" /></li>
      <li>Cilium은 이미 타 Service Mesh에서 사이드카 형태로 사용하는 Envoy를 L7 정책이나 관측성(Observability) 기능을 위해 사용하고 있었습니다.</li>
      <li>이미 Cilium이 Envoy를 사용하고 있기 때문에 자연스럽게 Service Mesh 기능을 추가할 수 있었습니다.</li>
      <li>특히 다른 Service Mesh와 달리 Cilium Service Mesh는 Node당 하나의 Envoy Proxy만을 사용합니다.
        <ul>
          <li>istiod의 Ambient 모드와 유사하지만, Cilium의 CNI 기능을 활용하여 더 효율적이고 통합된 구성을 제공합니다.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li><strong>제공 기능</strong>
    <ul>
      <li><strong>탄력적인 연결성(Resilient Connectivity)</strong>: 서비스 간 통신은 클라우드, 클러스터, 온프레미스 등 경계를 넘어 가능해야 하며, 통신은 <strong>탄력적</strong>이고 <strong>장애 허용</strong>이 가능해야 합니다.</li>
      <li><strong>L7 트래픽 관리(L7 Traffic Management)</strong>: 로드 밸런싱, 속도 제한, 장애 복원력 등은 L7(HTTP, REST, gRPC, WebSocket 등)을 인식해야 합니다.</li>
      <li><strong>ID 기반 보안(Identity-based Security)</strong>: 네트워크 식별자에만 의존하는 보안은 더 이상 충분하지 않으며, 송신 및 수신 서비스 모두 네트워크 식별자가 아닌 ID 기반으로 상호 인증할 수 있어야 합니다.</li>
      <li><strong>관측성 및 트레이싱(Observability &amp; Tracing)</strong>: 트레이싱과 메트릭 형태의 관측성은 애플리케이션의 안정성, 성능, 가용성을 이해하고 모니터링하며 문제를 해결하는 데 매우 중요합니다.</li>
      <li><strong>투명성(Transparency)</strong>: 이 기능들은 애플리케이션 코드를 변경하지 않고도 투명하게 제공되어야 합니다.</li>
    </ul>
  </li>
</ul>

<hr />

<h2 id="k8s-ingress-support">K8S Ingress Support</h2>

<h3 id="cilium-k8s-ingress-support-소개">Cilium K8S Ingress Support 소개</h3>

<ul>
  <li><a href="https://docs.cilium.io/en/stable/network/servicemesh/ingress/">관련문서</a></li>
  <li>Cilium은 Kubernetes Ingress resource definition을 지원하며 <code class="language-plaintext highlighter-rouge">ingressClassName</code>을 cilium으로 지정함으로써 사용할 수 있습니다.</li>
  <li>경로 기반 라우팅과 TLS termination을 지원합니다. 하위 호환을 위해서 <code class="language-plaintext highlighter-rouge">kubernetes.io/ingress.class</code>을 cilium으로 설정할 수도 있습니다.</li>
  <li>Cilium Ingress Controller는 LoadBalancer Type의 Service로 배포되기 때문에, LoadBalancer를 지원하는 환경을 필요로 합니다.</li>
  <li>Cilium은 로드밸런서 모드를 다음 중 하나로 설정할 수 있습니다. 각 모드는 장단점이 있기 때문에 사용 환경에 따라 적절한 모드를 선택해야 합니다.
    <ul>
      <li><code class="language-plaintext highlighter-rouge">dedicated</code> : 해당 ingress를 위해서 단독 로드밸런서를 사용합니다. 각 ingress마다 별도의 로드밸런서를 사용하기 때문에, 충돌이 발생하지 않습니다. 하지만 자원 낭비가 발생할 수 있습니다.</li>
      <li><code class="language-plaintext highlighter-rouge">shared</code> : 모든 ingress들이 하나의 공통 로드밸런서를 공유합니다. 자원은 절약하지만 path prefix 충돌이 발생할 수 있습니다.</li>
    </ul>
  </li>
  <li>로드밸런서 모드는 변경이 가능하지만, 변경을 위해서는 LB IP 주소가 변경되어야 합니다. 따라서, 변경시 연결이 종료되며, 다운타임이 발생할 수 있습니다.</li>
</ul>

<h5 id="필수-조건">필수 조건</h5>

<ul>
  <li>Cilium은 <code class="language-plaintext highlighter-rouge">nodePort.enabled=true</code>로 설정되어 NodePort가 활성화되어 있거나 <code class="language-plaintext highlighter-rouge">kubeProxyReplacement=true</code>를 통해 kube-proxy를 대체하는 경우에만 Ingress를 지원합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">l7Proxy=true</code>로 설정해서 L7 Proxy를 활성화해야 합니다. (기본값)</li>
  <li>기본적으로 LoadBalancer 타입의 Service로 배포되기 때문에, LoadBalancer를 지원하는 환경이 필요합니다. 다른 방법으로는 NodePort를 사용하거나, Cilium 1.16 이상 버전에서는 <a href="https://docs.cilium.io/en/stable/network/servicemesh/ingress/#gs-ingress-host-network-mode">host network</a>에 L7 Proxy를 배포할 수 있습니다.</li>
</ul>

<h5 id="cilium-ingress와-cilium-gateway-api의-다른-ingress-controller와의-차이점">Cilium Ingress와 Cilium Gateway API의 다른 Ingress Controller와의 차이점</h5>

<ul>
  <li><strong>CNI와의 밀접한 연결</strong> : 다른 Ingress Controller는 CNI와 독립적으로 동작하지만, Cilium Ingress는 Cilium CNI와 밀접하게 통합되어 있습니다.</li>
  <li><strong>eBPF와 TPROXY를 사용하여 투명하게 Envoy에 전달</strong> : 다른 Ingress Controller는 iptables를 사용하여 단순 포트포워딩을 통해 트래픽을 가로채지만, Cilium Ingress는 eBPF와 TPROXY를 사용하여 트래픽을 Envoy에 투명하게 전달합니다. 이를 통해 성능과 확장성이 향상됩니다.
    <ul>
      <li>이를 통해 Client IP Visibility 같은 문제를 해결 할 수 있으며, Cilium의 네트워크 정책 엔진이 Ingress를 통해 들어오는 트래픽에 Cilium Network Policy를 적용할 수 있도록 해줍니다.</li>
      <li>동작 경로 : - [Client] → [K8s Node:Ingress/Gateway Service Port] → (eBPF Service LB) → (TPROXY) → [Envoy Proxy (Pod)]
→ (L7 라우팅/정책 처리) → (eBPF) → [Backend Pod]</li>
    </ul>
  </li>
</ul>

<h5 id="cilium-ingress-구성-및-cilium-network-policy">Cilium Ingress 구성 및 Cilium Network Policy</h5>

<ul>
  <li>노드별 Envoy Proxy에 NetworkPolicy를 적용할 수 있습니다.</li>
  <li>Cilium을 통해 각 백엔드 서비스로 전송되는 Ingress와 Gateway API 트래픽은 각 노드별 Envoy Proxy를 통해 처리됩니다.</li>
  <li>노드별 Envoy Proxy는 eBPF 정책 엔진과 상호작용할 수 있는 특수한 코드를 갖고 있으며, 트래픽에 대해 정책을 적용할 수 있습니다.
이를 통해 Envoy는 Ingress와 Gateway API 트래픽, east-west 트래픽에 대해서 Network Policy Enforcement Point로 작동할 수 있습니다.</li>
  <li>Envoy에 도착한 트래픽은 Cilium의 정책 엔진이 부여한 특수 ingress ID를 할당 받습니다.</li>
  <li>클러스터 외부에서 들어오는 트래픽은 일반적으로 클러스터에 (IP CIDR 정책이 없는 한) world identity가 할당 됩니다.</li>
  <li>이는 실제로 Cilium Ingress에 두개의 논리적 정책 집행 지점이 있다는것을 의미합니다.</li>
  <li>즉, ingress identity에 트래픽이 도착하기 전과 노드별 Envoy를 통해 백엔드 서비스로 전달되기 전입니다.
<img src="/assets/2025/cilium/w6/20250824_cilium_w6_6.png" alt="img.png" /></li>
  <li>이는 네트워크 정책을 클러스터에 적용할때 world에서 ingress로 들어갈때도 허용(allow)하고, ingress에서 클러스터의 identities (위의 그림에서는 productpage identity)로 전달될때도 동시에 허용(allow)해야 한다는 것을 의미합니다.
Gateway API에서도 동일합니다.</li>
</ul>

<h5 id="source-ip-visibility">Source IP Visibility</h5>

<ul>
  <li>기본값으로 Cilium의 Envoy는 클라이언트의 IP 주소를 <code class="language-plaintext highlighter-rouge">X-Forwarded-For</code> 헤더에 추가하여 
백엔드 서비스로 전달합니다. 이를 통해 백엔드 서비스는 클라이언트의 실제 IP 주소를 알 수 있습니다.</li>
  <li><code class="language-plaintext highlighter-rouge">trusted hops</code>를 <code class="language-plaintext highlighter-rouge">0</code>을 기본값으로 설정하여, Envoy가 <code class="language-plaintext highlighter-rouge">X-Forwarded-For</code>헤더의 값을 보는 대신, 연결이 시작된 실제 클라이언트 IP를 사용합니다.</li>
  <li>즉, <code class="language-plaintext highlighter-rouge">trusted hops</code>를 증가 시킴으로써 Envoy가 <code class="language-plaintext highlighter-rouge">X-Forwarded-For</code>의 오른쪽 부터 수를 세는 n번째 항목을 사용하게 할 수 있습니다.</li>
  <li>Envoy는 또한 <code class="language-plaintext highlighter-rouge">X-Envoy-External-Address</code> 헤더를 사용하여 <code class="language-plaintext highlighter-rouge">X-Forwarded-For</code>를 기반으로한 신뢰할 수 있는 클라이언트의 주소를 전달합니다.</li>
</ul>

<h5 id="tls-passthrough와-source-ip-visibility">TLS Passthrough와 Source IP Visibility</h5>

<ul>
  <li>Ingress와 Gateway API는 모두 TLS Passthrough 구성을 지원합니다. (Ingress는 annotation을 통해, Gateway API는 <code class="language-plaintext highlighter-rouge">TLSRoute</code> 리소스를 통해 지원합니다.)</li>
  <li>이 구성을 통해 여러 TLS Passthrough 백엔드가 Load Balancer에서 동일한 TLS 포트를 공유 할 수 있으며, Envoy는 TLS 핸드셰이크의
서버 이름 표시기(SNI)를 기반으로 백엔드를 선택합니다.</li>
  <li>동작방식 : TLS 트래픽 -&gt; Envoy에 도착 -&gt; TCP 스트림 종료 -&gt; Envoy가 클라이언트 hello를 검사하여 SNI를 찾고 백엔드 선택 -&gt; <strong>✨새로운 TCP 스트림 시작</strong> 
-&gt; 다운스트림(외부) 패킷 내부의 TLS 트래픽을 업스트림(백엔드)로 전달</li>
  <li>하지만 이러한 동작은 Source IP Visibility 문제를 발생시킬수 있습니다. 왜냐하면 Envoy가 TLS 스트림의 TCP 프록시를 수행하고 있기 때문입니다.</li>
  <li>새로운 TCP 스트림이 생기기 때문에 백엔드에서 바라본 소스 IP는 Envoy(Cilium 구성에 따라 Node IP인 경우가 많음)입니다.</li>
  <li>즉, TLS Passthrough를 사용하면 백엔드는 Envoy의 IP 주소를 소스 IP로 받게되는 문제가 발생합니다.</li>
</ul>

<h5 id="ingress-path-type과-우선순위">Ingress Path Type과 우선순위</h5>

<ul>
  <li>Ingress 규격은 다음의 세가지 타입의 경로를 지원합니다.
    <ul>
      <li>정확한 값 (<code class="language-plaintext highlighter-rouge">Exact</code>) : 경로가 정확히 일치해야 합니다.</li>
      <li>접두사 (<code class="language-plaintext highlighter-rouge">Prefix</code>) : 경로가 <code class="language-plaintext highlighter-rouge">/</code>로 구분되는 지정된 접두사로 시작해야 합니다.
        <ul>
          <li>마지막 부분은 온전히 동일해야 합니다. 예를들어서 prefix가 <code class="language-plaintext highlighter-rouge">/foo/bar</code>인 경우 <code class="language-plaintext highlighter-rouge">/foo/bar/baz</code>는 일치하지만 <code class="language-plaintext highlighter-rouge">/foo/barbaz</code>는 일치하지 않습니다.</li>
        </ul>
      </li>
      <li>구현 종속 (<code class="language-plaintext highlighter-rouge">ImplementationSpecific</code>) : Ingress Controller에 따라 다르게 동작합니다.
        <ul>
          <li>Cilium Ingress의 경우에는 <code class="language-plaintext highlighter-rouge">Regex</code>, 즉, 정규표현식을 의미합니다.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>ingress에 대해서 여러 경로가 구성되어있으면 다음의 순서로 매칭합니다
    <ol>
      <li>정확한 값 (<code class="language-plaintext highlighter-rouge">Exact</code>)</li>
      <li>구현 종속 (<code class="language-plaintext highlighter-rouge">ImplementationSpecific</code>)</li>
      <li>접두사 (<code class="language-plaintext highlighter-rouge">Prefix</code>)</li>
      <li><code class="language-plaintext highlighter-rouge">/</code> 접두사 처리</li>
    </ol>
  </li>
  <li>또한 동일한 경로 타입인 경우 경로의 길이가 긴 경로가 우선순위가 높습니다. 예를들어서 <code class="language-plaintext highlighter-rouge">/foo/bar</code>와 <code class="language-plaintext highlighter-rouge">/foo</code>가 있을때 <code class="language-plaintext highlighter-rouge">/foo/bar</code>가 우선순위가 높습니다.</li>
  <li>만약 구현 종속 방식을 사용한다면 <code class="language-plaintext highlighter-rouge">*</code>을 사용할때 주의가 필요합니다. <code class="language-plaintext highlighter-rouge">*</code>문자로 인해서 길이가 길어지지만, 실제 매칭되는 경로는 더 짧을 수 있습니다.
    <ul>
      <li>예를들어서 <code class="language-plaintext highlighter-rouge">/foo/bar/</code>와 <code class="language-plaintext highlighter-rouge">/foo/bar/*</code>가 있을때, <code class="language-plaintext highlighter-rouge">/foo/bar/*</code>는 <code class="language-plaintext highlighter-rouge">/foo/bar/</code>에도 매칭이 되지만, 길이가 길어서 
<code class="language-plaintext highlighter-rouge">/foo/bar/</code>보다 우선순위가 높습니다. 이러한 경우 엉뚱한 백엔드로 트래픽이 전달될 수 있으니 주의해야 합니다.</li>
    </ul>
  </li>
  <li>추가적인 사항은 문서를 참고하시기 바랍니다. <a href="https://docs.cilium.io/en/stable/network/servicemesh/path-types/#gs-ingress-path-types">Docs</a></li>
</ul>

<h5 id="ebpf-datapath--ingress-to-endpoint">eBPF Datapath : Ingress to Endpoint</h5>

<p><img src="/assets/2025/cilium/w6/20250824_cilium_w6_7.png" alt="img.png" class="image-center image-bg" />
<em class="image-caption"><a href="https://docs.cilium.io/en/stable/network/ebpf/lifeofapacket/#ingress-to-endpoint">https://docs.cilium.io/en/stable/network/ebpf/lifeofapacket/#ingress-to-endpoint</a></em></p>

<ul>
  <li><a href="https://docs.cilium.io/en/stable/network/ebpf/">참고 문서</a>, <a href="https://www.youtube.com/watch?v=0BKU6avwS98">Youtube</a></li>
</ul>

<h5 id="cilium-k8s-ingress-support-관련-정보-확인">Cilium K8S Ingress Support 관련 정보 확인</h5>

<ul>
  <li>Cilium Ingress와  Cilium Gateway API는 동시 활성화가 불가능합니다. 단, 다른 Ingress Controller와 Cilium Gateway API는 함께 사용할 수 있습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># cilium 설치 시 아래 파라미터 적용되어 있음</span>
<span class="c">## --set ingressController.enabled=true</span>
<span class="c">## --set ingressController.loadbalancerMode=shared</span>
<span class="c">## --set loadBalancer.l7.backend=envoy \</span>
<span class="nv">$ </span>cilium config view | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'^loadbalancer|l7'</span>
<span class="c"># =&gt; enable-l7-proxy                                   true</span>
<span class="c">#    loadbalancer-l7                                   envoy</span>
<span class="c">#    loadbalancer-l7-algorithm                         round_robin</span>
<span class="c">#    loadbalancer-l7-ports</span>

<span class="c"># ingress 에 예약된 내부 IP 확인 : node(cilium-envoy) 별로 존재</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium ip list | <span class="nb">grep </span>ingress
<span class="c"># =&gt; 172.20.0.16/32      reserved:ingress</span>
<span class="c">#    172.20.1.60/32      reserved:ingress</span>

<span class="c"># cilium-envoy 확인</span>
<span class="nv">$ </span>kubectl get ds <span class="nt">-n</span> kube-system cilium-envoy <span class="nt">-owide</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium-envoy <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                 READY   STATUS    RESTARTS   AGE     IP               NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    cilium-envoy-b25zf   1/1     Running   0          2m50s   192.168.10.101   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    cilium-envoy-hpsbc   1/1     Running   0          4m37s   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>

<span class="nv">$ </span>kc describe pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium-envoy
<span class="c"># =&gt; ...</span>
<span class="c">#    Containers:</span>
<span class="c">#      cilium-envoy:</span>
<span class="c">#        Container ID:  containerd://db82015552f31d7a16d8cada0883cdc7a4f75d39f36e76e0c582b10b1f3988e4</span>
<span class="c">#        Image:         quay.io/cilium/cilium-envoy:v1.34.4-1754895458-68cffdfa568b6b226d70a7ef81fc65dda3b890bf@sha256:247e908700012f7ef56f75908f8c965215c26a27762f296068645eb55450bda2</span>
<span class="c">#        Image ID:      quay.io/cilium/cilium-envoy@sha256:247e908700012f7ef56f75908f8c965215c26a27762f296068645eb55450bda2</span>
<span class="c">#        Port:          9964/TCP</span>
<span class="c">#        Host Port:     9964/TCP</span>
<span class="c">#        Command:</span>
<span class="c">#          /usr/bin/cilium-envoy-starter</span>
<span class="c">#        Args:</span>
<span class="c">#          --</span>
<span class="c">#          -c /var/run/cilium/envoy/bootstrap-config.json</span>
<span class="c">#          --base-id 0</span>
<span class="c">#        ...</span>
<span class="c">#        Mounts:</span>
<span class="c">#          /sys/fs/bpf from bpf-maps (rw)</span>
<span class="c">#          /var/run/cilium/envoy/ from envoy-config (ro)</span>
<span class="c">#          /var/run/cilium/envoy/artifacts from envoy-artifacts (ro)</span>
<span class="c">#          /var/run/cilium/envoy/sockets from envoy-sockets (rw)</span>
<span class="c">#          /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-jxsqh (ro)</span>
<span class="c">#    ...</span>
<span class="c">#    Volumes:</span>
<span class="c">#      envoy-sockets:</span>
<span class="c">#        Type:          HostPath (bare host directory volume)</span>
<span class="c">#        Path:          /var/run/cilium/envoy/sockets</span>
<span class="c">#        HostPathType:  DirectoryOrCreate</span>
<span class="c">#      envoy-artifacts:</span>
<span class="c">#        Type:          HostPath (bare host directory volume)</span>
<span class="c">#        Path:          /var/run/cilium/envoy/artifacts</span>
<span class="c">#        HostPathType:  DirectoryOrCreate</span>
<span class="c">#      envoy-config:</span>
<span class="c">#        Type:      ConfigMap (a volume populated by a ConfigMap)</span>
<span class="c">#        Name:      cilium-envoy-config</span>
<span class="c">#        Optional:  false</span>
<span class="c">#      bpf-maps:</span>
<span class="c">#        Type:          HostPath (bare host directory volume)</span>
<span class="c">#        Path:          /sys/fs/bpf</span>
<span class="c">#        HostPathType:  DirectoryOrCreate</span>
<span class="c">#      kube-api-access-jxsqh:</span>
<span class="c">#        Type:                    Projected (a volume that contains injected data from multiple sources)</span>
<span class="c">#        TokenExpirationSeconds:  3607</span>
<span class="c">#        ConfigMapName:           kube-root-ca.crt</span>
<span class="c">#        Optional:                false</span>
<span class="c">#        DownwardAPI:             true</span>

<span class="c">#</span>
<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-al</span> /var/run/cilium/envoy/sockets
<span class="c"># =&gt; ...</span>
<span class="c">#    srw-rw---- 1 root 1337   0 Aug 23 14:20 access_log.sock</span>
<span class="c">#    srwxr-xr-x 1 root root   0 Aug 23 14:19 admin.sock</span>
<span class="c">#    drwxr-xr-x 3 root root  60 Aug 23 14:20 envoy</span>
<span class="c">#    srw-rw---- 1 root 1337   0 Aug 23 14:20 xds.sock</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium-envoy <span class="nt">--</span> <span class="nb">ls</span> <span class="nt">-al</span> /var/run/cilium/envoy
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium-envoy <span class="nt">--</span> <span class="nb">cat</span> /var/run/cilium/envoy/bootstrap-config.json
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium-envoy <span class="nt">--</span> <span class="nb">cat</span> /var/run/cilium/envoy/bootstrap-config.json <span class="o">&gt;</span> envoy.json
<span class="nv">$ </span><span class="nb">cat </span>envoy.json | jq

<span class="c"># envoy configmap 설정 내용 확인</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system get configmap cilium-envoy-config
<span class="c"># =&gt; NAME                  DATA   AGE</span>
<span class="c">#    cilium-envoy-config   1      7m54s</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system get configmap cilium-envoy-config <span class="nt">-o</span> json <span class="se">\</span>
  | jq <span class="nt">-r</span> <span class="s1">'.data["bootstrap-config.json"]'</span> <span class="se">\</span>
  | jq <span class="nb">.</span>
<span class="c"># =&gt; ...</span>
<span class="c">#      "admin": {</span>
<span class="c">#        "address": {</span>
<span class="c">#          "pipe": {</span>
<span class="c">#            "path": "/var/run/cilium/envoy/sockets/admin.sock"</span>
<span class="c">#          }</span>
<span class="c">#        }</span>
<span class="c">#      },</span>
<span class="c">#    ...</span>
<span class="c">#        "listeners": [</span>
<span class="c">#          {</span>
<span class="c">#            "address": {</span>
<span class="c">#              "socketAddress": {</span>
<span class="c">#                "address": "0.0.0.0",</span>
<span class="c">#                "portValue": 9964  </span>
<span class="c">#    ...</span>

<span class="nv">$ </span>tree /sys/fs/bpf
<span class="c"># =&gt; /sys/fs/bpf</span>
<span class="c">#    ├── cilium</span>
<span class="c">#    │   ├── devices</span>
<span class="c">#    │   │   ├── cilium_host</span>
<span class="c">#    │   │   │   └── links</span>
<span class="c">#    │   │   │       ├── cil_from_host</span>
<span class="c">#    │   │   │       └── cil_to_host</span>
<span class="c">#    │   │   ├── cilium_net</span>
<span class="c">#    │   │   │   └── links</span>
<span class="c">#    │   │   │       └── cil_to_host</span>
<span class="c">#    │   │   ├── eth0</span>
<span class="c">#    │   │   │   └── links</span>
<span class="c">#    │   │   │       ├── cil_from_netdev</span>
<span class="c">#    │   │   │       └── cil_to_netdev</span>
<span class="c">#    │   │   └── eth1</span>
<span class="c">#    │   │       └── links</span>
<span class="c">#    │   │           ├── cil_from_netdev</span>
<span class="c">#    │   │           └── cil_to_netdev</span>
<span class="c">#    │   ├── endpoints</span>
<span class="c">#    │   │   ├── 1019</span>
<span class="c">#    │   │   │   └── links</span>
<span class="c">#    │   │   │       ├── cil_from_container</span>
<span class="c">#    │   │   │       └── cil_to_container</span>
<span class="c">#    ...</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get svc,ep <span class="nt">-n</span> kube-system cilium-envoy
<span class="c"># =&gt; NAME                   TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)    AGE</span>
<span class="c">#    service/cilium-envoy   ClusterIP   None         &lt;none&gt;        9964/TCP   9m24s</span>
<span class="c">#    </span>
<span class="c">#    NAME                     ENDPOINTS                                 AGE</span>
<span class="c">#    endpoints/cilium-envoy   192.168.10.100:9964,192.168.10.101:9964   9m22s</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get svc,ep <span class="nt">-n</span> kube-system cilium-ingress
<span class="c"># =&gt; NAME                     TYPE           CLUSTER-IP     EXTERNAL-IP   PORT(S)                      AGE</span>
<span class="c">#    service/cilium-ingress   LoadBalancer   10.96.58.190   &lt;pending&gt;     80:32243/TCP,443:30329/TCP   9m35s</span>
<span class="c">#    </span>
<span class="c">#    NAME                       ENDPOINTS              AGE</span>
<span class="c">#    endpoints/cilium-ingress   192.192.192.192:9999   9m35s  # Cilium → Envoy 간의 제어 채널(Control Plane), 외부 클라이언트가 접근하는 데이터 채널이 아님 </span>
</code></pre></div></div>

<h5 id="lb-ipam-설정-후-확인--ciliuml2announcementpolicy">LB-IPAM 설정 후 확인 : CiliumL2AnnouncementPolicy</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 현재 L2 Announcement 활성화 상태</span>
<span class="nv">$ </span>cilium config view | <span class="nb">grep </span>l2
<span class="c"># =&gt; enable-l2-announcements                           true</span>
<span class="c">#    enable-l2-neigh-discovery                         false</span>

<span class="c"># 충돌나지 않는지 대역 확인 할 것!</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: "cilium.io/v2" 
kind: CiliumLoadBalancerIPPool
metadata:
  name: "cilium-lb-ippool"
spec:
  blocks:
  - start: "192.168.10.211"
    stop:  "192.168.10.215"
</span><span class="no">EOF
</span><span class="c"># =&gt; ciliumloadbalancerippool.cilium.io/cilium-lb-ippool created</span>
<span class="nv">$ </span>kubectl get ippool
<span class="c"># =&gt; NAME               DISABLED   CONFLICTING   IPS AVAILABLE   AGE</span>
<span class="c">#    cilium-lb-ippool   false      False         4               7s</span>
<span class="nv">$ </span>kubectl get ippools <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[*].status.conditions[?(@.type!="cilium.io/PoolConflict")]}'</span> | jq
<span class="c"># =&gt; {</span>
<span class="c">#      "lastTransitionTime": "2025-08-23T06:40:43Z",</span>
<span class="c">#      "message": "5",</span>
<span class="c">#      "observedGeneration": 1,</span>
<span class="c">#      "reason": "noreason",</span>
<span class="c">#      "status": "Unknown",</span>
<span class="c">#      "type": "cilium.io/IPsTotal"</span>
<span class="c">#    }</span>
<span class="c">#    {</span>
<span class="c">#      "lastTransitionTime": "2025-08-23T06:40:43Z",</span>
<span class="c">#      "message": "4",</span>
<span class="c">#      "observedGeneration": 1,</span>
<span class="c">#      "reason": "noreason",</span>
<span class="c">#      "status": "Unknown",</span>
<span class="c">#      "type": "cilium.io/IPsAvailable"</span>
<span class="c">#    }</span>
<span class="c">#    {</span>
<span class="c">#      "lastTransitionTime": "2025-08-23T06:40:43Z",</span>
<span class="c">#      "message": "1",</span>
<span class="c">#      "observedGeneration": 1,</span>
<span class="c">#      "reason": "noreason",</span>
<span class="c">#      "status": "Unknown",</span>
<span class="c">#      "type": "cilium.io/IPsUsed"</span>
<span class="c">#    }</span>

<span class="c"># L2 Announcement 정책 설정</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: "cilium.io/v2alpha1"
kind: CiliumL2AnnouncementPolicy
metadata:
  name: policy1
spec:
  interfaces:
  - eth1
  externalIPs: true
  loadBalancerIPs: true
</span><span class="no">EOF
</span><span class="c"># =&gt; ciliuml2announcementpolicy.cilium.io/policy1 created</span>

<span class="c"># 현재 리더 역할 노드 확인</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system get lease | <span class="nb">grep</span> <span class="s2">"cilium-l2announce"</span>
<span class="c"># =&gt; cilium-l2announce-kube-system-cilium-ingress  k8s-w1  16s</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system get lease/cilium-l2announce-kube-system-cilium-ingress <span class="nt">-o</span> yaml | yq

<span class="c"># K8S 클러스터 내부 LB EX-IP로 호출 가능</span>
<span class="nv">$ LBIP</span><span class="o">=</span><span class="si">$(</span>kubectl get svc <span class="nt">-n</span> kube-system cilium-ingress <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.loadBalancer.ingress[0].ip}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$LBIP</span>
<span class="c"># =&gt; 192.168.10.211</span>
<span class="nv">$ </span>arping <span class="nt">-i</span> eth1 <span class="nv">$LBIP</span> <span class="nt">-c</span> 2
<span class="c"># =&gt; ARPING 192.168.10.211</span>
<span class="c">#    60 bytes from 08:00:27:12:18:4f (192.168.10.211): index=0 time=3.241 msec</span>
<span class="c">#    60 bytes from 08:00:27:12:18:4f (192.168.10.211): index=1 time=184.759 usec</span>
<span class="c">#    </span>
<span class="c">#    --- 192.168.10.211 statistics ---</span>
<span class="c">#    2 packets transmitted, 2 packets received,   0% unanswered (0 extra)</span>
<span class="c">#    rtt min/avg/max/std-dev = 0.185/1.713/3.241/1.528 ms</span>

<span class="c"># k8s 외부 노드(router)에서 LB EX-IP로 호출 가능 확인</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router <span class="nb">sudo </span>arping <span class="nt">-i</span> eth1 <span class="nv">$LBIP</span> <span class="nt">-c</span> 2
<span class="c"># =&gt; ARPING 192.168.10.211</span>
<span class="c">#    60 bytes from 08:00:27:12:18:4f (192.168.10.211): index=0 time=385.109 usec</span>
<span class="c">#    60 bytes from 08:00:27:12:18:4f (192.168.10.211): index=1 time=384.192 usec</span>
<span class="c">#    </span>
<span class="c">#    --- 192.168.10.211 statistics ---</span>
<span class="c">#    2 packets transmitted, 2 packets received,   0% unanswered (0 extra)</span>
<span class="c">#    rtt min/avg/max/std-dev = 0.384/0.385/0.385/0.000 ms</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s 외부 노드에서 LB EX-IP로 호출 가능합니다.&lt;/span&gt;</span>
</code></pre></div></div>

<h3 id="ingress-http-example--xff-확인">Ingress HTTP Example : XFF 확인</h3>

<ul>
  <li><a href="https://docs.cilium.io/en/stable/network/servicemesh/http/">관련문서</a></li>
  <li>이번 예제에서는 ingress를 통해 트래픽을 Istio 프로젝트에서 제공하는 <a href="https://istio.io/latest/docs/examples/bookinfo/">Bookinfo</a> 백엔드로 라우팅해 보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Deploy the Demo App : 공식 문서는 release-1.11 로 ARM CPU 에서 실패한다. 1.26 버전을 높여서 샘플 배포 할 것!</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/istio/istio/release-1.26/samples/bookinfo/platform/kube/bookinfo.yaml
<span class="c"># =&gt; ...</span>
<span class="c">#    service/productpage created</span>
<span class="c">#    serviceaccount/bookinfo-productpage created</span>
<span class="c">#    deployment.apps/productpage-v1 created</span>

<span class="nv">$ </span>kubectl get pod,svc,ep
<span class="c"># =&gt; NAME                                  READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/details-v1-766844796b-fwxlh       &lt;span style="color: green;"&gt;1/1&lt;/span&gt;     Running   0          81s</span>
<span class="c">#    pod/productpage-v1-54bb874995-5zh9b   &lt;span style="color: green;"&gt;1/1&lt;/span&gt;     Running   0          81s</span>
<span class="c">#    pod/ratings-v1-5dc79b6bcd-l4fw4       &lt;span style="color: green;"&gt;1/1&lt;/span&gt;     Running   0          81s</span>
<span class="c">#    pod/reviews-v1-598b896c9d-wxrrw       &lt;span style="color: green;"&gt;1/1&lt;/span&gt;     Running   0          81s</span>
<span class="c">#    ...</span>
<span class="c">#    </span>
<span class="c">#    NAME                  TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE</span>
<span class="c">#    service/details       &lt;span style="color: green;"&gt;ClusterIP&lt;/span&gt;   10.96.68.221    &lt;none&gt;        9080/TCP   81s</span>
<span class="c">#    service/kubernetes    &lt;span style="color: green;"&gt;ClusterIP&lt;/span&gt;   10.96.0.1       &lt;none&gt;        443/TCP    92m</span>
<span class="c">#    service/productpage   &lt;span style="color: green;"&gt;ClusterIP&lt;/span&gt;   10.96.86.254    &lt;none&gt;        9080/TCP   81s</span>
<span class="c">#    service/ratings       &lt;span style="color: green;"&gt;ClusterIP&lt;/span&gt;   10.96.108.142   &lt;none&gt;        9080/TCP   81s</span>
<span class="c">#    service/reviews       &lt;span style="color: green;"&gt;ClusterIP&lt;/span&gt;   10.96.47.199    &lt;none&gt;        9080/TCP   81s</span>
<span class="c">#    </span>
<span class="c">#    NAME                    ENDPOINTS                                               AGE</span>
<span class="c">#    endpoints/details       172.20.1.185:9080                                       81s</span>
<span class="c">#    endpoints/kubernetes    192.168.10.100:6443                                     92m</span>
<span class="c">#    endpoints/productpage   172.20.1.100:9080                                       81s</span>
<span class="c">#    endpoints/ratings       172.20.1.247:9080                                       81s</span>
<span class="c">#    endpoints/reviews       172.20.1.114:9080,172.20.1.186:9080,172.20.1.232:9080   81s</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 istio 와 다르게 사이드카 컨테이너가 없어서 파드가 1개의 (1/1) 컨테이너로 동작합니다. NodePort와 LoadBalancer 서비스도 없습니다.&lt;/span&gt;</span>

<span class="c"># </span>
<span class="nv">$ </span>kc describe ingressclasses.networking.k8s.io
<span class="c"># =&gt; Name:         cilium</span>
<span class="c">#    Labels:       app.kubernetes.io/managed-by=Helm</span>
<span class="c">#    Annotations:  meta.helm.sh/release-name: cilium</span>
<span class="c">#                  meta.helm.sh/release-namespace: kube-system</span>
<span class="c">#    Controller:   cilium.io/ingress-controller</span>
<span class="c">#    Events:       &lt;none&gt;</span>
<span class="nv">$ </span>kubectl get ingressclasses.networking.k8s.io
<span class="c"># =&gt; NAME     CONTROLLER                     PARAMETERS   AGE</span>
<span class="c">#    cilium   cilium.io/ingress-controller   &lt;none&gt;       94m</span>


<span class="c"># Basic ingress for istio bookinfo demo application, which can be found in below</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: basic-ingress
  namespace: default
spec:
  ingressClassName: cilium
  rules:
  - http:
      paths:
      - backend:
          service:
            name: details
            port:
              number: 9080
        path: /details
        pathType: Prefix
      - backend:
          service:
            name: productpage
            port:
              number: 9080
        path: /
        pathType: Prefix
</span><span class="no">EOF
</span><span class="c"># =&gt; ingress.networking.k8s.io/basic-ingress created</span>

<span class="c"># Adress 는 cilium-ingress LoadBalancer 의 EX-IP</span>
<span class="nv">$ </span>kubectl get svc <span class="nt">-n</span> kube-system cilium-ingress
<span class="c"># =&gt; NAME             TYPE           CLUSTER-IP     EXTERNAL-IP      PORT(S)                      AGE</span>
<span class="c">#    cilium-ingress   LoadBalancer   10.96.58.190   192.168.10.211   80:32243/TCP,443:30329/TCP   95m</span>

<span class="nv">$ </span>kubectl get ingress
<span class="c"># =&gt; NAME            CLASS    HOSTS   ADDRESS          PORTS   AGE</span>
<span class="c">#    basic-ingress   cilium   *       192.168.10.211   80      34s</span>

<span class="nv">$ </span>kc describe ingress
<span class="c"># =&gt; ...</span>
<span class="c">#    Rules:</span>
<span class="c">#      Host        Path  Backends</span>
<span class="c">#      ----        ----  --------</span>
<span class="c">#      *</span>
<span class="c">#                  /details   details:9080 (172.20.1.185:9080)</span>
<span class="c">#                  /          productpage:9080 (172.20.1.100:9080)</span>

<span class="c"># 호출 확인</span>
<span class="nv">$ LBIP</span><span class="o">=</span><span class="si">$(</span>kubectl get svc <span class="nt">-n</span> kube-system cilium-ingress <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.loadBalancer.ingress[0].ip}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$LBIP</span>
<span class="c"># =&gt; 192.168.10.211</span>

<span class="c"># 실패하는 호출이 있는가?</span>
<span class="nv">$ </span>curl <span class="nt">-so</span> /dev/null <span class="nt">-w</span> <span class="s2">"%{http_code}</span><span class="se">\n</span><span class="s2">"</span> http://<span class="nv">$LBIP</span>/
<span class="c"># =&gt; 200</span>
<span class="nv">$ </span>curl <span class="nt">-so</span> /dev/null <span class="nt">-w</span> <span class="s2">"%{http_code}</span><span class="se">\n</span><span class="s2">"</span> http://<span class="nv">$LBIP</span>/details/1
<span class="c"># =&gt; 200</span>
<span class="nv">$ </span>curl <span class="nt">-so</span> /dev/null <span class="nt">-w</span> <span class="s2">"%{http_code}</span><span class="se">\n</span><span class="s2">"</span> http://<span class="nv">$LBIP</span>/ratings
<span class="c"># =&gt; 404</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 실패하였습니다. 앞서 살펴본 ingress 룰에는 /ratings가 없고, `/`를 담당하는 productpage에서도 처리하지 않는 URL이기 때문입니다.&lt;/span&gt;</span>

<span class="c"># Access the Bookinfo application</span>
<span class="nv">$ </span>curl <span class="s2">"http://</span><span class="nv">$LBIP</span><span class="s2">/productpage?u=normal"</span>

<span class="c"># 모니터링</span>
<span class="nv">$ </span>cilium hubble port-forward&amp;
<span class="c"># =&gt; ℹ️   Hubble Relay is available at 127.0.0.1:4245</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">-t</span> l7
<span class="c"># or </span>
<span class="c"># $ hubble observe -f --identity ingress</span>
<span class="c"># =&gt; ...</span>

<span class="c"># router에서 호출</span>
<span class="nv">$ </span>curl <span class="nt">-so</span> /dev/null <span class="nt">-w</span> <span class="s2">"%{http_code}</span><span class="se">\n</span><span class="s2">"</span> http://<span class="nv">$LBIP</span>/
<span class="c"># =&gt; 200</span>
<span class="nv">$ </span>curl <span class="nt">-so</span> /dev/null <span class="nt">-w</span> <span class="s2">"%{http_code}</span><span class="se">\n</span><span class="s2">"</span> http://<span class="nv">$LBIP</span>/details/1
<span class="c"># =&gt; 200</span>

<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router curl <span class="nt">-s</span> http://<span class="nv">$LBIP</span>/
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router curl <span class="nt">-s</span> http://<span class="nv">$LBIP</span>/details/1 <span class="nt">-v</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    &lt; server: envoy</span>
<span class="c">#    &lt; date: Sat, 23 Aug 2025 07:06:51 GMT</span>
<span class="c">#    &lt; content-length: 178</span>
<span class="c">#    &lt; x-envoy-upstream-service-time: 18</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router curl <span class="nt">-s</span> http://<span class="nv">$LBIP</span>/ratings
<span class="c"># =&gt; &lt;!doctype html&gt;</span>
<span class="c">#    &lt;html lang=en&gt;</span>
<span class="c">#    &lt;title&gt;404 Not Found&lt;/title&gt;</span>
<span class="c">#    &lt;h1&gt;Not Found&lt;/h1&gt;</span>
<span class="c">#    &lt;p&gt;The requested URL was not found on the server. If you entered the URL manually please check your spelling and try again.&lt;/p&gt;</span>

<span class="c"># productpage-v1 파드가 배포된 노드 확인 </span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>productpage <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                              READY   STATUS    RESTARTS   AGE   IP             NODE     NOMINATED NODE   READINESS GATES</span>
<span class="c">#    productpage-v1-54bb874995-5zh9b   1/1     Running   0          17m   172.20.1.100   k8s-w1   &lt;none&gt;           &lt;none&gt;</span>

<span class="c"># 해당 노드(k8s-w1)에서 veth 인터페이스 정보 확인</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w1
<span class="nt">---</span>
<span class="nv">$ PROID</span><span class="o">=</span>172.20.1.100

<span class="nv">$ </span>ip route |grep <span class="nv">$PROID</span>
<span class="c"># =&gt; 172.20.1.100 dev &lt;span style="color: green;"&gt;lxcdd0576ed651e&lt;/span&gt; proto kernel scope link</span>

<span class="nv">$ PROVETH</span><span class="o">=</span>lxcdd0576ed651e

<span class="c"># ngrep 로 veth 트래픽 캡쳐 : productpage 는 9080 TCP Port 사용</span>
<span class="nv">$ </span>ngrep <span class="nt">-tW</span> byline <span class="nt">-d</span> <span class="nv">$PROVETH</span> <span class="s1">''</span> <span class="s1">'tcp port 9080'</span>

<span class="c"># 외부에서 호출 시도</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router curl <span class="nt">-s</span> http://<span class="nv">$LBIP</span>

<span class="c"># ngrep 로 veth 트래픽 캡쳐 : productpage 는 9080 TCP Port 사용</span>
<span class="nv">$ </span>ngrep <span class="nt">-tW</span> byline <span class="nt">-d</span> <span class="nv">$PROVETH</span> <span class="s1">''</span> <span class="s1">'tcp port 9080'</span>
<span class="c"># =&gt; &lt;span style="color: green;"&gt;## igress(envoy) 가 XFF에 client-ip 담고, 목적지 파드로 요청&lt;/span&gt;</span>
<span class="c">#    T 2025/08/23 16:10:12.309006 10.0.2.15:32780 -&gt; 172.20.1.100:9080 [AP] #4</span>
<span class="c">#    GET / HTTP/1.1.</span>
<span class="c">#    host: 192.168.10.211.</span>
<span class="c">#    user-agent: curl/8.5.0.</span>
<span class="c">#    accept: */*.</span>
<span class="c">#    &lt;span style="color: green;"&gt;x-forwarded-for: 192.168.10.200.&lt;/span&gt;</span>
<span class="c">#    x-forwarded-proto: http.</span>
<span class="c">#    x-envoy-internal: true.</span>
<span class="c">#    x-request-id: 6d2bda20-5f73-41d3-ac90-159cd56a2386.</span>
<span class="c">#    .</span>
<span class="c">#    </span>
<span class="c">#    &lt;span style="color: green;"&gt;## igress(envoy)로 리턴하는 트래픽&lt;/span&gt;</span>
<span class="c">#    T 2025/08/23 16:10:12.325238 172.20.1.100:9080 -&gt; 10.0.2.15:32780 [AP] #6</span>
<span class="c">#    HTTP/1.1 200 OK.</span>
<span class="c">#    Server: gunicorn.</span>
<span class="c">#    Date: Sat, 23 Aug 2025 07:10:12 GMT.</span>
<span class="c">#    Connection: keep-alive.</span>
<span class="c">#    Content-Type: text/html; charset=utf-8.</span>
<span class="c">#    Content-Length: 2080.</span>
</code></pre></div></div>

<h3 id="ingress-nginx-설치하여-cilium-ingress와-공존-가능여부-확인">Ingress-Nginx 설치하여 Cilium Ingress와 공존 가능여부 확인</h3>

<ul>
  <li>이번에는 Cilium ingress와 Ingress-Nginx가 동시에 활성화 될 수 있는지 확인해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Ingress-Nginx 컨트롤러 설치</span>
<span class="nv">$ </span>helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
<span class="c"># =&gt; "ingress-nginx" has been added to your repositories</span>
<span class="nv">$ </span>helm <span class="nb">install </span>ingress-nginx ingress-nginx/ingress-nginx <span class="nt">--create-namespace</span> <span class="nt">-n</span> ingress-nginx
<span class="c"># =&gt; NAME: ingress-nginx</span>
<span class="c">#    LAST DEPLOYED: Sat Aug 23 16:18:18 2025</span>
<span class="c">#    NAMESPACE: ingress-nginx</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 1</span>
<span class="c">#    TEST SUITE: None</span>
<span class="c">#    NOTES:</span>
<span class="c">#    The ingress-nginx controller has been installed.</span>
<span class="c">#    It may take a few minutes for the load balancer IP to be available.</span>
<span class="c">#    ...</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get all <span class="nt">-n</span> ingress-nginx
<span class="c"># =&gt; NAME                                            READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/ingress-nginx-controller-67bbdf7d8d-qmtp2   1/1     Running   0          34s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                         TYPE           CLUSTER-IP     EXTERNAL-IP      PORT(S)                      AGE</span>
<span class="c">#    service/ingress-nginx-controller             LoadBalancer   10.96.45.145   192.168.10.212   80:32426/TCP,443:30289/TCP   35s</span>
<span class="c">#    service/ingress-nginx-controller-admission   ClusterIP      10.96.79.200   &lt;none&gt;           443/TCP                      35s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                       READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/ingress-nginx-controller   1/1     1            1           35s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                                  DESIRED   CURRENT   READY   AGE</span>
<span class="c">#    replicaset.apps/ingress-nginx-controller-67bbdf7d8d   1         1         1       34s</span>
<span class="nv">$ </span>kc describe svc <span class="nt">-n</span> ingress-nginx ingress-nginx-controller
<span class="c"># =&gt; Name:                     ingress-nginx-controller</span>
<span class="c">#    Namespace:                ingress-nginx</span>
<span class="c">#    ...</span>
<span class="c">#    LoadBalancer Ingress:     192.168.10.212 (VIP)</span>
<span class="c">#    Port:                     http  80/TCP</span>
<span class="c">#    TargetPort:               http/TCP</span>
<span class="c">#    NodePort:                 http  32426/TCP</span>
<span class="c">#    Endpoints:                172.20.1.154:80</span>
<span class="c">#    Port:                     https  443/TCP</span>
<span class="c">#    TargetPort:               https/TCP</span>
<span class="c">#    NodePort:                 https  30289/TCP</span>
<span class="c">#    Endpoints:                172.20.1.154:443</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>kubectl get svc <span class="nt">-n</span> ingress-nginx
<span class="c"># =&gt; NAME                                 TYPE           CLUSTER-IP     EXTERNAL-IP      PORT(S)                      AGE</span>
<span class="c">#    ingress-nginx-controller             LoadBalancer   10.96.45.145   192.168.10.212   80:32426/TCP,443:30289/TCP   2m</span>
<span class="c">#    ingress-nginx-controller-admission   ClusterIP      10.96.79.200   &lt;none&gt;           443/TCP                      2m</span>
<span class="nv">$ </span>kubectl get ingressclasses.networking.k8s.io
<span class="c"># =&gt; NAME     CONTROLLER                     PARAMETERS   AGE</span>
<span class="c">#    cilium   cilium.io/ingress-controller   &lt;none&gt;       121m</span>
<span class="c">#    nginx    k8s.io/ingress-nginx           &lt;none&gt;       2m6s</span>

<span class="c"># ingress 설정</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: webpod-ingress-nginx
  namespace: default
spec:
  ingressClassName: nginx
  rules:
  - host: nginx.webpod.local
    http:
      paths:
      - backend:
          service:
            name: webpod
            port:
              number: 80
        path: /
        pathType: Prefix
</span><span class="no">EOF
</span><span class="c"># =&gt; ingress.networking.k8s.io/webpod-ingress-nginx created</span>

<span class="c"># ingress LB EX-IP 할당 까지 다소 시간 소요..</span>
<span class="nv">$ </span>kubectl get ingress <span class="nt">-w</span>
<span class="c"># =&gt; NAME                   CLASS    HOSTS                ADDRESS          PORTS   AGE</span>
<span class="c">#    basic-ingress          cilium   *                    192.168.10.211   80      29m</span>
<span class="c">#    webpod-ingress-nginx   nginx    nginx.webpod.local   &lt;span style="color: green;"&gt;192.168.10.212&lt;/span&gt;   80      32s</span>

<span class="c">#</span>
<span class="nv">$ LB2IP</span><span class="o">=</span><span class="si">$(</span>kubectl get svc <span class="nt">-n</span> ingress-nginx ingress-nginx-controller <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.loadBalancer.ingress[0].ip}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$LB2IP</span>
<span class="c"># =&gt; 192.168.10.211</span>

<span class="nv">$ </span>curl <span class="nv">$LB2IP</span>
<span class="c"># =&gt; &lt;html&gt;</span>
<span class="c">#    &lt;head&gt;&lt;title&gt;404 Not Found&lt;/title&gt;&lt;/head&gt;</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 nginx.webpod.local 호스트명이 없어서 404 에러 발생&lt;/span&gt;</span>
<span class="nv">$ </span>curl <span class="nt">-H</span> <span class="s2">"Host: nginx.webpod.local"</span> <span class="nv">$LB2IP</span>
<span class="c"># =&gt; Hostname: webpod-697b545f57-b5vtj</span>
<span class="c">#    IP: 172.20.0.70</span>
<span class="c">#    RemoteAddr: 172.20.1.154:40984</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: nginx.webpod.local</span>
<span class="c">#    User-Agent: curl/8.5.0</span>
<span class="c">#    Accept: */*</span>
<span class="c">#    X-Forwarded-For: &lt;span style="color: green;"&gt;192.168.10.100&lt;/span&gt;</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>curl <span class="nt">-H</span> <span class="s2">"Host: nginx.webpod.local"</span> <span class="nv">$LB2IP</span>
<span class="c"># =&gt; Hostname: webpod-697b545f57-jp4wc</span>
<span class="c">#    IP: 172.20.1.206</span>
<span class="c">#    RemoteAddr: 172.20.1.154:48320</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: nginx.webpod.local</span>
<span class="c">#    User-Agent: curl/8.5.0</span>
<span class="c">#    Accept: */*</span>
<span class="c">#    X-Forwarded-For: 192.168.10.100</span>
<span class="c">#    ...</span>

<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router <span class="s2">"curl -s -H 'Host: nginx.webpod.local' </span><span class="nv">$LB2IP</span><span class="s2">"</span>
<span class="c"># =&gt; Hostname: webpod-697b545f57-jp4wc</span>
<span class="c">#    ...</span>
<span class="c">#    X-Forwarded-For: 192.168.10.200</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router <span class="s2">"curl -s -H 'Host: nginx.webpod.local' </span><span class="nv">$LB2IP</span><span class="s2">"</span>
<span class="c"># =&gt; Hostname: webpod-697b545f57-b5vtj</span>
<span class="c">#    ...</span>
<span class="c">#    X-Forwarded-For: 192.168.10.200</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<ul>
  <li>Cilium Ingress와 Nginx ingress는 동시 활성화가 가능하며, 각각의 EX-IP로 정상 호출이 가능한 것을 확인할 수 있습니다.</li>
</ul>

<h3 id="dedicated-mode">Dedicated Mode</h3>

<ul>
  <li>Cilium Ingress는 기본적으로 Shared Mode로 동작합니다. Dedicated Mode로 변경하는 방법을 알아보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Basic ingress for istio bookinfo demo application, which can be found in below</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: webpod-ingress
  namespace: default
  annotations:
    ingress.cilium.io/loadbalancer-mode: dedicated
spec:
  ingressClassName: cilium
  rules:
  - http:
      paths:
      - backend:
          service:
            name: webpod
            port:
              number: 80
        path: /
        pathType: Prefix
</span><span class="no">EOF
</span><span class="c"># =&gt; ingress.networking.k8s.io/webpod-ingress created</span>

<span class="c">#</span>
<span class="nv">$ </span>kc describe ingress webpod-ingress
<span class="c"># =&gt; Name:             webpod-ingress</span>
<span class="c">#    Labels:           &lt;none&gt;</span>
<span class="c">#    Namespace:        default</span>
<span class="c">#    Address:          192.168.10.213</span>
<span class="c">#    Ingress Class:    cilium</span>
<span class="c">#    Default backend:  &lt;default&gt;</span>
<span class="c">#    Rules:</span>
<span class="c">#      Host        Path  Backends</span>
<span class="c">#      ----        ----  --------</span>
<span class="c">#      *</span>
<span class="c">#                  /   webpod:80 (172.20.1.206:80,172.20.0.70:80)</span>
<span class="c">#    Annotations:  ingress.cilium.io/loadbalancer-mode: &lt;span style="color: green;"&gt;dedicated&lt;/span&gt;</span>
<span class="nv">$ </span>kubectl get ingress
<span class="c"># =&gt; NAME                   CLASS    HOSTS                ADDRESS          PORTS   AGE</span>
<span class="c">#    basic-ingress          cilium   *                    192.168.10.211   80      45m</span>
<span class="c">#    &lt;span style="color: green;"&gt;webpod-ingress&lt;/span&gt;         cilium   *                    192.168.10.213   80      29s</span>
<span class="c">#    webpod-ingress-nginx   nginx    nginx.webpod.local   192.168.10.212   80      16m</span>

<span class="nv">$ </span>kubectl get svc,ep cilium-ingress-webpod-ingress
<span class="c"># =&gt; NAME                                    TYPE           CLUSTER-IP      EXTERNAL-IP      PORT(S)                      AGE</span>
<span class="c">#    service/cilium-ingress-webpod-ingress   LoadBalancer   10.96.153.108   192.168.10.213   80:30159/TCP,443:30408/TCP   50s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                      ENDPOINTS              AGE</span>
<span class="c">#    endpoints/cilium-ingress-webpod-ingress   192.192.192.192:9999   50s</span>

<span class="c"># LB EX-IP에 대한 L2 Announcement 의 Leader 노드 확인</span>
<span class="nv">$ </span>kubectl get lease <span class="nt">-n</span> kube-system | <span class="nb">grep </span>ingress
<span class="c"># =&gt; cilium-l2announce-default-cilium-ingress-webpod-ingress   k8s-w1  80s</span>
<span class="c">#    cilium-l2announce-ingress-nginx-ingress-nginx-controller  k8s-w1  21m</span>
<span class="c">#    cilium-l2announce-kube-system-cilium-ingress              k8s-w1  58m</span>

<span class="c"># webpod 파드 IP 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>webpod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                      READY   STATUS    RESTARTS   AGE   IP             NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    webpod-697b545f57-b5vtj   1/1     Running   0          12m   172.20.0.70    k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-697b545f57-jp4wc   1/1     Running   0          12m   172.20.1.206   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>

<span class="c"># k8c-ctr, k8s-w1 노드에서 파드 IP에 veth 찾기(ip -c route) 이후 ngrep 로 각각 트래픽 캡쳐</span>

<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-ctr
<span class="nt">---</span> 
<span class="nv">$ </span>ip route | <span class="nb">grep </span>172.20.0.70
<span class="c"># =&gt; 172.20.0.70 dev lxc148c311965e6 proto kernel scope link</span>
<span class="nv">$ WPODVETHCTR</span><span class="o">=</span>lxc148c311965e6
<span class="nv">$ </span>ngrep <span class="nt">-tW</span> byline <span class="nt">-d</span> <span class="nv">$WPODVETHCTR</span> <span class="s1">''</span> <span class="s1">'tcp port 80'</span>
<span class="c"># =&gt; lxc148c311965e6: no IPv4 address assigned: Cannot assign requested address</span>
<span class="c">#    interface: lxc148c311965e6</span>
<span class="c">#    filter: ( tcp port 80 ) and ((ip || ip6) || (vlan &amp;&amp; (ip || ip6)))</span>
<span class="c">#    ###</span>
<span class="c">#    T 2025/08/23 16:48:28.123959 172.20.0.70:80 -&gt; 172.20.1.60:40517 [AP] #3</span>
<span class="c">#    HTTP/1.1 200 OK.</span>
<span class="c">#    Date: Sat, 23 Aug 2025 07:48:28 GMT.</span>
<span class="c">#    Content-Length: 343.</span>
<span class="c">#    Content-Type: text/plain; charset=utf-8.</span>
<span class="c">#    .</span>
<span class="c">#    Hostname: webpod-697b545f57-b5vtj</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: ::1</span>
<span class="c">#    IP: 172.20.0.70</span>
<span class="c">#    IP: fe80::d46d:b0ff:fe0d:619a</span>
<span class="c">#    RemoteAddr: 172.20.1.60:40517</span>
<span class="c">#    GET / HTTP/1.1.</span>
<span class="c">#    Host: 192.168.10.213.</span>
<span class="c">#    User-Agent: curl/8.5.0.</span>
<span class="c">#    Accept: */*.</span>
<span class="c">#    X-Envoy-Internal: true.</span>
<span class="c">#    X-Forwarded-For: 192.168.10.200.</span>
<span class="c">#    X-Forwarded-Proto: http.</span>
<span class="c">#    X-Request-Id: 01bd1da4-e1f1-47e7-958d-1032c55ec11b.</span>
<span class="c">#    ...</span>
<span class="nt">---</span>

<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w1
<span class="nt">---</span> 
<span class="nv">$ </span>ip route | <span class="nb">grep </span>172.20.1.206
<span class="c"># =&gt; 172.20.1.206 dev lxc9e0d1071b53f proto kernel scope link</span>
<span class="nv">$ WPODVETHW1</span><span class="o">=</span>lxc9e0d1071b53f
<span class="nv">$ </span>ngrep <span class="nt">-tW</span> byline <span class="nt">-d</span> <span class="nv">$WPODVETHW1</span> <span class="s1">''</span> <span class="s1">'tcp port 80'</span>
<span class="c"># =&gt; lxc9e0d1071b53f: no IPv4 address assigned: Cannot assign requested address</span>
<span class="c">#    interface: lxc9e0d1071b53f</span>
<span class="c">#    filter: ( tcp port 80 ) and ((ip || ip6) || (vlan &amp;&amp; (ip || ip6)))</span>
<span class="c">#    ####</span>
<span class="c">#    T 2025/08/23 16:48:29.296230 10.0.2.15:34958 -&gt; 172.20.1.206:80 [AP] #4</span>
<span class="c">#    GET / HTTP/1.1.</span>
<span class="c">#    host: 192.168.10.213.</span>
<span class="c">#    user-agent: curl/8.5.0.</span>
<span class="c">#    accept: */*.</span>
<span class="c">#    x-forwarded-for: 192.168.10.200.</span>
<span class="c">#    x-forwarded-proto: http.</span>
<span class="c">#    x-envoy-internal: true.</span>
<span class="c">#    x-request-id: 80e8099d-b64b-4f05-805e-72a4d670024f.</span>
<span class="c">#    .</span>
<span class="c">#    </span>
<span class="c">#    ##</span>
<span class="c">#    T 2025/08/23 16:48:29.300200 172.20.1.206:80 -&gt; 10.0.2.15:34958 [AP] #6</span>
<span class="c">#    HTTP/1.1 200 OK.</span>
<span class="c">#    Date: Sat, 23 Aug 2025 07:48:29 GMT.</span>
<span class="c">#    Content-Length: 342.</span>
<span class="c">#    Content-Type: text/plain; charset=utf-8.</span>
<span class="c">#    .</span>
<span class="c">#    Hostname: webpod-697b545f57-jp4wc</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: ::1</span>
<span class="c">#    IP: 172.20.1.206</span>
<span class="c">#    IP: fe80::a4ee:c1ff:fed4:b3c3</span>
<span class="c">#    RemoteAddr: 10.0.2.15:34958</span>
<span class="c">#    GET / HTTP/1.1.</span>
<span class="c">#    Host: 192.168.10.213.</span>
<span class="c">#    User-Agent: curl/8.5.0.</span>
<span class="c">#    Accept: */*.</span>
<span class="c">#    X-Envoy-Internal: true.</span>
<span class="c">#    X-Forwarded-For: 192.168.10.200.</span>
<span class="c">#    X-Forwarded-Proto: http.</span>
<span class="c">#    X-Request-Id: 80e8099d-b64b-4f05-805e-72a4d670024f.</span>
<span class="c">#    ...</span>
<span class="nt">---</span>

<span class="c"># router 에서 호출 확인</span>
<span class="nv">$ LB2IP</span><span class="o">=</span><span class="si">$(</span>kubectl get svc cilium-ingress-webpod-ingress <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.loadBalancer.ingress[0].ip}'</span><span class="si">)</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router curl <span class="nt">-s</span> http://<span class="nv">$LB2IP</span>
<span class="c"># =&gt; Hostname: webpod-697b545f57-jp4wc</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: ::1</span>
<span class="c">#    IP: 172.20.1.206</span>
<span class="c">#    IP: fe80::a4ee:c1ff:fed4:b3c3</span>
<span class="c">#    RemoteAddr: 10.0.2.15:34958  # webpod 인입 시 S.IP : 마치 L2 Leader 노드에 webpod로 전달되어, 소스IP가 해당 노드의 첫 번째 NIC IP,</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: 192.168.10.213</span>
<span class="c">#    User-Agent: curl/8.5.0</span>
<span class="c">#    Accept: */*</span>
<span class="c">#    X-Envoy-Internal: true</span>
<span class="c">#    X-Forwarded-For: 192.168.10.200</span>
<span class="c">#    X-Forwarded-Proto: http</span>
<span class="c">#    X-Request-Id: 80e8099d-b64b-4f05-805e-72a4d670024f</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router curl <span class="nt">-s</span> http://<span class="nv">$LB2IP</span>
<span class="c"># =&gt; Hostname: webpod-697b545f57-b5vtj</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: ::1</span>
<span class="c">#    IP: 172.20.0.70</span>
<span class="c">#    IP: fe80::d46d:b0ff:fe0d:619a</span>
<span class="c">#    RemoteAddr: 172.20.1.60:40517  # webpod 인입 시 S.IP : L2 Leader 노드(k8s-w1)에서 다른 노드에 파드로 전달되어, ingress 예약IP로 SNAT</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: 192.168.10.213</span>
<span class="c">#    User-Agent: curl/8.5.0</span>
<span class="c">#    Accept: */*</span>
<span class="c">#    X-Envoy-Internal: true</span>
<span class="c">#    X-Forwarded-For: 192.168.10.200</span>
<span class="c">#    X-Forwarded-Proto: http</span>
<span class="c">#    X-Request-Id: 01bd1da4-e1f1-47e7-958d-1032c55ec11b</span>
</code></pre></div></div>

<h3 id="ingress-and-network-policies-example">Ingress and Network Policies Example</h3>

<ul>
  <li><a href="https://docs.cilium.io/en/stable/network/servicemesh/ingress-and-network-policy/">관련 문서</a></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 클러스터 전체(모든 네임스페이스)에 적용되는 정책 : 참고로 아래 정책 적용 후 Hubble-ui 로 접속 불가!</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: "cilium.io/v2"
kind: CiliumClusterwideNetworkPolicy
metadata:
  name: "external-lockdown"
spec:
  description: "Block all the traffic originating from outside of the cluster"
  endpointSelector: {}
  ingress:
  - fromEntities:
    - cluster
</span><span class="no">EOF
</span><span class="c"># =&gt; ciliumclusterwidenetworkpolicy.cilium.io/external-lockdown created</span>
<span class="nv">$ </span>kubectl get ciliumclusterwidenetworkpolicy
<span class="c"># =&gt; NAME                VALID</span>
<span class="c">#    external-lockdown   True</span>

<span class="c">#</span>
<span class="nv">$ </span>curl <span class="nt">--fail</span> <span class="nt">-v</span> http://<span class="s2">"</span><span class="nv">$LBIP</span><span class="s2">"</span>/details/1
<span class="c"># =&gt; &lt; HTTP/1.1 403 Forbidden</span>

<span class="c"># </span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--identity</span> ingress
<span class="c">## k8s-ctr 에서 curl 실행 시</span>
<span class="c"># =&gt; Aug 23 08:10:11.770: 127.0.0.1:36726 (ingress) -&gt; 127.0.0.1:15778 (world) http-request DROPPED (HTTP/1.1 GET http://192.168.10.211/details/1)</span>
<span class="c">#    Aug 23 08:10:11.770: 127.0.0.1:36726 (ingress) &lt;- 127.0.0.1:15778 (world) http-response FORWARDED (HTTP/1.1 403 1ms (GET http://192.168.10.211/details/1))</span>
<span class="c">## router 에서 curl 실행 시</span>
<span class="c"># =&gt; Aug 23 08:10:20.475: 192.168.10.200:43490 (ingress) -&gt; kube-system/cilium-ingress:80 (world) http-request DROPPED (HTTP/1.1 GET http://192.168.10.211/details/1)</span>
<span class="c">#    Aug 23 08:10:20.475: 192.168.10.200:43490 (ingress) &lt;- kube-system/cilium-ingress:80 (world) http-response FORWARDED (HTTP/1.1 403 0ms (GET http://192.168.10.211/details/1))</span>

<span class="c"># router와 k8s-ctr의 요청은 허용하는 정책 적용 </span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: "cilium.io/v2"
kind: CiliumClusterwideNetworkPolicy
metadata:
  name: "allow-cidr"
spec:
  description: "Allow all the traffic originating from a specific CIDR"
  endpointSelector:
    matchExpressions:
    - key: reserved:ingress
      operator: Exists
  ingress:
  - fromCIDRSet:
    # Please update the CIDR to match your environment
    - cidr: 192.168.10.200/32
    - cidr: 127.0.0.1/32
</span><span class="no">EOF
</span><span class="c"># =&gt; ciliumclusterwidenetworkpolicy.cilium.io/allow-cidr created</span>

<span class="c"># 요청 성공! : k8s-ctr , router 모두 가능</span>
<span class="nv">$ </span>curl <span class="nt">--fail</span> <span class="nt">-v</span> http://<span class="s2">"</span><span class="nv">$LBIP</span><span class="s2">"</span>/details/1
<span class="c"># =&gt; &lt; HTTP/1.1 200 OK</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router <span class="s2">"curl -s --fail -v http://"</span><span class="nv">$LBIP</span><span class="s2">"/details/1"</span>
<span class="c"># =&gt; *   Trying 192.168.10.211:80...</span>
<span class="c">#    * Connected to 192.168.10.211 (192.168.10.211) port 80</span>
<span class="c">#    &gt; GET /details/1 HTTP/1.1</span>
<span class="c">#    &gt; Host: 192.168.10.211</span>
<span class="c">#    &gt; User-Agent: curl/8.5.0</span>
<span class="c">#    &gt; Accept: */*</span>
<span class="c">#    &gt;</span>
<span class="c">#    {"id":1,"author":"William Shakespeare","year":1595,"type":"paperback","pages":200,"publisher":"PublisherA","language":"English","ISBN-10":"1234567890","ISBN-13":"123-1234567890"}&lt; HTTP/1.1 200 OK</span>
<span class="c">#    &lt; content-type: application/json</span>
<span class="c">#    &lt; server: envoy</span>
<span class="c">#    &lt; date: Sat, 23 Aug 2025 08:11:39 GMT</span>
<span class="c">#    &lt; content-length: 178</span>
<span class="c">#    &lt; x-envoy-upstream-service-time: 16</span>
<span class="c">#    &lt;</span>
<span class="c">#    { [178 bytes data]</span>
<span class="c">#    * Connection #0 to host 192.168.10.211 left intact</span>

<span class="c"># Default Deny Ingress Policy : DNS쿼리와 kube-system내의 파드 제외 to deny all traffic by default</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: cilium.io/v2
kind: CiliumClusterwideNetworkPolicy
metadata:
  name: "default-deny"
spec:
  description: "Block all the traffic (except DNS) by default"
  egress:
  - toEndpoints:
    - matchLabels:
        io.kubernetes.pod.namespace: kube-system
        k8s-app: kube-dns
    toPorts:
    - ports:
      - port: '53'
        protocol: UDP
      rules:
        dns:
        - matchPattern: '*'
  endpointSelector:
    matchExpressions:
    - key: io.kubernetes.pod.namespace
      operator: NotIn
      values:
      - kube-system
</span><span class="no">EOF
</span><span class="c"># =&gt; ciliumclusterwidenetworkpolicy.cilium.io/default-deny created</span>
<span class="nv">$ </span>kubectl get ciliumclusterwidenetworkpolicy
<span class="c"># =&gt; NAME                VALID</span>
<span class="c">#    allow-cidr          True</span>
<span class="c">#    default-deny        True</span>
<span class="c">#    external-lockdown   True</span>

<span class="c"># 요청 </span>
<span class="nv">$ </span>curl <span class="nt">--fail</span> <span class="nt">-v</span> http://<span class="s2">"</span><span class="nv">$LBIP</span><span class="s2">"</span>/details/1
<span class="c"># =&gt; &lt; HTTP/1.1 403 Forbidden</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router <span class="s2">"curl -s --fail -v http://"</span><span class="nv">$LBIP</span><span class="s2">"/details/1"</span>
<span class="c"># =&gt; &lt; HTTP/1.1 403 Forbidden</span>

<span class="c"># ingress 를 통해서 인입 시 허용</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: cilium.io/v2
kind: CiliumClusterwideNetworkPolicy
metadata:
  name: allow-ingress-egress
spec:
  description: "Allow all the egress traffic from reserved ingress identity to any endpoints in the cluster"
  endpointSelector:
    matchExpressions:
    - key: reserved:ingress
      operator: Exists
  egress:
  - toEntities:
    - cluster
</span><span class="no">EOF
</span><span class="c"># =&gt; ciliumclusterwidenetworkpolicy.cilium.io/allow-ingress-egress created</span>
<span class="nv">$ </span>kubectl get ciliumclusterwidenetworkpolicy
<span class="c"># =&gt; NAME                   VALID</span>
<span class="c">#    allow-cidr             True</span>
<span class="c">#    allow-ingress-egress   True</span>
<span class="c">#    default-deny           True</span>
<span class="c">#    external-lockdown      True</span>

<span class="c">#</span>
<span class="nv">$ </span>curl <span class="nt">--fail</span> <span class="nt">-v</span> http://<span class="s2">"</span><span class="nv">$LBIP</span><span class="s2">"</span>/details/1
<span class="c"># =&gt; &lt; HTTP/1.1 200 OK</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router <span class="s2">"curl -s --fail -v http://"</span><span class="nv">$LBIP</span><span class="s2">"/details/1"</span>
<span class="c"># =&gt; *   Trying 192.168.10.211:80...</span>
<span class="c">#    * Connected to 192.168.10.211 (192.168.10.211) port 80</span>
<span class="c">#    &gt; GET /details/1 HTTP/1.1</span>
<span class="c">#    &gt; Host: 192.168.10.211</span>
<span class="c">#    &gt; User-Agent: curl/8.5.0</span>
<span class="c">#    &gt; Accept: */*</span>
<span class="c">#    &gt;</span>
<span class="c">#    {"id":1,"author":"William Shakespeare","year":1595,"type":"paperback","pages":200,"publisher":"PublisherA","language":"English","ISBN-10":"1234567890","ISBN-13":"123-1234567890"}&lt; HTTP/1.1 200 OK</span>
<span class="c">#    &lt; content-type: application/json</span>
<span class="c">#    &lt; server: envoy</span>
<span class="c">#    &lt; date: Sat, 23 Aug 2025 08:13:20 GMT</span>
<span class="c">#    &lt; content-length: 178</span>
<span class="c">#    &lt; x-envoy-upstream-service-time: 8</span>
<span class="c">#    &lt;</span>
<span class="c">#    { [178 bytes data]</span>
<span class="c">#    * Connection #0 to host 192.168.10.211 left intact</span>

<span class="c"># 정책 삭제</span>
<span class="nv">$ </span>kubectl delete CiliumClusterwideNetworkPolicy <span class="nt">--all</span>
<span class="c"># =&gt; ciliumclusterwidenetworkpolicy.cilium.io "allow-cidr" deleted</span>
<span class="c">#    ciliumclusterwidenetworkpolicy.cilium.io "allow-ingress-egress" deleted</span>
<span class="c">#    ciliumclusterwidenetworkpolicy.cilium.io "default-deny" deleted</span>
<span class="c">#    ciliumclusterwidenetworkpolicy.cilium.io "external-lockdown" deleted</span>
</code></pre></div></div>

<h3 id="ingress-path-type-example">Ingress Path Type Example</h3>

<ul>
  <li><a href="https://docs.cilium.io/en/stable/network/servicemesh/path-types/">관련 문서</a></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Apply the base definitions</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/cilium/cilium/main/examples/kubernetes/servicemesh/ingress-path-types.yaml
<span class="c"># =&gt; ...</span>
<span class="c">#    deployment.apps/implpath2 created</span>
<span class="c">#    ...</span>
<span class="c">#    service/implpath2 created</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get <span class="nt">-f</span> https://raw.githubusercontent.com/cilium/cilium/main/examples/kubernetes/servicemesh/ingress-path-types.yaml
<span class="c"># =&gt; NAME                          READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/exactpath     1/1     1            1           18s</span>
<span class="c">#    deployment.apps/prefixpath    1/1     1            1           18s</span>
<span class="c">#    deployment.apps/prefixpath2   1/1     1            1           18s</span>
<span class="c">#    deployment.apps/implpath      1/1     1            1           18s</span>
<span class="c">#    deployment.apps/implpath2     1/1     1            1           18s</span>
<span class="c">#    </span>
<span class="c">#    NAME                  TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE</span>
<span class="c">#    service/prefixpath    ClusterIP   10.96.11.159   &lt;none&gt;        80/TCP    18s</span>
<span class="c">#    service/prefixpath2   ClusterIP   10.96.158.98   &lt;none&gt;        80/TCP    18s</span>
<span class="c">#    service/exactpath     ClusterIP   10.96.46.141   &lt;none&gt;        80/TCP    18s</span>
<span class="c">#    service/implpath      ClusterIP   10.96.88.45    &lt;none&gt;        80/TCP    18s</span>
<span class="c">#    service/implpath2     ClusterIP   10.96.18.242   &lt;none&gt;        80/TCP    18s</span>

<span class="c"># Apply the Ingress</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/cilium/cilium/main/examples/kubernetes/servicemesh/ingress-path-types-ingress.yaml
<span class="c"># =&gt; ingress.networking.k8s.io/multiple-path-types created</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kc describe ingress multiple-path-types
<span class="c"># =&gt; Rules:</span>
<span class="c">#      Host                   Path  Backends</span>
<span class="c">#      ----                   ----  --------</span>
<span class="c">#      pathtypes.example.com</span>
<span class="c">#                             /exact    exactpath:80 (172.20.1.238:3000)</span>
<span class="c">#                             /         prefixpath:80 (172.20.1.72:3000)</span>
<span class="c">#                             /prefix   prefixpath2:80 (172.20.1.176:3000)</span>
<span class="c">#                             /impl     implpath:80 (172.20.1.210:3000)</span>
<span class="c">#                             /impl.+   implpath2:80 (172.20.1.223:3000)</span>
<span class="nv">$ </span>kc get ingress multiple-path-types <span class="nt">-o</span> yaml
<span class="c"># =&gt; ...</span>
<span class="c">#    spec:</span>
<span class="c">#      ingressClassName: cilium</span>
<span class="c">#      rules:</span>
<span class="c">#      - host: pathtypes.example.com</span>
<span class="c">#        http:</span>
<span class="c">#          paths:</span>
<span class="c">#          - backend:</span>
<span class="c">#              service:</span>
<span class="c">#                name: exactpath</span>
<span class="c">#                port:</span>
<span class="c">#                  number: 80</span>
<span class="c">#            path: /exact</span>
<span class="c">#            pathType: Exact</span>
<span class="c">#          - backend:</span>
<span class="c">#              service:</span>
<span class="c">#                name: prefixpath</span>
<span class="c">#                port:</span>
<span class="c">#                  number: 80</span>
<span class="c">#            path: /</span>
<span class="c">#            pathType: Prefix</span>
<span class="c">#          - backend:</span>
<span class="c">#              service:</span>
<span class="c">#                name: prefixpath2</span>
<span class="c">#                port:</span>
<span class="c">#                  number: 80</span>
<span class="c">#            path: /prefix</span>
<span class="c">#            pathType: Prefix</span>
<span class="c">#          - backend:</span>
<span class="c">#              service:</span>
<span class="c">#                name: implpath</span>
<span class="c">#                port:</span>
<span class="c">#                  number: 80</span>
<span class="c">#            path: /impl</span>
<span class="c">#            pathType: ImplementationSpecific</span>
<span class="c">#          - backend:</span>
<span class="c">#              service:</span>
<span class="c">#                name: implpath2</span>
<span class="c">#                port:</span>
<span class="c">#                  number: 80</span>
<span class="c">#            path: /impl.+</span>
<span class="c">#            pathType: ImplementationSpecific</span>

<span class="c"># 호출 확인</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">PATHTYPE_IP</span><span class="o">=</span><span class="sb">`</span>k get ing multiple-path-types <span class="nt">-o</span> json | jq <span class="nt">-r</span> <span class="s1">'.status.loadBalancer.ingress[0].ip'</span><span class="sb">`</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nt">-H</span> <span class="s2">"Host: pathtypes.example.com"</span> http://<span class="nv">$PATHTYPE_IP</span>/ | jq
<span class="c"># =&gt; {</span>
<span class="c">#      "path": "/",</span>
<span class="c">#      "host": "pathtypes.example.com",</span>
<span class="c">#      "method": "GET",</span>
<span class="c">#      ...</span>
<span class="c">#        "X-Envoy-Internal": [</span>
<span class="c">#          "true"</span>
<span class="c">#        ],</span>
<span class="c">#        "X-Forwarded-For": [</span>
<span class="c">#          "10.0.2.15"</span>
<span class="c">#        ],</span>
<span class="c">#    ...</span>

<span class="c"># 파드명 이름 확인</span>
<span class="nv">$ </span>kubectl get pod | <span class="nb">grep </span>path
<span class="c"># =&gt; exactpath-7488f8c6c6-4w7rx        1/1     Running   0          2m7s</span>
<span class="c">#    implpath-7d8bf85676-qz6t6         1/1     Running   0          2m7s</span>
<span class="c">#    implpath2-56c97c8556-mv66q        1/1     Running   0          2m7s</span>
<span class="c">#    prefixpath-5d6b989d4-kwvv6        1/1     Running   0          2m7s</span>
<span class="c">#    prefixpath2-b7c7c9568-br2nl       1/1     Running   0          2m7s</span>

<span class="c"># Should show prefixpath</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nt">-H</span> <span class="s2">"Host: pathtypes.example.com"</span> http://<span class="nv">$PATHTYPE_IP</span>/ | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'path|pod'</span>
<span class="c"># =&gt;  "path": "/",</span>
<span class="c">#     "host": "pathtypes.example.com",</span>
<span class="c">#     "pod": "prefixpath-5d6b989d4-kwvv6"</span>

<span class="c"># Should show exactpath</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nt">-H</span> <span class="s2">"Host: pathtypes.example.com"</span> http://<span class="nv">$PATHTYPE_IP</span>/exact | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'path|pod'</span>
<span class="c"># =&gt;  "path": "/exact",</span>
<span class="c">#     "host": "pathtypes.example.com",</span>
<span class="c">#     "pod": "exactpath-7488f8c6c6-4w7rx"</span>

<span class="c"># Should show prefixpath2</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nt">-H</span> <span class="s2">"Host: pathtypes.example.com"</span> http://<span class="nv">$PATHTYPE_IP</span>/prefix | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'path|pod'</span>
<span class="c"># =&gt;  "path": "/prefix",</span>
<span class="c">#     "host": "pathtypes.example.com",</span>
<span class="c">#     "pod": "prefixpath2-b7c7c9568-br2nl"</span>

<span class="c"># Should show implpath</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nt">-H</span> <span class="s2">"Host: pathtypes.example.com"</span> http://<span class="nv">$PATHTYPE_IP</span>/impl | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'path|pod'</span>
<span class="c"># =&gt;  "path": "/impl",</span>
<span class="c">#     "host": "pathtypes.example.com",</span>
<span class="c">#     "pod": "implpath-7d8bf85676-qz6t6"</span>

<span class="c"># Should show implpath2</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nt">-H</span> <span class="s2">"Host: pathtypes.example.com"</span> http://<span class="nv">$PATHTYPE_IP</span>/implementation | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'path|pod'</span>
<span class="c"># =&gt;  "path": "/implementation",</span>
<span class="c">#     "host": "pathtypes.example.com",</span>
<span class="c">#     "pod": "implpath2-56c97c8556-mv66q"</span>

<span class="c"># 삭제</span>
<span class="nv">$ </span>kubectl delete <span class="nt">-f</span> https://raw.githubusercontent.com/cilium/cilium/main/examples/kubernetes/servicemesh/ingress-path-types.yaml
<span class="nv">$ </span>kubectl delete <span class="nt">-f</span> https://raw.githubusercontent.com/cilium/cilium/main/examples/kubernetes/servicemesh/ingress-path-types-ingress.yaml
</code></pre></div></div>

<h3 id="ingress-example-with-tls-termination">Ingress Example with TLS Termination</h3>

<ul>
  <li><a href="https://docs.cilium.io/en/stable/network/servicemesh/tls-termination/">관련 문서</a></li>
</ul>

<h5 id="tls-인증서와-개인키-생성--mkcert---github">TLS 인증서와 개인키 생성 : mkcert - <a href="https://github.com/FiloSottile/mkcert">Github</a></h5>

<ul>
  <li><code class="language-plaintext highlighter-rouge">mkcert</code>는 로컬 개발 환경에서 신뢰할 수 있는 SSL 인증서를 쉽게 생성할 수 있도록 도와주는 도구입니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># For demonstration purposes we will use a TLS certificate signed by a made-up, self-signed certificate authority (CA). </span>
<span class="c"># One easy way to do this is with mkcert. We want a certificate that will validate bookinfo.cilium.rocks and hipstershop.cilium.rocks, as these are the host names used in this example.</span>
<span class="nv">$ </span>apt <span class="nb">install </span>mkcert <span class="nt">-y</span>
<span class="nv">$ </span>mkcert <span class="nt">-h</span>
<span class="c"># =&gt; Usage of mkcert:</span>
<span class="c">#    </span>
<span class="c">#            $ mkcert -install</span>
<span class="c">#            Install the local CA in the system trust store.</span>
<span class="c">#    </span>
<span class="c">#            $ mkcert example.org</span>
<span class="c">#            Generate "example.org.pem" and "example.org-key.pem".</span>
<span class="c">#    </span>
<span class="c">#            $ mkcert example.com myapp.dev localhost 127.0.0.1 ::1</span>
<span class="c">#            Generate "example.com+4.pem" and "example.com+4-key.pem".</span>
<span class="c">#    </span>
<span class="c">#            $ mkcert "*.example.it"</span>
<span class="c">#            Generate "_wildcard.example.it.pem" and "_wildcard.example.it-key.pem".</span>
<span class="c">#    </span>
<span class="c">#            $ mkcert -uninstall</span>
<span class="c">#            Uninstall the local CA (but do not delete it).</span>
<span class="c">#    </span>
<span class="c">#    For more options, run "mkcert -help".</span>

<span class="c">#</span>
<span class="nv">$ </span>mkcert <span class="s1">'*.cilium.rocks'</span>
<span class="c"># =&gt; Created a new local CA 💥</span>
<span class="c">#    Note: the local CA is not installed in the system trust store.</span>
<span class="c">#    Run "mkcert -install" for certificates to be trusted automatically ⚠️</span>
<span class="c">#    </span>
<span class="c">#    Created a new certificate valid for the following names 📜</span>
<span class="c">#     - "*.cilium.rocks"</span>
<span class="c">#    ...</span>

<span class="c">#</span>
<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-l</span> <span class="k">*</span>.pem
<span class="c"># =&gt; -rw------- 1 root root 1704 Aug 23 17:27 _wildcard.cilium.rocks-key.pem</span>
<span class="c">#    -rw-r--r-- 1 root root 1452 Aug 23 17:27 _wildcard.cilium.rocks.pem</span>

<span class="c">#</span>
<span class="nv">$ </span>openssl x509 <span class="nt">-in</span> _wildcard.cilium.rocks.pem <span class="nt">-text</span> <span class="nt">-noout</span>
<span class="c"># =&gt;         Issuer: O = mkcert development CA, OU = root@k8s-ctr, CN = mkcert root@k8s-ctr</span>
<span class="c">#            Validity</span>
<span class="c">#                Not Before: Aug 23 08:27:20 2025 GMT</span>
<span class="c">#                Not After : Oct 01 08:27:20 2027 GMT</span>
<span class="c">#            Subject: O = mkcert development certificate, OU = root@k8s-ctr</span>
<span class="c">#            ...</span>
<span class="c">#            X509v3 extensions:</span>
<span class="c">#                X509v3 Key Usage: critical</span>
<span class="c">#                    Digital Signature, Key Encipherment</span>
<span class="c">#                X509v3 Extended Key Usage:</span>
<span class="c">#                    TLS Web Server Authentication</span>
<span class="c">#                X509v3 Authority Key Identifier:</span>
<span class="c">#                    4E:3C:EA:36:AE:39:1C:4C:16:E0:55:3A:B8:B3:E3:D6:10:5B:31:FC</span>
<span class="c">#                X509v3 Subject Alternative Name:</span>
<span class="c">#                    &lt;span style="color: green;"&gt;DNS:*.cilium.rocks&lt;/span&gt;</span>

<span class="nv">$ </span>openssl rsa <span class="nt">-in</span> _wildcard.cilium.rocks-key.pem <span class="nt">-text</span> <span class="nt">-noout</span>
<span class="c"># =&gt; Private-Key: (2048 bit, 2 primes)</span>
<span class="c">#    modulus:</span>
<span class="c">#        00:95:4a:de:e4:5c:7a:b6:7e:6c:8a:65:fe:8d:9c:</span>
<span class="c">#    ...</span>

<span class="c"># Mkcert created a key (_wildcard.cilium.rocks-key.pem) and a certificate (_wildcard.cilium.rocks.pem) that we will use for the Gateway service.</span>
<span class="c"># Create a Kubernetes TLS secret with this key and certificate:</span>
<span class="nv">$ </span>kubectl create secret tls demo-cert <span class="nt">--key</span><span class="o">=</span>_wildcard.cilium.rocks-key.pem <span class="nt">--cert</span><span class="o">=</span>_wildcard.cilium.rocks.pem
<span class="c"># =&gt; secret/demo-cert created</span>
<span class="nv">$ </span>kubectl get secret demo-cert <span class="nt">-o</span> json | jq
<span class="c"># =&gt; {</span>
<span class="c">#      "apiVersion": "v1",</span>
<span class="c">#      "data": {</span>
<span class="c">#        "tls.crt": "LS0tLS1CRUdJT...VRFLS0tLS0K",</span>
<span class="c">#        "tls.key": "LS0tLS1CRUdJT...gS0VZLS0tLS0K"</span>
<span class="c">#      },</span>
<span class="c">#      ...</span>
<span class="c">#      "type": "kubernetes.io/tls"</span>
<span class="c">#    }</span>
</code></pre></div></div>

<h5 id="ingress-배포">Ingress 배포</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: tls-ingress
  namespace: default
spec:
  ingressClassName: cilium
  rules:
  - host: webpod.cilium.rocks
    http:
      paths:
      - backend:
          service:
            name: webpod
            port:
              number: 80
        path: /
        pathType: Prefix
  - host: bookinfo.cilium.rocks
    http:
      paths:
      - backend:
          service:
            name: details
            port:
              number: 9080
        path: /details
        pathType: Prefix
      - backend:
          service:
            name: productpage
            port:
              number: 9080
        path: /
        pathType: Prefix
  tls:
  - hosts:
    - webpod.cilium.rocks
    - bookinfo.cilium.rocks
    secretName: demo-cert
</span><span class="no">EOF
</span><span class="c"># =&gt; ingress.networking.k8s.io/tls-ingress created</span>

<span class="c">#    </span>
<span class="nv">$ </span>kubectl get ingress tls-ingress
<span class="c"># =&gt; NAME          CLASS    HOSTS                                       ADDRESS          PORTS     AGE</span>
<span class="c">#    tls-ingress   cilium   webpod.cilium.rocks,bookinfo.cilium.rocks   192.168.10.211   80, 443   22s</span>
</code></pre></div></div>

<h5 id="요청하기">요청하기</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 시스템(OS) 신뢰 저장소에 CA 정보 확인</span>
<span class="nv">$ </span><span class="nb">cat</span> /etc/ssl/certs/ca-certificates.crt
<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-al</span> /etc/ssl/certs/ca-certificates.crt
<span class="c"># =&gt; -rw-r--r-- 1 root root 219342 Feb 17  2025 /etc/ssl/certs/ca-certificates.crt</span>

<span class="c"># Install the Mkcert CA into your system so cURL can trust it:</span>
<span class="c"># mkcert -install은 “내 로컬에서 만든 인증서를 시스템이 믿도록” 환경을 꾸며주는 명령.</span>
<span class="nv">$ </span>mkcert <span class="nt">-install</span>
<span class="c"># =&gt; The local CA is now installed in the system trust store! ⚡️</span>

<span class="c"># 1. 로컬 CA(자체 루트 인증기관) 생성</span>
<span class="c"># 아직 없으면 로컬 CA 인증서와 개인키를 만듭니다.</span>
<span class="c"># 파일은 $(mkcert -CAROOT)가 가리키는 사용자 데이터 디렉터리에 저장돼요(예: rootCA.pem, rootCA-key.pem). 이 위치는 mkcert -CAROOT로 확인합니다. </span>
<span class="c">## CA 저장 위치 확인</span>
<span class="nv">$ </span>mkcert <span class="nt">-CAROOT</span>
<span class="c"># =&gt; /root/.local/share/mkcert</span>

<span class="nv">$ </span><span class="nb">ls</span> <span class="s2">"</span><span class="si">$(</span>mkcert <span class="nt">-CAROOT</span><span class="si">)</span><span class="s2">"</span>
<span class="c"># =&gt; rootCA-key.pem  rootCA.pem</span>

<span class="c"># 2. 시스템(OS) 신뢰 저장소에 CA를 등록</span>
<span class="c"># 배포판에 맞는 도구(예: Debian/Ubuntu의 update-ca-certificates, RHEL/Fedora의 update-ca-trust, Arch의 trust)를 사용해 루트 CA 인증서를 시스템 신뢰 저장소에 넣습니다.</span>
<span class="c"># 이렇게 하면 OpenSSL/GnuTLS를 쓰는 대부분의 CLI가 이 CA로 서명된 서버 인증서를 신뢰합니다. (curl도 포함)</span>
<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-al</span> /etc/ssl/certs/ca-certificates.crt
<span class="c"># =&gt; -rw-r--r-- 1 root root 220952 Aug 23 17:31 /etc/ssl/certs/ca-certificates.crt</span>

<span class="c">## 맨 하단에 인증서만 파일로 만들어서 디코딩!</span>
<span class="nv">$ </span><span class="nb">tail</span> <span class="nt">-n</span> 50 /etc/ssl/certs/ca-certificates.crt
<span class="c"># =&gt; ...</span>
<span class="c">#    -----END CERTIFICATE-----</span>
<span class="c">#    -----BEGIN CERTIFICATE-----</span>
<span class="c">#    MIIEeTCCAuGgAwIBAgIQHQmaPLojsfEios2wRChKPTANBgkqhkiG9w0BAQsFADBV</span>
<span class="c">#    ...</span>
<span class="c">#    zLFNEfhNUdhcRarky3dp/Jbp16t2QJRYh39gFskAJ1+02uQrsFq14pPnOO1d</span>
<span class="c">#    -----END CERTIFICATE-----</span>
<span class="nv">$ </span>vi 1.pem
<span class="nt">---</span>
<span class="nt">-----BEGIN</span> CERTIFICATE-----
MIIEeTCCAuGgAwIBAgIQHQmaPLojsfEios2wRChKPTANBgkqhkiG9w0BAQsFADBV
...
zLFNEfhNUdhcRarky3dp/Jbp16t2QJRYh39gFskAJ1+02uQrsFq14pPnOO1d
<span class="nt">-----END</span> CERTIFICATE-----
<span class="nt">---</span>
<span class="nv">$ </span>openssl x509 <span class="nt">-in</span> 1.pem <span class="nt">-text</span> <span class="nt">-noout</span>
<span class="c"># =&gt;         Issuer: O = mkcert development CA, OU = root@k8s-ctr, CN = mkcert root@k8s-ctr</span>
<span class="c">#            Validity</span>
<span class="c">#                Not Before: Aug 23 08:27:20 2025 GMT</span>
<span class="c">#                Not After : Aug 23 08:27:20 2035 GMT</span>
<span class="c">#            Subject: O = mkcert development CA, OU = root@k8s-ctr, CN = mkcert root@k8s-ctr</span>
<span class="c">#            Subject Public Key Info:</span>
<span class="c">#    ...</span>
<span class="c">#            X509v3 extensions:</span>
<span class="c">#                X509v3 Key Usage: critical</span>
<span class="c">#                    Certificate Sign</span>
<span class="c">#                X509v3 Basic Constraints: critical</span>
<span class="c">#                    CA:TRUE, pathlen:0</span>
<span class="c">#    ...</span>

<span class="c"># 3. NSS(브라우저) 신뢰 저장소에 등록</span>
<span class="c"># Linux에서는 Firefox/Chromium이 쓰는 NSS 데이터베이스에도 CA를 넣습니다(사전에 certutil 설치 필요). Firefox는 브라우저 재시작이 필요합니다</span>

<span class="c"># Now let's make a request to the Gateway:</span>
<span class="c"># The data should be properly retrieved, using HTTPS (and thus, the TLS handshake was properly achieved).</span>
<span class="c"># In the next challenge, we will see how to use Gateway API for general TLS traffic.</span>
<span class="nv">$ </span>kubectl get ingress tls-ingress <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.loadBalancer.ingress[0].ip}'</span>
<span class="c"># =&gt; 192.168.10.211</span>
<span class="nv">$ LBIP</span><span class="o">=</span><span class="si">$(</span>kubectl get ingress tls-ingress <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.loadBalancer.ingress[0].ip}'</span><span class="si">)</span>

<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nt">--resolve</span> bookinfo.cilium.rocks:443:<span class="k">${</span><span class="nv">LBIP</span><span class="k">}</span> https://bookinfo.cilium.rocks/details/1 | jq
<span class="c"># =&gt; {</span>
<span class="c">#      "id": 1,</span>
<span class="c">#      "author": "William Shakespeare",</span>
<span class="c">#      "year": 1595,</span>
<span class="c">#      "type": "paperback",</span>
<span class="c">#      "pages": 200,</span>
<span class="c">#      "publisher": "PublisherA",</span>
<span class="c">#      "language": "English",</span>
<span class="c">#      "ISBN-10": "1234567890",</span>
<span class="c">#      "ISBN-13": "123-1234567890"</span>
<span class="c">#    }</span>
  
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nt">--resolve</span> webpod.cilium.rocks:443:<span class="k">${</span><span class="nv">LBIP</span><span class="k">}</span>   https://webpod.cilium.rocks/ <span class="nt">-v</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    *  CAfile: /etc/ssl/certs/ca-certificates.crt</span>
<span class="c">#    *  CApath: /etc/ssl/certs</span>
<span class="c">#    ...</span>
<span class="c">#    * Server certificate:</span>
<span class="c">#    *  subject: O=mkcert development certificate; OU=root@k8s-ctr</span>
<span class="c">#    *  start date: Aug 23 08:27:20 2025 GMT</span>
<span class="c">#    *  expire date: Oct 01 08:27:20 2027 GMT</span>
<span class="c">#    *  subjectAltName: host "webpod.cilium.rocks" matched cert's "*.cilium.rocks"</span>
<span class="c">#    *  issuer: O=mkcert development CA; OU=root@k8s-ctr; CN=mkcert root@k8s-ctr</span>
<span class="c">#    ...</span>
<span class="c">#    Hostname: webpod-697b545f57-b5vtj</span>
<span class="c">#    ...</span>
<span class="c">#    IP: 172.20.0.70</span>
<span class="c">#    RemoteAddr: 10.0.2.15:51328</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: webpod.cilium.rocks</span>
<span class="c">#    User-Agent: curl/8.5.0</span>
<span class="c">#    Accept: */*</span>
<span class="c">#    X-Envoy-Internal: true</span>
<span class="c">#    X-Forwarded-For: 10.0.2.15</span>
<span class="c">#    X-Forwarded-Proto: https</span>
<span class="c">#    X-Request-Id: da68b521-852e-4678-92ed-37f72101d75d</span>
</code></pre></div></div>

<ul>
  <li>TLS Termination이 잘 되어서 https로 요청시 인증서가 유효하고, 서비스로 요청이 잘 전달되는 것을 확인할 수 있습니다.</li>
</ul>

<h5 id="ingress-삭제">ingress 삭제</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl delete ingress basic-ingress tls-ingress webpod-ingress
<span class="c"># =&gt; ingress.networking.k8s.io "basic-ingress" deleted</span>
<span class="c">#    ingress.networking.k8s.io "tls-ingress" deleted</span>
<span class="c">#    ingress.networking.k8s.io "webpod-ingress" deleted</span>
</code></pre></div></div>

<hr />

<h2 id="gateway-api-support">Gateway API Support</h2>

<h3 id="gateway-api-소개">Gateway API 소개</h3>

<ul>
  <li>Gateway API는 기존의 Ingress API의 한계를 극복하고 대체하기 위한 차세대 API로, 기능을 추가하고, 역할을 분리하고, 더 유연하고 확장 가능한 방식으로 클러스터 외부에서 내부로의 트래픽을 관리할 수 있도록 설계되었습니다.
<a href="https://kubernetes.io/docs/concepts/services-networking/gateway/">Docs</a>, <a href="https://www.youtube.com/watch?v=kbTVzAhtHKs">Youtube</a></li>
  <li>기존 Ingress의 한계
    <ul>
      <li><strong>고급 라우팅 지원 부족 (URL rewriting 등)</strong> : Ingress Controller 마다 지원하는 기능이 다르고, 특수한 Annotation을 사용해야 하는 등 일관성이 부족합니다.</li>
      <li><strong>역할 분리 부족</strong> : Ingress 리소스는 클러스터 운영자와 애플리케이션 개발자 간의 역할 분리가 명확하지 않아, 운영자가 애플리케이션의 라우팅 정책을 완전히 제어할 수 있습니다</li>
      <li><strong>프로토콜 제한</strong> : Ingress는 주로 HTTP/HTTPS 트래픽을 처리하도록 설계되어 있어, TCP, UDP 등 다른 프로토콜에 대한 지원이 제한적입니다.</li>
      <li><strong>운영 제한</strong> : Ingress의 API는 유연하지 못하여 로드밸런싱을 공유하는 인프라를 여러 팀이 관리하는 클러스터에 적합하지 않는등 운영상의 제약이 있습니다.</li>
    </ul>
  </li>
  <li>서비스 메시(istiod 등)에서 제공하는 풍부한 기능 중 일부 기능들과 운영관리 기능들을 Gateway API를 통해 사용할 수 있습니다.</li>
  <li>주요 기능
    <ul>
      <li><strong>개선된 리소스 모델</strong> : Gateway API는 GatewayClass, Gateway 및 Route(HTTPRoute, TCPRoute 등)와 같은 새로운 사용자 정의 리소스를 도입하여 라우팅 규칙을 정의하는 보다 세부적이고 표현력 있는 방법을 제공합니다.</li>
      <li><strong>프로토콜 독립적</strong> : 주로 HTTP용으로 설계된 Ingress와 달리 Gateway API는 TCP, UDP, TLS를 포함한 여러 프로토콜을 지원합니다.</li>
      <li><strong>강화된 보안</strong> : TLS 구성 및 보다 세부적인 액세스 제어에 대한 기본 제공 지원.</li>
      <li><strong>교차 네임스페이스 지원</strong> : 서로 다른 네임스페이스의 서비스로 트래픽을 라우팅하여 보다 유연한 아키텍처를 구축할 수 있는 기능을 제공합니다.</li>
      <li><strong>확장성</strong> : API는 사용자 정의 리소스 및 정책으로 쉽게 확장할 수 있도록 설계되었습니다.</li>
      <li><strong>역할 지향</strong> : 클러스터 운영자, 애플리케이션 개발자, 보안 팀 간의 관심사를 명확하게 분리합니다.</li>
    </ul>
  </li>
  <li>Gateway API의 구성요소 (Resource)
<img src="/assets/2025/cilium/w6/20250824_cilium_w6_8.png" alt="img.png" />
    <ul>
      <li>GatewayClass : 클러스터에서 사용 가능한 Gateway의 유형을 정의합니다. 클래스를 구현하는 컨트롤러에의해 관리 됩니다.</li>
      <li>Gateway : 네트워크 트래픽을 처리하는 인프라스트럭쳐 구성요소를 나타냅니다. (예) 클라우드 로드 밸런서, 프록시 서버 등)</li>
      <li>HTTPRoute : HTTP 트래픽에 특화된 라우팅 규칙을 정의합니다.</li>
      <li>TCPRoute : TCP 트래픽에 특화된 라우팅 규칙을 정의합니다.</li>
      <li>Service : Kubernetes 서비스 리소스와 유사하게,트래픽이 라우팅될 백엔드 서비스를 나타냅니다.</li>
    </ul>
  </li>
  <li>역할 지향에 의한 관심사 분리
<img src="/assets/2025/cilium/w6/20250824_cilium_w6_9.png" alt="img.png" class="image-center w-80" />
    <ul>
      <li>Ingress의 경우 Ingress 리소스에 대한 권한이 있는 사용자가 Ingress 컨트롤러의 동작을 완전히 제어할 수 있습니다.</li>
      <li>하지만 Gateway API에서는 GatewayClass, Gateway 및 Route 리소스를 통해 역할을 분리하여 각 역할에 대한 권한을 세분화하여
필요한 최소한의 권한만 부여할 수 있습니다.</li>
      <li>역할 지향에 의한 권한 부여 예시 - <a href="https://www.anyflow.net/sw-engineer/kubernetes-gateway-api-1">Blog1</a>, <a href="https://www.anyflow.net/sw-engineer/kubernetes-gateway-api-2">Blog2</a>
        <ul>
          <li>아래의 그림 처럼 “Store 개발자”는 Store namespace에서 해당 store PATH 라우팅 정책을 스스로 관리할 수 있습니다.
<img src="/assets/2025/cilium/w6/20250824_cilium_w6_10.png" alt="img.png" class="image-center" />
<em class="image-caption"><a href="https://gateway-api.sigs.k8s.io/">https://gateway-api.sigs.k8s.io/</a></em></li>
          <li><strong>Infrastructure 제공자</strong> : 여러 테넌트를 지원하기위해 여러 격리된 클러스터를 운영하는 인프라를 관리합니다.</li>
          <li><strong>Cluster 운영자</strong> : 정책, 네트워크 제어, 애플리케이션 권한 등의 클러스터를 관리합니다. 위의 그림에서는 도메인, 인증서, 전체적인 정책 등을 관리합니다.</li>
          <li><strong>Application 개발자</strong> : 클러스터에서 동작하는 애플리케이션을 개발하고 배포, 관리합니다. 위의 그림에서는 개별 애플리케이션에 대한 라우팅 정책을 관리합니다.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="cilium-gateway-api-지원">Cilium Gateway API 지원</h3>

<ul>
  <li><a href="https://docs.cilium.io/en/stable/network/servicemesh/gateway-api/gateway-api/">관련 문서</a></li>
  <li>Cilium은 Gateway API를 지원하며, Cilium의 서비스 메시 기능과 통합하여 고급 트래픽 관리 및 보안 기능을 제공합니다.</li>
  <li>Cilium은 아래의 resource에 대해 Gateway API v1.2.0을 지원하고, 모든 중요한 기능에 대한 만족토 테스트를 통과하였습니다. (v1.3은 아직 일부항목이 만족되지 않은 상태입니다. - <a href="https://gateway-api.sigs.k8s.io/implementations/v1.3/">https://gateway-api.sigs.k8s.io/implementations/v1.3/</a>)
    <ul>
      <li><a href="https://gateway-api.sigs.k8s.io/api-types/gatewayclass/">GatewayClass</a></li>
      <li><a href="https://gateway-api.sigs.k8s.io/api-types/gateway/">Gateway</a></li>
      <li><a href="https://gateway-api.sigs.k8s.io/api-types/httproute/">HTTPRoute</a></li>
      <li><a href="https://gateway-api.sigs.k8s.io/api-types/grpcroute/">GRPCRoute</a></li>
      <li><a href="https://gateway-api.sigs.k8s.io/references/spec/#gateway.networking.k8s.io/v1alpha2.TLSRoute">TLSRoute (experimental)</a></li>
      <li><a href="https://gateway-api.sigs.k8s.io/api-types/referencegrant/">ReferenceGrant</a>
        <ul>
          <li>추가적으로 <code class="language-plaintext highlighter-rouge">CiliumGatewayClassConfig</code> CRD를 제공하며, <a href="https://gateway-api.sigs.k8s.io/api-types/gatewayclass/#gatewayclass-parameters">GatewayClass.parametersRef</a>에서 참조할 수 있습니다.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>사전 준비
    <ul>
      <li>Cilium은 NodePort 지원이 활성화(<code class="language-plaintext highlighter-rouge">nodePort.enabled=true</code>) 되어 있어있거나 Kube-Proxy 대체 모드(<code class="language-plaintext highlighter-rouge">kubeProxyReplacement=true</code>)로 동작하고 있어야 합니다.</li>
      <li>Cilium은 L7 프록시 기능이 활성화(<code class="language-plaintext highlighter-rouge">l7Proxy=true</code>) 되어 있어야 합니다. (기본값은 true)</li>
      <li>아래의 Gateway API 1.2.0 CRD가 클러스터에 적용되어 있어야 합니다. (설치과정은 <a href="https://gateway-api.sigs.k8s.io/guides/?h=crds#getting-started-with-gateway-api">문서</a>를 참고하세요.)
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># CRD 설치</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/kubernetes-sigs/gateway-api/v1.2.0/config/crd/standard/gateway.networking.k8s.io_gatewayclasses.yaml
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/kubernetes-sigs/gateway-api/v1.2.0/config/crd/standard/gateway.networking.k8s.io_gateways.yaml
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/kubernetes-sigs/gateway-api/v1.2.0/config/crd/standard/gateway.networking.k8s.io_httproutes.yaml
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/kubernetes-sigs/gateway-api/v1.2.0/config/crd/standard/gateway.networking.k8s.io_referencegrants.yaml
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/kubernetes-sigs/gateway-api/v1.2.0/config/crd/standard/gateway.networking.k8s.io_grpcroutes.yaml
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/kubernetes-sigs/gateway-api/v1.2.0/config/crd/experimental/gateway.networking.k8s.io_tlsroutes.yaml
    
<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get crd | <span class="nb">grep </span>gateway.networking.k8s.io
<span class="c"># =&gt; gatewayclasses.gateway.networking.k8s.io     2025-08-23T10:48:59Z</span>
<span class="c">#    gateways.gateway.networking.k8s.io           2025-08-23T10:48:59Z</span>
<span class="c">#    grpcroutes.gateway.networking.k8s.io         2025-08-23T10:49:01Z</span>
<span class="c">#    httproutes.gateway.networking.k8s.io         2025-08-23T10:49:00Z</span>
<span class="c">#    referencegrants.gateway.networking.k8s.io    2025-08-23T10:49:01Z</span>
<span class="c">#    tlsroutes.gateway.networking.k8s.io          2025-08-23T10:49:02Z</span>
</code></pre></div>        </div>
      </li>
      <li>기본적으로 Gateway API 컨트롤러는 LoadBalancer 타입의 Service를 생성하여 외부에서 접근할 수 있도록 합니다. 대안으로 Cilium 1.16 이상에서는 Cilium L7 Proxy를 <a href="https://docs.cilium.io/en/stable/network/servicemesh/gateway-api/gateway-api/#gs-gateway-host-network-mode">호스트 네트워크</a>에 노출 시킬 수도 있습니다.</li>
    </ul>
  </li>
  <li>전반적인 동작 메커니즘
    <ul>
      <li>Cilium은 크게 Cilium Agent와 Cilium Operator의 두 컴포넌트로 구성됩니다.</li>
      <li>Cilium Operator는 모든 Gateway API 리소스를 감시하고, 리소스가 적합한지 검증합니다. 만약 리소스가 적합하다면 구성을 수용해서 Cilium Envoy 구성에 반영합니다.</li>
      <li>Cilium Agent는 각 노드에서 실행되며, Cilium Operator가 제공하는 구성을 사용하여 Envoy나 Envoy DaemonSet을 설정하고 관리합니다. Envoy는 트래픽을 처리하고 라우팅하는 역할을 합니다.</li>
    </ul>
  </li>
</ul>

<h3 id="cilium-gateway-api-설정-및-배포">Cilium Gateway API 설정 및 배포</h3>

<h5 id="cilium-gateway-api-활성화">Cilium Gateway API 활성화</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># ingress와 Gateway API는 동시에 사용할 수 없기 때문에 ingressController를 비활성화합니다.</span>
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--version</span> 1.18.1 <span class="nt">--namespace</span> kube-system <span class="nt">--reuse-values</span> <span class="se">\</span>
  <span class="nt">--set</span> ingressController.enabled<span class="o">=</span><span class="nb">false</span> <span class="nt">--set</span> gatewayAPI.enabled<span class="o">=</span><span class="nb">true</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system rollout restart deployment/cilium-operator
<span class="c"># =&gt; deployment.apps/cilium-operator restarted</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system rollout restart ds/cilium
<span class="c"># =&gt; daemonset.apps/cilium restarted</span>

<span class="c">#</span>
<span class="nv">$ </span>cilium config view | <span class="nb">grep </span>gateway-api
<span class="c"># =&gt; enable-gateway-api                                true</span>
<span class="c">#    enable-gateway-api-alpn                           false</span>
<span class="c">#    enable-gateway-api-app-protocol                   false</span>
<span class="c">#    enable-gateway-api-proxy-protocol                 false</span>
<span class="c">#    enable-gateway-api-secrets-sync                   true</span>
<span class="c">#    gateway-api-hostnetwork-enabled                   false</span>
<span class="c">#    gateway-api-hostnetwork-nodelabelselector</span>
<span class="c">#    gateway-api-secrets-namespace                     cilium-secrets</span>
<span class="c">#    gateway-api-service-externaltrafficpolicy         Cluster</span>
<span class="c">#    gateway-api-xff-num-trusted-hops                  0</span>

<span class="c"># cilium-ingress 제거 확인</span>
<span class="nv">$ </span>kubectl get svc,pod <span class="nt">-n</span> kube-system

<span class="nv">$ </span>kubectl get GatewayClass
<span class="c"># =&gt; NAME     CONTROLLER                     ACCEPTED   AGE</span>
<span class="c">#    cilium   io.cilium/gateway-controller   True       64s</span>

<span class="nv">$ </span>kubectl get gateway <span class="nt">-A</span>
<span class="c"># =&gt; No resources found</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 아직 배포된 Gateway가 없습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<h5 id="cilium-gateway-배포">Cilium Gateway 배포</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: my-gateway
spec:
  gatewayClassName: cilium
  listeners:
  - protocol: HTTP
    port: 80
    name: web-gw
    allowedRoutes:
      namespaces:
        from: Same
---
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: http-app-1
spec:
  parentRefs:
  - name: my-gateway
    namespace: default
  rules:
  - matches:
    - path:
        type: PathPrefix
        value: /details
    backendRefs:
    - name: details
      port: 9080
  - matches:
    - headers:
      - type: Exact
        name: magic
        value: foo
      queryParams:
      - type: Exact
        name: great
        value: example
      path:
        type: PathPrefix
        value: /
      method: GET
    backendRefs:
    - name: productpage
      port: 9080
</span><span class="no">EOF
</span><span class="c"># =&gt; gateway.gateway.networking.k8s.io/my-gateway created</span>
<span class="c">#    httproute.gateway.networking.k8s.io/http-app-1 created</span>

<span class="nv">$ </span>kubectl get svc,ep cilium-gateway-my-gateway
<span class="c"># =&gt; NAME                                TYPE           CLUSTER-IP     EXTERNAL-IP      PORT(S)        AGE</span>
<span class="c">#    service/cilium-gateway-my-gateway   LoadBalancer   10.96.119.37   192.168.10.211   80:30910/TCP   17s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                  ENDPOINTS              AGE</span>
<span class="c">#    endpoints/cilium-gateway-my-gateway   192.192.192.192:9999   17s</span>

<span class="nv">$ </span>kubectl get gateway
<span class="c"># =&gt; NAME         CLASS    ADDRESS          PROGRAMMED   AGE</span>
<span class="c">#    my-gateway   cilium   192.168.10.211   True         32s</span>

<span class="c">## Accepted: Gateway 구성이 올바르고 수용되었음을 나타냅니다.</span>
<span class="c">## Programmed: Gateway 구성이 Envoy에 성공적으로 적용되었음을 나타냅니다.</span>
<span class="c">## ResolvedRefs: 모든 참조된 시크릿이 발견되고 사용 권한이 있음을 나타냅니다.</span>
<span class="nv">$ </span>kc describe gateway
<span class="c"># =&gt; ...</span>
<span class="c">#      Conditions:</span>
<span class="c">#        Last Transition Time:  2025-08-23T11:11:49Z</span>
<span class="c">#        Message:               Gateway successfully scheduled</span>
<span class="c">#        Observed Generation:   1</span>
<span class="c">#        Reason:                Accepted</span>
<span class="c">#        Status:                True</span>
<span class="c">#        Type:                  Accepted</span>
<span class="c">#        Last Transition Time:  2025-08-23T11:11:49Z</span>
<span class="c">#        Message:               Gateway successfully reconciled</span>
<span class="c">#        Observed Generation:   1</span>
<span class="c">#        Reason:                Programmed</span>
<span class="c">#        Status:                True</span>
<span class="c">#        Type:                  Programmed</span>
<span class="c">#    ...</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get httproutes <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE   NAME         HOSTNAMES   AGE</span>
<span class="c">#    default     http-app-1               2m53s</span>

<span class="c"># Accepted: HTTPRoute가 올바르게 수용되었음을 나타냅니다.</span>
<span class="c"># ResolvedRefs: 참조된 서비스가 발견되고 유효한 참조임을 나타냅니다.</span>
<span class="nv">$ </span>kc describe httproutes
<span class="c"># =&gt; ...</span>
<span class="c">#        Conditions:</span>
<span class="c">#          Last Transition Time:  2025-08-23T11:11:49Z</span>
<span class="c">#          Message:               Accepted HTTPRoute</span>
<span class="c">#          Observed Generation:   1</span>
<span class="c">#          Reason:                Accepted</span>
<span class="c">#          Status:                True</span>
<span class="c">#          Type:                  Accepted</span>
<span class="c">#          Last Transition Time:  2025-08-23T11:11:49Z</span>
<span class="c">#          Message:               Service reference is valid</span>
<span class="c">#          Observed Generation:   1</span>
<span class="c">#          Reason:                ResolvedRefs</span>
<span class="c">#          Status:                True</span>
<span class="c">#          Type:                  ResolvedRefs</span>
<span class="c">#    ...</span>

<span class="c"># Cilium Operator 로그 확인</span>
<span class="nv">$ </span>kubectl logs <span class="nt">-n</span> kube-system deployments/cilium-operator | <span class="nb">grep </span>gateway
</code></pre></div></div>

<h5 id="요청-하기">요청 하기</h5>

<ul>
  <li>HTTP 경로 매칭과 HTTP 헤더 매칭</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ GATEWAY</span><span class="o">=</span><span class="si">$(</span>kubectl get gateway my-gateway <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.addresses[0].value}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$GATEWAY</span>
<span class="c"># =&gt; 192.168.10.211</span>

<span class="c"># HTTP 경로 매칭</span>
<span class="nv">$ </span>curl <span class="nt">--fail</span> <span class="nt">-s</span> http://<span class="s2">"</span><span class="nv">$GATEWAY</span><span class="s2">"</span>/details/1 | jq
<span class="c"># =&gt; {</span>
<span class="c">#      "id": 1,</span>
<span class="c">#      "author": "William Shakespeare",</span>
<span class="c">#      "year": 1595,</span>
<span class="c">#      "type": "paperback",</span>
<span class="c">#      "pages": 200,</span>
<span class="c">#      "publisher": "PublisherA",</span>
<span class="c">#      "language": "English",</span>
<span class="c">#      "ISBN-10": "1234567890",</span>
<span class="c">#      "ISBN-13": "123-1234567890"</span>
<span class="c">#    }</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router <span class="s2">"curl -s --fail -v http://"</span><span class="nv">$GATEWAY</span><span class="s2">"/details/1"</span>
<span class="c"># =&gt; {"id":1,"author":"William Shakespeare","year":1595,"type":"paperback","pages":200,"publisher":"PublisherA","language":"English","ISBN-10":"1234567890","ISBN-13":"123-1234567890"}</span>
<span class="c">#    &lt; HTTP/1.1 200 OK</span>

<span class="c"># HTTP 헤더 매칭</span>
<span class="nv">$ </span>curl <span class="nt">-v</span> <span class="nt">-H</span> <span class="s1">'magic: foo'</span> http://<span class="s2">"</span><span class="nv">$GATEWAY</span><span class="s2">"</span><span class="se">\?</span>great<span class="se">\=</span>example
<span class="c"># =&gt; &lt; HTTP/1.1 200 OK</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router <span class="s2">"curl -s -v -H 'magic: foo' http://"</span><span class="nv">$GATEWAY</span><span class="s2">"</span><span class="se">\?</span><span class="s2">great</span><span class="se">\=</span><span class="s2">example"</span>
<span class="c"># =&gt; &lt; HTTP/1.1 200 OK</span>
</code></pre></div></div>

<h5 id="https-예제">HTTPS 예제</h5>

<ul>
  <li><a href="https://docs.cilium.io/en/stable/network/servicemesh/gateway-api/https/">관련 문서</a></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: tls-gateway
spec:
  gatewayClassName: cilium
  listeners:
  - name: https-1
    protocol: HTTPS
    port: 443
    hostname: "bookinfo.cilium.rocks"
    tls:
      certificateRefs:
      - kind: Secret
        name: demo-cert
  - name: https-2
    protocol: HTTPS
    port: 443
    hostname: "webpod.cilium.rocks"
    tls:
      certificateRefs:
      - kind: Secret
        name: demo-cert
---
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: https-app-route-1
spec:
  parentRefs:
  - name: tls-gateway
  hostnames:
  - "bookinfo.cilium.rocks"
  rules:
  - matches:
    - path:
        type: PathPrefix
        value: /details
    backendRefs:
    - name: details
      port: 9080
---
apiVersion: gateway.networking.k8s.io/v1
kind: HTTPRoute
metadata:
  name: https-app-route-2
spec:
  parentRefs:
  - name: tls-gateway
  hostnames:
  - "webpod.cilium.rocks"
  rules:
  - matches:
    - path:
        type: PathPrefix
        value: /
    backendRefs:
    - name: webpod
      port: 80
</span><span class="no">EOF
</span><span class="c"># =&gt; gateway.gateway.networking.k8s.io/tls-gateway created</span>
<span class="c">#    httproute.gateway.networking.k8s.io/https-app-route-1 created</span>
<span class="c">#    httproute.gateway.networking.k8s.io/https-app-route-2 created</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get gateway tls-gateway
<span class="c"># =&gt; NAME          CLASS    ADDRESS          PROGRAMMED   AGE</span>
<span class="c">#    tls-gateway   cilium   192.168.10.213   True         24s</span>

<span class="nv">$ </span>kubectl get httproutes https-app-route-1 https-app-route-2
<span class="c"># =&gt; NAME                HOSTNAMES                   AGE</span>
<span class="c">#    https-app-route-1   ["bookinfo.cilium.rocks"]   36s</span>
<span class="c">#    https-app-route-2   ["webpod.cilium.rocks"]     36s</span>

<span class="c">#</span>
<span class="nv">$ GATEWAY2</span><span class="o">=</span><span class="si">$(</span>kubectl get gateway tls-gateway <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.addresses[0].value}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$GATEWAY2</span>
<span class="c"># =&gt; 192.168.10.213</span>

<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nt">--resolve</span> bookinfo.cilium.rocks:443:<span class="k">${</span><span class="nv">GATEWAY2</span><span class="k">}</span> https://bookinfo.cilium.rocks/details/1 | jq
<span class="c"># =&gt; {</span>
<span class="c">#      "id": 1,</span>
<span class="c">#      "author": "William Shakespeare",</span>
<span class="c">#      "year": 1595,</span>
<span class="c">#      "type": "paperback",</span>
<span class="c">#      "pages": 200,</span>
<span class="c">#      "publisher": "PublisherA",</span>
<span class="c">#      "language": "English",</span>
<span class="c">#      "ISBN-10": "1234567890",</span>
<span class="c">#      "ISBN-13": "123-1234567890"</span>
<span class="c">#    }</span>
  
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nt">--resolve</span> webpod.cilium.rocks:443:<span class="k">${</span><span class="nv">GATEWAY2</span><span class="k">}</span>   https://webpod.cilium.rocks/ <span class="nt">-v</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    * TLSv1.3 (OUT), TLS handshake, Client hello (1):</span>
<span class="c">#    *  CAfile: /etc/ssl/certs/ca-certificates.crt</span>
<span class="c">#    *  CApath: /etc/ssl/certs</span>
<span class="c">#    ...</span>
<span class="c">#    *  subjectAltName: host "webpod.cilium.rocks" matched cert's "*.cilium.rocks"</span>
<span class="c">#    *  issuer: O=mkcert development CA; OU=root@k8s-ctr; CN=mkcert root@k8s-ctr</span>
<span class="c">#    *  SSL certificate verify ok.</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<ul>
  <li>TLS Termination이 잘 되어서 https로 요청시 인증서가 유효하고, 서비스로 요청이 잘 전달되는 것을 확인할 수 있습니다.</li>
</ul>

<h5 id="tls-route">TLS Route</h5>

<ul>
  <li>TLS Route는 앞에서 살펴본 TLS Termination과는 다르게 TLS Passthrough를 지원합니다.
    <ul>
      <li><strong>TLS Termination</strong> : Gateway가 TLS 연결을 종료하고, 내부 서비스로는 평문 HTTP 트래픽을 전달합니다. (즉, Gateway가 클라이언트와 서버 간의 TLS 세션을 종료합니다.)</li>
      <li>
        <p><strong>TLS Passthrough</strong> : Gateway가 TLS 연결을 종료하지 않고, 클라이언트와 서버 간의 TLS 트래픽을 그대로 전달합니다.</p>

        <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
        <div class="mermaid">
graph TD
  A[Client] --&gt;|TLS Handshake| B["Gateway (TLS Termination)"]
  B --&gt;|HTTP Traffic| C[Backend Service]
  A2[Client] --&gt;|TLS Handshake| B2["Gateway (TLS Passthrough)"]
  B2 --&gt;|TLS Traffic| C2[Backend Service]
</div>
      </li>
    </ul>
  </li>
  <li>샘플앱 배포</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Deploy the Demo app : HTTPS 웹서버</span>
<span class="c"># We will be using a NGINX web server. Review the NGINX configuration.</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="sh">'</span><span class="no">EOF</span><span class="sh">' &gt; nginx.conf
events {
}

http {
  log_format main '</span><span class="nv">$remote_addr</span><span class="sh"> - </span><span class="nv">$remote_user</span><span class="sh"> [</span><span class="nv">$time_local</span><span class="sh">]  </span><span class="nv">$status</span><span class="sh"> '
  '"</span><span class="nv">$request</span><span class="sh">" </span><span class="nv">$body_bytes_sent</span><span class="sh"> "</span><span class="nv">$http_referer</span><span class="sh">" '
  '"</span><span class="nv">$http_user_agent</span><span class="sh">" "</span><span class="nv">$http_x_forwarded_for</span><span class="sh">"';
  access_log /var/log/nginx/access.log main;
  error_log  /var/log/nginx/error.log;

  server {
    listen 443 ssl;

    root /usr/share/nginx/html;
    index index.html;

    server_name nginx.cilium.rocks;
    ssl_certificate /etc/nginx-server-certs/tls.crt;
    ssl_certificate_key /etc/nginx-server-certs/tls.key;
  }
}
</span><span class="no">EOF

</span><span class="c"># As you can see, it listens on port 443 for SSL traffic. Notice it specifies the certificate and key previously created.</span>
<span class="c"># We will need to mount the files to the right path (/etc/nginx-server-certs) when we deploy the server.</span>
<span class="c"># The NGINX server configuration is held in a Kubernetes ConfigMap. Let's create it.</span>
<span class="nv">$ </span>kubectl create configmap nginx-configmap <span class="nt">--from-file</span><span class="o">=</span>nginx.conf<span class="o">=</span>./nginx.conf
<span class="c"># =&gt; configmap/nginx-configmap created</span>

<span class="c"># Review the NGINX server Deployment and the Service fronting it:</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Service
metadata:
  name: my-nginx
  labels:
    run: my-nginx
spec:
  ports:
    - port: 443
      protocol: TCP
  selector:
    run: my-nginx
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-nginx
spec:
  selector:
    matchLabels:
      run: my-nginx
  replicas: 1
  template:
    metadata:
      labels:
        run: my-nginx
    spec:
      containers:
        - name: my-nginx
          image: nginx
          ports:
            - containerPort: 443
          volumeMounts:
            - name: nginx-config
              mountPath: /etc/nginx
              readOnly: true
            - name: nginx-server-certs
              mountPath: /etc/nginx-server-certs
              readOnly: true
      volumes:
        - name: nginx-config
          configMap:
            name: nginx-configmap
        - name: nginx-server-certs
          secret:
            secretName: demo-cert
</span><span class="no">EOF
</span><span class="c"># =&gt; service/my-nginx created</span>
<span class="c">#    deployment.apps/my-nginx created</span>

<span class="c"># Verify the Service and Deployment have been deployed successfully:</span>
<span class="nv">$ </span>kubectl get deployment,svc,ep my-nginx
<span class="c"># =&gt; NAME                       READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/my-nginx   1/1     1            1           17s</span>
<span class="c">#    </span>
<span class="c">#    NAME               TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE</span>
<span class="c">#    service/my-nginx   ClusterIP   10.96.141.153   &lt;none&gt;        443/TCP   17s</span>
<span class="c">#    </span>
<span class="c">#    NAME                 ENDPOINTS          AGE</span>
<span class="c">#    endpoints/my-nginx   172.20.1.187:443   17s</span>
</code></pre></div></div>

<ul>
  <li>Gateway 배포</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># </span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: gateway.networking.k8s.io/v1
kind: Gateway
metadata:
  name: cilium-tls-gateway
spec:
  gatewayClassName: cilium
  listeners:
    - name: https
      hostname: "nginx.cilium.rocks"
      port: 443
      protocol: TLS
      tls:
        mode: Passthrough
      allowedRoutes:
        namespaces:
          from: All
---
apiVersion: gateway.networking.k8s.io/v1alpha2
kind: TLSRoute
metadata:
  name: nginx
spec:
  parentRefs:
    - name: cilium-tls-gateway
  hostnames:
    - "nginx.cilium.rocks"
  rules:
    - backendRefs:
        - name: my-nginx
          port: 443
</span><span class="no">EOF
</span><span class="c"># =&gt; gateway.gateway.networking.k8s.io/cilium-tls-gateway created</span>
<span class="c">#    tlsroute.gateway.networking.k8s.io/nginx created</span>

<span class="c"># The Gateway does not actually inspect the traffic aside from using the SNI header for routing. Indeed the hostnames field defines a set of SNI names that should match against the SNI attribute of TLS ClientHello message in TLS handshake.</span>
<span class="c"># Let's now deploy the Gateway and the TLSRoute to the cluste</span>
<span class="nv">$ </span>kubectl get gateway cilium-tls-gateway
<span class="c"># =&gt; NAME                 CLASS    ADDRESS          PROGRAMMED   AGE</span>
<span class="c">#    cilium-tls-gateway   cilium   192.168.10.214   True         10s</span>

<span class="nv">$ GATEWAY</span><span class="o">=</span><span class="si">$(</span>kubectl get gateway cilium-tls-gateway <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.addresses[0].value}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$GATEWAY</span>
<span class="c"># =&gt; 192.168.10.214</span>

<span class="c"># Let's also double check the TLSRoute has been provisioned successfully and has been attached to the Gateway.</span>
<span class="nv">$ </span>kubectl get tlsroutes.gateway.networking.k8s.io <span class="nt">-o</span> json | jq <span class="s1">'.items[0].status.parents[0]'</span>
<span class="c"># =&gt; {</span>
<span class="c">#      "conditions": [</span>
<span class="c">#        {</span>
<span class="c">#          "lastTransitionTime": "2025-08-23T11:34:35Z",</span>
<span class="c">#          "message": "Accepted TLSRoute",</span>
<span class="c">#          "observedGeneration": 1,</span>
<span class="c">#          "reason": "Accepted",</span>
<span class="c">#          "status": "True",</span>
<span class="c">#          "type": "Accepted"</span>
<span class="c">#        },</span>
<span class="c">#        {</span>
<span class="c">#          "lastTransitionTime": "2025-08-23T11:34:35Z",</span>
<span class="c">#          "message": "Service reference is valid",</span>
<span class="c">#          "observedGeneration": 1,</span>
<span class="c">#          "reason": "ResolvedRefs",</span>
<span class="c">#          "status": "True",</span>
<span class="c">#          "type": "ResolvedRefs"</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<ul>
  <li>TLS 요청 보내기</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># nginx 파드에서 tcpdump 실행</span>

<span class="c"># nginx 파드로 진입</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> my-nginx-d65548cd4-nn5b4 <span class="nt">--</span> bash
<span class="nt">---</span>
<span class="c"># tcpdump 설치</span>
<span class="nv">$ </span>apt update <span class="o">&amp;&amp;</span> apt <span class="nb">install</span> <span class="nt">-y</span> tcpdump
<span class="c"># tcpdump 실행 (모든 tcp 패킷 캡처)</span>
<span class="nv">$ </span>tcpdump tcp
<span class="c"># =&gt; tcpdump: verbose output suppressed, use -v[v]... for full protocol decode</span>
<span class="c">#    listening on eth0, link-type EN10MB (Ethernet), snapshot length 262144 bytes</span>
<span class="c">#    11:41:57.543620 IP 172.20.0.16.37591 &gt; my-nginx-d65548cd4-nn5b4.&lt;span style="color: green;"&gt;443&lt;/span&gt;: Flags [S], seq 2314011092, win 64240, options [mss 1460,sackOK,TS val 363195874 ecr 0,nop,wscale 7], length 0</span>
<span class="c">#    11:41:57.544029 IP my-nginx-d65548cd4-nn5b4.&lt;span style="color: green;"&gt;443&lt;/span&gt; &gt; 172.20.0.16.37591: Flags [S.], seq 3765696136, ack 2314011093, win 65160, options [mss 1460,sackOK,TS val 3668269186 ecr 363195874,nop,wscale 7], length 0</span>
<span class="c">#    11:41:57.546319 IP 172.20.0.16.37591 &gt; my-nginx-d65548cd4-nn5b4.443: Flags [.], ack 1, win 502, options [nop,nop,TS val 363195876 ecr 3668269186], length 0</span>
<span class="c">#    11:41:57.546319 IP 172.20.0.16.37591 &gt; my-nginx-d65548cd4-nn5b4.443: Flags [P.], seq 1:518, ack 1, win 502, options [nop,nop,TS val 363195876 ecr 3668269186], length 517    </span>
<span class="c">#    ...</span>
<span class="nt">---</span>

<span class="c"># k8s-ctr에서 TLS 요청 보내기</span>
<span class="nv">$ </span>curl <span class="nt">-v</span> <span class="nt">--resolve</span> <span class="s2">"nginx.cilium.rocks:443:</span><span class="nv">$GATEWAY</span><span class="s2">"</span> <span class="s2">"https://nginx.cilium.rocks:443"</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    * Server certificate:</span>
<span class="c">#    *  subject: O=mkcert development certificate; OU=root@k8s-ctr</span>
<span class="c">#    *  start date: Aug 23 08:27:20 2025 GMT</span>
<span class="c">#    *  expire date: Oct 01 08:27:20 2027 GMT</span>
<span class="c">#    *  subjectAltName: host "nginx.cilium.rocks" matched cert's "*.cilium.rocks"</span>
<span class="c">#    *  issuer: O=mkcert development CA; OU=root@k8s-ctr; CN=mkcert root@k8s-ctr</span>
<span class="c">#    *  SSL certificate verify ok.</span>
<span class="c">#    ...</span>
<span class="c">#    &lt; HTTP/1.1 200 OK</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<ul>
  <li>nginx 파드에서 tcpdump 결과 nginx의 https(443) 포트로 인입되어 https(443) 포트를 통해 응답이 나가는 것을 확인할 수 있습니다.</li>
  <li>즉, TLS Termination과는 달리 전체 TLS 트래픽이 nginx 파드까지 전달된 것을 확인할 수 있습니다.</li>
</ul>

<h5 id="gateway-api-주소-지정">Gateway API 주소 지정</h5>

<ul>
  <li>Gateway의 External IP를 직접 지정 가능합니다. - <a href="https://docs.cilium.io/en/stable/network/servicemesh/gateway-api/gateway-api/#gateway-api-addresses-support">관련 문서</a></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl edit gateway tls-gateway
<span class="c"># spec에 addresses 추가</span>
<span class="nt">---</span>
...
spec:
  addresses:                <span class="c"># 추가됨</span>
  - <span class="nb">type</span>: IPAddress         <span class="c">#     </span>
    value: 192.168.10.219   <span class="c"># </span>
  gatewayClassName: cilium
...
<span class="nt">---</span>
<span class="c"># =&gt; gateway.gateway.networking.k8s.io/tls-gateway edited</span>
</code></pre></div></div>

<ul>
  <li>호출 테스트</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ GATEWAY</span><span class="o">=</span><span class="si">$(</span>kubectl get gateway tls-gateway <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.addresses[0].value}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$GATEWAY</span>
<span class="c"># =&gt; 192.168.10.219</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 지정한 IP(192.168.10.219)로 External IP가 변경된 것을 확인할 수 있습니다.&lt;/span&gt;</span>

<span class="nv">$ </span>curl <span class="nt">-v</span> <span class="nt">--resolve</span> <span class="s2">"nginx.cilium.rocks:443:</span><span class="nv">$GATEWAY</span><span class="s2">"</span> <span class="s2">"https://nginx.cilium.rocks:443"</span> 
</code></pre></div></div>

<h5 id="ingress에서-gateway-api로-마이그레이션">Ingress에서 Gateway API로 마이그레이션</h5>

<ul>
  <li><a href="https://docs.cilium.io/en/stable/network/servicemesh/ingress-to-gateway/ingress-to-gateway/">관련 문서</a></li>
  <li><strong>수동 전환</strong> : 기존의 Ingress API 리소스를 참고하여 동일한 구성을 가진 Gateway API 리소스를 수동으로 작성합니다.</li>
  <li><strong>자동 전환</strong> : <a href="https://github.com/kubernetes-sigs/ingress2gateway">ingress2gateway</a> 툴과 같은 자동화 도구를 사용하여 Ingress 리소스를 Gateway API 리소스로 변환합니다.</li>
  <li>마이그레이션 예제
    <ul>
      <li>HTTP Migration 예제 - <a href="https://docs.cilium.io/en/stable/network/servicemesh/ingress-to-gateway/http-migration/">Docs</a></li>
      <li>TLS Migration 예제 - <a href="https://docs.cilium.io/en/stable/network/servicemesh/ingress-to-gateway/tls-migration/">Docs</a></li>
    </ul>
  </li>
</ul>

<h6 id="실습-리소스-삭제">실습 리소스 삭제</h6>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Gateway 삭제</span>
<span class="nv">$ </span>kubectl delete gateway my-gateway tls-gateway cilium-tls-gateway

<span class="c"># Bookinfo 삭제</span>
<span class="nv">$ </span>kubectl delete <span class="nt">-f</span> https://raw.githubusercontent.com/istio/istio/release-1.26/samples/bookinfo/platform/kube/bookinfo.yaml
</code></pre></div></div>

<hr />

<h2 id="mutual-authentication-beta">Mutual Authentication (Beta)</h2>

<ul>
  <li>Cilium도 istio와 마찬가지로 SPIFFE(“스피페”라고 발음하는것 같습니다.) 통한 상호 인증을 지원합니다.</li>
  <li>아직은 Beta 단계이기 때문에 프로덕션 환경에서 사용하기에는 무리가 있어보입니다.</li>
  <li><a href="https://docs.cilium.io/en/stable/network/servicemesh/mutual-authentication/mutual-authentication/">관련 문서</a></li>
</ul>

<h3 id="주요-개념">주요 개념</h3>

<ul>
  <li>SPIFFE
    <ul>
      <li>Secure Production Identity Framework For Everyone의 약자로
클라우드 네이티브 환경에서 서비스 간의 신뢰를 구축하기 위한 오픈 소스 표준입니다.</li>
      <li>서비스가 서로를 신뢰할 수 있도록 고유한 식별자(SPIFFE ID)를 제공합니다.</li>
      <li>ID를 발급하고 부트스트랩하기 위해 다음 사양을 정의 합니다.
        <ul>
          <li>SPIFFE ID : 신뢰 도메인 내의 서비스 고유 ID</li>
          <li>Workload Endpoint : 워크로드의 ID를 나타내는 엔드포인트</li>
          <li>Workload API : SPIFFE ID가 포함된 인증서를 서명하고 발급하는 API</li>
          <li>SVID (SPIFFE Verifiable Identity Document) : Workload API가 발급하는 인증서</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>TLS와 mTLS - <a href="https://www.jacobbaek.com/1040">관련 블로그</a>
    <ul>
      <li>TLS (Transport Layer Security) : 네트워크 통신을 암호화하여 데이터의 기밀성과 무결성을 보장하는 프로토콜입니다.</li>
      <li>mTLS (Mutual TLS) : TLS의 확장으로, 클라이언트와 서버가 서로를 인증하는 양방향 인증을 제공합니다.
        <ul>
          <li>기본 TLS가 서버측의 인증서를 활용하여, 적합한 서버임을 증명하는것 과는 달리 mTLS는 클라이언트와 서버 모두가 인증서를 사용하여 서로의 신원을 확인합니다.</li>
          <li>mTLS는 서비스 간의 신뢰를 구축하고, 중간자 공격과 같은 보안 위협을 방지하는 데 효과적입니다.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="cilium에서의-상호-인증">Cilium에서의 상호 인증</h3>

<ul>
  <li>Cilium은 SPIFFE 표준을 준수하는 구현체인 <a href="https://spiffe.io/spire/">spire 서버</a>를 사용하여 상호인증을 구현합니다.</li>
  <li>Cilium은 spire 서버와 통신하여 각 워크로드에 대한 SPIFFE ID를 발급받고, 이를 기반으로 각 노드에서 실행중인 워크로드의 ID 요청을 검증합니다.</li>
  <li>Spire 서버는 Kubernetes에서 실행되는 Spire 에이전트의 검증을 위해 PSAT(Kubernetes Projected Service Account Token)을 사용합니다.</li>
</ul>

<p><img src="/assets/2025/cilium/w6/20250824_cilium_w6_11.png" alt="img.png" class="image-center" />
<img src="/assets/2025/cilium/w6/20250824_cilium_w6_13.png" alt="img_2.png" class="image-center" />
<em class="image-caption">Cilium의 상호인증 구조</em></p>

<h5 id="cilium의-상호-인증-아키텍쳐">Cilium의 상호 인증 아키텍쳐</h5>

<p><img src="/assets/2025/cilium/w6/20250824_cilium_w6_14.png" alt="img.png" class="image-center" /></p>

<ul>
  <li>Cilium의 상호 인증은 다음과 같은 주요 구성 요소로 이루어져 있습니다.
    <ul>
      <li><strong>Spire 서버</strong> : SPIFFE ID를 발급하고 관리하는 중앙 컴포넌트입니다. Cilium Operator와 통신하여 워크로드의 ID 요청을 처리합니다.</li>
      <li><strong>Spire 에이전트</strong> : 각 노드에서 실행되며, Spire 서버와 통신하여 워크로드에 대한 SPIFFE ID를 요청하고 갱신합니다.</li>
      <li><strong>Cilium Agent</strong> : 각 노드에서 실행되며, Spire 에이전트와 통신하여 워크로드의 ID를 검증합니다.</li>
    </ul>
  </li>
</ul>

<hr />

<h2 id="l7-aware-traffic-management">L7-Aware Traffic Management</h2>

<h3 id="l7-aware-traffic-management-소개">L7-Aware Traffic Management 소개</h3>

<ul>
  <li>L7-Aware Traffic Management는 HTTP, gRPC와 같은 애플리케이션 계층(Layer 7) 프로토콜의 특성을 이해하고 이를 기반으로 트래픽을 세밀하게 제어하는 기능입니다.</li>
  <li>Cilium은 eBPF와 Envoy 프록시를 통해 강력한 L7 트래픽 관리 기능을 제공합니다.</li>
</ul>

<h5 id="주요-기능">주요 기능</h5>

<ul>
  <li><strong>L7 프로토콜 인식</strong>: HTTP, gRPC, Kafka 등 다양한 애플리케이션 계층 프로토콜을 인식하고 제어할 수 있습니다.</li>
  <li><strong>고급 로드 밸런싱</strong>: 요청 헤더, 경로, 메소드 등을 기반으로 한 지능적인 로드 밸런싱이 가능합니다.</li>
  <li><strong>트래픽 분할</strong>: 동일한 서비스의 여러 버전 간에 트래픽을 비율에 따라 분배할 수 있어 카나리 배포 및 A/B 테스트를 지원합니다.</li>
  <li><strong>자동 재시도</strong>: 일시적인 오류 발생 시 요청을 자동으로 재시도하여 애플리케이션의 복원력을 높일 수 있습니다.</li>
  <li><strong>타임아웃 및 서킷 브레이킹</strong>: 장애 확산을 방지하기 위한 타임아웃 설정 및 서킷 브레이커 패턴을 지원합니다.</li>
</ul>

<h5 id="구현-방식">구현 방식</h5>

<ul>
  <li>Cilium은 eBPF를 사용하여 네트워크 패킷을 가로채고, L7 처리가 필요한 경우 Envoy 프록시로 트래픽을 리디렉션합니다.</li>
  <li>이러한 아키텍처는 기존 서비스 메시 솔루션에 비해 더 적은 오버헤드를 제공합니다.</li>
</ul>

<h5 id="istio와의-비교">Istio와의 비교</h5>

<ul>
  <li>Cilium의 L7 트래픽 관리는 Istio와 같은 기존 Service Mesh 보다 성능 오버헤드가 적습니다.</li>
  <li>kubeproxy 대신 eBPF를 사용하여 필요한 트래픽만 선택적으로 Envoy 프록시로 리디렉션하기 때문입니다.</li>
  <li>그러나 기능 측면에서는 Istio가 더 풍부한 옵션을 제공할 수 있습니다.</li>
</ul>

<h3 id="실습-l7-트래픽-관리">실습: L7 트래픽 관리</h3>

<ul>
  <li>이번 실습에는 isovalent에서 제공하는 온라인 Lab 환경을 사용합니다. <a href="https://isovalent.com/labs/cilium-envoy-l7-proxy/">https://isovalent.com/labs/cilium-envoy-l7-proxy/</a></li>
</ul>

<h5 id="실습환경-설정">실습환경 설정</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 데모 앱 설치</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> sw-pods.yaml
<span class="c"># =&gt; service/deathstar created</span>
<span class="c">#    deployment.apps/deathstar created</span>
<span class="c">#    pod/tiefighter created</span>
<span class="c">#    pod/xwing created</span>

<span class="c"># 앱 배포 확인</span>
<span class="nv">$ </span>kubectl rollout status deployment/deathstar
<span class="c"># =&gt; deployment "deathstar" successfully rolled out</span>

<span class="nv">$ </span>kubectl get pod xwing
<span class="c"># =&gt; NAME    READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    xwing   1/1     Running   0          2m22s</span>

<span class="nv">$ </span>kubectl <span class="nb">exec </span>xwing <span class="nt">--</span> curl <span class="nt">--max-time</span> 1 <span class="nt">-s</span> <span class="nt">-X</span> POST deathstar.default.svc.cluster.local/v1/request-landing
<span class="c"># =&gt; Ship landed</span>

<span class="nv">$ </span>hubble observe <span class="nt">--to-pod</span> default/deathstar
<span class="c"># =&gt; Aug 23 14:05:42.357: default/xwing (ID:57137) &lt;&gt; default/deathstar-67c5c5c88-d9xct:80 (ID:3549) post-xlate-fwd TRANSLATED (TCP)</span>
<span class="c">#    Aug 23 14:05:42.357: default/xwing:54550 (ID:57137) -&gt; default/deathstar-67c5c5c88-d9xct:80 (ID:3549) to-endpoint FORWARDED (TCP Flags: SYN)</span>
<span class="c">#    Aug 23 14:05:42.357: default/xwing:54550 (ID:57137) -&gt; default/deathstar-67c5c5c88-d9xct:80 (ID:3549) to-endpoint FORWARDED (TCP Flags: ACK)</span>
<span class="c">#    Aug 23 14:05:42.357: default/xwing:54550 (ID:57137) &lt;&gt; default/deathstar-67c5c5c88-d9xct (ID:3549) pre-xlate-rev TRACED (TCP)</span>
<span class="c">#    Aug 23 14:05:42.357: default/xwing:54550 (ID:57137) -&gt; default/deathstar-67c5c5c88-d9xct:80 (ID:3549) to-endpoint FORWARDED (TCP Flags: ACK, PSH)</span>
<span class="c">#    Aug 23 14:05:42.358: default/xwing:54550 (ID:57137) -&gt; default/deathstar-67c5c5c88-d9xct:80 (ID:3549) to-endpoint FORWARDED (TCP Flags: ACK, FIN)</span>
<span class="c">#    Aug 23 14:05:42.358: default/xwing:54550 (ID:57137) -&gt; default/deathstar-67c5c5c88-d9xct:80 (ID:3549) to-endpoint FORWARDED (TCP Flags: ACK)</span>
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w6/20250824_cilium_w6_16.png" alt="img.png" /></p>

<h5 id="http-트래픽-관측하기">HTTP 트래픽 관측하기</h5>

<ul>
  <li>L7 Cilium Network Policy를 사용하여 HTTP 트래픽을 관측할 수 있습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># The trace:to-proxy filter will show all flows that go through a proxy. In general, this could be either Envoy or the Cilium DNS proxy. </span>
<span class="c"># However, since we have not yet deployed a DNS Network Policy, you will only see flows related to Envoy at the moment.</span>
<span class="nv">$ </span>hubble observe <span class="nt">--type</span> trace:to-proxy
<span class="c"># =&gt; Aug 23 14:10:33.004: default/tiefighter:53502 (ID:13923) -&gt; default/deathstar-67c5c5c88-d9xct:80 (ID:3549) to-proxy FORWARDED (TCP Flags: SYN)</span>
<span class="c">#    Aug 23 14:10:33.004: default/tiefighter:53502 (ID:13923) -&gt; default/deathstar-67c5c5c88-d9xct:80 (ID:3549) to-proxy FORWARDED (TCP Flags: ACK)</span>
<span class="c">#    Aug 23 14:10:33.004: default/tiefighter:53502 (ID:13923) -&gt; default/deathstar-67c5c5c88-d9xct:80 (ID:3549) to-proxy FORWARDED (TCP Flags: ACK, PSH)</span>
<span class="c">#    Aug 23 14:10:33.006: default/tiefighter:53502 (ID:13923) -&gt; default/deathstar-67c5c5c88-d9xct:80 (ID:3549) to-proxy FORWARDED (TCP Flags: ACK, FIN)</span>
<span class="c">#    ...</span>

<span class="c"># Let's extract all the flow information based on the protocol (e.g. HTTP) and source pod (e.g. the Tie Fighter), then export the result with the JSON output option, and finally filter with jq to only see the .flow.l7 field. This will show us the specific details parsed from the L7 traffic, such as the method and headers:</span>
<span class="c"># Observe the details of the flow, in particular the envoy-specific headers added to the request:</span>
<span class="c">## X-Envoy-Internal</span>
<span class="c">## X-Request-Id</span>
<span class="nv">$ </span>hubble observe <span class="nt">--protocol</span> http <span class="nt">--from-pod</span> default/tiefighter <span class="nt">-o</span> jsonpb | <span class="se">\</span>
  <span class="nb">head</span> <span class="nt">-n</span> 1 | jq <span class="s1">'.flow.l7'</span>
<span class="c"># =&gt; {</span>
<span class="c">#      "type": "REQUEST",</span>
<span class="c">#      "http": {</span>
<span class="c">#        "method": "POST",</span>
<span class="c">#        "url": "http://deathstar.default.svc.cluster.local/v1/request-landing",</span>
<span class="c">#        "protocol": "HTTP/1.1",</span>
<span class="c">#        "headers": [</span>
<span class="c">#          {</span>
<span class="c">#            "key": ":scheme",</span>
<span class="c">#            "value": "http"</span>
<span class="c">#          },</span>
<span class="c">#          {</span>
<span class="c">#            "key": "Accept",</span>
<span class="c">#            "value": "*/*"</span>
<span class="c">#          },</span>
<span class="c">#          {</span>
<span class="c">#            "key": "User-Agent",</span>
<span class="c">#            "value": "curl/7.88.1"</span>
<span class="c">#          },</span>
<span class="c">#          {</span>
<span class="c">#            "key": "X-Envoy-Internal",</span>
<span class="c">#            "value": "true"</span>
<span class="c">#          },</span>
<span class="c">#          {</span>
<span class="c">#            "key": "X-Request-Id",</span>
<span class="c">#            "value": "45ee8e37-6ae0-48bf-925d-13c98532b113"</span>
<span class="c">#          }</span>
<span class="c">#        ]</span>
<span class="c">#      }</span>
<span class="c">#    }</span>

<span class="c"># Let's use the X-Request-Id to match a request and its response.</span>
<span class="c"># First, we'll need to make sure egress traffic from the Tie Fighter is captured by Envoy, so we'll need a L7 CNP for that.</span>
<span class="c"># If we apply an egress CNP though, this will disrupt DNS requests, which are also egress traffic, so we need to add a DNS policy as well:</span>
<span class="nv">$ </span><span class="nb">cat </span>policies/tiefighter.yaml
<span class="c"># =&gt; apiVersion: cilium.io/v2</span>
<span class="c">#    kind: CiliumNetworkPolicy</span>
<span class="c">#    metadata:</span>
<span class="c">#      name: tiefighter</span>
<span class="c">#      namespace: default</span>
<span class="c">#    spec:</span>
<span class="c">#      endpointSelector:</span>
<span class="c">#        matchLabels:</span>
<span class="c">#          org: empire</span>
<span class="c">#          class: tiefighter</span>
<span class="c">#      egress:</span>
<span class="c">#        - toEndpoints:</span>
<span class="c">#            - matchLabels:</span>
<span class="c">#                class: deathstar</span>
<span class="c">#                org: empire</span>
<span class="c">#          toPorts:</span>
<span class="c">#            - ports:</span>
<span class="c">#                - port: "80"</span>
<span class="c">#                  protocol: TCP</span>
<span class="c">#              rules:</span>
<span class="c">#                http:</span>
<span class="c">#                - method: POST</span>
<span class="c">#                  path: /v1/request-landing</span>
              
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> policies/dns.yaml <span class="nt">-f</span> policies/tiefighter.yaml
<span class="c"># =&gt; ciliumnetworkpolicy.cilium.io/dns created</span>
<span class="c">#    ciliumnetworkpolicy.cilium.io/tiefighter created</span>

<span class="c"># All these flows are ingress flows, as you can see by filtering for HTTP flows in the egress direction, which should return nothing:</span>
<span class="c"># You can now see egress requests from the Tie Fighter being forwarded to the Death Star, as well as the responses from the Death Star:</span>
<span class="c"># When using Kubernetes Network Policies, responses are automatically allowed and do not require an explicit rule.</span>
<span class="c"># This is why egress traffic corresponding to the response from the Death Star to the Tie Fighter is allowed, even though there is not egress policy for it.</span>
<span class="nv">$ </span>hubble observe <span class="nt">--protocol</span> http <span class="nt">--traffic-direction</span> egress
<span class="c"># =&gt; Aug 23 14:12:40.875: default/tiefighter:57526 (ID:13923) -&gt; default/deathstar-67c5c5c88-d9xct:80 (ID:3549) http-request FORWARDED (HTTP/1.1 POST http://deathstar.default.svc.cluster.local/v1/request-landing)</span>
<span class="c">#    Aug 23 14:12:40.876: default/tiefighter:57526 (ID:13923) &lt;- default/deathstar-67c5c5c88-d9xct:80 (ID:3549) http-response FORWARDED (HTTP/1.1 200 0ms (POST http://deathstar.default.svc.cluster.local/v1/request-landing))</span>
<span class="c">#    ...</span>

<span class="c"># Now, let's match request IDs! Run the following command to record some Hubble HTTP flows and save them to a file:</span>
<span class="nv">$ </span>hubble observe <span class="nt">--namespace</span> default <span class="nt">--protocol</span> http <span class="nt">-o</span> jsonpb <span class="o">&gt;</span> flows.json

<span class="c"># Find the first EGRESS flow in the file and get its ID:</span>
<span class="nv">$ REQUEST_ID</span><span class="o">=</span><span class="si">$(</span><span class="nb">cat </span>flows.json | jq <span class="nt">-r</span> <span class="s1">'.flow | select(.source.labels[0]=="k8s:app.kubernetes.io/name=tiefighter" and .traffic_direction=="EGRESS") .l7.http.headers[] | select(.key=="X-Request-Id") .value'</span> | <span class="nb">head</span> <span class="nt">-n1</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$REQUEST_ID</span>
<span class="c"># =&gt; 91e9eb02-b1a7-4379-9825-8c6f72124d04</span>

<span class="c"># Then find all flows with this request ID in the file and display their source identities:</span>
<span class="c">## an egress flow from the tiefighter to the deathstar, corresponding to the original request</span>
<span class="c">## the ingress flow for the same request, being forwarded from the proxy to the Death Star</span>
<span class="c">## another egress flow for the response, from the deathstar to the tiefighter</span>
<span class="c">## the corresponding ingress flow from the deathstar pod to the tiefighter</span>

<span class="nv">$ </span><span class="nb">cat </span>flows.json | <span class="se">\</span>
  jq <span class="s1">'select(.flow.l7.http.headers[] | .value == "'</span><span class="nv">$REQUEST_ID</span><span class="s1">'") .flow | {src_label: .source.labels[0], dst_label: .destination.labels[0], traffic_direction, type: .l7.type, time}'</span>
<span class="c"># =&gt; {</span>
<span class="c">#      "src_label": "k8s:app.kubernetes.io/name=tiefighter",</span>
<span class="c">#      "dst_label": "k8s:app.kubernetes.io/name=deathstar",</span>
<span class="c">#      "traffic_direction": "EGRESS",</span>
<span class="c">#      "type": "REQUEST",</span>
<span class="c">#      "time": "2025-08-23T14:13:38.661418360Z"</span>
<span class="c">#    }</span>
<span class="c">#    {</span>
<span class="c">#      "src_label": "k8s:app.kubernetes.io/name=tiefighter",</span>
<span class="c">#      "dst_label": "k8s:app.kubernetes.io/name=deathstar",</span>
<span class="c">#      "traffic_direction": "INGRESS",</span>
<span class="c">#      "type": "REQUEST",</span>
<span class="c">#      "time": "2025-08-23T14:13:38.661841958Z"</span>
<span class="c">#    }</span>
<span class="c">#    {</span>
<span class="c">#      "src_label": "k8s:app.kubernetes.io/name=deathstar",</span>
<span class="c">#      "dst_label": "k8s:app.kubernetes.io/name=tiefighter",</span>
<span class="c">#      "traffic_direction": "INGRESS",</span>
<span class="c">#      "type": "RESPONSE",</span>
<span class="c">#      "time": "2025-08-23T14:13:38.662308747Z"</span>
<span class="c">#    }</span>
<span class="c">#    {</span>
<span class="c">#      "src_label": "k8s:app.kubernetes.io/name=deathstar",</span>
<span class="c">#      "dst_label": "k8s:app.kubernetes.io/name=tiefighter",</span>
<span class="c">#      "traffic_direction": "EGRESS",</span>
<span class="c">#      "type": "RESPONSE",</span>
<span class="c">#      "time": "2025-08-23T14:13:38.662497732Z"</span>
<span class="c">#    }</span>
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w6/20250824_cilium_w6_17.png" alt="img.png" /></p>

<h5 id="l7-메트릭">L7 메트릭</h5>

<ul>
  <li>Envoy를 통해 Hubble에서 L7 메트릭을 수집할 수 있고, Prometheus로 내보낼 수 있습니다.</li>
</ul>

<p><img src="/assets/2025/cilium/w6/20250824_cilium_w6_15.png" alt="img.png" class="image-center image-bg" />
<em class="image-caption">Cilium의 L7 메트릭 수집</em></p>

<h5 id="envoy를-통한-l7-네트워크-정책-적용">Envoy를 통한 L7 네트워크 정책 적용</h5>

<ul>
  <li><strong>HTTP</strong> : 지난 포스트에서 <a href="https://sweetlittlebird.github.io/posts/2025-07-27-Cilium-Week2/#http-aware-l7-%EC%A0%95%EC%B1%85-%EC%A0%81%EC%9A%A9-%EB%B0%8F-%ED%85%8C%EC%8A%A4%ED%8A%B8">[Cilium] (Observability) Hubble, Prometheus, Grafana</a>
Http-aware L7 정책 적용 및 테스트를 다뤘습니다. 해당 포스트를 참고해주세요.</li>
</ul>

<h3 id="l7-aware-traffic-management-활성화">L7-Aware Traffic Management 활성화</h3>

<ul>
  <li>CiliumEnvoyConfig , CiliumClusterwideEnvoyConfig - <a href="https://docs.cilium.io/en/stable/network/servicemesh/l7-traffic-management/">Docs</a>
    <ul>
      <li>주의사항 :
        <ul>
          <li>CiliumEnvoyConfig 리소스는 최소한의 검증만 수행되며 정의된 충돌 해결 동작이 없습니다. 즉, EnvoyConfig의 동일한 구성 부분을 수정하는 CEC를 여러 개 만들면 결과를 예측할 수 없을 수 있습니다.</li>
          <li>이 최소한의 검증 외에도, CiliumEnvoyConfig는 사용자에게 구성의 정확성에 대한 피드백을 최소한으로 제공합니다. 따라서 CEC가 바람직하지 않은 결과를 초래할 경우, 문제 해결을 위해서는 문제의 CiliumEnvoyConfig를 확인할 수 있는 대신 EnvoyConfig를 검토해야 합니다.</li>
          <li>CiliumEnvoyConfig는 Cilium의 Ingress 및 Gateway API 지원을 통해 노드별 Envoy 프록시를 통해 트래픽을 유도하는 데 사용됩니다. 자동 생성된 구성과 충돌하거나 수정하는 CEC를 만들면 결과를 예측할 수 없을 수 있습니다. 이러한 사용 사례에서는 CEC를 사용하는 데 매우 주의하세요. 위의 위험은 Cilium에서 생성된 모든 구성이 가능한 한 의미적으로 유효한지 확인함으로써 관리됩니다.</li>
          <li>CiliumEnvoyConfig 리소스를 직접 생성하는 경우(즉, Cilium Ingress 또는 Gateway API 컨트롤러를 통해 생성하지 않고), CEC가 E/W 트래픽을 관리하려는 경우 레이블 cilium.io/use-original-source-address : “false”를 설정합니다. 그렇지 않으면, EnvoyConfig는 업스트림 연결 풀의 소켓을 원래 소스 주소/포트에 바인딩합니다. 이로 인해 포드가 동일한 파이프라인 HTTP/1.1 또는 HTTP/2 연결을 통해 여러 요청을 보낼 때 5-tup 충돌이 발생할 수 있습니다. (Cilium 에이전트는 부모 Ref가 Cilium Ingress 또는 Gateway API 컨트롤러를 가리키는 모든 CEC가 cilium.io/use-original-source-address 을 “false”로 설정한 것으로 가정하지만, 다른 모든 CEC는 이 레이블을 “true”로 설정한 것으로 가정합니다.)</li>
          <li>현재는 Envoy API v3만 지원합니다. - <a href="https://docs.cilium.io/en/stable/network/servicemesh/l7-traffic-management/#supported-envoy-api-versions">Docs</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>설정
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--version</span> 1.18.1 <span class="nt">--namespace</span> kube-system <span class="nt">--reuse-values</span> <span class="se">\</span>
  <span class="nt">--set</span> ingressController.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> gatewayAPI.enabled<span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
  <span class="nt">--set</span> envoyConfig.enabled<span class="o">=</span><span class="nb">true</span>  <span class="nt">--set</span> loadBalancer.l7.backend<span class="o">=</span>envoy
<span class="c"># =&gt; Release "cilium" has been upgraded. Happy Helming!</span>
  
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system rollout restart deployment/cilium-operator
<span class="c"># =&gt; deployment.apps/cilium-operator restarted</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system rollout restart ds/cilium
<span class="c"># =&gt; daemonset.apps/cilium restarted</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system rollout restart ds/cilium-envoy
<span class="c"># =&gt; daemonset.apps/cilium-envoy restarted</span>
  
<span class="c">#</span>
<span class="nv">$ </span>cilium config view |grep <span class="nt">-i</span> envoy
<span class="c"># =&gt; enable-envoy-config                               true</span>
<span class="c">#    envoy-access-log-buffer-size                      4096</span>
<span class="c">#    envoy-base-id                                     0</span>
<span class="c">#    envoy-config-retry-interval                       15s</span>
<span class="c">#    envoy-keep-cap-netbindservice                     false</span>
<span class="c">#    envoy-secrets-namespace                           cilium-secrets</span>
<span class="c">#    external-envoy-proxy                              true</span>
<span class="c">#    loadbalancer-l7                                   envoy</span>
<span class="nv">$ </span>cilium status <span class="nt">--wait</span>
</code></pre></div>    </div>
  </li>
  <li>지원하는 Envoy 확장 리소스 유형
    <ul>
      <li>확장은 Envoy 빌드에 선택적으로 포함될 수 있는 리소스 유형입니다. Envoy 문서에서 언급되는 표준 유형들, 
예를 들어 <code class="language-plaintext highlighter-rouge">type.googleapis.com/envoy.config.listener.v3.Listener</code>와 
<code class="language-plaintext highlighter-rouge">type.googleapis.com/envoy.config.route.v3.RouteConfiguration</code>은 항상 사용할 수 있습니다.</li>
      <li>Cilium 노드는 Cilium HTTP 정책 적용 및 관측 가능성을 지원하기 위해 Envoy 이미지를 배포합니다.
이 Envoy 빌드는 Cilium Agent의 요구사항에 최적화되어 있으며 
Envoy 코드베이스에서 사용할 수 있는 많은 Envoy 확장들을 포함하지 않습니다.</li>
      <li>사용 가능한 Envoy 확장을 확인하려면 <a href="https://github.com/cilium/proxy/blob/main/envoy_build_config/extensions_build_config.bzl">Envoy 확장 구성 파일</a>을 참조하세요. 
<code class="language-plaintext highlighter-rouge">#</code>으로 주석 처리되지 않은 확장만이 Cilium Envoy 이미지에 빌드됩니다. 
사용자 피드백에 따라 내장 확장 목록을 발전해 나갈 것입니다.</li>
    </ul>
  </li>
</ul>

<h3 id="l7-load-balancing과-url-rewriting">L7 Load Balancing과 URL Rewriting</h3>

<ul>
  <li><a href="https://docs.cilium.io/en/stable/network/servicemesh/envoy-traffic-management/">관련 문서</a></li>
  <li>두 백엔드 서비스(echo-service-1/2) 간의 요청 부하를 분산하고, URL을 Rewrite하는 Envoy 구성을 생성해 보겠습니다.</li>
</ul>

<h5 id="실습-환경-구성-1">실습 환경 구성</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 샘플 애플리케이션 배포</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/cilium/cilium/1.18.1/examples/kubernetes/servicemesh/envoy/test-application.yaml
<span class="c"># =&gt; configmap/coredns-configmap created</span>
<span class="c">#    deployment.apps/client created</span>
<span class="c">#    deployment.apps/client2 created</span>
<span class="c">#    deployment.apps/echo-service-1 created</span>
<span class="c">#    deployment.apps/echo-service-2 created</span>
<span class="c">#    service/echo-service-1 created</span>
<span class="c">#    service/echo-service-2 created</span>

<span class="c"># 확인</span>
<span class="c">## 두 개의 클라이언트 배포 client , client2</span>
<span class="c">## 두 가지 서비스, echo-service-1, echo-service-2</span>
<span class="nv">$ </span>kubectl get <span class="nt">-f</span> https://raw.githubusercontent.com/cilium/cilium/1.18.1/examples/kubernetes/servicemesh/envoy/test-application.yaml
<span class="c"># =&gt; NAME                          DATA   AGE</span>
<span class="c">#    configmap/coredns-configmap   1      30s</span>
<span class="c">#    </span>
<span class="c">#    NAME                             READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/client           1/1     1            1           30s</span>
<span class="c">#    deployment.apps/client2          1/1     1            1           30s</span>
<span class="c">#    deployment.apps/echo-service-1   1/1     1            1           30s</span>
<span class="c">#    deployment.apps/echo-service-2   1/1     1            1           30s</span>
<span class="c">#    </span>
<span class="c">#    NAME                     TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE</span>
<span class="c">#    service/echo-service-1   NodePort   10.96.162.98   &lt;none&gt;        8080:30749/TCP   30s</span>
<span class="c">#    service/echo-service-2   NodePort   10.96.78.11    &lt;none&gt;        8080:31200/TCP   30s</span>

<span class="c"># client2 에 대한 Pod ID로 환경 변수 지정</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CLIENT2</span><span class="o">=</span><span class="si">$(</span>kubectl get pods <span class="nt">-l</span> <span class="nv">name</span><span class="o">=</span>client2 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$CLIENT2</span>
<span class="c"># =&gt; client2-c97ddf6cf-2gm94</span>

<span class="c"># Start Observing Traffic with Hubble</span>
<span class="nv">$ </span>cilium hubble port-forward&amp;
<span class="c"># =&gt; ℹ️   Hubble Relay is available at 127.0.0.1:4245</span>
<span class="nv">$ </span>hubble observe <span class="nt">--from-pod</span> <span class="nv">$CLIENT2</span> <span class="nt">-f</span>


<span class="c"># You should be able to get a response from both of the backend services individually from client2:</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$CLIENT2</span> <span class="nt">--</span> curl <span class="nt">-v</span> echo-service-1:8080/
<span class="c"># =&gt; &lt; HTTP/1.1 200 OK</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$CLIENT2</span> <span class="nt">--</span> curl <span class="nt">-v</span> echo-service-2:8080/
<span class="c"># =&gt; &lt; HTTP/1.1 200 OK</span>

<span class="c"># Verify that you get a 404 error response if you curl to the non-existent URL /foo on these services:</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$CLIENT2</span> <span class="nt">--</span> curl <span class="nt">-v</span> echo-service-1:8080/foo
<span class="c"># =&gt; &lt; HTTP/1.1 404 Not Found</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$CLIENT2</span> <span class="nt">--</span> curl <span class="nt">-v</span> echo-service-2:8080/foo 
<span class="c"># =&gt; &lt; HTTP/1.1 404 Not Found</span>
</code></pre></div></div>

<h5 id="l7-정책-추가">L7 정책 추가</h5>

<ul>
  <li><code class="language-plaintext highlighter-rouge">one.one.one.one</code> 도메인에 대한 HTTP GET 요청을 허용하는 정책과 echo 서비스의 <code class="language-plaintext highlighter-rouge">/</code> 경로에 대한 HTTP GET 요청을 허용하는 정책을 추가합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Adding a Layer 7 policy introduces the Envoy proxy into the path for this traffic</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/cilium/cilium/1.18.1/examples/kubernetes/servicemesh/envoy/client-egress-l7-http.yaml
<span class="c"># =&gt; ciliumnetworkpolicy.cilium.io/client-egress-l7-http created</span>

<span class="c"># client2 is allowed to contact one.one.one.one/ on port 80 and the echo Pod</span>
<span class="c"># on port 8080. HTTP introspection is enabled for client2.</span>
<span class="c"># The toFQDNs section relies on DNS introspection being performed by</span>
<span class="c"># the client-egress-only-dns policy.</span>
apiVersion: <span class="s2">"cilium.io/v2"</span>
kind: CiliumNetworkPolicy
metadata:
  name: client-egress-l7-http
spec:
  description: <span class="s2">"Allow GET one.one.one.one:80/ and GET &lt;echo&gt;:8080/ from client2"</span>
  endpointSelector:
    matchLabels:
      other: client
  egress:
    <span class="c"># Allow GET / requests towards echo pods.</span>
    - toEndpoints:
        - matchLabels:
            k8s:kind: <span class="nb">echo
      </span>toPorts:
        - ports:
            - port: <span class="s2">"8080"</span>
              protocol: TCP
          rules:
            http:
              - method: <span class="s2">"GET"</span>
                path: <span class="s2">"/"</span>
    <span class="c"># Allow GET / requests, only towards one.one.one.one.</span>
    - toFQDNs:
        - matchName: <span class="s2">"one.one.one.one"</span>
      toPorts:
        - ports:
            - port: <span class="s2">"80"</span>
              protocol: TCP
          rules:
            http:
              - method: <span class="s2">"GET"</span>
                path: <span class="s2">"/"</span>
                
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/cilium/cilium/1.18.1/examples/kubernetes/servicemesh/envoy/client-egress-only-dns.yaml
<span class="c"># =&gt; ciliumnetworkpolicy.cilium.io/client-egress-only-dns created</span>

apiVersion: cilium.io/v2
kind: CiliumNetworkPolicy
metadata:
  name: client-egress-only-dns
spec:
  endpointSelector:
    matchLabels:
      kind: client
  egress:
    - toPorts:
        - ports:
            - port: <span class="s2">"53"</span>
              protocol: ANY
          rules:
            dns:
              - matchPattern: <span class="s2">"*"</span>
      toEndpoints:
        - matchLabels:
            k8s:io.kubernetes.pod.namespace: kube-system
            k8s:k8s-app: kube-dns
        - matchLabels:
            k8s:io.kubernetes.pod.namespace: kube-system
            k8s:k8s-app: coredns

<span class="c"># Make a request to a backend service (either will do):</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$CLIENT2</span> <span class="nt">--</span> curl <span class="nt">-v</span> echo-service-1:8080/
<span class="c"># =&gt; &lt; HTTP/1.1 200 OK</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 echo 서비스의 / 경로에 대해서는 승인 정책이 적용되었기 때문에 200 OK 응답을 받을 수 있습니다.&lt;/span&gt;</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$CLIENT2</span> <span class="nt">--</span> curl <span class="nt">-v</span> echo-service-2:8080/foo
<span class="c"># =&gt; &lt; HTTP/1.1 403 Forbidden</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 /foo는 승인 정책에 포함되지 않았기 때문에 403 Forbidden 응답을 받습니다.&lt;/span&gt;</span>

<span class="nv">$ </span>hubble observe <span class="nt">--from-pod</span> <span class="nv">$CLIENT2</span> <span class="nt">-f</span>
<span class="c"># =&gt; Aug 23 15:01:32.615: default/client2-c97ddf6cf-2gm94:35118 (ID:30927) -&gt; default/echo-service-2-5df858689b-lbtff:8080 (ID:15303) http-request DROPPED (HTTP/1.1 GET http://echo-service-2:8080/foo)</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 Hubble에서 트래픽을 관찰해보면, echo-service-2로의 요청이 DROPPED된 것을 확인할 수 있습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<h5 id="l7-load-balancing과-url-rewriting-적용">L7 Load Balancing과 URL Rewriting 적용</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Envoy 로드 밸런싱 및 URL 재작성 추가 : 두 백엔드 echo-서비스 간에 50/50의 부하 분산 , 경로 /foo를 다시 작성합니다/</span>
<span class="c"># Apply the envoy-traffic-management-test.yaml file, which defines a CiliumClusterwideEnvoyConfig</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/cilium/cilium/1.18.1/examples/kubernetes/servicemesh/envoy/envoy-traffic-management-test.yaml
<span class="c"># =&gt; ciliumclusterwideenvoyconfig.cilium.io/envoy-lb-listener created</span>

apiVersion: cilium.io/v2
kind: CiliumClusterwideEnvoyConfig
metadata:
  name: envoy-lb-listener
spec:
  services:
    - name: echo-service-1
      namespace: default
    - name: echo-service-2
      namespace: default
  resources:
    - <span class="s2">"@type"</span>: type.googleapis.com/envoy.config.listener.v3.Listener
      name: envoy-lb-listener
      filter_chains:
        - filters:
            - name: envoy.filters.network.http_connection_manager
              typed_config:
                <span class="s2">"@type"</span>: type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager
                stat_prefix: envoy-lb-listener
                rds:
                  route_config_name: lb_route
                use_remote_address: <span class="nb">true
                </span>skip_xff_append: <span class="nb">true
                </span>http_filters:
                  - name: envoy.filters.http.router
                    typed_config:
                      <span class="s2">"@type"</span>: type.googleapis.com/envoy.extensions.filters.http.router.v3.Router
    - <span class="s2">"@type"</span>: type.googleapis.com/envoy.config.route.v3.RouteConfiguration
      name: lb_route
      virtual_hosts:
        - name: <span class="s2">"lb_route"</span>
          domains: <span class="o">[</span> <span class="s2">"*"</span> <span class="o">]</span>
          routes:
            - match:
                prefix: <span class="s2">"/"</span>
              route:
                weighted_clusters:
                  clusters:
                    - name: <span class="s2">"default/echo-service-1"</span>
                      weight: 50
                    - name: <span class="s2">"default/echo-service-2"</span>
                      weight: 50
                retry_policy:
                  retry_on: 5xx
                  num_retries: 3
                  per_try_timeout: 1s
                regex_rewrite:
                  pattern:
                    google_re2: <span class="o">{</span> <span class="o">}</span>
                    regex: <span class="s2">"^/foo.*$"</span>
                  substitution: <span class="s2">"/"</span>
    - <span class="s2">"@type"</span>: type.googleapis.com/envoy.config.cluster.v3.Cluster
      name: <span class="s2">"default/echo-service-1"</span>
      connect_timeout: 5s
      lb_policy: ROUND_ROBIN
      <span class="nb">type</span>: EDS
      outlier_detection:
        split_external_local_origin_errors: <span class="nb">true
        </span>consecutive_local_origin_failure: 2
    - <span class="s2">"@type"</span>: type.googleapis.com/envoy.config.cluster.v3.Cluster
      name: <span class="s2">"default/echo-service-2"</span>
      connect_timeout: 3s
      lb_policy: ROUND_ROBIN
      <span class="nb">type</span>: EDS
      outlier_detection:
        split_external_local_origin_errors: <span class="nb">true
        </span>consecutive_local_origin_failure: 2

<span class="c"># CiliumClusterwideEnvoyConfig 약자 ccec</span>
<span class="nv">$ </span>kubectl get ccec <span class="nt">-o</span> yaml | yq
<span class="nv">$ </span>kubectl get ccec 
<span class="c"># =&gt; NAME                AGE</span>
<span class="c">#    envoy-lb-listener   21s</span>

<span class="c"># 50:50 LB 분산 호출됨</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$CLIENT2</span> <span class="nt">--</span> curl <span class="nt">-v</span> echo-service-1:8080/foo

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$CLIENT2</span> <span class="nt">--</span> curl <span class="nt">-v</span> echo-service-1:8080/foo
<span class="c"># =&gt; &lt; HTTP/1.1 200 OK</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 URL Rewriting이 적용되어 /foo 경로에 대한 요청이 /로 다시 작성되어 200 OK 응답을 받습니다.&lt;/span&gt;</span>

<span class="c"># 하지만 네트워크 정책은 여전히 /로 다시 작성되지 않은 경로에 대한 요청을 방지합니다. </span>
<span class="c"># 예를 들어, 이 요청은 패킷이 삭제되고 403 금지 응답 코드가 생성</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$CLIENT2</span> <span class="nt">--</span> curl <span class="nt">-v</span> echo-service-1:8080/bar
<span class="c"># =&gt; &lt; HTTP/1.1 403 Forbidden</span>

<span class="c">## rewrite 되지 않은 /bar 경로에 대한 요청에 대한 hubble 출력</span>
<span class="c"># =&gt; Aug 23 15:26:06.041: default/client2-c97ddf6cf-2gm94:50256 (ID:30927) -&gt; default/echo-service-2-5df858689b-lbtff:8080 (ID:15303) http-request DROPPED (HTTP/1.1 GET http://echo-service-1:8080/bar)</span>

<span class="c"># 로그 확인</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system logs daemonsets/cilium-envoy
</code></pre></div></div>

<hr />

<h2 id="마치며">마치며</h2>

<p>이번 포스트에서도 Cilium Service Mesh에서 제공하는 다양한 기능을 살펴보았습니다.
특히 기존에 Nginx Ingress를 사용하면서 세부적인 설정을 하려면 annotation도 찾아보고, 해당 annotation의 동작을 이해하기 위해서
nginx 문서도 봐야했는데, Gateway API가 이를 해결 할 것 같아서 기대됩니다.</p>

<p>상호 인증만 Beta를 벗어나면 istio같은 기존 서비스 메시 솔루션을 대체할 수 있을것 같다는 생각이 듭니다.
eBPF와 Envoy라는 튼튼한 기초가 있으니 다양한 기능들을 확장해 나가는것 같아서
초기 설계와 철학이 얼마나 중요한지 다시 한번 느끼게 됩니다.</p>]]></content><author><name></name></author><category term="cilium" /><category term="kubernetes," /><category term="network," /><category term="linux," /><category term="cilium," /><category term="servicemesh" /><summary type="html"><![CDATA[이번 포스트에서는 ServiceMesh이란 무엇인가와 등장배경을 알아보고, Cilium에서 제공하는 ServiceMesh의 각 기능들에 대해 실습을 통하여 알아보도록 하겠습니다.]]></summary></entry><entry><title type="html">[Cilium] BGP Control Plane &amp;amp; ClusterMesh</title><link href="https://sweetlittlebird.github.io/posts/2025-08-17-Cilium-Week5/" rel="alternate" type="text/html" title="[Cilium] BGP Control Plane &amp;amp; ClusterMesh" /><published>2025-08-17T00:10:18+09:00</published><updated>2025-08-17T00:10:18+09:00</updated><id>https://sweetlittlebird.github.io/posts/Cilium%20-%20Week5</id><content type="html" xml:base="https://sweetlittlebird.github.io/posts/2025-08-17-Cilium-Week5/"><![CDATA[<h2 id="들어가며">들어가며</h2>

<p>이번 포스트에서는 BGP를 통한 라우팅과 kind, cluster-mesh를 통한 멀티 클러스터 환경에서의 Cilium 동작을 살펴보겠습니다.</p>

<hr />

<h2 id="실습-환경-구성">실습 환경 구성</h2>

<ul>
  <li>이번 실습에서는 지난 실습과 마찬가지로 k8s-w0를 별도의 네트워크에 배치하고 router를 통해 k8s-w0와 k8s-ctr/w1 노드간 통신을 확인합니다. 하지만 이번 실습에서는 frr을 설치하여 BGP 라우팅을 통해 통신을 확인해보겠습니다.
<img src="/assets/2025/cilium/w5/20250817_cilium_w5_1.png" alt="20250817_cilium_w5_1.png" class="image-center image-bg" />
    <ul>
      <li>기본 배포 가상 머신 : k8s-ctr, k8s-w1, k8s-w0, router (<strong>frr 라우팅</strong>)</li>
      <li><strong>router</strong> : router : 192.168.<strong>10</strong>.0/24 ↔ 192.168.<strong>20</strong>.0/24 대역 라우팅 역할, k8s 에 join 되지 않은 서버이며, BGP 동작을 위해 <a href="https://docs.frrouting.org/en/stable-10.4/about.html">frr</a> 툴이 설치되어있습니다.</li>
      <li><strong>k8s-w0</strong> : k8s-ctr/w1 노드와 다른 네트워크 대역에 배치됩니다.</li>
      <li>실습 동작에 필요한 static routing이 설저된 상태로 배포 됩니다.</li>
    </ul>
  </li>
</ul>

<h3 id="실습환경-배포-파일">실습환경 배포 파일</h3>

<ul>
  <li>
    <p><strong>Vagrantfile</strong> : 가상머신 정의, 부팅 시 초기 프로비저닝 설정을 포함하는 Vagrantfile입니다.</p>

    <div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Variables</span>
<span class="no">K8SV</span> <span class="o">=</span> <span class="s1">'1.33.2-1.1'</span> <span class="c1"># Kubernetes Version : apt list -a kubelet , ex) 1.32.5-1.1</span>
<span class="no">CONTAINERDV</span> <span class="o">=</span> <span class="s1">'1.7.27-1'</span> <span class="c1"># Containerd Version : apt list -a containerd.io , ex) 1.6.33-1</span>
<span class="no">CILIUMV</span> <span class="o">=</span> <span class="s1">'1.18.0'</span> <span class="c1"># Cilium CNI Version : https://github.com/cilium/cilium/tags</span>
<span class="no">N</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># max number of worker nodes</span>
  
<span class="c1"># Base Image  https://portal.cloud.hashicorp.com/vagrant/discover/bento/ubuntu-24.04</span>
<span class="no">BOX_IMAGE</span> <span class="o">=</span> <span class="s2">"bento/ubuntu-24.04"</span>
<span class="no">BOX_VERSION</span> <span class="o">=</span> <span class="s2">"202508.03.0"</span>
  
<span class="no">Vagrant</span><span class="p">.</span><span class="nf">configure</span><span class="p">(</span><span class="s2">"2"</span><span class="p">)</span> <span class="k">do</span> <span class="o">|</span><span class="n">config</span><span class="o">|</span>
  <span class="c1">#-ControlPlane Node</span>
  <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">define</span> <span class="s2">"k8s-ctr"</span> <span class="k">do</span> <span class="o">|</span><span class="n">subconfig</span><span class="o">|</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="no">BOX_IMAGE</span>
  
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box_version</span> <span class="o">=</span> <span class="no">BOX_VERSION</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provider</span> <span class="s2">"virtualbox"</span> <span class="k">do</span> <span class="o">|</span><span class="n">vb</span><span class="o">|</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--groups"</span><span class="p">,</span> <span class="s2">"/Cilium-Lab"</span><span class="p">]</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--nicpromisc2"</span><span class="p">,</span> <span class="s2">"allow-all"</span><span class="p">]</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">name</span> <span class="o">=</span> <span class="s2">"k8s-ctr"</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">cpus</span> <span class="o">=</span> <span class="mi">2</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">memory</span> <span class="o">=</span> <span class="mi">2560</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">linked_clone</span> <span class="o">=</span> <span class="kp">true</span>
    <span class="k">end</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">host_name</span> <span class="o">=</span> <span class="s2">"k8s-ctr"</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.10.100"</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="mi">60000</span><span class="p">,</span> <span class="ss">auto_correct: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">id: </span><span class="s2">"ssh"</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">synced_folder</span> <span class="s2">"./"</span><span class="p">,</span> <span class="s2">"/vagrant"</span><span class="p">,</span> <span class="ss">disabled: </span><span class="kp">true</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/5w/init_cfg.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">K8SV</span><span class="p">,</span> <span class="no">CONTAINERDV</span> <span class="p">]</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/5w/k8s-ctr.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">N</span><span class="p">,</span> <span class="no">CILIUMV</span><span class="p">,</span> <span class="no">K8SV</span> <span class="p">]</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/5w/route-add1.sh"</span>
  <span class="k">end</span>
  
  <span class="c1">#-Worker Nodes Subnet1</span>
  <span class="p">(</span><span class="mi">1</span><span class="o">..</span><span class="no">N</span><span class="p">).</span><span class="nf">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">i</span><span class="o">|</span>
    <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">define</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span> <span class="k">do</span> <span class="o">|</span><span class="n">subconfig</span><span class="o">|</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="no">BOX_IMAGE</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box_version</span> <span class="o">=</span> <span class="no">BOX_VERSION</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provider</span> <span class="s2">"virtualbox"</span> <span class="k">do</span> <span class="o">|</span><span class="n">vb</span><span class="o">|</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--groups"</span><span class="p">,</span> <span class="s2">"/Cilium-Lab"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--nicpromisc2"</span><span class="p">,</span> <span class="s2">"allow-all"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">name</span> <span class="o">=</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">cpus</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">memory</span> <span class="o">=</span> <span class="mi">1536</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">linked_clone</span> <span class="o">=</span> <span class="kp">true</span>
      <span class="k">end</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">host_name</span> <span class="o">=</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.10.10</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="s2">"6000</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span> <span class="ss">auto_correct: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">id: </span><span class="s2">"ssh"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">synced_folder</span> <span class="s2">"./"</span><span class="p">,</span> <span class="s2">"/vagrant"</span><span class="p">,</span> <span class="ss">disabled: </span><span class="kp">true</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/5w/init_cfg.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">K8SV</span><span class="p">,</span> <span class="no">CONTAINERDV</span><span class="p">]</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/5w/k8s-w.sh"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/5w/route-add1.sh"</span>
    <span class="k">end</span>
  <span class="k">end</span>
  
  <span class="c1">#-Router Node</span>
  <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">define</span> <span class="s2">"router"</span> <span class="k">do</span> <span class="o">|</span><span class="n">subconfig</span><span class="o">|</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="no">BOX_IMAGE</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box_version</span> <span class="o">=</span> <span class="no">BOX_VERSION</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provider</span> <span class="s2">"virtualbox"</span> <span class="k">do</span> <span class="o">|</span><span class="n">vb</span><span class="o">|</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--groups"</span><span class="p">,</span> <span class="s2">"/Cilium-Lab"</span><span class="p">]</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">name</span> <span class="o">=</span> <span class="s2">"router"</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">cpus</span> <span class="o">=</span> <span class="mi">1</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">memory</span> <span class="o">=</span> <span class="mi">768</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">linked_clone</span> <span class="o">=</span> <span class="kp">true</span>
    <span class="k">end</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">host_name</span> <span class="o">=</span> <span class="s2">"router"</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.10.200"</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="mi">60009</span><span class="p">,</span> <span class="ss">auto_correct: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">id: </span><span class="s2">"ssh"</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.20.200"</span><span class="p">,</span> <span class="ss">auto_config: </span><span class="kp">false</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">synced_folder</span> <span class="s2">"./"</span><span class="p">,</span> <span class="s2">"/vagrant"</span><span class="p">,</span> <span class="ss">disabled: </span><span class="kp">true</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/5w/router.sh"</span>
  <span class="k">end</span>
  
  <span class="c1">#-Worker Nodes Subnet2</span>
  <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">define</span> <span class="s2">"k8s-w0"</span> <span class="k">do</span> <span class="o">|</span><span class="n">subconfig</span><span class="o">|</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="no">BOX_IMAGE</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box_version</span> <span class="o">=</span> <span class="no">BOX_VERSION</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provider</span> <span class="s2">"virtualbox"</span> <span class="k">do</span> <span class="o">|</span><span class="n">vb</span><span class="o">|</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--groups"</span><span class="p">,</span> <span class="s2">"/Cilium-Lab"</span><span class="p">]</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--nicpromisc2"</span><span class="p">,</span> <span class="s2">"allow-all"</span><span class="p">]</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">name</span> <span class="o">=</span> <span class="s2">"k8s-w0"</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">cpus</span> <span class="o">=</span> <span class="mi">2</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">memory</span> <span class="o">=</span> <span class="mi">1536</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">linked_clone</span> <span class="o">=</span> <span class="kp">true</span>
    <span class="k">end</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">host_name</span> <span class="o">=</span> <span class="s2">"k8s-w0"</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.20.100"</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="mi">60010</span><span class="p">,</span> <span class="ss">auto_correct: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">id: </span><span class="s2">"ssh"</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">synced_folder</span> <span class="s2">"./"</span><span class="p">,</span> <span class="s2">"/vagrant"</span><span class="p">,</span> <span class="ss">disabled: </span><span class="kp">true</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/5w/init_cfg.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">K8SV</span><span class="p">,</span> <span class="no">CONTAINERDV</span><span class="p">]</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/5w/k8s-w.sh"</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/5w/route-add2.sh"</span>
  <span class="k">end</span>
  
<span class="k">end</span>

</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>init_cfg.sh</strong> : args 참고하여 초기 설정을 수행하는 스크립트입니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config Start &lt;&lt;&lt;&lt;"</span>
  
<span class="nb">echo</span> <span class="s2">"[TASK 1] Setting Profile &amp; Bashrc"</span>
<span class="nb">echo</span> <span class="s1">'alias vi=vim'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s2">"sudo su -"</span> <span class="o">&gt;&gt;</span> /home/vagrant/.bashrc
<span class="nb">ln</span> <span class="nt">-sf</span> /usr/share/zoneinfo/Asia/Seoul /etc/localtime <span class="c"># Change Timezone</span>
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 2] Disable AppArmor"</span>
systemctl stop ufw <span class="o">&amp;&amp;</span> systemctl disable ufw <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
systemctl stop apparmor <span class="o">&amp;&amp;</span> systemctl disable apparmor <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 3] Disable and turn off SWAP"</span>
swapoff <span class="nt">-a</span> <span class="o">&amp;&amp;</span> <span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'/swap/s/^/#/'</span> /etc/fstab
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 4] Install Packages"</span>
apt update <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
apt-get <span class="nb">install </span>apt-transport-https ca-certificates curl gpg <span class="nt">-y</span> <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="c"># Download the public signing key for the Kubernetes package repositories.</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> <span class="nt">-m</span> 755 /etc/apt/keyrings
<span class="nv">K8SMMV</span><span class="o">=</span><span class="si">$(</span><span class="nb">echo</span> <span class="nv">$1</span> | <span class="nb">sed</span> <span class="nt">-En</span> <span class="s1">'s/^([0-9]+\.[0-9]+)\..*/\1/p'</span><span class="si">)</span>
curl <span class="nt">-fsSL</span> https://pkgs.k8s.io/core:/stable:/v<span class="nv">$K8SMMV</span>/deb/Release.key | <span class="nb">sudo </span>gpg <span class="nt">--dearmor</span> <span class="nt">-o</span> /etc/apt/keyrings/kubernetes-apt-keyring.gpg
<span class="nb">echo</span> <span class="s2">"deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v</span><span class="nv">$K8SMMV</span><span class="s2">/deb/ /"</span> <span class="o">&gt;&gt;</span> /etc/apt/sources.list.d/kubernetes.list
curl <span class="nt">-fsSL</span> https://download.docker.com/linux/ubuntu/gpg <span class="nt">-o</span> /etc/apt/keyrings/docker.asc
<span class="nb">echo</span> <span class="s2">"deb [arch=</span><span class="si">$(</span>dpkg <span class="nt">--print-architecture</span><span class="si">)</span><span class="s2"> signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu </span><span class="si">$(</span><span class="nb">.</span> /etc/os-release <span class="o">&amp;&amp;</span> <span class="nb">echo</span> <span class="s2">"</span><span class="nv">$VERSION_CODENAME</span><span class="s2">"</span><span class="si">)</span><span class="s2"> stable"</span> | <span class="nb">tee</span> /etc/apt/sources.list.d/docker.list <span class="o">&gt;</span> /dev/null
  
<span class="c"># packets traversing the bridge are processed by iptables for filtering</span>
<span class="nb">echo </span>1 <span class="o">&gt;</span> /proc/sys/net/ipv4/ip_forward
<span class="nb">echo</span> <span class="s2">"net.ipv4.ip_forward = 1"</span> <span class="o">&gt;&gt;</span> /etc/sysctl.d/k8s.conf
  
<span class="c"># enable br_netfilter for iptables </span>
modprobe br_netfilter
modprobe overlay
<span class="nb">echo</span> <span class="s2">"br_netfilter"</span> <span class="o">&gt;&gt;</span> /etc/modules-load.d/k8s.conf
<span class="nb">echo</span> <span class="s2">"overlay"</span> <span class="o">&gt;&gt;</span> /etc/modules-load.d/k8s.conf
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 5] Install Kubernetes components (kubeadm, kubelet and kubectl)"</span>
<span class="c"># Update the apt package index, install kubelet, kubeadm and kubectl, and pin their version</span>
apt update <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="c"># apt list -a kubelet ; apt list -a containerd.io</span>
apt-get <span class="nb">install</span> <span class="nt">-y</span> <span class="nv">kubelet</span><span class="o">=</span><span class="nv">$1</span> <span class="nv">kubectl</span><span class="o">=</span><span class="nv">$1</span> <span class="nv">kubeadm</span><span class="o">=</span><span class="nv">$1</span> containerd.io<span class="o">=</span><span class="nv">$2</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
apt-mark hold kubelet kubeadm kubectl <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="c"># containerd configure to default and cgroup managed by systemd</span>
containerd config default <span class="o">&gt;</span> /etc/containerd/config.toml
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'s/SystemdCgroup = false/SystemdCgroup = true/g'</span> /etc/containerd/config.toml
  
<span class="c"># avoid WARN&amp;ERRO(default endpoints) when crictl run  </span>
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; /etc/crictl.yaml
runtime-endpoint: unix:///run/containerd/containerd.sock
image-endpoint: unix:///run/containerd/containerd.sock
</span><span class="no">EOF
  
</span><span class="c"># ready to install for k8s </span>
systemctl restart containerd <span class="o">&amp;&amp;</span> systemctl <span class="nb">enable </span>containerd
systemctl <span class="nb">enable</span> <span class="nt">--now</span> kubelet
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 6] Install Packages &amp; Helm"</span>
<span class="nb">export </span><span class="nv">DEBIAN_FRONTEND</span><span class="o">=</span>noninteractive
apt-get <span class="nb">install</span> <span class="nt">-y</span> bridge-utils sshpass net-tools conntrack ngrep tcpdump ipset arping wireguard jq yq tree bash-completion unzip kubecolor termshark <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
curl <span class="nt">-s</span> https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>k8s-ctr.sh</strong> : kubeadm init를 통하여 kubernetes controlplane 노드를 설정하고 Cilium CNI 설치, 편리성 설정(k, kc)하는 스크립트입니다. local-path-storageclass와 metrics-server도 설치합니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Controlplane config Start &lt;&lt;&lt;&lt;"</span>
  
<span class="nb">echo</span> <span class="s2">"[TASK 1] Initial Kubernetes"</span>
curl <span class="nt">--silent</span> <span class="nt">-o</span> /root/kubeadm-init-ctr-config.yaml https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/kubeadm-init-ctr-config.yaml
<span class="nv">K8SMMV</span><span class="o">=</span><span class="si">$(</span><span class="nb">echo</span> <span class="nv">$3</span> | <span class="nb">sed</span> <span class="nt">-En</span> <span class="s1">'s/^([0-9]+\.[0-9]+\.[0-9]+).*/\1/p'</span><span class="si">)</span>
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/K8S_VERSION_PLACEHOLDER/v</span><span class="k">${</span><span class="nv">K8SMMV</span><span class="k">}</span><span class="s2">/g"</span> /root/kubeadm-init-ctr-config.yaml
kubeadm init <span class="nt">--config</span><span class="o">=</span><span class="s2">"/root/kubeadm-init-ctr-config.yaml"</span>  <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 2] Setting kube config file"</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> /root/.kube
<span class="nb">cp</span> <span class="nt">-i</span> /etc/kubernetes/admin.conf /root/.kube/config
<span class="nb">chown</span> <span class="si">$(</span><span class="nb">id</span> <span class="nt">-u</span><span class="si">)</span>:<span class="si">$(</span><span class="nb">id</span> <span class="nt">-g</span><span class="si">)</span> /root/.kube/config
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 3] Source the completion"</span>
<span class="nb">echo</span> <span class="s1">'source &lt;(kubectl completion bash)'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'source &lt;(kubeadm completion bash)'</span> <span class="o">&gt;&gt;</span> /etc/profile
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 4] Alias kubectl to k"</span>
<span class="nb">echo</span> <span class="s1">'alias k=kubectl'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'alias kc=kubecolor'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'complete -F __start_kubectl k'</span> <span class="o">&gt;&gt;</span> /etc/profile
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 5] Install Kubectx &amp; Kubens"</span>
git clone https://github.com/ahmetb/kubectx /opt/kubectx <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">ln</span> <span class="nt">-s</span> /opt/kubectx/kubens /usr/local/bin/kubens
<span class="nb">ln</span> <span class="nt">-s</span> /opt/kubectx/kubectx /usr/local/bin/kubectx
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 6] Install Kubeps &amp; Setting PS1"</span>
git clone https://github.com/jonmosco/kube-ps1.git /root/kube-ps1 <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="sh">"</span><span class="no">EOT</span><span class="sh">" &gt;&gt; /root/.bash_profile
source /root/kube-ps1/kube-ps1.sh
KUBE_PS1_SYMBOL_ENABLE=true
function get_cluster_short() {
  echo "</span><span class="nv">$1</span><span class="sh">" | cut -d . -f1
}
KUBE_PS1_CLUSTER_FUNCTION=get_cluster_short
KUBE_PS1_SUFFIX=') '
PS1='</span><span class="si">$(</span>kube_ps1<span class="si">)</span><span class="sh">'</span><span class="nv">$PS1</span><span class="sh">
</span><span class="no">EOT
</span>kubectl config rename-context <span class="s2">"kubernetes-admin@kubernetes"</span> <span class="s2">"HomeLab"</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 7] Install Cilium CNI"</span>
<span class="nv">NODEIP</span><span class="o">=</span><span class="si">$(</span>ip <span class="nt">-4</span> addr show eth1 | <span class="nb">grep</span> <span class="nt">-oP</span> <span class="s1">'(?&lt;=inet\s)\d+(\.\d+){3}'</span><span class="si">)</span>
helm repo add cilium https://helm.cilium.io/ <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
helm repo update <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
helm <span class="nb">install </span>cilium cilium/cilium <span class="nt">--version</span> <span class="nv">$2</span> <span class="nt">--namespace</span> kube-system <span class="se">\</span>
<span class="nt">--set</span> <span class="nv">k8sServiceHost</span><span class="o">=</span>192.168.10.100 <span class="nt">--set</span> <span class="nv">k8sServicePort</span><span class="o">=</span>6443 <span class="se">\</span>
<span class="nt">--set</span> ipam.mode<span class="o">=</span><span class="s2">"cluster-pool"</span> <span class="nt">--set</span> ipam.operator.clusterPoolIPv4PodCIDRList<span class="o">={</span><span class="s2">"172.20.0.0/16"</span><span class="o">}</span> <span class="nt">--set</span> <span class="nv">ipv4NativeRoutingCIDR</span><span class="o">=</span>172.20.0.0/16 <span class="se">\</span>
<span class="nt">--set</span> <span class="nv">routingMode</span><span class="o">=</span>native <span class="nt">--set</span> <span class="nv">autoDirectNodeRoutes</span><span class="o">=</span><span class="nb">false</span> <span class="nt">--set</span> bgpControlPlane.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> <span class="nv">kubeProxyReplacement</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> bpf.masquerade<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> <span class="nv">installNoConntrackIptablesRules</span><span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> endpointHealthChecking.enabled<span class="o">=</span><span class="nb">false</span> <span class="nt">--set</span> <span class="nv">healthChecking</span><span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
<span class="nt">--set</span> hubble.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> hubble.relay.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> hubble.ui.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> hubble.ui.service.type<span class="o">=</span>NodePort <span class="nt">--set</span> hubble.ui.service.nodePort<span class="o">=</span>30003 <span class="se">\</span>
<span class="nt">--set</span> prometheus.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> operator.prometheus.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> hubble.metrics.enableOpenMetrics<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> hubble.metrics.enabled<span class="o">=</span><span class="s2">"{dns,drop,tcp,flow,port-distribution,icmp,httpV2:exemplars=true;labelsContext=source_ip</span><span class="se">\,</span><span class="s2">source_namespace</span><span class="se">\,</span><span class="s2">source_workload</span><span class="se">\,</span><span class="s2">destination_ip</span><span class="se">\,</span><span class="s2">destination_namespace</span><span class="se">\,</span><span class="s2">destination_workload</span><span class="se">\,</span><span class="s2">traffic_direction}"</span> <span class="se">\</span>
<span class="nt">--set</span> operator.replicas<span class="o">=</span>1 <span class="nt">--set</span> debug.enabled<span class="o">=</span><span class="nb">true</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 8] Install Cilium / Hubble CLI"</span>
<span class="nv">CILIUM_CLI_VERSION</span><span class="o">=</span><span class="si">$(</span>curl <span class="nt">-s</span> https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt<span class="si">)</span>
<span class="nv">CLI_ARCH</span><span class="o">=</span>amd64
<span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span><span class="si">)</span><span class="s2">"</span> <span class="o">=</span> <span class="s2">"aarch64"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then </span><span class="nv">CLI_ARCH</span><span class="o">=</span>arm64<span class="p">;</span> <span class="k">fi
</span>curl <span class="nt">-L</span> <span class="nt">--fail</span> <span class="nt">--remote-name-all</span> https://github.com/cilium/cilium-cli/releases/download/<span class="k">${</span><span class="nv">CILIUM_CLI_VERSION</span><span class="k">}</span>/cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">tar </span>xzvfC cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz /usr/local/bin
<span class="nb">rm </span>cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz
  
<span class="nv">HUBBLE_VERSION</span><span class="o">=</span><span class="si">$(</span>curl <span class="nt">-s</span> https://raw.githubusercontent.com/cilium/hubble/master/stable.txt<span class="si">)</span>
<span class="nv">HUBBLE_ARCH</span><span class="o">=</span>amd64
<span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span><span class="si">)</span><span class="s2">"</span> <span class="o">=</span> <span class="s2">"aarch64"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then </span><span class="nv">HUBBLE_ARCH</span><span class="o">=</span>arm64<span class="p">;</span> <span class="k">fi
</span>curl <span class="nt">-L</span> <span class="nt">--fail</span> <span class="nt">--remote-name-all</span> https://github.com/cilium/hubble/releases/download/<span class="nv">$HUBBLE_VERSION</span>/hubble-linux-<span class="k">${</span><span class="nv">HUBBLE_ARCH</span><span class="k">}</span>.tar.gz <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">tar </span>xzvfC hubble-linux-<span class="k">${</span><span class="nv">HUBBLE_ARCH</span><span class="k">}</span>.tar.gz /usr/local/bin
<span class="nb">rm </span>hubble-linux-<span class="k">${</span><span class="nv">HUBBLE_ARCH</span><span class="k">}</span>.tar.gz
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 9] Remove node taint"</span>
kubectl taint nodes k8s-ctr node-role.kubernetes.io/control-plane-
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 10] local DNS with hosts file"</span>
<span class="nb">echo</span> <span class="s2">"192.168.10.100 k8s-ctr"</span> <span class="o">&gt;&gt;</span> /etc/hosts
<span class="nb">echo</span> <span class="s2">"192.168.10.200 router"</span> <span class="o">&gt;&gt;</span> /etc/hosts
<span class="nb">echo</span> <span class="s2">"192.168.20.100 k8s-w0"</span> <span class="o">&gt;&gt;</span> /etc/hosts
<span class="k">for</span> <span class="o">((</span> <span class="nv">i</span><span class="o">=</span>1<span class="p">;</span> i&lt;<span class="o">=</span><span class="nv">$1</span><span class="p">;</span> i++  <span class="o">))</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"192.168.10.10</span><span class="nv">$i</span><span class="s2"> k8s-w</span><span class="nv">$i</span><span class="s2">"</span> <span class="o">&gt;&gt;</span> /etc/hosts<span class="p">;</span> <span class="k">done
  
  
</span><span class="nb">echo</span> <span class="s2">"[TASK 11] Dynamically provisioning persistent local storage with Kubernetes"</span>
kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.31/deploy/local-path-storage.yaml <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
kubectl patch storageclass local-path <span class="nt">-p</span> <span class="s1">'{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="c"># echo "[TASK 12] Install Prometheus &amp; Grafana"</span>
<span class="c"># kubectl apply -f https://raw.githubusercontent.com/cilium/cilium/1.18.0/examples/kubernetes/addons/prometheus/monitoring-example.yaml &gt;/dev/null 2&gt;&amp;1</span>
<span class="c"># kubectl patch svc -n cilium-monitoring prometheus -p '{"spec": {"type": "NodePort", "ports": [{"port": 9090, "targetPort": 9090, "nodePort": 30001}]}}' &gt;/dev/null 2&gt;&amp;1</span>
<span class="c"># kubectl patch svc -n cilium-monitoring grafana -p '{"spec": {"type": "NodePort", "ports": [{"port": 3000, "targetPort": 3000, "nodePort": 30002}]}}' &gt;/dev/null 2&gt;&amp;1</span>
  
<span class="c"># echo "[TASK 12] Install Prometheus Stack"</span>
<span class="c"># helm repo add prometheus-community https://prometheus-community.github.io/helm-charts  &gt;/dev/null 2&gt;&amp;1</span>
<span class="c"># cat &lt;&lt;EOT &gt; monitor-values.yaml</span>
<span class="c"># prometheus:</span>
<span class="c">#   prometheusSpec:</span>
<span class="c">#     scrapeInterval: "15s"</span>
<span class="c">#     evaluationInterval: "15s"</span>
<span class="c">#   service:</span>
<span class="c">#     type: NodePort</span>
<span class="c">#     nodePort: 30001</span>
  
<span class="c"># grafana:</span>
<span class="c">#   defaultDashboardsTimezone: Asia/Seoul</span>
<span class="c">#   adminPassword: prom-operator</span>
<span class="c">#   service:</span>
<span class="c">#     type: NodePort</span>
<span class="c">#     nodePort: 30002</span>
  
<span class="c"># alertmanager:</span>
<span class="c">#   enabled: false</span>
<span class="c"># defaultRules:</span>
<span class="c">#   create: false</span>
<span class="c"># prometheus-windows-exporter:</span>
<span class="c">#   prometheus:</span>
<span class="c">#     monitor:</span>
<span class="c">#       enabled: false</span>
<span class="c"># EOT</span>
<span class="c"># helm install kube-prometheus-stack prometheus-community/kube-prometheus-stack --version 75.15.1 \</span>
<span class="c">#   -f monitor-values.yaml --create-namespace --namespace monitoring  &gt;/dev/null 2&gt;&amp;1</span>
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 13] Install Metrics-server"</span>
helm repo add metrics-server https://kubernetes-sigs.github.io/metrics-server/  <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
helm upgrade <span class="nt">--install</span> metrics-server metrics-server/metrics-server <span class="nt">--set</span> <span class="s1">'args[0]=--kubelet-insecure-tls'</span> <span class="nt">-n</span> kube-system  <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 14] Install k9s"</span>
<span class="nv">CLI_ARCH</span><span class="o">=</span>amd64
<span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span><span class="si">)</span><span class="s2">"</span> <span class="o">=</span> <span class="s2">"aarch64"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then </span><span class="nv">CLI_ARCH</span><span class="o">=</span>arm64<span class="p">;</span> <span class="k">fi
</span>wget https://github.com/derailed/k9s/releases/latest/download/k9s_linux_<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.deb <span class="nt">-O</span> /tmp/k9s_linux_<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.deb  <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
apt <span class="nb">install</span> /tmp/k9s_linux_<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.deb  <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Controlplane Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div>    </div>

    <ul>
      <li>
        <p><strong>kubeadm-init-ctr-config.yaml</strong></p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apiVersion: kubeadm.k8s.io/v1beta4
kind: InitConfiguration
bootstrapTokens:
- token: <span class="s2">"123456.1234567890123456"</span>
  ttl: <span class="s2">"0s"</span>
  usages:
  - signing
  - authentication
localAPIEndpoint:
  advertiseAddress: <span class="s2">"192.168.10.100"</span>
nodeRegistration:
  kubeletExtraArgs:
    - name: node-ip
      value: <span class="s2">"192.168.10.100"</span>
  criSocket: <span class="s2">"unix:///run/containerd/containerd.sock"</span>
<span class="nt">---</span>
apiVersion: kubeadm.k8s.io/v1beta4
kind: ClusterConfiguration
kubernetesVersion: <span class="s2">"K8S_VERSION_PLACEHOLDER"</span>
networking:
  podSubnet: <span class="s2">"10.244.0.0/16"</span>
  serviceSubnet: <span class="s2">"10.96.0.0/16"</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li><strong>k8s-w.sh</strong> : kubernetes worker 노드 설정, kubeadm join 등을 수행하는  스크립트입니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Node config Start &lt;&lt;&lt;&lt;"</span>
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 1] K8S Controlplane Join"</span>
curl <span class="nt">--silent</span> <span class="nt">-o</span> /root/kubeadm-join-worker-config.yaml https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/2w/kubeadm-join-worker-config.yaml
<span class="nv">NODEIP</span><span class="o">=</span><span class="si">$(</span>ip <span class="nt">-4</span> addr show eth1 | <span class="nb">grep</span> <span class="nt">-oP</span> <span class="s1">'(?&lt;=inet\s)\d+(\.\d+){3}'</span><span class="si">)</span>
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/NODE_IP_PLACEHOLDER/</span><span class="k">${</span><span class="nv">NODEIP</span><span class="k">}</span><span class="s2">/g"</span> /root/kubeadm-join-worker-config.yaml
kubeadm <span class="nb">join</span> <span class="nt">--config</span><span class="o">=</span><span class="s2">"/root/kubeadm-join-worker-config.yaml"</span> <span class="o">&gt;</span> /dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Node config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div>    </div>
    <ul>
      <li>
        <p><strong>kubeadm-join-worker-config.yaml</strong></p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apiVersion: kubeadm.k8s.io/v1beta4
kind: JoinConfiguration
discovery:
  bootstrapToken:
    token: <span class="s2">"123456.1234567890123456"</span>
    apiServerEndpoint: <span class="s2">"192.168.10.100:6443"</span>
    unsafeSkipCAVerification: <span class="nb">true
</span>nodeRegistration:
  criSocket: <span class="s2">"unix:///run/containerd/containerd.sock"</span>
  kubeletExtraArgs:
    - name: node-ip
      value: <span class="s2">"NODE_IP_PLACEHOLDER"</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>route-add1.sh</strong> : k8s node 들이 내부망과 통신을 위한 route 설정 스크립트입니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Route Add Config Start &lt;&lt;&lt;&lt;"</span>
  
<span class="nb">chmod </span>600 /etc/netplan/01-netcfg.yaml
<span class="nb">chmod </span>600 /etc/netplan/50-vagrant.yaml
  
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh">&gt;&gt; /etc/netplan/50-vagrant.yaml
      routes:
      - to: 192.168.20.0/24
        via: 192.168.10.200
      # - to: 172.20.0.0/16
      #   via: 192.168.10.200
</span><span class="no">EOT
  
</span>netplan apply
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Route Add Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>route-add2.sh</strong> : k8s node 들이 내부망과 통신을 위한 route 설정 스크립트입니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Route Add Config Start &lt;&lt;&lt;&lt;"</span>
  
<span class="nb">chmod </span>600 /etc/netplan/01-netcfg.yaml
<span class="nb">chmod </span>600 /etc/netplan/50-vagrant.yaml
  
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh">&gt;&gt; /etc/netplan/50-vagrant.yaml
      routes:
      - to: 192.168.10.0/24
        via: 192.168.20.200
      # - to: 172.20.0.0/16
      #   via: 192.168.20.200
</span><span class="no">EOT
  
</span>netplan apply
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Route Add Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>router.sh</strong> : router(<strong>frr - BGP</strong>) 역할, 간단 웹 서버 역할</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config Start &lt;&lt;&lt;&lt;"</span>
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 0] Setting eth2"</span>
<span class="nb">chmod </span>600 /etc/netplan/01-netcfg.yaml
<span class="nb">chmod </span>600 /etc/netplan/50-vagrant.yaml
  
<span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOT</span><span class="sh"> &gt;&gt; /etc/netplan/50-vagrant.yaml
    eth2:
      addresses:
      - 192.168.20.200/24
</span><span class="no">EOT
  
</span>netplan apply
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 1] Setting Profile &amp; Bashrc"</span>
<span class="nb">echo</span> <span class="s1">'alias vi=vim'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s2">"sudo su -"</span> <span class="o">&gt;&gt;</span> /home/vagrant/.bashrc
<span class="nb">ln</span> <span class="nt">-sf</span> /usr/share/zoneinfo/Asia/Seoul /etc/localtime
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 2] Disable AppArmor"</span>
systemctl stop ufw <span class="o">&amp;&amp;</span> systemctl disable ufw <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
systemctl stop apparmor <span class="o">&amp;&amp;</span> systemctl disable apparmor <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 3] Add Kernel setting - IP Forwarding"</span>
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'s/#net.ipv4.ip_forward=1/net.ipv4.ip_forward=1/g'</span> /etc/sysctl.conf
sysctl <span class="nt">-p</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 4] Setting Dummy Interface"</span>
modprobe dummy
ip <span class="nb">link </span>add loop1 <span class="nb">type </span>dummy
ip <span class="nb">link set </span>loop1 up
ip addr add 10.10.1.200/24 dev loop1
  
ip <span class="nb">link </span>add loop2 <span class="nb">type </span>dummy
ip <span class="nb">link set </span>loop2 up
ip addr add 10.10.2.200/24 dev loop2
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 5] Install Packages"</span>
<span class="nb">export </span><span class="nv">DEBIAN_FRONTEND</span><span class="o">=</span>noninteractive
apt update <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
apt-get <span class="nb">install </span>net-tools jq yq tree ngrep tcpdump arping termshark <span class="nt">-y</span> <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 6] Install Apache"</span>
apt <span class="nb">install </span>apache2 <span class="nt">-y</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"&lt;h1&gt;Web Server : </span><span class="si">$(</span><span class="nb">hostname</span><span class="si">)</span><span class="s2">&lt;/h1&gt;"</span> <span class="o">&gt;</span> /var/www/html/index.html
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 7] Configure FRR"</span>
apt <span class="nb">install </span>frr <span class="nt">-y</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/^bgpd=no/bgpd=yes/g"</span> /etc/frr/daemons
  
<span class="nv">NODEIP</span><span class="o">=</span><span class="si">$(</span>ip <span class="nt">-4</span> addr show eth1 | <span class="nb">grep</span> <span class="nt">-oP</span> <span class="s1">'(?&lt;=inet\s)\d+(\.\d+){3}'</span><span class="si">)</span>
<span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> &gt;&gt; /etc/frr/frr.conf
!
router bgp 65000
  bgp router-id </span><span class="nv">$NODEIP</span><span class="sh">
  bgp graceful-restart
  no bgp ebgp-requires-policy
  bgp bestpath as-path multipath-relax
  maximum-paths 4
  network 10.10.1.0/24
</span><span class="no">EOF
  
  
</span>systemctl daemon-reexec <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
systemctl restart frr <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
systemctl <span class="nb">enable </span>frr <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div>    </div>
  </li>
</ul>

<h3 id="실습환경-배포">실습환경 배포</h3>

<h5 id="실습환경-배포-1">실습환경 배포</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nv">$ </span>vagrant up
  <span class="c"># =&gt;     k8s-w0: &gt;&gt;&gt;&gt; Initial Config End &lt;&lt;&lt;&lt;</span>
  <span class="c">#    ==&gt; k8s-w0: Running provisioner: shell...</span>
  <span class="c">#        k8s-w0: Running: /var/folders/7k/qy6rsdds57z3tmyn9_7hhd8r0000gn/T/vagrant-shell20250815-16129-ssrxpm.sh</span>
  <span class="c">#        k8s-w0: &gt;&gt;&gt;&gt; K8S Node config Start &lt;&lt;&lt;&lt;</span>
  <span class="c">#        k8s-w0: [TASK 1] K8S Controlplane Join</span>
  <span class="c">#        k8s-w0: &gt;&gt;&gt;&gt; K8S Node config End &lt;&lt;&lt;&lt;</span>
  <span class="c">#    ==&gt; k8s-w0: Running provisioner: shell...</span>
  <span class="c">#        k8s-w0: Running: /var/folders/7k/qy6rsdds57z3tmyn9_7hhd8r0000gn/T/vagrant-shell20250815-16129-iotl22.sh</span>
  <span class="c">#        k8s-w0: &gt;&gt;&gt;&gt; Route Add Config Start &lt;&lt;&lt;&lt;</span>
  <span class="c">#        k8s-w0: &gt;&gt;&gt;&gt; Route Add Config End &lt;&lt;&lt;&lt;</span>
</code></pre></div></div>

<h5 id="기본정보-확인">기본정보 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># cilium 상태 확인 : bgp-control-plane 미리 활성화.</span>
<span class="nv">$ </span>kubectl get cm <span class="nt">-n</span> kube-system cilium-config <span class="nt">-o</span> json | jq
<span class="nv">$ </span>cilium status 
<span class="nv">$ </span>cilium config view | <span class="nb">grep</span> <span class="nt">-i</span> bgp
<span class="c"># =&gt; bgp-router-id-allocation-ip-pool</span>
<span class="c">#    bgp-router-id-allocation-mode                     default</span>
<span class="c">#    bgp-secrets-namespace                             kube-system</span>
<span class="c">#    enable-bgp-control-plane                          true</span>
<span class="c">#    enable-bgp-control-plane-status-report            true</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg status <span class="nt">--verbose</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg metrics list 

<span class="c"># monitor</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg monitor
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg monitor <span class="nt">-v</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg monitor <span class="nt">-v</span> <span class="nt">-v</span>
...
</code></pre></div></div>

<h5 id="네트워크-정보-확인--autodirectnoderoutesfalse">네트워크 정보 확인 : <code class="language-plaintext highlighter-rouge">autoDirectNodeRoutes=false</code></h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># router 네트워크 인터페이스 정보 확인</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router ip <span class="nt">-br</span> <span class="nt">-c</span> <span class="nt">-4</span> addr

<span class="c"># k8s node 네트워크 인터페이스 정보 확인</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> <span class="nt">-4</span> addr show dev eth1
<span class="c"># =&gt; 3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span>
<span class="c">#        altname enp0s9</span>
<span class="c">#        inet &lt;span style="color: green;"&gt;192.168.10.100/24&lt;/span&gt; brd 192.168.10.255 scope global eth1</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w0 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> <span class="nt">-4</span> addr show dev eth1<span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; 3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span>
<span class="c">#        altname enp0s9</span>
<span class="c">#        inet &lt;span style="color: green;"&gt;192.168.10.101/24&lt;/span&gt; brd 192.168.10.255 scope global eth1</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    &gt;&gt; node : k8s-w0 &lt;&lt;</span>
<span class="c">#    3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span>
<span class="c">#        altname enp0s9</span>
<span class="c">#        inet &lt;span style="color: green;"&gt;192.168.20.100/24&lt;/span&gt; brd 192.168.20.255 scope global eth1</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>

<span class="c"># 라우팅 정보 확인</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router ip <span class="nt">-c</span> route
<span class="c"># =&gt; ...</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.200</span>
<span class="c">#    192.168.20.0/24 dev eth2 proto kernel scope link src 192.168.20.200</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route | <span class="nb">grep </span>static
<span class="c"># =&gt; 192.168.20.0/24 via 192.168.10.200 dev eth1 proto static</span>

<span class="c">## 노드별 PodCIDR 라우팅이 없습니다!</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    172.20.0.0/24 via 172.20.0.222 dev cilium_host proto kernel src 172.20.0.222</span>
<span class="c">#    172.20.0.222 dev cilium_host proto kernel scope link</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.100</span>
<span class="c">#    192.168.20.0/24 via 192.168.10.200 dev eth1 proto static</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w0 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> route<span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    172.20.1.0/24 via 172.20.1.44 dev cilium_host proto kernel src 172.20.1.44</span>
<span class="c">#    172.20.1.44 dev cilium_host proto kernel scope link</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.101</span>
<span class="c">#    192.168.20.0/24 via 192.168.10.200 dev eth1 proto static</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w0 &lt;&lt;</span>
<span class="c">#    default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    172.20.2.0/24 via 172.20.2.246 dev cilium_host proto kernel src 172.20.2.246</span>
<span class="c">#    172.20.2.246 dev cilium_host proto kernel scope link</span>
<span class="c">#    192.168.10.0/24 via 192.168.20.200 dev eth1 proto static</span>
<span class="c">#    192.168.20.0/24 dev eth1 proto kernel scope link src 192.168.20.100</span>

<span class="c"># 통신 확인</span>
<span class="nv">$ </span>ping <span class="nt">-c</span> 1 192.168.20.100  <span class="c"># k8s-w0 eth1</span>
<span class="c"># =&gt; PING 192.168.20.100 (192.168.20.100) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 192.168.20.100: icmp_seq=1 ttl=63 time=2.46 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 192.168.20.100 ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 2.461/2.461/2.461/0.000 ms</span>
</code></pre></div></div>

<ul>
  <li>현재노드간 통신은 가능하지만 pod 간 통신은 불가능합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">autoDirectNodeRoutes=false</code>을 통해 자동으로 같은 L2 네트워크에 있는 노드들간의 PodCIDR 라우팅하는 기능이 꺼져있어서 라우팅 룰이 없기때문입니다.</li>
</ul>

<h3 id="샘플-애플리케이션-배포-및-통신-문제-확인">샘플 애플리케이션 배포 및 통신 문제 확인</h3>

<ul>
  <li>샘플 애플리케이션 배포</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 샘플 애플리케이션 배포</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webpod
spec:
  replicas: 3
  selector:
    matchLabels:
      app: webpod
  template:
    metadata:
      labels:
        app: webpod
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - sample-app
            topologyKey: "kubernetes.io/hostname"
      containers:
      - name: webpod
        image: traefik/whoami
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: webpod
  labels:
    app: webpod
spec:
  selector:
    app: webpod
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
  type: ClusterIP
</span><span class="no">EOF
</span><span class="c"># =&gt; deployment.apps/webpod created</span>
<span class="c">#    service/webpod created</span>

<span class="c"># k8s-ctr 노드에 curl-pod 파드 배포</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: curl-pod
  labels:
    app: curl
spec:
  nodeName: k8s-ctr
  containers:
  - name: curl
    image: nicolaka/netshoot
    command: ["tail"]
    args: ["-f", "/dev/null"]
  terminationGracePeriodSeconds: 0
</span><span class="no">EOF
</span><span class="c"># =&gt; pod/curl-pod created</span>
</code></pre></div></div>

<ul>
  <li>통신 문제 확인 : 노드 내의 파드간에만 통신이 되는 중입니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 배포 확인</span>
<span class="nv">$ </span>kubectl get deploy,svc,ep webpod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                     READY   UP-TO-DATE   AVAILABLE   AGE    CONTAINERS   IMAGES           SELECTOR</span>
<span class="c">#    deployment.apps/webpod   3/3     3            3           102s   webpod       traefik/whoami   app=webpod</span>
<span class="c">#    </span>
<span class="c">#    NAME             TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE    SELECTOR</span>
<span class="c">#    service/webpod   ClusterIP   10.96.28.4   &lt;none&gt;        80/TCP    102s   app=webpod</span>
<span class="c">#    </span>
<span class="c">#    NAME               ENDPOINTS                                      AGE</span>
<span class="c">#    endpoints/webpod   172.20.0.72:80,172.20.1.7:80,172.20.2.190:80   102s</span>
<span class="nv">$ </span>kubectl get endpointslices <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>webpod
<span class="c"># =&gt; NAME           ADDRESSTYPE   PORTS   ENDPOINTS                             AGE</span>
<span class="c">#    webpod-4pxps   IPv4          80      172.20.0.72,172.20.1.7,172.20.2.190   2m23s</span>
<span class="nv">$ </span>kubectl get ciliumendpoints <span class="c"># IP 확인</span>
<span class="c"># =&gt; NAME                      SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    curl-pod                  47416               ready            172.20.0.187</span>
<span class="c">#    &lt;span style="color: green;"&gt;webpod-697b545f57-j6b7t&lt;/span&gt;   9975                ready            &lt;span style="color: green;"&gt;172.20.0.72&lt;/span&gt;</span>
<span class="c">#    webpod-697b545f57-n7fk7   9975                ready            172.20.2.190</span>
<span class="c">#    webpod-697b545f57-rl4d2   9975                ready            172.20.1.7</span>

<span class="c"># 통신 문제 확인 : 노드 내의 파드들 끼리만 통신되는 중!</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 webpod | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod-697b545f57-j6b7t</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s-ctr에서 실행중이어서 같은 k8s-ctr에 있는 파드와는 통신이 됩니다.&lt;/span&gt;</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 webpod | <span class="nb">grep </span>Hostname
<span class="c"># &lt;span style="color: green;"&gt;👉 다시 실행했을때는 Kubernetes Service에 의해 다른 노드의 파드로 로드밸런싱되어 통신이 실패합니다.&lt;/span&gt;</span>
<span class="c"># =&gt; command terminated with exit code 28</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s --connect-timeout 1 webpod | grep Hostname; echo "---" ; sleep 1; done'</span>
<span class="c"># =&gt; Hostname: webpod-697b545f57-j6b7t</span>
<span class="c">#    ---</span>
<span class="c">#    ---</span>
<span class="c">#    Hostname: webpod-697b545f57-j6b7t</span>
<span class="c">#    ---</span>
<span class="c">#    ---</span>
<span class="c">#    Hostname: webpod-697b545f57-j6b7t</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 여러번 실행해도 k8s-ctr 노드에 있는 파드만 통신이 되는것을 확인할 수 있습니다.&lt;/span&gt;</span>

<span class="c"># cilium-dbg, map</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg ip list
<span class="c"># =&gt; IP                  IDENTITY                                                                            SOURCE</span>
<span class="c">#    ...</span>
<span class="c">#    &lt;span style="color: green;"&gt;172.20.1.7/32&lt;/span&gt;       k8s:app=webpod                                                                      custom-resource</span>
<span class="c">#    ...</span>
<span class="c">#    &lt;span style="color: green;"&gt;172.20.2.190/32&lt;/span&gt;     k8s:app=webpod                                                                      custom-resource</span>
<span class="c">#    ...</span>
<span class="c">#    192.168.10.101/32   reserved:remote-node</span>
<span class="c">#    192.168.20.100/32   reserved:remote-node</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 cilium도 다른 노드의 파드 IP를 알고 있지만, 라우팅이 되지 않아서 통신이 되지 않습니다.&lt;/span&gt;</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg endpoint list
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg service list
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg bpf lb list
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg bpf nat list
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg map list | <span class="nb">grep</span> <span class="nt">-v</span> <span class="s1">'0             0'</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg map get cilium_lb4_services_v2
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg map get cilium_lb4_backends_v3
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg map get cilium_lb4_reverse_nat
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg map get cilium_ipcache_v2
</code></pre></div></div>

<hr />

<h2 id="cilium-bgp-control-plane">Cilium BGP Control Plane</h2>

<ul>
  <li>Cilium BGP Control Plane (BGPv2) : Cilium Custom Resources 를 통해 BGP 설정이 관리 가능합니다. - <a href="https://docs.cilium.io/en/stable/network/bgp-control-plane/bgp-control-plane-v2/">Docs</a>, <a href="https://github.com/cilium/cilium/tree/main/operator/pkg/bgpv2">Code</a>
<img src="/assets/2025/cilium/w5/20250817_cilium_w5_2.png" alt="img.png" class="image-center image-bg" />
<em class="image-caption"><a href="https://docs.cilium.io/en/stable/network/bgp-control-plane/bgp-control-plane-v2/">https://docs.cilium.io/en/stable/network/bgp-control-plane/bgp-control-plane-v2/</a></em>
    <ul>
      <li><code class="language-plaintext highlighter-rouge">CiliumBGPClusterConfig</code>: BGP 인스턴스와 여러 노드에 적용되는 피어 구성을 정의합니다.</li>
      <li><code class="language-plaintext highlighter-rouge">CiliumBGPPeerConfig</code>: 공통 BGP 피어링 설정을 정의합니다. 여러 피어에서 사용할 수 있습니다.</li>
      <li><code class="language-plaintext highlighter-rouge">CiliumBGPAdvertisement</code>: BGP 라우팅 테이블에 삽입되는 접두사를 정의합니다.</li>
      <li><code class="language-plaintext highlighter-rouge">CiliumBGPNodeConfigOverride</code>: 세밀한 제어를 제공하기 위해 특정 노드에 대한 BGP 설정 오버라이드을 정의합니다.</li>
    </ul>
  </li>
</ul>

<h4 id="bgp설정-후-통신-확인">BGP 설정 후 통신 확인</h4>

<blockquote>
  <p>Cilium의 BGP는 기본적으로 외부 경로를 커널 라우팅 테이블에 주입하지 않습니다.</p>
</blockquote>

<ul>
  <li>[router] router 접속 후 설정 : <code class="language-plaintext highlighter-rouge">sshpass -p 'vagrant' ssh vagrant@router</code></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># k8s-ctr 에서 router 로 ssh 접속</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router

<span class="c"># BGP 관련 프로세스를 확인합니다.</span>
<span class="nv">$ </span>ss <span class="nt">-tnlp</span> | <span class="nb">grep</span> <span class="nt">-iE</span> <span class="s1">'zebra|bgpd'</span>
<span class="c"># =&gt; LISTEN 0      3          127.0.0.1:2601      0.0.0.0:*    users:(("zebra",pid=4144,fd=23))</span>
<span class="c">#    LISTEN 0      3          127.0.0.1:2605      0.0.0.0:*    users:(("bgpd",pid=4149,fd=18))</span>
<span class="c">#    LISTEN 0      4096         0.0.0.0:179       0.0.0.0:*    users:(("bgpd",pid=4149,fd=22))</span>
<span class="c">#    LISTEN 0      4096            [::]:179          [::]:*    users:(("bgpd",pid=4149,fd=23))</span>
<span class="nv">$ </span>ps <span class="nt">-ef</span> |grep frr
<span class="c"># =&gt; root        4131       1  0 16:49 ?        00:00:03 /usr/lib/frr/watchfrr -d -F traditional zebra bgpd staticd</span>
<span class="c">#    frr         4144       1  0 16:49 ?        00:00:01 /usr/lib/frr/zebra -d -F traditional -A 127.0.0.1 -s 90000000</span>
<span class="c">#    frr         4149       1  0 16:49 ?        00:00:00 /usr/lib/frr/bgpd -d -F traditional -A 127.0.0.1</span>
<span class="c">#    frr         4156       1  0 16:49 ?        00:00:00 /usr/lib/frr/staticd -d -F traditional -A 127.0.0.1</span>

<span class="c"># frr 설정을 확인합니다.</span>
<span class="nv">$ </span>vtysh <span class="nt">-c</span> <span class="s1">'show running'</span>   <span class="c"># 명령을 통해 현재 설정을 확인할 수 있습니다.</span>
<span class="c"># =&gt; uilding configuration...</span>
<span class="c">#    </span>
<span class="c">#    Current configuration:</span>
<span class="c">#    !</span>
<span class="c">#    frr version 8.4.4</span>
<span class="c">#    frr defaults traditional</span>
<span class="c">#    hostname router</span>
<span class="c">#    log syslog informational</span>
<span class="c">#    no ipv6 forwarding</span>
<span class="c">#    service integrated-vtysh-config</span>
<span class="c">#    !</span>
<span class="c">#    router bgp 65000</span>
<span class="c">#     bgp router-id 192.168.10.200</span>
<span class="c">#     no bgp ebgp-requires-policy</span>
<span class="c">#     bgp graceful-restart</span>
<span class="c">#     bgp bestpath as-path multipath-relax</span>
<span class="c">#     !</span>
<span class="c">#     address-family ipv4 unicast</span>
<span class="c">#      network 10.10.1.0/24</span>
<span class="c">#      maximum-paths 4</span>
<span class="c">#     exit-address-family</span>
<span class="c">#    exit</span>
<span class="c">#    !</span>
<span class="c">#    end</span>
<span class="nv">$ </span><span class="nb">cat</span> /etc/frr/frr.conf
<span class="c"># =&gt; ... </span>
<span class="c">#    log syslog informational</span>
<span class="c">#    !</span>
<span class="c">#    router bgp 65000</span>
<span class="c">#      bgp router-id 192.168.10.200</span>
<span class="c">#      bgp graceful-restart</span>
<span class="c">#      no bgp ebgp-requires-policy</span>
<span class="c">#      bgp bestpath as-path multipath-relax</span>
<span class="c">#      maximum-paths 4</span>
<span class="c">#      network 10.10.1.0/24</span>

<span class="c">#</span>
<span class="nv">$ </span>vtysh <span class="nt">-c</span> <span class="s1">'show running'</span>
<span class="nv">$ </span>vtysh <span class="nt">-c</span> <span class="s1">'show ip bgp summary'</span>
<span class="c"># =&gt; % No BGP neighbors found in VRF default</span>
<span class="nv">$ </span>vtysh <span class="nt">-c</span> <span class="s1">'show ip bgp'</span>
<span class="c"># =&gt; BGP table version is 1, local router ID is 192.168.10.200, vrf id 0</span>
<span class="c">#    Default local pref 100, local AS 65000</span>
<span class="c">#    Status codes:  s suppressed, d damped, h history, * valid, &gt; best, = multipath,</span>
<span class="c">#                   i internal, r RIB-failure, S Stale, R Removed</span>
<span class="c">#    Nexthop codes: @NNN nexthop's vrf id, &lt; announce-nh-self</span>
<span class="c">#    Origin codes:  i - IGP, e - EGP, ? - incomplete</span>
<span class="c">#    RPKI validation codes: V valid, I invalid, N Not found</span>
<span class="c">#    </span>
<span class="c">#       Network          Next Hop            Metric LocPrf Weight Path</span>
<span class="c">#    *&gt; 10.10.1.0/24     0.0.0.0                  0         32768 i</span>

<span class="nv">$ </span>ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.10.1.0/24 dev loop1 proto kernel scope link src 10.10.1.200</span>
<span class="c">#    10.10.2.0/24 dev loop2 proto kernel scope link src 10.10.2.200</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.200</span>
<span class="c">#    192.168.20.0/24 dev eth2 proto kernel scope link src 192.168.20.200</span>
<span class="nv">$ </span>vtysh <span class="nt">-c</span> <span class="s1">'show ip route'</span>
...
K&gt;<span class="k">*</span> 0.0.0.0/0 <span class="o">[</span>0/100] via 10.0.2.2, eth0, src 10.0.2.15, 00:34:45
...
C&gt;<span class="k">*</span> 192.168.10.0/24 is directly connected, eth1, 00:34:45
C&gt;<span class="k">*</span> 192.168.20.0/24 is directly connected, eth2, 00:34:45
<span class="c"># =&gt; ...    </span>
<span class="c">#    K&gt;* 0.0.0.0/0 [0/100] via 10.0.2.2, eth0, src 10.0.2.15, 06:52:38</span>
<span class="c">#    ...</span>
<span class="c">#    C&gt;* 192.168.10.0/24 is directly connected, eth1, 06:52:38</span>
<span class="c">#    C&gt;* 192.168.20.0/24 is directly connected, eth2, 06:52:38</span>

<span class="c"># Cilium node 연동 설정 방안 1</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 설정 파일을 직접 수정하는 방법입니다.&lt;/span&gt;</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> &gt;&gt; /etc/frr/frr.conf
  neighbor CILIUM peer-group
  neighbor CILIUM remote-as external
  neighbor 192.168.10.100 peer-group CILIUM
  neighbor 192.168.10.101 peer-group CILIUM
  neighbor 192.168.20.100 peer-group CILIUM 
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> /etc/frr/frr.conf
<span class="c"># =&gt; log syslog informational</span>
<span class="c">#    !</span>
<span class="c">#    router bgp 65000</span>
<span class="c">#      bgp router-id 192.168.10.200</span>
<span class="c">#      bgp graceful-restart</span>
<span class="c">#      no bgp ebgp-requires-policy</span>
<span class="c">#      bgp bestpath as-path multipath-relax</span>
<span class="c">#      maximum-paths 4</span>
<span class="c">#      network 10.10.1.0/24</span>
<span class="c">#      neighbor CILIUM peer-group</span>
<span class="c">#      neighbor CILIUM remote-as external</span>
<span class="c">#      neighbor 192.168.10.100 peer-group CILIUM</span>
<span class="c">#      neighbor 192.168.10.101 peer-group CILIUM</span>
<span class="c">#      neighbor 192.168.20.100 peer-group CILIUM</span>

<span class="nv">$ </span>systemctl daemon-reexec <span class="o">&amp;&amp;</span> systemctl restart frr
<span class="nv">$ </span>systemctl status frr <span class="nt">--no-pager</span> <span class="nt">--full</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    Aug 15 23:43:00 router zebra[5215]: [VTVCM-Y2NW3] Configuration Read in Took: 00:00:00</span>
<span class="c">#    Aug 15 23:43:00 router staticd[5227]: [VTVCM-Y2NW3] Configuration Read in Took: 00:00:00</span>
<span class="c">#    Aug 15 23:43:00 router bgpd[5220]: [VTVCM-Y2NW3] Configuration Read in Took: 00:00:00</span>
<span class="c">#    Aug 15 23:43:00 router watchfrr[5201]: [QDG3Y-BY5TN] zebra state -&gt; up : connect succeeded</span>
<span class="c">#    Aug 15 23:43:00 router watchfrr[5201]: [QDG3Y-BY5TN] bgpd state -&gt; up : connect succeeded</span>
<span class="c">#    Aug 15 23:43:00 router watchfrr[5201]: [QDG3Y-BY5TN] staticd state -&gt; up : connect succeeded</span>
<span class="c">#    Aug 15 23:43:00 router watchfrr[5201]: [KWE5Q-QNGFC] all daemons up, doing startup-complete notify</span>
<span class="c">#    Aug 15 23:43:00 router frrinit.sh[5190]:  * Started watchfrr</span>
<span class="c">#    Aug 15 23:43:00 router systemd[1]: Started frr.service - FRRouting.</span>

<span class="c"># 모니터링 걸어두기!</span>
<span class="nv">$ </span>journalctl <span class="nt">-u</span> frr <span class="nt">-f</span>

<span class="c"># Cilium node 연동 설정 방안 2</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 frr에서 제공하는 vtysh 명령어를 통해 설정하는 방법입니다.&lt;/span&gt;</span>
<span class="nv">$ </span>vtysh
<span class="nt">---------------------------</span>
?
show ?
show running
show ip route

<span class="c"># config 모드 진입</span>
conf
?

<span class="c">## bgp 65000 설정 진입</span>
router bgp 65000
?
neighbor CILIUM peer-group
neighbor CILIUM remote-as external
neighbor 192.168.10.100 peer-group CILIUM
neighbor 192.168.10.101 peer-group CILIUM
neighbor 192.168.20.100 peer-group CILIUM 
end

<span class="c"># Write configuration to the file (same as write file)</span>
write memory
<span class="c"># &lt;span style="color: green;"&gt;👉 실제로 frr.conf 파일에 설정이 추가됩니다.&lt;/span&gt;</span>

<span class="nb">exit</span>
<span class="nt">---------------------------</span>

<span class="nv">$ </span><span class="nb">cat</span> /etc/frr/frr.conf
</code></pre></div></div>

<ul>
  <li>cilium에 bgp 설정</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 신규 터미널 1 (router) : 모니터링 걸어두기!</span>
<span class="nv">$ </span>journalctl <span class="nt">-u</span> frr <span class="nt">-f</span>

<span class="c"># 신규 터미널 2 (k8s-ctr) : 반복 호출</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s --connect-timeout 1 webpod | grep Hostname; echo "---" ; sleep 1; done'</span>


<span class="c"># BGP 동작할 노드를 위한 label 설정</span>
<span class="nv">$ </span>kubectl label nodes k8s-ctr k8s-w0 k8s-w1 enable-bgp<span class="o">=</span><span class="nb">true</span>
<span class="c"># =&gt; node/k8s-w0 labeled</span>
<span class="c">#    node/k8s-w1 labeled</span>
<span class="nv">$ </span>kubectl get node <span class="nt">-l</span> enable-bgp<span class="o">=</span><span class="nb">true</span>
<span class="c"># =&gt; NAME      STATUS   ROLES           AGE     VERSION</span>
<span class="c">#    k8s-ctr   Ready    control-plane   7h35m   v1.33.2</span>
<span class="c">#    k8s-w0    Ready    &lt;none&gt;          7h30m   v1.33.2</span>
<span class="c">#    k8s-w1    Ready    &lt;none&gt;          7h33m   v1.33.2</span>

<span class="c"># Config Cilium BGP</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: cilium.io/v2
kind: CiliumBGPAdvertisement
metadata:
  name: bgp-advertisements
  labels:
    advertise: bgp
spec:
  advertisements:
    - advertisementType: "PodCIDR"
---
apiVersion: cilium.io/v2
kind: CiliumBGPPeerConfig
metadata:
  name: cilium-peer
spec:
  timers:
    holdTimeSeconds: 9
    keepAliveTimeSeconds: 3
  ebgpMultihop: 2
  gracefulRestart:
    enabled: true
    restartTimeSeconds: 15
  families:
    - afi: ipv4
      safi: unicast
      advertisements:
        matchLabels:
          advertise: "bgp"
---
apiVersion: cilium.io/v2
kind: CiliumBGPClusterConfig
metadata:
  name: cilium-bgp
spec:
  nodeSelector:
    matchLabels:
      "enable-bgp": "true"
  bgpInstances:
  - name: "instance-65001"
    localASN: 65001
    peers:
    - name: "tor-switch"
      peerASN: 65000
      peerAddress: 192.168.10.200  # router ip address
      peerConfigRef:
        name: "cilium-peer"
</span><span class="no">EOF
</span><span class="c"># =&gt; ciliumbgpadvertisement.cilium.io/bgp-advertisements created</span>
<span class="c">#    ciliumbgppeerconfig.cilium.io/cilium-peer created</span>
<span class="c">#    ciliumbgpclusterconfig.cilium.io/cilium-bgp created</span>
</code></pre></div></div>

<ul>
  <li>통신확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># [k8s-ctr]에서 확인</span>

<span class="c"># BGP 연결 확인</span>
<span class="nv">$ </span>ss <span class="nt">-tnlp</span> | <span class="nb">grep </span>179
<span class="c"># =&gt; (없음)</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s-ctr 노드에는 BGP 데몬이 실행되고 있지 않습니다.&lt;/span&gt;</span>
<span class="nv">$ </span>ss <span class="nt">-tnp</span> | <span class="nb">grep </span>179
<span class="c"># =&gt; ESTAB 0      0               192.168.10.100:46459          192.168.10.200:179   users:(("cilium-agent",pid=5674,fd=193))</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 cilium-agent가 BGP 연결을 위해 router와 연결되어 있습니다.&lt;/span&gt;</span>

<span class="c"># cilium bgp 정보 확인</span>
<span class="nv">$ </span>cilium bgp peers
<span class="c"># =&gt; Node      Local AS   Peer AS   Peer Address     Session State   Uptime   Family         Received   Advertised</span>
<span class="c">#    k8s-ctr   65001      65000     192.168.10.200   established     2m20s    ipv4/unicast   4          2</span>
<span class="c">#    k8s-w0    65001      65000     192.168.10.200   established     2m20s    ipv4/unicast   4          2</span>
<span class="c">#    k8s-w1    65001      65000     192.168.10.200   established     2m19s    ipv4/unicast   4          2</span>
<span class="nv">$ </span>cilium bgp routes available ipv4 unicast
<span class="c"># =&gt; Node      VRouter   Prefix          NextHop   Age     Attrs</span>
<span class="c">#    k8s-ctr   65001     172.20.0.0/24   0.0.0.0   2m30s   [{Origin: i} {Nexthop: 0.0.0.0}]</span>
<span class="c">#    k8s-w0    65001     172.20.2.0/24   0.0.0.0   2m30s   [{Origin: i} {Nexthop: 0.0.0.0}]</span>
<span class="c">#    k8s-w1    65001     172.20.1.0/24   0.0.0.0   2m30s   [{Origin: i} {Nexthop: 0.0.0.0}]</span>

<span class="nv">$ </span>kubectl get ciliumbgpadvertisements,ciliumbgppeerconfigs,ciliumbgpclusterconfigs
<span class="c"># =&gt; NAME                                                  AGE</span>
<span class="c">#    ciliumbgpadvertisement.cilium.io/bgp-advertisements   2m40s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                        AGE</span>
<span class="c">#    ciliumbgppeerconfig.cilium.io/cilium-peer   2m40s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                          AGE</span>
<span class="c">#    ciliumbgpclusterconfig.cilium.io/cilium-bgp   2m40s</span>
<span class="nv">$ </span>kubectl get ciliumbgpnodeconfigs <span class="nt">-o</span> yaml | yq
<span class="c"># =&gt; ...</span>
<span class="c">#                    "peeringState": "established",</span>
<span class="c">#                    "routeCount": [</span>
<span class="c">#                      {</span>
<span class="c">#                        "advertised": 2,</span>
<span class="c">#                        "afi": "ipv4",</span>
<span class="c">#                        "received": 1,</span>
<span class="c">#                        "safi": "unicast"</span>
<span class="c">#                      }</span>
<span class="c">#                    ],</span>
<span class="c">#    ...</span>

<span class="c"># 신규 터미널 1 (router) : 모니터링 걸어두기!</span>
<span class="nv">$ </span>journalctl <span class="nt">-u</span> frr <span class="nt">-f</span>
<span class="c"># =&gt; Aug 16 00:21:44 router bgpd[5422]: [M59KS-A3ZXZ] bgp_update_receive: rcvd End-of-RIB for IPv4 Unicast from 192.168.10.101 in vrf default</span>
<span class="c">#    Aug 16 00:21:44 router bgpd[5422]: [M59KS-A3ZXZ] bgp_update_receive: rcvd End-of-RIB for IPv4 Unicast from 192.168.20.100 in vrf default</span>
<span class="c">#    Aug 16 00:21:44 router bgpd[5422]: [M59KS-A3ZXZ] bgp_update_receive: rcvd End-of-RIB for IPv4 Unicast from 192.168.10.100 in vrf default</span>

<span class="nv">$ </span>ip <span class="nt">-c</span> route | <span class="nb">grep </span>bgp
<span class="c"># =&gt; 172.20.0.0/24 nhid 32 via 192.168.10.100 dev eth1 proto bgp metric 20</span>
<span class="c">#    172.20.1.0/24 nhid 30 via 192.168.10.101 dev eth1 proto bgp metric 20</span>
<span class="c">#    172.20.2.0/24 nhid 31 via 192.168.20.100 dev eth2 proto bgp metric 20</span>

<span class="nv">$ </span>vtysh <span class="nt">-c</span> <span class="s1">'show ip bgp summary'</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    Neighbor        V         AS   MsgRcvd   MsgSent   TblVer  InQ OutQ  Up/Down State/PfxRcd   PfxSnt Desc</span>
<span class="c">#    192.168.10.100  4      65001        88        91        0    0    0 00:04:12            1        4 N/A</span>
<span class="c">#    192.168.10.101  4      65001        88        91        0    0    0 00:04:12            1        4 N/A</span>
<span class="c">#    192.168.20.100  4      65001        88        91        0    0    0 00:04:12            1        4 N/A</span>

<span class="nv">$ </span>vtysh <span class="nt">-c</span> <span class="s1">'show ip bgp'</span>
<span class="c"># =&gt; ...</span>
<span class="c">#       Network          Next Hop            Metric LocPrf Weight Path</span>
<span class="c">#    *&gt; 10.10.1.0/24     0.0.0.0                  0         32768 i</span>
<span class="c">#    *&gt; 172.20.0.0/24    192.168.10.100                         0 65001 i</span>
<span class="c">#    *&gt; 172.20.1.0/24    192.168.10.101                         0 65001 i</span>
<span class="c">#    *&gt; 172.20.2.0/24    192.168.20.100                         0 65001 i</span>

<span class="c"># 신규 터미널 2 (k8s-ctr) : 반복 호출???</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s --connect-timeout 1 webpod | grep Hostname; echo "---" ; sleep 1; done'</span>
<span class="c"># =&gt; Hostname: webpod-697b545f57-j6b7t</span>
<span class="c">#    ---</span>
<span class="c">#    ---</span>
<span class="c">#    ---</span>
<span class="c">#    Hostname: webpod-697b545f57-j6b7t</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 여전히 k8s-ctr 노드에 있는 파드만 통신이 되고, 다른 노드의 파드와는 통신이 안 됩니다.&lt;/span&gt;</span>
</code></pre></div></div>

<ul>
  <li>BGP 정보 전달 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># k8s-ctr tcpdump 해두기</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> eth1 tcp port 179 <span class="nt">-w</span> /tmp/bgp.pcap

<span class="c"># router : frr 재시작</span>
<span class="nv">$ </span>systemctl restart frr <span class="o">&amp;&amp;</span> journalctl <span class="nt">-u</span> frr <span class="nt">-f</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    Aug 16 00:28:35 router watchfrr[5625]: [KWE5Q-QNGFC] all daemons up, doing startup-complete notify</span>
<span class="c">#    Aug 16 00:28:41 router bgpd[5643]: [M59KS-A3ZXZ] bgp_update_receive: rcvd End-of-RIB for IPv4 Unicast from 192.168.20.100 in vrf default</span>
<span class="c">#    Aug 16 00:28:41 router bgpd[5643]: [M59KS-A3ZXZ] bgp_update_receive: rcvd End-of-RIB for IPv4 Unicast from 192.168.10.100 in vrf default</span>
<span class="c">#    Aug 16 00:28:41 router bgpd[5643]: [M59KS-A3ZXZ] bgp_update_receive: rcvd End-of-RIB for IPv4 Unicast from 192.168.10.101 in vrf default</span>

<span class="c"># termshark 실행후 filter에 `bgp.type == 2` 입력해서 bgp update 패킷을 확인합니다.</span>
<span class="nv">$ </span>termshark <span class="nt">-r</span> /tmp/bgp.pcap
 
<span class="c"># 분명 Router 장비를 통해 BGP UPDATE로 받음을 확인.</span>
<span class="nv">$ </span>cilium bgp routes
<span class="c"># =&gt; Node      VRouter   Prefix          NextHop   Age      Attrs</span>
<span class="c">#    k8s-ctr   65001     172.20.0.0/24   0.0.0.0   15m44s   [{Origin: i} {Nexthop: 0.0.0.0}]</span>
<span class="c">#    k8s-w0    65001     172.20.2.0/24   0.0.0.0   15m44s   [{Origin: i} {Nexthop: 0.0.0.0}]</span>
<span class="c">#    k8s-w1    65001     172.20.1.0/24   0.0.0.0   15m44s   [{Origin: i} {Nexthop: 0.0.0.0}]</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 cilium 라우팅 정보에는 BGP UPDATE로 받은 정보가 있습니다.&lt;/span&gt;</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    172.20.0.0/24 via 172.20.0.222 dev cilium_host proto kernel src 172.20.0.222</span>
<span class="c">#    172.20.0.222 dev cilium_host proto kernel scope link</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.100</span>
<span class="c">#    192.168.20.0/24 via 192.168.10.200 dev eth1 proto static</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s-ctr 노드의 커널 라우팅 테이블에는 추가되지 않았습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w5/20250817_cilium_w5_3.png" alt="img.png" class="image-center image-bg" />
<em class="image-caption">termshark에서 BGP UPDATE 패킷 확인</em></p>

<ul>
  <li>cilium에 BGP 설정이되어 이제 라우팅이 가능해질것 같습니다.</li>
  <li>하지만 커널 라우팅 테이블에는 추가되지 않았습니다. 그 이유는 다음과 같습니다.
    <ul>
      <li>Cilium BGP는 eBPF를 통해 라우팅하기 때문에 커널 라우팅 테이블에 추가할 필요가 없습니다.</li>
      <li>Cilium BGP Speaker가 기반하는 GoBGP 라이브러리는 <code class="language-plaintext highlighter-rouge">disable-fib</code> 상태로 빌드되어 Linux 커널(FIB)에 주입되도록 설정 되어있습니다.</li>
    </ul>
  </li>
</ul>

<h3 id="문제-해결-후-통신">문제 해결 후 통신</h3>

<ul>
  <li>현재 실습 환경은 2개의 NIC(eth0, eth1)을 사용하고 있는 상황으로, default GW가 eth0 경로로 설정 되어 있습니다.</li>
  <li>eth1은 k8s 통신 용도로 사용 중이며, 현재 k8s 파드 사용 대역 통신 전체는 eth1을 통해서 라우팅 설정해야 합니다.</li>
  <li>해당 라우팅을 상단에 네트워크 장비가 받게 되고, 해당 장비는 Cilium Node를 통해 모든 PodCIDR 정보를 알고 있기에, 목적지로 전달 가능합니다.</li>
  <li>결론은 Cilium 으로 BGP 사용 시, 2개 이상의 NIC 사용할 경우에는 Node에 직접 라우팅 설정 및 관리가 필요합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># k8s 파드 사용 대역 통신 전체는 eth1을 통해서 라우팅 설정</span>
<span class="nv">$ </span>ip route add 172.20.0.0/16 via 192.168.10.200
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w1 <span class="nb">sudo </span>ip route add 172.20.0.0/16 via 192.168.10.200
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w0 <span class="nb">sudo </span>ip route add 172.20.0.0/16 via 192.168.20.200

<span class="c"># router 가 bgp로 학습한 라우팅 정보 한번 더 확인 : </span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router ip <span class="nt">-c</span> route | <span class="nb">grep </span>bgp
<span class="c"># =&gt; 172.20.0.0/24 nhid 63 via 192.168.10.100 dev eth1 proto bgp metric 20</span>
<span class="c">#    172.20.1.0/24 nhid 64 via 192.168.10.101 dev eth1 proto bgp metric 20</span>
<span class="c">#    172.20.2.0/24 nhid 60 via 192.168.20.100 dev eth2 proto bgp metric 20 </span>

<span class="c"># 정상 통신 확인!</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s --connect-timeout 1 webpod | grep Hostname; echo "---" ; sleep 1; done'</span>
<span class="c"># =&gt; Hostname: webpod-697b545f57-rl4d2</span>
<span class="c">#    ---</span>
<span class="c">#    Hostname: webpod-697b545f57-n7fk7</span>
<span class="c">#    ---</span>
<span class="c">#    Hostname: webpod-697b545f57-j6b7t</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 각 노드의 파드와 잘 통신이 되는것을 확인할 수 있습니다.&lt;/span&gt;</span>

<span class="c"># hubble relay 포트 포워딩 실행</span>
<span class="nv">$ </span>cilium hubble port-forward&amp;
<span class="nv">$ </span>hubble status
<span class="c"># =&gt; hubble status</span>
<span class="c">#    Healthcheck (via localhost:4245): Ok</span>
<span class="c">#    Current/Max Flows: 12,285/12,285 (100.00%)</span>
<span class="c">#    Flows/s: 65.38</span>
<span class="c">#    Connected Nodes: 3/3</span>

<span class="c"># flow log 모니터링</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--protocol</span> tcp <span class="nt">--pod</span> curl-pod
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w5/20250817_cilium_w5_4.png" alt="img.png" class="image-center image-bg" />
<em class="image-caption">curl-pod에서 webpod로 통신하는 흐름 확인</em></p>

<h3 id="노드-유지보수-k8s-w0-실습">노드 유지보수 (k8s-w0) 실습</h3>

<ul>
  <li>노드를 유지보수 하기 위해서 라우팅을 해제시키고, 다시 복구하는 실습을 진행해 보겠습니다. - <a href="https://docs.cilium.io/en/stable/network/bgp-control-plane/bgp-control-plane-operation/#shutting-down-a-node">Docs</a></li>
</ul>

<h5 id="노드-유지보수를-위한-설정">노드 유지보수를 위한 설정</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 모니터링 : 반복 호출</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s --connect-timeout 1 webpod | grep Hostname; echo "---" ; sleep 1; done'</span>

<span class="c"># (참고) BGP Control Plane logs</span>
<span class="nv">$ </span>kubectl logs <span class="nt">-n</span> kube-system <span class="nt">-l</span> <span class="nv">name</span><span class="o">=</span>cilium-operator <span class="nt">-f</span> | <span class="nb">grep</span> <span class="s2">"subsys=bgp-cp-operator"</span>
<span class="nv">$ </span>kubectl logs <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium <span class="nt">-f</span> | <span class="nb">grep</span> <span class="s2">"subsys=bgp-control-plane"</span>

<span class="c"># 유지보수를 위한 설정</span>
<span class="nv">$ </span>kubectl drain k8s-w0 <span class="nt">--ignore-daemonsets</span>
<span class="c"># =&gt; evicting pod default/webpod-697b545f57-n7fk7</span>
<span class="c">#    pod/webpod-697b545f57-n7fk7 evicted</span>
<span class="c">#    node/k8s-w0 drained</span>
<span class="nv">$ </span>kubectl label nodes k8s-w0 enable-bgp<span class="o">=</span><span class="nb">false</span> <span class="nt">--overwrite</span>
<span class="c"># =&gt; node/k8s-w0 labeled</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get node
<span class="c"># =&gt; NAME      STATUS                     ROLES           AGE   VERSION</span>
<span class="c">#    k8s-ctr   Ready                      control-plane   8h    v1.33.2</span>
<span class="c">#    k8s-w0    Ready&lt;span style="color: green;"&gt;,SchedulingDisabled&lt;/span&gt;   &lt;none&gt;          8h    v1.33.2</span>
<span class="c">#    k8s-w1    Ready                      &lt;none&gt;          8h    v1.33.2</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 drain을 통해 k8s-w0에 pod 스케줄링이 되지 않도록 설정 되었습니다.&lt;/span&gt;</span>
<span class="nv">$ </span>kubectl get ciliumbgpnodeconfigs
<span class="c"># =&gt; NAME      AGE</span>
<span class="c">#    k8s-ctr   50m</span>
<span class="c">#    k8s-w1    50m</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 enable-bgp=false로 라벨을 수정해서 cilium bgp node에서 k8s-w0 노드가 제외 되었습니다.&lt;/span&gt;</span>
<span class="nv">$ </span>cilium bgp routes
<span class="c"># =&gt; Node      VRouter   Prefix          NextHop   Age      Attrs</span>
<span class="c">#    k8s-ctr   65001     172.20.0.0/24   0.0.0.0   52m12s   [{Origin: i} {Nexthop: 0.0.0.0}]</span>
<span class="c">#    k8s-w1    65001     172.20.1.0/24   0.0.0.0   52m12s   [{Origin: i} {Nexthop: 0.0.0.0}]</span>
<span class="nv">$ </span>cilium bgp peers
<span class="c"># =&gt; Node      Local AS   Peer AS   Peer Address     Session State   Uptime   Family         Received   Advertised</span>
<span class="c">#    k8s-ctr   65001      65000     192.168.10.200   established     45m21s   ipv4/unicast   3          2</span>
<span class="c">#    k8s-w1    65001      65000     192.168.10.200   established     45m21s   ipv4/unicast   3          2   </span>

<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router <span class="s2">"sudo vtysh -c 'show ip bgp'"</span>
<span class="c"># =&gt;    Network          Next Hop            Metric LocPrf Weight Path</span>
<span class="c">#    *&gt; 10.10.1.0/24     0.0.0.0                  0         32768 i</span>
<span class="c">#    *&gt; 172.20.0.0/24    192.168.10.100                         0 65001 i</span>
<span class="c">#    *&gt; 172.20.1.0/24    192.168.10.101                         0 65001 i</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router <span class="s2">"sudo vtysh -c 'show ip route bgp'"</span>
<span class="c"># =&gt; B&gt;* 172.20.0.0/24 [20/0] via 192.168.10.100, eth1, weight 1, 00:46:08</span>
<span class="c">#    B&gt;* 172.20.1.0/24 [20/0] via 192.168.10.101, eth1, weight 1, 00:46:08</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router ip <span class="nt">-c</span> route | <span class="nb">grep </span>bgp
<span class="c"># =&gt; 172.20.0.0/24 nhid 63 via 192.168.10.100 dev eth1 proto bgp metric 20</span>
<span class="c">#    172.20.1.0/24 nhid 64 via 192.168.10.101 dev eth1 proto bgp metric 20</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router <span class="s2">"sudo vtysh -c 'show ip bgp summary'"</span>
<span class="c"># =&gt; Neighbor        V         AS   MsgRcvd   MsgSent   TblVer  InQ OutQ  Up/Down State/PfxRcd   PfxSnt Desc</span>
<span class="c">#    192.168.10.100  4      65001       915       919        0    0    0 00:45:35            1        3 N/A</span>
<span class="c">#    192.168.10.101  4      65001       915       919        0    0    0 00:45:35            1        3 N/A</span>
<span class="c">#    &lt;span style="color: green;"&gt;192.168.20.100&lt;/span&gt;  4      65001       856       857        0    0    0 00:03:03       Active        0 N/A</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 누적된 통계를 제외하면 router의 BGP 정보에는 k8s-w0 노드가 제외된 것을 확인할 수 있습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<h5 id="유지보수-완료-후-라우팅-복원">유지보수 완료 후 라우팅 복원</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 원복 설정</span>
<span class="nv">$ </span>kubectl label nodes k8s-w0 enable-bgp<span class="o">=</span><span class="nb">true</span> <span class="nt">--overwrite</span>
<span class="c"># =&gt; node/k8s-w0 labeled</span>
<span class="nv">$ </span>kubectl uncordon k8s-w0
<span class="c"># =&gt; node/k8s-w0 uncordoned</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 node를 다시 스케쥴링 가능하도록 설정합니다.&lt;/span&gt;</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get node
<span class="c"># =&gt; NAME      STATUS   ROLES           AGE   VERSION</span>
<span class="c">#    k8s-ctr   Ready    control-plane   8h    v1.33.2</span>
<span class="c">#    k8s-w0    &lt;span style="color: green;"&gt;Ready&lt;/span&gt;    &lt;none&gt;          8h    v1.33.2</span>
<span class="c">#    k8s-w1    Ready    &lt;none&gt;          8h    v1.33.2</span>
<span class="nv">$ </span>kubectl get ciliumbgpnodeconfigs
<span class="c"># =&gt; NAME      AGE</span>
<span class="c">#    k8s-ctr   57m</span>
<span class="c">#    &lt;span style="color: green;"&gt;k8s-w0    65s&lt;/span&gt;</span>
<span class="c">#    k8s-w1    57m</span>
<span class="nv">$ </span>cilium bgp routes
<span class="c"># =&gt; Node      VRouter   Prefix          NextHop   Age      Attrs</span>
<span class="c">#    k8s-ctr   65001     172.20.0.0/24   0.0.0.0   57m48s   [{Origin: i} {Nexthop: 0.0.0.0}]</span>
<span class="c">#    &lt;span style="color: green;"&gt;k8s-w0    65001     172.20.2.0/24   0.0.0.0   1m25s    [{Origin: i} {Nexthop: 0.0.0.0}]&lt;/span&gt;</span>
<span class="c">#    k8s-w1    65001     172.20.1.0/24   0.0.0.0   57m48s   [{Origin: i} {Nexthop: 0.0.0.0}]</span>
<span class="nv">$ </span>cilium bgp peers
<span class="c"># =&gt; Node      Local AS   Peer AS   Peer Address     Session State   Uptime   Family         Received   Advertised</span>
<span class="c">#    k8s-ctr   65001      65000     192.168.10.200   established     51m18s   ipv4/unicast   4          2</span>
<span class="c">#    &lt;span style="color: green;"&gt;k8s-w0    65001      65000     192.168.10.200   established     1m52s    ipv4/unicast   4          2&lt;/span&gt;</span>
<span class="c">#    k8s-w1    65001      65000     192.168.10.200   established     51m18s   ipv4/unicast   4          2</span>

<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router <span class="s2">"sudo vtysh -c 'show ip bgp'"</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router <span class="s2">"sudo vtysh -c 'show ip route bgp'"</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router ip <span class="nt">-c</span> route | <span class="nb">grep </span>bgp
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router <span class="s2">"sudo vtysh -c 'show ip bgp summary'"</span>

<span class="c"># 노드별 파드 분배 실행</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                      READY   STATUS    RESTARTS   AGE     IP             NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    curl-pod                  1/1     Running   0          138m    172.20.0.187   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-697b545f57-d7dn8   1/1     Running   0          9m33s   172.20.1.197   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-697b545f57-j6b7t   1/1     Running   0          138m    172.20.0.72    k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-697b545f57-rl4d2   1/1     Running   0          138m    172.20.1.7     k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="nv">$ </span>kubectl scale deployment webpod <span class="nt">--replicas</span> 0
<span class="nv">$ </span>kubectl scale deployment webpod <span class="nt">--replicas</span> 3
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                      READY   STATUS    RESTARTS   AGE    IP             NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    curl-pod                  1/1     Running   0          138m   172.20.0.187   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-697b545f57-h4lmx   1/1     Running   0          9s     172.20.1.12    k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-697b545f57-q8bzk   1/1     Running   0          9s     172.20.0.161   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-697b545f57-ssc5l   1/1     Running   0          9s     172.20.2.143   &lt;span style="color: green;"&gt;k8s-w0&lt;/span&gt;    &lt;none&gt;           &lt;none&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 webpod의 replica 수를 0으로 줄였다가 3으로 늘려서 노드별로 파드가 분배되는 것을 확인합니다.&lt;/span&gt;</span>
</code></pre></div></div>

<h5 id="crd-status-report-끄기">CRD Status Report 끄기</h5>

<ul>
  <li>노드가 많은 대규모 클러스터의 경우, api 서버의 부하를 유발할 수 있어서 <code class="language-plaintext highlighter-rouge">bgp status reporting off</code>이 권장 됩니다. <a href="https://docs.cilium.io/en/stable/network/bgp-control-plane/bgp-control-plane-operation/#disabling-crd-status-report">Docs</a></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get ciliumbgpnodeconfigs <span class="nt">-o</span> yaml | yq
<span class="c"># =&gt; ...</span>
<span class="c">#      status:</span>
<span class="c">#        bgpInstances:</span>
<span class="c">#        - localASN: 65001</span>
<span class="c">#          name: instance-65001</span>
<span class="c">#          peers:</span>
<span class="c">#    ...</span>

<span class="c"># 설정</span>
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--version</span> 1.18.0 <span class="nt">--namespace</span> kube-system <span class="nt">--reuse-values</span> <span class="se">\</span>
  <span class="nt">--set</span> bgpControlPlane.statusReport.enabled<span class="o">=</span><span class="nb">false</span>
<span class="c"># =&gt; Release "cilium" has been upgraded. Happy Helming!</span>

<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system rollout restart ds/cilium
<span class="c"># =&gt; daemonset.apps/cilium restarted</span>

<span class="c"># 확인 : CiliumBGPNodeConfig Status 정보가 없다!</span>
<span class="nv">$ </span>kubectl get ciliumbgpnodeconfigs <span class="nt">-o</span> yaml | yq
<span class="c"># =&gt; ...</span>
<span class="c">#     "status": {}</span>
<span class="c">#    ...       </span>
</code></pre></div></div>

<h5 id="serviceloadbalancer---externalip-ips를-bgp로-광고">Service(LoadBalancer - ExternalIP) IPs를 BGP로 광고</h5>

<p><img src="/assets/2025/cilium/w5/20250817_cilium_w5_5.png" alt="img.png" class="image-center image-bg" />
<em class="image-caption"><a href="https://isovalent.com/blog/post/migrating-from-metallb-to-cilium/#l3-announcement-over-bgp">Service(LoadBalancer - ExternalIP) IPs를 BGP로 광고</a></em></p>

<ul>
  <li>Cilium BGP는 Service(LoadBalancer - ExternalIP) IPs를 BGP로 광고할 수 있고, MetalLB를 대체할 수 있습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># LB IPAM Announcement over BGP 설정 예정으로, 노드의 네트워크 대역이 아니여도 가능!</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: "cilium.io/v2"
kind: CiliumLoadBalancerIPPool
metadata:
  name: "cilium-pool"
spec:
  allowFirstLastIPs: "No"
  blocks:
  - cidr: "172.16.1.0/24"
</span><span class="no">EOF
</span><span class="c"># =&gt; ciliumloadbalancerippool.cilium.io/cilium-pool created</span>

<span class="nv">$ </span>kubectl get ippool
<span class="c"># =&gt; NAME          DISABLED   CONFLICTING   IPS AVAILABLE   AGE</span>
<span class="c">#    cilium-pool   false      False         254             16s</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl patch svc webpod <span class="nt">-p</span> <span class="s1">'{"spec": {"type": "LoadBalancer"}}'</span>
<span class="nv">$ </span>kubectl get svc webpod 
NAME     TYPE           CLUSTER-IP    EXTERNAL-IP   PORT<span class="o">(</span>S<span class="o">)</span>        AGE
<span class="c"># =&gt; NAME     TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE</span>
<span class="c">#    webpod   LoadBalancer   10.96.134.232   172.16.1.1    80:31973/TCP   7m5s</span>

<span class="nv">$ </span>kubectl get ippool
<span class="c"># =&gt; NAME          DISABLED   CONFLICTING   IPS AVAILABLE   AGE</span>
<span class="c">#    cilium-pool   false      False         &lt;span style="color: green;"&gt;253&lt;/span&gt;             8m25s</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 External IP가 할당되어서, 남은 IP수가 하나 줄어서 253개의 IP가 남았습니다.&lt;/span&gt;</span>

<span class="nv">$ </span>kubectl describe svc webpod | <span class="nb">grep</span> <span class="s1">'Traffic Policy'</span>
<span class="c"># =&gt; External Traffic Policy:  Cluster</span>
<span class="c">#    Internal Traffic Policy:  Cluster</span>

<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system <span class="nb">exec </span>ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium-dbg service list
<span class="c"># =&gt; ID   Frontend               Service Type   Backend</span>
<span class="c">#    ...</span>
<span class="c">#    16   &lt;span style="color: green;"&gt;172.16.1.1:80/TCP&lt;/span&gt;      LoadBalancer   1 =&gt; 172.20.0.123:80/TCP (active)</span>
<span class="c">#                                               2 =&gt; 172.20.1.72:80/TCP (active)</span>
<span class="c">#                                               3 =&gt; 172.20.2.138:80/TCP (active)</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 ExternalIP와 각 파드의 IP가 매핑된 것을 확인할 수 있습니다.&lt;/span&gt;</span>

<span class="c"># LBIP로 curl 요청 확인</span>
<span class="nv">$ </span>kubectl get svc webpod <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.loadBalancer.ingress[0].ip}'</span>
<span class="c"># =&gt; 172.16.1.1</span>
<span class="nv">$ LBIP</span><span class="o">=</span><span class="si">$(</span>kubectl get svc webpod <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.loadBalancer.ingress[0].ip}'</span><span class="si">)</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LBIP</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LBIP</span> | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod-697b545f57-2kvd9</span>

<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LBIP</span> | <span class="nb">grep </span>RemoteAddr
<span class="c"># =&gt; RemoteAddr: 192.168.10.100:60634</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LBIP</span> | <span class="nb">grep </span>RemoteAddr
<span class="c"># =&gt; RemoteAddr: 172.20.0.201:60184</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 같은 노드의 파드로 통신 될 때는 cilium_host IP가, 다른 노드의 파드로 통신 될 때는 node의 IP가 RemoteAddr로 보입니다.&lt;/span&gt;</span>

<span class="c"># 모니터링</span>
<span class="nv">$ </span>watch <span class="s2">"sshpass -p 'vagrant' ssh vagrant@router ip -c route"</span>
<span class="c"># =&gt; default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.10.1.0/24 dev loop1 proto kernel scope link src 10.10.1.200</span>
<span class="c">#    10.10.2.0/24 dev loop2 proto kernel scope link src 10.10.2.200</span>
<span class="c">#    172.20.0.0/24 nhid 60 via 192.168.10.100 dev eth1 proto bgp metric 20</span>
<span class="c">#    172.20.1.0/24 nhid 64 via 192.168.10.101 dev eth1 proto bgp metric 20</span>
<span class="c">#    172.20.2.0/24 nhid 62 via 192.168.20.100 dev eth2 proto bgp metric 20</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.200</span>
<span class="c">#    192.168.20.0/24 dev eth2 proto kernel scope link src 192.168.20.200</span>

<span class="c"># LB EX-IP를 BGP로 광고 설정</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: cilium.io/v2
kind: CiliumBGPAdvertisement
metadata:
  name: bgp-advertisements-lb-exip-webpod
  labels:
    advertise: bgp
spec:
  advertisements:
    - advertisementType: "Service"
      service:
        addresses:
          - LoadBalancerIP
      selector:             
        matchExpressions:
          - { key: app, operator: In, values: [ webpod ] }
</span><span class="no">EOF

</span><span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router ip <span class="nt">-c</span> route
<span class="c"># =&gt; ...</span>
<span class="c">#    172.16.1.1 nhid 70 proto bgp metric 20</span>
<span class="c">#            &lt;span style="color: green;"&gt;nexthop via 192.168.10.100 dev eth1 weight 1&lt;/span&gt; # &lt;span style="color: green;"&gt;👉 BGP 광고 후 3줄이 추가되었습니다.&lt;/span&gt;</span>
<span class="c">#            &lt;span style="color: green;"&gt;nexthop via 192.168.20.100 dev eth2 weight 1&lt;/span&gt;</span>
<span class="c">#            &lt;span style="color: green;"&gt;nexthop via 192.168.10.101 dev eth1 weight 1&lt;/span&gt;</span>
<span class="c">#    ...</span>

<span class="nv">$ </span>kubectl get CiliumBGPAdvertisement
<span class="c"># =&gt; NAME                                AGE</span>
<span class="c">#    bgp-advertisements                  16m</span>
<span class="c">#    bgp-advertisements-lb-exip-webpod   3m</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg bgp route-policies
<span class="c"># =&gt; VRouter   Policy Name                                             Type     Match Peers         Match Families   Match Prefixes (Min..Max Len)   RIB Action   Path Actions</span>
<span class="c">#    65001     allow-local                                             import                                                                        accept</span>
<span class="c">#    65001     tor-switch-ipv4-PodCIDR                                 export   192.168.10.200/32                    172.20.1.0/24 (24..24)          accept</span>
<span class="c">#    65001     tor-switch-ipv4-Service-webpod-default-LoadBalancerIP   export   192.168.10.200/32                    172.16.1.1/32 (32..32)          accept</span>

<span class="nv">$ </span>cilium bgp routes available ipv4 unicast
<span class="c"># =&gt; Node      VRouter   Prefix          NextHop   Age      Attrs</span>
<span class="c">#    k8s-ctr   65001     172.16.1.1/32   0.0.0.0   3m36s    [{Origin: i} {Nexthop: 0.0.0.0}]</span>
<span class="c">#              65001     172.20.0.0/24   0.0.0.0   12m38s   [{Origin: i} {Nexthop: 0.0.0.0}]</span>
<span class="c">#    k8s-w0    65001     172.16.1.1/32   0.0.0.0   3m35s    [{Origin: i} {Nexthop: 0.0.0.0}]</span>
<span class="c">#              65001     172.20.2.0/24   0.0.0.0   12m25s   [{Origin: i} {Nexthop: 0.0.0.0}]</span>
<span class="c">#    k8s-w1    65001     172.16.1.1/32   0.0.0.0   3m35s    [{Origin: i} {Nexthop: 0.0.0.0}]</span>
<span class="c">#              65001     172.20.1.0/24   0.0.0.0   12m40s   [{Origin: i} {Nexthop: 0.0.0.0}]  </span>

<span class="c"># 현재 BGP가 동작하는 모든 노드로 전달 가능!</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router ip <span class="nt">-c</span> route
<span class="c"># =&gt; ...</span>
<span class="c">#    172.16.1.1 nhid 70 proto bgp metric 20</span>
<span class="c">#            nexthop via 192.168.10.100 dev eth1 weight 1</span>
<span class="c">#            nexthop via 192.168.20.100 dev eth2 weight 1</span>
<span class="c">#            nexthop via 192.168.10.101 dev eth1 weight 1</span>

<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router <span class="s2">"sudo vtysh -c 'show ip route bgp'"</span>
<span class="c"># =&gt; B&gt;* 172.16.1.1/32 [20/0] via 192.168.10.100, eth1, weight 1, 00:04:10  </span>
<span class="c">#      *                      via 192.168.10.101, eth1, weight 1, 00:04:10</span>
<span class="c">#      *                      via 192.168.20.100, eth2, weight 1, 00:04:10</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 `B&gt;`로 시작하는 라우팅 정보가 BGP로 광고된 것을 확인할 수 있습니다.&lt;/span&gt;</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router <span class="s2">"sudo vtysh -c 'show ip bgp summary'"</span>
<span class="c"># =&gt; Neighbor        V         AS   MsgRcvd   MsgSent   TblVer  InQ OutQ  Up/Down State/PfxRcd   PfxSnt Desc</span>
<span class="c">#    192.168.10.100  4      65001       332       335        0    0    0 00:14:00            2        5 N/A</span>
<span class="c">#    192.168.10.101  4      65001       331       334        0    0    0 00:14:02            2        5 N/A</span>
<span class="c">#    192.168.20.100  4      65001       333       337        0    0    0 00:13:47            2        5 N/A</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router <span class="s2">"sudo vtysh -c 'show ip bgp'"</span>
<span class="c"># =&gt;    Network          Next Hop            Metric LocPrf Weight Path</span>
<span class="c">#    ...</span>
<span class="c">#    *= 172.16.1.1/32    192.168.20.100                         0 65001 i   # * valid, &gt; best, = multipath</span>
<span class="c">#    *&gt;                  192.168.10.100                         0 65001 i</span>
<span class="c">#    *=                  192.168.10.101                         0 65001 i</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 BGP 라우팅 테이블에 Multipath로 등록된 것을 확인할 수 있습니다.&lt;/span&gt;</span>

<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router <span class="s2">"sudo vtysh -c 'show ip bgp 172.16.1.1/32'"</span>
<span class="c"># =&gt; BGP routing table entry for 172.16.1.1/32, version 7</span>
<span class="c">#    Paths: (&lt;span style="color: green;"&gt;3 available&lt;/span&gt;, best #2, table default)</span>
<span class="c">#      Advertised to non peer-group peers:</span>
<span class="c">#      192.168.10.100 192.168.10.101 192.168.20.100</span>
<span class="c">#      65001</span>
<span class="c">#        192.168.20.100 from 192.168.20.100 (192.168.20.100)</span>
<span class="c">#          Origin IGP, valid, external, multipath</span>
<span class="c">#          Last update: Sat Aug 16 16:19:43 2025</span>
<span class="c">#      65001</span>
<span class="c">#        192.168.10.100 from 192.168.10.100 (192.168.10.100)</span>
<span class="c">#          Origin IGP, valid, external, multipath, best (Router ID)</span>
<span class="c">#          Last update: Sat Aug 16 16:19:43 2025</span>
<span class="c">#      65001</span>
<span class="c">#        192.168.10.101 from 192.168.10.101 (192.168.10.101)</span>
<span class="c">#          Origin IGP, valid, external, multipath</span>
<span class="c">#          Last update: Sat Aug 16 16:19:43 2025</span>
</code></pre></div></div>

<h5 id="router에서-ll-external-ip-호출-확인">router에서 LL External IP 호출 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ LBIP</span><span class="o">=</span>172.16.1.1
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LBIP</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LBIP</span> | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod-697b545f57-2kvd9</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LBIP</span> | <span class="nb">grep </span>RemoteAddr
<span class="c"># =&gt; RemoteAddr: 192.168.10.100:35378</span>

<span class="c"># 반복 접속</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span>  <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$LBIP</span> | <span class="nb">grep </span>Hostname<span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;      34 Hostname: webpod-697b545f57-lz8mc</span>
<span class="c">#         33 Hostname: webpod-697b545f57-gzzdb</span>
<span class="c">#         33 Hostname: webpod-697b545f57-2kvd9</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$LBIP</span> | egrep <span class="s1">'Hostname|RemoteAddr'</span> <span class="p">;</span> <span class="nb">sleep </span>0.1<span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; Hostname: webpod-697b545f57-2kvd9</span>
<span class="c">#    RemoteAddr: 192.168.10.100:46014</span>
<span class="c">#    Hostname: webpod-697b545f57-lz8mc</span>
<span class="c">#    RemoteAddr: 192.168.10.100:38402</span>
<span class="c">#    Hostname: webpod-697b545f57-gzzdb</span>
<span class="c">#    RemoteAddr: 172.20.0.201:44744</span>
<span class="c">#    ...</span>

<span class="c"># 호출 확인을 쉽게 테스트할 수 있게 k8s-ctr 에서 replicas=2 로 줄여보겠습니다.</span>
<span class="nv">$ </span>kubectl scale deployment webpod <span class="nt">--replicas</span> 2
<span class="c"># =&gt; deployment.apps/webpod scaled</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                      READY   STATUS    RESTARTS   AGE   IP             NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c"># =&gt; webpod-697b545f57-nhdcd   1/1     Running   0          3s    172.20.1.130   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-697b545f57-t7wb4   1/1     Running   0          3s    172.20.2.198   k8s-w0    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>cilium bgp routes
<span class="c"># =&gt; Node      VRouter   Prefix          NextHop   Age      Attrs</span>
<span class="c">#    k8s-ctr   65001     172.16.1.1/32   0.0.0.0   10m58s   [{Origin: i} {Nexthop: 0.0.0.0}]</span>
<span class="c">#              65001     172.20.0.0/24   0.0.0.0   20m0s    [{Origin: i} {Nexthop: 0.0.0.0}]</span>
<span class="c">#    k8s-w0    65001     172.16.1.1/32   0.0.0.0   10m58s   [{Origin: i} {Nexthop: 0.0.0.0}]</span>
<span class="c">#              65001     172.20.2.0/24   0.0.0.0   19m48s   [{Origin: i} {Nexthop: 0.0.0.0}]</span>
<span class="c">#    k8s-w1    65001     172.16.1.1/32   0.0.0.0   10m57s   [{Origin: i} {Nexthop: 0.0.0.0}]</span>
<span class="c">#              65001     172.20.1.0/24   0.0.0.0   20m2s    [{Origin: i} {Nexthop: 0.0.0.0}]</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 파드를 2개로 줄여서 k8s-w0과 k8s-w1에만 파드가 있지만, k8s-ctr에도 파드 및 LB ExtIP의 라우팅 정보가 남아 있습니다.&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   이렇게 되면 LB ExtIP 사용시 k8s-ctr로도 접속이 되어서 k8s-w0이나 k8s-w1의 webpod에서 처리되어서 k8s-ctr으로 다시 응답이 리턴되는&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   오버헤드가 생길 수 있다는 것을 의미합니다. 이에 대한 해결 방법은 이후에 알아 보겠습니다.&lt;/span&gt;</span>

<span class="c"># router 에서 정보 확인 : k8s-ctr 노드에 대상 파드가 배치되지 않았지만, 라우팅 경로 설정이 되어 있다.</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route
<span class="nv">$ </span>vtysh <span class="nt">-c</span> <span class="s1">'show ip bgp summary'</span>
<span class="c"># =&gt; Neighbor        V         AS   MsgRcvd   MsgSent   TblVer  InQ OutQ  Up/Down State/PfxRcd   PfxSnt Desc</span>
<span class="c">#    192.168.10.100  4      65001       548       552        0    0    0 00:24:49            2        5 N/A</span>
<span class="c">#    192.168.10.101  4      65001       547       550        0    0    0 00:24:51            2        5 N/A</span>
<span class="c">#    192.168.20.100  4      65001       550       553        0    0    0 00:24:36            2        5 N/A</span>
<span class="nv">$ </span>vtysh <span class="nt">-c</span> <span class="s1">'show ip bgp'</span>
<span class="c"># =&gt;    Network          Next Hop            Metric LocPrf Weight Path</span>
<span class="c">#    ...</span>
<span class="c">#    *= 172.16.1.1/32    192.168.20.100                         0 65001 i</span>
<span class="c">#    *&gt;                  &lt;span style="color: green;"&gt;192.168.10.100&lt;/span&gt;                         0 65001 i</span>
<span class="c">#    *=                  192.168.10.101                         0 65001 i</span>
<span class="nv">$ </span>vtysh <span class="nt">-c</span> <span class="s1">'show ip bgp 172.16.1.1/32'</span>
<span class="c"># =&gt; BGP routing table entry for 172.16.1.1/32, version 7</span>
<span class="c">#    Paths: (3 available, best #2, table default)</span>
<span class="c">#      Advertised to non peer-group peers:</span>
<span class="c">#      &lt;span style="color: green;"&gt;192.168.10.100&lt;/span&gt; 192.168.10.101 192.168.20.100</span>
<span class="c">#      65001</span>
<span class="c">#        192.168.20.100 from 192.168.20.100 (192.168.20.100)</span>
<span class="c">#          Origin IGP, valid, external, multipath</span>
<span class="c">#          Last update: Sat Aug 16 16:19:42 2025</span>
<span class="c">#      65001</span>
<span class="c">#        &lt;span style="color: green;"&gt;192.168.10.100&lt;/span&gt; from 192.168.10.100 (192.168.10.100)</span>
<span class="c">#          Origin IGP, valid, external, multipath, best (Router ID)</span>
<span class="c">#          Last update: Sat Aug 16 16:19:42 2025</span>
<span class="c">#      65001</span>
<span class="c">#        192.168.10.101 from 192.168.10.101 (192.168.10.101)</span>
<span class="c">#          Origin IGP, valid, external, multipath</span>
<span class="c">#          Last update: Sat Aug 16 16:19:42 2025</span>
<span class="nv">$ </span>vtysh <span class="nt">-c</span> <span class="s1">'show ip route bgp'</span>
<span class="c"># =&gt; B&gt;* 172.16.1.1/32 [20/0] via &lt;span style="color: green;"&gt;192.168.10.100&lt;/span&gt;, eth1, weight 1, 00:17:01</span>
<span class="c">#      *                      via 192.168.10.101, eth1, weight 1, 00:17:01</span>
<span class="c">#      *                      via 192.168.20.100, eth2, weight 1, 00:17:01</span>
<span class="c">#    ...</span>

<span class="c"># [k8s-ctr] 반복 접속</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span>  <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$LBIP</span> | <span class="nb">grep </span>Hostname<span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;      52 Hostname: webpod-697b545f57-t7wb4</span>
<span class="c">#         48 Hostname: webpod-697b545f57-nhdcd</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 replicas가 2이기 때문에, webpod의 파드가 k8s-w0, k8s-w1의 2개로 분배되어서 Hostname이 2개가 출력되는 것을 확인할 수 있습니다.&lt;/span&gt;</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$LBIP</span> | egrep <span class="s1">'Hostname|RemoteAddr'</span> <span class="p">;</span> <span class="nb">sleep </span>0.1<span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; Hostname: webpod-697b545f57-t7wb4</span>
<span class="c">#    RemoteAddr: 192.168.10.100:43914</span>
<span class="c">#    Hostname: webpod-697b545f57-t7wb4</span>
<span class="c">#    RemoteAddr: 192.168.10.100:43920</span>
<span class="c">#    Hostname: webpod-697b545f57-nhdcd</span>
<span class="c">#    RemoteAddr: 192.168.10.100:53840</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 다른 노드에 있는 webpod 파드와 접속이 되어서 k8s-ctr의 NodeIP가 출력됩니다.&lt;/span&gt;</span>

<span class="c"># 신규터미널 (3개) : k8s-w1, k8s-w2, k8s-w0</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> eth1 <span class="nt">-A</span> <span class="nt">-s</span> 0 <span class="nt">-nn</span> <span class="s1">'tcp port 80'</span>

<span class="c"># k8s-ctr 를 경유하거나 등 확인 : ExternalTrafficPolicy 설정 확인</span>
<span class="nv">$ LBIP</span><span class="o">=</span>172.16.1.1
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LBIP</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LBIP</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LBIP</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LBIP</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s-w0 이나 k8s-w1과 통신이 되며 k8s-ctr의 eth1을 경유해서 패킷이 전송되는 것을 확인할 수 있습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<hr />

<h2 id="kind">Kind</h2>

<h3 id="kind-소개">Kind 소개</h3>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_8.png" alt="img.png" class="w-20 image-center" /></p>

<ul>
  <li>Kind는 <strong>K</strong>ubernetes <strong>in</strong> <strong>D</strong>ocker의 줄임말로, 로컬 환경에서 쉽게 Kubernetes 클러스터를 구성할 수 있도록 도와주는 도구입니다.</li>
  <li>이름처럼 Docker를 이용하여 Kubernetes 클러스터를 구성하며, Docker를 이용하기 때문에 다양한 환경에서 쉽게 사용할 수 있습니다.</li>
  <li>Kind는 HA를 포함한 멀티노드를 지원하지만, 테스트와 실험적인 목적으로만 사용하기를 추천합니다.</li>
  <li>Kind는 클러스터를 구성하기 위해 kubeadm을 사용합니다.</li>
  <li><a href="https://sweetlittlebird.github.io/posts/2024-09-07-KANS-Study-Week2/#kind-%EC%86%8C%EA%B0%9C-%EB%B0%8F-%EC%84%A4%EC%B9%98">Kind 소개 및 설치</a>, <a href="https://kind.sigs.k8s.io/docs/user/quick-start/">Kind 공식문서</a></li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_9.png" alt="img.png" class="image-center" />
<em class="image-caption"><a href="https://kind.sigs.k8s.io/">Kind 구성도</a></em></p>

<h3 id="kind-설치">Kind 설치</h3>

<ul>
  <li>Apple Silicon 기반 Mac 기준으로 설치를 진행해보겠습니다.</li>
</ul>

<h4 id="docker-desktop-및-필수-툴-설치">Docker Desktop 및 필수 툴 설치</h4>

<ul>
  <li>Docker Desktop 설치 - <a href="https://docs.docker.com/desktop/install/mac-install/">Link</a>
    <ul>
      <li>실습 환경 : Kind 사용하는 도커 엔진 리소스에 최소 <strong>vCPU 4</strong>, <strong>Memory 8GB</strong> 할당을 권고합니다. - <a href="https://kind.sigs.k8s.io/docs/user/quick-start/#settings-for-docker-desktop">링크</a></li>
    </ul>
  </li>
  <li>필수 툴 설치
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Install Kind</span>
<span class="nv">$ </span>brew <span class="nb">install </span>kind
<span class="nv">$ </span>kind <span class="nt">--version</span>
<span class="c"># =&gt; kind version 0.29.0</span>
  
<span class="c"># Install kubectl</span>
<span class="nv">$ </span>brew <span class="nb">install </span>kubernetes-cli
<span class="nv">$ </span>kubectl version <span class="nt">--client</span><span class="o">=</span><span class="nb">true</span>
<span class="c"># =&gt; Client Version: v1.33.1</span>
  
<span class="c">## kubectl -&gt; k 단축키 설정</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"alias kubectl=kubecolor"</span> <span class="o">&gt;&gt;</span> ~/.zshrc
  
<span class="c"># Install Helm</span>
<span class="nv">$ </span>brew <span class="nb">install </span>helm
<span class="nv">$ </span>helm version
<span class="c"># =&gt; version.BuildInfo{Version:"v3.18.2", GitCommit:"04cad4610054e5d546aa5c5d9c1b1d5cf68ec1f8", GitTreeState:"clean", GoVersion:"go1.24.3"}</span>
</code></pre></div>    </div>
  </li>
  <li>(선택) 유용한 툴 설치
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 툴 설치</span>
<span class="nv">$ </span>brew <span class="nb">install </span>krew
<span class="nv">$ </span>brew <span class="nb">install </span>kube-ps1
<span class="nv">$ </span>brew <span class="nb">install </span>kubectx
  
<span class="c"># kubectl 출력 시 하이라이트 처리</span>
<span class="nv">$ </span>brew <span class="nb">install </span>kubecolor
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"alias kubectl=kubecolor"</span> <span class="o">&gt;&gt;</span> ~/.zshrc
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"compdef kubecolor=kubectl"</span> <span class="o">&gt;&gt;</span> ~/.zshrc
</code></pre></div>    </div>
    <h3 id="kind-기본-사용---클러스터-배포-및-확인">kind 기본 사용 - 클러스터 배포 및 확인</h3>
  </li>
</ul>

<blockquote>
  <p>이미 kubeconfig가 있다면, 미리 kubeconfig를 백업 후 kind를 실습하거나, 아래 처럼 kubeconfig 변수를 지정하여 사용하기를 권장합니다.</p>
</blockquote>

<ul>
  <li>(옵션) 별도 kubeconfig 지정 후 사용
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 방안1 : 환경변수 지정</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">KUBECONFIG</span><span class="o">=</span>/Users/&lt;Username&gt;/Downloads/kind/config
  
<span class="c"># 방안2 : 혹은 --kubeconfig ./config 지정 가능</span>
  
<span class="c"># 클러스터 생성</span>
<span class="nv">$ </span>kind create cluster
  
<span class="c"># kubeconfig 파일 확인</span>
<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-l</span> /Users/&lt;Username&gt;/Downloads/kind/config
<span class="c"># =&gt; -rw-------  1 &lt;Username&gt;  staff  5608  4 24 09:05 /Users/&lt;Username&gt;/Downloads/kind/config</span>
  
<span class="c"># 파드 정보 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-A</span>
  
<span class="c"># 클러스터 삭제</span>
<span class="nv">$ </span>kind delete cluster
<span class="nv">$ </span><span class="nb">unset </span>KUBECONFIG
</code></pre></div>    </div>
  </li>
  <li>Kind 클러스터 배포 및 확인
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 클러스터 배포 전 확인</span>
<span class="nv">$ </span>docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES</span>
  
<span class="c"># Create a cluster with kind</span>
<span class="nv">$ </span>kind create cluster
<span class="c"># =&gt; Creating cluster "kind" ...</span>
<span class="c">#     ✓ Ensuring node image (kindest/node:v1.33.1) 🖼</span>
<span class="c">#     ✓ Preparing nodes 📦</span>
<span class="c">#     ✓ Writing configuration 📜</span>
<span class="c">#     ✓ Starting control-plane 🕹️</span>
<span class="c">#     ✓ Installing CNI 🔌</span>
<span class="c">#     ✓ Installing StorageClass 💾</span>
<span class="c">#    Set kubectl context to "kind-kind"</span>
<span class="c">#    You can now use your cluster with:</span>
<span class="c">#    </span>
<span class="c">#    kubectl cluster-info --context kind-kind</span>
  
<span class="c"># 클러스터 배포 확인</span>
<span class="nv">$ </span>kind get clusters
<span class="c"># =&gt; kind</span>
<span class="nv">$ </span>kind get nodes
<span class="c"># =&gt; kind-control-plane</span>
<span class="nv">$ </span>kubectl cluster-info
<span class="c"># =&gt; Kubernetes control plane is running at https://127.0.0.1:56460</span>
<span class="c">#    CoreDNS is running at https://127.0.0.1:56460/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</span>
<span class="c">#    </span>
<span class="c">#    To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.</span>
  
<span class="c"># 노드 정보 확인</span>
<span class="nv">$ </span>kubectl get node <span class="nt">-o</span> wide
<span class="c"># =&gt; NAME                 STATUS   ROLES           AGE   VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE                         KERNEL-VERSION     CONTAINER-RUNTIME</span>
<span class="c">#    kind-control-plane   Ready    control-plane   48s   v1.33.1   172.20.0.2    &lt;none&gt;        Debian GNU/Linux 12 (bookworm)   5.10.76-linuxkit   containerd://2.1.1</span>
  
<span class="c"># 파드 정보 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE            NAME                                         READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    kube-system          coredns-674b8bbfcf-922ww                     1/1     Running   0          49s</span>
<span class="c">#    kube-system          coredns-674b8bbfcf-mm68k                     1/1     Running   0          49s</span>
<span class="c">#    kube-system          etcd-kind-control-plane                      1/1     Running   0          55s</span>
<span class="c">#    kube-system          kindnet-cvgzn                                1/1     Running   0          49s</span>
<span class="c">#    kube-system          kube-apiserver-kind-control-plane            1/1     Running   0          55s</span>
<span class="c">#    kube-system          kube-controller-manager-kind-control-plane   1/1     Running   0          55s</span>
<span class="c">#    kube-system          kube-proxy-xkczv                             1/1     Running   0          49s</span>
<span class="c">#    kube-system          kube-scheduler-kind-control-plane            1/1     Running   0          55s</span>
<span class="c">#    local-path-storage   local-path-provisioner-7dc846544d-th5jx      1/1     Running   0          49s</span>
<span class="nv">$ </span>kubectl get componentstatuses
<span class="c"># =&gt; NAME                 STATUS    MESSAGE   ERROR</span>
<span class="c">#    scheduler            Healthy   ok</span>
<span class="c">#    controller-manager   Healthy   ok</span>
<span class="c">#    etcd-0               Healthy   ok</span>
  
<span class="c"># 컨트롤플레인 (컨테이너) 노드 1대가 실행</span>
<span class="nv">$ </span>docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE                  COMMAND                  CREATED              STATUS              PORTS                       NAMES</span>
<span class="c">#    d2b1bc35791a   kindest/node:v1.33.1   "/usr/local/bin/entr…"   About a minute ago   Up About a minute   127.0.0.1:56460-&gt;6443/tcp   kind-control-plane</span>
<span class="nv">$ </span>docker images
<span class="c"># =&gt; REPOSITORY                                        TAG                                        IMAGE ID       CREATED         SIZE</span>
<span class="c">#    kindest/node                                      &lt;none&gt;                                     071dd73121e8   2 months ago    1.09GB</span>
  
<span class="c"># kube config 파일 확인</span>
<span class="nv">$ </span><span class="nb">cat</span> ~/.kube/config
<span class="c"># 혹은</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="nv">$KUBECONFIG</span> <span class="c"># KUBECONFIG 변수 지정 사용 시</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 기존 kube config에 추가적으로 kind 클러스터 관련 항목이 추가된 것을 확인할 수 있습니다.&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   또한 current-context: kind-kind여서 kubectl 명령어를 실행하면 kind 클러스터에 연결되어 실행됩니다.&lt;/span&gt;</span>
  
<span class="c"># nginx 파드 배포 및 확인 : 컨트롤플레인 노드인데 파드가 배포 될까요?</span>
<span class="nv">$ </span>kubectl run nginx <span class="nt">--image</span><span class="o">=</span>nginx:alpine
<span class="c"># =&gt; pod/nginx created</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME    READY   STATUS    RESTARTS   AGE   IP           NODE                 NOMINATED NODE   READINESS GATES</span>
<span class="c">#    nginx   1/1     Running   0          11s   10.244.0.5   kind-control-plane   &lt;none&gt;           &lt;none&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 파드가 배포 됩니다!&lt;/span&gt;</span>
  
<span class="c"># 노드에 Taints 정보 확인</span>
<span class="nv">$ </span>kubectl describe node | <span class="nb">grep </span>Taints
<span class="c"># =&gt; Taints:             &lt;none&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 컨트롤플레인이지만 Taints가 없어서 파드가 배포 됩니다.&lt;/span&gt;</span>
  
<span class="c"># 클러스터 삭제</span>
<span class="nv">$ </span>kind delete cluster
<span class="c"># =&gt; Deleting cluster "kind" ...</span>
  
<span class="c"># kube config 삭제 확인</span>
<span class="nv">$ </span><span class="nb">cat</span> ~/.kube/config
<span class="c"># 혹은</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="nv">$KUBECONFIG</span> <span class="c"># KUBECONFIG 변수 지정 사용 시</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 kind 클러스터 관련 항목이 삭제된 것을 확인할 수 있습니다.&lt;/span&gt;</span>
</code></pre></div>    </div>
  </li>
  <li>kind로 worker node가 3개인 클러스터 배포 후 기본 정보를 확인해보겠습니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 클러스터 배포 전 확인</span>
<span class="nv">$ </span>docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES</span>
  
<span class="c"># Create a cluster with kind</span>
<span class="nv">$ </span>kind create cluster <span class="nt">--name</span> myk8s <span class="nt">--image</span> kindest/node:v1.32.2 <span class="nt">--config</span> - <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
  extraPortMappings:
  - containerPort: 30000
    hostPort: 30000
  - containerPort: 30001
    hostPort: 30001
  - containerPort: 30002
    hostPort: 30002
  - containerPort: 30003
    hostPort: 30003
- role: worker
- role: worker
- role: worker
</span><span class="no">EOF
</span><span class="c"># =&gt; Creating cluster "myk8s" ...</span>
<span class="c">#     ✓ Ensuring node image (kindest/node:v1.32.2) 🖼</span>
<span class="c">#     ✓ Preparing nodes 📦 📦 📦 📦</span>
<span class="c">#     ✓ Writing configuration 📜</span>
<span class="c">#     ✓ Starting control-plane 🕹️</span>
<span class="c">#     ✓ Installing CNI 🔌</span>
<span class="c">#     ✓ Installing StorageClass 💾</span>
<span class="c">#     ✓ Joining worker nodes 🚜</span>
<span class="c">#    Set kubectl context to "kind-myk8s"</span>
<span class="c">#    You can now use your cluster with:</span>
<span class="c">#    </span>
<span class="c">#    kubectl cluster-info --context kind-myk8s</span>
<span class="c">#    Have a nice day! 👋</span>
  
<span class="c"># 확인</span>
<span class="nv">$ </span>kind get nodes <span class="nt">--name</span> myk8s
<span class="c"># =&gt; myk8s-worker3</span>
<span class="c">#    myk8s-worker2</span>
<span class="c">#    myk8s-control-plane</span>
<span class="c">#    myk8s-worker</span>
<span class="nv">$ </span>kubens default
<span class="c"># =&gt; Context "kind-myk8s" modified.</span>
<span class="c">#    Active namespace is "default".</span>
  
<span class="c"># kind 는 별도 도커 네트워크 생성 후 사용 : 기본값 172.20.0.0/16</span>
<span class="nv">$ </span>docker network <span class="nb">ls</span>
<span class="c"># =&gt; NETWORK ID     NAME                         DRIVER    SCOPE</span>
<span class="c">#    db5d49a84cd0   bridge                       bridge    local</span>
<span class="c">#    8204a0851463   host                         host      local</span>
<span class="c">#    &lt;span style="color: green;"&gt;3bbcc6aa8f38   kind&lt;/span&gt;                         bridge    local</span>
<span class="nv">$ </span>docker inspect kind | jq
<span class="c"># =&gt; ...</span>
<span class="c">#        "IPAM": {</span>
<span class="c">#          "Config": [</span>
<span class="c">#            {</span>
<span class="c">#              "Subnet": "172.20.0.0/16",</span>
<span class="c">#              "Gateway": "172.20.0.1"</span>
<span class="c">#    ...</span>
<span class="c"># k8s api 주소 확인 : 어떻게 로컬에서 접속이 되는 걸까요?</span>
<span class="nv">$ </span>kubectl cluster-info
<span class="c"># =&gt; Kubernetes control plane is running at &lt;span style="color: green;"&gt;https://127.0.0.1:57349&lt;/span&gt;</span>
<span class="c">#    CoreDNS is running at https://127.0.0.1:57349/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</span>
<span class="c">#    </span>
<span class="c">#    To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.</span>
  
<span class="c"># 노드 정보 확인 : CRI 는 containerd 사용</span>
<span class="nv">$ </span>kubectl get node <span class="nt">-o</span> wide
<span class="c"># =&gt; NAME                  STATUS   ROLES           AGE     VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE                         KERNEL-VERSION     CONTAINER-RUNTIME</span>
<span class="c">#    myk8s-control-plane   Ready    control-plane   3m36s   v1.32.2   172.20.0.5    &lt;none&gt;        Debian GNU/Linux 12 (bookworm)   5.10.76-linuxkit   containerd://2.0.3</span>
<span class="c">#    myk8s-worker          Ready    &lt;none&gt;          3m26s   v1.32.2   172.20.0.2    &lt;none&gt;        Debian GNU/Linux 12 (bookworm)   5.10.76-linuxkit   containerd://2.0.3</span>
<span class="c">#    myk8s-worker2         Ready    &lt;none&gt;          3m26s   v1.32.2   172.20.0.3    &lt;none&gt;        Debian GNU/Linux 12 (bookworm)   5.10.76-linuxkit   containerd://2.0.3</span>
<span class="c">#    myk8s-worker3         Ready    &lt;none&gt;          3m26s   v1.32.2   172.20.0.4    &lt;none&gt;        Debian GNU/Linux 12 (bookworm)   5.10.76-linuxkit   containerd://2.0.3</span>
  
<span class="c"># 파드 정보 확인 : CNI 는 kindnet 사용</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-A</span> <span class="nt">-o</span> wide
<span class="c"># =&gt; NAMESPACE            NAME                                          READY   STATUS    RESTARTS   AGE     IP           NODE                  NOMINATED NODE   READINESS GATES</span>
<span class="c">#    kube-system          coredns-668d6bf9bc-2d5fq                      1/1     Running   0          3m37s   10.244.0.3   myk8s-control-plane   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          coredns-668d6bf9bc-f8vg2                      1/1     Running   0          3m37s   10.244.0.4   myk8s-control-plane   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          etcd-myk8s-control-plane                      1/1     Running   0          3m45s   172.20.0.5   myk8s-control-plane   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          &lt;span style="color: green;"&gt;kindnet-b47qh&lt;/span&gt;                                 1/1     Running   0          3m36s   172.20.0.2   myk8s-worker          &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          &lt;span style="color: green;"&gt;kindnet-fx7pl&lt;/span&gt;                                 1/1     Running   0          3m38s   172.20.0.5   myk8s-control-plane   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          &lt;span style="color: green;"&gt;kindnet-jr9g8&lt;/span&gt;                                 1/1     Running   0          3m36s   172.20.0.4   myk8s-worker3         &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          &lt;span style="color: green;"&gt;kindnet-sck5c&lt;/span&gt;                                 1/1     Running   0          3m36s   172.20.0.3   myk8s-worker2         &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          kube-apiserver-myk8s-control-plane            1/1     Running   0          3m45s   172.20.0.5   myk8s-control-plane   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          kube-controller-manager-myk8s-control-plane   1/1     Running   0          3m45s   172.20.0.5   myk8s-control-plane   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          kube-proxy-5vlx4                              1/1     Running   0          3m36s   172.20.0.4   myk8s-worker3         &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          kube-proxy-8kz4j                              1/1     Running   0          3m36s   172.20.0.3   myk8s-worker2         &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          kube-proxy-rlnwn                              1/1     Running   0          3m37s   172.20.0.5   myk8s-control-plane   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          kube-proxy-znszc                              1/1     Running   0          3m36s   172.20.0.2   myk8s-worker          &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          kube-scheduler-myk8s-control-plane            1/1     Running   0          3m45s   172.20.0.5   myk8s-control-plane   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    local-path-storage   local-path-provisioner-7dc846544d-h5xp6       1/1     Running   0          3m37s   10.244.0.2   myk8s-control-plane   &lt;none&gt;           &lt;none&gt;</span>
  
<span class="c"># 네임스페이스 확인 &gt;&gt; 도커 컨테이너에서 배운 네임스페이스와 다릅니다!</span>
<span class="nv">$ </span>kubectl get namespaces
<span class="c"># =&gt; NAME                 STATUS   AGE</span>
<span class="c">#    default              Active   5m31s</span>
<span class="c">#    kube-node-lease      Active   5m31s</span>
<span class="c">#    kube-public          Active   5m31s</span>
<span class="c">#    kube-system          Active   5m31s</span>
<span class="c">#    local-path-storage   Active   5m23s</span>
  
<span class="c"># 컨트롤플레인/워커 노드(컨테이너) 확인 : 도커 컨테이너 이름은 myk8s-control-plane , myk8s-worker/2/3 임을 확인</span>
<span class="nv">$ </span>docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE                  COMMAND                  CREATED         STATUS         PORTS                                                             NAMES</span>
<span class="c">#    98bc90974283   kindest/node:v1.32.2   "/usr/local/bin/entr…"   6 minutes ago   Up 5 minutes                                                                     myk8s-worker3</span>
<span class="c">#    4bf34678cbed   kindest/node:v1.32.2   "/usr/local/bin/entr…"   6 minutes ago   Up 5 minutes                                                                     myk8s-worker2</span>
<span class="c">#    f85eef8fcd53   kindest/node:v1.32.2   "/usr/local/bin/entr…"   6 minutes ago   Up 5 minutes   0.0.0.0:30000-30003-&gt;30000-30003/tcp, 127.0.0.1:57349-&gt;6443/tcp   myk8s-control-plane</span>
<span class="c">#    1f27bfafc1ac   kindest/node:v1.32.2   "/usr/local/bin/entr…"   6 minutes ago   Up 5 minutes                                                                     myk8s-worker</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 controlplane의 API 서버(6443/tcp)를 host의 57349포트로 포트포워딩 하고 &lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   kubectl cluster-info에서 확인한것 처럼 kubectl 사용시 127.0.0.1:57349로 접속이 되기 때문에&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   host에서 kubectl로 접속이 가능하게 됩니다.&lt;/span&gt;</span>
<span class="nv">$ </span>docker images
<span class="c"># =&gt; REPOSITORY                                        TAG                                        IMAGE ID       CREATED         SIZE</span>
<span class="c">#    kindest/node                                      &lt;none&gt;                                     071dd73121e8   2 months ago    1.09GB</span>
<span class="c">#    kindest/node                                      &lt;span style="color: green;"&gt;v1.32.2&lt;/span&gt;                                    b5193db9db63   5 months ago    1.06GB</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 클러스터 설치시 버전을 1.32.2로 지정했기 때문에 kindest/node:v1.32.2 이미지가 다운로드된 것을 확인할 수 있습니다.&lt;/span&gt;</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane ss <span class="nt">-tnlp</span>
<span class="c"># =&gt; State              Recv-Q             Send-Q                           Local Address:Port                            Peer Address:Port             Process</span>
<span class="c">#    LISTEN             0                  4096                                 127.0.0.1:10257                                0.0.0.0:*                 users:(("kube-controller",pid=584,fd=3))</span>
<span class="c">#    LISTEN             0                  4096                                 127.0.0.1:10259                                0.0.0.0:*                 users:(("kube-scheduler",pid=522,fd=3))</span>
<span class="c">#    LISTEN             0                  4096                                 127.0.0.1:34873                                0.0.0.0:*                 users:(("containerd",pid=105,fd=11))</span>
<span class="c">#    LISTEN             0                  4096                                 127.0.0.1:10248                                0.0.0.0:*                 users:(("kubelet",pid=705,fd=17))</span>
<span class="c">#    LISTEN             0                  4096                                 127.0.0.1:10249                                0.0.0.0:*                 users:(("kube-proxy",pid=890,fd=12))</span>
<span class="c">#    LISTEN             0                  4096                                172.20.0.5:2379                                 0.0.0.0:*                 users:(("etcd",pid=646,fd=9))</span>
<span class="c">#    LISTEN             0                  4096                                 127.0.0.1:2379                                 0.0.0.0:*                 users:(("etcd",pid=646,fd=8))</span>
<span class="c">#    LISTEN             0                  4096                                172.20.0.5:2380                                 0.0.0.0:*                 users:(("etcd",pid=646,fd=7))</span>
<span class="c">#    LISTEN             0                  4096                                 127.0.0.1:2381                                 0.0.0.0:*                 users:(("etcd",pid=646,fd=13))</span>
<span class="c">#    LISTEN             0                  1024                                127.0.0.11:38253                                0.0.0.0:*</span>
<span class="c">#    LISTEN             0                  4096                                         *:10250                                      *:*                 users:(("kubelet",pid=705,fd=11))</span>
<span class="c">#    LISTEN             0                  4096                                         &lt;span style="color: green;"&gt;*:6443&lt;/span&gt;                                       *:*                 users:(("kube-apiserver",pid=562,fd=3))</span>
<span class="c">#    LISTEN             0                  4096                                         *:10256                                      *:*                 users:(("kube-proxy",pid=890,fd=10))</span>
  
<span class="c"># 디버그용 내용 출력에 ~/.kube/config 권한 인증 로드</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-v6</span>
<span class="c"># =&gt; I0816 17:31:00.340008   21457 loader.go:402] &lt;span style="color: green;"&gt;Config loaded from file:  /Users/anonym/.kube/config&lt;/span&gt;</span>
<span class="c">#    I0816 17:31:00.342176   21457 envvar.go:172] "Feature gate default state" feature="ClientsAllowCBOR" enabled=false</span>
<span class="c">#    I0816 17:31:00.342185   21457 envvar.go:172] "Feature gate default state" feature="ClientsPreferCBOR" enabled=false</span>
<span class="c">#    I0816 17:31:00.342188   21457 envvar.go:172] "Feature gate default state" feature="InformerResourceVersion" enabled=false</span>
<span class="c">#    I0816 17:31:00.342190   21457 envvar.go:172] "Feature gate default state" feature="InOrderInformers" enabled=true</span>
<span class="c">#    I0816 17:31:00.342212   21457 envvar.go:172] "Feature gate default state" feature="WatchListClient" enabled=false</span>
<span class="c">#    I0816 17:31:00.378209   21457 round_trippers.go:632] "Response" verb="GET" url="https://127.0.0.1:57349/api/v1/namespaces/default/pods?limit=500" status="200 OK" milliseconds=29</span>
<span class="c">#    No resources found in default namespace.</span>
  
<span class="c"># kube config 파일 확인</span>
<span class="nv">$ </span><span class="nb">cat</span> ~/.kube/config
<span class="c"># 혹은</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="nv">$KUBECONFIG</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 kind-myk8s 클러스터 관련 항목이 추가된 것을 확인할 수 있습니다.&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   또한 current-context: kind-myk8s여서 kubectl 명령어를 실행하면 kind-myk8s 클러스터에 연결되어 실행됩니다.&lt;/span&gt;</span>
</code></pre></div>    </div>
  </li>
  <li>Kind 클러스터 삭제
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 클러스터 삭제</span>
<span class="nv">$ </span>kind delete cluster <span class="nt">--name</span> myk8s
<span class="c"># =&gt; Deleting cluster "myk8s" ...</span>
<span class="c">#    Deleted nodes: ["myk8s-worker3" "myk8s-worker2" "myk8s-control-plane" "myk8s-worker"]</span>
<span class="nv">$ </span>docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES</span>
<span class="nv">$ </span><span class="nb">cat</span> ~/.kube/config
</code></pre></div>    </div>
  </li>
</ul>

<hr />

<h2 id="cluster-mesh">Cluster Mesh</h2>

<blockquote>
  <p>현재 1.18 버전의 ClusterMesh 분산 동작에 이상이 있는것 같아서, 1.17.6 버전으로 실습을 진행하겠습니다.</p>
</blockquote>

<ul>
  <li>Cluster Mesh는 Cilium의 기능 중 하나로, 여러 Kubernetes 클러스터를 연결하여 네트워크를 확장할 수 있는 기능입니다.</li>
</ul>

<h4 id="kind-k8s-클러스터-west-east-배포">kind k8s 클러스터 west, east 배포</h4>

<ul>
  <li><a href="https://docs.cilium.io/en/latest/installation/kind/">관련 문서</a></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># west 클러스터를 먼저 배포합니다.</span>
<span class="nv">$ </span>kind create cluster <span class="nt">--name</span> west <span class="nt">--image</span> kindest/node:v1.33.2 <span class="nt">--config</span> - <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
  extraPortMappings:
  - containerPort: 30000 # sample apps
    hostPort: 30000
  - containerPort: 30001 # hubble ui
    hostPort: 30001
- role: worker
  extraPortMappings:
  - containerPort: 30002 # sample apps
    hostPort: 30002
networking:
  podSubnet: "10.0.0.0/16"
  serviceSubnet: "10.2.0.0/16"
  disableDefaultCNI: true
  kubeProxyMode: none
</span><span class="no">EOF
</span><span class="c"># =&gt; Creating cluster "west" ...</span>
<span class="c">#     ✓ Ensuring node image (kindest/node:v1.33.2) 🖼</span>
<span class="c">#     ✓ Preparing nodes 📦 📦</span>
<span class="c">#     ✓ Writing configuration 📜</span>
<span class="c">#     ✓ Starting control-plane 🕹️</span>
<span class="c">#     ✓ Installing StorageClass 💾</span>
<span class="c">#     ✓ Joining worker nodes 🚜</span>
<span class="c">#    Set kubectl context to "kind-west"</span>
<span class="c">#    You can now use your cluster with:</span>
<span class="c">#    </span>
<span class="c">#    kubectl cluster-info --context kind-west</span>
<span class="c">#    </span>
<span class="c">#    Have a nice day! 👋</span>

<span class="c"># 설치 확인</span>
<span class="nv">$ </span>kubectl ctx
<span class="c"># =&gt;   kind-west</span>
<span class="nv">$ </span>kubectl get node 
<span class="c"># =&gt; NAME                 STATUS     ROLES           AGE   VERSION</span>
<span class="c">#    west-control-plane   NotReady   control-plane   75s   v1.33.2</span>
<span class="c">#    west-worker          NotReady   &lt;none&gt;          64s   v1.33.2</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE            NAME                                         READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    kube-system          coredns-674b8bbfcf-5zmlc                     &lt;span style="color: green;"&gt;0/1&lt;/span&gt;     Pending   0          86s</span>
<span class="c">#    kube-system          coredns-674b8bbfcf-b72sk                     &lt;span style="color: green;"&gt;0/1&lt;/span&gt;     Pending   0          86s</span>
<span class="c">#    kube-system          etcd-west-control-plane                      1/1     Running   0          93s</span>
<span class="c">#    kube-system          kube-apiserver-west-control-plane            1/1     Running   0          93s</span>
<span class="c">#    kube-system          kube-controller-manager-west-control-plane   1/1     Running   0          93s</span>
<span class="c">#    kube-system          kube-scheduler-west-control-plane            1/1     Running   0          93s</span>
<span class="c">#    local-path-storage   local-path-provisioner-7dc846544d-vlh7b      &lt;span style="color: green;"&gt;0/1&lt;/span&gt;     Pending   0          86s</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 Cilium 설치를 위해 disableDefaultCNI: true를 지정했기 때문에, CNI가 설치되지 않았고 일부 파드가 Pending 상태입니다.&lt;/span&gt;</span>

<span class="c"># 노드에 기본 툴 설치</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> west-control-plane sh <span class="nt">-c</span> <span class="s1">'apt update &amp;&amp; apt install tree psmisc lsof wget net-tools dnsutils tcpdump ngrep iputils-ping git -y'</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> west-worker sh <span class="nt">-c</span> <span class="s1">'apt update &amp;&amp; apt install tree psmisc lsof wget net-tools dnsutils tcpdump ngrep iputils-ping git -y'</span>

<span class="c"># 이어서 east 클러스터를 배포합니다.</span>
<span class="nv">$ </span>kind create cluster <span class="nt">--name</span> east <span class="nt">--image</span> kindest/node:v1.33.2 <span class="nt">--config</span> - <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
  extraPortMappings:
  - containerPort: 31000 # sample apps
    hostPort: 31000
  - containerPort: 31001 # hubble ui
    hostPort: 31001
- role: worker
  extraPortMappings:
  - containerPort: 31002 # sample apps
    hostPort: 31002
networking:
  podSubnet: "10.1.0.0/16"
  serviceSubnet: "10.3.0.0/16"
  disableDefaultCNI: true
  kubeProxyMode: none
</span><span class="no">EOF
</span><span class="c"># =&gt; Creating cluster "east" ...</span>
<span class="c">#     ✓ Ensuring node image (kindest/node:v1.33.2) 🖼</span>
<span class="c">#     ✓ Preparing nodes 📦 📦</span>
<span class="c">#     ✓ Writing configuration 📜</span>
<span class="c">#     ✓ Starting control-plane 🕹️</span>
<span class="c">#     ✓ Installing StorageClass 💾</span>
<span class="c">#     ✓ Joining worker nodes 🚜</span>
<span class="c">#    Set kubectl context to "kind-east"</span>
<span class="c">#    You can now use your cluster with:</span>
<span class="c">#    </span>
<span class="c">#    kubectl cluster-info --context kind-east</span>
<span class="c">#    </span>
<span class="c">#    Have a nice day! 👋</span>

<span class="c"># 설치 확인</span>
<span class="nv">$ </span>kubectl config get-contexts 
<span class="c"># =&gt; CURRENT   NAME         CLUSTER     AUTHINFO    NAMESPACE</span>
<span class="c">#    *         kind-east    kind-east   kind-east</span>
<span class="c">#              kind-west    kind-west   kind-west</span>

<span class="c"># 기본 context를 kind-east로 변경</span>
<span class="nv">$ </span>kubectl config set-context kind-east
<span class="c"># =&gt; Context "kind-east" modified.</span>

<span class="nv">$ </span>kubectl get node <span class="nt">-v</span><span class="o">=</span>6 <span class="nt">--context</span> kind-east
<span class="c"># &lt;span style="color: green;"&gt;👉 kind-east 클러스터의 노드 정보가 출력됩니다.&lt;/span&gt;</span>
<span class="nv">$ </span>kubectl get node <span class="nt">-v</span><span class="o">=</span>6
<span class="c"># &lt;span style="color: green;"&gt;👉 기본 컨텍스트가 kind-east이기 때문에 kind-east 클러스터의 노드 정보가 출력됩니다.&lt;/span&gt;</span>
<span class="nv">$ </span>kubectl get node <span class="nt">-v</span><span class="o">=</span>6 <span class="nt">--context</span> kind-west
<span class="c"># &lt;span style="color: green;"&gt;👉 명시적으로 kind-west 컨텍스르틀 지정하여 west 클러스터의 노드 정보가 출력됩니다.&lt;/span&gt;</span>
<span class="nv">$ </span><span class="nb">cat</span> ~/.kube/config

<span class="nv">$ </span>kubectl get pod <span class="nt">-A</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 kind-east 클러스터의 파드 정보가 출력됩니다.&lt;/span&gt;</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-A</span> <span class="nt">--context</span> kind-west
<span class="c"># &lt;span style="color: green;"&gt;👉 명시적으로 kind-west 컨텍스트를 지정하여 west 클러스터의 파드 정보가 출력됩니다.&lt;/span&gt;</span>

<span class="c"># 노드에 기본 툴 설치</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> east-control-plane sh <span class="nt">-c</span> <span class="s1">'apt update &amp;&amp; apt install tree psmisc lsof wget net-tools dnsutils tcpdump ngrep iputils-ping git -y'</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> east-worker sh <span class="nt">-c</span> <span class="s1">'apt update &amp;&amp; apt install tree psmisc lsof wget net-tools dnsutils tcpdump ngrep iputils-ping git -y'</span>
</code></pre></div></div>

<ul>
  <li>alias 설정</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># alias 설정</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">kwest</span><span class="o">=</span><span class="s1">'kubectl --context kind-west'</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">keast</span><span class="o">=</span><span class="s1">'kubectl --context kind-east'</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kwest get node <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                 STATUS     ROLES           AGE     VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE                         KERNEL-VERSION     CONTAINER-RUNTIME</span>
<span class="c">#    west-control-plane   NotReady   control-plane   2m57s   v1.33.2   172.20.0.4    &lt;none&gt;        Debian GNU/Linux 12 (bookworm)   5.10.76-linuxkit   containerd://2.1.3</span>
<span class="c">#    west-worker          NotReady   &lt;none&gt;          2m45s   v1.33.2   172.20.0.2    &lt;none&gt;        Debian GNU/Linux 12 (bookworm)   5.10.76-linuxkit   containerd://2.1.3</span>
<span class="nv">$ </span>keast get node <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                 STATUS     ROLES           AGE     VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE                         KERNEL-VERSION     CONTAINER-RUNTIME</span>
<span class="c">#    east-control-plane   NotReady   control-plane   9m45s   v1.33.2   172.20.0.5    &lt;none&gt;        Debian GNU/Linux 12 (bookworm)   5.10.76-linuxkit   containerd://2.1.3</span>
<span class="c">#    east-worker          NotReady   &lt;none&gt;          9m32s   v1.33.2   172.20.0.3    &lt;none&gt;        Debian GNU/Linux 12 (bookworm)   5.10.76-linuxkit   containerd://2.1.3</span>
</code></pre></div></div>

<h3 id="cilium-cni-배포">Cilium CNI 배포</h3>

<ul>
  <li>Cilium CNI의 ClusterMesh 기능을 사용하기 위해 먼저 Cilium CNI를 배포합니다. <a href="https://docs.cilium.io/en/stable/network/clustermesh/clustermesh/">Docs</a>, <a href="https://nomadxd.github.io/blog/multi-cluster-networking-with-cilium-cluster-mesh">Blog</a></li>
  <li>이번에는 Cilium CLI를 사용하여 Cilium CNI를 배포해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># cilium cli 설치</span>
<span class="nv">$ </span>brew <span class="nb">install </span>cilium-cli <span class="c"># macOS</span>

<span class="c">## https://docs.cilium.io/en/stable/gettingstarted/k8s-install-default/#install-the-cilium-cli # Windwos WSL2 , 아래 명령어로 설치</span>
<span class="c">#$ CILIUM_CLI_VERSION=$(curl -s https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt)</span>
<span class="c">#$ CLI_ARCH=amd64</span>
<span class="c">#$ if [ "$(uname -m)" = "aarch64" ]; then CLI_ARCH=arm64; fi</span>
<span class="c">#$ curl -L --fail --remote-name-all https://github.com/cilium/cilium-cli/releases/download/${CILIUM_CLI_VERSION}/cilium-linux-${CLI_ARCH}.tar.gz{,.sha256sum}</span>
<span class="c">#$ sha256sum --check cilium-linux-${CLI_ARCH}.tar.gz.sha256sum</span>
<span class="c">#$ sudo tar xzvfC cilium-linux-${CLI_ARCH}.tar.gz /usr/local/bin</span>
<span class="c">#$ rm cilium-linux-${CLI_ARCH}.tar.gz{,.sha256sum}</span>

<span class="c"># cilium cli 로 cilium cni 설치해보기 : dry-run</span>
<span class="nv">$ </span>cilium <span class="nb">install</span> <span class="nt">--version</span> 1.17.6 <span class="nt">--set</span> ipam.mode<span class="o">=</span>kubernetes <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">kubeProxyReplacement</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> bpf.masquerade<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> endpointHealthChecking.enabled<span class="o">=</span><span class="nb">false</span> <span class="nt">--set</span> <span class="nv">healthChecking</span><span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
  <span class="nt">--set</span> operator.replicas<span class="o">=</span>1 <span class="nt">--set</span> debug.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">routingMode</span><span class="o">=</span>native <span class="nt">--set</span> <span class="nv">autoDirectNodeRoutes</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> <span class="nv">ipv4NativeRoutingCIDR</span><span class="o">=</span>10.0.0.0/16 <span class="se">\</span>
  <span class="nt">--set</span> ipMasqAgent.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> ipMasqAgent.config.nonMasqueradeCIDRs<span class="o">=</span><span class="s1">'{10.1.0.0/16}'</span> <span class="se">\</span>
  <span class="nt">--set</span> cluster.name<span class="o">=</span>west <span class="nt">--set</span> cluster.id<span class="o">=</span>1 <span class="se">\</span>
  <span class="nt">--context</span> kind-west <span class="nt">--dry-run-helm-values</span>
<span class="c"># =&gt; autoDirectNodeRoutes: true</span>
<span class="c">#    bpf:</span>
<span class="c">#      masquerade: true</span>
<span class="c">#    cluster:</span>
<span class="c">#      id: 1</span>
<span class="c">#      name: west</span>
<span class="c">#    debug:</span>
<span class="c">#      enabled: true</span>
<span class="c">#    endpointHealthChecking:</span>
<span class="c">#      enabled: false</span>
<span class="c">#    healthChecking: false</span>
<span class="c">#    ipMasqAgent:</span>
<span class="c">#      config:</span>
<span class="c">#        nonMasqueradeCIDRs:</span>
<span class="c">#        - 10.1.0.0/16</span>
<span class="c">#      enabled: true</span>
<span class="c">#    ipam:</span>
<span class="c">#      mode: kubernetes</span>
<span class="c">#    ipv4NativeRoutingCIDR: 10.0.0.0/16</span>
<span class="c">#    k8sServiceHost: 172.20.0.4</span>
<span class="c">#    k8sServicePort: 6443</span>
<span class="c">#    kubeProxyReplacement: true</span>
<span class="c">#    operator:</span>
<span class="c">#      replicas: 1</span>
<span class="c">#    routingMode: native  </span>

<span class="c"># cilium cli 로 cilium cni 설치</span>
<span class="nv">$ </span>cilium <span class="nb">install</span> <span class="nt">--version</span> 1.17.6 <span class="nt">--set</span> ipam.mode<span class="o">=</span>kubernetes <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">kubeProxyReplacement</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> bpf.masquerade<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> endpointHealthChecking.enabled<span class="o">=</span><span class="nb">false</span> <span class="nt">--set</span> <span class="nv">healthChecking</span><span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
  <span class="nt">--set</span> operator.replicas<span class="o">=</span>1 <span class="nt">--set</span> debug.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">routingMode</span><span class="o">=</span>native <span class="nt">--set</span> <span class="nv">autoDirectNodeRoutes</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> <span class="nv">ipv4NativeRoutingCIDR</span><span class="o">=</span>10.0.0.0/16 <span class="se">\</span>
  <span class="nt">--set</span> ipMasqAgent.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> ipMasqAgent.config.nonMasqueradeCIDRs<span class="o">=</span><span class="s1">'{10.1.0.0/16}'</span> <span class="se">\</span>
  <span class="nt">--set</span> cluster.name<span class="o">=</span>west <span class="nt">--set</span> cluster.id<span class="o">=</span>1 <span class="se">\</span>
  <span class="nt">--context</span> kind-west
<span class="c"># =&gt; 🔮 Auto-detected Kubernetes kind: kind</span>
<span class="c">#    ℹ️   Using Cilium version 1.17.6</span>
<span class="c">#    ℹ️   Using cluster name "west"</span>
<span class="c">#    ℹ️   Detecting real Kubernetes API server addr and port on Kind</span>
<span class="c">#    🔮 Auto-detected kube-proxy has not been installed</span>
<span class="c">#    ℹ️   Cilium will fully replace all functionalities of kube-proxy  </span>

<span class="nv">$ </span>watch kubectl get pod <span class="nt">-n</span> kube-system <span class="nt">--context</span> kind-west


<span class="c"># dry-run</span>
<span class="nv">$ </span>cilium <span class="nb">install</span> <span class="nt">--version</span> 1.17.6 <span class="nt">--set</span> ipam.mode<span class="o">=</span>kubernetes <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">kubeProxyReplacement</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> bpf.masquerade<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> endpointHealthChecking.enabled<span class="o">=</span><span class="nb">false</span> <span class="nt">--set</span> <span class="nv">healthChecking</span><span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
  <span class="nt">--set</span> operator.replicas<span class="o">=</span>1 <span class="nt">--set</span> debug.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">routingMode</span><span class="o">=</span>native <span class="nt">--set</span> <span class="nv">autoDirectNodeRoutes</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> <span class="nv">ipv4NativeRoutingCIDR</span><span class="o">=</span>10.1.0.0/16 <span class="se">\</span>
  <span class="nt">--set</span> ipMasqAgent.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> ipMasqAgent.config.nonMasqueradeCIDRs<span class="o">=</span><span class="s1">'{10.0.0.0/16}'</span> <span class="se">\</span>
  <span class="nt">--set</span> cluster.name<span class="o">=</span>east <span class="nt">--set</span> cluster.id<span class="o">=</span>2 <span class="se">\</span>
  <span class="nt">--context</span> kind-east <span class="nt">--dry-run-helm-values</span>

<span class="nv">$ </span>cilium <span class="nb">install</span> <span class="nt">--version</span> 1.17.6 <span class="nt">--set</span> ipam.mode<span class="o">=</span>kubernetes <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">kubeProxyReplacement</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> bpf.masquerade<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> endpointHealthChecking.enabled<span class="o">=</span><span class="nb">false</span> <span class="nt">--set</span> <span class="nv">healthChecking</span><span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
  <span class="nt">--set</span> operator.replicas<span class="o">=</span>1 <span class="nt">--set</span> debug.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">routingMode</span><span class="o">=</span>native <span class="nt">--set</span> <span class="nv">autoDirectNodeRoutes</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> <span class="nv">ipv4NativeRoutingCIDR</span><span class="o">=</span>10.1.0.0/16 <span class="se">\</span>
  <span class="nt">--set</span> ipMasqAgent.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> ipMasqAgent.config.nonMasqueradeCIDRs<span class="o">=</span><span class="s1">'{10.0.0.0/16}'</span> <span class="se">\</span>
  <span class="nt">--set</span> cluster.name<span class="o">=</span>east <span class="nt">--set</span> cluster.id<span class="o">=</span>2 <span class="se">\</span>
  <span class="nt">--context</span> kind-east
<span class="c"># =&gt; 🔮 Auto-detected Kubernetes kind: kind</span>
<span class="c">#    ℹ️  Using Cilium version 1.17.6</span>
<span class="c">#    ℹ️  Using cluster name "east"</span>
<span class="c">#    ℹ️  Detecting real Kubernetes API server addr and port on Kind</span>
<span class="c">#    🔮 Auto-detected kube-proxy has not been installed</span>
<span class="c">#    ℹ️  Cilium will fully replace all functionalities of kube-proxy</span>

<span class="nv">$ </span>watch kubectl get pod <span class="nt">-n</span> kube-system <span class="nt">--context</span> kind-east

<span class="c"># 확인</span>
<span class="nv">$ </span>kwest get pod <span class="nt">-A</span> <span class="o">&amp;&amp;</span> keast get pod <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE            NAME                                         READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    kube-system          cilium-8tblx                                 1/1     Running   0          4m55s</span>
<span class="c">#    kube-system          cilium-envoy-f9wd9                           1/1     Running   0          4m55s</span>
<span class="c">#    kube-system          cilium-envoy-fvthm                           1/1     Running   0          4m55s</span>
<span class="c">#    kube-system          cilium-fsnxx                                 1/1     Running   0          4m55s</span>
<span class="c">#    kube-system          cilium-operator-7d99d97595-wdt52             1/1     Running   0          4m55s</span>
<span class="c">#    kube-system          coredns-674b8bbfcf-85kzg                     1/1     Running   0          3h2m</span>
<span class="c">#    kube-system          coredns-674b8bbfcf-cf7xm                     1/1     Running   0          3h2m</span>
<span class="c">#    kube-system          etcd-west-control-plane                      1/1     Running   0          3h2m</span>
<span class="c">#    kube-system          kube-apiserver-west-control-plane            1/1     Running   0          3h2m</span>
<span class="c">#    kube-system          kube-controller-manager-west-control-plane   1/1     Running   0          3h2m</span>
<span class="c">#    kube-system          kube-scheduler-west-control-plane            1/1     Running   0          3h2m</span>
<span class="c">#    local-path-storage   local-path-provisioner-7dc846544d-t968t      1/1     Running   0          3h2m</span>
<span class="c">#    NAMESPACE            NAME                                         READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    kube-system          cilium-envoy-25kb6                           1/1     Running   0          4m7s</span>
<span class="c">#    kube-system          cilium-envoy-xmxkx                           1/1     Running   0          4m7s</span>
<span class="c">#    kube-system          cilium-gvcf9                                 1/1     Running   0          4m7s</span>
<span class="c">#    kube-system          cilium-operator-6d9fc44d58-8xmkb             1/1     Running   0          4m7s</span>
<span class="c">#    kube-system          cilium-w547m                                 1/1     Running   0          4m7s</span>
<span class="c">#    kube-system          coredns-674b8bbfcf-s6bdx                     1/1     Running   0          3h9m</span>
<span class="c">#    kube-system          coredns-674b8bbfcf-sb52k                     1/1     Running   0          3h9m</span>
<span class="c">#    kube-system          etcd-east-control-plane                      1/1     Running   0          3h9m</span>
<span class="c">#    kube-system          kube-apiserver-east-control-plane            1/1     Running   0          3h9m</span>
<span class="c">#    kube-system          kube-controller-manager-east-control-plane   1/1     Running   0          3h9m</span>
<span class="c">#    kube-system          kube-scheduler-east-control-plane            1/1     Running   0          3h9m</span>
<span class="c">#    local-path-storage   local-path-provisioner-7dc846544d-m7trp      1/1     Running   0          3h9m</span>
<span class="nv">$ </span>cilium status <span class="nt">--context</span> kind-west
<span class="nv">$ </span>cilium status <span class="nt">--context</span> kind-east
<span class="nv">$ </span>cilium config view <span class="nt">--context</span> kind-west
<span class="nv">$ </span>cilium config view <span class="nt">--context</span> kind-east
<span class="nv">$ </span>kwest <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium status <span class="nt">--verbose</span>
<span class="nv">$ </span>keast <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium status <span class="nt">--verbose</span>

<span class="nv">$ </span>kwest <span class="nt">-n</span> kube-system <span class="nb">exec </span>ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium-dbg bpf ipmasq list
<span class="c"># =&gt; IP PREFIX/ADDRESS</span>
<span class="c">#    169.254.0.0/16</span>
<span class="c">#    10.1.0.0/16</span>
<span class="nv">$ </span>keast <span class="nt">-n</span> kube-system <span class="nb">exec </span>ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium-dbg bpf ipmasq list
<span class="c"># =&gt; IP PREFIX/ADDRESS</span>
<span class="c">#    169.254.0.0/16</span>
<span class="c">#    10.0.0.0/16</span>

<span class="c"># coredns 확인 : 둘 다, cluster.local 기본 도메인 네임 사용 중</span>
<span class="nv">$ </span>kubectl describe cm <span class="nt">-n</span> kube-system coredns <span class="nt">--context</span> kind-west | <span class="nb">grep </span>kubernetes
<span class="c"># =&gt;     kubernetes cluster.local in-addr.arpa ip6.arpa {</span>

<span class="nv">$ </span>kubectl describe cm <span class="nt">-n</span> kube-system coredns <span class="nt">--context</span> kind-west | <span class="nb">grep </span>kubernetes
<span class="c"># =&gt;     kubernetes cluster.local in-addr.arpa ip6.arpa {</span>

<span class="c"># k9s 사용 시</span>
<span class="nv">$ </span>k9s <span class="nt">--context</span> kind-west
<span class="nv">$ </span>k9s <span class="nt">--context</span> kind-east

<span class="c"># 삭제 시</span>
<span class="c"># cilium uninstall --context kind-west</span>
<span class="c"># cilium uninstall --context kind-east</span>
</code></pre></div></div>

<h3 id="clustermesh-배포">ClusterMesh 배포</h3>

<ul>
  <li><a href="https://docs.cilium.io/en/stable/network/clustermesh/clustermesh/">관련문서</a></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 라우팅 정보 확인</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> west-control-plane ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 172.20.0.1 dev eth0</span>
<span class="c">#    10.0.0.0/24 via 10.0.0.175 dev cilium_host proto kernel src 10.0.0.175</span>
<span class="c">#    10.0.0.175 dev cilium_host proto kernel scope link</span>
<span class="c">#    10.0.1.0/24 via 172.20.0.2 dev eth0 proto kernel</span>
<span class="c">#    172.20.0.0/16 dev eth0 proto kernel scope link src 172.20.0.4</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> west-worker ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 172.20.0.1 dev eth0</span>
<span class="c">#    10.0.0.0/24 via 172.20.0.4 dev eth0 proto kernel</span>
<span class="c">#    10.0.1.0/24 via 10.0.1.10 dev cilium_host proto kernel src 10.0.1.10</span>
<span class="c">#    10.0.1.10 dev cilium_host proto kernel scope link</span>
<span class="c">#    172.20.0.0/16 dev eth0 proto kernel scope link src 172.20.0.2</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> east-control-plane ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 172.20.0.1 dev eth0</span>
<span class="c">#    10.1.0.0/24 via 10.1.0.80 dev cilium_host proto kernel src 10.1.0.80</span>
<span class="c">#    10.1.0.80 dev cilium_host proto kernel scope link</span>
<span class="c">#    10.1.1.0/24 via 172.20.0.3 dev eth0 proto kernel</span>
<span class="c">#    172.20.0.0/16 dev eth0 proto kernel scope link src 172.20.0.5</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> east-worker ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 172.20.0.1 dev eth0</span>
<span class="c">#    10.1.0.0/24 via 172.20.0.5 dev eth0 proto kernel</span>
<span class="c">#    10.1.1.0/24 via 10.1.1.94 dev cilium_host proto kernel src 10.1.1.94</span>
<span class="c">#    10.1.1.94 dev cilium_host proto kernel scope link</span>
<span class="c">#    172.20.0.0/16 dev eth0 proto kernel scope link src 172.20.0.3</span>

<span class="c"># Specify the Cluster Name and ID : 이미 설정 되어 있음</span>

<span class="c"># Certificate Authority를 공유하기 위해서 east 클러스터의 cilium-ca 시크릿을 삭제합니다.</span>
<span class="nv">$ </span>keast get secret <span class="nt">-n</span> kube-system cilium-ca
<span class="nv">$ </span>keast delete secret <span class="nt">-n</span> kube-system cilium-ca

<span class="c"># west 클러스터의 cilium-ca 시크릿을 east 클러스터로 복사합니다.</span>
<span class="nv">$ </span>kubectl <span class="nt">--context</span> kind-west get secret <span class="nt">-n</span> kube-system cilium-ca <span class="nt">-o</span> yaml | <span class="se">\</span>
  kubectl <span class="nt">--context</span> kind-east create <span class="nt">-f</span> -
  <span class="c"># =&gt; secret/cilium-ca created</span>

<span class="nv">$ </span>keast get secret <span class="nt">-n</span> kube-system cilium-ca
<span class="c"># =&gt; NAME        TYPE     DATA   AGE</span>
<span class="c">#    cilium-ca   Opaque   2      12s</span>

<span class="c"># 모니터링 : 신규 터미널 2개</span>
<span class="nv">$ </span>cilium clustermesh status <span class="nt">--context</span> kind-west <span class="nt">--wait</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    ⚠️  Service type NodePort detected! Service may fail when nodes are removed from the cluster!</span>
<span class="c">#    ✅ Service "clustermesh-apiserver" of type "NodePort" found</span>
<span class="c">#    ✅ Cluster access information is available:</span>
<span class="c">#      - 172.20.0.4:32379</span>
<span class="c">#    ✅ Deployment clustermesh-apiserver is ready</span>
<span class="c">#    ℹ️  KVStoreMesh is disabled</span>
<span class="c">#    </span>
<span class="c">#    </span>
<span class="c">#    🔌 No cluster connected</span>
<span class="c">#    </span>
<span class="c">#    🔀 Global services: [ min:0 / avg:0.0 / max:0 ]  </span>
<span class="nv">$ </span>cilium clustermesh status <span class="nt">--context</span> kind-east <span class="nt">--wait</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    ⚠️  Service type NodePort detected! Service may fail when nodes are removed from the cluster!</span>
<span class="c">#    ✅ Service "clustermesh-apiserver" of type "NodePort" found</span>
<span class="c">#    ✅ Cluster access information is available:</span>
<span class="c">#      - 172.20.0.5:32379</span>
<span class="c">#    ✅ Deployment clustermesh-apiserver is ready</span>
<span class="c">#    ℹ️  KVStoreMesh is disabled</span>
<span class="c">#    </span>
<span class="c">#    </span>
<span class="c">#    🔌 No cluster connected</span>
<span class="c">#    </span>
<span class="c">#    🔀 Global services: [ min:0 / avg:0.0 / max:0 ]</span>


<span class="c"># Enable Cluster Mesh : 간단한 실습 환경으로 NodePort 로 진행</span>
<span class="nv">$ </span>cilium clustermesh <span class="nb">enable</span> <span class="nt">--service-type</span> NodePort <span class="nt">--enable-kvstoremesh</span><span class="o">=</span><span class="nb">false</span> <span class="nt">--context</span> kind-west
<span class="c"># =&gt; ⚠️  Using service type NodePort may fail when nodes are removed from the cluster!</span>
<span class="nv">$ </span>cilium clustermesh <span class="nb">enable</span> <span class="nt">--service-type</span> NodePort <span class="nt">--enable-kvstoremesh</span><span class="o">=</span><span class="nb">false</span> <span class="nt">--context</span> kind-east
<span class="c"># =&gt; ⚠️  Using service type NodePort may fail when nodes are removed from the cluster! </span>

<span class="c"># 32379 NodePort 정보 : clustermesh-apiserver 서비스 정보</span>
<span class="nv">$ </span>kwest get svc,ep <span class="nt">-n</span> kube-system clustermesh-apiserver <span class="nt">--context</span> kind-west
<span class="c"># =&gt; NAME                            TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE</span>
<span class="c">#    service/clustermesh-apiserver   NodePort   10.2.173.178   &lt;none&gt;        2379:32379/TCP   2m55s</span>
<span class="c">#    </span>
<span class="c">#    NAME                              ENDPOINTS         AGE</span>
<span class="c">#    endpoints/clustermesh-apiserver   10.0.1.223:2379   2m55s       # 대상 파드는 clustermesh-apiserver 파드 IP</span>

<span class="nv">$ </span>kwest get pod <span class="nt">-n</span> kube-system <span class="nt">-owide</span> | <span class="nb">grep </span>clustermesh
<span class="c"># =&gt; clustermesh-apiserver-5cf45db9cc-r26tw       2/2     Running     0          3m21s   10.0.1.223   west-worker          &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    clustermesh-apiserver-generate-certs-788q6   0/1     Completed   0          3m21s   172.20.0.2   west-worker          &lt;none&gt;           &lt;none&gt;</span>

<span class="nv">$ </span>keast get svc,ep <span class="nt">-n</span> kube-system clustermesh-apiserver <span class="nt">--context</span> kind-east
<span class="c"># =&gt; NAME                            TYPE       CLUSTER-IP    EXTERNAL-IP   PORT(S)          AGE</span>
<span class="c">#    service/clustermesh-apiserver   NodePort   10.3.201.32   &lt;none&gt;        2379:32379/TCP   2m40s</span>
<span class="c">#    </span>
<span class="c">#    NAME                              ENDPOINTS         AGE</span>
<span class="c">#    endpoints/clustermesh-apiserver   10.1.1.225:2379   2m40s       # 대상 파드는 clustermesh-apiserver 파드 IP</span>

<span class="nv">$ </span>keast get pod <span class="nt">-n</span> kube-system <span class="nt">-owide</span> | <span class="nb">grep </span>clustermesh
<span class="c"># =&gt; clustermesh-apiserver-5cf45db9cc-r4wgj       2/2     Running     0          2m56s   10.1.1.225   east-worker          &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    clustermesh-apiserver-generate-certs-89vnn   0/1     Completed   0          2m56s   172.20.0.3   east-worker          &lt;none&gt;           &lt;none&gt;</span>

<span class="c"># 모니터링 : 신규 터미널 2개</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> <span class="s2">"cilium clustermesh status --context kind-west --wait"</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> <span class="s2">"cilium clustermesh status --context kind-east --wait"</span>

<span class="c"># Connect Clusters</span>
<span class="nv">$ </span>cilium clustermesh connect <span class="nt">--context</span> kind-west <span class="nt">--destination-context</span> kind-east
<span class="c"># =&gt; ✨ Extracting access information of cluster west...</span>
<span class="c">#    🔑 Extracting secrets from cluster west...</span>
<span class="c">#    ⚠️  Service type NodePort detected! Service may fail when nodes are removed from the cluster!</span>
<span class="c">#    ℹ️  Found ClusterMesh service IPs: [172.20.0.4]</span>
<span class="c">#    ✨ Extracting access information of cluster east...</span>
<span class="c">#    🔑 Extracting secrets from cluster east...</span>
<span class="c">#    ⚠️  Service type NodePort detected! Service may fail when nodes are removed from the cluster!</span>
<span class="c">#    ℹ️  Found ClusterMesh service IPs: [172.20.0.5]</span>
<span class="c">#    ℹ️ Configuring Cilium in cluster kind-west to connect to cluster kind-east</span>
<span class="c">#    ℹ️ Configuring Cilium in cluster kind-east to connect to cluster kind-west</span>
<span class="c">#    ✅ Connected cluster kind-west &lt;=&gt; kind-east!</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>cilium clustermesh status <span class="nt">--context</span> kind-west <span class="nt">--wait</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    ✅ All 2 nodes are connected to all clusters [min:1 / avg:1.0 / max:1]</span>
<span class="c">#    </span>
<span class="c">#    🔌 Cluster Connections:</span>
<span class="c">#      - east: 2/2 configured, 2/2 connected</span>
<span class="nv">$ </span>cilium clustermesh status <span class="nt">--context</span> kind-east <span class="nt">--wait</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    ✅ All 2 nodes are connected to all clusters [min:1 / avg:1.0 / max:1]</span>
<span class="c">#    </span>
<span class="c">#    🔌 Cluster Connections:</span>
<span class="c">#      - west: 2/2 configured, 2/2 connected</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 ClusterMesh 연결이 잘 되었습니다.&lt;/span&gt;</span>

<span class="c"># </span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--context</span> kind-west <span class="nt">--</span> cilium-dbg troubleshoot clustermesh
<span class="c"># =&gt; ...</span>
<span class="c">#    Cluster "east":</span>
<span class="c">#    📄 Configuration path: /var/lib/cilium/clustermesh/east</span>
<span class="c">#    </span>
<span class="c">#    🔌 Endpoints:</span>
<span class="c">#       - https://east.mesh.cilium.io:32379</span>
<span class="c">#         ✅ Hostname resolved to: 172.20.0.5</span>
<span class="c">#         ✅ TCP connection successfully established to 172.20.0.5:32379</span>
<span class="c">#         ✅ TLS connection successfully established to 172.20.0.5:32379</span>
<span class="c">#    ...</span>
<span class="c">#    🔑 Digital certificates:</span>
<span class="c">#       ✅ TLS Root CA certificates:</span>
<span class="c">#          - Serial number:       &lt;span style="color: green;"&gt;84:08:1a:87:5e:23:5b:d9:0b:ca:62:3a:46:9b:13:9&lt;/span&gt;</span>
<span class="c">#    ...</span>
<span class="c">#       ✅ TLS client certificates:</span>
<span class="c">#          - Serial number:       65:79:dd:0b:b6:6d:92:6a:59:ce:40:d2:7b:dc:0c:67:ef:c9:96:06</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--context</span> kind-east <span class="nt">--</span> cilium-dbg troubleshoot clustermesh
<span class="c"># =&gt; ...</span>
<span class="c">#    Cluster "west":</span>
<span class="c">#    📄 Configuration path: /var/lib/cilium/clustermesh/west</span>
<span class="c">#    </span>
<span class="c">#    🔌 Endpoints:</span>
<span class="c">#       - https://west.mesh.cilium.io:32379</span>
<span class="c">#         ✅ Hostname resolved to: 172.20.0.4</span>
<span class="c">#         ✅ TCP connection successfully established to 172.20.0.4:32379</span>
<span class="c">#         ✅ TLS connection successfully established to 172.20.0.4:32379</span>
<span class="c">#    ...</span>
<span class="c">#    🔑 Digital certificates:</span>
<span class="c">#       ✅ TLS Root CA certificates:</span>
<span class="c">#          - Serial number:       &lt;span style="color: green;"&gt;84:08:1a:87:5e:23:5b:d9:0b:ca:62:3a:46:9b:13:9&lt;/span&gt;</span>
<span class="c">#    ...</span>
<span class="c">#       ✅ TLS client certificates:</span>
<span class="c">#          - Serial number:       29:14:65:5d:5d:ff:bf:80:24:ba:16:88:a4:55:d3:e0:ba:a3:9d:14</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 서로 다른 클러스터에 대해서 구성을 갖고 있고, 앞서 Cilium CA를 복사했기 때문에, 같은 Root CA를 사용하고 있습니다.&lt;/span&gt;</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kwest get pod <span class="nt">-A</span> <span class="o">&amp;&amp;</span> keast get pod <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE            NAME                                         READY   STATUS      RESTARTS   AGE</span>
<span class="c">#    ...</span>
<span class="c">#    kube-system          clustermesh-apiserver-5cf45db9cc-r26tw       2/2     Running     0          12m</span>
<span class="c">#    kube-system          clustermesh-apiserver-generate-certs-2xlxh   0/1     Completed   0          8m4s</span>
<span class="c">#    ...</span>
<span class="c">#    NAMESPACE            NAME                                         READY   STATUS      RESTARTS   AGE</span>
<span class="c">#    ...</span>
<span class="c">#    kube-system          clustermesh-apiserver-5cf45db9cc-r4wgj       2/2     Running     0          11m</span>
<span class="c">#    kube-system          clustermesh-apiserver-generate-certs-fr5cz   0/1     Completed   0          7m58s</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>cilium status <span class="nt">--context</span> kind-west
<span class="nv">$ </span>cilium status <span class="nt">--context</span> kind-east
<span class="nv">$ </span>cilium clustermesh status <span class="nt">--context</span> kind-west
<span class="nv">$ </span>cilium clustermesh status <span class="nt">--context</span> kind-east
<span class="nv">$ </span>cilium config view <span class="nt">--context</span> kind-west
<span class="nv">$ </span>cilium config view <span class="nt">--context</span> kind-east
<span class="nv">$ </span>kwest <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium status <span class="nt">--verbose</span>
<span class="nv">$ </span>keast <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium status <span class="nt">--verbose</span>
<span class="c"># =&gt; ClusterMesh:   1/1 remote clusters ready, 0 global-services</span>
<span class="c">#       west: ready, 2 nodes, 4 endpoints, 3 identities, 0 services, 0 MCS-API service exports, 0 reconnections (last: never)</span>
<span class="c">#       └  etcd: 1/1 connected, leases=0, lock leases=0, has-quorum=true: endpoint status checks are disabled, ID: ea025158a8e3c0a3</span>
<span class="c">#       └  remote configuration: expected=true, retrieved=true, cluster-id=1, kvstoremesh=false, sync-canaries=true, service-exports=disabled</span>
<span class="c">#       └  synchronization status: nodes=true, endpoints=true, identities=true, services=true</span>

<span class="c">#</span>
<span class="nv">$ </span>helm get values <span class="nt">-n</span> kube-system cilium <span class="nt">--kube-context</span> kind-west 
<span class="c"># =&gt; ...</span>
<span class="c">#    cluster:</span>
<span class="c">#      id: 1</span>
<span class="c">#      name: west</span>
<span class="c">#    clustermesh:</span>
<span class="c">#      apiserver:</span>
<span class="c">#        kvstoremesh:</span>
<span class="c">#          enabled: false</span>
<span class="c">#        service:</span>
<span class="c">#          type: NodePort</span>
<span class="c">#        tls:</span>
<span class="c">#          auto:</span>
<span class="c">#            enabled: true</span>
<span class="c">#            method: cronJob</span>
<span class="c">#            schedule: 0 0 1 */4 *</span>
<span class="c">#      config:</span>
<span class="c">#        clusters:</span>
<span class="c">#        - ips:</span>
<span class="c">#          - 172.20.0.5</span>
<span class="c">#          name: east</span>
<span class="c">#          port: 32379</span>
<span class="c">#        enabled: true</span>
<span class="c">#      useAPIServer: true</span>

<span class="nv">$ </span>helm get values <span class="nt">-n</span> kube-system cilium <span class="nt">--kube-context</span> kind-east 
<span class="c"># =&gt; ...</span>
<span class="c">#    cluster:</span>
<span class="c">#      id: 2</span>
<span class="c">#      name: east</span>
<span class="c">#    clustermesh:</span>
<span class="c">#      apiserver:</span>
<span class="c">#        kvstoremesh:</span>
<span class="c">#          enabled: false</span>
<span class="c">#        service:</span>
<span class="c">#          type: NodePort</span>
<span class="c">#        tls:</span>
<span class="c">#          auto:</span>
<span class="c">#            enabled: true</span>
<span class="c">#            method: cronJob</span>
<span class="c">#            schedule: 0 0 1 */4 *</span>
<span class="c">#      config:</span>
<span class="c">#        clusters:</span>
<span class="c">#        - ips:</span>
<span class="c">#          - 172.20.0.4</span>
<span class="c">#          name: west</span>
<span class="c">#          port: 32379</span>
<span class="c">#        enabled: true</span>
<span class="c">#      useAPIServer: true</span>

<span class="c"># 라우팅 정보 확인 : 클러스터간 PodCIDR 라우팅 주입 확인!</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> west-control-plane ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 172.20.0.1 dev eth0</span>
<span class="c">#    10.0.0.0/24 via 10.0.0.175 dev cilium_host proto kernel src 10.0.0.175</span>
<span class="c">#    10.0.0.175 dev cilium_host proto kernel scope link</span>
<span class="c">#    10.0.1.0/24 via 172.20.0.2 dev eth0 proto kernel</span>
<span class="c">#    &lt;span style="color: green;"&gt;10.1.0.0/24 via 172.20.0.5 dev eth0 proto kernel&lt;/span&gt;</span>
<span class="c">#    &lt;span style="color: green;"&gt;10.1.1.0/24 via 172.20.0.3 dev eth0 proto kernel&lt;/span&gt;</span>
<span class="c">#    172.20.0.0/16 dev eth0 proto kernel scope link src 172.20.0.4</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> west-worker ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 172.20.0.1 dev eth0</span>
<span class="c">#    10.0.0.0/24 via 172.20.0.4 dev eth0 proto kernel</span>
<span class="c">#    10.0.1.0/24 via 10.0.1.10 dev cilium_host proto kernel src 10.0.1.10</span>
<span class="c">#    10.0.1.10 dev cilium_host proto kernel scope link</span>
<span class="c">#    &lt;span style="color: green;"&gt;10.1.0.0/24 via 172.20.0.5 dev eth0 proto kernel&lt;/span&gt;</span>
<span class="c">#    &lt;span style="color: green;"&gt;10.1.1.0/24 via 172.20.0.3 dev eth0 proto kernel&lt;/span&gt;</span>
<span class="c">#    172.20.0.0/16 dev eth0 proto kernel scope link src 172.20.0.2</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> east-control-plane ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 172.20.0.1 dev eth0</span>
<span class="c">#    &lt;span style="color: green;"&gt;10.0.0.0/24 via 172.20.0.4 dev eth0 proto kernel&lt;/span&gt;</span>
<span class="c">#    &lt;span style="color: green;"&gt;10.0.1.0/24 via 172.20.0.2 dev eth0 proto kernel&lt;/span&gt;</span>
<span class="c">#    10.1.0.0/24 via 10.1.0.80 dev cilium_host proto kernel src 10.1.0.80</span>
<span class="c">#    10.1.0.80 dev cilium_host proto kernel scope link</span>
<span class="c">#    10.1.1.0/24 via 172.20.0.3 dev eth0 proto kernel</span>
<span class="c">#    172.20.0.0/16 dev eth0 proto kernel scope link src 172.20.0.5</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> east-worker ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 172.20.0.1 dev eth0</span>
<span class="c">#    &lt;span style="color: green;"&gt;10.0.0.0/24 via 172.20.0.4 dev eth0 proto kernel&lt;/span&gt;</span>
<span class="c">#    &lt;span style="color: green;"&gt;10.0.1.0/24 via 172.20.0.2 dev eth0 proto kernel&lt;/span&gt;</span>
<span class="c">#    10.1.0.0/24 via 172.20.0.5 dev eth0 proto kernel</span>
<span class="c">#    10.1.1.0/24 via 10.1.1.94 dev cilium_host proto kernel src 10.1.1.94</span>
<span class="c">#    10.1.1.94 dev cilium_host proto kernel scope link</span>
<span class="c">#    172.20.0.0/16 dev eth0 proto kernel scope link src 172.20.0.3</span>
</code></pre></div></div>

<ul>
  <li>Hubble enable</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># cilium helm repo 등록</span>
<span class="nv">$ </span>helm repo add cilium https://helm.cilium.io/
<span class="nv">$ </span>helm repo update

<span class="c"># 설정</span>
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--version</span> 1.17.6 <span class="nt">--namespace</span> kube-system <span class="nt">--reuse-values</span> <span class="se">\</span>
  <span class="nt">--set</span> hubble.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> hubble.relay.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> hubble.ui.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> hubble.ui.service.type<span class="o">=</span>NodePort <span class="nt">--set</span> hubble.ui.service.nodePort<span class="o">=</span>30001 <span class="nt">--kube-context</span> kind-west
<span class="c"># =&gt; Release "cilium" has been upgraded. Happy Helming!</span>
<span class="c">#    NAME: cilium</span>
<span class="c">#    LAST DEPLOYED: Sat Aug 16 21:31:07 2025</span>
<span class="c">#    NAMESPACE: kube-system</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 4</span>
<span class="c">#    TEST SUITE: None</span>
<span class="c">#    NOTES:</span>
<span class="c">#    You have successfully installed Cilium with Hubble Relay and Hubble UI.</span>
<span class="c">#    </span>
<span class="c">#    Your release version is 1.17.6.  </span>
<span class="nv">$ </span>kwest <span class="nt">-n</span> kube-system rollout restart ds/cilium
<span class="c"># =&gt; daemonset.apps/cilium restarted</span>

<span class="c">## 혹은 cilium hubble enable --ui --relay --context kind-west</span>
<span class="c">## kubectl --context kind-west patch svc -n kube-system hubble-ui -p '{"spec": {"type": "NodePort", "ports": [{"port": 80, "targetPort": 8081, "nodePort": 30001}]}}'</span>

<span class="c"># 설정</span>
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--version</span> 1.17.6 <span class="nt">--namespace</span> kube-system <span class="nt">--reuse-values</span> <span class="se">\</span>
  <span class="nt">--set</span> hubble.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> hubble.relay.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> hubble.ui.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> hubble.ui.service.type<span class="o">=</span>NodePort <span class="nt">--set</span> hubble.ui.service.nodePort<span class="o">=</span>31001 <span class="nt">--kube-context</span> kind-east
<span class="nv">$ </span>kwest <span class="nt">-n</span> kube-system rollout restart ds/cilium
<span class="c"># =&gt; daemonset.apps/cilium restarted</span>

<span class="c">## 혹은 cilium hubble enable --ui --relay --context kind-east</span>
<span class="c">## kubectl --context kind-east patch svc -n kube-system hubble-ui -p '{"spec": {"type": "NodePort", "ports": [{"port": 80, "targetPort": 8081, "nodePort": 31001}]}}'</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kwest get svc,ep <span class="nt">-n</span> kube-system hubble-ui <span class="nt">--context</span> kind-west
<span class="c"># =&gt; NAME                TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE</span>
<span class="c">#    service/hubble-ui   NodePort   10.2.253.104   &lt;none&gt;        80:30001/TCP   51s</span>
<span class="c">#    </span>
<span class="c">#    NAME                  ENDPOINTS         AGE</span>
<span class="c">#    endpoints/hubble-ui   10.0.1.192:8081   51s</span>
<span class="nv">$ </span>keast get svc,ep <span class="nt">-n</span> kube-system hubble-ui <span class="nt">--context</span> kind-east
<span class="c"># =&gt; NAME                TYPE       CLUSTER-IP    EXTERNAL-IP   PORT(S)        AGE</span>
<span class="c">#    service/hubble-ui   NodePort   10.3.93.132   &lt;none&gt;        80:31001/TCP   26s</span>
<span class="c">#    </span>
<span class="c">#    NAME                  ENDPOINTS   AGE</span>
<span class="c">#    endpoints/hubble-ui   &lt;none&gt;      25s</span>

<span class="c"># hubble-ui 접속 시</span>
<span class="nv">$ </span>open http://localhost:30001
<span class="nv">$ </span>open http://localhost:31001
</code></pre></div></div>

<h3 id="west-파드---east-파드-간-직접-통신-확인-with-static-routing">west 파드 &lt;-&gt; east 파드 간 직접 통신 확인 with static routing</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply --context kind-west -f -
apiVersion: v1
kind: Pod
metadata:
  name: curl-pod
  labels:
    app: curl
spec:
  containers:
  - name: curl
    image: nicolaka/netshoot
    command: ["tail"]
    args: ["-f", "/dev/null"]
  terminationGracePeriodSeconds: 0
</span><span class="no">EOF
</span><span class="c"># =&gt; pod/curl-pod created</span>

<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply --context kind-east -f -
apiVersion: v1
kind: Pod
metadata:
  name: curl-pod
  labels:
    app: curl
spec:
  containers:
  - name: curl
    image: nicolaka/netshoot
    command: ["tail"]
    args: ["-f", "/dev/null"]
  terminationGracePeriodSeconds: 0
</span><span class="no">EOF
</span><span class="c"># =&gt; pod/curl-pod created</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kwest get pod <span class="nt">-A</span> <span class="o">&amp;&amp;</span> keast get pod <span class="nt">-A</span>
<span class="nv">$ </span>kwest get pod <span class="nt">-owide</span> <span class="o">&amp;&amp;</span> keast get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME       READY   STATUS    RESTARTS   AGE   IP           NODE          NOMINATED NODE   READINESS GATES</span>
<span class="c">#    curl-pod   1/1     Running   0          20m   10.0.1.101   west-worker   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    NAME       READY   STATUS    RESTARTS   AGE   IP           NODE          NOMINATED NODE   READINESS GATES</span>
<span class="c">#    curl-pod   1/1     Running   0          20m   10.1.1.146   east-worker   &lt;none&gt;           &lt;none&gt;</span>

<span class="c"># west 파드에서 east 파드로 직접 라우팅 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--context</span> kind-west <span class="nt">--</span> ping <span class="nt">-c</span> 1 10.1.1.146
<span class="c"># =&gt; 64 bytes from 10.1.1.146: icmp_seq=1 ttl=62 time=1.80 ms</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--context</span> kind-west <span class="nt">--</span> ping 10.1.1.146

<span class="c"># 목적지 파드에서 tcpdump 로 확인 : NAT 없이 직접 라우팅.</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--context</span> kind-east <span class="nt">--</span> tcpdump <span class="nt">-i</span> eth0 <span class="nt">-nn</span>
<span class="c"># =&gt; 14:30:09.035714 IP 10.1.1.146 &gt; 10.0.1.101: ICMP echo request, id 15, seq 1, length 64</span>
<span class="c">#    14:30:09.036120 IP 10.0.1.101 &gt; 10.1.1.146: ICMP echo reply, id 15, seq 1, length 64</span>

<span class="c"># 목적지 k8s 노드?에서 icmp tcpdump 로 확인 : 다른곳 경유하지 않고 직접 노드에서 파드로 인입 확인</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> east-control-plane tcpdump <span class="nt">-i</span> any icmp <span class="nt">-nn</span>
<span class="c"># =&gt; (캡쳐된 패킷 없음)</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> east-worker tcpdump <span class="nt">-i</span> any icmp <span class="nt">-nn</span>
<span class="c"># =&gt; 14:30:09.035725 lxce19e07e06482 In  IP 10.1.1.146 &gt; 10.0.1.101: ICMP echo request, id 15, seq 1, length 64</span>
<span class="c">#    14:30:09.035904 eth0  Out IP 10.1.1.146 &gt; 10.0.1.101: ICMP echo request, id 15, seq 1, length 64</span>
<span class="c">#    14:30:09.036120 eth0  In  IP 10.0.1.101 &gt; 10.1.1.146: ICMP echo reply, id 15, seq 1, length 64</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 east-control-plane에는 패킷 캡쳐가 없고, tcp dump 상에도 east &lt;-&gt; west 파드 IP간의 직접 통신으로&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   캡쳐되는것으로 보아 다른곳을 경유하지 않고 직접 파드로 인입되는것을 확인할 수 있습니다.&lt;/span&gt;</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--context</span> kind-east <span class="nt">--</span> ping <span class="nt">-c</span> 1 10.0.1.101
<span class="c"># =&gt; 64 bytes from 10.0.1.101: icmp_seq=1 ttl=62 time=0.291 ms</span>
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w5/20250817_cilium_w5_6.png" alt="img.png" class="image-center" /></p>

<h3 id="load-balancing--service-discovery">Load-Balancing &amp; Service Discovery</h3>

<ul>
  <li>ClusterMesh를 통한 Load-Balacing 및 Service Discovery를 실습을 통해 확인해 보겠습니다.</li>
  <li><a href="https://docs.cilium.io/en/stable/network/clustermesh/services/">관련문서</a></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply --context kind-west -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webpod
spec:
  replicas: 2
  selector:
    matchLabels:
      app: webpod
  template:
    metadata:
      labels:
        app: webpod
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - sample-app
            topologyKey: "kubernetes.io/hostname"
      containers:
      - name: webpod
        image: traefik/whoami
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: webpod
  labels:
    app: webpod
  annotations:
    service.cilium.io/global: "true"
spec:
  selector:
    app: webpod
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
  type: ClusterIP
</span><span class="no">EOF
</span><span class="c"># =&gt; deployment.apps/webpod created</span>
<span class="c">#    service/webpod created</span>

<span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply --context kind-east -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webpod
spec:
  replicas: 2
  selector:
    matchLabels:
      app: webpod
  template:
    metadata:
      labels:
        app: webpod
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - sample-app
            topologyKey: "kubernetes.io/hostname"
      containers:
      - name: webpod
        image: traefik/whoami
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: webpod
  labels:
    app: webpod
  annotations:
    service.cilium.io/global: "true"
spec:
  selector:
    app: webpod
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
  type: ClusterIP
</span><span class="no">EOF
</span><span class="c"># =&gt; deployment.apps/webpod created</span>
<span class="c">#    service/webpod created</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kwest get svc,ep webpod <span class="o">&amp;&amp;</span> keast get svc,ep webpod
<span class="c"># =&gt; NAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE</span>
<span class="c">#    service/webpod   ClusterIP   10.2.184.162   &lt;none&gt;        80/TCP    43s</span>
<span class="c">#    </span>
<span class="c">#    NAME               ENDPOINTS                   AGE</span>
<span class="c">#    endpoints/webpod   10.0.1.70:80,10.0.1.77:80   43s</span>
<span class="c">#    </span>
<span class="c">#    NAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE</span>
<span class="c">#    service/webpod   ClusterIP   10.3.136.103   &lt;none&gt;        80/TCP    8s</span>
<span class="c">#    </span>
<span class="c">#    NAME               ENDPOINTS       AGE</span>
<span class="c">#    endpoints/webpod   10.1.1.217:80   8s</span>

<span class="nv">$ </span>kwest <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium service list <span class="nt">--clustermesh-affinity</span>
<span class="c"># =&gt; ID   Frontend                Service Type   Backend</span>
<span class="c">#    ...</span>
<span class="c">#    13   10.2.184.162:80/TCP     ClusterIP      1 =&gt; 10.0.1.70:80/TCP (active)</span>
<span class="c">#                                                2 =&gt; 10.0.1.77:80/TCP (active)</span>
<span class="c">#                                                3 =&gt; 10.1.1.217:80/TCP (active)</span>
<span class="c">#                                                4 =&gt; 10.1.1.207:80/TCP (active) </span>
                                            
<span class="nv">$ </span>keast <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium service list <span class="nt">--clustermesh-affinity</span>
<span class="c"># =&gt; ID   Frontend               Service Type   Backend</span>
<span class="c">#    ...</span>
<span class="c">#    13   10.3.136.103:80/TCP    ClusterIP      1 =&gt; 10.0.1.77:80/TCP (active)</span>
<span class="c">#                                               2 =&gt; 10.0.1.70:80/TCP (active)</span>
<span class="c">#                                               3 =&gt; 10.1.1.217:80/TCP (active)</span>
<span class="c">#                                               4 =&gt; 10.1.1.207:80/TCP (active)</span>
 
<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--context</span> kind-west <span class="nt">--</span> ping <span class="nt">-c</span> 1 10.1.1.146
<span class="c"># =&gt; 64 bytes from 10.1.1.146: icmp_seq=1 ttl=62 time=1.35 ms</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--context</span> kind-east <span class="nt">--</span> ping <span class="nt">-c</span> 1 10.0.1.101
<span class="c"># =&gt; 64 bytes from 10.0.1.101: icmp_seq=1 ttl=62 time=0.889 ms</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--context</span> kind-west <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s --connect-timeout 1 webpod ; sleep 1; echo "---"; done;'</span>
<span class="c"># =&gt; ---</span>
<span class="c">#    Hostname: webpod-697b545f57-twg87</span>
<span class="c">#    IP: 10.0.1.77</span>
<span class="c">#    RemoteAddr: 10.0.1.101:36858</span>
<span class="c">#    ...</span>
<span class="c">#    ---</span>
<span class="c">#    Hostname: webpod-697b545f57-9ndvj</span>
<span class="c">#    IP: 10.0.1.70</span>
<span class="c">#    RemoteAddr: 10.0.1.101:58324</span>
<span class="c">#    ...</span>
<span class="c">#    ---</span>
<span class="c">#    Hostname: webpod-697b545f57-9ndvj</span>
<span class="c">#    IP: 10.0.1.70</span>
<span class="c">#    RemoteAddr: 10.0.1.101:58354</span>
<span class="c">#    ...    </span>
<span class="c">#    ---</span>
<span class="c">#    Hostname: webpod-697b545f57-k6wdn</span>
<span class="c">#    IP: 10.1.1.217</span>
<span class="c">#    RemoteAddr: 10.0.1.101:56788</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--context</span> kind-east <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s --connect-timeout 1 webpod ; sleep 1; echo "---"; done;'</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    ---</span>
<span class="c">#    Hostname: webpod-697b545f57-k6wdn</span>
<span class="c">#    IP: 10.1.1.217</span>
<span class="c">#    RemoteAddr: 10.1.1.146:41276</span>
<span class="c">#    ...</span>
<span class="c">#    ---</span>
<span class="c">#    Hostname: webpod-697b545f57-9ndvj</span>
<span class="c">#    IP: 10.0.1.70</span>
<span class="c">#    RemoteAddr: 10.1.1.146:56488</span>
<span class="c">#    ...    </span>
<span class="c">#    ---</span>
<span class="c">#    Hostname: webpod-697b545f57-924nf</span>
<span class="c">#    IP: 10.1.1.207</span>
<span class="c">#    RemoteAddr: 10.1.1.146:34020</span>
<span class="c">#    ...</span>
<span class="c">#    ---</span>
<span class="c">#    Hostname: webpod-697b545f57-twg87</span>
<span class="c">#    IP: 10.0.1.77</span>
<span class="c">#    RemoteAddr: 10.1.1.146:44744</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 curl-pod의 클러스터와 관계 없이 west와 east의 webpod가 골고루 사용되고 있습니다.&lt;/span&gt;</span>

<span class="c"># 현재 Service Annotations 설정</span>
<span class="nv">$ </span>kwest describe svc webpod | <span class="nb">grep </span>Annotations <span class="nt">-A1</span>
<span class="c"># =&gt; Annotations:              service.cilium.io/global: true</span>
<span class="c">#    Selector:                 app=webpod</span>

<span class="nv">$ </span>keast describe svc webpod | <span class="nb">grep </span>Annotations <span class="nt">-A1</span>
<span class="c"># =&gt; Annotations:              service.cilium.io/global: true</span>
<span class="c">#    Selector:                 app=webpod</span>

<span class="c"># 모니터링 : 반복 접속해두기</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--context</span> kind-west <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s --connect-timeout 1 webpod ; sleep 1; echo "---"; done;'</span>

<span class="c">#</span>
<span class="nv">$ </span>kwest scale deployment webpod <span class="nt">--replicas</span> 1
<span class="nv">$ </span>kwest <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium service list <span class="nt">--clustermesh-affinity</span>
<span class="c"># =&gt; ID   Frontend                Service Type   Backend</span>
<span class="c">#    ...</span>
<span class="c">#    13   10.2.184.162:80/TCP     ClusterIP      1 =&gt; 10.0.1.77:80/TCP (active)</span>
<span class="c">#                                                2 =&gt; 10.1.1.217:80/TCP (active)</span>
<span class="c">#                                                3 =&gt; 10.1.1.207:80/TCP (active)</span>
<span class="nv">$ </span>keast <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium service list <span class="nt">--clustermesh-affinity</span>
<span class="c"># =&gt; ID   Frontend               Service Type   Backend</span>
<span class="c">#    ...</span>
<span class="c">#    13   10.3.136.103:80/TCP    ClusterIP      1 =&gt; 10.0.1.77:80/TCP (active)</span>
<span class="c">#                                               2 =&gt; 10.1.1.217:80/TCP (active)</span>
<span class="c">#                                               3 =&gt; 10.1.1.207:80/TCP (active)</span>

<span class="c"># 로컬 k8s 에 목적지가 없을 경우 어떻게 되나요?</span>
<span class="nv">$ </span>kwest scale deployment webpod <span class="nt">--replicas</span> 0
<span class="c"># =&gt; deployment.apps/webpod scaled</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 west에 webpod가 없으므로, east의 webpod로만 접속이 됩니다.&lt;/span&gt;</span>
<span class="nv">$ </span>kwest <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium service list <span class="nt">--clustermesh-affinity</span>
<span class="c"># =&gt; ID   Frontend                Service Type   Backend</span>
<span class="c">#    ...</span>
<span class="c">#    13   10.2.184.162:80/TCP     ClusterIP      1 =&gt; 10.1.1.217:80/TCP (active)</span>
<span class="c">#                                                2 =&gt; 10.1.1.207:80/TCP (active)</span>
<span class="nv">$ </span>keast <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium service list <span class="nt">--clustermesh-affinity</span>

<span class="c">#</span>
<span class="nv">$ </span>kwest scale deployment webpod <span class="nt">--replicas</span> 2
<span class="c"># =&gt; deployment.apps/webpod scaled</span>
<span class="nv">$ </span>kwest <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium service list <span class="nt">--clustermesh-affinity</span>
<span class="c"># =&gt; ID   Frontend                Service Type   Backend</span>
<span class="c">#    ...</span>
<span class="c">#    13   10.2.184.162:80/TCP     ClusterIP      1 =&gt; 10.1.1.217:80/TCP (active)</span>
<span class="c">#                                                2 =&gt; 10.1.1.207:80/TCP (active)</span>
<span class="c">#                                                3 =&gt; &lt;span style="color: green;"&gt;10.0.1.210:80/TCP&lt;/span&gt; (active)</span>
<span class="c">#                                                4 =&gt; &lt;span style="color: green;"&gt;10.0.1.140:80/TCP&lt;/span&gt; (active)</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 west의 webpod가 복구되면 Service Discovery가 되면서, west의 webpod로도 접속이 됩니다.&lt;/span&gt;</span>
<span class="nv">$ </span>keast <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium service list <span class="nt">--clustermesh-affinity</span>

<span class="c"># tcpdump 확인 : dataplane flow 확인</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> west-control-plane tcpdump <span class="nt">-i</span> any tcp port 80 <span class="nt">-nnq</span> 
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> west-worker tcpdump <span class="nt">-i</span> any tcp port 80 <span class="nt">-nnq</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> east-control-plane tcpdump <span class="nt">-i</span> any tcp port 80 <span class="nt">-nnq</span> 
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> east-worker tcpdump <span class="nt">-i</span> any tcp port 80 <span class="nt">-nnq</span>
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w5/20250817_cilium_w5_8.png" alt="img.png" class="image-center" /></p>

<ul>
  <li>west와 east의 각 클러스터에 webpod가 있음에도 클러스터 자신의 webpod 뿐만 아니라 상대방의 webpod로도 접속이 되는것을 확인할 수 있습니다.</li>
  <li>이는 시스템 안정성 면에서는 좋을지 몰라도, 오버헤드를 발생시킬 수 있습니다. 다음의 Service Affinity 설정을 통해 이를 해결할 수 있습니다.</li>
</ul>

<h3 id="service-affinity">Service Affinity</h3>

<ul>
  <li><a href="https://docs.cilium.io/en/stable/network/clustermesh/affinity/">관련 문서</a>
<img src="/assets/2025/cilium/w5/20250817_cilium_w5_9.svg" alt="20250817_cilium_w5_9.svg" class="image-center w-100p" /></li>
</ul>

<h5 id="serviceciliumioaffinitylocal">service.cilium.io/affinity=local</h5>

<ul>
  <li><code class="language-plaintext highlighter-rouge">service.cilium.io/affinity=local</code> 설정을 통해, 각 클러스터의 파드가 자기자신의 클러스터의 파드를 우선하여 접속하도록 설정할 수 있습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 모니터링 : 반복 접속해두기</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--context</span> kind-west <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s --connect-timeout 1 webpod ; sleep 1; echo "---"; done;'</span>

<span class="c"># 현재 Service Annotations 설정</span>
<span class="nv">$ </span>kwest describe svc webpod | <span class="nb">grep </span>Annotations <span class="nt">-A1</span>
<span class="c"># =&gt; Annotations:              service.cilium.io/global: true</span>
<span class="c">#    Selector:                 app=webpod</span>
<span class="nv">$ </span>keast describe svc webpod | <span class="nb">grep </span>Annotations <span class="nt">-A1</span>
<span class="c"># =&gt; Annotations:              service.cilium.io/global: true</span>
<span class="c">#    Selector:                 app=webpod</span>

<span class="c"># Session Affinity Local 설정</span>
<span class="nv">$ </span>kwest annotate service webpod service.cilium.io/affinity<span class="o">=</span><span class="nb">local</span> <span class="nt">--overwrite</span>
<span class="c"># =&gt; service/webpod annotated</span>
<span class="nv">$ </span>kwest describe svc webpod | <span class="nb">grep </span>Annotations <span class="nt">-A3</span>
<span class="c"># =&gt; Annotations:              service.cilium.io/affinity: local</span>
<span class="c">#                              service.cilium.io/global: true</span>
<span class="c">#    Selector:                 app=webpod</span>
<span class="c">#    Type:                     ClusterIP</span>

<span class="nv">$ </span>keast annotate service webpod service.cilium.io/affinity<span class="o">=</span><span class="nb">local</span> <span class="nt">--overwrite</span>
<span class="c"># =&gt; service/webpod annotated</span>
<span class="nv">$ </span>keast describe svc webpod | <span class="nb">grep </span>Annotations <span class="nt">-A3</span>
<span class="c"># =&gt; Annotations:              service.cilium.io/affinity: local</span>
<span class="c">#                              service.cilium.io/global: true</span>
<span class="c">#    Selector:                 app=webpod</span>
<span class="c">#    Type:                     ClusterIP</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kwest <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium service list <span class="nt">--clustermesh-affinity</span>
<span class="c"># =&gt; 13   10.2.184.162:80/TCP     ClusterIP      1 =&gt; 10.1.1.217:80/TCP (active)</span>
<span class="c">#                                                2 =&gt; 10.1.1.207:80/TCP (active)</span>
<span class="c">#                                                3 =&gt; 10.0.1.210:80/TCP (active) &lt;span style="color: green;"&gt;(preferred)&lt;/span&gt;</span>
<span class="c">#                                                4 =&gt; 10.0.1.140:80/TCP (active) &lt;span style="color: green;"&gt;(preferred)&lt;/span&gt;</span>

<span class="nv">$ </span>keast <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium service list <span class="nt">--clustermesh-affinity</span>
<span class="c"># =&gt; 13   10.3.136.103:80/TCP    ClusterIP      1 =&gt; 10.1.1.217:80/TCP (active) &lt;span style="color: green;"&gt;(preferred)&lt;/span&gt;</span>
<span class="c">#                                               2 =&gt; 10.1.1.207:80/TCP (active) &lt;span style="color: green;"&gt;(preferred)&lt;/span&gt;</span>
<span class="c">#                                               3 =&gt; 10.0.1.210:80/TCP (active)</span>
<span class="c">#                                               4 =&gt; 10.0.1.140:80/TCP (active) </span>

<span class="c"># 호출 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--context</span> kind-west <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s --connect-timeout 1 webpod ; sleep 1; echo "---"; done;'</span>
<span class="c"># =&gt; Hostname: webpod-697b545f57-mm9g7</span>
<span class="c">#    IP: 10.0.1.210</span>
<span class="c">#    RemoteAddr: 10.0.1.101:52556</span>
<span class="c">#    ...    </span>
<span class="c">#    ---</span>
<span class="c">#    Hostname: webpod-697b545f57-rspmq</span>
<span class="c">#    IP: 10.0.1.140</span>
<span class="c">#    RemoteAddr: 10.0.1.101:59782</span>
<span class="c">#    ...    </span>
<span class="c">#    ---</span>
<span class="c">#    Hostname: webpod-697b545f57-rspmq</span>
<span class="c">#    IP: 10.0.1.140</span>
<span class="c">#    RemoteAddr: 10.0.1.101:59782</span>
<span class="c">#    ...    </span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--context</span> kind-east <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s --connect-timeout 1 webpod ; sleep 1; echo "---"; done;'</span>
<span class="c"># =&gt; Hostname: webpod-697b545f57-924nf</span>
<span class="c">#    IP: 10.1.1.207</span>
<span class="c">#    RemoteAddr: 10.1.1.146:42244</span>
<span class="c">#    ...    </span>
<span class="c">#    ---</span>
<span class="c">#    Hostname: webpod-697b545f57-k6wdn</span>
<span class="c">#    IP: 10.1.1.217</span>
<span class="c">#    RemoteAddr: 10.1.1.146:49716</span>
<span class="c">#    ...    </span>
<span class="c">#    ---    </span>
<span class="c">#    Hostname: webpod-697b545f57-924nf</span>
<span class="c">#    IP: 10.1.1.207</span>
<span class="c">#    RemoteAddr: 10.1.1.146:42244</span>
<span class="c">#    ...    </span>
<span class="c">#    ---</span>
<span class="c">#    Hostname: webpod-697b545f57-k6wdn</span>
<span class="c">#    IP: 10.1.1.217</span>
<span class="c">#    RemoteAddr: 10.1.1.146:49716</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 Service Affinity 설정 후 각 클러스터는 자기자신의 클러스터의 webpod를 통해 통신이 진행됩니다.&lt;/span&gt;    </span>

<span class="c"># 현재 상태에서 replicas 변경 후 확인 : preferred 동작 이해하기!</span>
<span class="nv">$ </span>kwest scale deployment webpod <span class="nt">--replicas</span> 0
<span class="c"># =&gt; deployment.apps/webpod scaled</span>
<span class="nv">$ </span>kwest <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium service list <span class="nt">--clustermesh-affinity</span>
<span class="c"># =&gt; 13   10.2.184.162:80/TCP     ClusterIP      1 =&gt; 10.1.1.217:80/TCP (active)</span>
<span class="c">#                                                2 =&gt; 10.1.1.207:80/TCP (active)</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--context</span> kind-west <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s --connect-timeout 1 webpod ; sleep 1; echo "---"; done;'</span>
<span class="c"># =&gt; ---</span>
<span class="c">#    Hostname: webpod-697b545f57-k6wdn</span>
<span class="c">#    IP: 10.1.1.217</span>
<span class="c">#    RemoteAddr: 10.0.1.101:47912</span>
<span class="c">#    ...    </span>
<span class="c">#    ---</span>
<span class="c">#    Hostname: webpod-697b545f57-924nf</span>
<span class="c">#    IP: 10.1.1.207</span>
<span class="c">#    RemoteAddr: 10.0.1.101:58092</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 west 클러스터에는 webpod가 없지만, east 클러스터의 webpod로 접속이 진행됩니다.&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   이는 preferred 설정으로, west 클러스터의 webpod를 선호하지만 없을 경우 east 클러스터의 webpod로 접속이 진행됩니다.&lt;/span&gt;</span>

<span class="c"># 다시 기본 설정값 적용</span>
<span class="nv">$ </span>kwest scale deployment webpod <span class="nt">--replicas</span> 2

<span class="c"># tcpdump 확인</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> west-control-plane tcpdump <span class="nt">-i</span> any tcp port 80 <span class="nt">-nnq</span> 
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> west-worker tcpdump <span class="nt">-i</span> any tcp port 80 <span class="nt">-nnq</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> east-control-plane tcpdump <span class="nt">-i</span> any tcp port 80 <span class="nt">-nnq</span> 
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> east-worker tcpdump <span class="nt">-i</span> any tcp port 80 <span class="nt">-nnq</span>
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w5/20250817_cilium_w5_10.png" alt="img.png" class="image-center" />
<em class="image-caption">각 클러스터의 webpod로 접속이 진행되는것을 확인할 수 있습니다.</em></p>

<h5 id="serviceciliumioaffinityremote">service.cilium.io/affinity=remote</h5>

<ul>
  <li><code class="language-plaintext highlighter-rouge">service.cilium.io/affinity=remote</code>로 설정시 자기 자신의 클러스터가 아닌 다른 원격(remote) 클러스터의 파드를 우선 사용하게 됩니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 현재 설정 상태 확인</span>
<span class="nv">$ </span>kwest <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium service list <span class="nt">--clustermesh-affinity</span>
<span class="c"># =&gt; ID   Frontend                Service Type   Backend</span>
<span class="c">#    ...</span>
<span class="c">#    13   10.2.184.162:80/TCP     ClusterIP      1 =&gt; 10.0.1.94:80/TCP (active) (preferred)</span>
<span class="c">#                                                2 =&gt; 10.0.1.172:80/TCP (active) (preferred)</span>
<span class="c">#                                                3 =&gt; 10.1.1.207:80/TCP (active)</span>
<span class="c">#                                                4 =&gt; 10.1.1.217:80/TCP (active)</span>
<span class="nv">$ </span>keast <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium service list <span class="nt">--clustermesh-affinity</span>
<span class="c"># =&gt; ID   Frontend               Service Type   Backend</span>
<span class="c">#    ...</span>
<span class="c">#    13   10.3.136.103:80/TCP    ClusterIP      1 =&gt; 10.1.1.217:80/TCP (active) (preferred)</span>
<span class="c">#                                               2 =&gt; 10.1.1.207:80/TCP (active) (preferred)</span>
<span class="c">#                                               3 =&gt; 10.0.1.172:80/TCP (active)</span>
<span class="c">#                                               4 =&gt; 10.0.1.94:80/TCP (active)</span>
<span class="nv">$ </span>kwest describe svc webpod | <span class="nb">grep </span>Annotations <span class="nt">-A3</span>
<span class="c"># =&gt; Annotations:              service.cilium.io/affinity: local</span>
<span class="c">#                              service.cilium.io/global: true</span>
<span class="c">#    Selector:                 app=webpod</span>
<span class="c">#    Type:                     ClusterIP</span>
<span class="nv">$ </span>keast describe svc webpod | <span class="nb">grep </span>Annotations <span class="nt">-A3</span>
<span class="c"># =&gt; Annotations:              service.cilium.io/affinity: local</span>
<span class="c">#                              service.cilium.io/global: true</span>
<span class="c">#    Selector:                 app=webpod</span>
<span class="c">#    Type:                     ClusterIP</span>

<span class="c"># remote</span>
<span class="nv">$ </span>kwest annotate service webpod service.cilium.io/affinity<span class="o">=</span>remote <span class="nt">--overwrite</span>
<span class="c"># =&gt; service/webpod annotated</span>
<span class="nv">$ </span>keast annotate service webpod service.cilium.io/affinity<span class="o">=</span>remote <span class="nt">--overwrite</span>
<span class="c"># =&gt; service/webpod annotated</span>
<span class="nv">$ </span>kwest describe svc webpod | <span class="nb">grep </span>Annotations <span class="nt">-A3</span>
<span class="c"># =&gt; Annotations:              service.cilium.io/affinity: remote</span>
<span class="c">#                              service.cilium.io/global: true</span>
<span class="c">#    Selector:                 app=webpod</span>
<span class="c">#    Type:                     ClusterIP</span>
<span class="nv">$ </span>keast describe svc webpod | <span class="nb">grep </span>Annotations <span class="nt">-A3</span>
<span class="c"># =&gt; Annotations:              service.cilium.io/affinity: remote</span>
<span class="c">#                              service.cilium.io/global: true</span>
<span class="c">#    Selector:                 app=webpod</span>
<span class="c">#    Type:                     ClusterIP</span>

<span class="nv">$ </span>kwest <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium service list <span class="nt">--clustermesh-affinity</span>
<span class="c"># =&gt; ID   Frontend                Service Type   Backend</span>
<span class="c">#    ...</span>
<span class="c">#    13   10.2.184.162:80/TCP     ClusterIP      1 =&gt; 10.0.1.94:80/TCP (active)</span>
<span class="c">#                                                2 =&gt; 10.0.1.172:80/TCP (active)</span>
<span class="c">#                                                3 =&gt; 10.1.1.207:80/TCP (active) (preferred)</span>
<span class="c">#                                                4 =&gt; 10.1.1.217:80/TCP (active) (preferred)</span>
<span class="nv">$ </span>keast <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium service list <span class="nt">--clustermesh-affinity</span>
<span class="c"># =&gt; ID   Frontend               Service Type   Backend</span>
<span class="c">#    ...</span>
<span class="c">#    13   10.3.136.103:80/TCP    ClusterIP      1 =&gt; 10.1.1.217:80/TCP (active)</span>
<span class="c">#                                               2 =&gt; 10.1.1.207:80/TCP (active)</span>
<span class="c">#                                               3 =&gt; 10.0.1.172:80/TCP (active) (preferred)</span>
<span class="c">#                                               4 =&gt; 10.0.1.94:80/TCP (active) (preferred)</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 affinity를 remote로 하면 다른 클러스터의 pod를 우선 사용합니다.&lt;/span&gt;</span>

<span class="c"># 호출 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--context</span> kind-west <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s --connect-timeout 1 webpod ; sleep 1; echo "---"; done;'</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--context</span> kind-east <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s --connect-timeout 1 webpod ; sleep 1; echo "---"; done;'</span>

<span class="c">#</span>
<span class="nv">$ </span>kwest scale deployment webpod <span class="nt">--replicas</span> 0
<span class="c"># =&gt; deployment.apps/webpod scaled</span>
<span class="nv">$ </span>kwest <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium service list <span class="nt">--clustermesh-affinity</span>
<span class="c"># =&gt; ID   Frontend                Service Type   Backend</span>
<span class="c">#    ...</span>
<span class="c">#    13   10.2.184.162:80/TCP     ClusterIP      1 =&gt; 10.1.1.207:80/TCP (active) (preferred)</span>
<span class="c">#                                                2 =&gt; 10.1.1.217:80/TCP (active) (preferred)</span>
<span class="nv">$ </span>keast <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium service list <span class="nt">--clustermesh-affinity</span>
<span class="c"># =&gt; ID   Frontend               Service Type   Backend</span>
<span class="c">#    ...</span>
<span class="c">#    13   10.3.136.103:80/TCP    ClusterIP      1 =&gt; 10.1.1.217:80/TCP (active)</span>
<span class="c">#                                               2 =&gt; 10.1.1.207:80/TCP (active)</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 west의 webpod를 다 내리면, east에서도 east의 webpod로만 접속이 진행됩니다.&lt;/span&gt;</span>

<span class="c"># 다시 설정 원복</span>
<span class="nv">$ </span>kwest scale deployment webpod <span class="nt">--replicas</span> 2
</code></pre></div></div>

<h5 id="serviceciliumioshared">service.cilium.io/shared</h5>

<ul>
  <li><code class="language-plaintext highlighter-rouge">service.cilium.io/shared=false</code>로 하면 해당 클러스터의 webpod는 다른 ClusterMesh 클러스터에서 접근할 수 없게 됩니다.</li>
  <li>즉, west 클러스터에 <code class="language-plaintext highlighter-rouge">shared=false</code>로 설정하면, east 클러스터에서는 west 클러스터의 webpod에 접근할 수 없게 됩니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 현재 설정 상태 확인</span>
<span class="nv">$ </span>kwest <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium service list <span class="nt">--clustermesh-affinity</span>
<span class="nv">$ </span>keast <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium service list <span class="nt">--clustermesh-affinity</span>
<span class="nv">$ </span>kwest describe svc webpod | <span class="nb">grep </span>Annotations <span class="nt">-A3</span>
<span class="nv">$ </span>keast describe svc webpod | <span class="nb">grep </span>Annotations <span class="nt">-A3</span>

<span class="c"># local로 다시 변경</span>
<span class="nv">$ </span>kwest annotate service webpod service.cilium.io/affinity<span class="o">=</span><span class="nb">local</span> <span class="nt">--overwrite</span>
<span class="nv">$ </span>keast annotate service webpod service.cilium.io/affinity<span class="o">=</span><span class="nb">local</span> <span class="nt">--overwrite</span>
<span class="nv">$ </span>kwest describe svc webpod | <span class="nb">grep </span>Annotations <span class="nt">-A3</span>
<span class="nv">$ </span>keast describe svc webpod | <span class="nb">grep </span>Annotations <span class="nt">-A3</span>

<span class="nv">$ </span>kwest <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium service list <span class="nt">--clustermesh-affinity</span>
<span class="nv">$ </span>keast <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium service list <span class="nt">--clustermesh-affinity</span>

<span class="c"># shared=false : 적용 시, 다른 k8s 클러스터가 영향을 받는다!</span>
<span class="nv">$ </span>kwest annotate service webpod service.cilium.io/shared<span class="o">=</span><span class="nb">false</span>
<span class="c"># =&gt; service/webpod annotated</span>
<span class="nv">$ </span>kwest describe svc webpod | <span class="nb">grep </span>Annotations <span class="nt">-A3</span>
<span class="c"># =&gt; Annotations:              service.cilium.io/affinity: local</span>
<span class="c">#                              service.cilium.io/global: true</span>
<span class="c">#                              &lt;span style="color: green;"&gt;service.cilium.io/shared: false&lt;/span&gt;</span>
<span class="c">#    Selector:                 app=webpod</span>

<span class="nv">$ </span>kwest <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium service list <span class="nt">--clustermesh-affinity</span>
<span class="c"># =&gt; ID   Frontend                Service Type   Backend</span>
<span class="c">#    ...</span>
<span class="c">#    13   10.2.184.162:80/TCP     ClusterIP      1 =&gt; 10.0.1.171:80/TCP (active) (preferred)</span>
<span class="c">#                                                2 =&gt; 10.0.1.92:80/TCP (active) (preferred)</span>
<span class="c">#                                                3 =&gt; 10.1.1.207:80/TCP (active)</span>
<span class="c">#                                                4 =&gt; 10.1.1.217:80/TCP (active)</span>
<span class="nv">$ </span>keast <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium service list <span class="nt">--clustermesh-affinity</span>
<span class="c"># =&gt; ID   Frontend               Service Type   Backend</span>
<span class="c">#    ...</span>
<span class="c">#    13   10.3.136.103:80/TCP    ClusterIP      1 =&gt; 10.1.1.217:80/TCP (active) (preferred)</span>
<span class="c">#                                               2 =&gt; 10.1.1.207:80/TCP (active) (preferred)</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 east 클러스터에서는 west 클러스터의 webpod를 이용할 수 없습니다.</span>

<span class="c"># 호출 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--context</span> kind-west <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s --connect-timeout 1 webpod ; sleep 1; echo "---"; done;'</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--context</span> kind-east <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s --connect-timeout 1 webpod ; sleep 1; echo "---"; done;'</span>

<span class="c"># 다시 설정 원복</span>
<span class="nv">$ </span>kwest annotate service webpod service.cilium.io/shared<span class="o">=</span><span class="nb">true</span> <span class="nt">--overwrite</span>
<span class="c"># =&gt; service/webpod annotated</span>
<span class="nv">$ </span>kwest describe svc webpod | <span class="nb">grep </span>Annotations <span class="nt">-A3</span>
<span class="c"># =&gt; ...</span>
<span class="c">#                              service.cilium.io/shared: &lt;span style="color: green;"&gt;true&lt;/span&gt;</span>
<span class="nv">$ </span>keast describe svc webpod | <span class="nb">grep </span>Annotations <span class="nt">-A3</span>
<span class="c"># =&gt; ...</span>
<span class="c">#                              service.cilium.io/shared: &lt;span style="color: green;"&gt;true&lt;/span&gt;</span>

<span class="nv">$ </span>kwest <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium service list <span class="nt">--clustermesh-affinity</span>
<span class="c"># =&gt; ID   Frontend                Service Type   Backend</span>
<span class="c">#    ...</span>
<span class="c">#    13   10.2.184.162:80/TCP     ClusterIP      1 =&gt; 10.0.1.171:80/TCP (active) (preferred)</span>
<span class="c">#                                                2 =&gt; 10.0.1.92:80/TCP (active) (preferred)</span>
<span class="c">#                                                3 =&gt; 10.1.1.207:80/TCP (active)</span>
<span class="c">#                                                4 =&gt; 10.1.1.217:80/TCP (active)</span>
<span class="nv">$ </span>keast <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium service list <span class="nt">--clustermesh-affinity</span>
<span class="c"># =&gt; ID   Frontend               Service Type   Backend</span>
<span class="c">#    ...</span>
<span class="c">#    13   10.3.136.103:80/TCP    ClusterIP      1 =&gt; 10.1.1.217:80/TCP (active) (preferred)</span>
<span class="c">#                                               2 =&gt; 10.1.1.207:80/TCP (active) (preferred)</span>
<span class="c">#                                               3 =&gt; 10.0.1.171:80/TCP (active)</span>
<span class="c">#                                               4 =&gt; 10.0.1.92:80/TCP (active)</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 다시 shared=true로 설정하면, east 클러스터에서도 west 클러스터의 webpod를 이용할 수 있습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<h3 id="clustermesh-apiserver-파드-정보-확인">clustermesh-apiserver 파드 정보 확인</h3>
<ul>
  <li>krew pexec 플러그인 활용 - <a href="https://github.com/ssup2/kpexec">Github</a></li>
  <li><a href="https://docs.cilium.io/en/stable/operations/troubleshooting/#state-propagation">관련문서</a></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>kwest <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium node list 
<span class="c"># =&gt; Name                      IPv4 Address   Endpoint CIDR   IPv6 Address   Endpoint CIDR   Source</span>
<span class="c">#    east/east-control-plane   172.20.0.5     10.1.0.0/24                                    clustermesh</span>
<span class="c">#    east/east-worker          172.20.0.3     10.1.1.0/24                                    clustermesh</span>
<span class="c">#    west/west-control-plane   172.20.0.4     10.0.0.0/24                                    local</span>
<span class="c">#    west/west-worker          172.20.0.2     10.0.1.0/24                                    custom-resource</span>

<span class="nv">$ </span>keast <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium node list            
<span class="c"># =&gt; Name                      IPv4 Address   Endpoint CIDR   IPv6 Address   Endpoint CIDR   Source</span>
<span class="c">#    east/east-control-plane   172.20.0.5     10.1.0.0/24                                    custom-resource</span>
<span class="c">#    east/east-worker          172.20.0.3     10.1.1.0/24                                    local</span>
<span class="c">#    west/west-control-plane   172.20.0.4     10.0.0.0/24                                    clustermesh</span>
<span class="c">#    west/west-worker          172.20.0.2     10.0.1.0/24                                    clustermesh</span>

<span class="nv">$ </span>kwest <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium identity list
<span class="nv">$ </span>keast <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium identity list

<span class="nv">$ </span>kwest <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium bpf ipcache list
<span class="nv">$ </span>keast <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium bpf ipcache list
<span class="nv">$ </span>kwest <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium map get cilium_ipcache
<span class="nv">$ </span>keast <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium map get cilium_ipcache


<span class="nv">$ </span>kwest <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium service list
<span class="nv">$ </span>keast <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium service list

<span class="nv">$ </span>kwest <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium bpf lb list                      
<span class="c"># =&gt; ...</span>
<span class="c">#    10.2.140.84:443/TCP (0)     0.0.0.0:0 (2) (0) [ClusterIP, InternalLocal, non-routable]</span>

<span class="nv">$ </span>keast <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium bpf lb list                      
<span class="c"># =&gt; ...</span>
<span class="c">#    10.3.70.57:443/TCP (0)     0.0.0.0:0 (2) (0) [ClusterIP, InternalLocal, non-routable]</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl describe pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>clustermesh-apiserver
<span class="c"># =&gt; ...</span>
<span class="c">#    Containers:</span>
<span class="c">#      etcd:</span>
<span class="c">#        Container ID:  containerd://924c44c01307d2812baa1c15f53b008720f878fedb45c29b8ec35c641d71b0ae</span>
<span class="c">#        Image:         quay.io/cilium/clustermesh-apiserver:v1.17.6@sha256:f619e97432db427e1511bf91af3be8ded418c53a353a09629e04c5880659d1df</span>
<span class="c">#        Image ID:      quay.io/cilium/clustermesh-apiserver@sha256:f619e97432db427e1511bf91af3be8ded418c53a353a09629e04c5880659d1df</span>
<span class="c">#        Ports:         2379/TCP, 9963/TCP</span>
<span class="c">#        Host Ports:    0/TCP, 0/TCP</span>
<span class="c">#        Command:</span>
<span class="c">#          /usr/bin/etcd</span>
<span class="c">#        Args:</span>
<span class="c">#          --data-dir=/var/run/etcd</span>
<span class="c">#          --name=clustermesh-apiserver</span>
<span class="c">#          --client-cert-auth</span>
<span class="c">#          --trusted-ca-file=/var/lib/etcd-secrets/ca.crt</span>
<span class="c">#          --cert-file=/var/lib/etcd-secrets/tls.crt</span>
<span class="c">#          --key-file=/var/lib/etcd-secrets/tls.key</span>
<span class="c">#          --listen-client-urls=https://127.0.0.1:2379,https://[$(HOSTNAME_IP)]:2379</span>
<span class="c">#          --advertise-client-urls=https://[$(HOSTNAME_IP)]:2379</span>
<span class="c">#          --initial-cluster-token=$(INITIAL_CLUSTER_TOKEN)</span>
<span class="c">#          --auto-compaction-retention=1</span>
<span class="c">#          --listen-metrics-urls=http://[$(HOSTNAME_IP)]:9963</span>
<span class="c">#          --metrics=basic</span>
<span class="c">#    ...</span>
<span class="c">#      apiserver:</span>
<span class="c">#        Container ID:  containerd://eecfbc62afc019580ff533a9a4d57b4e2c193ec48a2e15f9875e3866bfdc86dd</span>
<span class="c">#        Image:         quay.io/cilium/clustermesh-apiserver:v1.17.6@sha256:f619e97432db427e1511bf91af3be8ded418c53a353a09629e04c5880659d1df</span>
<span class="c">#        Image ID:      quay.io/cilium/clustermesh-apiserver@sha256:f619e97432db427e1511bf91af3be8ded418c53a353a09629e04c5880659d1df</span>
<span class="c">#        Ports:         9880/TCP, 9962/TCP</span>
<span class="c">#        Host Ports:    0/TCP, 0/TCP</span>
<span class="c">#        Command:</span>
<span class="c">#          /usr/bin/clustermesh-apiserver</span>
<span class="c">#        Args:</span>
<span class="c">#          clustermesh</span>
<span class="c">#          --debug</span>
<span class="c">#          --cluster-name=$(CLUSTER_NAME)</span>
<span class="c">#          --cluster-id=$(CLUSTER_ID)</span>
<span class="c">#          --kvstore-opt=etcd.config=/var/lib/cilium/etcd-config.yaml</span>
<span class="c">#          --kvstore-opt=etcd.qps=20</span>
<span class="c">#          --kvstore-opt=etcd.bootstrapQps=10000</span>
<span class="c">#          --max-connected-clusters=255</span>
<span class="c">#          --health-port=9880</span>
<span class="c">#          --enable-external-workloads=false</span>
<span class="c">#          --prometheus-serve-addr=:9962</span>
<span class="c">#          --controller-group-metrics=all</span>
<span class="c">#    ...</span>

<span class="c"># etcd 컨터이너 로그 확인</span>
<span class="nv">$ </span>kubectl logs <span class="nt">-n</span> kube-system deployment/clustermesh-apiserver <span class="nt">-c</span> etcd

<span class="c"># apiserver 컨터이너 로그 확인</span>
<span class="nv">$ </span>kubectl logs <span class="nt">-n</span> kube-system deployment/clustermesh-apiserver <span class="nt">-c</span> apiserver


<span class="c">#</span>
<span class="nv">$ </span>kwest <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium status <span class="nt">--all-clusters</span>
<span class="c"># =&gt; ClusterMesh:            1/1 remote clusters ready, 1 global-services</span>
<span class="c">#       east: ready, 2 nodes, 9 endpoints, 7 identities, 1 services, 0 MCS-API service exports, 0 reconnections (last: never)</span>
<span class="c">#       └  etcd: 1/1 connected, leases=0, lock leases=0, has-quorum=true: endpoint status checks are disabled, ID: b4f3f4384ecc342c</span>
<span class="c">#       └  remote configuration: expected=true, retrieved=true, cluster-id=2, kvstoremesh=false, sync-canaries=true, service-exports=disabled</span>
<span class="c">#       └  synchronization status: nodes=true, endpoints=true, identities=true, services=true</span>

<span class="nv">$ </span>keast <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium status <span class="nt">--all-clusters</span>
<span class="c"># =&gt; ClusterMesh:            1/1 remote clusters ready, 1 global-services</span>
<span class="c">#       west: ready, 2 nodes, 9 endpoints, 7 identities, 1 services, 0 MCS-API service exports, 0 reconnections (last: never)</span>
<span class="c">#       └  etcd: 1/1 connected, leases=0, lock leases=0, has-quorum=true: endpoint status checks are disabled, ID: ea025158a8e3c0a3</span>
<span class="c">#       └  remote configuration: expected=true, retrieved=true, cluster-id=1, kvstoremesh=false, sync-canaries=true, service-exports=disabled</span>
<span class="c">#       └  synchronization status: nodes=true, endpoints=true, identities=true, services=true</span>

<span class="c"># etcd 컨테이너 bash 진입 후 확인</span>
<span class="c"># krew pexec 플러그인 활용 https://github.com/ssup2/kpexec</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>clustermesh-apiserver
<span class="c"># =&gt; NAME                                     READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    clustermesh-apiserver-5cf45db9cc-r26tw   2/2     Running   0          4h1m</span>
<span class="nv">$ DPOD</span><span class="o">=</span>clustermesh-apiserver-5cf45db9cc-r26tw

<span class="nv">$ </span>kubectl pexec <span class="nv">$DPOD</span> <span class="nt">-it</span> <span class="nt">-T</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> etcd <span class="nt">--</span> bash
<span class="c"># =&gt; Create cnsenter pod (cnsenter-ehk0cx7v3a)</span>
<span class="c">#    Wait to run cnsenter pod (cnsenter-ehk0cx7v3a)</span>
<span class="c">#    </span>
<span class="c">#    If you don't see a command prompt, try pressing enter.</span>
<span class="nt">------------------------------------------------</span>
<span class="nv">$ </span>ps <span class="nt">-ef</span>
<span class="nv">$ </span>ps <span class="nt">-ef</span> <span class="nt">-T</span> <span class="nt">-o</span> pid,ppid,comm,args
<span class="nv">$ </span>ps <span class="nt">-ef</span> <span class="nt">-T</span> <span class="nt">-o</span> args
<span class="c"># =&gt; COMMAND</span>
<span class="c">#    /usr/bin/etcd --data-dir=/var/run/etcd --name=clustermesh-apiserver --client-cert-auth --trusted-ca-file=/var/lib/etcd-secrets/ca.crt --cert-file=/var/lib/etcd-secrets/tls.crt --</span>

<span class="nv">$ </span><span class="nb">cat</span> /proc/1/cmdline <span class="p">;</span> <span class="nb">echo</span>
<span class="c"># =&gt; /usr/bin/etcd--data-dir=/var/run/etcd--name=clustermesh-apiserver--client-cert-auth--trusted-ca-file=/var/lib/etcd-secrets/ca.crt--cert-file=/var/lib/etcd-secrets/tls.crt--key-file=/var/lib/etcd-secrets/tls.key--listen-client-urls=https://127.0.0.1:2379,https://[10.0.1.223]:2379--advertise-client-urls=https://[10.0.1.223]:2379--initial-cluster-token=7a3aaa07-ca4f-4627-a84b-d7cb8aff8987--auto-compaction-retention=1--listen-metrics-urls=http://[10.0.1.223]:9963--metrics=basic</span>

<span class="nv">$ </span>ss <span class="nt">-tnlp</span>
<span class="c"># =&gt; LISTEN    0       4096     10.0.1.223:2379     0.0.0.0:*           users:(("etcd",pid=1,fd=8))</span>
<span class="nv">$ </span>ss <span class="nt">-tnp</span>
<span class="c"># =&gt; ESTAB     0       0        10.0.1.223:2379     172.20.0.4:43498    users:(("etcd",pid=1,fd=14))</span>
<span class="c">#    ESTAB     0       0        10.0.1.223:2379     172.20.0.4:39300    users:(("etcd",pid=1,fd=15))</span>

<span class="nv">$ </span><span class="nb">exit</span>
<span class="nt">------------------------------------------------</span>

<span class="nv">$ </span>kubectl pexec <span class="nv">$DPOD</span> <span class="nt">-it</span> <span class="nt">-T</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> apiserver <span class="nt">--</span> bash
<span class="nt">------------------------------------------------</span>
<span class="nv">$ </span>ps <span class="nt">-ef</span>
<span class="nv">$ </span>ps <span class="nt">-ef</span> <span class="nt">-T</span> <span class="nt">-o</span> pid,ppid,comm,args
<span class="nv">$ </span>ps <span class="nt">-ef</span> <span class="nt">-T</span> <span class="nt">-o</span> args
<span class="c"># =&gt; COMMAND</span>
<span class="c">#    /usr/bin/clustermesh-apiserver clustermesh --debug --cluster-name=west --cluster-id=1 --kvstore-opt=etcd.config=/var/lib/cilium/etcd-config.yaml --kvstore-opt=etcd.qps=20 --kvsto</span>
<span class="nv">$ </span><span class="nb">cat</span> /proc/1/cmdline <span class="p">;</span> <span class="nb">echo</span>
<span class="c"># =&gt; /usr/bin/clustermesh-apiserverclustermesh--debug--cluster-name=west--cluster-id=1--kvstore-opt=etcd.config=/var/lib/cilium/etcd-config.yaml--kvstore-opt=etcd.qps=20--kvstore-opt=etcd.bootstrapQps=10000--max-connected-clusters=255--health-port=9880--enable-external-workloads=false--prometheus-serve-addr=:9962--controller-group-metrics=all</span>

<span class="nv">$ </span>ss <span class="nt">-tnlp</span>
<span class="c"># =&gt; LISTEN           0                4096                          10.0.1.223:2379                           0.0.0.0:*</span>
<span class="c">#    LISTEN           0                4096                           127.0.0.1:2379                           0.0.0.0:*</span>
<span class="nv">$ </span>ss <span class="nt">-tnp</span>
<span class="c"># =&gt; State           Recv-Q           Send-Q                     Local Address:Port                      Peer Address:Port            Process</span>
<span class="c">#    ESTAB           0                0                             10.0.1.223:60950                       172.20.0.4:6443             users:(("clustermesh-api",pid=1,fd=6))</span>
<span class="c">#    ESTAB           0                0                              127.0.0.1:33160                        127.0.0.1:2379             users:(("clustermesh-api",pid=1,fd=7))</span>
<span class="nv">$ </span><span class="nb">exit</span>
<span class="nt">------------------------------------------------</span>
</code></pre></div></div>

<h3 id="kind-클러스터-삭제">kind 클러스터 삭제</h3>

<ul>
  <li>실습 완료 후 kind 클러스터를 삭제합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kind delete cluster <span class="nt">--name</span> west <span class="o">&amp;&amp;</span> kind delete cluster <span class="nt">--name</span> east <span class="o">&amp;&amp;</span> kind delete cluster <span class="nt">--name</span> center
</code></pre></div></div>

<hr />

<h2 id="마치며">마치며</h2>

<p>이번 포스트에서는 BGP를 통한 라우팅 및 BGP를 통한 LoadBalancer - ExternalIP 광고,
ClusterMesh를 통한 클러스터 간 통신을 설정하는 방법에 대해 알아보았습니다.
다양한 유스케이스에 대한 기능이 준비되어있음에 감탄했습니다.</p>

<p>특히 ClusterMesh는 단일 CSP에서도 사용할 수 있지만, 멀티 클라우드 환경이나 하이브리드 클라우드 환경에서도
유용할것 같아서 정말 좋은 기능인것 같습니다.
BGP의 동작에 대해서도 조금이나마 이해를 갖게 되었고, 스터디를 통해서 정말 많은 것을 배워가는것 같습니다.</p>]]></content><author><name></name></author><category term="cilium" /><category term="kubernetes," /><category term="network," /><category term="linux," /><category term="cilium," /><category term="bgp," /><category term="kind," /><category term="cluster-mesh" /><summary type="html"><![CDATA[이번 포스트에서는 BGP를 통한 라우팅과 kind, cluster-mesh를 통한 멀티 클러스터 환경에서의 Cilium 동작을 살펴보겠습니다.]]></summary></entry><entry><title type="html">[Cilium] Networking - 노드의 파드들간 통신 상세 part 2</title><link href="https://sweetlittlebird.github.io/posts/2025-08-10-Cilium-Week4/" rel="alternate" type="text/html" title="[Cilium] Networking - 노드의 파드들간 통신 상세 part 2" /><published>2025-08-10T00:10:18+09:00</published><updated>2025-08-10T00:10:18+09:00</updated><id>https://sweetlittlebird.github.io/posts/Cilium%20-%20Week4</id><content type="html" xml:base="https://sweetlittlebird.github.io/posts/2025-08-10-Cilium-Week4/"><![CDATA[<h2 id="들어가며">들어가며</h2>

<p>이번 포스트에서는 Overlay Network인 VXLAN을 통한 파드간 통신과 Kubernetes 서비스의 외부 노출, LB-IPAM 등을 통한 통신을 살펴보겠습니다.</p>

<hr />

<h2 id="실습-환경-구성">실습 환경 구성</h2>

<ul>
  <li>이번 실습에서는 다음 그림과 같이 k8s-w0를 별도의 네트워크에 배치하고 router를 통해 k8s-w0와 k8s-ctr/w1 노드간 통신을 확인합니다.
<img src="/assets/2025/cilium/w4/20250810_cilium_w4_2.png" alt="img.png" class="image-center" />
    <ul>
      <li>기본 배포 가상 머신 : k8s-ctr, k8s-w1, k8s-w0, router</li>
      <li><strong>router</strong> : router : 192.168.10.0/24 ↔ 192.168.20.0/24 대역 라우팅 역할, k8s 에 join 되지 않은 서버, loop1/loop2 dump 인터페이스 배치</li>
      <li><strong>k8s-w0</strong> : k8s-ctr/w1 노드와 다른 네트워크 대역에 배치됩니다.</li>
      <li>실습 동작에 필요한 static routing이 설저된 상태로 배포 됩니다.</li>
      <li>Cilium CNI v1.18이 설치된 상태로 배포됩니다.</li>
    </ul>
  </li>
</ul>

<h3 id="실습환경-배포-파일">실습환경 배포 파일</h3>

<ul>
  <li>
    <p><strong>Vagrantfile</strong> : 가상머신 정의, 부팅 시 초기 프로비저닝 설정을 포함하는 Vagrantfile입니다.</p>

    <div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Variables</span>
<span class="no">K8SV</span> <span class="o">=</span> <span class="s1">'1.33.2-1.1'</span> <span class="c1"># Kubernetes Version : apt list -a kubelet , ex) 1.32.5-1.1</span>
<span class="no">CONTAINERDV</span> <span class="o">=</span> <span class="s1">'1.7.27-1'</span> <span class="c1"># Containerd Version : apt list -a containerd.io , ex) 1.6.33-1</span>
<span class="no">CILIUMV</span> <span class="o">=</span> <span class="s1">'1.18.0'</span> <span class="c1"># Cilium CNI Version : https://github.com/cilium/cilium/tags</span>
<span class="no">N</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># max number of worker nodes</span>
  
<span class="c1"># Base Image  https://portal.cloud.hashicorp.com/vagrant/discover/bento/ubuntu-24.04</span>
<span class="no">BOX_IMAGE</span> <span class="o">=</span> <span class="s2">"bento/ubuntu-24.04"</span>
<span class="no">BOX_VERSION</span> <span class="o">=</span> <span class="s2">"202502.21.0"</span>
  
<span class="no">Vagrant</span><span class="p">.</span><span class="nf">configure</span><span class="p">(</span><span class="s2">"2"</span><span class="p">)</span> <span class="k">do</span> <span class="o">|</span><span class="n">config</span><span class="o">|</span>
<span class="c1">#-ControlPlane Node</span>
    <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">define</span> <span class="s2">"k8s-ctr"</span> <span class="k">do</span> <span class="o">|</span><span class="n">subconfig</span><span class="o">|</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="no">BOX_IMAGE</span>
        
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box_version</span> <span class="o">=</span> <span class="no">BOX_VERSION</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provider</span> <span class="s2">"virtualbox"</span> <span class="k">do</span> <span class="o">|</span><span class="n">vb</span><span class="o">|</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--groups"</span><span class="p">,</span> <span class="s2">"/Cilium-Lab"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--nicpromisc2"</span><span class="p">,</span> <span class="s2">"allow-all"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">name</span> <span class="o">=</span> <span class="s2">"k8s-ctr"</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">cpus</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">memory</span> <span class="o">=</span> <span class="mi">2560</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">linked_clone</span> <span class="o">=</span> <span class="kp">true</span>
      <span class="k">end</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">host_name</span> <span class="o">=</span> <span class="s2">"k8s-ctr"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.10.100"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="mi">60000</span><span class="p">,</span> <span class="ss">auto_correct: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">id: </span><span class="s2">"ssh"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">synced_folder</span> <span class="s2">"./"</span><span class="p">,</span> <span class="s2">"/vagrant"</span><span class="p">,</span> <span class="ss">disabled: </span><span class="kp">true</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/4w/init_cfg.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">K8SV</span><span class="p">,</span> <span class="no">CONTAINERDV</span> <span class="p">]</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/4w/k8s-ctr.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">N</span><span class="p">,</span> <span class="no">CILIUMV</span><span class="p">,</span> <span class="no">K8SV</span> <span class="p">]</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/4w/route-add1.sh"</span>
    <span class="k">end</span>
  
<span class="c1">#-Worker Nodes Subnet1</span>
  <span class="p">(</span><span class="mi">1</span><span class="o">..</span><span class="no">N</span><span class="p">).</span><span class="nf">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">i</span><span class="o">|</span>
    <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">define</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span> <span class="k">do</span> <span class="o">|</span><span class="n">subconfig</span><span class="o">|</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="no">BOX_IMAGE</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box_version</span> <span class="o">=</span> <span class="no">BOX_VERSION</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provider</span> <span class="s2">"virtualbox"</span> <span class="k">do</span> <span class="o">|</span><span class="n">vb</span><span class="o">|</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--groups"</span><span class="p">,</span> <span class="s2">"/Cilium-Lab"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--nicpromisc2"</span><span class="p">,</span> <span class="s2">"allow-all"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">name</span> <span class="o">=</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">cpus</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">memory</span> <span class="o">=</span> <span class="mi">1536</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">linked_clone</span> <span class="o">=</span> <span class="kp">true</span>
      <span class="k">end</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">host_name</span> <span class="o">=</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.10.10</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="s2">"6000</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span> <span class="ss">auto_correct: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">id: </span><span class="s2">"ssh"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">synced_folder</span> <span class="s2">"./"</span><span class="p">,</span> <span class="s2">"/vagrant"</span><span class="p">,</span> <span class="ss">disabled: </span><span class="kp">true</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/4w/init_cfg.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">K8SV</span><span class="p">,</span> <span class="no">CONTAINERDV</span><span class="p">]</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/4w/k8s-w.sh"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/4w/route-add1.sh"</span>
    <span class="k">end</span>
  <span class="k">end</span>
  
<span class="c1">#-Router Node</span>
    <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">define</span> <span class="s2">"router"</span> <span class="k">do</span> <span class="o">|</span><span class="n">subconfig</span><span class="o">|</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="no">BOX_IMAGE</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box_version</span> <span class="o">=</span> <span class="no">BOX_VERSION</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provider</span> <span class="s2">"virtualbox"</span> <span class="k">do</span> <span class="o">|</span><span class="n">vb</span><span class="o">|</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--groups"</span><span class="p">,</span> <span class="s2">"/Cilium-Lab"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">name</span> <span class="o">=</span> <span class="s2">"router"</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">cpus</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">memory</span> <span class="o">=</span> <span class="mi">768</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">linked_clone</span> <span class="o">=</span> <span class="kp">true</span>
      <span class="k">end</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">host_name</span> <span class="o">=</span> <span class="s2">"router"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.10.200"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="mi">60009</span><span class="p">,</span> <span class="ss">auto_correct: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">id: </span><span class="s2">"ssh"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.20.200"</span><span class="p">,</span> <span class="ss">auto_config: </span><span class="kp">false</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">synced_folder</span> <span class="s2">"./"</span><span class="p">,</span> <span class="s2">"/vagrant"</span><span class="p">,</span> <span class="ss">disabled: </span><span class="kp">true</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/4w/router.sh"</span>
    <span class="k">end</span>
  
<span class="c1">#-Worker Nodes Subnet2</span>
    <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">define</span> <span class="s2">"k8s-w0"</span> <span class="k">do</span> <span class="o">|</span><span class="n">subconfig</span><span class="o">|</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="no">BOX_IMAGE</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box_version</span> <span class="o">=</span> <span class="no">BOX_VERSION</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provider</span> <span class="s2">"virtualbox"</span> <span class="k">do</span> <span class="o">|</span><span class="n">vb</span><span class="o">|</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--groups"</span><span class="p">,</span> <span class="s2">"/Cilium-Lab"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--nicpromisc2"</span><span class="p">,</span> <span class="s2">"allow-all"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">name</span> <span class="o">=</span> <span class="s2">"k8s-w0"</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">cpus</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">memory</span> <span class="o">=</span> <span class="mi">1536</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">linked_clone</span> <span class="o">=</span> <span class="kp">true</span>
      <span class="k">end</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">host_name</span> <span class="o">=</span> <span class="s2">"k8s-w0"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.20.100"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="mi">60010</span><span class="p">,</span> <span class="ss">auto_correct: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">id: </span><span class="s2">"ssh"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">synced_folder</span> <span class="s2">"./"</span><span class="p">,</span> <span class="s2">"/vagrant"</span><span class="p">,</span> <span class="ss">disabled: </span><span class="kp">true</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/4w/init_cfg.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">K8SV</span><span class="p">,</span> <span class="no">CONTAINERDV</span><span class="p">]</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/4w/k8s-w.sh"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/4w/route-add2.sh"</span>
    <span class="k">end</span>
<span class="k">end</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>init_cfg.sh</strong> : args 참고하여 초기 설정을 수행하는 스크립트입니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config Start &lt;&lt;&lt;&lt;"</span>
  
<span class="nb">echo</span> <span class="s2">"[TASK 1] Setting Profile &amp; Bashrc"</span>
<span class="nb">echo</span> <span class="s1">'alias vi=vim'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s2">"sudo su -"</span> <span class="o">&gt;&gt;</span> /home/vagrant/.bashrc
<span class="nb">ln</span> <span class="nt">-sf</span> /usr/share/zoneinfo/Asia/Seoul /etc/localtime <span class="c"># Change Timezone</span>
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 2] Disable AppArmor"</span>
systemctl stop ufw <span class="o">&amp;&amp;</span> systemctl disable ufw <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
systemctl stop apparmor <span class="o">&amp;&amp;</span> systemctl disable apparmor <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 3] Disable and turn off SWAP"</span>
swapoff <span class="nt">-a</span> <span class="o">&amp;&amp;</span> <span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'/swap/s/^/#/'</span> /etc/fstab
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 4] Install Packages"</span>
apt update <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
apt-get <span class="nb">install </span>apt-transport-https ca-certificates curl gpg <span class="nt">-y</span> <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="c"># Download the public signing key for the Kubernetes package repositories.</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> <span class="nt">-m</span> 755 /etc/apt/keyrings
<span class="nv">K8SMMV</span><span class="o">=</span><span class="si">$(</span><span class="nb">echo</span> <span class="nv">$1</span> | <span class="nb">sed</span> <span class="nt">-En</span> <span class="s1">'s/^([0-9]+\.[0-9]+)\..*/\1/p'</span><span class="si">)</span>
curl <span class="nt">-fsSL</span> https://pkgs.k8s.io/core:/stable:/v<span class="nv">$K8SMMV</span>/deb/Release.key | <span class="nb">sudo </span>gpg <span class="nt">--dearmor</span> <span class="nt">-o</span> /etc/apt/keyrings/kubernetes-apt-keyring.gpg
<span class="nb">echo</span> <span class="s2">"deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v</span><span class="nv">$K8SMMV</span><span class="s2">/deb/ /"</span> <span class="o">&gt;&gt;</span> /etc/apt/sources.list.d/kubernetes.list
curl <span class="nt">-fsSL</span> https://download.docker.com/linux/ubuntu/gpg <span class="nt">-o</span> /etc/apt/keyrings/docker.asc
<span class="nb">echo</span> <span class="s2">"deb [arch=</span><span class="si">$(</span>dpkg <span class="nt">--print-architecture</span><span class="si">)</span><span class="s2"> signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu </span><span class="si">$(</span><span class="nb">.</span> /etc/os-release <span class="o">&amp;&amp;</span> <span class="nb">echo</span> <span class="s2">"</span><span class="nv">$VERSION_CODENAME</span><span class="s2">"</span><span class="si">)</span><span class="s2"> stable"</span> | <span class="nb">tee</span> /etc/apt/sources.list.d/docker.list <span class="o">&gt;</span> /dev/null
  
<span class="c"># packets traversing the bridge are processed by iptables for filtering</span>
<span class="nb">echo </span>1 <span class="o">&gt;</span> /proc/sys/net/ipv4/ip_forward
<span class="nb">echo</span> <span class="s2">"net.ipv4.ip_forward = 1"</span> <span class="o">&gt;&gt;</span> /etc/sysctl.d/k8s.conf
  
<span class="c"># enable br_netfilter for iptables </span>
modprobe br_netfilter
modprobe overlay
<span class="nb">echo</span> <span class="s2">"br_netfilter"</span> <span class="o">&gt;&gt;</span> /etc/modules-load.d/k8s.conf
<span class="nb">echo</span> <span class="s2">"overlay"</span> <span class="o">&gt;&gt;</span> /etc/modules-load.d/k8s.conf
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 5] Install Kubernetes components (kubeadm, kubelet and kubectl)"</span>
<span class="c"># Update the apt package index, install kubelet, kubeadm and kubectl, and pin their version</span>
apt update <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="c"># apt list -a kubelet ; apt list -a containerd.io</span>
apt-get <span class="nb">install</span> <span class="nt">-y</span> <span class="nv">kubelet</span><span class="o">=</span><span class="nv">$1</span> <span class="nv">kubectl</span><span class="o">=</span><span class="nv">$1</span> <span class="nv">kubeadm</span><span class="o">=</span><span class="nv">$1</span> containerd.io<span class="o">=</span><span class="nv">$2</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
apt-mark hold kubelet kubeadm kubectl <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="c"># containerd configure to default and cgroup managed by systemd</span>
containerd config default <span class="o">&gt;</span> /etc/containerd/config.toml
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'s/SystemdCgroup = false/SystemdCgroup = true/g'</span> /etc/containerd/config.toml
  
<span class="c"># avoid WARN&amp;ERRO(default endpoints) when crictl run  </span>
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; /etc/crictl.yaml
runtime-endpoint: unix:///run/containerd/containerd.sock
image-endpoint: unix:///run/containerd/containerd.sock
</span><span class="no">EOF
  
</span><span class="c"># ready to install for k8s </span>
systemctl restart containerd <span class="o">&amp;&amp;</span> systemctl <span class="nb">enable </span>containerd
systemctl <span class="nb">enable</span> <span class="nt">--now</span> kubelet
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 6] Install Packages &amp; Helm"</span>
<span class="nb">export </span><span class="nv">DEBIAN_FRONTEND</span><span class="o">=</span>noninteractive
apt-get <span class="nb">install</span> <span class="nt">-y</span> bridge-utils sshpass net-tools conntrack ngrep tcpdump ipset arping wireguard jq yq tree bash-completion unzip kubecolor termshark <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
curl <span class="nt">-s</span> https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>k8s-ctr.sh</strong> : kubeadm init를 통하여 kubernetes controlplane 노드를 설정하고 Cilium CNI 설치, 편리성 설정(k, kc)하는 스크립트입니다. local-path-storageclass와 metrics-server도 설치합니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Controlplane config Start &lt;&lt;&lt;&lt;"</span>
  
<span class="nb">echo</span> <span class="s2">"[TASK 1] Initial Kubernetes"</span>
curl <span class="nt">--silent</span> <span class="nt">-o</span> /root/kubeadm-init-ctr-config.yaml https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/kubeadm-init-ctr-config.yaml
<span class="nv">K8SMMV</span><span class="o">=</span><span class="si">$(</span><span class="nb">echo</span> <span class="nv">$3</span> | <span class="nb">sed</span> <span class="nt">-En</span> <span class="s1">'s/^([0-9]+\.[0-9]+\.[0-9]+).*/\1/p'</span><span class="si">)</span>
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/K8S_VERSION_PLACEHOLDER/v</span><span class="k">${</span><span class="nv">K8SMMV</span><span class="k">}</span><span class="s2">/g"</span> /root/kubeadm-init-ctr-config.yaml
kubeadm init <span class="nt">--config</span><span class="o">=</span><span class="s2">"/root/kubeadm-init-ctr-config.yaml"</span>  <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 2] Setting kube config file"</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> /root/.kube
<span class="nb">cp</span> <span class="nt">-i</span> /etc/kubernetes/admin.conf /root/.kube/config
<span class="nb">chown</span> <span class="si">$(</span><span class="nb">id</span> <span class="nt">-u</span><span class="si">)</span>:<span class="si">$(</span><span class="nb">id</span> <span class="nt">-g</span><span class="si">)</span> /root/.kube/config
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 3] Source the completion"</span>
<span class="nb">echo</span> <span class="s1">'source &lt;(kubectl completion bash)'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'source &lt;(kubeadm completion bash)'</span> <span class="o">&gt;&gt;</span> /etc/profile
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 4] Alias kubectl to k"</span>
<span class="nb">echo</span> <span class="s1">'alias k=kubectl'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'alias kc=kubecolor'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'complete -F __start_kubectl k'</span> <span class="o">&gt;&gt;</span> /etc/profile
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 5] Install Kubectx &amp; Kubens"</span>
git clone https://github.com/ahmetb/kubectx /opt/kubectx <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">ln</span> <span class="nt">-s</span> /opt/kubectx/kubens /usr/local/bin/kubens
<span class="nb">ln</span> <span class="nt">-s</span> /opt/kubectx/kubectx /usr/local/bin/kubectx
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 6] Install Kubeps &amp; Setting PS1"</span>
git clone https://github.com/jonmosco/kube-ps1.git /root/kube-ps1 <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="sh">"</span><span class="no">EOT</span><span class="sh">" &gt;&gt; /root/.bash_profile
source /root/kube-ps1/kube-ps1.sh
KUBE_PS1_SYMBOL_ENABLE=true
function get_cluster_short() {
  echo "</span><span class="nv">$1</span><span class="sh">" | cut -d . -f1
}
KUBE_PS1_CLUSTER_FUNCTION=get_cluster_short
KUBE_PS1_SUFFIX=') '
PS1='</span><span class="si">$(</span>kube_ps1<span class="si">)</span><span class="sh">'</span><span class="nv">$PS1</span><span class="sh">
</span><span class="no">EOT
</span>kubectl config rename-context <span class="s2">"kubernetes-admin@kubernetes"</span> <span class="s2">"HomeLab"</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 7] Install Cilium CNI"</span>
<span class="nv">NODEIP</span><span class="o">=</span><span class="si">$(</span>ip <span class="nt">-4</span> addr show eth1 | <span class="nb">grep</span> <span class="nt">-oP</span> <span class="s1">'(?&lt;=inet\s)\d+(\.\d+){3}'</span><span class="si">)</span>
helm repo add cilium https://helm.cilium.io/ <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
helm repo update <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
helm <span class="nb">install </span>cilium cilium/cilium <span class="nt">--version</span> <span class="nv">$2</span> <span class="nt">--namespace</span> kube-system <span class="se">\</span>
<span class="nt">--set</span> <span class="nv">k8sServiceHost</span><span class="o">=</span>192.168.10.100 <span class="nt">--set</span> <span class="nv">k8sServicePort</span><span class="o">=</span>6443 <span class="se">\</span>
<span class="nt">--set</span> ipam.mode<span class="o">=</span><span class="s2">"cluster-pool"</span> <span class="nt">--set</span> ipam.operator.clusterPoolIPv4PodCIDRList<span class="o">={</span><span class="s2">"172.20.0.0/16"</span><span class="o">}</span> <span class="nt">--set</span> <span class="nv">ipv4NativeRoutingCIDR</span><span class="o">=</span>172.20.0.0/16 <span class="se">\</span>
<span class="nt">--set</span> <span class="nv">routingMode</span><span class="o">=</span>native <span class="nt">--set</span> <span class="nv">autoDirectNodeRoutes</span><span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> <span class="nv">kubeProxyReplacement</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> bpf.masquerade<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> <span class="nv">installNoConntrackIptablesRules</span><span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> endpointHealthChecking.enabled<span class="o">=</span><span class="nb">false</span> <span class="nt">--set</span> <span class="nv">healthChecking</span><span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
<span class="nt">--set</span> hubble.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> hubble.relay.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> hubble.ui.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> hubble.ui.service.type<span class="o">=</span>NodePort <span class="nt">--set</span> hubble.ui.service.nodePort<span class="o">=</span>30003 <span class="se">\</span>
<span class="nt">--set</span> prometheus.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> operator.prometheus.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> hubble.metrics.enableOpenMetrics<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> hubble.metrics.enabled<span class="o">=</span><span class="s2">"{dns,drop,tcp,flow,port-distribution,icmp,httpV2:exemplars=true;labelsContext=source_ip</span><span class="se">\,</span><span class="s2">source_namespace</span><span class="se">\,</span><span class="s2">source_workload</span><span class="se">\,</span><span class="s2">destination_ip</span><span class="se">\,</span><span class="s2">destination_namespace</span><span class="se">\,</span><span class="s2">destination_workload</span><span class="se">\,</span><span class="s2">traffic_direction}"</span> <span class="se">\</span>
<span class="nt">--set</span> operator.replicas<span class="o">=</span>1 <span class="nt">--set</span> debug.enabled<span class="o">=</span><span class="nb">true</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 8] Install Cilium / Hubble CLI"</span>
<span class="nv">CILIUM_CLI_VERSION</span><span class="o">=</span><span class="si">$(</span>curl <span class="nt">-s</span> https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt<span class="si">)</span>
<span class="nv">CLI_ARCH</span><span class="o">=</span>amd64
<span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span><span class="si">)</span><span class="s2">"</span> <span class="o">=</span> <span class="s2">"aarch64"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then </span><span class="nv">CLI_ARCH</span><span class="o">=</span>arm64<span class="p">;</span> <span class="k">fi
</span>curl <span class="nt">-L</span> <span class="nt">--fail</span> <span class="nt">--remote-name-all</span> https://github.com/cilium/cilium-cli/releases/download/<span class="k">${</span><span class="nv">CILIUM_CLI_VERSION</span><span class="k">}</span>/cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">tar </span>xzvfC cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz /usr/local/bin
<span class="nb">rm </span>cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz
  
<span class="nv">HUBBLE_VERSION</span><span class="o">=</span><span class="si">$(</span>curl <span class="nt">-s</span> https://raw.githubusercontent.com/cilium/hubble/master/stable.txt<span class="si">)</span>
<span class="nv">HUBBLE_ARCH</span><span class="o">=</span>amd64
<span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span><span class="si">)</span><span class="s2">"</span> <span class="o">=</span> <span class="s2">"aarch64"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then </span><span class="nv">HUBBLE_ARCH</span><span class="o">=</span>arm64<span class="p">;</span> <span class="k">fi
</span>curl <span class="nt">-L</span> <span class="nt">--fail</span> <span class="nt">--remote-name-all</span> https://github.com/cilium/hubble/releases/download/<span class="nv">$HUBBLE_VERSION</span>/hubble-linux-<span class="k">${</span><span class="nv">HUBBLE_ARCH</span><span class="k">}</span>.tar.gz <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">tar </span>xzvfC hubble-linux-<span class="k">${</span><span class="nv">HUBBLE_ARCH</span><span class="k">}</span>.tar.gz /usr/local/bin
<span class="nb">rm </span>hubble-linux-<span class="k">${</span><span class="nv">HUBBLE_ARCH</span><span class="k">}</span>.tar.gz
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 9] Remove node taint"</span>
kubectl taint nodes k8s-ctr node-role.kubernetes.io/control-plane-
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 10] local DNS with hosts file"</span>
<span class="nb">echo</span> <span class="s2">"192.168.10.100 k8s-ctr"</span> <span class="o">&gt;&gt;</span> /etc/hosts
<span class="nb">echo</span> <span class="s2">"192.168.10.200 router"</span> <span class="o">&gt;&gt;</span> /etc/hosts
<span class="nb">echo</span> <span class="s2">"192.168.20.100 k8s-w0"</span> <span class="o">&gt;&gt;</span> /etc/hosts
<span class="k">for</span> <span class="o">((</span> <span class="nv">i</span><span class="o">=</span>1<span class="p">;</span> i&lt;<span class="o">=</span><span class="nv">$1</span><span class="p">;</span> i++  <span class="o">))</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"192.168.10.10</span><span class="nv">$i</span><span class="s2"> k8s-w</span><span class="nv">$i</span><span class="s2">"</span> <span class="o">&gt;&gt;</span> /etc/hosts<span class="p">;</span> <span class="k">done
  
  
</span><span class="nb">echo</span> <span class="s2">"[TASK 11] Dynamically provisioning persistent local storage with Kubernetes"</span>
kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.31/deploy/local-path-storage.yaml <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
kubectl patch storageclass local-path <span class="nt">-p</span> <span class="s1">'{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 12] Install Prometheus &amp; Grafana"</span>
kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/cilium/cilium/1.18.0/examples/kubernetes/addons/prometheus/monitoring-example.yaml <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
kubectl patch svc <span class="nt">-n</span> cilium-monitoring prometheus <span class="nt">-p</span> <span class="s1">'{"spec": {"type": "NodePort", "ports": [{"port": 9090, "targetPort": 9090, "nodePort": 30001}]}}'</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
kubectl patch svc <span class="nt">-n</span> cilium-monitoring grafana <span class="nt">-p</span> <span class="s1">'{"spec": {"type": "NodePort", "ports": [{"port": 3000, "targetPort": 3000, "nodePort": 30002}]}}'</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="c"># echo "[TASK 12] Install Prometheus Stack"</span>
<span class="c"># helm repo add prometheus-community https://prometheus-community.github.io/helm-charts  &gt;/dev/null 2&gt;&amp;1</span>
<span class="c"># cat &lt;&lt;EOT &gt; monitor-values.yaml</span>
<span class="c"># prometheus:</span>
<span class="c">#   prometheusSpec:</span>
<span class="c">#     scrapeInterval: "15s"</span>
<span class="c">#     evaluationInterval: "15s"</span>
<span class="c">#   service:</span>
<span class="c">#     type: NodePort</span>
<span class="c">#     nodePort: 30001</span>
  
<span class="c"># grafana:</span>
<span class="c">#   defaultDashboardsTimezone: Asia/Seoul</span>
<span class="c">#   adminPassword: prom-operator</span>
<span class="c">#   service:</span>
<span class="c">#     type: NodePort</span>
<span class="c">#     nodePort: 30002</span>
  
<span class="c"># alertmanager:</span>
<span class="c">#   enabled: false</span>
<span class="c"># defaultRules:</span>
<span class="c">#   create: false</span>
<span class="c"># prometheus-windows-exporter:</span>
<span class="c">#   prometheus:</span>
<span class="c">#     monitor:</span>
<span class="c">#       enabled: false</span>
<span class="c"># EOT</span>
<span class="c"># helm install kube-prometheus-stack prometheus-community/kube-prometheus-stack --version 75.15.1 \</span>
<span class="c">#   -f monitor-values.yaml --create-namespace --namespace monitoring  &gt;/dev/null 2&gt;&amp;1</span>
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 13] Install Metrics-server"</span>
helm repo add metrics-server https://kubernetes-sigs.github.io/metrics-server/  <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
helm upgrade <span class="nt">--install</span> metrics-server metrics-server/metrics-server <span class="nt">--set</span> <span class="s1">'args[0]=--kubelet-insecure-tls'</span> <span class="nt">-n</span> kube-system  <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 14] Install k9s"</span>
<span class="nv">CLI_ARCH</span><span class="o">=</span>amd64
<span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span><span class="si">)</span><span class="s2">"</span> <span class="o">=</span> <span class="s2">"aarch64"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then </span><span class="nv">CLI_ARCH</span><span class="o">=</span>arm64<span class="p">;</span> <span class="k">fi
</span>wget https://github.com/derailed/k9s/releases/latest/download/k9s_linux_<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.deb <span class="nt">-O</span> /tmp/k9s_linux_<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.deb  <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
apt <span class="nb">install</span> /tmp/k9s_linux_<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.deb  <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Controlplane Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div>    </div>

    <ul>
      <li>
        <p><strong>kubeadm-init-ctr-config.yaml</strong></p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  apiVersion: kubeadm.k8s.io/v1beta4
  kind: InitConfiguration
  bootstrapTokens:
  - token: <span class="s2">"123456.1234567890123456"</span>
    ttl: <span class="s2">"0s"</span>
    usages:
    - signing
    - authentication
  localAPIEndpoint:
    advertiseAddress: <span class="s2">"192.168.10.100"</span>
  nodeRegistration:
    kubeletExtraArgs:
      - name: node-ip
        value: <span class="s2">"192.168.10.100"</span>
    criSocket: <span class="s2">"unix:///run/containerd/containerd.sock"</span>
  <span class="nt">---</span>
  apiVersion: kubeadm.k8s.io/v1beta4
  kind: ClusterConfiguration
  kubernetesVersion: <span class="s2">"K8S_VERSION_PLACEHOLDER"</span>
  networking:
    podSubnet: <span class="s2">"10.244.0.0/16"</span>
    serviceSubnet: <span class="s2">"10.96.0.0/16"</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li><strong>k8s-w.sh</strong> : kubernetes worker 노드 설정, kubeadm join 등을 수행하는  스크립트입니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Node config Start &lt;&lt;&lt;&lt;"</span>
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 1] K8S Controlplane Join"</span>
curl <span class="nt">--silent</span> <span class="nt">-o</span> /root/kubeadm-join-worker-config.yaml https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/2w/kubeadm-join-worker-config.yaml
<span class="nv">NODEIP</span><span class="o">=</span><span class="si">$(</span>ip <span class="nt">-4</span> addr show eth1 | <span class="nb">grep</span> <span class="nt">-oP</span> <span class="s1">'(?&lt;=inet\s)\d+(\.\d+){3}'</span><span class="si">)</span>
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/NODE_IP_PLACEHOLDER/</span><span class="k">${</span><span class="nv">NODEIP</span><span class="k">}</span><span class="s2">/g"</span> /root/kubeadm-join-worker-config.yaml
kubeadm <span class="nb">join</span> <span class="nt">--config</span><span class="o">=</span><span class="s2">"/root/kubeadm-join-worker-config.yaml"</span> <span class="o">&gt;</span> /dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Node config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div>    </div>
    <ul>
      <li>
        <p><strong>kubeadm-join-worker-config.yaml</strong></p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apiVersion: kubeadm.k8s.io/v1beta4
kind: JoinConfiguration
discovery:
  bootstrapToken:
    token: <span class="s2">"123456.1234567890123456"</span>
    apiServerEndpoint: <span class="s2">"192.168.10.100:6443"</span>
    unsafeSkipCAVerification: <span class="nb">true
</span>nodeRegistration:
  criSocket: <span class="s2">"unix:///run/containerd/containerd.sock"</span>
  kubeletExtraArgs:
    - name: node-ip
      value: <span class="s2">"NODE_IP_PLACEHOLDER"</span>    
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>route-add1.sh</strong> : k8s node 들이 내부망과 통신을 위한 route 설정 스크립트입니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Route Add Config Start &lt;&lt;&lt;&lt;"</span>
  
<span class="nb">chmod </span>600 /etc/netplan/01-netcfg.yaml
<span class="nb">chmod </span>600 /etc/netplan/50-vagrant.yaml
  
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh">&gt;&gt; /etc/netplan/50-vagrant.yaml
      routes:
      - to: 192.168.20.0/24
        via: 192.168.10.200
      - to: 172.20.0.0/16
        via: 192.168.10.200
      - to: 10.10.0.0/16
        via: 192.168.10.200
</span><span class="no">EOT
  
</span>netplan apply
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Route Add Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>route-add2.sh</strong> : k8s node 들이 내부망과 통신을 위한 route 설정 스크립트입니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Route Add Config Start &lt;&lt;&lt;&lt;"</span>
  
<span class="nb">chmod </span>600 /etc/netplan/01-netcfg.yaml
<span class="nb">chmod </span>600 /etc/netplan/50-vagrant.yaml
  
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh">&gt;&gt; /etc/netplan/50-vagrant.yaml
      routes:
      - to: 192.168.10.0/24
        via: 192.168.20.200
      - to: 172.20.0.0/16
        via: 192.168.20.200
      - to: 10.10.0.0/16
        via: 192.168.20.200
</span><span class="no">EOT
  
</span>netplan apply
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Route Add Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>router.sh</strong> : router 역할과 추가적으로 웹서버 역할을 하는 서버의 초기 설정을 담당합니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config Start &lt;&lt;&lt;&lt;"</span>
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 0] Setting eth2"</span>
<span class="nb">chmod </span>600 /etc/netplan/01-netcfg.yaml
<span class="nb">chmod </span>600 /etc/netplan/50-vagrant.yaml
  
<span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOT</span><span class="sh"> &gt;&gt; /etc/netplan/50-vagrant.yaml
    eth2:
      addresses:
      - 192.168.20.200/24
</span><span class="no">EOT
  
</span>netplan apply
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 1] Setting Profile &amp; Bashrc"</span>
<span class="nb">echo</span> <span class="s1">'alias vi=vim'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s2">"sudo su -"</span> <span class="o">&gt;&gt;</span> /home/vagrant/.bashrc
<span class="nb">ln</span> <span class="nt">-sf</span> /usr/share/zoneinfo/Asia/Seoul /etc/localtime
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 2] Disable AppArmor"</span>
systemctl stop ufw <span class="o">&amp;&amp;</span> systemctl disable ufw <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
systemctl stop apparmor <span class="o">&amp;&amp;</span> systemctl disable apparmor <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 3] Add Kernel setting - IP Forwarding"</span>
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'s/#net.ipv4.ip_forward=1/net.ipv4.ip_forward=1/g'</span> /etc/sysctl.conf
sysctl <span class="nt">-p</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 4] Setting Dummy Interface"</span>
modprobe dummy
ip <span class="nb">link </span>add loop1 <span class="nb">type </span>dummy
ip <span class="nb">link set </span>loop1 up
ip addr add 10.10.1.200/24 dev loop1
  
ip <span class="nb">link </span>add loop2 <span class="nb">type </span>dummy
ip <span class="nb">link set </span>loop2 up
ip addr add 10.10.2.200/24 dev loop2
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 5] Install Packages"</span>
<span class="nb">export </span><span class="nv">DEBIAN_FRONTEND</span><span class="o">=</span>noninteractive
apt update <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
apt-get <span class="nb">install </span>net-tools jq yq tree ngrep tcpdump arping termshark <span class="nt">-y</span> <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 6] Install Apache"</span>
apt <span class="nb">install </span>apache2 <span class="nt">-y</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"&lt;h1&gt;Web Server : </span><span class="si">$(</span><span class="nb">hostname</span><span class="si">)</span><span class="s2">&lt;/h1&gt;"</span> <span class="o">&gt;</span> /var/www/html/index.html
  
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div>    </div>
  </li>
</ul>

<h3 id="실습환경-배포-및-분석-툴-설치">실습환경 배포 및 분석 툴 설치</h3>

<ul>
  <li>
    <p>실습환경 배포</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>vagrant up
<span class="c"># =&gt; ...    </span>
<span class="c">#        k8s-w0: &gt;&gt;&gt;&gt; Initial Config End &lt;&lt;&lt;&lt;</span>
<span class="c">#    ==&gt; k8s-w0: Running provisioner: shell...</span>
<span class="c">#        k8s-w0: Running: /var/folders/7k/qy6rsdds57z3tmyn9_7hhd8r0000gn/T/vagrant-shell20250807-27868-fg24bd.sh</span>
<span class="c">#        k8s-w0: &gt;&gt;&gt;&gt; K8S Node config Start &lt;&lt;&lt;&lt;</span>
<span class="c">#        k8s-w0: [TASK 1] K8S Controlplane Join</span>
<span class="c">#        k8s-w0: &gt;&gt;&gt;&gt; K8S Node config End &lt;&lt;&lt;&lt;</span>
<span class="c">#    ==&gt; k8s-w0: Running provisioner: shell...</span>
<span class="c">#        k8s-w0: Running: /var/folders/7k/qy6rsdds57z3tmyn9_7hhd8r0000gn/T/vagrant-shell20250807-27868-fzndov.sh</span>
<span class="c">#        k8s-w0: &gt;&gt;&gt;&gt; Route Add Config Start &lt;&lt;&lt;&lt;</span>
<span class="c">#        k8s-w0: &gt;&gt;&gt;&gt; Route Add Config End &lt;&lt;&lt;&lt;</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>기본정보 확인</p>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># k8s-ctr 노드에 접속</span>
<span class="nv">$ </span>vagrant ssh k8s-ctr

<span class="nt">---------------------------------</span>

<span class="c"># k9s 설치</span>
<span class="nv">$ CLI_ARCH</span><span class="o">=</span>amd64
<span class="nv">$ </span><span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span><span class="si">)</span><span class="s2">"</span> <span class="o">=</span> <span class="s2">"aarch64"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then </span><span class="nv">CLI_ARCH</span><span class="o">=</span>arm64<span class="p">;</span> <span class="k">fi</span>
<span class="nv">$ </span>wget https://github.com/derailed/k9s/releases/latest/download/k9s_linux_<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.deb <span class="nt">-O</span> /tmp/k9s_linux_<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.deb
<span class="nv">$ </span>apt <span class="nb">install</span> /tmp/k9s_linux_<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.deb
<span class="nv">$ </span>k9s <span class="c"># node/pod 정보 확인 - metrics-server 설치되어 있어서, cpu/mem 확인 가능</span>

<span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> /etc/hosts
<span class="c"># =&gt; 127.0.2.1 k8s-ctr k8s-ctr</span>
<span class="c">#    192.168.10.100 k8s-ctr</span>
<span class="c">#    192.168.20.100 k8s-w0</span>
<span class="c">#    192.168.10.101 k8s-w1</span>
<span class="c">#    192.168.10.200 router</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-w0 <span class="nb">hostname</span>
<span class="c"># =&gt; k8s-w0</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s-w0는 k8s-ctr과 다른 네트워크에 있지만 정적 route 설정이 되어 있어서 접속이 가능합니다.&lt;/span&gt;</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-w1 <span class="nb">hostname</span>
<span class="c"># =&gt; k8s-w1</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@router <span class="nb">hostname</span>
<span class="c"># =&gt; router</span>

<span class="c"># 클러스터 정보 확인</span>
<span class="nv">$ </span>kubectl cluster-info
<span class="c"># =&gt; Kubernetes control plane is running at https://192.168.10.100:6443</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>kubectl cluster-info dump | <span class="nb">grep</span> <span class="nt">-m</span> 2 <span class="nt">-E</span> <span class="s2">"cluster-cidr|service-cluster-ip-range"</span>
<span class="c"># =&gt;                             "--service-cluster-ip-range=10.96.0.0/16",</span>
<span class="c">#                                "--cluster-cidr=10.244.0.0/16",                           </span>

<span class="nv">$ </span>kubectl describe cm <span class="nt">-n</span> kube-system kubeadm-config
<span class="c"># =&gt; ...</span>
<span class="c">#      podSubnet: 10.244.0.0/16</span>
<span class="c">#      serviceSubnet: 10.96.0.0/16</span>
<span class="nv">$ </span>kubectl describe cm <span class="nt">-n</span> kube-system kubelet-config

<span class="c"># 노드 정보 : 상태, INTERNAL-IP 확인</span>
<span class="nv">$ </span>ifconfig | <span class="nb">grep</span> <span class="nt">-iEA1</span> <span class="s1">'eth[0-9]:'</span>
<span class="c"># =&gt; eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span>
<span class="c">#            inet 10.0.2.15  netmask 255.255.255.0  broadcast 10.0.2.255</span>
<span class="c">#    --</span>
<span class="c">#    eth1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span>
<span class="c">#            inet 192.168.10.100  netmask 255.255.255.0  broadcast 192.168.10.255</span>
<span class="nv">$ </span>kubectl get node <span class="nt">-owide</span>
<span class="c"># =&gt; NAME      STATUS   ROLES           AGE     VERSION   INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION     CONTAINER-RUNTIME</span>
<span class="c">#    k8s-ctr   Ready    control-plane   9m41s   v1.33.2   192.168.10.100   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>
<span class="c">#    k8s-w0    Ready    &lt;none&gt;          4m37s   v1.33.2   192.168.20.100   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>
<span class="c">#    k8s-w1    Ready    &lt;none&gt;          7m13s   v1.33.2   192.168.10.101   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>

<span class="c"># 파드 정보 : 상태, 파드 IP 확인</span>
<span class="nv">$ </span>kubectl get nodes <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{range .items[*]}{.metadata.name}{"\t"}{.spec.podCIDR}{"\n"}{end}'</span>
<span class="c"># =&gt; k8s-ctr 10.244.0.0/24</span>
<span class="c">#    k8s-w0  10.244.3.0/24</span>
<span class="c">#    k8s-w1  10.244.1.0/24</span>
<span class="nv">$ </span>kubectl get ciliumnode <span class="nt">-o</span> json | <span class="nb">grep </span>podCIDRs <span class="nt">-A2</span>
<span class="c"># =&gt;                     "podCIDRs": [</span>
<span class="c">#                            "172.20.0.0/24"</span>
<span class="c">#                        ],</span>
<span class="c">#    --</span>
<span class="c">#                        "podCIDRs": [</span>
<span class="c">#                            "172.20.2.0/24"</span>
<span class="c">#                        ],</span>
<span class="c">#    --</span>
<span class="c">#                        "podCIDRs": [</span>
<span class="c">#                            "172.20.1.0/24"</span>
<span class="c">#                        ],</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-A</span> <span class="nt">-owide</span>
<span class="c"># =&gt; NAMESPACE            NAME                                      READY   STATUS    RESTARTS   AGE     IP               NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    cilium-monitoring    grafana-5c69859d9-n82rg                   1/1     Running   0          10m     172.20.0.209     k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    cilium-monitoring    prometheus-6fc896bc5d-m82wl               1/1     Running   0          10m     172.20.0.230     k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          cilium-c8265                              1/1     Running   0          10m     192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          cilium-envoy-2x4fb                        1/1     Running   0          7m54s   192.168.10.101   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          cilium-envoy-fktjl                        1/1     Running   0          5m18s   192.168.20.100   k8s-w0    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          cilium-envoy-gw7cw                        1/1     Running   0          10m     192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          cilium-h5k5g                              1/1     Running   0          5m18s   192.168.20.100   k8s-w0    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          cilium-operator-76788cffb7-8nhzr          1/1     Running   0          10m     192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          cilium-tzlkp                              1/1     Running   0          7m54s   192.168.10.101   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          coredns-674b8bbfcf-bkc4b                  1/1     Running   0          10m     172.20.0.42      k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          coredns-674b8bbfcf-jdxtw                  1/1     Running   0          10m     172.20.0.185     k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          etcd-k8s-ctr                              1/1     Running   0          10m     192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          hubble-relay-5b48c999f9-vh8jq             1/1     Running   0          10m     172.20.0.156     k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          hubble-ui-655f947f96-vv266                2/2     Running   0          10m     172.20.0.147     k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          kube-apiserver-k8s-ctr                    1/1     Running   0          10m     192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          kube-controller-manager-k8s-ctr           1/1     Running   0          10m     192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          kube-proxy-5qw8d                          1/1     Running   0          10m     192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          kube-proxy-7z4ds                          1/1     Running   0          7m54s   192.168.10.101   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          kube-proxy-twtfn                          1/1     Running   0          5m18s   192.168.20.100   k8s-w0    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          kube-scheduler-k8s-ctr                    1/1     Running   0          10m     192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          metrics-server-5dd7b49d79-25cdj           1/1     Running   0          9m59s   172.20.0.253     k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    local-path-storage   local-path-provisioner-74f9666bc9-rxvrq   1/1     Running   0          10m     172.20.0.103     k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="nv">$ </span>kubectl get ciliumendpoints <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE            NAME                                      SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    cilium-monitoring    grafana-5c69859d9-n82rg                   9513                ready            172.20.0.209</span>
<span class="c">#    cilium-monitoring    prometheus-6fc896bc5d-m82wl               47077               ready            172.20.0.230</span>
<span class="c">#    kube-system          coredns-674b8bbfcf-bkc4b                  2750                ready            172.20.0.42</span>
<span class="c">#    kube-system          coredns-674b8bbfcf-jdxtw                  2750                ready            172.20.0.185</span>
<span class="c">#    kube-system          hubble-relay-5b48c999f9-vh8jq             17251               ready            172.20.0.156</span>
<span class="c">#    kube-system          hubble-ui-655f947f96-vv266                10805               ready            172.20.0.147</span>
<span class="c">#    kube-system          metrics-server-5dd7b49d79-25cdj           14866               ready            172.20.0.253</span>
<span class="c">#    local-path-storage   local-path-provisioner-74f9666bc9-rxvrq   11456               ready            172.20.0.103</span>

<span class="c"># ipam 모드 확인</span>
<span class="nv">$ </span>cilium config view | <span class="nb">grep</span> ^ipam
<span class="c"># =&gt; ipam                                              cluster-pool</span>

<span class="c"># iptables 확인</span>
<span class="nv">$ </span>iptables-save
<span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> filter <span class="nt">-S</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> mangle <span class="nt">-S</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> raw <span class="nt">-S</span>
</code></pre></div></div>

<ul>
  <li>[k8s-ctr] cilium 설치정보 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># cilium 상태 확인</span>
<span class="nv">$ </span>kubectl get cm <span class="nt">-n</span> kube-system cilium-config <span class="nt">-o</span> json | jq
<span class="nv">$ </span>cilium status
<span class="nv">$ </span>cilium config view
<span class="c"># =&gt; ...</span>
<span class="c">#    auto-direct-node-routes                           true</span>
<span class="c">#    ...</span>
<span class="c">#    routing-mode                                      native</span>
<span class="c">#    ...</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg status <span class="nt">--verbose</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg metrics list

<span class="c"># monitor</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg monitor
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg monitor <span class="nt">-v</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg monitor <span class="nt">-v</span> <span class="nt">-v</span>

<span class="c">## Filter for only the events related to endpoint</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg monitor <span class="nt">--related-to</span><span class="o">=</span>&lt;<span class="nb">id</span><span class="o">&gt;</span>

<span class="c">## Show notifications only for dropped packet events</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg monitor <span class="nt">--type</span> drop

<span class="c">## Don’t dissect packet payload, display payload in hex information</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg monitor <span class="nt">-v</span> <span class="nt">-v</span> <span class="nt">--hex</span>

<span class="c">## Layer7</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg monitor <span class="nt">-v</span> <span class="nt">--type</span> l7
</code></pre></div></div>

<ul>
  <li>네트워크 정보 확인 : <code class="language-plaintext highlighter-rouge">autoDirectNodeRoutes=true</code> 동작 이해</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># router 네트워크 인터페이스 정보 확인</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router ip <span class="nt">-br</span> <span class="nt">-c</span> <span class="nt">-4</span> addr
<span class="c"># =&gt; lo               UNKNOWN        127.0.0.1/8</span>
<span class="c">#    eth0             UP             10.0.2.15/24 metric 100</span>
<span class="c">#    eth1             UP             192.168.10.200/24</span>
<span class="c">#    eth2             UP             192.168.20.200/24</span>
<span class="c">#    loop1            UNKNOWN        10.10.1.200/24</span>
<span class="c">#    loop2            UNKNOWN        10.10.2.200/24</span>

<span class="c"># k8s node 네트워크 인터페이스 정보 확인</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> <span class="nt">-4</span> addr show dev eth1
<span class="c"># =&gt; 3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span>
<span class="c">#        altname enp0s9</span>
<span class="c">#        inet 192.168.10.100/24 brd 192.168.10.255 scope global eth1</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w1 ip <span class="nt">-c</span> <span class="nt">-4</span> addr show dev eth1
<span class="c"># =&gt; 3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span>
<span class="c">#        altname enp0s9</span>
<span class="c">#        inet 192.168.10.101/24 brd 192.168.10.255 scope global eth1</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w0 ip <span class="nt">-c</span> <span class="nt">-4</span> addr show dev eth1
<span class="c"># =&gt; 3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span>
<span class="c">#        altname enp0s9</span>
<span class="c">#        inet 192.168.20.100/24 brd 192.168.20.255 scope global eth1</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>

<span class="c"># 라우팅 정보 확인</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.10.1.0/24 dev loop1 proto kernel scope link src 10.10.1.200</span>
<span class="c">#    10.10.2.0/24 dev loop2 proto kernel scope link src 10.10.2.200</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.200</span>
<span class="c">#    192.168.20.0/24 dev eth2 proto kernel scope link src 192.168.20.200</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route | <span class="nb">grep </span>static
<span class="c"># =&gt; 10.10.0.0/16 via 192.168.10.200 dev eth1 proto static</span>
<span class="c">#    172.20.0.0/16 via 192.168.10.200 dev eth1 proto static</span>
<span class="c">#    192.168.20.0/24 via 192.168.10.200 dev eth1 proto static</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 192.168.10.0/24와 192.168.20.0/24 네트워크의 routing 등을 위해서 router에 static route 설정이 되어 있습니다.&lt;/span&gt;</span>

<span class="c">## --set routingMode=native --set autoDirectNodeRoutes=true 동작을 정확히 이해해보자!</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route
<span class="c"># =&gt; 10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    &lt;span style="color: green;"&gt;10.10.0.0/16 via 192.168.10.200 dev eth1 proto static&lt;/span&gt;</span>
<span class="c">#    172.20.0.0/24 via 172.20.0.201 dev cilium_host proto kernel src 172.20.0.201</span>
<span class="c">#    &lt;span style="color: green;"&gt;172.20.0.0/16 via 192.168.10.200 dev eth1 proto static&lt;/span&gt;</span>
<span class="c">#    172.20.0.201 dev cilium_host proto kernel scope link</span>
<span class="c">#    172.20.1.0/24 via 192.168.10.101 dev eth1 proto kernel</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.100</span>
<span class="c">#    &lt;span style="color: green;"&gt;192.168.20.0/24 via 192.168.10.200 dev eth1 proto static&lt;/span&gt;</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w1 ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    &lt;span style="color: green;"&gt;10.10.0.0/16 via 192.168.10.200 dev eth1 proto static&lt;/span&gt;</span>
<span class="c">#    172.20.0.0/24 via 192.168.10.100 dev eth1 proto kernel</span>
<span class="c">#    &lt;span style="color: green;"&gt;172.20.0.0/16 via 192.168.10.200 dev eth1 proto static&lt;/span&gt;</span>
<span class="c">#    172.20.1.0/24 via 172.20.1.197 dev cilium_host proto kernel src 172.20.1.197</span>
<span class="c">#    172.20.1.197 dev cilium_host proto kernel scope link</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.101</span>
<span class="c">#    &lt;span style="color: green;"&gt;192.168.20.0/24 via 192.168.10.200 dev eth1 proto static&lt;/span&gt;</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w0 ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    &lt;span style="color: green;"&gt;10.10.0.0/16 via 192.168.20.200 dev eth1 proto static&lt;/span&gt;</span>
<span class="c">#    &lt;span style="color: green;"&gt;172.20.0.0/16 via 192.168.20.200 dev eth1 proto static&lt;/span&gt;</span>
<span class="c">#    172.20.2.0/24 via 172.20.2.25 dev cilium_host proto kernel src 172.20.2.25</span>
<span class="c">#    172.20.2.25 dev cilium_host proto kernel scope link</span>
<span class="c">#    &lt;span style="color: green;"&gt;192.168.10.0/24 via 192.168.20.200 dev eth1 proto static&lt;/span&gt;</span>
<span class="c">#    192.168.20.0/24 dev eth1 proto kernel scope link src 192.168.20.100</span>

<span class="c"># 통신 확인</span>
<span class="nv">$ </span>ping <span class="nt">-c</span> 1 10.10.1.200     <span class="c"># router loop1 </span>
<span class="c"># =&gt; PING 10.10.1.200 (10.10.1.200) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 10.10.1.200: icmp_seq=1 ttl=64 time=0.780 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 10.10.1.200 ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 0.780/0.780/0.780/0.000 ms</span>
<span class="nv">$ </span>ping <span class="nt">-c</span> 1 192.168.20.100  <span class="c"># k8s-w0 eth1</span>
<span class="c"># =&gt; PING 192.168.20.100 (192.168.20.100) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 192.168.20.100: icmp_seq=1 ttl=63 time=1.82 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 192.168.20.100 ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 1.821/1.821/1.821/0.000 ms</span>

<span class="c"># 목적지까지 경우하는 라우팅 정보 제공</span>
<span class="c">## Path MTU (pmtu): 출발지에서 목적지까지 모든 네트워크 경로 상에서 통과할 수 있는 최대 패킷 크기(Byte), IP fragmentation 없이 전송 가능한 가장 큰 패킷 크기를 의미.</span>
<span class="c">## pmtu 1500: 전체 경로의 최소 MTU는 1500 , hops 2: 총 2단계 라우터/노드를 거쳐서 도달 , back 2: 응답도 동일한 hop 수로 돌아옴 </span>
<span class="nv">$ </span>tracepath <span class="nt">-n</span> 192.168.20.100
<span class="c"># =&gt;  1?: [LOCALHOST]                      pmtu 1500</span>
<span class="c">#     1:  192.168.10.200                                        2.759ms</span>
<span class="c">#     1:  192.168.10.200                                        0.994ms</span>
<span class="c">#     2:  192.168.20.100                                        1.461ms reached</span>
<span class="c">#         Resume: pmtu 1500 hops 2 back 2</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s-ctr(192.168.10.100)에서 k8s-w0(192.168.20.100)은 다른 네트워크이기 때문에&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   직접적으로 통신할 수 없고, router(192.168.10.200)를 거쳐서 routing되어 통신이 됩니다.&lt;/span&gt;</span>
</code></pre></div></div>

<hr />

<h2 id="native-routing-mode">Native Routing Mode</h2>

<h3 id="샘플-애플리케이션-배포-및-확인">샘플 애플리케이션 배포 및 확인</h3>

<ul>
  <li>샘플 애플리케이션 배포 : <code class="language-plaintext highlighter-rouge">cilium-dbg</code></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 샘플 애플리케이션 배포</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webpod
spec:
  replicas: 3
  selector:
    matchLabels:
      app: webpod
  template:
    metadata:
      labels:
        app: webpod
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - sample-app
            topologyKey: "kubernetes.io/hostname"
      containers:
      - name: webpod
        image: traefik/whoami
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: webpod
  labels:
    app: webpod
spec:
  selector:
    app: webpod
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
  type: ClusterIP
</span><span class="no">EOF
</span><span class="c"># =&gt; deployment.apps/webpod created</span>
<span class="c">#    service/webpod created</span>

<span class="c"># k8s-ctr 노드에 curl-pod 파드 배포</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: curl-pod
  labels:
    app: curl
spec:
  nodeName: k8s-ctr
  containers:
  - name: curl
    image: nicolaka/netshoot
    command: ["tail"]
    args: ["-f", "/dev/null"]
  terminationGracePeriodSeconds: 0
</span><span class="no">EOF
</span><span class="c"># =&gt; pod/curl-pod created</span>
</code></pre></div></div>

<ul>
  <li>확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 배포 확인</span>
<span class="nv">$ </span>kubectl get deploy,svc,ep webpod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                     READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES           SELECTOR</span>
<span class="c">#    deployment.apps/webpod   3/3     3            3           53s   webpod       traefik/whoami   app=webpod</span>
<span class="c">#    </span>
<span class="c">#    NAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE   SELECTOR</span>
<span class="c">#    service/webpod   ClusterIP   10.96.129.95   &lt;none&gt;        80/TCP    53s   app=webpod</span>
<span class="c">#    </span>
<span class="c">#    NAME               ENDPOINTS                                        AGE</span>
<span class="c">#    endpoints/webpod   172.20.0.131:80,172.20.1.217:80,172.20.2.73:80   53s</span>
<span class="nv">$ </span>kubectl get endpointslices <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>webpod
<span class="c"># =&gt; NAME           ADDRESSTYPE   PORTS   ENDPOINTS                               AGE</span>
<span class="c">#    webpod-njp7j   IPv4          80      172.20.0.131,172.20.2.73,172.20.1.217   65s</span>
<span class="nv">$ </span>kubectl get ciliumendpoints <span class="c"># IP 확인</span>
<span class="c"># =&gt; NAME                      SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    curl-pod                  21500               ready            172.20.0.89</span>
<span class="c">#    webpod-697b545f57-b46tz   17081               ready            172.20.0.131          # &lt;span style="color: green;"&gt;k8s-wctr&lt;/span&gt;</span>
<span class="c">#    webpod-697b545f57-66grn   17081               ready            172.20.1.217          # &lt;span style="color: green;"&gt;k8s-w1&lt;/span&gt;</span>
<span class="c">#    webpod-697b545f57-24ck5   17081               ready            172.20.2.73           # &lt;span style="color: green;"&gt;k8s-w0&lt;/span&gt;</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg ip list
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg endpoint list

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg service list
<span class="c"># =&gt; ...</span>
<span class="c">#    20   10.96.129.95:80/TCP     ClusterIP      1 =&gt; 172.20.0.131:80/TCP (active)</span>
<span class="c">#                                                2 =&gt; 172.20.1.217:80/TCP (active)</span>
<span class="c">#                                                3 =&gt; 172.20.2.73:80/TCP (active)</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg bpf lb list
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg bpf lb list | <span class="nb">grep </span>10.96.129.95
<span class="c"># =&gt; 10.96.129.95:80/TCP (3)        172.20.2.73:80/TCP (20) (3)</span>
<span class="c">#    10.96.129.95:80/TCP (0)        0.0.0.0:0 (20) (0) [ClusterIP, non-routable]</span>
<span class="c">#    10.96.129.95:80/TCP (1)        172.20.0.131:80/TCP (20) (1)</span>
<span class="c">#    10.96.129.95:80/TCP (2)        172.20.1.217:80/TCP (20) (2)</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 cilium의 load balancer가 각 파드의 IP을 확인하고, 해당 IP로 요청을 전달합니다.&lt;/span&gt;</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg bpf nat list

<span class="c"># map</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg map list | <span class="nb">grep</span> <span class="nt">-v</span> <span class="s1">'0             0'</span>
<span class="c"># =&gt; Name                           Num entries   Num errors   Cache enabled</span>
<span class="c">#    cilium_policy_v2_03166         3             0            true</span>
<span class="c">#    cilium_policy_v2_01270         3             0            true</span>
<span class="c">#    cilium_policy_v2_01641         3             0            true</span>
<span class="c">#    cilium_policy_v2_01688         3             0            true</span>
<span class="c">#    cilium_lb4_reverse_nat         20            0            true</span>
<span class="c">#    cilium_lxc                     13            0            true</span>
<span class="c">#    cilium_policy_v2_02965         3             0            true</span>
<span class="c">#    cilium_runtime_config          256           0            true</span>
<span class="c">#    cilium_ipcache_v2              22            0            true</span>
<span class="c">#    cilium_policy_v2_00459         2             0            true</span>
<span class="c">#    cilium_policy_v2_00222         3             0            true</span>
<span class="c">#    cilium_policy_v2_03535         3             0            true</span>
<span class="c">#    cilium_policy_v2_02230         3             0            true</span>
<span class="c">#    cilium_lb4_services_v2         45            0            true</span>
<span class="c">#    cilium_lb4_backends_v3         16            0            true</span>
<span class="c">#    cilium_lb4_reverse_sk          9             0            true</span>
<span class="c">#    cilium_policy_v2_00745         3             0            true</span>
<span class="c">#    cilium_policy_v2_01678         3             0            true</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg map get cilium_lb4_services_v2
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg map get cilium_lb4_services_v2 | <span class="nb">grep </span>10.96.129.95
<span class="c"># =&gt; Key                            Value                     State   Error</span>
<span class="c">#    10.96.129.95:80/TCP (3)        15 0[0] (20) [0x0 0x0]</span>
<span class="c">#    10.96.129.95:80/TCP (2)        16 0[0] (20) [0x0 0x0]</span>
<span class="c">#    10.96.129.95:80/TCP (0)        0 3[0] (20) [0x0 0x0]</span>
<span class="c">#    10.96.129.95:80/TCP (1)        14 0[0] (20) [0x0 0x0]   </span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg map get cilium_lb4_backends_v3
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg map get cilium_lb4_reverse_nat
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg map get cilium_ipcache_v2
</code></pre></div></div>

<h3 id="통신-확인-및-hubble로-모니터링">통신 확인 및 hubble로 모니터링</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 통신 확인 : 문제 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl webpod | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod-697b545f57-66grn</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s --connect-timeout 1 webpod | grep Hostname; echo "---" ; sleep 1; done'</span>
<span class="c"># =&gt; ---</span>
<span class="c">#    Hostname: webpod-697b545f57-b46tz</span>
<span class="c">#    ---</span>
<span class="c">#    Hostname: webpod-697b545f57-66grn</span>
<span class="c">#    ---  # &lt;span style="color: green;"&gt;👉 k8s-w0 노드에 배포된 webpod 파드에 대해서는 통신이 되지 않습니다.&lt;/span&gt;</span>
<span class="c">#    ---</span>
<span class="c">#    Hostname: webpod-697b545f57-b46tz</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s-ctr 노드와 k8s-w1 노드에 배포된 webpod 파드에 대해서는 통신이 되지만,&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   k8s-w0 노드에 배포된 webpod 파드에 대해서는 통신이 되지 않습니다.&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   왜냐하면, 노드간의 통신은 router에서 정적 라우팅을 통해 통신이 가능하지만,&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   파드 간의 통신에 대해서는 routing 처리가 되어있지 않기 때문입니다.&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   이번 포스트에서는 Encapsulation Mode를 통해 이 문제를 해결해보고&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   다음 포스트에서 Native Routing Mode를 통해 이 문제를 해결해보겠습니다.&lt;/span&gt;</span>

<span class="c"># k8s-w0 노드에 배포된 webpod 파드 IP 지정</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">WEBPOD</span><span class="o">=</span><span class="si">$(</span>kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>webpod <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-w0 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].status.podIP}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$WEBPOD</span>
<span class="c"># =&gt; 172.20.2.73</span>

<span class="c"># 신규 터미널 [router]</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> any icmp <span class="nt">-nn</span>

<span class="c"># </span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> ping <span class="nt">-c</span> 2 <span class="nt">-w</span> 1 <span class="nt">-W</span> 1 <span class="nv">$WEBPOD</span>

<span class="c"># 신규 터미널 [router] : 라우팅이 어떻게 되는가?</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> any icmp <span class="nt">-nn</span>
<span class="c"># =&gt; 14:29:00.156370 eth1  In  IP 172.20.0.89 &gt; 172.20.2.73: ICMP echo request, id 35, seq 1, length 64</span>
<span class="c">#    14:29:00.156388 eth0  Out IP 172.20.0.89 &gt; 172.20.2.73: ICMP echo request, id 35, seq 1, length 64</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s-ctr 노드의 파드(172.20.0.89)에서 k8s-w0 노드의 파드(172.20.2.73)로 ping을 보내면,&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   서로간의 라우팅이 되어있지 않기 때문에 ping이 실패합니다.&lt;/span&gt;</span>

<span class="c"># 신규 터미널 [router]</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route
<span class="nv">$ </span>ip route get 172.20.2.36   <span class="c"># &lt;span style="color: green;"&gt;👉 172.20.2.36으로 통신할때 사용되는 라우팅 정보 확인하는 명령어&lt;/span&gt;</span>
<span class="c"># =&gt; 172.20.2.36 via 10.0.2.2 dev eth0 src 10.0.2.15 uid 0</span>

<span class="c"># [k8s-ctr]에서 반복 호출</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s --connect-timeout 1 webpod | grep Hostname; echo "---" ; sleep 1; done'</span>

<span class="c"># 신규 터미널 [router]</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> any tcp port 80 <span class="nt">-nn</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s-w0노드의 파드로 통신을 시도하여 통신이 안 될 때 마다 router의 tcpdump에 통신이 안 되는 로그가 찍힙니다.&lt;/span&gt;</span>

<span class="c"># hubble 확인</span>
<span class="c"># hubble ui 웹 접속 주소 확인 : default 네임스페이스 확인</span>
<span class="nv">$ NODEIP</span><span class="o">=</span><span class="si">$(</span>ip <span class="nt">-4</span> addr show eth1 | <span class="nb">grep</span> <span class="nt">-oP</span> <span class="s1">'(?&lt;=inet\s)\d+(\.\d+){3}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"http://</span><span class="nv">$NODEIP</span><span class="s2">:30003"</span>
<span class="c"># =&gt; http://192.168.10.100:30003</span>

<span class="c"># hubble relay 포트 포워딩 실행</span>
<span class="nv">$ </span>cilium hubble port-forward&amp;
<span class="c"># =&gt; ℹ️  Hubble Relay is available at 127.0.0.1:4245</span>
<span class="nv">$ </span>hubble status
<span class="c"># =&gt; Healthcheck (via localhost:4245): Ok</span>

<span class="c"># flow log 모니터링</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--protocol</span> tcp <span class="nt">--pod</span> curl-pod
<span class="c"># =&gt; ...</span>
<span class="c">#    Aug  9 05:38:54.615: default/curl-pod:46490 (ID:21500) -&gt; default/webpod-697b545f57-66grn:80 (ID:17081) to-network FORWARDED (TCP Flags: ACK, FIN)</span>
<span class="c">#    Aug  9 05:38:54.618: default/curl-pod:46490 (ID:21500) &lt;- default/webpod-697b545f57-66grn:80 (ID:17081) to-endpoint FORWARDED (TCP Flags: ACK, FIN)</span>
<span class="c">#    Aug  9 05:38:54.618: default/curl-pod:46490 (ID:21500) -&gt; default/webpod-697b545f57-66grn:80 (ID:17081) to-network FORWARDED (TCP Flags: ACK)</span>
<span class="c">#    Aug  9 05:38:55.627: default/curl-pod (ID:21500) &lt;&gt; 10.96.129.95:80 (world) pre-xlate-fwd TRACED (TCP)</span>
<span class="c">#    Aug  9 05:38:55.627: default/curl-pod (ID:21500) &lt;&gt; &lt;span style="color: green;"&gt;default/webpod-697b545f57-24ck5:80&lt;/span&gt; (ID:17081) post-xlate-fwd TRANSLATED (TCP)</span>
<span class="c">#    Aug  9 05:38:55.628: default/curl-pod:37198 (ID:21500) -&gt; &lt;span style="color: green;"&gt;default/webpod-697b545f57-24ck5:80&lt;/span&gt; (ID:17081) to-network FORWARDED &lt;span style="color: green;"&gt;(TCP Flags: SYN)&lt;/span&gt;</span>
<span class="c">#    &lt;span style="color: green;"&gt;👉 k8s-w0 노드에 배포된 webpod 파드(default/webpod-697b545f57-24ck5)로 통신을 시도할 때,&lt;/span&gt;</span>
<span class="c">#    &lt;span style="color: green;"&gt;    라우팅이 되지 않아 SYN 패킷에 대한 ACK 패킷이 오지 않기 때문에, 통신이 되지 않습니다.&lt;/span&gt;</span>
<span class="c">#    Aug  9 05:38:57.528: default/curl-pod:46498 (ID:21500) -&gt; default/webpod-697b545f57-66grn:80 (ID:17081) to-endpoint FORWARDED (TCP Flags: SYN)</span>
<span class="c">#    Aug  9 05:38:57.528: default/curl-pod:46498 (ID:21500) &lt;- default/webpod-697b545f57-66grn:80 (ID:17081) to-network FORWARDED (TCP Flags: SYN, ACK)</span>
<span class="c">#    Aug  9 05:38:57.528: default/curl-pod:46498 (ID:21500) -&gt; default/webpod-697b545f57-66grn:80 (ID:17081) to-endpoint FORWARDED (TCP Flags: ACK)</span>
<span class="c">#    Aug  9 05:38:57.529: default/curl-pod:46498 (ID:21500) -&gt; default/webpod-697b545f57-66grn:80 (ID:17081) to-endpoint FORWARDED (TCP Flags: ACK, PSH)</span>
</code></pre></div></div>

<hr />

<h2 id="overlay-network-encapsulated-mode">Overlay Network (Encapsulated) Mode</h2>

<ul>
  <li>앞에서 살펴본 것과 같이 k8s-ctr 노드와 k8s-w0 노드가 다른 네트워크에 있는 경우,
라우팅 장비에서 라우팅 룰을 추가해서 노드간에는 통신이 가능하지만,
파드 간의 통신은 라우팅 룰이 없기 때문에 통신이 되지 않습니다.</li>
  <li>이러한 경우에도 파드 간의 통신을 가능하게 하기 위해서 Cilium에서는 Overlay Network(Encapsulated) Mode를 제공합니다.</li>
  <li>VXLAN과 GENEVE 등을 지원하는데, 이번 포스트에서는 VXLAN을 통해 통신이 되도록 해보겠습니다.</li>
</ul>

<h3 id="vxlan-설정">VXLAN 설정</h3>

<p><a href="https://docs.cilium.io/en/stable/network/concepts/routing/">Docs</a></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># [커널 구성 옵션] Requirements for Tunneling and Routing</span>
<span class="nv">$ </span><span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'CONFIG_VXLAN=y|CONFIG_VXLAN=m|CONFIG_GENEVE=y|CONFIG_GENEVE=m|CONFIG_FIB_RULES=y'</span> /boot/config-<span class="si">$(</span><span class="nb">uname</span> <span class="nt">-r</span><span class="si">)</span>
<span class="nv">CONFIG_FIB_RULES</span><span class="o">=</span>y <span class="c"># 커널에 내장됨</span>
<span class="nv">CONFIG_VXLAN</span><span class="o">=</span>m <span class="c"># 모듈로 컴파일됨 → 커널에 로드해서 사용</span>
<span class="nv">CONFIG_GENEVE</span><span class="o">=</span>m <span class="c"># 모듈로 컴파일됨 → 커널에 로드해서 사용</span>

<span class="c">#  커널 로드</span>
<span class="nv">$ </span>lsmod | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'vxlan|geneve'</span>
<span class="nv">$ </span>modprobe vxlan <span class="c"># modprobe geneve</span>
<span class="nv">$ </span>lsmod | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'vxlan|geneve'</span>
<span class="c"># =&gt; vxlan                 147456  0</span>
<span class="c">#    ip6_udp_tunnel         16384  1 vxlan</span>
<span class="c">#    udp_tunnel             36864  1 vxlan</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 modprobe 명령어로 커널 모듈이 로딩 되어 vxlan과 필요 모듈들이 활성화 되었습니다.&lt;/span&gt;</span>

<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w0 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>modprobe vxlan <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    &gt;&gt; node : k8s-w0 &lt;&lt;</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w0 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>lsmod | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'vxlan|geneve'</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    vxlan                 147456  0</span>
<span class="c">#    ip6_udp_tunnel         16384  1 vxlan</span>
<span class="c">#    udp_tunnel             36864  1 vxlan</span>
<span class="c">#    &gt;&gt; node : k8s-w0 &lt;&lt;</span>
<span class="c">#    vxlan                 147456  0</span>
<span class="c">#    ip6_udp_tunnel         16384  1 vxlan</span>
<span class="c">#    udp_tunnel             36864  1 vxlan</span>

<span class="c"># k8s-w1 노드에 배포된 webpod 파드 IP 지정</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">WEBPOD1</span><span class="o">=</span><span class="si">$(</span>kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>webpod <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-w1 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].status.podIP}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$WEBPOD1</span>
<span class="c"># =&gt; 172.20.1.217</span>

<span class="c"># 반복 ping 실행해두기</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> ping <span class="nv">$WEBPOD1</span>


<span class="c"># 업그레이드</span>
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--namespace</span> kube-system <span class="nt">--version</span> 1.18.0 <span class="nt">--reuse-values</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">routingMode</span><span class="o">=</span>tunnel <span class="nt">--set</span> <span class="nv">tunnelProtocol</span><span class="o">=</span>vxlan <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">autoDirectNodeRoutes</span><span class="o">=</span><span class="nb">false</span> <span class="nt">--set</span> <span class="nv">installNoConntrackIptablesRules</span><span class="o">=</span><span class="nb">false</span>
<span class="c"># =&gt; Release "cilium" has been upgraded. Happy Helming!</span>
<span class="c">#    ...</span>

<span class="c"># 설정을 적용하기 위해서 Cilium DaemonSet을 재시작합니다.</span>
<span class="nv">$ </span>kubectl rollout restart <span class="nt">-n</span> kube-system ds/cilium

<span class="c"># 설정 확인</span>
<span class="nv">$ </span>cilium features status
<span class="nv">$ </span>cilium features status | <span class="nb">grep </span>datapath_network
<span class="c"># =&gt; Cilium   Agents</span>
<span class="c">#    Uniform  Name                             Labels              k8s-ctr  k8s-w0  k8s-w1</span>
<span class="c">#    Yes      cilium_feature_datapath_network  mode=&lt;span style="color: green;"&gt;overlay-vxlan&lt;/span&gt;  1        1        1</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium status | <span class="nb">grep</span> ^Routing
<span class="c"># =&gt; Routing:                 Network: &lt;span style="color: green;"&gt;Tunnel [vxlan]&lt;/span&gt;   Host: BPF</span>
<span class="nv">$ </span>cilium config view | <span class="nb">grep </span>tunnel
<span class="c"># =&gt; routing-mode                                      &lt;span style="color: green;"&gt;tunnel&lt;/span&gt;</span>
<span class="c">#    tunnel-protocol                                   &lt;span style="color: green;"&gt;vxlan&lt;/span&gt;</span>
<span class="c">#    tunnel-source-port-range                          0-0</span>

<span class="c"># cilium_vxlan 확인</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> addr show dev cilium_vxlan
<span class="c"># =&gt; 26: cilium_vxlan: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN group default</span>
<span class="c">#        link/ether 42:59:64:e0:f6:38 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet6 fe80::4059:64ff:fee0:f638/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w0 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> addr show dev cilium_vxlan <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    8: cilium_vxlan: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN group default</span>
<span class="c">#        link/ether 02:c4:af:d7:83:fc brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet6 fe80::c4:afff:fed7:83fc/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w0 &lt;&lt;</span>
<span class="c">#    8: cilium_vxlan: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN group default</span>
<span class="c">#        link/ether ee:f6:72:2b:b9:b9 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet6 fe80::ecf6:72ff:fe2b:b9b9/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>

<span class="c"># 라우팅 정보 확인 : k8s node 간 다른 네트워크 대역에 있더라도, 파드의 네트워크 대역 정보가 라우팅에 올라왔다!</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route | <span class="nb">grep </span>cilium_host
<span class="c"># =&gt; 172.20.0.0/24 via 172.20.0.201 dev cilium_host proto kernel src 172.20.0.201</span>
<span class="c">#    172.20.0.201 dev cilium_host proto kernel scope link</span>
<span class="c">#    172.20.1.0/24 via 172.20.0.201 dev cilium_host proto kernel src 172.20.0.201 mtu 1450</span>
<span class="c">#    172.20.2.0/24 via 172.20.0.201 dev cilium_host proto kernel src 172.20.0.201 mtu 1450 </span>

<span class="nv">$ </span>ip route get 172.20.1.10
<span class="c"># =&gt; 172.20.1.10 dev cilium_host src 172.20.0.201 uid 0</span>
<span class="c">#        cache mtu 1450</span>
<span class="nv">$ </span>ip route get 172.20.2.10
<span class="c"># =&gt; 172.20.2.10 dev cilium_host src 172.20.0.201 uid 0</span>
<span class="c">#        cache mtu 1450</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 MTU는 Maximum Transmission Unit의 약자로, 네트워크에서 전송할 수 있는 최대 패킷 크기를 의미합니다.&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   본래의 MTU는 1500이지만, VXLAN이 이미 50 bytes를 사용하기 때문에&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   최대 1450 bytes까지 전송할 수 있는것을 확인할 수 있습니다.&lt;/span&gt;</span>

<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w0 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> route | <span class="nb">grep </span>cilium_host <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    172.20.0.0/24 via 172.20.1.197 dev cilium_host proto kernel src 172.20.1.197 mtu 1450</span>
<span class="c">#    172.20.1.0/24 via 172.20.1.197 dev cilium_host proto kernel src 172.20.1.197</span>
<span class="c">#    172.20.1.197 dev cilium_host proto kernel scope link</span>
<span class="c">#    172.20.2.0/24 via 172.20.1.197 dev cilium_host proto kernel src 172.20.1.197 mtu 1450</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w0 &lt;&lt;</span>
<span class="c">#    172.20.0.0/24 via 172.20.2.25 dev cilium_host proto kernel src 172.20.2.25 mtu 1450</span>
<span class="c">#    172.20.1.0/24 via 172.20.2.25 dev cilium_host proto kernel src 172.20.2.25 mtu 1450</span>
<span class="c">#    172.20.2.0/24 via 172.20.2.25 dev cilium_host proto kernel src 172.20.2.25</span>
<span class="c">#    172.20.2.25 dev cilium_host proto kernel scope link</span>

<span class="c"># cilium 파드 이름 지정</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD0</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-ctr <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD1</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-w1  <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD2</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-w0  <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$CILIUMPOD0</span> <span class="nv">$CILIUMPOD1</span> <span class="nv">$CILIUMPOD2</span>
<span class="c"># =&gt; cilium-4jf9p cilium-dqgbw cilium-sqx45</span>

<span class="c"># router 역할 IP 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$CILIUMPOD0</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium status <span class="nt">--all-addresses</span> | <span class="nb">grep </span>router
<span class="c"># =&gt;   172.20.0.201 (router)</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$CILIUMPOD1</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium status <span class="nt">--all-addresses</span> | <span class="nb">grep </span>router
<span class="c"># =&gt;   172.20.1.197 (router)</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$CILIUMPOD2</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium status <span class="nt">--all-addresses</span> | <span class="nb">grep </span>router
<span class="c"># =&gt;   172.20.2.25 (router)</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg bpf ipcache list
<span class="c"># =&gt; IP PREFIX/ADDRESS   IDENTITY</span>
<span class="c">#    ...</span>
<span class="c">#    172.20.0.201/32     identity=6 encryptkey=0 tunnelendpoint=192.168.10.100 flags=hastunnel</span>
<span class="c">#    172.20.2.25/32      identity=6 encryptkey=0 tunnelendpoint=192.168.20.100 flags=hastunnel</span>
<span class="c">#    172.20.1.197/32     identity=1 encryptkey=0 tunnelendpoint=0.0.0.0 flags=&lt;none&gt;</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nv">$CILIUMPOD0</span> <span class="nt">--</span> cilium-dbg bpf ipcache list
<span class="c"># =&gt; IP PREFIX/ADDRESS   IDENTITY</span>
<span class="c">#    ...</span>
<span class="c">#    172.20.0.201/32     identity=1 encryptkey=0 tunnelendpoint=0.0.0.0 flags=&lt;none&gt;</span>
<span class="c">#    172.20.2.25/32      identity=6 encryptkey=0 tunnelendpoint=192.168.20.100 flags=hastunnel</span>
<span class="c">#    172.20.1.197/32     identity=6 encryptkey=0 tunnelendpoint=192.168.10.101 flags=hastunnel</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nv">$CILIUMPOD1</span> <span class="nt">--</span> cilium-dbg bpf ipcache list
<span class="c"># =&gt; IP PREFIX/ADDRESS   IDENTITY</span>
<span class="c">#    ...</span>
<span class="c">#    172.20.1.197/32     identity=1 encryptkey=0 tunnelendpoint=0.0.0.0 flags=&lt;none&gt;</span>
<span class="c">#    172.20.0.201/32     identity=6 encryptkey=0 tunnelendpoint=192.168.10.100 flags=hastunnel</span>
<span class="c">#    172.20.2.25/32      identity=6 encryptkey=0 tunnelendpoint=192.168.20.100 flags=hastunnel</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nv">$CILIUMPOD2</span> <span class="nt">--</span> cilium-dbg bpf ipcache list
<span class="c"># =&gt; IP PREFIX/ADDRESS   IDENTITY</span>
<span class="c">#    ...</span>
<span class="c">#    172.20.0.201/32     identity=6 encryptkey=0 tunnelendpoint=192.168.10.100 flags=hastunnel</span>
<span class="c">#    172.20.2.25/32      identity=1 encryptkey=0 tunnelendpoint=0.0.0.0 flags=&lt;none&gt;</span>
<span class="c">#    172.20.1.197/32     identity=6 encryptkey=0 tunnelendpoint=192.168.10.101 flags=hastunnel</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg bpf socknat list
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nv">$CILIUMPOD0</span> <span class="nt">--</span> cilium-dbg bpf socknat list
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nv">$CILIUMPOD1</span> <span class="nt">--</span> cilium-dbg bpf socknat list
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nv">$CILIUMPOD2</span> <span class="nt">--</span> cilium-dbg bpf socknat list
</code></pre></div></div>

<h3 id="파드간-통신-확인">파드간 통신 확인</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 통신 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl webpod | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod-697b545f57-b46tz</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s --connect-timeout 1 webpod | grep Hostname; echo "---" ; sleep 1; done'</span>
<span class="c"># =&gt; ---</span>
<span class="c">#    Hostname: webpod-697b545f57-b46tz</span>
<span class="c">#    ---</span>
<span class="c">#    Hostname: webpod-697b545f57-24ck5  # &lt;span style="color: green;"&gt;👉 k8s-w0 노드에 배포된 webpod 파드에 대해서도 통신이 됩니다.&lt;/span&gt;</span>
<span class="c">#    ---</span>
<span class="c">#    Hostname: webpod-697b545f57-66grn</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 VXLAN 설정 후 이전에는 통신이 되지 않던 k8s-w0 노드에 배포된 webpod 파드에 대해서도 통신이 됩니다.&lt;/span&gt;</span>

<span class="c"># k8s-w0 노드에 배포된 webpod 파드 IP 지정</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">WEBPOD</span><span class="o">=</span><span class="si">$(</span>kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>webpod <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-w0 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].status.podIP}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$WEBPOD</span>
<span class="c"># =&gt; 172.20.2.73</span>

<span class="c"># 신규 터미널 [router]</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> any udp port 8472 <span class="nt">-nn</span>

<span class="c"># [k8s-ctr] 에서 ping 실행</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> ping <span class="nt">-c</span> 2 <span class="nt">-w</span> 1 <span class="nt">-W</span> 1 <span class="nv">$WEBPOD</span>
<span class="c"># =&gt; PING 172.20.2.73 (172.20.2.73) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 172.20.2.73: icmp_seq=1 ttl=63 time=1.77 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 172.20.2.73 ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 1.769/1.769/1.769/0.000 ms</span>
<span class="c">#    command terminated with exit code 1</span>

<span class="c"># [router]에서 tcpdump 확인 (VXLAN 포트 8472/udp로 통신이 되는지 확인)</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> any udp port 8472 <span class="nt">-nn</span>
<span class="c"># =&gt; 16:17:25.514596 eth1  In  IP 192.168.10.100.56046 &gt; 192.168.20.100.8472: OTV, flags [I] (0x08), overlay 0, instance 21500</span>
<span class="c">#    IP 172.20.0.89 &gt; 172.20.2.73: ICMP echo request, id 11684, seq 1, length 64</span>
<span class="c">#    16:17:25.514636 eth2  Out IP 192.168.10.100.56046 &gt; 192.168.20.100.8472: OTV, flags [I] (0x08), overlay 0, instance 21500</span>
<span class="c">#    IP 172.20.0.89 &gt; 172.20.2.73: ICMP echo request, id 11684, seq 1, length 64</span>
<span class="c">#    16:17:25.515307 eth2  In  IP 192.168.20.100.59302 &gt; 192.168.10.100.8472: OTV, flags [I] (0x08), overlay 0, instance 17081</span>
<span class="c">#    IP 172.20.2.73 &gt; 172.20.0.89: ICMP echo reply, id 11684, seq 1, length 64</span>
<span class="c">#    16:17:25.515315 eth1  Out IP &lt;span style="color: green;"&gt;192.168.20.100.59302 &gt; 192.168.10.100.8472&lt;/span&gt;: OTV, flags [I] (0x08), overlay 0, instance 17081</span>
<span class="c">#    IP &lt;span style="color: green;"&gt;172.20.2.73 &gt; 172.20.0.89&lt;/span&gt;: ICMP echo reply, id 11684, seq 1, length 64</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 VXLAN을 통해 파드 IP간 통신이 노드간 IP로 캡슐화되어 통신이 되는 것을 확인할 수 있습니다.&lt;/span&gt;</span>

<span class="c"># 신규 터미널 [router] : 라우팅이 어떻게 되는가?</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> any icmp <span class="nt">-nn</span>
<span class="c"># =&gt; (없음)</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 VXLAN을 통해 캡슐화된 패킷으로 통신이 되기 때문에 직접적으로 ICMP(ping) 패킷은 보이지 않습니다.&lt;/span&gt;</span>

<span class="c"># 반복 접속</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl webpod | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod-697b545f57-b46tz</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s --connect-timeout 1 webpod | grep Hostname; echo "---" ; sleep 1; done'</span>

<span class="c"># 신규 터미널 [router]</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> any udp port 8472 <span class="nt">-w</span> /tmp/vxlan.pcap
<span class="nv">$ </span>tshark <span class="nt">-r</span> /tmp/vxlan.pcap <span class="nt">-d</span> udp.port<span class="o">==</span>8472,vxlan
<span class="c"># =&gt;     1   0.000000  172.20.0.89 → 172.20.2.73  TCP 130 53224 → 80 [SYN] Seq=0 Win=64860 Len=0 MSS=1410 SACK_PERM TSval=2585589520 TSecr=0 WS=128</span>
<span class="c">#        2   0.000015  172.20.0.89 → 172.20.2.73  TCP 130 [TCP Retransmission] 53224 → 80 [SYN] Seq=0 Win=64860 Len=0 MSS=1410 SACK_PERM TSval=2585589520 TSecr=0 WS=128</span>
<span class="c">#        3   0.000633  172.20.2.73 → 172.20.0.89  TCP 130 80 → 53224 [SYN, ACK] Seq=0 Ack=1 Win=64308 Len=0 MSS=1410 SACK_PERM TSval=3020660677 TSecr=2585589520 WS=128</span>
<span class="c">#        4   0.000637  172.20.2.73 → 172.20.0.89  TCP 130 [TCP Retransmission] 80 → 53224 [SYN, ACK] Seq=0 Ack=1 Win=64308 Len=0 MSS=1410 SACK_PERM TSval=3020660677 TSecr=2585589520 WS=128</span>
<span class="c">#        5   0.001244  172.20.0.89 → 172.20.2.73  TCP 122 53224 → 80 [ACK] Seq=1 Ack=1 Win=64896 Len=0 TSval=2585589521 TSecr=3020660677</span>
<span class="c">#        6   0.001245  172.20.0.89 → 172.20.2.73  TCP 122 [TCP Dup ACK 5#1] 53224 → 80 [ACK] Seq=1 Ack=1 Win=64896 Len=0 TSval=2585589521 TSecr=3020660677</span>
<span class="c">#        7   0.002239  172.20.0.89 → 172.20.2.73  HTTP 192 GET / HTTP/1.1</span>
<span class="c">#        8   0.002247  172.20.0.89 → 172.20.2.73  TCP 192 [TCP Retransmission] 53224 → 80 [PSH, ACK] Seq=1 Ack=1 Win=64896 Len=70 TSval=2585589522 TSecr=3020660677</span>
<span class="c">#        9   0.002625  172.20.2.73 → 172.20.0.89  TCP 122 80 → 53224 [ACK] Seq=1 Ack=71 Win=64256 Len=0 TSval=3020660679 TSecr=2585589522</span>
<span class="c">#       10   0.002628  172.20.2.73 → 172.20.0.89  TCP 122 [TCP Dup ACK 9#1] 80 → 53224 [ACK] Seq=1 Ack=71 Win=64256 Len=0 TSval=3020660679 TSecr=2585589522</span>
<span class="c">#       11   0.004215  172.20.2.73 → 172.20.0.89  HTTP 441 HTTP/1.1 200 OK  (text/plain)</span>
<span class="c">#       12   0.004221  172.20.2.73 → 172.20.0.89  TCP 441 [TCP Retransmission] 80 → 53224 [PSH, ACK] Seq=1 Ack=71 Win=64256 Len=319 TSval=3020660680 TSecr=2585589522</span>
<span class="c">#       13   0.004783  172.20.0.89 → 172.20.2.73  TCP 122 53224 → 80 [ACK] Seq=71 Ack=320 Win=64640 Len=0 TSval=2585589525 TSecr=3020660680</span>
<span class="c">#       14   0.004785  172.20.0.89 → 172.20.2.73  TCP 122 [TCP Dup ACK 13#1] 53224 → 80 [ACK] Seq=71 Ack=320 Win=64640 Len=0 TSval=2585589525 TSecr=3020660680</span>
<span class="c">#       15   0.005245  172.20.0.89 → 172.20.2.73  TCP 122 53224 → 80 [FIN, ACK] Seq=71 Ack=320 Win=64640 Len=0 TSval=2585589525 TSecr=3020660680</span>
<span class="c">#       16   0.005248  172.20.0.89 → 172.20.2.73  TCP 122 [TCP Retransmission] 53224 → 80 [FIN, ACK] Seq=71 Ack=320 Win=64640 Len=0 TSval=2585589525 TSecr=3020660680</span>
<span class="c">#       17   0.005631  172.20.2.73 → 172.20.0.89  TCP 122 80 → 53224 [FIN, ACK] Seq=320 Ack=72 Win=64256 Len=0 TSval=3020660682 TSecr=2585589525</span>
<span class="c">#       18   0.005633  172.20.2.73 → 172.20.0.89  TCP 122 [TCP Retransmission] 80 → 53224 [FIN, ACK] Seq=320 Ack=72 Win=64256 Len=0 TSval=3020660682 TSecr=2585589525</span>
<span class="c">#       19   0.006526  172.20.0.89 → 172.20.2.73  TCP 122 53224 → 80 [ACK] Seq=72 Ack=321 Win=64640 Len=0 TSval=2585589526 TSecr=3020660682</span>
<span class="c">#       20   0.006529  172.20.0.89 → 172.20.2.73  TCP 122 [TCP Dup ACK 19#1] 53224 → 80 [ACK] Seq=72 Ack=321 Win=64640 Len=0 TSval=2585589526 TSecr=3020660682</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 tshark로도 VXLAN 캡슐화된 패킷을 해석할 수 있지만 조금 더 원활한 해석을 위해서 termshark를 사용해보겠습니다.&lt;/span&gt;</span>

<span class="nv">$ </span>termshark <span class="nt">-r</span> /tmp/vxlan.pcap
<span class="c"># =&gt; termshark 2.4.0  |  vxlan.pcap                                                         Analysis    Misc</span>
<span class="c">#    ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓</span>
<span class="c">#    ┃Filter:                                                                               &lt;Apply&gt; &lt;Recent&gt; ┃</span>
<span class="c">#    ┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛</span>
<span class="c">#     No. -  Time -      Source -           Dest -             Proto -  Length -  Info -                     ▲</span>
<span class="c">#     2      0.000015    192.168.10.100     192.168.20.100     UDP      130       56560 → 8472 Len=82</span>
<span class="c">#     3      0.000633    192.168.20.100     192.168.10.100     UDP      130       38192 → 8472 Len=82        █</span>
<span class="c">#     4      0.000637    192.168.20.100     192.168.10.100     UDP      130       38192 → 8472 Len=82</span>
<span class="c">#     5      0.001244    192.168.10.100     192.168.20.100     UDP      122       56560 → 8472 Len=74</span>
<span class="c">#     6      0.001245    192.168.10.100     192.168.20.100     UDP      122       56560 → 8472 Len=74</span>
<span class="c">#     7      0.002239    192.168.10.100     192.168.20.100     UDP      192       56560 → 8472 Len=144       ▼</span>
<span class="c">#    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>
<span class="c">#    [+] Frame 2: 130 bytes on wire (1040 bits), 130 bytes captured (1040 bits) [=]</span>
<span class="c">#    [+] Linux cooked capture v2</span>
<span class="c">#    [+] Internet Protocol Version 4, Src: 192.168.10.100, Dst: 192.168.20.100</span>
<span class="c">#    [+] User Datagram Protocol, Src Port: 56560, Dst Port: 8472</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 기본 termshark 명령어로는 VXLAN 캡슐화된 패킷을 해석할 수 없어서 8472/udp로 캡슐화된 패킷이 보이지 않습니다.&lt;/span&gt;</span>

<span class="nv">$ </span>termshark <span class="nt">-r</span> /tmp/vxlan.pcap <span class="nt">-d</span> udp.port<span class="o">==</span>8472,vxlan
<span class="c"># =&gt; termshark 2.4.0  |  vxlan.pcap                                                         Analysis    Misc</span>
<span class="c">#    ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓</span>
<span class="c">#    ┃Filter:                                                                               &lt;Apply&gt; &lt;Recent&gt; ┃</span>
<span class="c">#    ┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛</span>
<span class="c">#     No. Time - Source - Dest -   Prot Lengt Info -                                                         ▲</span>
<span class="c">#     1   0.0000 172.20.0 172.20.2 TCP  130   53224 → 80 [SYN] Seq=0 Win=64860 Len=0 MSS=1410 SACK_PERM TSva</span>
<span class="c">#     2   0.0000 172.20.0 172.20.2 TCP  130   [TCP Retransmission] 53224 → 80 [SYN] Seq=0 Win=64860 Len=0 MS █</span>
<span class="c">#     3   0.0006 172.20.2 172.20.0 TCP  130   80 → 53224 [SYN, ACK] Seq=0 Ack=1 Win=64308 Len=0 MSS=1410 SAC</span>
<span class="c">#     4   0.0006 172.20.2 172.20.0 TCP  130   [TCP Retransmission] 80 → 53224 [SYN, ACK] Seq=0 Ack=1 Win=643</span>
<span class="c">#     5   0.0012 172.20.0 172.20.2 TCP  122   53224 → 80 [ACK] Seq=1 Ack=1 Win=64896 Len=0 TSval=2585589521</span>
<span class="c">#     6   0.0012 172.20.0 172.20.2 TCP  122   [TCP Dup ACK 5#1] 53224 → 80 [ACK] Seq=1 Ack=1 Win=64896 Len=0</span>
<span class="c">#     7   0.0022 172.20.0 172.20.2 HTTP 192   GET / HTTP/1.1</span>
<span class="c">#     8   0.0022 172.20.0 172.20.2 TCP  192   [TCP Retransmission] 53224 → 80 [PSH, ACK] Seq=1 Ack=1 Win=648</span>
<span class="c">#     9   0.0026 172.20.2 172.20.0 TCP  122   80 → 53224 [ACK] Seq=1 Ack=71 Win=64256 Len=0 TSval=3020660679</span>
<span class="c">#     10  0.0026 172.20.2 172.20.0 TCP  122   [TCP Dup ACK 9#1] 80 → 53224 [ACK] Seq=1 Ack=71 Win=64256 Len=</span>
<span class="c">#     11  0.0042 172.20.2 172.20.0 HTTP 441   HTTP/1.1 200 OK  (text/plain)                                  ▼</span>
<span class="c">#    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>
<span class="c">#    [+] Frame 7: 192 bytes on wire (1536 bits), 192 bytes captured (1536 bits)</span>
<span class="c">#    [+] Linux cooked capture v2 [=]</span>
<span class="c">#    [+] Internet Protocol Version 4, &lt;span style="color: green; border: 2px solid rgba(255, 0, 0, 0.5); padding: 1px 4px;"&gt;Src: 192.168.10.100, Dst: 192.168.20.100&lt;/span&gt;</span>
<span class="c">#    [+] User Datagram Protocol, Src Port: 56560, Dst Port: 8472</span>
<span class="c">#    [+] &lt;span style="color: green; border: 2px solid rgba(255, 0, 0, 0.5); padding: 1px 4px;"&gt;Virtual eXtensible Local Area Network&lt;/span&gt;</span>
<span class="c">#    [+] Ethernet II, Src: 46:02:28:c8:e7:b6 (46:02:28:c8:e7:b6), Dst: ca:7a:5c:b2:2c:4a (ca:7a:5c:b2:2c:4a)</span>
<span class="c">#    [+] Internet Protocol Version 4, Src: &lt;span style="color: green; border: 2px solid rgba(255, 0, 0, 0.5); padding: 1px 4px;"&gt;172.20.0.89, Dst: 172.20.2.73&lt;/span&gt;</span>
<span class="c">#    [+] Transmission Control Protocol, Src Port: 53224, Dst Port: 80, Seq: 1, Ack: 1, Len: 70</span>
<span class="c">#    [-] Hypertext Transfer Protocol</span>
<span class="c">#      [+] GET / HTTP/1.1</span>
<span class="c">#          Host: webpod</span>
<span class="c">#          User-Agent: curl/8.14.1</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 -d udp.port==8472,vxlan 옵션을 통해 VXLAN 캡슐화된 패킷을 해석할 수 있습니다.&lt;/span&gt;</span>

<span class="c"># 신규 터미널 [k8s-ctr] hubble flow log 모니터링 : overlay 통신 모드 확인!</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--protocol</span> tcp <span class="nt">--pod</span> curl-pod
<span class="c"># =&gt; ...</span>
<span class="c">#    Aug  9 07:34:42.262: default/curl-pod:37272 (ID:21500) -&gt; default/webpod-697b545f57-24ck5:80 (ID:17081) &lt;span style="color: green;"&gt;to-overlay FORWARDED&lt;/span&gt; (TCP Flags: SYN)</span>
<span class="c">#    Aug  9 07:34:42.263: default/curl-pod:37272 (ID:21500) &lt;- default/webpod-697b545f57-24ck5:80 (ID:17081) to-endpoint FORWARDED (TCP Flags: SYN, ACK)</span>
<span class="c">#    Aug  9 07:34:42.263: default/curl-pod:37272 (ID:21500) -&gt; default/webpod-697b545f57-24ck5:80 (ID:17081) &lt;span style="color: green;"&gt;to-overlay FORWARDED&lt;/span&gt; (TCP Flags: ACK)</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w4/20250810_cilium_w4_3.png" alt="img.png" class="image-center" />
<em class="image-caption">파드에서 나갈때 패킷 흐름</em></p>

<p><img src="/assets/2025/cilium/w4/20250810_cilium_w4_4.png" alt="img_1.png" class="image-center" />
<em class="image-caption">파드로 인입시 패킷 흐름</em></p>

<ul>
  <li>이상과 같이 VXLAN을 통해서 파드간 통신이 가능해졌습니다. 하지만 VXLAN 등의 캡슐화 기술을 사용하게 되면, 다음의 단점이 있습니다.
    <ul>
      <li>50 bytes의 캡슐화 오버헤드가 발생합니다. (MTU 감소 및 그로인한 패킷 fragmentation 발생 가능성)</li>
      <li>캡슐화 및 디캡슐화 과정에서 CPU 리소스가 소모됩니다.</li>
      <li>같은 네트워크 대역에 있더라도 VXLAN을 통해 캡슐화 됩니다.</li>
    </ul>
  </li>
  <li>VXLAN은 별도의 네트워크 설정 없이 노드간 통신이 가능하다는 장점이 있지만, 위와 같은 문제들로 인프라적인 지원이 가능하다면 Native Routing을 사용하는 것이 좋습니다.</li>
  <li>MTU(Maximum Transmission Unit)는 네트워크에서 전송할 수 있는 최대 패킷 크기를 의미합니다. VXLAN을 사용하면 MTU가 감소하게 되며, 이는 패킷이 분할(fragmentation)되어 전송될 수 있음을 의미합니다. 따라서, VXLAN을 사용할 때는 MTU 설정을 주의 깊게 관리해야 합니다.</li>
  <li>MTU에 대한 간단한 실험을 하고 다음 단계로 넘어가겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># -M do : Don't Fragment (DF) 플래그를 설정하여 조각화 방지</span>
<span class="c"># -s 1472 : 페이로드(payload) 크기, 즉 ICMP 데이터 크기</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> ping <span class="nt">-M</span> <span class="k">do</span> <span class="nt">-s</span> 1472 <span class="nv">$WEBPOD</span>
<span class="c"># =&gt; PING 172.20.2.73 (172.20.2.73) 1472(1500) bytes of data.</span>
<span class="c">#    ping: sendmsg: Message too large</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 ping 명령어를 통해 VXLAN 에 의한 MTU (1450 bytes)보다 큰 1500 bytes를 강제로 전송하면 &lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   "ping: sendmsg: Message too large" 에러가 발생합니다.&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   즉, MTU보다 큰 패킷은 전송할 수 없음을 확인할 수 있으며, MTU 단위로 패킷이 분할(fragmentation)되어 전송됩니다.&lt;/span&gt;</span>
</code></pre></div></div>

<h3 id="도전과제2-vxlan-대신-geneve-모드-사용"><code class="language-plaintext highlighter-rouge">도전과제2.</code> VXLAN 대신 GENEVE 모드 사용</h3>

<ul>
  <li>Cilium은 VXLAN 외에도 GENEVE 모드를 지원합니다. GENEVE는 VXLAN보다 더 유연하고 확장 가능한 캡슐화 프로토콜입니다.</li>
</ul>

<h4 id="geneve-소개">GENEVE 소개</h4>

<ul>
  <li>GENEVE(Generic Network Virtualization Encapsulation)는 VXLAN/NVGRE 등과 유사한 네트워크 가상화 캡슐화 프로토콜로 좀 더 발전된 기능을 제공합니다.</li>
  <li>주요 특징은 다음과 같습니다.
<img src="/assets/2025/cilium/w4/20250810_cilium_w4_17.png" alt="img.png" class="image-center w-80" />
<em class="image-caption">Geneve 헤더 구조 - <a href="https://www.redhat.com/en/blog/what-geneve">출처</a></em>
    <ul>
      <li><strong>확장성 높은 옵션 필드(TLV:Type-Length-Value)</strong> : 고정 헤더 구조에서 벗어나  유동적으로 다양한 옵션을 추가할 수 있어 다양한 환경과 요구사항에 맞는 발전이 가능합니다. (단, 늘어난 헤더 크기가 오버헤드로 작용합니다.)</li>
      <li><strong>UDP 기반 처리</strong> : VXLAN과 마찬가지로 UDP 6081 포트를 사용하며, 하드웨어·소프트웨어에서 호환성이 뛰어납니다.</li>
      <li><strong>표준화된 프로토콜</strong> : Cisco 주도로 만들어진 VXLAN과 달리, 처음부터 IETF에서 <strong>범람하는 캡슐화 프로토콜을 통합할 목적으로 만든</strong> 프로토콜로, 더 널리 채택될 가능성이 높습니다.</li>
      <li><strong>확장 가능한 서비스</strong> : 정책, 전송 보안, 서비스 체이닝 등 다양한 서비스에 대한 확장성을 제공하며, SDN(Software Defined Networking) 환경에서 유용합니다.</li>
      <li><strong>하드웨어 오프로드</strong> : VXLAN도 NIC 오프로드를 지원하지만, Geneve는 설계시 부터 하드웨어 오프로드를 고려하여 설계되어, 성능이 향상될 수 있습니다.</li>
    </ul>
  </li>
</ul>

<h4 id="geneve-실습">GENEVE 실습</h4>

<ul>
  <li>실습을 통해 GENEVE 모드를 사용하여 파드 간 통신을 설정해보겠습니다.</li>
</ul>

<h5 id="geneve-모드-설정">GENEVE 모드 설정</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># GENEVE 커널 모듈 로드</span>
<span class="nv">$ </span>lsmod | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'vxlan|geneve'</span>
<span class="c"># =&gt; vxlan                 147456  0</span>
<span class="c">#    ip6_udp_tunnel         16384  1 vxlan</span>
<span class="c">#    udp_tunnel             36864  1 vxlan</span>
<span class="nv">$ </span>modprobe geneve
<span class="nv">$ </span>lsmod | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'vxlan|geneve'</span>
<span class="c"># =&gt; &lt;span style="color: green; padding: 2px 3px; border: 2px solid red; margin: 0 -5px;"&gt;geneve                 45056  0&lt;/span&gt;</span>
<span class="c">#    vxlan                 147456  0</span>
<span class="c">#    ...</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w0 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>modprobe geneve <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    &gt;&gt; node : k8s-w0 &lt;&lt;</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w0 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>lsmod | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'vxlan|geneve'</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    &lt;span style="color: green; padding: 2px 3px; border: 2px solid red; margin: 0 -5px;"&gt;geneve                 45056  0&lt;/span&gt;</span>
<span class="c">#    vxlan                 147456  0</span>
<span class="c">#    ip6_udp_tunnel         16384  2 &lt;span style="color: green; padding: 2px 3px; border: 2px solid red; margin: 0 -5px;"&gt;geneve&lt;/span&gt;,vxlan</span>
<span class="c">#    udp_tunnel             36864  2 &lt;span style="color: green; padding: 2px 3px; border: 2px solid red; margin: 0 -5px;"&gt;geneve&lt;/span&gt;,vxlan</span>
<span class="c">#    &gt;&gt; node : k8s-w0 &lt;&lt;</span>
<span class="c">#    &lt;span style="color: green; padding: 2px 3px; border: 2px solid red; margin: 0 -5px;"&gt;geneve                 45056  0&lt;/span&gt;</span>
<span class="c">#    vxlan                 147456  0</span>
<span class="c">#    ip6_udp_tunnel         16384  2 &lt;span style="color: green; padding: 2px 3px; border: 2px solid red; margin: 0 -5px;"&gt;geneve&lt;/span&gt;,vxlan</span>
<span class="c">#    udp_tunnel             36864  2 &lt;span style="color: green; padding: 2px 3px; border: 2px solid red; margin: 0 -5px;"&gt;geneve&lt;/span&gt;,vxlan</span>

<span class="c"># k8s-w1 노드에 배포된 webpod 파드 IP 지정</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">WEBPOD1</span><span class="o">=</span><span class="si">$(</span>kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>webpod <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-w1 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].status.podIP}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$WEBPOD1</span>
<span class="c"># =&gt; 172.20.1.198</span>

<span class="c"># 반복 ping 실행해두기</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> ping <span class="nv">$WEBPOD1</span>


<span class="c"># 업그레이드</span>
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--namespace</span> kube-system <span class="nt">--version</span> 1.18.0 <span class="nt">--reuse-values</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">routingMode</span><span class="o">=</span>tunnel <span class="nt">--set</span> <span class="nv">tunnelProtocol</span><span class="o">=</span>geneve <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">autoDirectNodeRoutes</span><span class="o">=</span><span class="nb">false</span> <span class="nt">--set</span> <span class="nv">installNoConntrackIptablesRules</span><span class="o">=</span><span class="nb">false</span>
<span class="c"># =&gt; Release "cilium" has been upgraded. Happy Helming!</span>
<span class="c">#    ...</span>

<span class="c"># 설정을 적용하기 위해서 Cilium DaemonSet을 재시작합니다.</span>
<span class="nv">$ </span>kubectl rollout restart <span class="nt">-n</span> kube-system ds/cilium
<span class="c"># =&gt; daemonset.apps/cilium restarted</span>

<span class="c"># 설정 확인</span>
<span class="nv">$ </span>cilium features status
<span class="nv">$ </span>cilium features status | <span class="nb">grep </span>datapath_network
<span class="c"># =&gt; Cilium   Agents</span>
<span class="c">#    Uniform  Name                             Labels              k8s-ctr  k8s-w0  k8s-w1</span>
<span class="c">#    Yes      cilium_feature_datapath_network                                         mode=&lt;span style="color: green; padding: 2px 3px; border: 2px solid red; margin: 0 -5px;"&gt;overlay-geneve&lt;/span&gt;                               1        1       1</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium status | <span class="nb">grep</span> ^Routing
<span class="c"># =&gt; Routing:                 Network: &lt;span style="color: green; padding: 2px 3px; border: 2px solid red; margin: 0 -5px;"&gt;Tunnel [geneve]&lt;/span&gt;   Host: BPF</span>
<span class="nv">$ </span>cilium config view | <span class="nb">grep </span>tunnel
<span class="c"># =&gt; routing-mode                                      tunnel</span>
<span class="c">#    tunnel-protocol                                   geneve</span>
<span class="c">#    tunnel-source-port-range                          0-0</span>

<span class="c"># cilium_geneve 확인</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> addr show dev cilium_geneve
<span class="c"># =&gt; 29: cilium_geneve: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN group default</span>
<span class="c">#        link/ether 9e:6f:d6:29:71:60 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet6 fe80::9c6f:d6ff:fe29:7160/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w0 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> addr show dev cilium_geneve <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    11: cilium_geneve: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN group default</span>
<span class="c">#        link/ether c2:bd:d4:eb:63:fd brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet6 fe80::c0bd:d4ff:feeb:63fd/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w0 &lt;&lt;</span>
<span class="c">#    11: cilium_geneve: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN group default</span>
<span class="c">#        link/ether 0e:fd:73:c8:6f:37 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet6 fe80::cfd:73ff:fec8:6f37/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>

<span class="c"># 라우팅 정보 확인 : k8s node 간 다른 네트워크 대역에 있더라도, 파드의 네트워크 대역 정보가 라우팅에 올라왔다!</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route | <span class="nb">grep </span>cilium_host
<span class="c"># =&gt; 172.20.0.0/24 via 172.20.0.201 dev cilium_host proto kernel src 172.20.0.201</span>
<span class="c">#    172.20.0.201 dev cilium_host proto kernel scope link</span>
<span class="c">#    172.20.1.0/24 via 172.20.0.201 dev cilium_host proto kernel src 172.20.0.201 mtu 1450</span>
<span class="c">#    172.20.2.0/24 via 172.20.0.201 dev cilium_host proto kernel src 172.20.0.201 mtu 1450 </span>

<span class="nv">$ </span>ip route get 172.20.1.10
<span class="c"># =&gt; 172.20.1.10 dev cilium_host src 172.20.0.201 uid 0</span>
<span class="c">#        cache mtu 1450</span>
<span class="nv">$ </span>ip route get 172.20.2.10
<span class="c"># =&gt; 172.20.2.10 dev cilium_host src 172.20.0.201 uid 0</span>
<span class="c">#        cache mtu 1450</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 geneve도 VXLAN과 마찬가지로 50 bytes의 캡슐화 오버헤드가 발생하는것 같습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<ul>
  <li>커널 모듈을 로드하고, helm을 통해 GENEVE 모드 설정을 바꾸고, daemonset을 재시작하는것 만으로 
간단하게 VXLAN 모드에서 GENEVE 모드로 변경할 수 있었습니다.</li>
  <li>VXLAN 모드로 변경할때와 마찬가지로 <strong>daemonset이 재시작 되는 동안 파드간 통신이 중단</strong>되는것을 확인할 수 있었습니다.
운영 환경에서는 주의가 필요합니다.</li>
</ul>

<h5 id="파드간-통신-확인-1">파드간 통신 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># k8s-w0 노드에 배포된 webpod 파드 IP 지정</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">WEBPOD</span><span class="o">=</span><span class="si">$(</span>kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>webpod <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-w0 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].status.podIP}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$WEBPOD</span>
<span class="c"># =&gt; 172.20.2.73</span>

<span class="c"># 신규 터미널 [router]</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> any udp port 8472 <span class="nt">-nn</span>

<span class="c"># [k8s-ctr] 에서 ping 실행</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> ping <span class="nt">-c</span> 2 <span class="nt">-w</span> 1 <span class="nt">-W</span> 1 <span class="nv">$WEBPOD</span>
<span class="c"># =&gt; PING 172.20.2.73 (172.20.2.73) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 172.20.2.73: icmp_seq=1 ttl=63 time=4.10 ms</span>
<span class="c">#    64 bytes from 172.20.2.73: icmp_seq=2 ttl=63 time=1.47 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 172.20.2.73 ping statistics ---</span>
<span class="c">#    2 packets transmitted, 2 received, 0% packet loss, time 1000ms</span>
<span class="c">#    rtt min/avg/max/mdev = 1.473/2.786/4.100/1.313 ms</span>

<span class="c"># [router]에서 tcpdump 확인 (GENEVE 포트 6081/udp로 통신이 되는지 확인)</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> any udp port 6081 <span class="nt">-nn</span>
<span class="c"># =&gt; 00:17:18.537335 eth1  In  IP 192.168.10.100.54038 &gt; 192.168.20.100.6081: Geneve, Flags [none], vni 0x53fc: IP 172.20.0.89 &gt; 172.20.2.73: ICMP echo request, id 59783, seq 1, length 64</span>
<span class="c">#    00:17:18.537385 eth2  Out IP 192.168.10.100.54038 &gt; 192.168.20.100.6081: Geneve, Flags [none], vni 0x53fc: IP 172.20.0.89 &gt; 172.20.2.73: ICMP echo request, id 59783, seq 1, length 64</span>
<span class="c">#    00:17:18.538608 eth2  In  IP 192.168.20.100.61597 &gt; 192.168.10.100.6081: Geneve, Flags [none], vni 0x42b9: IP 172.20.2.73 &gt; 172.20.0.89: ICMP echo reply, id 59783, seq 1, length 64</span>
<span class="c">#    00:17:18.538616 eth1  Out IP &lt;span style="color: green;"&gt;192.168.20.100.61597 &gt; 192.168.10.100.6081&lt;/span&gt;: &lt;span style="color: green;"&gt;Geneve&lt;/span&gt;, Flags [none], vni 0x42b9: IP &lt;span style="color: green;"&gt;172.20.2.73 &gt; 172.20.0.89&lt;/span&gt;: ICMP echo reply, id 59783, seq 1, length 64</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 GENEVE을 통해 파드 IP간 통신이 노드간 IP로 캡슐화되어 통신이 되는 것을 확인할 수 있습니다.&lt;/span&gt;</span>

<span class="c"># 신규 터미널 [router] : 라우팅이 어떻게 되는가?</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> any icmp <span class="nt">-nn</span>
<span class="c"># =&gt; (없음)</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 GENEVE을 통해 캡슐화된 패킷으로 통신이 되기 때문에 직접적으로 ICMP(ping) 패킷은 보이지 않습니다.&lt;/span&gt;</span>

<span class="c"># 반복 접속</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl webpod | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod-697b545f57-b46tz</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s --connect-timeout 1 webpod | grep Hostname; echo "---" ; sleep 1; done'</span>

<span class="c"># 신규 터미널 [router]</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> any udp port 6081 <span class="nt">-w</span> /tmp/geneve.pcap
<span class="nv">$ </span>tshark <span class="nt">-r</span> /tmp/geneve.pcap <span class="nt">-d</span> udp.port<span class="o">==</span>6081,geneve
<span class="c"># =&gt;     1   0.000000  172.20.0.89 → 172.20.2.73  TCP 130 44270 → 80 [SYN] Seq=0 Win=64860 Len=0 MSS=1410 SACK_PERM TSval=2614161702 TSecr=0 WS=128</span>
<span class="c">#        2   0.000026  172.20.0.89 → 172.20.2.73  TCP 130 [TCP Retransmission] 44270 → 80 [SYN] Seq=0 Win=64860 Len=0 MSS=1410 SACK_PERM TSval=2614161702 TSecr=0 WS=128</span>
<span class="c">#        3   0.000809  172.20.2.73 → 172.20.0.89  TCP 130 80 → 44270 [SYN, ACK] Seq=0 Ack=1 Win=64308 Len=0 MSS=1410 SACK_PERM TSval=3049232850 TSecr=2614161702 WS=128</span>
<span class="c">#        4   0.000817  172.20.2.73 → 172.20.0.89  TCP 130 [TCP Retransmission] 80 → 44270 [SYN, ACK] Seq=0 Ack=1 Win=64308 Len=0 MSS=1410 SACK_PERM TSval=3049232850 TSecr=2614161702 WS=128</span>
<span class="c">#        5   0.001933  172.20.0.89 → 172.20.2.73  TCP 122 44270 → 80 [ACK] Seq=1 Ack=1 Win=64896 Len=0 TSval=2614161704 TSecr=3049232850</span>
<span class="c">#        6   0.001940  172.20.0.89 → 172.20.2.73  TCP 122 [TCP Dup ACK 5#1] 44270 → 80 [ACK] Seq=1 Ack=1 Win=64896 Len=0 TSval=2614161704 TSecr=3049232850</span>
<span class="c">#        7   0.002279  172.20.0.89 → 172.20.2.73  HTTP 192 GET / HTTP/1.1</span>
<span class="c">#        8   0.002446  172.20.0.89 → 172.20.2.73  TCP 192 [TCP Retransmission] 44270 → 80 [PSH, ACK] Seq=1 Ack=1 Win=64896 Len=70 TSval=2614161705 TSecr=3049232850</span>
<span class="c">#        9   0.004700  172.20.2.73 → 172.20.0.89  TCP 122 80 → 44270 [ACK] Seq=1 Ack=71 Win=64256 Len=0 TSval=3049232852 TSecr=2614161705</span>
<span class="c">#       10   0.004712  172.20.2.73 → 172.20.0.89  TCP 122 [TCP Dup ACK 9#1] 80 → 44270 [ACK] Seq=1 Ack=71 Win=64256 Len=0 TSval=3049232852 TSecr=2614161705</span>
<span class="c">#       11   0.005871  172.20.2.73 → 172.20.0.89  HTTP 441 HTTP/1.1 200 OK  (text/plain)</span>
<span class="c">#       12   0.005874  172.20.2.73 → 172.20.0.89  TCP 441 [TCP Retransmission] 80 → 44270 [PSH, ACK] Seq=1 Ack=71 Win=64256 Len=319 TSval=3049232855 TSecr=2614161705</span>
<span class="c">#       13   0.006514  172.20.0.89 → 172.20.2.73  TCP 122 44270 → 80 [ACK] Seq=71 Ack=320 Win=64640 Len=0 TSval=2614161709 TSecr=3049232855</span>
<span class="c">#       14   0.006527  172.20.0.89 → 172.20.2.73  TCP 122 [TCP Dup ACK 13#1] 44270 → 80 [ACK] Seq=71 Ack=320 Win=64640 Len=0 TSval=2614161709 TSecr=3049232855</span>
<span class="c">#       15   0.006916  172.20.0.89 → 172.20.2.73  TCP 122 44270 → 80 [FIN, ACK] Seq=71 Ack=320 Win=64640 Len=0 TSval=2614161709 TSecr=3049232855</span>
<span class="c">#       16   0.006922  172.20.0.89 → 172.20.2.73  TCP 122 [TCP Retransmission] 44270 → 80 [FIN, ACK] Seq=71 Ack=320 Win=64640 Len=0 TSval=2614161709 TSecr=3049232855</span>
<span class="c">#       17   0.007468  172.20.2.73 → 172.20.0.89  TCP 122 80 → 44270 [FIN, ACK] Seq=320 Ack=72 Win=64256 Len=0 TSval=3049232856 TSecr=2614161709</span>
<span class="c">#       18   0.007474  172.20.2.73 → 172.20.0.89  TCP 122 [TCP Retransmission] 80 → 44270 [FIN, ACK] Seq=320 Ack=72 Win=64256 Len=0 TSval=3049232856 TSecr=2614161709</span>
<span class="c">#       19   0.008120  172.20.0.89 → 172.20.2.73  TCP 122 44270 → 80 [ACK] Seq=72 Ack=321 Win=64640 Len=0 TSval=2614161710 TSecr=3049232856</span>
<span class="c">#       20   0.008125  172.20.0.89 → 172.20.2.73  TCP 122 [TCP Dup ACK 19#1] 44270 → 80 [ACK] Seq=72 Ack=321 Win=64640 Len=0 TSval=2614161710 TSecr=3049232856</span>
<span class="c">#       ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 tshark로도 GENEVE 캡슐화된 패킷을 해석할 수 있지만 조금 더 원활한 해석을 위해서 termshark를 사용해보겠습니다.&lt;/span&gt;</span>

<span class="nv">$ </span>termshark <span class="nt">-r</span> /tmp/geneve.pcap <span class="nt">-d</span> udp.port<span class="o">==</span>6081,geneve
<span class="c"># =&gt; termshark 2.4.0  |  geneve.pcap                                                                                                                                  Analysis    Misc</span>
<span class="c">#    ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓</span>
<span class="c">#    ┃Filter:                                                                                                                                                         &lt;Apply&gt; &lt;Recent&gt; ┃</span>
<span class="c">#    ┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛</span>
<span class="c">#     No. - Time -    Source -     Dest -       Proto - Length - Info -                                                                                                                ▲</span>
<span class="c">#     1     0.000000  172.20.0.89  172.20.2.73  TCP     130      44270 → 80 [SYN] Seq=0 Win=64860 Len=0 MSS=1410 SACK_PERM TSval=2614161702 TSecr=0 WS=128</span>
<span class="c">#     2     0.000026  172.20.0.89  172.20.2.73  TCP     130      [TCP Retransmission] 44270 → 80 [SYN] Seq=0 Win=64860 Len=0 MSS=1410 SACK_PERM TSval=2614161702 TSecr=0 WS=128</span>
<span class="c">#     3     0.000809  172.20.2.73  172.20.0.89  TCP     130      80 → 44270 [SYN, ACK] Seq=0 Ack=1 Win=64308 Len=0 MSS=1410 SACK_PERM TSval=3049232850 TSecr=2614161702 WS=128         █</span>
<span class="c">#     4     0.000817  172.20.2.73  172.20.0.89  TCP     130      [TCP Retransmission] 80 → 44270 [SYN, ACK] Seq=0 Ack=1 Win=64308 Len=0 MSS=1410 SACK_PERM TSval=3049232850 TSecr=2614</span>
<span class="c">#     5     0.001933  172.20.0.89  172.20.2.73  TCP     122      44270 → 80 [ACK] Seq=1 Ack=1 Win=64896 Len=0 TSval=2614161704 TSecr=3049232850</span>
<span class="c">#     6     0.001940  172.20.0.89  172.20.2.73  TCP     122      [TCP Dup ACK 5#1] 44270 → 80 [ACK] Seq=1 Ack=1 Win=64896 Len=0 TSval=2614161704 TSecr=3049232850</span>
<span class="c">#     7     0.002279  172.20.0.89  172.20.2.73  HTTP    192      GET / HTTP/1.1</span>
<span class="c">#     8     0.002446  172.20.0.89  172.20.2.73  TCP     192      [TCP Retransmission] 44270 → 80 [PSH, ACK] Seq=1 Ack=1 Win=64896 Len=70 TSval=2614161705 TSecr=3049232850</span>
<span class="c">#     9     0.004700  172.20.2.73  172.20.0.89  TCP     122      80 → 44270 [ACK] Seq=1 Ack=71 Win=64256 Len=0 TSval=3049232852 TSecr=2614161705</span>
<span class="c">#     10    0.004712  172.20.2.73  172.20.0.89  TCP     122      [TCP Dup ACK 9#1] 80 → 44270 [ACK] Seq=1 Ack=71 Win=64256 Len=0 TSval=3049232852 TSecr=2614161705</span>
<span class="c">#     11    0.005871  172.20.2.73  172.20.0.89  HTTP    441      HTTP/1.1 200 OK  (text/plain)                                                                                         ▼</span>
<span class="c">#    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>
<span class="c">#    [+] Linux cooked capture v2</span>
<span class="c">#    [+] Internet Protocol Version 4, &lt;span style="color: green; padding: 2px 3px; border: 2px solid red; margin: 0 -5px;"&gt;Src: 192.168.10.100, Dst: 192.168.20.100&lt;/span&gt;</span>
<span class="c">#    [+] User Datagram Protocol, Src Port: 41753, Dst Port: 6081</span>
<span class="c">#    [+] &lt;span style="color: green; padding: 2px 3px; border: 2px solid red; margin: 0 -5px;"&gt;Generic Network Virtualization Encapsulation&lt;/span&gt;, VNI: 0x0053fc [=]</span>
<span class="c">#    [+] Ethernet II, Src: 46:02:28:c8:e7:b6 (46:02:28:c8:e7:b6), Dst: ca:7a:5c:b2:2c:4a (ca:7a:5c:b2:2c:4a)</span>
<span class="c">#    [+] Internet Protocol Version 4, Src: &lt;span style="color: green; padding: 2px 3px; border: 2px solid red; margin: 0 -5px;"&gt;172.20.0.89, Dst: 172.20.2.73&lt;/span&gt;</span>
<span class="c">#    [+] Transmission Control Protocol, Src Port: 44270, Dst Port: 80, Seq: 1, Ack: 1, Len: 70</span>
<span class="c">#    [-] Hypertext Transfer Protocol</span>
<span class="c">#      [+] GET / HTTP/1.1</span>
<span class="c">#          Host: webpod</span>
<span class="c">#          User-Agent: curl/8.14.1</span>
<span class="c">#          Accept: */*</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 -d udp.port==6081,geneve 옵션을 통해 VXLAN 캡슐화된 패킷을 해석할 수 있습니다.&lt;/span&gt;</span>

<span class="c"># 신규 터미널 [k8s-ctr] hubble flow log 모니터링 : overlay 통신 모드 확인!</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--protocol</span> tcp <span class="nt">--pod</span> curl-pod
<span class="c"># =&gt; ...</span>
<span class="c">#    Aug  9 15:29:04.546: default/curl-pod:53356 (ID:21500) -&gt; default/webpod-697b545f57-66grn:80 (ID:17081) to-overlay FORWARDED (TCP Flags: SYN)</span>
<span class="c">#    Aug  9 15:29:04.548: default/curl-pod:53356 (ID:21500) &lt;- default/webpod-697b545f57-66grn:80 (ID:17081) to-endpoint FORWARDED (TCP Flags: SYN, ACK)</span>
<span class="c">#    Aug  9 15:29:04.548: default/curl-pod:53356 (ID:21500) -&gt; default/webpod-697b545f57-66grn:80 (ID:17081) to-overlay FORWARDED (TCP Flags: ACK)</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<ul>
  <li>GENEVE 모드로 변경한 후에도 파드 간 통신이 정상적으로 이루어지는 것을 확인할 수 있었습니다.</li>
</ul>

<hr />

<h2 id="k8s-service">K8S Service</h2>

<h3 id="클러스터-내부를-외부에-노출하는-방법의-발전단계">클러스터 내부를 외부에 노출하는 방법의 발전단계</h3>

<ol>
  <li>파드 생성 : K8S 클러스터 내부에서만 접속
  <img src="/assets/2025/cilium/w4/20250810_cilium_w4_5.png" alt="img.png" class="image-left" /><br /></li>
  <li>서비스(<strong>Cluster</strong> Type) 연결 : K8S 클러스터 내부에서만 접속
<img src="/assets/2025/cilium/w4/20250810_cilium_w4_6.png" alt="img_1.png" class="image-left" />
    <ul>
      <li>동일한 애플리케이션의 다수의 파드의 접속을 용이하게 하기 위한 서비스에 접속</li>
      <li><strong>고정 접속(호출)</strong> 방법을 제공 : 흔히 말하는 ‘<strong>고정 Virtual IP</strong>’ 와 ‘<strong>Domain주소</strong>’ 생성<br /><br /></li>
    </ul>
  </li>
  <li>서비스(<strong>NodePort</strong> Type) 연결 : 외부 클라이언트가 서비스를 통해서 클러스터 내부의 파드로 접속
<img src="/assets/2025/cilium/w4/20250810_cilium_w4_7.png" alt="img_2.png" class="image-left" />
    <ul>
      <li>서비스(<strong>NodePort</strong> Type)의 일부 단점을 보완한 서비스(<strong>LoadBalancer</strong> Type) 도 있습니다.</li>
    </ul>
  </li>
</ol>

<h3 id="service-종류">Service 종류</h3>

<h4 id="clusterip-타입">ClusterIP 타입</h4>

<p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_1.png" alt="img.png" class="w-80 image-center" /></p>

<ul>
  <li>동일한 애플리케이션을 실행하는 여러 Pod에 접속을 용이하기 위해 사용합니다.</li>
  <li>ClusterIP는 Cluster 내부에서만 접근이 가능하며 외부에서는 접근이 불가능합니다.</li>
  <li>iptables 의 NAT 기능을 이용하여 Pod에 접근하며, 동일한 iptables 분산룰을 각 노드에 적용합니다.</li>
</ul>

<h4 id="nodeport-타입">NodePort 타입</h4>

<p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_2.png" alt="img.png" class="w-80 image-center" /></p>

<ul>
  <li>NodePort는 ClusterIP와 같이 Cluster 내부에서 접근이 가능하며, 외부에서도 접근이 가능합니다.</li>
  <li>NodePort도 ClusterIP와 같이 iptables의 NAT 기능을 이용하여 Pod에 접근하며, 각 노드에 NodePort를 할당합니다.</li>
  <li>외부에서는 NodePort를 통해 각 노드에 접근 할 수 있습니다.</li>
</ul>

<h4 id="loadbalancer-타입">LoadBalancer 타입</h4>

<p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_3.png" alt="img.png" class="w-80 image-center" /></p>

<ul>
  <li>LoadBalancer도 외부에서 접근이 가능하며, 클라우드 서비스에서 제공하는 LoadBalancer를 사용합니다. (AWS의 경우 ELB(Elastic Load Balancer)가 사용됩니다.)</li>
  <li>온프레미스 환경에서도 MetalLB와 같은 LoadBalancer를 사용할 수 있습니다.</li>
</ul>

<h3 id="서비스의-구조">서비스의 구조</h3>

<p>서비스를 선언시 <code class="language-plaintext highlighter-rouge">port</code>와 <code class="language-plaintext highlighter-rouge">targetPort</code>, 그리고 <code class="language-plaintext highlighter-rouge">label selector</code> 를 사용합니다. 각각의 역할은 다음과 같습니다.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">port</code> : 서비스가 listen 할 포트를 지정합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">targetPort</code> : 대상 파드의 port를 지정합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">label selector</code>  : 대상 파드를 특정합니다.</li>
</ul>

<p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_7.png" alt="img.png" /></p>

<h3 id="kube-proxy-모드">kube-proxy 모드</h3>

<ul>
  <li>kube-proxy는 쿠버네티스 클러스터에서 서비스의 트래픽을 파드로 라우팅하는 역할을 합니다.</li>
  <li><strong>선택사항이지만</strong>, 반드시 kube-proxy를 대체할 수 있는 대안이 배포되어야 합니다. (예) cilium 등)</li>
  <li>kube-proxy는 서비스 통신 동작에 대한 설정을 관리합니다. 데몬셋으로 배포되어 모든 노드에 파드가 생성됩니다.</li>
  <li>kube-proxy 모드의 종류는 userspace proxy 모드, iptables proxy 모드, ipvs proxy 모드, nftables proxy 모드 등이 있습니다.</li>
</ul>

<h4 id="userspace-proxy-모드-현재는-미사용">userspace proxy 모드 (현재는 미사용)</h4>

<p><img src="/assets/2025/cilium/w4/20250810_cilium_w4_8.png" alt="img.png" class="image-center w-80" />
<em class="image-caption">출처 : <a href="https://medium.com/finda-tech/kubernetes-%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EC%A0%95%EB%A6%AC-fccd4fd0ae6">https://medium.com/finda-tech/kubernetes-네트워크-정리-fccd4fd0ae6</a></em></p>

<ul>
  <li>기초적인 모드이며 사용자 영역의 kube-proxy를 통해 NIC1으로 들어온 패킷을 NIC2로 전달하여 목적 파드로 전달합니다.</li>
  <li>이렇게 하는 과정에서 커널영역(netfilter)과 사용자영역(kube-proxy)를 오가는 과정에서 스위칭에 의한 오버헤드가 발생하는 단점이 있습니다.</li>
</ul>

<h4 id="iptables-proxy-모드">iptables proxy 모드</h4>

<p><img src="/assets/2025/cilium/w4/20250810_cilium_w4_9.png" alt="img.png" class="image-center w-80" />
<em class="image-caption">출처 : <a href="https://medium.com/finda-tech/kubernetes-%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EC%A0%95%EB%A6%AC-fccd4fd0ae6">https://medium.com/finda-tech/kubernetes-네트워크-정리-fccd4fd0ae6</a></em></p>

<ul>
  <li>쿠버네티스 설치시 기본 모드이며, userspace proxy 모드와는 달리 kube-proxy는 트래픽 전달에 직접 관여하지는 않고, netfilter(iptables)를 사용하여 트래픽을 전달합니다.</li>
  <li>iptables proxy 모드는 트래픽 전달 과정에서 kube-proxy를 경유하지 않고, 커널 영역과 사용자 영역 전환이 필요하지 않아서, 유저스페이스 proxy 모드에 비해 오버헤드가 줄어듭니다.</li>
  <li>단점으로는 iptables 규칙이 많아 질 경우 모든 규칙 평가 하는데 지연이 발생할 수 있습니다.</li>
  <li>또한 장애시 모든 규칙을 확인하기 어려워 장애 처리에 불리합니다.</li>
</ul>

<h4 id="ipvs-proxy-모드">ipvs proxy 모드</h4>

<p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_10.png" alt="img.png" /></p>

<ul>
  <li>IPVS Mode는 Linue Kernel에서 제공하는 L4 Load Balacner인 IPVS가 Service Proxy 역할을 수행하는 Mode입니다.</li>
  <li>Packet Load Balancing 수행시 IPVS가 iptables보다 높은 성능을 보이기 때문에 IPVS Mode는 iptables Mode보다 높은 성능을 보여준다</li>
  <li>IPVS 프록시 모드는 iptables 모드와 유사한 netfilter hook 기능을 기반으로 하지만, 해시 테이블을 기본 데이터 구조로 사용하고 <strong>커널 스페이스</strong>에서 동작하여 효율 적으로 동작합니다.</li>
  <li>다른 프록시 모드와 비교했을 때, IPVS 모드는 높은 네트워크 트래픽 처리량도 지원합니다.</li>
</ul>

<h4 id="nftables-proxy-모드">nftables proxy 모드</h4>
<ul>
  <li>nftables 는 iptables를 대체하기 위해 개발된 패킷 필터링 프레임워크로, iptables 보다 더 유연하고 강력한 규칙 설정을 제공합니다.</li>
  <li>하지만 아직  실험적으로 개발중인 단계로 실무에서는 ipvs proxy 모드를 권장합니다.</li>
</ul>

<h4 id="ebpf-모드--xdp">eBPF 모드 + XDP</h4>

<p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_11.png" alt="img.png" class="w-90 image-center" /></p>

<ul>
  <li>앞에서 알아보았던 모든 모드들이 netfilter 기반인데 반해, eBPF 모드 +  XDP 는 netfilter 전 단계에서 트래픽 라우팅을 처리하여 훨씬 효율 적입니다. calico나 cilium을 사용하여서 eBPF 모드를 사용할 수 있습니다.</li>
</ul>

<hr />

<h2 id="service-lb-ipam">Service LB-IPAM</h2>

<p><img src="/assets/2025/cilium/w4/20250810_cilium_w4_10.png" alt="img.png" class="image-center" />
<em class="image-caption">출처 : <a href="https://isovalent.com/blog/post/migrating-from-metallb-to-cilium/#load-balancer-ipam">https://isovalent.com/blog/post/migrating-from-metallb-to-cilium/</a></em></p>

<ul>
  <li>LoadBalancer IP Address Management (LB IPAM) 소개 - <a href="https://docs.cilium.io/en/stable/network/lb-ipam/">Docs</a>, <a href="https://www.youtube.com/watch?v=amC00re6-5k">Youtube</a>
    <ul>
      <li>LB-IPAM은 Cilium에서 제공하는 LoadBalancer IP Address Management 기능으로 LoadBalancer 서비스의 External-IP 를 관리합니다. 이 기능은 AWS 등의 클라우드 제공업체에서 제공하는 기능이지만
Private Cloud 환경에서는 K8S 자체에서는 지원하지 않기 때문에 MetalLB와 같은 솔루션을 사용해야 합니다.</li>
      <li>Cilium은 LB-IPAM을 통해서 MetalLB와 같은 솔루션 없이도 LoadBalancer 서비스를 지원합니다.</li>
      <li>LB-IPAM은 <code class="language-plaintext highlighter-rouge">Cilium BGP Control Plane</code> 및 <code class="language-plaintext highlighter-rouge">L2 Announcements</code> / <code class="language-plaintext highlighter-rouge">L2 Aware LB</code> 등의 기능과 함께 사용됩니다. LB-IPAM이 서비스 객체 및 기타 기능에 IP를 할당하고, <code class="language-plaintext highlighter-rouge">L2 Announcements</code>를 통해서 IP를 노출하고, <code class="language-plaintext highlighter-rouge">L2 Aware LB</code>를 통해서 IP를 라우팅합니다.</li>
      <li>LB IPAM은 항상 활성화되어 있지만 휴면 상태입니다. 첫 번째 IP 풀이 클러스터에 추가되면 컨트롤러가 활성화됩니다.</li>
      <li>기능
        <ul>
          <li>Service Selectors - <a href="https://docs.cilium.io/en/stable/network/lb-ipam/#service-selectors">Docs</a></li>
          <li>Disabling a Pool - <a href="https://docs.cilium.io/en/stable/network/lb-ipam/#disabling-a-pool">Docs</a></li>
          <li>Service 사용 확인 - <a href="https://docs.cilium.io/en/stable/network/lb-ipam/#services">Docs</a></li>
          <li>LoadBalancerClass : BGP or L2 지정 - <a href="https://docs.cilium.io/en/stable/network/lb-ipam/#loadbalancerclass">Docs</a></li>
          <li>Requesting IPs : 특정 Service에 EX-IP를 직접 설정 - <a href="https://docs.cilium.io/en/stable/network/lb-ipam/#loadbalancerclass">Docs</a></li>
          <li>Sharing Keys : EX-IP 1개를 각기 다른 Port 를 통해서 사용 - <a href="https://docs.cilium.io/en/stable/network/lb-ipam/#requesting-ips">Docs</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>[k8s 클러스터 내부] webpod 서비스를 LoadBalancer Type 설정 with Cilium LB IPAM</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl get CiliumLoadBalancerIPPool <span class="nt">-A</span>
<span class="c"># =&gt; No resources found</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 아직 등록된 IP Pool이 없으므로, CiliumLoadBalancerIPPool 리소스가 없습니다.&lt;/span&gt;</span>

<span class="c"># cilium ip pool 생성</span>
<span class="c"># 충돌나지 않는지 대역 확인 할 것!</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: "cilium.io/v2"  # v1.17 : cilium.io/v2alpha1
kind: CiliumLoadBalancerIPPool
metadata:
  name: "cilium-lb-ippool"
spec:
  blocks:
  - start: "192.168.10.211"
    stop:  "192.168.10.215"
</span><span class="no">EOF
</span><span class="c"># =&gt; ciliumloadbalancerippool.cilium.io/cilium-lb-ippool created</span>

<span class="nv">$ </span>kubectl get CiliumLoadBalancerIPPool <span class="nt">-A</span>
<span class="c"># =&gt; NAME               DISABLED   CONFLICTING   IPS AVAILABLE   AGE</span>
<span class="c">#    cilium-lb-ippool   false      False         5               13s</span>

<span class="c"># CiliumLoadBalancerIPPool 축약어 : ippools,ippool,lbippool,lbippools</span>
<span class="nv">$ </span>kubectl api-resources | <span class="nb">grep</span> <span class="nt">-i</span> CiliumLoadBalancerIPPool
<span class="c"># =&gt; ciliumloadbalancerippools           ippools,ippool,lbippool,lbippools   cilium.io/v2                      false        CiliumLoadBalancerIPPool</span>

<span class="nv">$ </span>kubectl get ippools
<span class="c"># =&gt; NAME               DISABLED   CONFLICTING   IPS AVAILABLE   AGE</span>
<span class="c">#    cilium-lb-ippool   false      False         5               101s</span>

<span class="c"># webpod 서비스를 LoadBalancer Type 변경 설정</span>
<span class="nv">$ </span>kubectl patch svc webpod <span class="nt">-p</span> <span class="s1">'{"spec":{"type":"LoadBalancer"}}'</span>
<span class="c"># =&gt; service/webpod patched</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get svc webpod
<span class="c"># =&gt; NAME     TYPE           CLUSTER-IP     EXTERNAL-IP      PORT(S)        AGE</span>
<span class="c">#    webpod   LoadBalancer   10.96.129.95   &lt;span style="color: green;"&gt;192.168.10.211&lt;/span&gt;   80:32203/TCP   3h17m</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 webpod 서비스가 LoadBalancer Type으로 변경되었으며, EXTERNAL-IP로 Cilium LB IP Pool에서 할당된 IP가 설정되었습니다.&lt;/span&gt;</span>

<span class="c"># LBIP로 curl 요청 확인 : k8s 노드들에서 LB EXIP로 통신 가능!</span>
<span class="nv">$ </span>kubectl get svc webpod <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.loadBalancer.ingress[0].ip}'</span>
<span class="c"># =&gt; 192.168.10.211</span>
<span class="nv">$ LBIP</span><span class="o">=</span><span class="si">$(</span>kubectl get svc webpod <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.loadBalancer.ingress[0].ip}'</span><span class="si">)</span>

<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LBIP</span>
<span class="c"># =&gt; Hostname: webpod-697b545f57-b46tz</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: ::1</span>
<span class="c">#    IP: 172.20.0.131</span>
<span class="c">#    IP: fe80::48ca:7aff:fee8:da55</span>
<span class="c">#    RemoteAddr: 172.20.0.201:38068</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: 192.168.10.211</span>
<span class="c">#    User-Agent: curl/8.5.0</span>
<span class="c">#    Accept: */*</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nv">$LBIP</span>
<span class="c"># =&gt; Hostname: webpod-697b545f57-b46tz</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: ::1</span>
<span class="c">#    IP: 172.20.0.131</span>
<span class="c">#    IP: fe80::48ca:7aff:fee8:da55</span>
<span class="c">#    RemoteAddr: 172.20.0.89:33706</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: 192.168.10.211</span>
<span class="c">#    User-Agent: curl/8.14.1</span>
<span class="c">#    Accept: */*</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nv">$LBIP</span> | <span class="nb">grep </span>Hostname   <span class="c"># 대상 파드 이름 출력</span>
<span class="c"># =&gt; Hostname: webpod-697b545f57-b46tz</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nv">$LBIP</span> | <span class="nb">grep </span>RemoteAddr <span class="c"># 대상 파드 입장에서 소스 IP 출력(Layer3)</span>
<span class="c"># =&gt; RemoteAddr: 172.20.0.89:46452</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 curl-pod의 파드 IP가 소스 IP로 출력됩니다.&lt;/span&gt;</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LBIP</span> | <span class="nb">grep </span>RemoteAddr <span class="c"># k8s-ctr 노드에서 curl 요청시 소스 IP 출력</span>
<span class="c"># =&gt; RemoteAddr: 172.20.0.201:35196</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s-ctr 노드의 cilium_host의 IP가 출력됩니다.&lt;/span&gt;</span>

<span class="c"># 반복 접속 : </span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nv">$LBIP</span> | <span class="nb">grep </span>Hostname<span class="p">;</span> <span class="nb">sleep </span>0.1<span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span>  <span class="k">do </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nv">$LBIP</span> | <span class="nb">grep </span>Hostname<span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;      38 Hostname: webpod-697b545f57-66grn</span>
<span class="c">#         35 Hostname: webpod-697b545f57-b46tz</span>
<span class="c">#         27 Hostname: webpod-697b545f57-24ck5</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 각 노드의 webpod 파드로 Loadbalancing이 잘 이루어지고 있습니다.&lt;/span&gt;</span>

<span class="c"># IP 할당 확인</span>
<span class="nv">$ </span>kubectl get ippools
<span class="c"># =&gt; NAME               DISABLED   CONFLICTING   IPS AVAILABLE   AGE</span>
<span class="c">#    cilium-lb-ippool   false      False         4               8m</span>
<span class="nv">$ </span>kubectl get ippools <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[*].status.conditions[?(@.type!="cilium.io/PoolConflict")]}'</span> | jq
<span class="c"># =&gt; {</span>
<span class="c">#      "lastTransitionTime": "2025-08-09T08:27:06Z",</span>
<span class="c">#      "message": "5",</span>
<span class="c">#      "observedGeneration": 1,</span>
<span class="c">#      "reason": "noreason",</span>
<span class="c">#      "status": "Unknown",</span>
<span class="c">#      "type": "cilium.io/IPsTotal"</span>
<span class="c">#    }</span>
<span class="c">#    {</span>
<span class="c">#      "lastTransitionTime": "2025-08-09T08:27:06Z",</span>
<span class="c">#      "message": "4",</span>
<span class="c">#      "observedGeneration": 1,</span>
<span class="c">#      "reason": "noreason",</span>
<span class="c">#      "status": "Unknown",</span>
<span class="c">#      "type": "cilium.io/IPsAvailable"</span>
<span class="c">#    }</span>
<span class="c">#    {</span>
<span class="c">#      "lastTransitionTime": "2025-08-09T08:27:06Z",</span>
<span class="c">#      "message": "1",</span>
<span class="c">#      "observedGeneration": 1,</span>
<span class="c">#      "reason": "noreason",</span>
<span class="c">#      "status": "Unknown",</span>
<span class="c">#      "type": "cilium.io/IPsUsed"</span>
<span class="c">#    }</span>

<span class="nv">$ </span>kubectl get svc webpod <span class="nt">-o</span> json | jq
<span class="nv">$ </span>kubectl get svc webpod <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status}'</span> | jq
<span class="c"># =&gt; {</span>
<span class="c">#      "conditions": [</span>
<span class="c">#        {</span>
<span class="c">#          "lastTransitionTime": "2025-08-09T08:29:01Z",</span>
<span class="c">#          "message": "",</span>
<span class="c">#          "reason": "satisfied",</span>
<span class="c">#          "status": "True",</span>
<span class="c">#          "type": "cilium.io/IPAMRequestSatisfied"</span>
<span class="c">#        }</span>
<span class="c">#      ],</span>
<span class="c">#      "loadBalancer": {</span>
<span class="c">#        "ingress": [</span>
<span class="c">#          {</span>
<span class="c">#            "ip": "192.168.10.211",</span>
<span class="c">#            "ipMode": "VIP"</span>
<span class="c">#          }</span>
<span class="c">#        ]</span>
<span class="c">#      }</span>
<span class="c">#    }</span>
</code></pre></div></div>

<ul>
  <li>[k8s 클러스터 외부] webpod 서비스를 LoadBalancer External IP로 호출 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># router : K8S 외부에서 통신 불가! </span>
<span class="nv">$ LBIP</span><span class="o">=</span>192.168.10.211
<span class="nv">$ </span>curl <span class="nt">--connect-timeout</span> 1 <span class="nv">$LBIP</span>
<span class="c"># =&gt; curl: (28) Failed to connect to 192.168.10.211 port 80 after 1002 ms: Timeout was reached</span>
<span class="nv">$ </span>arping <span class="nt">-i</span> eth1 <span class="nv">$LBIP</span> <span class="nt">-c</span> 1
<span class="c"># =&gt; ARPING 192.168.10.211</span>
<span class="c">#    Timeout</span>
<span class="nv">$ </span>arping <span class="nt">-i</span> eth1 <span class="nv">$LBIP</span> <span class="nt">-c</span> 100000
<span class="c"># =&gt; ARPING 192.168.10.211</span>
<span class="c">#    Timeout</span>
<span class="c">#    Timeout</span>
<span class="c">#    Timeout</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 클러스터 외부에서는 webpod 서비스의 LoadBalancer External IP로 통신이 불가능합니다.&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   LB External IP가 외부로 광고(Announcement) 되지 않기 때문입니다.&lt;/span&gt;</span>
</code></pre></div></div>

<hr />

<h2 id="cilium-l2-announcement">Cilium L2 Announcement</h2>

<h3 id="참고-metallb-layer2-모드">(참고) MetalLB Layer2 모드</h3>

<ul>
  <li><a href="https://metallb.universe.tf/concepts/layer2/">Docs</a></li>
  <li>MetalLB는 Layer2 모드에서 BGP를 사용하지 않고, ARP(IPv4) 또는 NDP(IPv6)를 사용하여 IP 주소를 광고합니다.</li>
  <li>하나의 노드 (Leader Node)에서만 IP 주소를 광고하며, Leader Node가 장애가 발생하면 다른 노드가 Leader Node로 승격되어 IP 주소를 광고합니다.</li>
  <li>MetalLB의 장점은 별도의 하드웨어나 라우팅 장치가 없어도 어떠한 이더넷 네트워크에서도 동작한다는 점입니다.</li>
  <li>
    <p>아래는 MetalLB Layer2 모드에서 GARP 패킷을 통해 VIP(Virtual IP : 서비스의 IP)를 광고하는 예시입니다.
<img src="/assets/2025/cilium/w4/20250810_cilium_w4_11.png" alt="img.png" class="image-center w-80" />
<img src="/assets/2025/cilium/w4/20250810_cilium_w4_12.png" alt="img_1.png" class="image-center w-80" /></p>
  </li>
  <li>MetalLB Layer 2 모드에서는 기본적으로 모든 트래픽이 Leader Node로 전달되며, kube-proxy 등을 통해 각 노드로 트래픽이 분산됩니다.</li>
  <li>
    <p>이로 인해 Leader Node에 장애가 발생하면 트래픽이 중단될 수 있습니다.
<img src="/assets/2025/cilium/w4/20250810_cilium_w4_13.png" alt="img_2.png" class="image-center w-80" /></p>
  </li>
  <li>Leader Node가 장애가 발생하면, 다른 노드가 Leader Node로 승격되어 IP 주소를 광고합니다. 
이때 새로운 Leader Node가 IP 주소를 GARP로 광고하기 전에 일정 시간 동안 트래픽이 중단될 수 있습니다.
<img src="/assets/2025/cilium/w4/20250810_cilium_w4_14.png" alt="img_3.png" class="image-center w-80" /></li>
</ul>

<h3 id="cilium-layer-2-l2-announcement-using-arp">Cilium Layer 2 (L2) Announcement Using ARP</h3>

<ul>
  <li><a href="https://docs.cilium.io/en/stable/network/l2-announcements/">Docs</a></li>
  <li>L2 Announcements은 로컬 영역 네트워크에서 서비스를 가시화하고 도달할 수 있도록 하는 기능입니다.</li>
  <li>이 기능은 주로 사무실이나 캠퍼스 네트워크와 같은 BGP 기반 라우팅 없이 네트워크 내에서 
온프레미스 배포를 목적으로 합니다.</li>
  <li>이 기능을 사용하면 ExternalIPs 또는 LoadBalancer IP에 대한 ARP 쿼리에 응답합니다. 
이러한 IP는 여러 노드에 있는 VIP(Virtual IP)이므로 각 서비스에 대해 한 번에 하나의 노드가 
ARP 쿼리에 응답하고 MAC 주소로 응답합니다. 
이 노드는 서비스 로드 밸런싱 기능으로 로드 밸런싱을 수행하여 north/south(내부&lt;=&gt;외부) 로드 밸런서 역할을 합니다.</li>
  <li>이 기능의 장점은 각 서비스가 고유한 IP를 사용할 수 있어 여러 서비스가 동일한 포트 번호를 사용할 
수 있다는 점입니다. NodePort를 사용할 때 트래픽을 보낼 호스트를 결정하는 것은 클라이언트의 몫이며, 
노드가 다운되면 IP+Port 조합을 사용할 수 없게 됩니다. L2 Announcements를 통해 서비스 VIP는 다른 노드로 마이그레이션하면 계속 작동하게 됩니다.
<img src="/assets/2025/cilium/w4/20250810_cilium_w4_15.png" alt="img.png" class="image-center" />
<img src="/assets/2025/cilium/w4/20250810_cilium_w4_16.png" alt="img_1.png" class="image-center" /></li>
</ul>

<h5 id="k8s-클러스터-외부-webpod-서비스를-loadbalancer-external-ip로-호출확인">[k8s 클러스터 외부] webpod 서비스를 LoadBalancer External IP로 호출확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 모니터링 : router VM</span>
<span class="nv">$ </span>arping <span class="nt">-i</span> eth1 <span class="nv">$LBIP</span> <span class="nt">-c</span> 100000
<span class="c"># =&gt; ARPING 192.168.10.211</span>
<span class="c">#    Timeout</span>
<span class="c">#    Timeout</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 설정 업그레이드 및 CiliumL2AnnouncementPolicy을 통해 정책 설정 시점부터 통신이 됩니다.&lt;/span&gt;</span>
<span class="c">#    60 bytes from 08:00:27:8e:9b:f8 (192.168.10.211): index=0 time=1.101 msec</span>
<span class="c">#    60 bytes from 08:00:27:8e:9b:f8 (192.168.10.211): index=1 time=1.967 msec</span>
<span class="c">#    ...</span>

<span class="c"># 설정 업그레이드</span>
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--namespace</span> kube-system <span class="nt">--version</span> 1.18.0 <span class="nt">--reuse-values</span> <span class="se">\</span>
   <span class="nt">--set</span> l2announcements.enabled<span class="o">=</span><span class="nb">true</span> 
<span class="c"># =&gt; Release "cilium" has been upgraded. Happy Helming!</span>

<span class="nv">$ </span>kubectl rollout restart <span class="nt">-n</span> kube-system ds/cilium
<span class="nv">$ </span>watch <span class="nt">-d</span> kubectl get pod <span class="nt">-A</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system <span class="nb">exec </span>ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium-dbg config <span class="nt">--all</span> | <span class="nb">grep </span>EnableL2Announcements
<span class="c"># =&gt; EnableL2Announcements             : true</span>

<span class="nv">$ </span>cilium config view | <span class="nb">grep </span>enable-l2
<span class="c"># =&gt; enable-l2-announcements                           true</span>
<span class="c">#    enable-l2-neigh-discovery                         false</span>

<span class="c"># 정책 설정 : arp 광고하게 될 service 와 node 지정(controlplane 제외) -&gt; 설정 직후 arping 확인!</span>
<span class="c">## 제약사항 : L2 ARP 모드에서 LB IPPool 은 같은 네트워크 대역에서만 유효. -&gt; k8s-w0 을 제외한 이유. 포함 시 리더 노드 선정 시 동작 실패 상황 발생!</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: "cilium.io/v2alpha1"  # not v2
kind: CiliumL2AnnouncementPolicy
metadata:
  name: policy1
spec:
  serviceSelector:
    matchLabels:
      app: webpod
  nodeSelector:
    matchExpressions:
      - key: kubernetes.io/hostname
        operator: NotIn
        values:
          - k8s-w0
  interfaces:
  - ^eth[1-9]+
  externalIPs: true
  loadBalancerIPs: true
</span><span class="no">EOF
</span><span class="c"># =&gt; ciliuml2announcementpolicy.cilium.io/policy1 created</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 정책 설정 후 부터 arping이 성공합니다.&lt;/span&gt;</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system get lease
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system get lease | <span class="nb">grep</span> <span class="s2">"cilium-l2announce"</span>
<span class="c"># =&gt; NAME                                   HOLDER                                                                      AGE</span>
<span class="c">#    cilium-l2announce-default-webpod       k8s-w1                                                                      2m56s</span>
<span class="c">#    ...</span>

<span class="c"># 현재 리더 역할 노드 확인</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system get lease/cilium-l2announce-default-webpod <span class="nt">-o</span> yaml | yq
<span class="c"># =&gt; ...</span>
<span class="c">#    spec:</span>
<span class="c">#      acquireTime: "2025-08-09T12:01:16.067503Z"</span>
<span class="c">#      holderIdentity: k8s-w1</span>
<span class="c">#      leaseDurationSeconds: 15</span>
<span class="c">#      leaseTransitions: 0</span>
<span class="c">#      renewTime: "2025-08-09T12:05:03.883829Z"</span>

<span class="c"># cilium 파드 이름 지정</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD0</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-ctr <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD1</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-w1  <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD2</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-w0  <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$CILIUMPOD0</span> <span class="nv">$CILIUMPOD1</span> <span class="nv">$CILIUMPOD2</span>
<span class="c"># =&gt; cilium-9dp58 cilium-tj7tw cilium-nftrl</span>

<span class="c"># 현재 해당 IP에 대한 리더가 위치한 노드의 cilium-agent 파드 내에서 정보 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nv">$CILIUMPOD0</span> <span class="nt">--</span> cilium-dbg shell <span class="nt">--</span> db/show l2-announce
<span class="c"># =&gt; IP   NetworkInterface</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nv">$CILIUMPOD1</span> <span class="nt">--</span> cilium-dbg shell <span class="nt">--</span> db/show l2-announce
<span class="c"># =&gt; IP               NetworkInterface</span>
<span class="c">#    192.168.10.211   eth1</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 리더 파드가 k8s-w1에 있기 때문에 k8s-w1의 IP와 Network Interface만 나옵니다.&lt;/span&gt;</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nv">$CILIUMPOD2</span> <span class="nt">--</span> cilium-dbg shell <span class="nt">--</span> db/show l2-announce
<span class="c"># =&gt; IP   NetworkInterface</span>

<span class="c"># 로그 확인</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system logs ds/cilium | <span class="nb">grep</span> <span class="s2">"l2"</span>

<span class="c"># router VM : LBIP로 curl 요청 확인</span>
<span class="nv">$ </span>arping <span class="nt">-i</span> eth1 <span class="nv">$LBIP</span> <span class="nt">-c</span> 1000

<span class="nv">$ </span>curl <span class="nt">--connect-timeout</span> 1 <span class="nv">$LBIP</span>
<span class="c"># =&gt; Hostname: webpod-697b545f57-b46tz</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: ::1</span>
<span class="c">#    IP: 172.20.0.131</span>
<span class="c">#    IP: fe80::48ca:7aff:fee8:da55</span>
<span class="c">#    RemoteAddr: 172.20.1.197:44454</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: 192.168.10.211</span>
<span class="c">#    User-Agent: curl/8.5.0</span>
<span class="c">#    Accept: */*</span>

<span class="c"># VIP 에 대한 mac 주소가 리더 노드의 mac 주소와 동일함을 확인</span>
<span class="nv">$ </span>arp <span class="nt">-a</span>
<span class="c"># =&gt; ? (192.168.10.211) at 08:00:27:8e:9b:f8 [ether] on eth1</span>
<span class="c">#    ? (192.168.10.101) at 08:00:27:8e:9b:f8 [ether] on eth1</span>
<span class="c">#    ? (192.168.10.100) at 08:00:27:42:b2:8c [ether] on eth1</span>
<span class="c">#    ...</span>

<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LBIP</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LBIP</span> | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod-697b545f57-24ck5</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LBIP</span> | <span class="nb">grep </span>RemoteAddr
<span class="c"># =&gt; RemoteAddr: 192.168.10.200:57078</span>

<span class="c"># 리더 노드가 아닌 다른 노드에 webpod 통신 시, SNAT 됨 : arp 동작(리더 노드)으로 인한 제약 사항</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 <span class="nv">$LBIP</span> | <span class="nb">grep </span>Hostname<span class="p">;</span> <span class="nb">sleep </span>0.1<span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 <span class="nv">$LBIP</span> | <span class="nb">grep </span>RemoteAddr<span class="p">;</span> <span class="nb">sleep </span>0.1<span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; RemoteAddr: 192.168.10.200:57284</span>
<span class="c">#    RemoteAddr: 192.168.10.200:57294   </span>
<span class="c">#    RemoteAddr: 172.20.1.197:57306   # &lt;span style="color: green;"&gt;👉 leader node인 k8s-w1이 아닌 다른 노드의 파드가 응답한 경우 SNAT으로 인해 다른 IP가 표시됨&lt;/span&gt;</span>
<span class="c">#    RemoteAddr: 172.20.1.197:57310 </span>
<span class="c">#    RemoteAddr: 192.168.10.200:57364</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<h5 id="l2-announcement-리더-노드에-주입-후-failover-확인">L2 Announcement 리더 노드에 주입 후 Failover 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 신규 터미널 (router) : 반복 호출</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 <span class="nv">$LBIP</span> | <span class="nb">grep </span>Hostname<span class="p">;</span> <span class="nb">sleep </span>0.1<span class="p">;</span> <span class="k">done</span>

<span class="c"># 현재 리더 노드 확인</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system get lease | <span class="nb">grep</span> <span class="s2">"cilium-l2announce"</span>
<span class="c"># =&gt; NAME                                   HOLDER                                                                      AGE</span>
<span class="c">#    cilium-l2announce-default-webpod       k8s-w1                                                                      19m</span>

<span class="c"># 리더 노드 강제 reboot</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w1  <span class="nb">sudo </span>reboot
<span class="c"># &lt;span style="color: green;"&gt;👉 리더 노드 재부팅시 curl이 타임아웃 되어 통신이 안 됩니다.&lt;/span&gt;</span>

<span class="c"># 신규 터미널 (router) : arp 변경(갱신) 확인</span>
<span class="nv">$ </span>arp <span class="nt">-a</span>
<span class="c"># =&gt; ? (192.168.10.211) at &lt;span style="color: green;"&gt;08:00:27:42:b2:8c&lt;/span&gt; [ether] on eth1</span>
<span class="c">#    ? (192.168.10.101) at 08:00:27:8e:9b:f8 [ether] on eth1</span>
<span class="c">#    ? (192.168.10.100) at 08:00:27:42:b2:8c [ether] on eth1</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 VIP(192.168.10.211)의 MAC 주소가 k8s-ctr의 eth1로 변경되었습니다.&lt;/span&gt;</span>

<span class="c"># 현재 리더 노드 확인</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system get lease | <span class="nb">grep</span> <span class="s2">"cilium-l2announce"</span>
<span class="c"># =&gt; cilium-l2announce-default-webpod       k8s-ctr                                                                     24m</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 예상대로 k8s-ctr 노드가 리더 노드로 승격되었습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<h3 id="service-lb-ipam-기능">Service LB-IPAM 기능</h3>

<h5 id="service-추가시-동작">Service 추가시 동작</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: netshoot-web
  labels:
    app: netshoot-web
spec:
  replicas: 3
  selector:
    matchLabels:
      app: netshoot-web
  template:
    metadata:
      labels:
        app: netshoot-web
    spec:
      terminationGracePeriodSeconds: 0
      containers:
        - name: netshoot
          image: nicolaka/netshoot
          ports:
            - containerPort: 8080
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
          command: ["sh", "-c"]
          args:
            - |
              while true; do 
                { echo -e "HTTP/1.1 200 OK</span><span class="se">\r\n</span><span class="sh">Content-Type: text/plain</span><span class="se">\r\n\r\n</span><span class="sh">OK from </span><span class="se">\$</span><span class="sh">POD_NAME"; } | nc -l -p 8080 -q 1;
              done
</span><span class="no">EOF
</span><span class="c"># =&gt; deployment.apps/netshoot-web created</span>

<span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Service
metadata:
  name: netshoot-web
  labels:
    app: netshoot-web
spec:
  type: LoadBalancer
  selector:
    app: netshoot-web
  ports:
    - name: http
      port: 80      
      targetPort: 8080
</span><span class="no">EOF
</span><span class="c"># =&gt; service/netshoot-web created</span>

<span class="c"># LB IP 확인</span>
<span class="nv">$ </span>kubectl get svc netshoot-web
<span class="c"># =&gt; NAME           TYPE           CLUSTER-IP      EXTERNAL-IP      PORT(S)        AGE</span>
<span class="c">#    netshoot-web   LoadBalancer   10.96.170.130   &lt;span style="color: green;"&gt;192.168.10.212&lt;/span&gt;   80:30240/TCP   8s</span>

<span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: "cilium.io/v2alpha1"  # not v2
kind: CiliumL2AnnouncementPolicy
metadata:
  name: policy2
spec:
  serviceSelector:
    matchLabels:
      app: netshoot-web
  nodeSelector:
    matchExpressions:
      - key: kubernetes.io/hostname
        operator: NotIn
        values:
          - k8s-w0
  interfaces:
  - ^eth[1-9]+
  externalIPs: true
  loadBalancerIPs: true
</span><span class="no">EOF
</span><span class="c"># =&gt; ciliuml2announcementpolicy.cilium.io/policy2 created</span>

<span class="c"># Service 별로 리더 노드가 다름 : 즉, 외부 인입 시 Service 별로 나름 분산(?) 처리.. </span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system get lease | <span class="nb">grep</span> <span class="s2">"cilium-l2announce"</span>
<span class="c"># =&gt; cilium-l2announce-default-netshoot-web   k8s-w1                                                                      36s</span>
<span class="c">#    cilium-l2announce-default-webpod         k8s-ctr                                                                     116m</span>

<span class="c"># 호출 확인</span>
<span class="c">## LBIP로 curl 요청 확인 : k8s 노드들에서 LB EXIP로 통신 가능!</span>
<span class="nv">$ </span>kubectl get svc netshoot-web <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.loadBalancer.ingress[0].ip}'</span>
<span class="c"># =&gt; 192.168.10.212</span>
<span class="nv">$ LB2IP</span><span class="o">=</span><span class="si">$(</span>kubectl get svc netshoot-web <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.loadBalancer.ingress[0].ip}'</span><span class="si">)</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LB2IP</span>
<span class="c"># =&gt; OK from netshoot-web-5c59d94bd4-jsh8p</span>

<span class="c">## 신규터미널 (router)</span>
<span class="nv">$ LB2IP</span><span class="o">=</span>192.168.10.212
<span class="nv">$ </span>arping <span class="nt">-i</span> eth1 <span class="nv">$LB2IP</span> <span class="nt">-c</span> 2
<span class="c"># =&gt; ARPING 192.168.10.212</span>
<span class="c">#    60 bytes from 08:00:27:8e:9b:f8 (192.168.10.212): index=0 time=452.250 usec</span>
<span class="c">#    60 bytes from 08:00:27:8e:9b:f8 (192.168.10.212): index=1 time=580.375 usec</span>
<span class="c">#    </span>
<span class="c">#    --- 192.168.10.212 statistics ---</span>
<span class="c">#    2 packets transmitted, 2 packets received,   0% unanswered (0 extra)</span>
<span class="c">#    rtt min/avg/max/std-dev = 0.452/0.516/0.580/0.064 ms</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LB2IP</span>
<span class="c"># =&gt; OK from netshoot-web-5c59d94bd4-5zb78</span>
</code></pre></div></div>

<ul>
  <li>특이하게도 Service별로 리더 노드가 다릅니다. 서비스가 여러개인 경우에는 서비스 별로 분산되는 효과가 있어서
리더 노드에 부하가 집중되는 문제가 다소 완화될 것으로 보입니다.</li>
</ul>

<h5 id="requesting-ips">Requesting IPs</h5>

<ul>
  <li>특정 Service의 External IP를 직접 설정할 수 있습니다. <a href="https://docs.cilium.io/en/stable/network/lb-ipam/#loadbalancerclass">Docs</a></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Service netshoot-web 에 EX-IP를 직접 지정 변경</span>
<span class="nv">$ </span>kubectl edit svc netshoot-web 
<span class="c"># 또는 k9s → svc → &lt;e&gt; edit</span>
<span class="nt">---</span>
<span class="c">## metadata.annotations 아래 아래 추가</span>
  annotations:
    <span class="s2">"lbipam.cilium.io/ips"</span>: <span class="s2">"192.168.10.215"</span>
<span class="nt">---</span>
<span class="c"># =&gt; service/netshoot-web edited</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get svc netshoot-web
<span class="c"># =&gt; NAME           TYPE           CLUSTER-IP      EXTERNAL-IP      PORT(S)        AGE</span>
<span class="c">#    netshoot-web   LoadBalancer   10.96.170.130   &lt;span style="color: green;"&gt;192.168.10.215&lt;/span&gt;   80:30240/TCP   9m6s</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 annotation을 통해 지정한 EXTERNAL-IP(192.168.10.215)가 설정되었습니다.&lt;/span&gt;</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get svc netshoot-web <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.loadBalancer.ingress[0].ip}'</span>
<span class="c"># =&gt; 192.168.10.215</span>
<span class="nv">$ LB2IP</span><span class="o">=</span><span class="si">$(</span>kubectl get svc netshoot-web <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.loadBalancer.ingress[0].ip}'</span><span class="si">)</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LB2IP</span>
<span class="c"># =&gt; OK from netshoot-web-5c59d94bd4-5zb78</span>
</code></pre></div></div>

<h5 id="sharing-keys">Sharing Keys</h5>

<ul>
  <li>External IP 1개를 각기 다른 Port를 통해서 사용할 수 있습니다. <a href="https://docs.cilium.io/en/stable/network/lb-ipam/#requesting-ips">Docs</a></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Service
metadata:
  name: netshoot-web2
  labels:
    app: netshoot-web
spec:
  type: LoadBalancer
  selector:
    app: netshoot-web
  ports:
    - name: http
      port: 8080      
      targetPort: 8080
</span><span class="no">EOF
</span><span class="c"># =&gt; service/netshoot-web2 created</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get svc <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>netshoot-web
<span class="c"># =&gt; NAME            TYPE           CLUSTER-IP      EXTERNAL-IP      PORT(S)          AGE</span>
<span class="c">#    netshoot-web    LoadBalancer   10.96.170.130   192.168.10.215   80:30240/TCP     12m</span>
<span class="c">#    netshoot-web2   LoadBalancer   10.96.75.231    192.168.10.212   8080:31278/TCP   14s</span>

<span class="c"># Service netshoot-web에 annotations 추가</span>
<span class="nv">$ </span>kubectl edit svc netshoot-web 
<span class="c"># 또는 k9s → svc → &lt;e&gt; edit</span>
<span class="nt">---</span> 
<span class="c">## metadata.annotations 아래 아래 추가</span>
  annotations:
    <span class="s2">"lbipam.cilium.io/ips"</span>: <span class="s2">"192.168.10.215"</span>
    <span class="s2">"lbipam.cilium.io/sharing-key"</span>: <span class="s2">"1234"</span>
<span class="nt">---</span>
<span class="c"># =&gt; service/netshoot-web edited</span>

<span class="c"># 동일하게 netshoot-web2 서비스에도 annotations 추가</span>
<span class="nv">$ </span>kubectl edit svc netshoot-web2 
<span class="c"># =&gt; service/netshoot-web2 edited</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get svc <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>netshoot-web
<span class="c"># =&gt; NAME            TYPE           CLUSTER-IP      EXTERNAL-IP      PORT(S)          AGE</span>
<span class="c">#    netshoot-web    LoadBalancer   10.96.170.130   192.168.10.215   80:30240/TCP     18m</span>
<span class="c">#    netshoot-web2   LoadBalancer   10.96.75.231    192.168.10.215   8080:31278/TCP   5m36s</span>

<span class="c"># sharing-key 사용되는 IP는 모든 같은 리더 노드 사용</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system get lease | <span class="nb">grep</span> <span class="s2">"cilium-l2announce"</span>
<span class="c"># =&gt; cilium-l2announce-default-netshoot-web    k8s-w1                                                                      17m</span>
<span class="c">#    cilium-l2announce-default-netshoot-web2   k8s-w1                                                                      5m45s</span>
<span class="c">#    cilium-l2announce-default-webpod          k8s-ctr                                                                     133m</span>

<span class="c"># 호출 확인</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LB2IP</span>
<span class="c"># =&gt; OK from netshoot-web-5c59d94bd4-5zb78</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 netshoot-web 서비스 응답&lt;/span&gt;</span>

<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LB2IP</span>:8080
<span class="c"># =&gt; OK from netshoot-web-5c59d94bd4-4fsnp</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 netshoot-web2 서비스 응답&lt;/span&gt;</span>

<span class="c"># 신규터미널 (router)</span>
<span class="nv">$ LB2IP</span><span class="o">=</span>192.168.10.215
<span class="nv">$ </span>arping <span class="nt">-i</span> eth1 <span class="nv">$LB2IP</span> <span class="nt">-c</span> 2
<span class="c"># =&gt; ARPING 192.168.10.215</span>
<span class="c">#    60 bytes from 08:00:27:8e:9b:f8 (192.168.10.215): index=0 time=1.236 msec</span>
<span class="c">#    60 bytes from 08:00:27:8e:9b:f8 (192.168.10.215): index=1 time=372.519 usec</span>
<span class="c">#    </span>
<span class="c">#    --- 192.168.10.215 statistics ---</span>
<span class="c">#    2 packets transmitted, 2 packets received,   0% unanswered (0 extra)</span>
<span class="c">#    rtt min/avg/max/std-dev = 0.373/0.804/1.236/0.432 ms</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LB2IP</span>
<span class="c"># =&gt; OK from netshoot-web-5c59d94bd4-jsh8p</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LB2IP</span>:8080
<span class="c"># =&gt; OK from netshoot-web-5c59d94bd4-5zb78</span>
</code></pre></div></div>

<hr />

<h2 id="마치며">마치며</h2>

<p>이번 포스트에서도 노드의 파드들간 통신에 대해서 알아보았습니다.
가장 관심 있게 본 점은 Cilium의 LoadBalancer IPAM 기능을 통해서 MetalLB (L2 모드)를 대체할 수 있다는 것입니다.
MetalLB라는 추가적인 구성요소 없이 Cilium 만으로 LoadBalancer Service를 구현할 수 있다는 점이 매력적인것 같습니다. :relaxed:</p>

<p>점점 더 Cilium의 매력에 빠져드는것 같습니다. 다음 주에도 Cilium에 대해서 더 알아보도록 하겠습니다. :smile:</p>

<ul>
  <li>약어 소개
    <ul>
      <li><strong>S.IP</strong> : Source IP, 출발지(소스) IP</li>
      <li><strong>D.IP</strong> : Destination IP, 도착치(목적지) IP</li>
      <li><strong>S.Port</strong> : Source Port, 출발지(소스) 포트</li>
      <li><strong>D.Port</strong> : Destination Port, 도착지(목적지) 포트</li>
      <li><strong>NAT</strong> : Network Address Translation, 네트워크 주소 변환</li>
      <li><strong>SNAT</strong> : Source IP 를 NAT 처리, 일반적으로 출발지 IP를 변환</li>
      <li><strong>DNAT</strong> : Destination IP 를 NAT 처리, 일반적으로 목적지 IP와 목적지 포트를 변환</li>
    </ul>
  </li>
</ul>]]></content><author><name></name></author><category term="cilium" /><category term="kubernetes," /><category term="network," /><category term="linux," /><category term="cilium," /><category term="ipam," /><category term="routing," /><category term="masquerading," /><category term="coredns," /><category term="nodelocaldns" /><summary type="html"><![CDATA[이번 포스트에서는 Overlay Network인 VXLAN을 통한 파드간 통신과 Kubernetes 서비스, LB-IPAM 등을 통한 통신을 살펴보겠습니다.]]></summary></entry><entry><title type="html">[Cilium] Networking - 노드의 파드들간 통신 상세 part 1</title><link href="https://sweetlittlebird.github.io/posts/2025-08-03-Cilium-Week3/" rel="alternate" type="text/html" title="[Cilium] Networking - 노드의 파드들간 통신 상세 part 1" /><published>2025-08-03T00:10:18+09:00</published><updated>2025-08-03T00:10:18+09:00</updated><id>https://sweetlittlebird.github.io/posts/Cilium%20-%20Week3</id><content type="html" xml:base="https://sweetlittlebird.github.io/posts/2025-08-03-Cilium-Week3/"><![CDATA[<h2 id="들어가며">들어가며</h2>

<p>이번 포스트에서는 Cilium의 Networking에 대해 살펴보겠습니다. 
Cilium이 어떻게 노드에 있는 파드들 간의 통신을 처리하는지, IP 주소 할당(IPAM), 라우팅, 마스커레이딩, DNS 설정 등을 다룰 것입니다.</p>

<hr />

<h2 id="실습-환경-구성">실습 환경 구성</h2>

<ul>
  <li>이번 실습에서는 다음 그림과 같이 worker 노드를 1대 줄이고, router 노드를 추가해서 실습할 예정입니다.
<img src="/assets/2025/cilium/w3/20250803_cilium_w3_1.png" alt="img.png" class="image-center" />
    <ul>
      <li><strong>가상머신</strong> : k8s-ctr, k8s-w1, router</li>
      <li><strong>router</strong> : 사내망 10.10.0.0/16 대역 통신과 연결, k8s 에 join 되지 않은 서버, loop1/loop2 dump 인터페이스 배치</li>
      <li>Cilium CNI 가 설치된 상태로 배포됩니다.</li>
    </ul>
  </li>
</ul>

<h3 id="실습환경-배포-파일">실습환경 배포 파일</h3>

<ul>
  <li>
    <p><strong>Vagrantfile</strong> : 가상머신 정의, 부팅 시 초기 프로비저닝 설정을 포함하는 Vagrantfile입니다.</p>

    <div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Variables</span>
<span class="no">K8SV</span> <span class="o">=</span> <span class="s1">'1.33.2-1.1'</span> <span class="c1"># Kubernetes Version : apt list -a kubelet, ex) 1.32.5-1.1</span>
<span class="no">CONTAINERDV</span> <span class="o">=</span> <span class="s1">'1.7.27-1'</span> <span class="c1"># Containerd Version : apt list -a containerd.io, ex) 1.6.33-1</span>
<span class="no">CILIUMV</span> <span class="o">=</span> <span class="s1">'1.17.6'</span> <span class="c1"># Cilium CNI Version : https://github.com/cilium/cilium/tags</span>
<span class="no">N</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># max number of worker nodes</span>
  
<span class="c1"># Base Image  https://portal.cloud.hashicorp.com/vagrant/discover/bento/ubuntu-24.04</span>
<span class="no">BOX_IMAGE</span> <span class="o">=</span> <span class="s2">"bento/ubuntu-24.04"</span>
<span class="no">BOX_VERSION</span> <span class="o">=</span> <span class="s2">"202502.21.0"</span>
  
<span class="no">Vagrant</span><span class="p">.</span><span class="nf">configure</span><span class="p">(</span><span class="s2">"2"</span><span class="p">)</span> <span class="k">do</span> <span class="o">|</span><span class="n">config</span><span class="o">|</span>
<span class="c1">#-ControlPlane Node</span>
    <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">define</span> <span class="s2">"k8s-ctr"</span> <span class="k">do</span> <span class="o">|</span><span class="n">subconfig</span><span class="o">|</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="no">BOX_IMAGE</span>
        
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box_version</span> <span class="o">=</span> <span class="no">BOX_VERSION</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provider</span> <span class="s2">"virtualbox"</span> <span class="k">do</span> <span class="o">|</span><span class="n">vb</span><span class="o">|</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--groups"</span><span class="p">,</span> <span class="s2">"/Cilium-Lab"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--nicpromisc2"</span><span class="p">,</span> <span class="s2">"allow-all"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">name</span> <span class="o">=</span> <span class="s2">"k8s-ctr"</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">cpus</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">memory</span> <span class="o">=</span> <span class="mi">2560</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">linked_clone</span> <span class="o">=</span> <span class="kp">true</span>
      <span class="k">end</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">host_name</span> <span class="o">=</span> <span class="s2">"k8s-ctr"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.10.100"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="mi">60000</span><span class="p">,</span> <span class="ss">auto_correct: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">id: </span><span class="s2">"ssh"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">synced_folder</span> <span class="s2">"./"</span><span class="p">,</span> <span class="s2">"/vagrant"</span><span class="p">,</span> <span class="ss">disabled: </span><span class="kp">true</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"init_cfg.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">K8SV</span><span class="p">,</span> <span class="no">CONTAINERDV</span> <span class="p">]</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"k8s-ctr.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">N</span><span class="p">,</span> <span class="no">CILIUMV</span><span class="p">,</span> <span class="no">K8SV</span> <span class="p">]</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"route-add1.sh"</span>
    <span class="k">end</span>
  
<span class="c1">#-Worker Nodes Subnet1</span>
  <span class="p">(</span><span class="mi">1</span><span class="o">..</span><span class="no">N</span><span class="p">).</span><span class="nf">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">i</span><span class="o">|</span>
    <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">define</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span> <span class="k">do</span> <span class="o">|</span><span class="n">subconfig</span><span class="o">|</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="no">BOX_IMAGE</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box_version</span> <span class="o">=</span> <span class="no">BOX_VERSION</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provider</span> <span class="s2">"virtualbox"</span> <span class="k">do</span> <span class="o">|</span><span class="n">vb</span><span class="o">|</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--groups"</span><span class="p">,</span> <span class="s2">"/Cilium-Lab"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--nicpromisc2"</span><span class="p">,</span> <span class="s2">"allow-all"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">name</span> <span class="o">=</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">cpus</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">memory</span> <span class="o">=</span> <span class="mi">1536</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">linked_clone</span> <span class="o">=</span> <span class="kp">true</span>
      <span class="k">end</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">host_name</span> <span class="o">=</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.10.10</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="s2">"6000</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span> <span class="ss">auto_correct: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">id: </span><span class="s2">"ssh"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">synced_folder</span> <span class="s2">"./"</span><span class="p">,</span> <span class="s2">"/vagrant"</span><span class="p">,</span> <span class="ss">disabled: </span><span class="kp">true</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"init_cfg.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">K8SV</span><span class="p">,</span> <span class="no">CONTAINERDV</span><span class="p">]</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"k8s-w.sh"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"route-add1.sh"</span>
    <span class="k">end</span>
  <span class="k">end</span>
  
<span class="c1">#-Router Node</span>
    <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">define</span> <span class="s2">"router"</span> <span class="k">do</span> <span class="o">|</span><span class="n">subconfig</span><span class="o">|</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="no">BOX_IMAGE</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box_version</span> <span class="o">=</span> <span class="no">BOX_VERSION</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provider</span> <span class="s2">"virtualbox"</span> <span class="k">do</span> <span class="o">|</span><span class="n">vb</span><span class="o">|</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--groups"</span><span class="p">,</span> <span class="s2">"/Cilium-Lab"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">name</span> <span class="o">=</span> <span class="s2">"router"</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">cpus</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">memory</span> <span class="o">=</span> <span class="mi">768</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">linked_clone</span> <span class="o">=</span> <span class="kp">true</span>
      <span class="k">end</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">host_name</span> <span class="o">=</span> <span class="s2">"router"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.10.200"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="mi">60009</span><span class="p">,</span> <span class="ss">auto_correct: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">id: </span><span class="s2">"ssh"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">synced_folder</span> <span class="s2">"./"</span><span class="p">,</span> <span class="s2">"/vagrant"</span><span class="p">,</span> <span class="ss">disabled: </span><span class="kp">true</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"router.sh"</span>
    <span class="k">end</span>    
<span class="k">end</span>  
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>init_cfg.sh</strong> : args 참고하여 초기 설정을 수행하는 스크립트입니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config Start &lt;&lt;&lt;&lt;"</span>
  
<span class="nb">echo</span> <span class="s2">"[TASK 1] Setting Profile &amp; Bashrc"</span>
<span class="nb">echo</span> <span class="s1">'alias vi=vim'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s2">"sudo su -"</span> <span class="o">&gt;&gt;</span> /home/vagrant/.bashrc
<span class="nb">ln</span> <span class="nt">-sf</span> /usr/share/zoneinfo/Asia/Seoul /etc/localtime <span class="c"># Change Timezone</span>
  
<span class="nb">echo</span> <span class="s2">"[TASK 2] Disable AppArmor"</span>
systemctl stop ufw <span class="o">&amp;&amp;</span> systemctl disable ufw <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
systemctl stop apparmor <span class="o">&amp;&amp;</span> systemctl disable apparmor <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="nb">echo</span> <span class="s2">"[TASK 3] Disable and turn off SWAP"</span>
swapoff <span class="nt">-a</span> <span class="o">&amp;&amp;</span> <span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'/swap/s/^/#/'</span> /etc/fstab
  
<span class="nb">echo</span> <span class="s2">"[TASK 4] Install Packages"</span>
apt update <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
apt-get <span class="nb">install </span>apt-transport-https ca-certificates curl gpg <span class="nt">-y</span> <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="c"># Download the public signing key for the Kubernetes package repositories.</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> <span class="nt">-m</span> 755 /etc/apt/keyrings
<span class="nv">K8SMMV</span><span class="o">=</span><span class="si">$(</span><span class="nb">echo</span> <span class="nv">$1</span> | <span class="nb">sed</span> <span class="nt">-En</span> <span class="s1">'s/^([0-9]+\.[0-9]+)\..*/\1/p'</span><span class="si">)</span>
curl <span class="nt">-fsSL</span> https://pkgs.k8s.io/core:/stable:/v<span class="nv">$K8SMMV</span>/deb/Release.key | <span class="nb">sudo </span>gpg <span class="nt">--dearmor</span> <span class="nt">-o</span> /etc/apt/keyrings/kubernetes-apt-keyring.gpg
<span class="nb">echo</span> <span class="s2">"deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v</span><span class="nv">$K8SMMV</span><span class="s2">/deb/ /"</span> <span class="o">&gt;&gt;</span> /etc/apt/sources.list.d/kubernetes.list
curl <span class="nt">-fsSL</span> https://download.docker.com/linux/ubuntu/gpg <span class="nt">-o</span> /etc/apt/keyrings/docker.asc
<span class="nb">echo</span> <span class="s2">"deb [arch=</span><span class="si">$(</span>dpkg <span class="nt">--print-architecture</span><span class="si">)</span><span class="s2"> signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu </span><span class="si">$(</span><span class="nb">.</span> /etc/os-release <span class="o">&amp;&amp;</span> <span class="nb">echo</span> <span class="s2">"</span><span class="nv">$VERSION_CODENAME</span><span class="s2">"</span><span class="si">)</span><span class="s2"> stable"</span> | <span class="nb">tee</span> /etc/apt/sources.list.d/docker.list <span class="o">&gt;</span> /dev/null
  
<span class="c"># packets traversing the bridge are processed by iptables for filtering</span>
<span class="nb">echo </span>1 <span class="o">&gt;</span> /proc/sys/net/ipv4/ip_forward
<span class="nb">echo</span> <span class="s2">"net.ipv4.ip_forward = 1"</span> <span class="o">&gt;&gt;</span> /etc/sysctl.d/k8s.conf
  
<span class="c"># enable br_netfilter for iptables </span>
modprobe br_netfilter
modprobe overlay
<span class="nb">echo</span> <span class="s2">"br_netfilter"</span> <span class="o">&gt;&gt;</span> /etc/modules-load.d/k8s.conf
<span class="nb">echo</span> <span class="s2">"overlay"</span> <span class="o">&gt;&gt;</span> /etc/modules-load.d/k8s.conf
  
<span class="nb">echo</span> <span class="s2">"[TASK 5] Install Kubernetes components (kubeadm, kubelet and kubectl)"</span>
<span class="c"># Update the apt package index, install kubelet, kubeadm and kubectl, and pin their version</span>
apt update <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="c"># apt list -a kubelet ; apt list -a containerd.io</span>
apt-get <span class="nb">install</span> <span class="nt">-y</span> <span class="nv">kubelet</span><span class="o">=</span><span class="nv">$1</span> <span class="nv">kubectl</span><span class="o">=</span><span class="nv">$1</span> <span class="nv">kubeadm</span><span class="o">=</span><span class="nv">$1</span> containerd.io<span class="o">=</span><span class="nv">$2</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
apt-mark hold kubelet kubeadm kubectl <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="c"># containerd configure to default and cgroup managed by systemd</span>
containerd config default <span class="o">&gt;</span> /etc/containerd/config.toml
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'s/SystemdCgroup = false/SystemdCgroup = true/g'</span> /etc/containerd/config.toml
  
<span class="c"># avoid WARN&amp;ERRO(default endpoints) when crictl run  </span>
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; /etc/crictl.yaml
runtime-endpoint: unix:///run/containerd/containerd.sock
image-endpoint: unix:///run/containerd/containerd.sock
</span><span class="no">EOF
  
</span><span class="c"># ready to install for k8s </span>
systemctl restart containerd <span class="o">&amp;&amp;</span> systemctl <span class="nb">enable </span>containerd
systemctl <span class="nb">enable</span> <span class="nt">--now</span> kubelet
  
<span class="nb">echo</span> <span class="s2">"[TASK 6] Install Packages &amp; Helm"</span>
<span class="nb">export </span><span class="nv">DEBIAN_FRONTEND</span><span class="o">=</span>noninteractive
apt-get <span class="nb">install</span> <span class="nt">-y</span> bridge-utils sshpass net-tools conntrack ngrep tcpdump ipset arping wireguard jq yq tree bash-completion unzip kubecolor termshark <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
curl <span class="nt">-s</span> https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config End &lt;&lt;&lt;&lt;"</span>
  
</code></pre></div>    </div>
  </li>
  <li><strong>k8s-ctr.sh</strong> : kubeadm init를 통하여 kubernetes controlplane 노드를 설정하고 Cilium CNI 설치, 편리성 설정(k, kc)하는 스크립트입니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Controlplane config Start &lt;&lt;&lt;&lt;"</span>
  
<span class="nb">echo</span> <span class="s2">"[TASK 1] Initial Kubernetes"</span>
curl <span class="nt">--silent</span> <span class="nt">-o</span> /root/kubeadm-init-ctr-config.yaml https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/kubeadm-init-ctr-config.yaml
<span class="nv">K8SMMV</span><span class="o">=</span><span class="si">$(</span><span class="nb">echo</span> <span class="nv">$3</span> | <span class="nb">sed</span> <span class="nt">-En</span> <span class="s1">'s/^([0-9]+\.[0-9]+\.[0-9]+).*/\1/p'</span><span class="si">)</span>
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/K8S_VERSION_PLACEHOLDER/v</span><span class="k">${</span><span class="nv">K8SMMV</span><span class="k">}</span><span class="s2">/g"</span> /root/kubeadm-init-ctr-config.yaml
kubeadm init <span class="nt">--config</span><span class="o">=</span><span class="s2">"/root/kubeadm-init-ctr-config.yaml"</span>  <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="nb">echo</span> <span class="s2">"[TASK 2] Setting kube config file"</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> /root/.kube
<span class="nb">cp</span> <span class="nt">-i</span> /etc/kubernetes/admin.conf /root/.kube/config
<span class="nb">chown</span> <span class="si">$(</span><span class="nb">id</span> <span class="nt">-u</span><span class="si">)</span>:<span class="si">$(</span><span class="nb">id</span> <span class="nt">-g</span><span class="si">)</span> /root/.kube/config
  
<span class="nb">echo</span> <span class="s2">"[TASK 3] Source the completion"</span>
<span class="nb">echo</span> <span class="s1">'source &lt;(kubectl completion bash)'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'source &lt;(kubeadm completion bash)'</span> <span class="o">&gt;&gt;</span> /etc/profile
  
<span class="nb">echo</span> <span class="s2">"[TASK 4] Alias kubectl to k"</span>
<span class="nb">echo</span> <span class="s1">'alias k=kubectl'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'alias kc=kubecolor'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'complete -F __start_kubectl k'</span> <span class="o">&gt;&gt;</span> /etc/profile
  
<span class="nb">echo</span> <span class="s2">"[TASK 5] Install Kubectx &amp; Kubens"</span>
git clone https://github.com/ahmetb/kubectx /opt/kubectx <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">ln</span> <span class="nt">-s</span> /opt/kubectx/kubens /usr/local/bin/kubens
<span class="nb">ln</span> <span class="nt">-s</span> /opt/kubectx/kubectx /usr/local/bin/kubectx
  
<span class="nb">echo</span> <span class="s2">"[TASK 6] Install Kubeps &amp; Setting PS1"</span>
git clone https://github.com/jonmosco/kube-ps1.git /root/kube-ps1 <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="sh">"</span><span class="no">EOT</span><span class="sh">" &gt;&gt; /root/.bash_profile
source /root/kube-ps1/kube-ps1.sh
KUBE_PS1_SYMBOL_ENABLE=true
function get_cluster_short() {
  echo "</span><span class="nv">$1</span><span class="sh">" | cut -d . -f1
}
KUBE_PS1_CLUSTER_FUNCTION=get_cluster_short
KUBE_PS1_SUFFIX=') '
PS1='</span><span class="si">$(</span>kube_ps1<span class="si">)</span><span class="sh">'</span><span class="nv">$PS1</span><span class="sh">
</span><span class="no">EOT
</span>kubectl config rename-context <span class="s2">"kubernetes-admin@kubernetes"</span> <span class="s2">"HomeLab"</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="nb">echo</span> <span class="s2">"[TASK 7] Install Cilium CNI"</span>
<span class="nv">NODEIP</span><span class="o">=</span><span class="si">$(</span>ip <span class="nt">-4</span> addr show eth1 | <span class="nb">grep</span> <span class="nt">-oP</span> <span class="s1">'(?&lt;=inet\s)\d+(\.\d+){3}'</span><span class="si">)</span>
helm repo add cilium https://helm.cilium.io/ <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
helm repo update <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
helm <span class="nb">install </span>cilium cilium/cilium <span class="nt">--version</span> <span class="nv">$2</span> <span class="nt">--namespace</span> kube-system <span class="se">\</span>
<span class="nt">--set</span> <span class="nv">k8sServiceHost</span><span class="o">=</span>192.168.10.100 <span class="nt">--set</span> <span class="nv">k8sServicePort</span><span class="o">=</span>6443 <span class="se">\</span>
<span class="nt">--set</span> ipam.mode<span class="o">=</span><span class="s2">"kubernetes"</span> <span class="nt">--set</span> k8s.requireIPv4PodCIDR<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> <span class="nv">ipv4NativeRoutingCIDR</span><span class="o">=</span>10.244.0.0/16 <span class="se">\</span>
<span class="nt">--set</span> <span class="nv">routingMode</span><span class="o">=</span>native <span class="nt">--set</span> <span class="nv">autoDirectNodeRoutes</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> endpointRoutes.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> <span class="nv">kubeProxyReplacement</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> bpf.masquerade<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> <span class="nv">installNoConntrackIptablesRules</span><span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> endpointHealthChecking.enabled<span class="o">=</span><span class="nb">false</span> <span class="nt">--set</span> <span class="nv">healthChecking</span><span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
<span class="nt">--set</span> hubble.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> hubble.relay.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> hubble.ui.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> hubble.ui.service.type<span class="o">=</span>NodePort <span class="nt">--set</span> hubble.ui.service.nodePort<span class="o">=</span>30003 <span class="se">\</span>
<span class="nt">--set</span> prometheus.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> operator.prometheus.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> hubble.metrics.enableOpenMetrics<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> hubble.metrics.enabled<span class="o">=</span><span class="s2">"{dns,drop,tcp,flow,port-distribution,icmp,httpV2:exemplars=true;labelsContext=source_ip</span><span class="se">\,</span><span class="s2">source_namespace</span><span class="se">\,</span><span class="s2">source_workload</span><span class="se">\,</span><span class="s2">destination_ip</span><span class="se">\,</span><span class="s2">destination_namespace</span><span class="se">\,</span><span class="s2">destination_workload</span><span class="se">\,</span><span class="s2">traffic_direction}"</span> <span class="se">\</span>
<span class="nt">--set</span> operator.replicas<span class="o">=</span>1 <span class="nt">--set</span> debug.enabled<span class="o">=</span><span class="nb">true</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="c">#--set ipam.mode="cluster-pool" --set ipam.operator.clusterPoolIPv4PodCIDRList={"172.20.0.0/16"} --set ipv4NativeRoutingCIDR=172.20.0.0/16 \</span>
  
<span class="nb">echo</span> <span class="s2">"[TASK 8] Install Cilium / Hubble CLI"</span>
<span class="nv">CILIUM_CLI_VERSION</span><span class="o">=</span><span class="si">$(</span>curl <span class="nt">-s</span> https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt<span class="si">)</span>
<span class="nv">CLI_ARCH</span><span class="o">=</span>amd64
<span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span><span class="si">)</span><span class="s2">"</span> <span class="o">=</span> <span class="s2">"aarch64"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then </span><span class="nv">CLI_ARCH</span><span class="o">=</span>arm64<span class="p">;</span> <span class="k">fi
</span>curl <span class="nt">-L</span> <span class="nt">--fail</span> <span class="nt">--remote-name-all</span> https://github.com/cilium/cilium-cli/releases/download/<span class="k">${</span><span class="nv">CILIUM_CLI_VERSION</span><span class="k">}</span>/cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">tar </span>xzvfC cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz /usr/local/bin
<span class="nb">rm </span>cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz
  
<span class="nv">HUBBLE_VERSION</span><span class="o">=</span><span class="si">$(</span>curl <span class="nt">-s</span> https://raw.githubusercontent.com/cilium/hubble/master/stable.txt<span class="si">)</span>
<span class="nv">HUBBLE_ARCH</span><span class="o">=</span>amd64
<span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span><span class="si">)</span><span class="s2">"</span> <span class="o">=</span> <span class="s2">"aarch64"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then </span><span class="nv">HUBBLE_ARCH</span><span class="o">=</span>arm64<span class="p">;</span> <span class="k">fi
</span>curl <span class="nt">-L</span> <span class="nt">--fail</span> <span class="nt">--remote-name-all</span> https://github.com/cilium/hubble/releases/download/<span class="nv">$HUBBLE_VERSION</span>/hubble-linux-<span class="k">${</span><span class="nv">HUBBLE_ARCH</span><span class="k">}</span>.tar.gz <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">tar </span>xzvfC hubble-linux-<span class="k">${</span><span class="nv">HUBBLE_ARCH</span><span class="k">}</span>.tar.gz /usr/local/bin
<span class="nb">rm </span>hubble-linux-<span class="k">${</span><span class="nv">HUBBLE_ARCH</span><span class="k">}</span>.tar.gz
  
<span class="nb">echo</span> <span class="s2">"[TASK 9] Remove node taint"</span>
kubectl taint nodes k8s-ctr node-role.kubernetes.io/control-plane-
  
<span class="nb">echo</span> <span class="s2">"[TASK 10] local DNS with hosts file"</span>
<span class="nb">echo</span> <span class="s2">"192.168.10.100 k8s-ctr"</span> <span class="o">&gt;&gt;</span> /etc/hosts
<span class="k">for</span> <span class="o">((</span> <span class="nv">i</span><span class="o">=</span>1<span class="p">;</span> i&lt;<span class="o">=</span><span class="nv">$1</span><span class="p">;</span> i++  <span class="o">))</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"192.168.10.10</span><span class="nv">$i</span><span class="s2"> k8s-w</span><span class="nv">$i</span><span class="s2">"</span> <span class="o">&gt;&gt;</span> /etc/hosts<span class="p">;</span> <span class="k">done
  
</span><span class="nb">echo</span> <span class="s2">"[TASK 11] Install Prometheus &amp; Grafana"</span>
kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/kubernetes/addons/prometheus/monitoring-example.yaml <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
kubectl patch svc <span class="nt">-n</span> cilium-monitoring prometheus <span class="nt">-p</span> <span class="s1">'{"spec": {"type": "NodePort", "ports": [{"port": 9090, "targetPort": 9090, "nodePort": 30001}]}}'</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
kubectl patch svc <span class="nt">-n</span> cilium-monitoring grafana <span class="nt">-p</span> <span class="s1">'{"spec": {"type": "NodePort", "ports": [{"port": 3000, "targetPort": 3000, "nodePort": 30002}]}}'</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="nb">echo</span> <span class="s2">"[TASK 12] Dynamically provisioning persistent local storage with Kubernetes"</span>
kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.31/deploy/local-path-storage.yaml <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
kubectl patch storageclass local-path <span class="nt">-p</span> <span class="s1">'{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Controlplane Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div>    </div>

    <ul>
      <li>이번 실습에서는 <code class="language-plaintext highlighter-rouge">--set endpointHealthChecking.enabled=false</code> 과 <code class="language-plaintext highlighter-rouge">--set healthChecking=false</code> 옵션을 통해 endpoint health check를 완전히 해제합니다.</li>
      <li>참고로 해당 health check 기능은 비교적 소규모의 클러스터(3~10노드)에만 활성화 하기를 권장하고 있습니다. 대규모의 클러스터에서는 방화벽 정책이나 하이퍼바이저 설정으로 인해 패킷 손실이 발생할 수 있기 때문입니다. - <a href="https://docs.cilium.io/en/stable/operations/performance/scalability/report/">Docs</a></li>
      <li>
        <p><strong>kubeadm-init-ctr-config.yaml</strong></p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  apiVersion: kubeadm.k8s.io/v1beta4
  kind: <span class="k">**</span>InitConfiguration<span class="k">**</span>
  bootstrapTokens:
  - token: <span class="s2">"123456.1234567890123456"</span>
    ttl: <span class="s2">"0s"</span>
    usages:
    - signing
    - authentication
  localAPIEndpoint:
    advertiseAddress: <span class="s2">"192.168.10.100"</span>
  nodeRegistration:
    <span class="k">**</span>kubeletExtraArgs:
      - name: node-ip
        value: <span class="s2">"192.168.10.100"</span><span class="k">**</span>
    criSocket: <span class="s2">"unix:///run/containerd/containerd.sock"</span>
  <span class="nt">---</span>
  apiVersion: kubeadm.k8s.io/v1beta4
  kind: <span class="k">**</span>ClusterConfiguration<span class="k">**</span>
  kubernetesVersion: <span class="s2">"**K8S_VERSION_PLACEHOLDER**"</span>
  networking:
    podSubnet: <span class="s2">"10.244.0.0/16"</span>
    serviceSubnet: <span class="s2">"10.96.0.0/16"</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li><strong>k8s-w.sh</strong> : kubernetes worker 노드 설정, kubeadm join, Cilium CNI 설치 등을 수행하는  스크립트입니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Node config Start &lt;&lt;&lt;&lt;"</span>
  
<span class="nb">echo</span> <span class="s2">"[TASK 1] K8S Controlplane Join"</span>
curl <span class="nt">--silent</span> <span class="nt">-o</span> /root/kubeadm-join-worker-config.yaml https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/2w/kubeadm-join-worker-config.yaml
<span class="nv">NODEIP</span><span class="o">=</span><span class="si">$(</span>ip <span class="nt">-4</span> addr show eth1 | <span class="nb">grep</span> <span class="nt">-oP</span> <span class="s1">'(?&lt;=inet\s)\d+(\.\d+){3}'</span><span class="si">)</span>
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/NODE_IP_PLACEHOLDER/</span><span class="k">${</span><span class="nv">NODEIP</span><span class="k">}</span><span class="s2">/g"</span> /root/kubeadm-join-worker-config.yaml
kubeadm <span class="nb">join</span> <span class="nt">--config</span><span class="o">=</span><span class="s2">"/root/kubeadm-join-worker-config.yaml"</span> <span class="o">&gt;</span> /dev/null 2&gt;&amp;1
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Node config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div>    </div>
    <ul>
      <li>
        <p><strong>kubeadm-join-worker-config.yaml</strong></p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apiVersion: kubeadm.k8s.io/v1beta4
kind: JoinConfiguration
discovery:
  bootstrapToken:
    token: <span class="s2">"123456.1234567890123456"</span>
    apiServerEndpoint: <span class="s2">"192.168.10.100:6443"</span>
    unsafeSkipCAVerification: <span class="nb">true
</span>nodeRegistration:
  criSocket: <span class="s2">"unix:///run/containerd/containerd.sock"</span>
  kubeletExtraArgs:
    - name: node-ip
      value: <span class="s2">"NODE_IP_PLACEHOLDER"</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>route-add1.sh</strong> : k8s node 들이 사내망(?)과 통신을 위한 route 설정 스크립트입니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Route Add Config Start &lt;&lt;&lt;&lt;"</span>
  
<span class="nb">chmod </span>600 /etc/netplan/01-netcfg.yaml
<span class="nb">chmod </span>600 /etc/netplan/50-vagrant.yaml
  
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh">&gt;&gt; /etc/netplan/50-vagrant.yaml
      routes:
      - to: 10.10.0.0/16
        via: 192.168.10.200
</span><span class="no">EOT
  
</span>netplan apply
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Route Add Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>router.sh</strong> : router 역할과 추가적으로 웹서버 역할을 하는 서버의 초기 설정을 담당합니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config Start &lt;&lt;&lt;&lt;"</span>
  
<span class="nb">echo</span> <span class="s2">"[TASK 1] Setting Profile &amp; Bashrc"</span>
<span class="nb">echo</span> <span class="s1">'alias vi=vim'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s2">"sudo su -"</span> <span class="o">&gt;&gt;</span> /home/vagrant/.bashrc
<span class="nb">ln</span> <span class="nt">-sf</span> /usr/share/zoneinfo/Asia/Seoul /etc/localtime
  
<span class="nb">echo</span> <span class="s2">"[TASK 2] Disable AppArmor"</span>
systemctl stop ufw <span class="o">&amp;&amp;</span> systemctl disable ufw <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
systemctl stop apparmor <span class="o">&amp;&amp;</span> systemctl disable apparmor <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="nb">echo</span> <span class="s2">"[TASK 3] Add Kernel setting - IP Forwarding"</span>
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'s/#net.ipv4.ip_forward=1/net.ipv4.ip_forward=1/g'</span> /etc/sysctl.conf
sysctl <span class="nt">-p</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="nb">echo</span> <span class="s2">"[TASK 4] Setting Dummy Interface"</span>
modprobe dummy
ip <span class="nb">link </span>add loop1 <span class="nb">type </span>dummy
ip <span class="nb">link set </span>loop1 up
ip addr add 10.10.1.200/24 dev loop1
  
ip <span class="nb">link </span>add loop2 <span class="nb">type </span>dummy
ip <span class="nb">link set </span>loop2 up
ip addr add 10.10.2.200/24 dev loop2
  
<span class="nb">echo</span> <span class="s2">"[TASK 5] Install Packages"</span>
<span class="nb">export </span><span class="nv">DEBIAN_FRONTEND</span><span class="o">=</span>noninteractive
apt update <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
apt-get <span class="nb">install </span>net-tools jq tree ngrep tcpdump arping <span class="nt">-y</span> <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="nb">echo</span> <span class="s2">"[TASK 6] Install Apache"</span>
apt <span class="nb">install </span>apache2 <span class="nt">-y</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"&lt;h1&gt;Web Server : </span><span class="si">$(</span><span class="nb">hostname</span><span class="si">)</span><span class="s2">&lt;/h1&gt;"</span> <span class="o">&gt;</span> /var/www/html/index.html
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div>    </div>
  </li>
</ul>

<h3 id="실습환경-배포-및-분석-툴-설치">실습환경 배포 및 분석 툴 설치</h3>

<ul>
  <li>
    <p>실습환경 배포</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>vagrant up
<span class="c"># =&gt;     ...</span>
<span class="c">#        router: [TASK 5] Install Packages</span>
<span class="c">#        router: [TASK 6] Install Apache</span>
<span class="c">#        router: &gt;&gt;&gt;&gt; Initial Config End &lt;&lt;&lt;&lt;</span>
</code></pre></div>    </div>
  </li>
  <li><code class="language-plaintext highlighter-rouge">k8s-ctr</code>, cilium 설치정보확인은 지난주의 포스트를 참고해주세요. <a href="https://sweetlittlebird.github.io/posts/2025-07-27-Cilium-Week2/#%EC%8B%A4%EC%8A%B5%ED%99%98%EA%B2%BD-%EB%B0%B0%ED%8F%AC">링크</a></li>
  <li><code class="language-plaintext highlighter-rouge">k9s</code>
    <ul>
      <li>이번 주에는 k9s라는 CLI 기반의 Kubernetes 대시보드 툴을 설치하고 살펴보겠습니다. <a href="https://github.com/derailed/k9s">github</a></li>
      <li>설치 및 실행
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># arm64 CPU 일 경우</span>
<span class="nv">$ </span>wget https://github.com/derailed/k9s/releases/latest/download/k9s_linux_arm64.deb <span class="nt">-O</span> /tmp/k9s_linux_arm64.deb
<span class="nv">$ </span>apt <span class="nb">install</span> /tmp/k9s_linux_arm64.deb
<span class="c"># =&gt; ...</span>
<span class="c">#    Preparing to unpack /tmp/k9s_linux_arm64.deb ...</span>
<span class="c">#    Unpacking k9s (0.50.9) ...</span>
<span class="c">#    Setting up k9s (0.50.9) ...</span>
    
<span class="c"># amd64 CPU 일 경우</span>
<span class="nv">$ </span>wget https://github.com/derailed/k9s/releases/latest/download/k9s_linux_amd64.deb <span class="nt">-O</span> /tmp/k9s_linux_amd64.deb
<span class="nv">$ </span>apt <span class="nb">install</span> /tmp/k9s_linux_amd64.deb
    
<span class="c"># k9s 설치 경로 확인</span>
<span class="nv">$ </span>which k9s
<span class="c"># =&gt; /usr/bin/k9s</span>
    
<span class="c"># k9s 실행</span>
<span class="nv">$ </span>k9s
</code></pre></div>        </div>
      </li>
      <li>실행 화면
<img src="/assets/2025/cilium/w3/20250803_cilium_w3_2.png" alt="img.png" />
터미널이지만 한눈에 보기 쉽게 구성되어 있습니다.</li>
      <li><code class="language-plaintext highlighter-rouge">k9s</code> 기본 사용법
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 버전 확인</span>
<span class="nv">$ </span>k9s version
<span class="c"># =&gt;  ____  __ ________</span>
<span class="c">#    |    |/  /   __   \______</span>
<span class="c">#    |       /\____    /  ___/</span>
<span class="c">#    |    \   \  /    /\___  \</span>
<span class="c">#    |____|\__ \/____//____  /</span>
<span class="c">#             \/           \/</span>
<span class="c">#    Version:    v0.50.9</span>
<span class="c">#    Commit:     ffdc7b70f044e1f26c2f6fbb93b5495e4ebdb1ad</span>
    
<span class="c"># k9s 런타임에 대한 정보</span>
<span class="nv">$ </span>k9s info
<span class="c"># =&gt; ...</span>
<span class="c">#    Version:           v0.50.9</span>
<span class="c">#    Config:            /root/.config/k9s/config.yaml</span>
<span class="c">#    Custom Views:      /root/.config/k9s/views.yaml</span>
<span class="c">#    Plugins:           /root/.config/k9s/plugins.yaml</span>
<span class="c">#    Hotkeys:           /root/.config/k9s/hotkeys.yaml</span>
<span class="c">#    Aliases:           /root/.config/k9s/aliases.yaml</span>
<span class="c">#    Skins:             /root/.config/k9s/skins</span>
<span class="c">#    Context Configs:   /root/.local/share/k9s/clusters</span>
<span class="c">#    Logs:              /root/.local/state/k9s/k9s.log</span>
<span class="c">#    Benchmarks:        /root/.local/state/k9s/benchmarks</span>
<span class="c">#    ScreenDumps:       /root/.local/state/k9s/screen-dumps</span>
    
<span class="c"># CLI의 도움말</span>
<span class="nv">$ </span>k9s <span class="nb">help</span>
    
<span class="c"># 특정 네임스페이스에서 K9s 시작</span>
<span class="nv">$ </span>k9s <span class="nt">-n</span> mycoolns
    
<span class="c"># KubeConfig에 존재하는 컨텍스트로 K9s 시작</span>
<span class="nv">$ </span>k9s <span class="nt">--context</span> coolCtx
    
<span class="c"># K9s를 읽기 전용 모드로 시작 - 클러스터 수정 명령이 비활성화됩니다.</span>
<span class="nv">$ </span>k9s <span class="nt">--readonly</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">termshark</code>
    <ul>
      <li>터미널에서 Wireshark 처럼 패킷을 볼 수 있는 툴입니다. <a href="https://github.com/gcla/termshark">github</a>, <a href="https://termshark.io/">Home</a>
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 이미 설치되어 있음</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">DEBIAN_FRONTEND</span><span class="o">=</span>noninteractive
<span class="nv">$ </span>apt-get <span class="nb">install</span> <span class="nt">-y</span> termshark
<span class="c"># =&gt; Reading package lists... Done</span>
<span class="c">#    Building dependency tree... Done</span>
<span class="c">#    Reading state information... Done</span>
<span class="c">#    termshark is already the newest version (2.4.0-1ubuntu0.24.04.3).</span>
<span class="c">#    0 upgraded, 0 newly installed, 0 to remove and 170 not upgraded.</span>
    
<span class="c"># pcap 파일 분석</span>
<span class="nv">$ </span>termshark <span class="nt">-r</span> test.pcap
    
<span class="c"># eth0 인터페이스에서 ping 패킷을 캡처합니다.</span>
<span class="nv">$ </span>termshark <span class="nt">-i</span> eth0 icmp
</code></pre></div>        </div>
      </li>
      <li>실행 화면
<img src="/assets/2025/cilium/w3/20250803_cilium_w3_3.png" alt="img.png" /></li>
    </ul>
  </li>
</ul>

<hr />

<h2 id="ipam">IPAM</h2>

<ul>
  <li>
    <p>IPAM은 <code class="language-plaintext highlighter-rouge">IP Address Management</code>의 약자로, 네트워크 엔드포인트(컨테이너 등)에 대한 IP 주소를 할당하고 관리하는 시스템입니다. <a href="https://docs.cilium.io/en/stable/network/concepts/ipam/">Docs</a></p>

    <table>
      <thead>
        <tr>
          <th><strong>Feature</strong></th>
          <th><strong>Kubernetes Host Scope</strong></th>
          <th><strong>Cluster Scope (default)</strong></th>
          <th><strong>Multi-Pool (Beta)</strong></th>
          <th><strong>CRD-backed</strong></th>
          <th><strong>AWS ENI…</strong></th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Tunnel routing</td>
          <td>✅</td>
          <td>✅</td>
          <td>❌</td>
          <td>❌</td>
          <td>❌</td>
        </tr>
        <tr>
          <td>Direct routing</td>
          <td>✅</td>
          <td>✅</td>
          <td>✅</td>
          <td>✅</td>
          <td>✅</td>
        </tr>
        <tr>
          <td>CIDR Configuration</td>
          <td>Kubernetes</td>
          <td>Cilium</td>
          <td>Cilium</td>
          <td>External</td>
          <td>External (AWS)</td>
        </tr>
        <tr>
          <td>Multiple CIDRs per cluster</td>
          <td>❌</td>
          <td>✅</td>
          <td>✅</td>
          <td>N/A</td>
          <td>N/A</td>
        </tr>
        <tr>
          <td>Multiple CIDRs per node</td>
          <td>❌</td>
          <td>❌</td>
          <td>✅</td>
          <td>N/A</td>
          <td>N/A</td>
        </tr>
        <tr>
          <td>Dynamic CIDR/IP allocation</td>
          <td>❌</td>
          <td>❌</td>
          <td>✅</td>
          <td>✅</td>
          <td>✅</td>
        </tr>
      </tbody>
    </table>

    <blockquote>
      <p>기존 <strong>클러스터의 IPAM 모드</strong>를 변경하지 마세요.<br />
라이브 환경에서 IPAM 모드를 변경하면 기존 워크로드의 <strong>지속적인 연결 중단</strong>이 발생할 수 있습니다.<br />
IPAM 모드를 변경하는 가장 안전한 방법은 새로운 IPAM 구성으로 새로운 Kubernetes 클러스터를 설치하는 것입니다.</p>
    </blockquote>
  </li>
</ul>

<h3 id="kubernetes-host-scope">Kubernetes Host Scope</h3>

<p><a href="https://docs.cilium.io/en/stable/network/concepts/ipam/kubernetes/">Docs</a></p>

<p><img src="/assets/2025/cilium/w3/20250803_cilium_w3_4.png" alt="img.png" /></p>

<ul>
  <li>Kubernetes 호스트 범위 IPAM 모드는 <code class="language-plaintext highlighter-rouge">ipam: Kubernetes</code>로 활성화되며, 클러스터의 각 개별 노드에 주소 할당을 위임합니다.</li>
  <li>IP는 Kubernetes에 의해 각 노드에 연결된 PodCIDR 범위에서 할당됩니다. 즉, CIDR 설정의 주체는 Kubernetes입니다.</li>
  <li>이 모드에서는 Cilium 에이전트가 <code class="language-plaintext highlighter-rouge">Kubernetes v1.Node</code> 객체를 통해 PodCIDR 범위가 다음 방법 중 하나를 통해 활성화된 모든 주소 패밀리에 대해 제공될때까지 시작시 대기합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 클러스터 정보 확인</span>
<span class="nv">$ </span>kubectl cluster-info dump | <span class="nb">grep</span> <span class="nt">-m</span> 2 <span class="nt">-E</span> <span class="s2">"cluster-cidr|service-cluster-ip-range"</span>
<span class="c"># =&gt;                             "--service-cluster-ip-range=10.96.0.0/16",</span>
<span class="c">#                                "--cluster-cidr=10.244.0.0/16",</span>

<span class="c"># ipam 모드 확인</span>
<span class="nv">$ </span>cilium config view | <span class="nb">grep</span> ^ipam
<span class="c"># =&gt; ipam                                              kubernetes</span>
<span class="c">#    ipam-cilium-node-update-rate                      15s</span>

<span class="c"># 노드별 파드에 할당되는 IPAM(PodCIDR) 정보 확인</span>
<span class="c"># --allocate-node-cidrs=true 로 설정된 kube-controller-manager에서 CIDR을 자동 할당함</span>
<span class="nv">$ </span>kubectl get nodes <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{range .items[*]}{.metadata.name}{"\t"}{.spec.podCIDR}{"\n"}{end}'</span>
<span class="c"># =&gt; k8s-ctr 10.244.0.0/24</span>
<span class="c">#    k8s-w1  10.244.1.0/24</span>

<span class="nv">$ </span>kc describe pod <span class="nt">-n</span> kube-system kube-controller-manager-k8s-ctr
<span class="c"># =&gt; ....</span>
<span class="c">#    Command:</span>
<span class="c">#          kube-controller-manager</span>
<span class="c">#          --allocate-node-cidrs=true</span>
<span class="c">#          --cluster-cidr=10.244.0.0/16</span>
<span class="c">#          --service-cluster-ip-range=10.96.0.0/16</span>
<span class="c">#    ...</span>

<span class="nv">$ </span>kubectl get ciliumnode <span class="nt">-o</span> json | <span class="nb">grep </span>podCIDRs <span class="nt">-A2</span>
<span class="c"># =&gt;                     "podCIDRs": [</span>
<span class="c">#                            "10.244.0.0/24"</span>
<span class="c">#                        ],</span>
<span class="c">#    --</span>
<span class="c">#                        "podCIDRs": [</span>
<span class="c">#                            "10.244.1.0/24"</span>
<span class="c">#                        ],</span>

<span class="c"># 파드 정보 : 상태, 파드 IP 확인</span>
<span class="nv">$ </span>kubectl get ciliumendpoints.cilium.io <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE            NAME                                      SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    cilium-monitoring    grafana-5c69859d9-zgx9k                   22364               ready            10.244.0.5</span>
<span class="c">#    cilium-monitoring    prometheus-6fc896bc5d-5rbpx               15628               ready            10.244.0.143</span>
<span class="c">#    kube-system          coredns-674b8bbfcf-dhckj                  28257               ready            10.244.0.155</span>
<span class="c">#    kube-system          coredns-674b8bbfcf-n4xbw                  28257               ready            10.244.0.7</span>
<span class="c">#    kube-system          hubble-relay-5dcd46f5c-9bcxl              9702                ready            10.244.0.59</span>
<span class="c">#    kube-system          hubble-ui-76d4965bb6-rq9gv                64346               ready            10.244.0.166</span>
<span class="c">#    local-path-storage   local-path-provisioner-74f9666bc9-rrn2r   29718               ready            10.244.0.130</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 현재 모든 파드가 k8s-ctr에서 동작 중이어서 10.244.0.0/24 아이피가 할당된 것을 확인할 수 있습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<h4 id="샘플-애플리케이션-배포-및-확인">샘플 애플리케이션 배포 및 확인</h4>

<ul>
  <li>샘플 애플리케이션을 배포하고 IPAM이 올바르게 작동하는지 확인합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 샘플 애플리케이션 배포</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webpod
spec:
  replicas: 2
  selector:
    matchLabels:
      app: webpod
  template:
    metadata:
      labels:
        app: webpod
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - sample-app
            topologyKey: "kubernetes.io/hostname"
      containers:
      - name: webpod
        image: traefik/whoami
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: webpod
  labels:
    app: webpod
spec:
  selector:
    app: webpod
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
  type: ClusterIP
</span><span class="no">EOF
</span><span class="c"># =&gt; deployment.apps/webpod created</span>
<span class="c">#    service/webpod created</span>

<span class="c"># k8s-ctr 노드에 curl-pod 파드 배포</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: curl-pod
  labels:
    app: curl
spec:
  nodeName: k8s-ctr
  containers:
  - name: curl
    image: nicolaka/netshoot
    command: ["tail"]
    args: ["-f", "/dev/null"]
  terminationGracePeriodSeconds: 0
</span><span class="no">EOF
</span><span class="c"># =&gt; pod/curl-pod created</span>
</code></pre></div></div>

<ul>
  <li>배포 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 배포 확인</span>
<span class="nv">$ </span>kubectl get deploy,svc,ep webpod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                     READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES           SELECTOR</span>
<span class="c">#    deployment.apps/webpod   2/2     2            2           77s   webpod       traefik/whoami   app=webpod</span>
<span class="c">#    </span>
<span class="c">#    NAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE   SELECTOR</span>
<span class="c">#    service/webpod   ClusterIP   10.96.194.47   &lt;none&gt;        80/TCP    77s   app=webpod</span>
<span class="c">#    </span>
<span class="c">#    NAME               ENDPOINTS                       AGE</span>
<span class="c">#    endpoints/webpod   10.244.0.2:80,10.244.1.188:80   77s</span>
<span class="nv">$ </span>kubectl get endpointslices <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>webpod
<span class="c"># =&gt; NAME           ADDRESSTYPE   PORTS   ENDPOINTS                 AGE</span>
<span class="c">#    webpod-j45jt   IPv4          80      10.244.0.2,10.244.1.188   95s</span>
<span class="nv">$ </span>kubectl get ciliumendpoints <span class="c"># IP 확인</span>
<span class="c"># =&gt; NAME                      SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    curl-pod                  1072                ready            10.244.0.188</span>
<span class="c">#    webpod-697b545f57-2zpdp   24748               ready            10.244.0.2</span>
<span class="c">#    webpod-697b545f57-thl79   24748               ready            10.244.1.188</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium-dbg endpoint list

<span class="c"># 통신 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl webpod | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod-697b545f57-2zpdp</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s webpod | grep Hostname; sleep 1; done'</span>
<span class="c"># =&gt; Hostname: webpod-697b545f57-thl79</span>
<span class="c">#    Hostname: webpod-697b545f57-2zpdp</span>
<span class="c">#    Hostname: webpod-697b545f57-thl79</span>
<span class="c">#    Hostname: webpod-697b545f57-thl79</span>
<span class="c">#    Hostname: webpod-697b545f57-2zpdp</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<ul>
  <li>Hubble 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># hubble ui 웹 접속 주소 확인 : default 네임스페이스 확인</span>
<span class="nv">$ NODEIP</span><span class="o">=</span><span class="si">$(</span>ip <span class="nt">-4</span> addr show eth1 | <span class="nb">grep</span> <span class="nt">-oP</span> <span class="s1">'(?&lt;=inet\s)\d+(\.\d+){3}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"http://</span><span class="nv">$NODEIP</span><span class="s2">:30003"</span>
<span class="c"># =&gt; http://192.168.10.100:30003</span>

<span class="c"># hubble relay 포트 포워딩 실행</span>
<span class="nv">$ </span>cilium hubble port-forward&amp;
<span class="c"># =&gt; ℹ️   Hubble Relay is available at 127.0.0.1:4245</span>
<span class="nv">$ </span>hubble status
<span class="c"># =&gt; Healthcheck (via localhost:4245): Ok</span>
<span class="c">#    Current/Max Flows: 5,284/8,190 (64.52%)</span>
<span class="c">#    Flows/s: 33.82</span>
<span class="c">#    Connected Nodes: 2/2</span>

<span class="c"># flow log 모니터링</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--protocol</span> tcp <span class="nt">--to-pod</span> curl-pod
<span class="c"># =&gt; Aug  2 08:36:29.808: default/curl-pod:56772 (ID:1072) &lt;- default/webpod-697b545f57-thl79:80 (ID:24748) to-network FORWARDED (TCP Flags: ACK, FIN)</span>
<span class="c">#    Aug  2 08:36:30.530: default/curl-pod:50248 (ID:1072) &lt;- default/webpod-697b545f57-2zpdp:80 (ID:24748) to-endpoint FORWARDED (TCP Flags: SYN, ACK)</span>
<span class="c">#    Aug  2 08:36:30.533: default/curl-pod:50248 (ID:1072) &lt;- default/webpod-697b545f57-2zpdp:80 (ID:24748) to-endpoint FORWARDED (TCP Flags: ACK, PSH)</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--protocol</span> tcp <span class="nt">--from-pod</span> curl-pod
<span class="c"># =&gt; Aug  2 08:36:57.991: default/curl-pod (ID:1072) &lt;&gt; 10.96.194.47:80 (world) pre-xlate-fwd TRACED (TCP)</span>
<span class="c">#    Aug  2 08:36:57.991: default/curl-pod (ID:1072) &lt;&gt; default/webpod-697b545f57-thl79:80 (ID:24748) post-xlate-fwd TRANSLATED (TCP)</span>
<span class="c">#    Aug  2 08:36:57.991: default/curl-pod:51316 (ID:1072) -&gt; default/webpod-697b545f57-thl79:80 (ID:24748) to-network FORWARDED (TCP Flags: SYN)</span>
<span class="c">#    Aug  2 08:36:57.992: default/curl-pod:51316 (ID:1072) -&gt; default/webpod-697b545f57-thl79:80 (ID:24748) to-network FORWARDED (TCP Flags: ACK, PSH)</span>
<span class="c">#    Aug  2 08:36:57.993: default/curl-pod:51316 (ID:1072) -&gt; default/webpod-697b545f57-thl79:80 (ID:24748) to-network FORWARDED (TCP Flags: ACK)</span>
<span class="c">#    Aug  2 08:36:57.999: default/curl-pod:51316 (ID:1072) -&gt; default/webpod-697b545f57-thl79:80 (ID:24748) to-network FORWARDED (TCP Flags: ACK, FIN)</span>
<span class="c">#    Aug  2 08:36:57.999: default/curl-pod:51316 (ID:1072) -&gt; default/webpod-697b545f57-thl79:80 (ID:24748) to-network FORWARDED (TCP Flags: ACK)</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--protocol</span> tcp <span class="nt">--pod</span> curl-pod
<span class="c"># =&gt; Aug  2 08:37:22.316: default/curl-pod (ID:1072) &lt;&gt; 10.96.194.47:80 (world) pre-xlate-fwd TRACED (TCP)</span>
<span class="c">#    Aug  2 08:37:22.316: default/curl-pod (ID:1072) &lt;&gt; default/webpod-697b545f57-2zpdp:80 (ID:24748) post-xlate-fwd TRANSLATED (TCP)</span>
<span class="c">#    Aug  2 08:37:22.317: default/curl-pod:51022 (ID:1072) -&gt; default/webpod-697b545f57-2zpdp:80 (ID:24748) to-endpoint FORWARDED (TCP Flags: SYN)</span>
<span class="c">#    Aug  2 08:37:22.317: default/curl-pod:51022 (ID:1072) &lt;- default/webpod-697b545f57-2zpdp:80 (ID:24748) to-endpoint FORWARDED (TCP Flags: SYN, ACK)</span>
<span class="c">#    Aug  2 08:37:22.317: default/curl-pod:51022 (ID:1072) -&gt; default/webpod-697b545f57-2zpdp:80 (ID:24748) to-endpoint FORWARDED (TCP Flags: ACK)</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 pre-xlate-fwd, TRACED : NAT (IP 변환) 전, 추적 중인 flow&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   post-xlate-fwd, TRANSLATED : NAT 후의 흐름, NAT 변환이 일어났음&lt;/span&gt;</span>

<span class="c"># 호출 시도</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl webpod | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod-697b545f57-2zpdp</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl webpod | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod-697b545f57-thl79</span>
<span class="c"># 혹은</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s webpod | grep Hostname; sleep 1; done'</span>

<span class="c"># tcpdump 확인 : 파드 IP 확인</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> eth1 tcp port 80 <span class="nt">-nn</span>
<span class="c"># =&gt; 20:11:41.085067 IP 10.244.0.188.56954 &gt; 10.244.1.188.80: Flags [P.], seq 1:71, ack 1, win 502, options [nop,nop,TS val 2064675417 ecr 2283779636], length 70: HTTP: GET / HTTP/1.1</span>

<span class="c"># http 패킷 캡처</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> eth1 tcp port 80 <span class="nt">-w</span> /tmp/http.pcap

<span class="c"># termshark로 pcap 파일 분석</span>
<span class="nv">$ </span>termshark <span class="nt">-r</span> /tmp/http.pcap
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w3/20250803_cilium_w3_5.png" alt="img.png" class="image-center" />
<em class="image-caption">hubble UI에서 확인한 흐름 정보</em></p>

<p><img src="/assets/2025/cilium/w3/20250803_cilium_w3_6.png" alt="img_1.png" class="image-center" />
<em class="image-caption">termshark에서 확인한 패킷 정보</em></p>

<h3 id="cilium-cluster-scope">[Cilium] Cluster Scope</h3>

<p><a href="https://docs.cilium.io/en/stable/network/concepts/ipam/cluster-pool/">Docs</a>, <a href="https://docs.cilium.io/en/stable/network/kubernetes/ipam-cluster-pool/">IPAM</a></p>

<p><img src="/assets/2025/cilium/w3/20250803_cilium_w3_7.png" alt="img.png" /></p>

<ul>
  <li>각 노드에 노드별 PodCIDR 범위가 할당되며, 각 노드의 호스트 범위 할당기를 사용하여 IP를 할당합니다.</li>
  <li>이 모드는 Kubernetes Host Scope IPAM 모드와 유사하지만, Cilium이 <code class="language-plaintext highlighter-rouge">v2.CiliumNode</code>라는 리소스(CRD)를 통해 노드별 PodCIDR 범위를 관리하는 점이 다릅니다.</li>
  <li>장점은 Kubernetes가 노드별 PodCIDR 범위를 관리하지 않기 때문에, Cilium이 노드별 PodCIDR 범위를 동적으로 할당할 수 있습니다.</li>
  <li>최소 마스크 길이는 /30이며, 권장 최소 마스크 길이는 /29 이상입니다. 2개 주소는 예약되어 있습니다. (네트워크, 브로드캐스트 주소)</li>
  <li>기본 pod CIDR은 <code class="language-plaintext highlighter-rouge">10.0.0.0/8</code>입니다.</li>
</ul>

<h4 id="ipam-모드를-cluster-scope로-변경">IPAM 모드를 Cluster Scope로 변경</h4>

<blockquote>
  <p>앞서 언급한것 처럼 라이브 환경에서 IPAM 모드를 변경하지 마세요.</p>
</blockquote>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 반복 요청 해두기</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s webpod | grep Hostname; sleep 1; done'</span>

<span class="c"># Cluster Scopre 로 설정 변경</span>
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--namespace</span> kube-system <span class="nt">--reuse-values</span> <span class="se">\</span>
  <span class="nt">--set</span> ipam.mode<span class="o">=</span><span class="s2">"cluster-pool"</span> <span class="nt">--set</span> ipam.operator.clusterPoolIPv4PodCIDRList<span class="o">={</span><span class="s2">"172.20.0.0/16"</span><span class="o">}</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">ipv4NativeRoutingCIDR</span><span class="o">=</span>172.20.0.0/16

<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system rollout restart deploy/cilium-operator <span class="c"># 오퍼레이터 재시작 필요</span>
<span class="c"># =&gt; deployment.apps/cilium-operator restarted</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system rollout restart ds/cilium
<span class="c"># =&gt; daemonset.apps/cilium restarted</span>

<span class="c"># 변경 확인</span>
<span class="nv">$ </span>kubectl get nodes <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{range .items[*]}{.metadata.name}{"\t"}{.spec.podCIDR}{"\n"}{end}'</span>
<span class="c"># =&gt; k8s-ctr 10.244.0.0/24</span>
<span class="c">#    k8s-w1  10.244.1.0/24</span>
<span class="nv">$ </span>cilium config view | <span class="nb">grep</span> ^ipam
<span class="c"># =&gt; ipam                                              cluster-pool</span>
<span class="c">#    ipam-cilium-node-update-rate                      15s</span>

<span class="nv">$ </span>kubectl get ciliumnode <span class="nt">-o</span> json | <span class="nb">grep </span>podCIDRs <span class="nt">-A2</span>
<span class="c"># =&gt;                     "podCIDRs": [</span>
<span class="c">#                            "10.244.0.0/24"</span>
<span class="c">#                        ],</span>
<span class="c">#    --</span>
<span class="c">#                        "podCIDRs": [</span>
<span class="c">#                            "10.244.1.0/24"</span>
<span class="c">#                        ],</span>
<span class="nv">$ </span>kubectl get ciliumendpoints.cilium.io <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE            NAME                                      SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    cilium-monitoring    grafana-5c69859d9-zgx9k                   22364               ready            10.244.0.5</span>
<span class="c">#    cilium-monitoring    prometheus-6fc896bc5d-5rbpx               15628               ready            10.244.0.143</span>
<span class="c">#    default              curl-pod                                  1072                ready            10.244.0.188</span>
<span class="c">#    default              webpod-697b545f57-2zpdp                   24748               ready            10.244.0.2</span>
<span class="c">#    default              webpod-697b545f57-thl79                   24748               ready            10.244.1.188</span>
<span class="c">#    kube-system          coredns-674b8bbfcf-dhckj                  28257               ready            10.244.0.155</span>
<span class="c">#    kube-system          coredns-674b8bbfcf-n4xbw                  28257               ready            10.244.0.7</span>
<span class="c">#    local-path-storage   local-path-provisioner-74f9666bc9-rrn2r   29718               ready            10.244.0.130</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 IPAM 모드는 변경되었으나 podCIDR을 비롯한 IP는 아직 변경되지 않았습니다.&lt;/span&gt;</span>

<span class="c"># IPAM 모드 변경 후, 반영을 위해 Cilium 노드 리소스를 삭제하고 데몬셋을 재시작합니다.</span>
<span class="nv">$ </span>kubectl delete ciliumnode k8s-w1
<span class="c"># =&gt; ciliumnode.cilium.io "k8s-w1" deleted</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system rollout restart ds/cilium
<span class="c"># =&gt; daemonset.apps/cilium restarted</span>
<span class="nv">$ </span>kubectl get ciliumnode <span class="nt">-o</span> json | <span class="nb">grep </span>podCIDRs <span class="nt">-A2</span>
<span class="c"># =&gt;                     "podCIDRs": [</span>
<span class="c">#                            "10.244.0.0/24"</span>
<span class="c">#                        ],</span>
<span class="c">#    --</span>
<span class="c">#                        "podCIDRs": [</span>
<span class="c">#                            "172.20.0.0/24"</span>
<span class="c">#                        ],</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s-w1의 podCIDR이 변경되었습니다.&lt;/span&gt;</span>
<span class="nv">$ </span>kubectl get ciliumendpoints.cilium.io <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE            NAME                                      SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    cilium-monitoring    grafana-5c69859d9-zgx9k                   22364               ready            10.244.0.5</span>
<span class="c">#    cilium-monitoring    prometheus-6fc896bc5d-5rbpx               15628               ready            10.244.0.143</span>
<span class="c">#    default              curl-pod                                  1072                ready            10.244.0.188</span>
<span class="c">#    default              webpod-697b545f57-2zpdp                   24748               ready            10.244.0.2</span>
<span class="c">#    kube-system          coredns-674b8bbfcf-dhckj                  28257               ready            10.244.0.155</span>
<span class="c">#    kube-system          coredns-674b8bbfcf-n4xbw                  28257               ready            10.244.0.7</span>
<span class="c">#    kube-system          hubble-relay-5b48c999f9-qktv5             9702                ready            172.20.0.167</span>
<span class="c">#    kube-system          hubble-ui-655f947f96-ts4n6                64346               ready            172.20.0.122</span>
<span class="c">#    local-path-storage   local-path-provisioner-74f9666bc9-rrn2r   29718               ready            10.244.0.130</span>

<span class="c"># 마찬가지로 k8s-ctr 노드의 podCIDR도 변경합니다.</span>
<span class="nv">$ </span>kubectl delete ciliumnode k8s-ctr
<span class="c"># =&gt; ciliumnode.cilium.io "k8s-ctr" deleted</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system rollout restart ds/cilium
<span class="c"># =&gt; daemonset.apps/cilium restarted</span>
<span class="nv">$ </span>kubectl get ciliumnode <span class="nt">-o</span> json | <span class="nb">grep </span>podCIDRs <span class="nt">-A2</span>
<span class="c"># =&gt;                     "podCIDRs": [</span>
<span class="c">#                            "172.20.1.0/24"</span>
<span class="c">#                        ],</span>
<span class="c">#    --</span>
<span class="c">#                        "podCIDRs": [</span>
<span class="c">#                            "172.20.0.0/24"</span>
<span class="c">#                        ],</span>
<span class="nv">$ </span>kubectl get ciliumendpoints.cilium.io <span class="nt">-A</span> <span class="c"># 파드 IP 변경 되는가?</span>
<span class="c"># =&gt; NAMESPACE     NAME                            SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-tg9ll        28257               ready            172.20.0.56</span>
<span class="c">#    kube-system   hubble-relay-5b48c999f9-qktv5   9702                ready            172.20.0.167</span>
<span class="c">#    kube-system   hubble-ui-655f947f96-ts4n6      64346               ready            172.20.0.122</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 변경되었습니다.&lt;/span&gt;</span>

<span class="c"># 노드의 podcidr static routing 자동 변경 적용 확인</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route
<span class="c"># =&gt; ...</span>
<span class="c">#    &lt;span style="color: green;"&gt;172.20.1.113 dev lxc781feae60918&lt;/span&gt; proto kernel scope link</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w1 ip <span class="nt">-c</span> route
<span class="c"># =&gt; ...</span>
<span class="c">#    &lt;span style="color: green;"&gt;172.20.0.56 dev lxc1bf5de6d4ec4&lt;/span&gt; proto kernel scope link</span>
<span class="c">#    &lt;span style="color: green;"&gt;172.20.0.122 dev lxcb644cb2f80be&lt;/span&gt; proto kernel scope link</span>
<span class="c">#    &lt;span style="color: green;"&gt;172.20.0.167 dev lxc9c5d083a0332&lt;/span&gt; proto kernel scope link</span>

<span class="c"># 직접 rollout restart 하자! </span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-A</span> <span class="nt">-owide</span> | <span class="nb">grep </span>10.244.
<span class="c"># =&gt; cilium-monitoring    grafana-5c69859d9-zgx9k                   0/1     Running   1 (4h58m ago)   20h     10.244.0.5       k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    cilium-monitoring    prometheus-6fc896bc5d-5rbpx               1/1     Running   1 (4h58m ago)   20h     10.244.0.143     k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    default              curl-pod                                  1/1     Running   0               4h18m   10.244.0.188     k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    default              webpod-697b545f57-2zpdp                   1/1     Running   0               4h18m   10.244.0.2       k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    default              webpod-697b545f57-thl79                   1/1     Running   0               4h18m   10.244.1.188     k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    local-path-storage   local-path-provisioner-74f9666bc9-rrn2r   1/1     Running   1 (4h58m ago)   20h     10.244.0.130     k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 아직 변경되지 않은 pod들이 남아있어서 재시작하겠습니다.&lt;/span&gt;</span>

<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system rollout restart deploy/hubble-relay deploy/hubble-ui
<span class="c"># =&gt; deployment.apps/hubble-relay restarted</span>
<span class="c">#    deployment.apps/hubble-ui restarted</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> cilium-monitoring rollout restart deploy/prometheus deploy/grafana
<span class="c"># =&gt; deployment.apps/prometheus restarted</span>
<span class="c">#    deployment.apps/grafana restarted</span>
<span class="nv">$ </span>kubectl rollout restart deploy/webpod
<span class="c"># =&gt; deployment.apps/webpod restarted</span>

<span class="c">#</span>
<span class="nv">$ </span>cilium hubble port-forward&amp;
<span class="c"># =&gt; ℹ️ Hubble Relay is available at 127.0.0.1:4245</span>

<span class="c"># curl-pod는 파드만 수동으로 배포한것이라 삭제하고 다시 만들겠습니다.</span>
<span class="nv">$ </span>kubectl delete pod curl-pod
<span class="c"># =&gt; pod "curl-pod" deleted</span>
<span class="c"># k8s-ctr 노드에 curl-pod 파드 배포</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: curl-pod
  labels:
    app: curl
spec:
  nodeName: k8s-ctr
  containers:
  - name: curl
    image: nicolaka/netshoot
    command: ["tail"]
    args: ["-f", "/dev/null"]
  terminationGracePeriodSeconds: 0
</span><span class="no">EOF
</span><span class="c"># =&gt; pod/curl-pod created</span>

<span class="c"># 파드 IP 변경 확인!</span>
<span class="nv">$ </span>kubectl get ciliumendpoints.cilium.io <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE           NAME                            SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    cilium-monitoring   grafana-74f45ff4b-8s8jk         22364               ready            172.20.0.129</span>
<span class="c">#    cilium-monitoring   prometheus-5cd9888b5c-nq2jh     15628               ready            172.20.0.22</span>
<span class="c">#    default             curl-pod                        1072                ready            172.20.1.80</span>
<span class="c">#    default             webpod-bb8b9557f-7rn8t          24748               ready            172.20.0.130</span>
<span class="c">#    default             webpod-bb8b9557f-9tzvj          24748               ready            172.20.1.31</span>
<span class="c">#    kube-system         coredns-674b8bbfcf-58c7n        28257               ready            172.20.1.113</span>
<span class="c">#    kube-system         coredns-674b8bbfcf-tg9ll        28257               ready            172.20.0.56</span>
<span class="c">#    kube-system         hubble-relay-575fc84f49-m7bkm   9702                ready            172.20.0.177</span>
<span class="c">#    kube-system         hubble-ui-5b686f8966-cnqxd      64346               ready            172.20.0.244</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 모든 파드의 IP가 변경되었습니다.&lt;/span&gt;</span>

<span class="c"># 반복 요청</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s webpod | grep Hostname; sleep 1; done'</span>
</code></pre></div></div>

<ul>
  <li>이렇듯 IPAM 모드를 변경해도 이미 배포된 파드들은 IP가 변경되지 않기 때문에 운영중인 클러스터에서 IPAM 모드를 변경하는 것은 권장하지 않습니다. <br />
새로운 IPAM 모드로 새로운 클러스터를 설치하고, 기존 클러스터에서 워크로드를 이전하는 것이 가장 안전한 방법입니다.</li>
</ul>

<h3 id="cilium-cni-chaining-aws-vpc-cni-plugin">[Cilium CNI Chaining] AWS VPC CNI plugin</h3>

<p><a href="https://docs.cilium.io/en/stable/installation/cni-chaining-aws-cni/">Docs</a></p>

<p><img src="/assets/2025/cilium/w3/20250803_cilium_w3_8.png" alt="img.png" /></p>

<ul>
  <li>이번에 알아볼 것은 Cilium을 AWS VPC CNI 플러그인과 함께 사용하는 방법입니다.</li>
  <li>이 하이브리드 모드에서는 AWS VPC CNI 플러그인이 가상 네트워크 장치 설정뿐만 아니라 ENI를 통한 IP 주소 관리(IPAM)도 담당합니다.</li>
  <li>주어진 pod에 대해 초기 네트워킹이 설정된 후, Cilium CNI 플러그인은 네트워크 정책을 시행하고 로드밸런싱을 수행하며 암호화를 제공하기 위해 AWS VPC CNI 플러그인이 설정한 네트워크 장치에 eBPF 프로그램을 연결하도록 호출합니다.</li>
</ul>

<p><img src="/assets/2025/cilium/w3/20250803_cilium_w3_9.png" alt="img.png" /></p>

<ul>
  <li><strong>AWS-CNI 역할</strong> : Device plumbing, IPAM(ENI), Routing(Native-Routing 등)</li>
  <li><strong>Cilium 역할</strong> : LB, Network Policy, Encrption, Multi-Cluster, Visiblity</li>
  <li><strong>설정</strong>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>helm <span class="nb">install </span>cilium cilium/cilium <span class="nt">--version</span> 1.17.6 <span class="se">\</span>
  <span class="nt">--namespace</span> kube-system <span class="se">\</span>
  <span class="nt">--set</span> cni.chainingMode<span class="o">=</span>aws-cni <span class="se">\</span>
  <span class="nt">--set</span> cni.exclusive<span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">enableIPv4Masquerade</span><span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">routingMode</span><span class="o">=</span>native
</code></pre></div>    </div>
  </li>
  <li>AWS ENI IPAM 모드 
<a href="https://docs.cilium.io/en/stable/network/concepts/ipam/eni/">Docs</a>
<img src="/assets/2025/cilium/w3/20250803_cilium_w3_10.png" alt="img.png" /></li>
  <li>AWS ENI 할당기는 AWS 클라우드에서 수행되는 Cilium 배포에 특화되어있으며, AWS EC2 API와 통신하여 AWS Elastic Network Interface(ENI)의 IP를 기반으로 IP 를 할당합니다.</li>
  <li>이 모드는 대규모 클러스터에서의 속도 제한 문제를 해결하기 위해 단일 운영자만 EC2 서비스 API와 통신할 수 있도록 보장합니다.</li>
  <li>사전 할당 워터마크는 클러스터에서 새 pod가 예약될때 EC2 API를 호출할 필요없이 노드에서 항상 사용할 수 있도록 여러 IP 주소를 유지하는데 사용됩니다.</li>
</ul>

<hr />

<h2 id="routing">Routing</h2>

<ul>
  <li>Cilium은 Encapsulation과 Native Routing을 지원합니다. 각각에 대해 살펴 보겠습니다.</li>
</ul>

<h3 id="method-1-encapsulation-vxlan-geneve">Method 1. Encapsulation (VXLAN, GENEVE)</h3>

<p><a href="https://docs.cilium.io/en/stable/network/concepts/routing/">Docs</a></p>

<ul>
  <li>Encapsulation 모드는 특별한 인프라 요구사항이 없기 때문에 Cilium은 기본적으로 Encapsulation 모드를 사용합니다.</li>
  <li>이 모드에서는 모든 클러스터 노드가 UDP 기반의 VXLAN 또는 GENEVE를 사용하여 터널링을 통해 서로 통신합니다.</li>
  <li>Cilium 노드간의 모든 트래픽이 캡슐화 됩니다.</li>
  <li>그리고 캡슐화는 일반 노드간 연결에 의존합니다. 즉, Cilium 노드가 이미 서로 연결될 수 있다면 Encapsulation 모드를 사용할 수 있다는 이야기 입니다.</li>
  <li>기본 네트워크는 IPv4를 지원해야 하며, 다음의 UDP 포트를 방화벽에서 허용해야 합니다.
    <ul>
      <li>VXLAN (Defaut) : UDP 8472</li>
      <li>GENEVE : UDP 6081</li>
    </ul>
  </li>
  <li>장점
    <ul>
      <li><strong>단순함</strong> (Simplicity)
        <ul>
          <li>
            <ul>
              <li>클러스터 노드를 연결하는 네트워크는 PodCIDR을 인식할 필요가 없습니다.</li>
            </ul>
          </li>
          <li>클러스터 노드는 여러 라우팅 또는 링크 계층 도메인을 생성할 수 있습니다.</li>
          <li>클러스터 노드가 IP/UDP를 사용하여 서로 연결할 수 있는 한 기본 네트워크의 토폴로지는 중요하지 않습니다.</li>
        </ul>
      </li>
      <li><strong>정체성 맥락</strong> (Identity context)
        <ul>
          <li>캡슐화 프로토콜은 네트워크 패킷과 함께 메타데이터를 전송할 수 있게 해줍니다.</li>
          <li>Cilium은 소스 보안 ID와 같은 메타데이터를 전송하는 이 기능을 활용합니다.</li>
          <li>정체성 전달은 원격 노드에서 하나의 정체성 조회를 피하기 위해 설계된 최적화입니다.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>단점
    <ul>
      <li><strong>MTU Overhead</strong>
        <ul>
          <li>캡슐화 헤더가 추가됨에 의해서 페이로드에 사용할 수 있는 유효 MTU가 줄어듭니다. (VXLAN의 경우 50바이트, GENEVE의 경우 60바이트)</li>
          <li>이로 인해 특정 네트워크 연결에 대한 최대 처리량이 낮아집니다.</li>
          <li>점보 프레임(Jumbo Frame)을 사용하여 MTU를 늘려 해당 문제를 크게 완화할 수 있지만, 모든 네트워크 장치가 점보 프레임을 지원하지는 않습니다.</li>
        </ul>
      </li>
      <li><strong>Encapsulation/Decapsulation Overhead</strong>
        <ul>
          <li>캡슐화 및 디캡슐화는 CPU 오버헤드를 발생시킵니다.</li>
          <li>이 오버헤드는 일반적으로 네트워크 대역폭에 비해 작지만, 대규모 클러스터에서는 성능에 영향을 미칠 수 있습니다.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>설정방법
    <ul>
      <li><code class="language-plaintext highlighter-rouge">tunnel-protocol</code> : Encapsulation 프로토콜을 <code class="language-plaintext highlighter-rouge">vxlan</code>이나 <code class="language-plaintext highlighter-rouge">geneve</code>로 설정합니다. (기본값: vxlan)</li>
      <li><code class="language-plaintext highlighter-rouge">tunnel-port</code> : Encapsulation 프로토콜을 위한 UDP 포트를 설정합니다. vxlan의 경우 8472, geneve의 경우 6081입니다. (기본값: 8472)</li>
    </ul>
  </li>
</ul>

<h3 id="method-2-native-routing">Method 2. Native Routing</h3>

<p><a href="https://docs.cilium.io/en/stable/network/concepts/routing/#native-routing">Docs</a></p>

<p><img src="/assets/2025/cilium/w3/20250803_cilium_w3_11.png" alt="img.png" /></p>

<ul>
  <li>Native Routing 모드는 Cilium이 캡슐화 없이 Pod 간에 직접 통신할 수 있도록 합니다.</li>
  <li>캡슐화를 수행하는 대신 Cilium이 실행되는 네트워크의 라우팅 기능을 활용합니다.</li>
  <li>Native Routing 모드에서는 Cilium이 다른 로컬 엔드포인트로 주소를 지정하지 않은 모든 패킷을 Linux 커널 라우팅 하위 시스템에 위임합니다.</li>
  <li>이는 패킷이 로컬 프로세스가 패킷을 방출하는 것 처럼 라우팅 된다는것을 의미합니다.</li>
  <li>따라서 클러스터 노드를 연결하는 네트워크가 PodCIDR을 인식하고, PodCIDR를 라우팅하는 설정되어 있어야 합니다.</li>
  <li>PodCIDR 라우팅 방안 1
    <ul>
      <li>각 개별 노드는 다른 모든 노드의 모든 포드 IP를 인식하고 이를 표현하기 위해 Linux 커널 라우팅 테이블에 삽입합니다.</li>
      <li>모든 노드가 단일 L2 네트워크를 공유하는 경우 <code class="language-plaintext highlighter-rouge">auto-direct-node-routes: true</code>하여 이 문제를 해결할 수 있습니다.</li>
      <li>그렇지 않으면 <strong>BGP</strong> 데몬과 같은 추가 시스템 구성 요소를 실행하여 경로를 배포해야 합니다.</li>
    </ul>
  </li>
  <li>PodCIDR 라우팅 방안 2
    <ul>
      <li>노드 자체는 모든 포드 IP를 라우팅하는 방법을 모르지만 다른 모든 포드에 도달하는 방법을 아는 라우터가 네트워크에 존재합니다.</li>
      <li>이 시나리오에서는 Linux 노드가 이러한 라우터를 가리키는 기본 경로를 포함하도록 구성됩니다.</li>
      <li>이 모델은 클라우드 제공자 네트워크 통합에 사용됩니다. 자세한 내용은 <a href="https://docs.cilium.io/en/stable/network/concepts/routing/#google-cloud">Google Cloud</a>, <a href="https://docs.cilium.io/en/stable/network/concepts/routing/#aws-eni">AWS ENI</a> 및 Azure IPAM을 참조하세요.</li>
    </ul>
  </li>
  <li>설정방법
    <ul>
      <li><code class="language-plaintext highlighter-rouge">routing-mode: native</code>: Native Routing 모드를 활성화합니다.</li>
      <li><code class="language-plaintext highlighter-rouge">ipv4-native-routing-cidr: x.x.x.x/y</code>: Native Routing 모드에서 PodCIDR를 라우팅하는 CIDR을 설정합니다.</li>
      <li><code class="language-plaintext highlighter-rouge">auto-direct-node-routes: true</code> : 동일 L2 네트워크 공유 시, 걱 노드의 PodCIDR에 대한 Linux 커널 라우팅 테이블에 삽입합니다.</li>
    </ul>
  </li>
  <li>Native Roung 실습을 위한 Cilium Agent 단축키 지정
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># cilium 파드 이름</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD0</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-ctr <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD1</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-w1  <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$CILIUMPOD0</span> <span class="nv">$CILIUMPOD1</span> <span class="nv">$CILIUMPOD2</span>
<span class="c"># =&gt; cilium-6ggxf cilium-hb6jp</span>
  
<span class="c"># 단축키(alias) 지정</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c0</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD0</span><span class="s2"> -n kube-system -c cilium-agent -- cilium"</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c1</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD1</span><span class="s2"> -n kube-system -c cilium-agent -- cilium"</span>
</code></pre></div>    </div>
  </li>
  <li>노드간 파드 통신 상세 확인 with Native Routing</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                     READY   STATUS    RESTARTS   AGE    IP             NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    curl-pod                 1/1     Running   0          104m   172.20.1.80    k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-bb8b9557f-7rn8t   1/1     Running   0          105m   172.20.0.130   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-bb8b9557f-9tzvj   1/1     Running   0          105m   172.20.1.31    k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>

<span class="c"># Webpod1,2 파드 IP</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">WEBPODIP1</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>webpod pods <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-ctr <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].status.podIP}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">WEBPODIP2</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>webpod pods <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-w1  <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].status.podIP}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$WEBPODIP1</span> <span class="nv">$WEBPODIP2</span>
<span class="c"># =&gt; 172.20.1.31 172.20.0.130</span>

<span class="c"># curl-pod 에서 WEBPODIP2 로 ping</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> ping <span class="nv">$WEBPODIP2</span>

<span class="c"># 커널 라우팅 확인</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route
<span class="c"># =&gt; ...</span>
<span class="c">#    &lt;span style="color: green;"&gt;172.20.0.0/24 via 192.168.10.101 dev eth1 proto kernel&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 curl-pod가 있는 k8s-ctr에서는 WEBPODIP2의 172.20.0.130이 포함된 패킷을 192.168.10.101 (k8s-w1 노드 IP)로 라우팅합니다.&lt;/span&gt;</span>

<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w1 ip <span class="nt">-c</span> route
<span class="c"># =&gt; ...</span>
<span class="c">#    &lt;span style="color: green;"&gt;172.20.0.130 dev lxc9938d1653585 proto kernel scope link&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s-w1에서는 172.20.0.130의 IP를 해당 pod의 veth로 전달합니다.&lt;/span&gt;</span>

<span class="c">#</span>
<span class="nv">$ </span>cilium hubble port-forward&amp;
<span class="c"># =&gt; ℹ️   Hubble Relay is available at 127.0.0.1:4245</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--pod</span> curl-pod
<span class="c"># =&gt; Aug  2 14:29:00.271: default/curl-pod (ID:1072) -&gt; default/webpod-bb8b9557f-7rn8t (ID:24748) to-network FORWARDED (ICMPv4 EchoRequest)</span>
<span class="c">#    Aug  2 14:29:00.272: default/curl-pod (ID:1072) &lt;- default/webpod-bb8b9557f-7rn8t (ID:24748) to-endpoint FORWARDED (ICMPv4 EchoReply)</span>

<span class="c">#</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> eth1 icmp
<span class="c"># =&gt; tcpdump: verbose output suppressed, use -v[v]... for full protocol decode</span>
<span class="c">#    listening on eth1, link-type EN10MB (Ethernet), snapshot length 262144 bytes</span>
<span class="c">#    23:29:18.464606 IP 172.20.1.80 &gt; 172.20.0.130: ICMP echo request, id 13, seq 815, length 64</span>
<span class="c">#    23:29:18.465333 IP 172.20.0.130 &gt; 172.20.1.80: ICMP echo reply, id 13, seq 815, length 64</span>

<span class="c">#</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> eth1 icmp <span class="nt">-w</span> /tmp/icmp.pcap
<span class="nv">$ </span>termshark <span class="nt">-r</span> /tmp/icmp.pcap
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w3/20250803_cilium_w3_14.png" alt="img.png" class="image-center" />
<em class="image-caption">termshark에서 확인한 ICMP 패킷 정보</em></p>

<p><img src="/assets/2025/cilium/w3/20250803_cilium_w3_13.png" alt="img_1.png" class="image-center" />
<em class="image-caption">Hubble UI에서 확인한 ICMP 흐름 정보</em></p>

<hr />

<h2 id="masquerading">Masquerading</h2>

<h3 id="masquerading-소개">Masquerading 소개</h3>

<p><a href="https://docs.cilium.io/en/stable/network/concepts/masquerading/">Docs</a></p>

<p><img src="/assets/2025/cilium/w3/20250803_cilium_w3_15.png" alt="img.png" /></p>

<ul>
  <li>Masquerading는 Pod가 외부 네트워크와 통신할 때 Pod의 IP 주소를 Cilium 노드의 IP 주소로 변환하는 기능입니다.</li>
  <li>Pod에서 사용되는 IPv4 주소는 일반적으로 RFC1918 개인 주소 공간에 할당되므로 외부로 라우팅 할 수 없습니다.</li>
  <li>Cilium은 이러한 Pod IP를 이미 네트워크에서 라우팅 가능한 Cilium 노드의 IP로 변환하여 외부 네트워크와 통신할 수 있도록 합니다.</li>
  <li>
    <p>만약 masquerading 기능을 사용하지 않으려면,  <code class="language-plaintext highlighter-rouge">enable-ipv4-masquerade: false</code>, <code class="language-plaintext highlighter-rouge">enable-ipv6-masquerade: false</code> 를 지정합니다</p>
  </li>
  <li>기본 동작은 로컬 노드의 IP 할당 CIDR 내에서 모든 목적지를 제외하는 것입니다.</li>
  <li>즉, Pod가 로컬 노드의 IP 할당 CIDR 내에 있는 다른 Pod와 통신할 때는 masquerading를 수행하지 않습니다.</li>
  <li>더 넓은 CIDR 범위를 제외하려면 <code class="language-plaintext highlighter-rouge">ipv4-native-routing-cidr: 10.0.0/8</code> (또는 IPv6 주소의 경우 <code class="language-plaintext highlighter-rouge">ipv6-native-routing-cidr: fd00:/100</code>) 
옵션을 사용하여 지정할 수 있습니다. 이 경우 해당 CIDR 내의 모든 목적지는 masquerade 되지 않습니다.</li>
</ul>

<h3 id="ebpf-기반-masquerading">eBPF 기반 Masquerading</h3>

<ul>
  <li><code class="language-plaintext highlighter-rouge">bpf.masquerade=true</code> 옵션을 사용하여 eBPF 기반 masquerading을 활성화할 수 있습니다.</li>
  <li>기본적으로 BPF masquerading은 BPF Host-Routing 모드도 활성화 시킵니다. 해당 모드의 장점과 한계를 확인하려면 <a href="https://docs.cilium.io/en/stable/operations/performance/tuning/#ebpf-host-routing">eBPF Host-Routing</a> 문서를 참조하세요.</li>
  <li>Masquerading은 eBPF Masquerading 프로그램을 실행하는 장치에서만 작동합니다.</li>
  <li>이는 출력 장치가 프로그램을 실행하는 경우 Pod에서 외부주소로 전송된 패킷이 Masquerading(출력장치 IPv4 주소로) 된다는 것을 의미합니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent  <span class="nt">--</span> cilium status | <span class="nb">grep </span>Masquerading
<span class="c"># =&gt; Masquerading:            BPF   [eth0, eth1]   172.20.0.0/16  [IPv4: Enabled, IPv6: Disabled]</span>
</code></pre></div>    </div>
  </li>
  <li>지정되지 않는 경우, 프로그램은 BPF NodePort 장치 감지를 사용하여 자동으로 감지됩니다.</li>
  <li>이를 수동으로 변경하려면 <code class="language-plaintext highlighter-rouge">devices</code> helm 옵션을 사용하세요.</li>
  <li>eBPF 기반 Masquerading은 TCP, UDP 및 ICMP 프로토콜을 지원합니다.</li>
  <li>기본적으로 <code class="language-plaintext highlighter-rouge">ipv4-native-routing-cidr</code> 범위를 벗어난 IP 주소를 향하는 모든 패킷을 Masquerade하지만, 다른 클러스터 노드의 Node IP로 향하는 패킷은 제외됩니다.
eBPF Masquerading이 활성화되면 pod에서 클러스터 노드의 External IP로의 트래픽도 Masquerading 되지 않습니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>cilium config view  | <span class="nb">grep </span>ipv4-native-routing-cidr
<span class="c"># =&gt; ipv4-native-routing-cidr                          172.20.0.0/16</span>
  
<span class="c"># 노드 IP로 통신 시 확인</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> eth1 icmp <span class="nt">-nn</span>
<span class="c"># =&gt; 23:58:58.175157 IP 172.20.1.80 &gt; 192.168.10.101: ICMP echo request, id 31, seq 1, length 64</span>
<span class="c">#    23:58:58.175918 IP 192.168.10.101 &gt; 172.20.1.80: ICMP echo reply, id 31, seq 1, length 64</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 Node IP로의 패킷은 Masquerading 되지 않고 Pod IP가 사용됨을 알 수 있습니다.&lt;/span&gt;</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> ping 192.168.10.101
<span class="c"># =&gt; PING 192.168.10.101 (192.168.10.101) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 192.168.10.101: icmp_seq=1 ttl=63 time=0.888 ms</span>
<span class="c">#    ...</span>
</code></pre></div>    </div>
  </li>
</ul>

<h3 id="iptables-기반-masquerading">iptables 기반 Masquerading</h3>

<ul>
  <li>이 모드는 모든 커널버전에서 작동할 수 있는 레거시 구현입니다.</li>
  <li>Cilium 네트워크 장치가 아닌 기본 네트워크 장치에서 iptables를 사용하여 masquerading을 수행합니다.</li>
  <li>masquerading이 사용되는 네트워크 장치를 제한하고 싶을 경우 <code class="language-plaintext highlighter-rouge">egress-masquerade-interfaces: eth0</code> 옵션을 사용합니다.</li>
  <li>대상 네트워크 CIDR에 따라 다른 소스 주소를 사용하는 고급 구성을 위해서는 <code class="language-plaintext highlighter-rouge">enable-masquerade-to-route-source: "true"</code>를 사용하여, 메인 network interface의 주소대신 소스 주소들을 사용할 수도 있습니다.</li>
</ul>

<h3 id="masquerading-실습">Masquerading 실습</h3>

<ul>
  <li>실습 환경 구성
<img src="/assets/2025/cilium/w3/20250803_cilium_w3_16.png" alt="img.png" />
    <ul>
      <li><strong>router</strong> : 사내망 10.10.0.0/16 대역 통신과 연결, k8s에 join 되지 않은 web 서버, loop1/loop2 dump 인터페이스를 배치</li>
    </ul>
  </li>
  <li>현재 상태 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 현재 설정 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent  <span class="nt">--</span> cilium status | <span class="nb">grep </span>Masquerading
<span class="c"># =&gt; Masquerading:            BPF   [eth0, eth1]   172.20.0.0/16  [IPv4: Enabled, IPv6: Disabled]</span>
<span class="c">#</span>
<span class="nv">$ </span>cilium config view  | <span class="nb">grep </span>ipv4-native-routing-cidr
<span class="c"># =&gt; ipv4-native-routing-cidr                          172.20.0.0/16</span>

<span class="c"># iptables 확인</span>
<span class="nv">$ </span>iptables-save | <span class="nb">grep</span> <span class="nt">-v</span> KUBE | iptables-restore
<span class="nv">$ </span>iptables-save

<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w1 <span class="s2">"sudo iptables-save | grep -v KUBE | sudo iptables-restore"</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w1 <span class="nb">sudo </span>iptables-save

<span class="c"># 통신 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nt">-s</span> webpod | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod-bb8b9557f-7rn8t</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nt">-s</span> webpod | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod-bb8b9557f-9tzvj</span>
</code></pre></div></div>

<ul>
  <li>router eth1 192.168.10.200 통신 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 터미널 2개 사용</span>
<span class="o">[</span>k8s-ctr] <span class="nv">$ </span>tcpdump <span class="nt">-i</span> eth1 icmp <span class="nt">-nn</span> <span class="c"># 혹은 hubble observe -f --pod curl-pod</span>
<span class="o">[</span>router] <span class="nv">$ </span>tcpdump <span class="nt">-i</span> eth1 icmp <span class="nt">-nn</span>

<span class="c"># router eth1 192.168.10.200 로 ping &gt;&gt; IP 확인해보자!</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> ping 192.168.10.101
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s-ctr 쪽에만 패킷이 캡쳐됨&lt;/span&gt;</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> ping 192.168.10.200
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s-ctr 및 router 모두 패킷이 캡쳐됨&lt;/span&gt;</span>

<span class="c"># k8s-ctr 패킷 캡쳐 결과</span>
<span class="c"># =&gt; 00:45:19.552476 IP 192.168.10.100 &gt; 192.168.10.200: ICMP echo request, id 73, seq 1, length 64</span>
<span class="c">#    00:45:19.553044 IP 192.168.10.200 &gt; 192.168.10.100: ICMP echo reply, id 73, seq 1, length 64</span>
<span class="c">#    ...</span>

<span class="c"># router 패킷 캡쳐 결과</span>
<span class="c"># =&gt; 00:45:19.494633 IP 192.168.10.100 &gt; 192.168.10.200: ICMP echo request, id 73, seq 1, length 64</span>
<span class="c">#    00:45:19.494758 IP 192.168.10.200 &gt; 192.168.10.100: ICMP echo reply, id 73, seq 1, length 64</span>
<span class="c">#    ...</span>

<span class="nt">---</span>
<span class="c"># 터미널 2개 사용</span>
<span class="o">[</span>k8s-ctr] <span class="nv">$ </span>tcpdump <span class="nt">-i</span> eth1 tcp port 80 <span class="nt">-nnq</span> <span class="c"># 혹은 hubble observe -f --pod curl-pod</span>
<span class="o">[</span>router] <span class="nv">$ </span>tcpdump <span class="nt">-i</span> eth1 tcp port 80 <span class="nt">-nnq</span>

<span class="c"># router eth1 192.168.10.200 로 curl &gt;&gt; IP 확인해보자!</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nt">-s</span> webpod
<span class="c"># =&gt; Hostname: webpod-bb8b9557f-9tzvj</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: ::1</span>
<span class="c">#    IP: 172.20.1.31</span>
<span class="c">#    IP: fe80::6857:8fff:fe68:c5d5</span>
<span class="c">#    RemoteAddr: 172.20.1.80:56614</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: webpod</span>
<span class="c">#    User-Agent: curl/8.14.1</span>
<span class="c">#    Accept: */*</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s-ctr 노드에 있는 webpod에 통신할때만 k8s-ctr에 캡쳐됨&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 router에는 캡쳐되지 않음&lt;/span&gt;</span>

<span class="c"># k8s-ctr 패킷 캡쳐 결과</span>
<span class="c"># =&gt; 00:58:25.714438 IP 172.20.1.80.58682 &gt; 172.20.0.130.80: tcp 70</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 IP는 Pod CIDR임&lt;/span&gt;</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nt">-s</span> webpod
<span class="c"># =&gt; Hostname: webpod-bb8b9557f-7rn8t</span>
<span class="c">#    IP: 172.20.0.130</span>
<span class="c">#    RemoteAddr: 172.20.1.80:60086</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s-1 노드에 있는 webpod에 통신할때는 패킷 캡쳐 되지않음&lt;/span&gt;</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nt">-s</span> 192.168.10.200
<span class="c"># =&gt; &lt;h1&gt;Web Server : router&lt;/h1&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s-ctr와 router 모두에 캡쳐됨&lt;/span&gt;</span>

<span class="c"># k8s-ctr 패킷 캡쳐 결과</span>
<span class="c"># =&gt; 01:01:34.458560 IP 192.168.10.100.45668 &gt; 192.168.10.200.80: tcp 78</span>
<span class="c">#    ...</span>
<span class="c"># router 패킷 캡쳐 결과</span>
<span class="c"># =&gt; 01:01:34.501812 IP 192.168.10.100.45668 &gt; 192.168.10.200.80: tcp 78</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 클러스터 바깥의 서버인 Router와는 Node IP로 통신하고 있음&lt;/span&gt;</span>
</code></pre></div></div>

<h3 id="ip-masq-agent-설정">ip-masq-agent 설정</h3>

<p><a href="https://github.com/kubernetes-sigs/ip-masq-agent">Docs</a></p>

<ul>
  <li>eBPF 기반 ip-masq-agent는 설정파일을 통해 <code class="language-plaintext highlighter-rouge">nonMasqueradeCIDRs</code>, <code class="language-plaintext highlighter-rouge">masqLinkLocal</code>, <code class="language-plaintext highlighter-rouge">masqLinkLocalIPv6</code> 옵션을 지원합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">nonMasqueradeCIDRs</code>는 masquerading을 수행하지 않을 CIDR 범위를 지정합니다.</li>
  <li>해당 설정이 없는 경우 agent는 다음의 masquerading 제외 CIDR을 사용합니다.
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="mi">10</span><span class="p">.</span><span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="o">/</span><span class="mi">8</span>
<span class="mi">172</span><span class="p">.</span><span class="mi">16</span><span class="p">.</span><span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="o">/</span><span class="mi">12</span>
<span class="mi">192</span><span class="p">.</span><span class="mi">168</span><span class="p">.</span><span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="o">/</span><span class="mi">16</span>
<span class="mi">100</span><span class="p">.</span><span class="mi">64</span><span class="p">.</span><span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="o">/</span><span class="mi">10</span>
<span class="mi">192</span><span class="p">.</span><span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="o">/</span><span class="mi">24</span>
<span class="mi">192</span><span class="p">.</span><span class="mi">0</span><span class="p">.</span><span class="mi">2</span><span class="p">.</span><span class="mi">0</span><span class="o">/</span><span class="mi">24</span>
<span class="mi">192</span><span class="p">.</span><span class="mi">88</span><span class="p">.</span><span class="mi">99</span><span class="p">.</span><span class="mi">0</span><span class="o">/</span><span class="mi">24</span>
<span class="mi">198</span><span class="p">.</span><span class="mi">18</span><span class="p">.</span><span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="o">/</span><span class="mi">15</span>
<span class="mi">198</span><span class="p">.</span><span class="mi">51</span><span class="p">.</span><span class="mi">100</span><span class="p">.</span><span class="mi">0</span><span class="o">/</span><span class="mi">24</span>
<span class="mi">203</span><span class="p">.</span><span class="mi">0</span><span class="p">.</span><span class="mi">113</span><span class="p">.</span><span class="mi">0</span><span class="o">/</span><span class="mi">24</span>
<span class="mi">240</span><span class="p">.</span><span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="o">/</span><span class="mi">4</span>
</code></pre></div>    </div>
  </li>
  <li><code class="language-plaintext highlighter-rouge">masqLinkLocal</code>이 false이거나 지정되어있지 않으면 <code class="language-plaintext highlighter-rouge">169.254.0.0/16</code> 또한 masquerading 제외 CIDR로 사용됩니다.</li>
  <li>ipMasqAgent 설정
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 아래 설정값은 cilium 데몬셋 자동 재시작됨</span>
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--namespace</span> kube-system <span class="nt">--reuse-values</span> <span class="se">\</span>
  <span class="nt">--set</span> ipMasqAgent.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> ipMasqAgent.config.nonMasqueradeCIDRs<span class="o">=</span><span class="s1">'{10.10.1.0/24,10.10.2.0/24}'</span>
  
<span class="nv">$ </span>cilium hubble port-forward&amp;
<span class="c"># =&gt; ℹ️   Hubble Relay is available at 127.0.0.1:4245</span>
  
<span class="c"># ip-masq-agent configmap 생성 확인</span>
<span class="nv">$ </span>kubectl get cm <span class="nt">-n</span> kube-system ip-masq-agent <span class="nt">-o</span> yaml | yq
<span class="c"># =&gt; ...</span>
<span class="c">#        "config": "{\"nonMasqueradeCIDRs\":[\"10.10.1.0/24\",\"10.10.2.0/24\"]}"</span>
<span class="c">#    ...</span>
<span class="c">#        "name": "ip-masq-agent",</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>kc describe cm <span class="nt">-n</span> kube-system ip-masq-agent 
<span class="c"># =&gt; Data</span>
<span class="c">#    ====</span>
<span class="c">#    config:</span>
<span class="c">#    ----</span>
<span class="c">#    {"nonMasqueradeCIDRs":["10.10.1.0/24","10.10.2.0/24"]}</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>k9s 
  
<span class="c">#</span>
<span class="nv">$ </span>cilium config view  | <span class="nb">grep</span> <span class="nt">-i</span> ip-masq
<span class="c"># =&gt; enable-ip-masq-agent                              true</span>
  
<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system <span class="nb">exec </span>ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium-dbg bpf ipmasq list
<span class="c"># =&gt; IP PREFIX/ADDRESS</span>
<span class="c">#    10.10.1.0/24</span>
<span class="c">#    10.10.2.0/24</span>
<span class="c">#    169.254.0.0/16</span>
</code></pre></div>    </div>
  </li>
</ul>

<hr />

<h2 id="coredns-nodelocaldns">CoreDNS, NodeLocalDNS</h2>

<h3 id="coredns">CoreDNS</h3>
<p><img src="/assets/2025/cilium/w3/20250803_cilium_w3_17.png" alt="img.png" class="image-center" /></p>

<ul>
  <li>CoreDNS 소개 - <a href="https://kubernetes.io/ko/docs/tasks/administer-cluster/dns-custom-nameservers/">Docs</a> , <a href="https://coredns.io/manual/toc/">Home</a> , <a href="https://coredns.io/plugins/">Plugins</a> , <a href="https://www.youtube.com/watch?v=W3f5Ks0j2Q8">Youtube</a>
    <ul>
      <li>CoreDNS는 Kubernetes 클러스터의 DNS 서버로, 클러스터 내에서 서비스와 파드의 이름을 IP 주소로 변환하는 역할을 합니다.</li>
      <li>CoreDNS는 BIND, Knot, PowerDNS와 같은 전통적인 DNS 서버와는 다르게 
대부분의 기능을 플러그인화 하여 유연하게 확장할 수 있습니다.</li>
    </ul>
  </li>
  <li>CoreDNS 설정 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 파드의 DNS 설정 정보 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> <span class="nb">cat</span> /etc/resolv.conf
<span class="c"># =&gt; search default.svc.cluster.local svc.cluster.local cluster.local</span>
<span class="c">#    nameserver 10.96.0.10</span>
<span class="c">#    options ndots:5</span>

<span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> /var/lib/kubelet/config.yaml | <span class="nb">grep </span>cluster <span class="nt">-A1</span>
<span class="c"># =&gt; clusterDNS:</span>
<span class="c">#    - 10.96.0.10</span>
<span class="c">#    clusterDomain: cluster.local</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get svc,ep <span class="nt">-n</span> kube-system kube-dns
<span class="c"># =&gt; NAME               TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE</span>
<span class="c">#    service/kube-dns   ClusterIP   10.96.0.10   &lt;none&gt;        53/UDP,53/TCP,9153/TCP   24h</span>
<span class="c">#    </span>
<span class="c">#    NAME                 ENDPOINTS                                                   AGE</span>
<span class="c">#    endpoints/kube-dns   172.20.0.56:53,172.20.1.113:53,172.20.0.56:53 + 3 more...   24h</span>

<span class="nv">$ </span>kubectl get pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>kube-dns
<span class="c"># =&gt; NAME                       READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    coredns-674b8bbfcf-58c7n   1/1     Running   0          4h17m</span>
<span class="c">#    coredns-674b8bbfcf-tg9ll   1/1     Running   0          4h17m</span>

<span class="c">#</span>
<span class="nv">$ </span>kc describe pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>kube-dns
<span class="c"># =&gt; ...</span>
<span class="c">#     config-volume:</span>
<span class="c">#        Type:      ConfigMap (a volume populated by a ConfigMap)</span>
<span class="c">#        Name:      coredns</span>
<span class="c">#        Optional:  false</span>
<span class="c">#    ...</span>

<span class="nv">$ </span>kc describe cm <span class="nt">-n</span> kube-system coredns
<span class="c"># =&gt; ...</span>
<span class="c">#    Corefile:</span>
<span class="c">#    ----</span>
<span class="c">#    .:53 {              # 모든 도메인 요청을 53포트에서 수신</span>
<span class="c">#        errors          # DNS 응답 중 에러가 발생할 경우 로그 출력</span>
<span class="c">#        health {        # health 엔드포인트를 제공하여 상태 확인 가능</span>
<span class="c">#           lameduck 5s  # 종료 시 5초간 lameduck 모드로 트래픽을 점차 줄이며 종료</span>
<span class="c">#        }</span>
<span class="c">#        ready           # ready 엔드포인트 제공, 8181 포트의 HTTP 엔드포인트가, 모든 플러그인이 준비되었다는 신호를 보내면 200 OK 를 반환</span>
<span class="c">#        kubernetes cluster.local in-addr.arpa ip6.arpa {    # Kubernetes DNS 플러그인 설정(클러스터 내부 도메인 처리), cluster.local: 클러스터 도메인</span>
<span class="c">#           pods insecure                         # 파드 IP로 DNS 조회 허용 (보안 없음)</span>
<span class="c">#           fallthrough in-addr.arpa ip6.arpa     #  해당 도메인에서 결과 없으면 다음 플러그인으로 전달</span>
<span class="c">#           ttl 30                                #  캐시 타임 (30초)</span>
<span class="c">#        }</span>
<span class="c">#        prometheus :9153 # Prometheus metrics 수집 가능</span>
<span class="c">#        forward . /etc/resolv.conf {             # CoreDNS가 모르는 도메인은 지정된 업스트림(보통 외부 DNS)으로 전달, .: 모든 쿼리</span>
<span class="c">#           max_concurrent 1000                   # 병렬 포워딩 최대 1000개</span>
<span class="c">#        }</span>
<span class="c">#        cache 30 {                        # DNS 응답 캐시 기능, 기본 캐시 TTL 30초</span>
<span class="c">#           disable success cluster.local  # 성공 응답 캐시 안 함 (cluster.local 도메인)</span>
<span class="c">#           disable denial cluster.local   # NXDOMAIN 응답도 캐시 안 함</span>
<span class="c">#        } </span>
<span class="c">#        loop         # 간단한 전달 루프(loop)를 감지하고, 루프가 발견되면 CoreDNS 프로세스를 중단(halt).</span>
<span class="c">#        reload       # Corefile 이 변경되었을 때 자동으로 재적용, 컨피그맵 설정을 변경한 후에 변경 사항이 적용되기 위하여 약 2분정도 소요.</span>
<span class="c">#        loadbalance  # 응답에 대하여 A, AAAA, MX 레코드의 순서를 무작위로 선정하는 라운드-로빈 DNS 로드밸런서.</span>
<span class="c">#    }</span>

<span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> /etc/resolv.conf
<span class="c"># =&gt; nameserver 127.0.0.53</span>
<span class="c">#    options edns0 trust-ad</span>
<span class="c">#    search .</span>

<span class="nv">$ </span>resolvectl 
<span class="c"># =&gt; Link 2 (eth0)</span>
<span class="c">#        Current Scopes: DNS</span>
<span class="c">#             Protocols: +DefaultRoute -LLMNR -mDNS -DNSOverTLS DNSSEC=no/unsupported</span>
<span class="c">#    Current DNS Server: 10.0.2.3</span>
<span class="c">#           DNS Servers: 10.0.2.3</span>
</code></pre></div></div>

<ul>
  <li>
    <p>(참고) forward 플러그인 - <a href="https://coredns.io/plugins/forward/">Docs</a></p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 활용 1 : '.consul.local' 도메인을 관리하는 도메인 서버가 존재 시, coredns 에서 해당 도메인 서버로 질의 설정 시</span>
consul.local:53 <span class="o">{</span>
    errors
    cache 30
    forward <span class="nb">.</span> 10.150.0.1
<span class="o">}</span>
  
<span class="c"># 활용 2 : 모든 비 클러스터의 DNS 조회가 172.16.0.1 의 특정 네임서버 사용 시, /etc/resolv.conf 대신 forward 를 네임서버로 지정</span>
forward <span class="nb">.</span>  172.16.0.1
  
<span class="c"># 위 1,2 포함한 설정 예시</span>
apiVersion: v1
kind: ConfigMap
metadata:
  name: coredns
  namespace: kube-system
data:
  Corefile: |
    .:53 <span class="o">{</span>
        errors
        health
        kubernetes cluster.local <span class="k">in</span><span class="nt">-addr</span>.arpa ip6.arpa <span class="o">{</span>
           pods insecure
           fallthrough <span class="k">in</span><span class="nt">-addr</span>.arpa ip6.arpa
        <span class="o">}</span>
        prometheus :9153
        forward <span class="nb">.</span> 172.16.0.1  <span class="c"># 활용 2</span>
        cache 30
        loop
        reload
        loadbalance
    <span class="o">}</span>
    consul.local:53 <span class="o">{</span>         <span class="c"># 활용 1</span>
        errors
        cache 30
        forward <span class="nb">.</span> 10.150.0.1
    <span class="o">}</span>  
</code></pre></div>    </div>
  </li>
  <li>
    <p>파드에서 DNS 질의 확인 - <a href="https://kubernetes.io/docs/tasks/administer-cluster/dns-debugging-resolution/">Docs</a> , <a href="https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/">DNS for Services and Pods</a> , <a href="https://kubernetes.io/docs/tasks/administer-cluster/dns-horizontal-autoscaling/">Autoscale the DNS Service in a Cluster</a></p>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 모니터링1</span>
<span class="nv">$ </span>cilium hubble port-forward&amp;
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--port</span> 53
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--port</span> 53 <span class="nt">--protocol</span> UDP

<span class="c"># 모니터링2</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> any udp port 53 <span class="nt">-nn</span>

<span class="c"># 파드 IP 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                     READY   STATUS    RESTARTS   AGE     IP             NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    curl-pod                 1/1     Running   0          3h55m   172.20.1.80    k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-bb8b9557f-7rn8t   1/1     Running   0          3h55m   172.20.0.130   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-bb8b9557f-9tzvj   1/1     Running   0          3h55m   172.20.1.31    k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>

<span class="nv">$ </span>kubectl get pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>kube-dns <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                       READY   STATUS    RESTARTS   AGE     IP             NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    coredns-674b8bbfcf-58c7n   1/1     Running   0          4h29m   172.20.1.113   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    coredns-674b8bbfcf-tg9ll   1/1     Running   0          4h29m   172.20.0.56    k8s-w1    &lt;none&gt;           &lt;none&gt;</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> <span class="nb">cat</span> /etc/resolv.conf
<span class="c"># =&gt; search default.svc.cluster.local svc.cluster.local cluster.local</span>
<span class="c">#    nameserver 10.96.0.10</span>
<span class="c">#    options ndots:5</span>

<span class="c"># 실습 편리를 위해 coredns 파드를 1개로 축소</span>
<span class="nv">$ </span>kubectl scale deployment <span class="nt">-n</span> kube-system coredns <span class="nt">--replicas</span> 1
<span class="c"># =&gt; deployment.apps/coredns scaled</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>kube-dns <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                       READY   STATUS    RESTARTS   AGE     IP            NODE     NOMINATED NODE   READINESS GATES</span>
<span class="c">#    coredns-674b8bbfcf-tg9ll   1/1     Running   0          4h29m   172.20.0.56   k8s-w1   &lt;none&gt;           &lt;none&gt;</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl kube-dns.kube-system.svc:9153/metrics | <span class="nb">grep </span>coredns_cache_ | <span class="nb">grep</span> <span class="nt">-v</span> ^#
<span class="c"># =&gt; coredns_cache_entries{server="dns://:53",type="denial",view="",zones="."} 1</span>
<span class="c">#    coredns_cache_entries{server="dns://:53",type="success",view="",zones="."} 0</span>
<span class="c">#    coredns_cache_misses_total{server="dns://:53",view="",zones="."} 46</span>
<span class="c">#    coredns_cache_requests_total{server="dns://:53",view="",zones="."} 46</span>

<span class="c"># 도메인 질의</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> nslookup webpod
<span class="c"># =&gt; Server:         10.96.0.10</span>
<span class="c">#    Address:        10.96.0.10#53</span>
<span class="c">#    </span>
<span class="c">#    Name:   webpod.default.svc.cluster.local</span>
<span class="c">#    Address: 10.96.194.47</span>

<span class="c"># tcpdump로 DNS 질의 패킷 확인</span>
<span class="c"># =&gt; 01:27:05.029100 lxc9dcdf61704e7 In  IP 172.20.1.80.41316 &gt; 172.20.0.56&lt;span style="color: green;"&gt;.53&lt;/span&gt;: 62435+ &lt;span style="color: green;"&gt;A? webpod.default.svc.cluster.local.&lt;/span&gt; (50)</span>
<span class="c">#    01:27:05.029378 eth1  Out IP 172.20.1.80.41316 &gt; 172.20.0.56.53: 62435+ A? webpod.default.svc.cluster.local. (50)</span>
<span class="c">#    01:27:05.032936 eth1  In  IP 172.20.0.56.53 &gt; 172.20.1.80.41316: 62435*- &lt;span style="color: green;"&gt;1/0/0 A 10.96.194.47&lt;/span&gt; (98)</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> nslookup <span class="nt">-debug</span> webpod
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> nslookup <span class="nt">-debug</span> google.com
<span class="c"># =&gt; Server:         10.96.0.10</span>
<span class="c">#    Address:        10.96.0.10#53</span>
<span class="c">#    </span>
<span class="c">#    ------------</span>
<span class="c">#        QUESTIONS:</span>
<span class="c">#            google.com.default.svc.cluster.local, type = A, class = IN</span>
<span class="c">#        ...</span>
<span class="c">#    ------------</span>
<span class="c">#    ** server can't find google.com.default.svc.cluster.local: NXDOMAIN</span>
<span class="c">#    ;; Got recursion not available from 10.96.0.10</span>
<span class="c">#    Server:         10.96.0.10</span>
<span class="c">#    Address:        10.96.0.10#53</span>
<span class="c">#    </span>
<span class="c">#    ------------</span>
<span class="c">#        QUESTIONS:</span>
<span class="c">#            google.com.svc.cluster.local, type = A, class = IN</span>
<span class="c">#        ...</span>
<span class="c">#    ------------</span>
<span class="c">#    ** server can't find google.com.svc.cluster.local: NXDOMAIN</span>
<span class="c">#    ;; Got recursion not available from 10.96.0.10</span>
<span class="c">#    Server:         10.96.0.10</span>
<span class="c">#    Address:        10.96.0.10#53</span>
<span class="c">#    </span>
<span class="c">#    ------------</span>
<span class="c">#        QUESTIONS:</span>
<span class="c">#            google.com.cluster.local, type = A, class = IN</span>
<span class="c">#        ...</span>
<span class="c">#    ------------</span>
<span class="c">#    ** server can't find google.com.cluster.local: NXDOMAIN</span>
<span class="c">#    Server:         10.96.0.10</span>
<span class="c">#    Address:        10.96.0.10#53</span>
<span class="c">#    </span>
<span class="c">#    ------------</span>
<span class="c">#        QUESTIONS:</span>
<span class="c">#            google.com, type = A, class = IN</span>
<span class="c">#        ANSWERS:</span>
<span class="c">#        -&gt;  google.com</span>
<span class="c">#            internet address = 142.250.206.238</span>
<span class="c">#            ttl = 30</span>
<span class="c">#        AUTHORITY RECORDS:</span>
<span class="c">#        ADDITIONAL RECORDS:</span>
<span class="c">#    ------------</span>
<span class="c">#    Non-authoritative answer:</span>
<span class="c">#    Name:   google.com</span>
<span class="c">#    Address: 142.250.206.238</span>
<span class="c">#    ------------</span>
<span class="c">#        QUESTIONS:</span>
<span class="c">#            google.com, type = AAAA, class = IN</span>
<span class="c">#        ANSWERS:</span>
<span class="c">#        -&gt;  google.com</span>
<span class="c">#            has AAAA address 2404:6800:400a:804::200e</span>
<span class="c">#            ttl = 30</span>
<span class="c">#        AUTHORITY RECORDS:</span>
<span class="c">#        ADDITIONAL RECORDS:</span>
<span class="c">#    ------------</span>
<span class="c">#    Name:   google.com</span>
<span class="c">#    Address: 2404:6800:400a:804::200e</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 클러스터 외부의 도메인을 질의할때는 클러스터 내부의 search 도메인들을 먼저&lt;/span&gt; </span>
<span class="c"># &lt;span style="color: green;"&gt;확인하고, 없으면 외부 DNS 서버로 질의하여 응답을 받는 것을 알 수 있습니다.&lt;/span&gt;</span>

<span class="c"># tcpdump로 DNS 질의 패킷 확인</span>
<span class="c"># =&gt; 01:33:33.852442 lxc9dcdf61704e7 In  IP 172.20.1.80.58442 &gt; 172.20.0.56.53: 52842+ &lt;span style="color: green;"&gt;A? google.com.default.svc.cluster.local.&lt;/span&gt; (54)</span>
<span class="c">#    01:33:33.852610 eth1  Out IP 172.20.1.80.58442 &gt; 172.20.0.56.53: 52842+ A? google.com.default.svc.cluster.local. (54)</span>
<span class="c">#    01:33:33.855947 eth1  In  IP 172.20.0.56.53 &gt; 172.20.1.80.58442: 52842 NXDomain*- 0/1/0 (147)</span>
<span class="c">#    01:33:33.861141 lxc9dcdf61704e7 In  IP 172.20.1.80.36323 &gt; 172.20.0.56.53: 10644+ &lt;span style="color: green;"&gt;A? google.com.svc.cluster.local.&lt;/span&gt; (46)</span>
<span class="c">#    01:33:33.861515 eth1  Out IP 172.20.1.80.36323 &gt; 172.20.0.56.53: 10644+ A? google.com.svc.cluster.local. (46)</span>
<span class="c">#    01:33:33.862582 eth1  In  IP 172.20.0.56.53 &gt; 172.20.1.80.36323: 10644 NXDomain*- 0/1/0 (139)</span>
<span class="c">#    01:33:33.868623 lxc9dcdf61704e7 In  IP 172.20.1.80.48326 &gt; 172.20.0.56.53: 52392+ &lt;span style="color: green;"&gt;A? google.com.cluster.local.&lt;/span&gt; (42)</span>
<span class="c">#    01:33:33.868857 eth1  Out IP 172.20.1.80.48326 &gt; 172.20.0.56.53: 52392+ A? google.com.cluster.local. (42)</span>
<span class="c">#    01:33:33.870240 eth1  In  IP 172.20.0.56.53 &gt; 172.20.1.80.48326: 52392 NXDomain*- 0/1/0 (135)</span>
<span class="c">#    01:33:33.874341 lxc9dcdf61704e7 In  IP 172.20.1.80.50810 &gt; 172.20.0.56.53: 16999+ &lt;span style="color: green;"&gt;A? google.com.&lt;/span&gt; (28)</span>
<span class="c">#    01:33:33.874556 eth1  Out IP 172.20.1.80.50810 &gt; 172.20.0.56.53: 16999+ A? google.com. (28)</span>
<span class="c">#    01:33:33.928831 eth1  In  IP 172.20.0.56.53 &gt; 172.20.1.80.50810: 16999 &lt;span style="color: green;"&gt;1/0/0 A 142.250.206.238&lt;/span&gt; (54)</span>

<span class="c"># coredns 로깅, 디버깅 활성화</span>
<span class="c"># k9s → configmap → coredns 선택 → E(edit) → 아래처럼 log, debug 입력 후 빠져나오기</span>
<span class="nt">---</span>
    .:53 <span class="o">{</span>
        log
        debug
        errors
<span class="nt">---</span>

<span class="c"># 로그 모니터링 3</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system logs <span class="nt">-l</span> k8s-app<span class="o">=</span>kube-dns <span class="nt">-f</span>

<span class="c"># 도메인 질의</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> nslookup webpod
<span class="c"># =&gt; ;; Got recursion not available from 10.96.0.10</span>
<span class="c">#    Server:         10.96.0.10</span>
<span class="c">#    Address:        10.96.0.10#53</span>
<span class="c">#    </span>
<span class="c">#    Name:   webpod.default.svc.cluster.local</span>
<span class="c">#    Address: 10.96.194.47</span>
<span class="c">#    ;; Got recursion not available from 10.96.0.10</span>

<span class="c"># coredns 로그 확인</span>
<span class="c"># =&gt; [INFO] 172.20.1.80:46753 - 59201 "A IN webpod.default.svc.cluster.local. udp 50 false 512" NOERROR qr,aa,rd 98 0.000500084s</span>
<span class="c">#    [INFO] 172.20.1.80:39996 - 54949 "AAAA IN webpod.default.svc.cluster.local. udp 50 false 512" NOERROR qr,aa,rd 143 0.000554333s</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> nslookup google.com
<span class="c"># =&gt; Server:         10.96.0.10</span>
<span class="c">#    Address:        10.96.0.10#53</span>
<span class="c">#    </span>
<span class="c">#    Non-authoritative answer:</span>
<span class="c">#    Name:   google.com</span>
<span class="c">#    Address: 142.250.206.238</span>
<span class="c">#    Name:   google.com</span>
<span class="c">#    Address: 2404:6800:400a:804::200e</span>

<span class="c"># coredns 로그 확인</span>
<span class="c"># =&gt; [INFO] 172.20.1.80:43389 - 1366 "A IN google.com.default.svc.cluster.local. udp 54 false 512" NXDOMAIN qr,aa,rd 147 0.001736458s</span>
<span class="c">#    [INFO] 172.20.1.80:34460 - 17323 "A IN google.com.svc.cluster.local. udp 46 false 512" NXDOMAIN qr,aa,rd 139 0.000483917s</span>
<span class="c">#    [INFO] 172.20.1.80:40469 - 26458 "A IN google.com.cluster.local. udp 42 false 512" NXDOMAIN qr,aa,rd 135 0.000331334s</span>
<span class="c">#    [INFO] 172.20.1.80:56627 - 19160 "A IN google.com. udp 28 false 512" NOERROR qr,rd,ra 54 0.054453541s</span>
<span class="c">#    [INFO] 172.20.1.80:48324 - 36047 "AAAA IN google.com. udp 28 false 512" NOERROR qr,rd,ra 66 0.044442084s</span>

<span class="c"># CoreDNS가 prometheus 플러그인을 사용하고 있다면, 메트릭 포트(:9153)를 통해 캐시 관련 정보를 수집.</span>
<span class="c">## coredns_cache_entries 현재 캐시에 저장된 엔트리(항목) 수 : type: success 또는 denial (정상 응답 or NXDOMAIN 등)</span>
<span class="c">## coredns_cache_hits_total	캐시 조회 성공 횟수</span>
<span class="c">## coredns_cache_misses_total	캐시 미스 횟수</span>
<span class="c">## coredns_cache_requests_total	캐시 관련 요청 횟수의 총합</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl kube-dns.kube-system.svc:9153/metrics | <span class="nb">grep </span>coredns_cache_ | <span class="nb">grep</span> <span class="nt">-v</span> ^#
<span class="c"># =&gt; coredns_cache_entries{server="dns://:53",type="denial",view="",zones="."} 1</span>
<span class="c">#    coredns_cache_entries{server="dns://:53",type="success",view="",zones="."} 2</span>
<span class="c">#    coredns_cache_hits_total{server="dns://:53",type="success",view="",zones="."} 4</span>
<span class="c">#    coredns_cache_misses_total{server="dns://:53",view="",zones="."} 116</span>
<span class="c">#    coredns_cache_requests_total{server="dns://:53",view="",zones="."} 120</span>
</code></pre></div></div>

<h3 id="nodelocaldns">NodeLocalDNS</h3>

<p><a href="https://popappend.tistory.com/142">소개 블로그</a></p>

<p><img src="/assets/2025/cilium/w3/20250803_cilium_w3_18.png" alt="img.png" class="image-center" /></p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">NodeLocal DNSCache</code>는 클러스터 노드에서 DNS 캐싱 에이전트를 DaemonSet으로 실행하여 클러스터 DNS 성능을 향상시킵니다.</li>
  <li>오늘날의 아키텍처에서 ‘<code class="language-plaintext highlighter-rouge">ClusterFirst</code>’ DNS 모드의 Pods는 DNS 쿼리를 위해 kube-dns 서비스 IP에 도달합니다.</li>
  <li>이는 kube-proxy에 의해 추가된 <strong>iptables</strong> 규칙을 통해 kube-dns/CoreDNS 엔드포인트로 변환됩니다.</li>
  <li>이 새로운 아키텍처를 통해 Pods는 동일한 노드에서 실행되는 DNS 캐싱 에이전트에 도달하여 iptables DNAT 규칙과 연결 추적을 피할 수 있습니다.</li>
  <li>로컬 캐싱 에이전트는 클러스터 호스트 이름(기본적으로 “cluster.local” 접미사)의 캐시 누락에 대해 kube-dns 서비스에 쿼리합니다.</li>
  <li>현재 DNS 아키텍처에서는 로컬 kube-dns/CoreDNS 인스턴스가 없는 경우 DNS QPS가 가장 높은 포드가 다른 노드에 도달해야 할 수도 있습니다. 로컬 캐시를 사용하면 이러한 시나리오에서 지연 시간을 개선하는 데 도움이 됩니다.</li>
  <li>iptables DNAT 및 연결 추적을 건너뛰면 <a href="https://github.com/kubernetes/kubernetes/issues/56903">연결 추적 레이스</a>를 줄이고 UDP DNS 항목이 연결 추적 테이블을 채우는 것을 방지하는 데 도움이 됩니다.</li>
  <li>로컬 캐싱 에이전트에서 kube-dns 서비스로의 연결은 TCP로 업그레이드할 수 있습니다. TCP 연결 트랙 항목은 시간 초과를 해야 하는 UDP 항목과 달리 연결 종료 시 제거됩니다(기본값 <code class="language-plaintext highlighter-rouge">nf_conntrack_udp_timeout</code>은 30초)</li>
  <li>DNS 쿼리를 UDP에서 TCP로 업그레이드하면 삭제된 UDP 패킷과 DNS 타임아웃으로 인한 테일 지연 시간이 보통 최대 30초(3회 재시도 + 10초 타임아웃)까지 줄어듭니다. 노드로컬 캐시가 UDP DNS 쿼리를 듣기 때문에 애플리케이션을 변경할 필요가 없습니다.</li>
  <li>노드 수준에서 DNS 요청에 대한 메트릭 및 가시성.</li>
  <li>
    <p>네거티브 캐싱을 다시 활성화하여 kube-dns 서비스에 대한 쿼리 수를 줄일 수 있습니다.</p>
  </li>
  <li>NodeLocal DNSCache 설치 방법 - <a href="https://kubernetes.io/docs/tasks/administer-cluster/nodelocaldns/#configuration">Docs</a>
    <ul>
      <li>설치시 NodeLocal DNSCache의 로컬 Listening IP 주소는 클러스터의 기존 IP와 충돌하지 않는 모든 주소일 수 있습니다.</li>
      <li>예를들어 IPv4의 링크 로컬 범위인 <code class="language-plaintext highlighter-rouge">169.254.0.0/16</code>을 사용하거나, IPv6의 <code class="language-plaintext highlighter-rouge">fd00::/8</code> 범위를 사용하는것이 좋습니다.</li>
    </ul>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>curl <span class="nt">-LO</span> https://raw.githubusercontent.com/kubernetes/kubernetes/refs/heads/master/cluster/addons/dns/nodelocaldns/nodelocaldns.yaml

<span class="c"># 다음 값들은 적절한 값으로 대체 합니다.</span>
<span class="nv">$ kubedns</span><span class="o">=</span><span class="sb">`</span>kubectl get svc kube-dns <span class="nt">-n</span> kube-system <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.spec.clusterIP<span class="o">}</span><span class="sb">`</span> <span class="c"># coredns 의 ClusterIP</span>
<span class="c"># $ domain=&lt;cluster-domain&gt; # 보통 기본값 cluster.local 사용</span>
<span class="nv">$ domain</span><span class="o">=</span>cluster.local
<span class="c"># $ localdns=&lt;node-local-address&gt; # local listen IP address chosen for NodeLocal DNSCache</span>
<span class="nv">$ localdns</span><span class="o">=</span>169.254.20.10
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$kubedns</span> <span class="nv">$domain</span> <span class="nv">$localdns</span>
<span class="c"># =&gt; 10.96.0.10 cluster.local 169.254.1.2</span>

<span class="c"># case 1) kube-proxy가 IPTABLES 모드인 경우</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/__PILLAR__LOCAL__DNS__/</span><span class="nv">$localdns</span><span class="s2">/g; s/__PILLAR__DNS__DOMAIN__/</span><span class="nv">$domain</span><span class="s2">/g; s/__PILLAR__DNS__SERVER__/</span><span class="nv">$kubedns</span><span class="s2">/g"</span> nodelocaldns.yaml
<span class="c"># 이 모드에서는 node-local-dns 포드가 kube-dns 서비스 IP와 &lt;node-local-address&gt;를 모두 수신하므로, 포드는 IP 주소 중 하나를 사용하여 DNS 레코드를 조회할 수 있습니다.</span>

<span class="c"># case 2) kube-proxy가 IPVS 모드인 경우</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/__PILLAR__LOCAL__DNS__/</span><span class="nv">$localdns</span><span class="s2">/g; s/__PILLAR__DNS__DOMAIN__/</span><span class="nv">$domain</span><span class="s2">/g; s/,__PILLAR__DNS__SERVER__//g; s/__PILLAR__CLUSTER__DNS__/</span><span class="nv">$kubedns</span><span class="s2">/g"</span> nodelocaldns.yaml
<span class="c"># - 이 모드에서는`node-local-dns` 포드가 **&lt;node-local-address&gt;**에서만 청취합니다.</span>
<span class="c"># - IPVS 로드 밸런싱에 사용되는 인터페이스가 이미 이 주소를 사용하고 있기 때문에 `node-local-dns` 인터페이스는 kube-dns 클러스터 IP를 바인딩할 수 없습니다.</span>
<span class="c"># - `__PILLAR__UPSTREAM__SERVERS__`는 `node-local-dns` 포드에 의해 채워집니다.</span>

<span class="nv">$ </span>kubectl create <span class="nt">-f</span> nodelocaldns.yaml
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">node-local-dns</code> 포드가 활성화되면 각 클러스터 노드의 <code class="language-plaintext highlighter-rouge">kube-system</code> 네임스페이스에서 실행됩니다.</li>
  <li>이 포드는 캐시 모드에서 CoreDNS를 실행하므로 서로 다른 플러그인이 노출하는 모든 CoreDNS 메트릭을 노드 단위로 사용할 수 있습니다.</li>
  <li><code class="language-plaintext highlighter-rouge">kubectl delete -f &lt;manifest&gt;</code>를 사용하여 DaemonSet을 제거하여 비활성화할 수 있습니다. 변경한 내용을 kubetle 설정으로 되돌려야 합니다.</li>
  <li>kube-dns의 ConfigMap에 지정된 StubDomains 과 upstream servers이 node-local-dns에 의해 사용됩니다.</li>
  <li>iptables 모드일때와 ipvs 모드일때의 차이
<img src="/assets/2025/cilium/w3/20250803_cilium_w3_20.png" alt="img.png" class="image-center" />
<em class="image-caption">iptables 모드일때</em>
<img src="/assets/2025/cilium/w3/20250803_cilium_w3_21.png" alt="img_1.png" class="image-center" />
<em class="image-caption">ipvs 모드일때</em>
    <ul>
      <li>iptables 모드일 때와 ipvs 모드일 때의 차이점은, ipvs 모드에서는 Pod에서 Domain Resolve 요청을 CoreDNS Service의 ClusterIP인 10.96.0.10 IP 주소가 아니라 NodeLocal DNSCache의 CoreDNS가 설정한 Local Address IP인 169.254.25.10 IP 주소로 전송한다는 점입니다.</li>
      <li>따라서 Kubernetes Cluster가 ipvs 모드 kube-proxy를 사용하고 있다면 NodeLocal DNSCache 기법 적용 유무를 변경할 수 없습니다. ipvs 모드에서는 매번 kubelet의 Pod DNS Server 주소를 변경하고 kublet을 재시작해야 합니다. 또한 Pod들도 재시작하여 Pod가 이용하는 DNS Server의 주소가 변경되도록 해야 합니다.</li>
      <li>Kubernetes Cluster가 ipvs kube-proxy 모드를 사용하면 ipvs가 iptables의 NOTRACK Rule 을 무시하고 Loadbalancing 하기 때문입니다.</li>
    </ul>
  </li>
</ul>

<h3 id="nodelocal-dnscache-설치-및-확인">NodeLocal DNSCache 설치 및 확인</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># iptables 확인</span>
<span class="nv">$ </span>iptables-save | <span class="nb">tee </span>before.txt

<span class="c">#</span>
<span class="nv">$ </span>wget https://github.com/kubernetes/kubernetes/raw/master/cluster/addons/dns/nodelocaldns/nodelocaldns.yaml
<span class="c"># =&gt; 2025-08-03 02:19:25 (534 KB/s) - ‘nodelocaldns.yaml’ saved [5377/5377]</span>

<span class="c"># kubedns 는 coredns 서비스의 ClusterIP를 변수 지정</span>
<span class="nv">$ kubedns</span><span class="o">=</span><span class="sb">`</span>kubectl get svc kube-dns <span class="nt">-n</span> kube-system <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.spec.clusterIP<span class="o">}</span><span class="sb">`</span>
<span class="nv">$ domain</span><span class="o">=</span><span class="s1">'cluster.local'</span>    <span class="c">## default 값</span>
<span class="nv">$ localdns</span><span class="o">=</span><span class="s1">'169.254.20.10'</span>  <span class="c">## default 값</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$kubedns</span> <span class="nv">$domain</span> <span class="nv">$localdns</span>
<span class="c"># =&gt; 10.96.0.10 cluster.local 169.254.20.10</span>

<span class="c"># iptables 모드 사용 중으로 아래 명령어 수행</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/__PILLAR__LOCAL__DNS__/</span><span class="nv">$localdns</span><span class="s2">/g; s/__PILLAR__DNS__DOMAIN__/</span><span class="nv">$domain</span><span class="s2">/g; s/__PILLAR__DNS__SERVER__/</span><span class="nv">$kubedns</span><span class="s2">/g"</span> nodelocaldns.yaml

<span class="c"># nodelocaldns 설치</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> nodelocaldns.yaml
<span class="c"># =&gt; serviceaccount/node-local-dns created</span>
<span class="c">#    service/kube-dns-upstream created</span>
<span class="c">#    configmap/node-local-dns created</span>
<span class="c">#    daemonset.apps/node-local-dns created</span>
<span class="c">#    service/node-local-dns created</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>node-local-dns <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                   READY   STATUS              RESTARTS   AGE   IP               NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    node-local-dns-6gzpj   0/1     ContainerCreating   0          10s   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    node-local-dns-c2846   0/1     ContainerCreating   0          10s   192.168.10.101   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl edit cm <span class="nt">-n</span> kube-system node-local-dns <span class="c"># 'cluster.local' 과 '.:53' 에 log, debug 추가</span>
<span class="c"># =&gt; configmap/node-local-dns edited</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system rollout restart ds node-local-dns
<span class="c"># =&gt; daemonset.apps/node-local-dns restarted</span>

<span class="nv">$ </span>kubectl describe cm <span class="nt">-n</span> kube-system node-local-dns
<span class="c"># =&gt; cluster.local:53 {</span>
<span class="c">#        log</span>
<span class="c">#        debug</span>
<span class="c">#        errors</span>
<span class="c">#        cache {</span>
<span class="c">#                success 9984 30</span>
<span class="c">#                denial 9984 5</span>
<span class="c">#        }</span>
<span class="c">#        reload</span>
<span class="c">#        loop</span>
<span class="c">#        bind 169.254.20.10 10.96.0.10</span>
<span class="c">#        forward . __PILLAR__CLUSTER__DNS__ {</span>
<span class="c">#                force_tcp</span>
<span class="c">#        }</span>
<span class="c">#        prometheus :9253</span>
<span class="c">#        health 169.254.20.10:8080</span>
<span class="c">#        }</span>
<span class="c">#    ...</span>
<span class="c">#    .:53 {</span>
<span class="c">#        log</span>
<span class="c">#        debug</span>
<span class="c">#        errors</span>
<span class="c">#        cache 30</span>
<span class="c">#        reload</span>
<span class="c">#        loop</span>
<span class="c">#        bind 169.254.20.10 10.96.0.10</span>
<span class="c">#        forward . __PILLAR__UPSTREAM__SERVERS__</span>
<span class="c">#        prometheus :9253</span>
<span class="c">#        }</span>

<span class="c"># iptables 확인 : 규칙 업데이트까지 다소 시간 소요!</span>
<span class="nv">$ </span>iptables-save | <span class="nb">tee </span>after.txt
<span class="nv">$ </span>diff before.txt after.txt

<span class="c">##</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> filter <span class="nt">-S</span> | <span class="nb">grep</span> <span class="nt">-i</span> dns
<span class="c"># =&gt; -A INPUT -d 10.96.0.10/32 -p udp -m udp --dport 53 -m comment --comment "NodeLocal DNS Cache: allow DNS traffic" -j ACCEPT</span>
<span class="c">#    -A INPUT -d 10.96.0.10/32 -p tcp -m tcp --dport 53 -m comment --comment "NodeLocal DNS Cache: allow DNS traffic" -j ACCEPT</span>
<span class="c">#    -A INPUT -d 169.254.20.10/32 -p udp -m udp --dport 53 -m comment --comment "NodeLocal DNS Cache: allow DNS traffic" -j ACCEPT</span>
<span class="c">#    -A INPUT -d 169.254.20.10/32 -p tcp -m tcp --dport 53 -m comment --comment "NodeLocal DNS Cache: allow DNS traffic" -j ACCEPT</span>
<span class="c">#    -A OUTPUT -s 10.96.0.10/32 -p udp -m udp --sport 53 -m comment --comment "NodeLocal DNS Cache: allow DNS traffic" -j ACCEPT</span>
<span class="c">#    -A OUTPUT -s 10.96.0.10/32 -p tcp -m tcp --sport 53 -m comment --comment "NodeLocal DNS Cache: allow DNS traffic" -j ACCEPT</span>
<span class="c">#    -A OUTPUT -s 169.254.20.10/32 -p udp -m udp --sport 53 -m comment --comment "NodeLocal DNS Cache: allow DNS traffic" -j ACCEPT</span>
<span class="c">#    -A OUTPUT -s 169.254.20.10/32 -p tcp -m tcp --sport 53 -m comment --comment "NodeLocal DNS Cache: allow DNS traffic" -j ACCEPT</span>

<span class="c">##</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> raw <span class="nt">-S</span> | <span class="nb">grep</span> <span class="nt">-i</span> dns
<span class="c"># =&gt; -A PREROUTING -d 10.96.0.10/32 -p udp -m udp --dport 53 -m comment --comment "NodeLocal DNS Cache: skip conntrack" -j NOTRACK</span>
<span class="c">#    -A PREROUTING -d 10.96.0.10/32 -p tcp -m tcp --dport 53 -m comment --comment "NodeLocal DNS Cache: skip conntrack" -j NOTRACK</span>
<span class="c">#    -A PREROUTING -d 169.254.20.10/32 -p udp -m udp --dport 53 -m comment --comment "NodeLocal DNS Cache: skip conntrack" -j NOTRACK</span>
<span class="c">#    -A PREROUTING -d 169.254.20.10/32 -p tcp -m tcp --dport 53 -m comment --comment "NodeLocal DNS Cache: skip conntrack" -j NOTRACK</span>
<span class="c">#    -A OUTPUT -s 10.96.0.10/32 -p tcp -m tcp --sport 8080 -m comment --comment "NodeLocal DNS Cache: skip conntrack" -j NOTRACK</span>
<span class="c">#    -A OUTPUT -d 10.96.0.10/32 -p tcp -m tcp --dport 8080 -m comment --comment "NodeLocal DNS Cache: skip conntrack" -j NOTRACK</span>
<span class="c">#    ...</span>

<span class="c"># logs : </span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system logs <span class="nt">-l</span> k8s-app<span class="o">=</span>kube-dns <span class="nt">-f</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system logs <span class="nt">-l</span> k8s-app<span class="o">=</span>node-local-dns <span class="nt">-f</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> <span class="nb">cat</span> /etc/resolv.conf
<span class="c"># =&gt; search default.svc.cluster.local svc.cluster.local cluster.local</span>
<span class="c">#    nameserver 10.96.0.10</span>
<span class="c">#    options ndots:5</span>

<span class="c"># </span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> nslookup webpod
<span class="c"># kube-dns 로그 확인</span>
<span class="c"># =&gt; [INFO] 172.20.1.80:57227 - 46178 "A IN webpod.default.svc.cluster.local. udp 50 false 512" NOERROR qr,aa,rd 98 0.000729042s</span>
<span class="c">#    [INFO] 172.20.1.80:49087 - 7946 "AAAA IN webpod.default.svc.cluster.local. udp 50 false 512" NOERROR qr,aa,rd 143 0.000557625s</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> nslookup google.com
<span class="c"># kube-dns 로그 확인</span>
<span class="c"># =&gt; [INFO] 172.20.1.80:52008 - 19063 "A IN google.com.default.svc.cluster.local. udp 54 false 512" NXDOMAIN qr,aa,rd 147 0.000802417s</span>
<span class="c">#    [INFO] 172.20.1.80:53056 - 1029 "A IN google.com.svc.cluster.local. udp 46 false 512" NXDOMAIN qr,aa,rd 139 0.000377583s</span>
<span class="c">#    [INFO] 172.20.1.80:40165 - 2061 "A IN google.com.cluster.local. udp 42 false 512" NXDOMAIN qr,aa,rd 135 0.000287959s</span>
<span class="c">#    [INFO] 172.20.1.80:42852 - 42332 "A IN google.com. udp 28 false 512" NOERROR qr,aa,rd,ra 54 0.000450083s</span>
<span class="c">#    [INFO] 172.20.1.80:52047 - 947 "AAAA IN google.com. udp 28 false 512" NOERROR qr,aa,rd,ra 66 0.000662125s</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 로그가 kube-dns 쪽에만 쌓입니다.&lt;/span&gt;</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl delete pod curl-pod

<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: curl-pod
  labels:
    app: curl
spec:
  containers:
  - name: curl
    image: nicolaka/netshoot
    command: ["tail"]
    args: ["-f", "/dev/null"]
  terminationGracePeriodSeconds: 0
</span><span class="no">EOF
</span><span class="c"># =&gt; pod/curl-pod created</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> <span class="nb">cat</span> /etc/resolv.conf
<span class="c"># =&gt; search default.svc.cluster.local svc.cluster.local cluster.local</span>
<span class="c">#    nameserver 10.96.0.10</span>
<span class="c">#    options ndots:5</span>

<span class="c"># 로그 확인 시 현재 nodelocaldns 미활용! </span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system logs <span class="nt">-l</span> k8s-app<span class="o">=</span>kube-dns <span class="nt">-f</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system logs <span class="nt">-l</span> k8s-app<span class="o">=</span>node-local-dns <span class="nt">-f</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> nslookup webpod
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> nslookup google.com
</code></pre></div></div>

<ul>
  <li>위의 예제에서는 아직 NodeLocal DNSCache를 사용하지 않고 있습니다.</li>
</ul>

<h3 id="cilium-local-redirect-policy">Cilium Local Redirect Policy</h3>

<ul>
  <li><code class="language-plaintext highlighter-rouge">--set localRedirectPolicy=true</code> 해서 Local Redirect Policy를 활성화하면, Cilium은 NodeLocal DNSCache를 사용하여 DNS 요청을 처리합니다. <a href="https://docs.cilium.io/en/stable/network/kubernetes/local-redirect-policy/">Docs</a></li>
  <li>IP 주소와 Port/Protocol tuple 또는 <strong>Kubernetes Service</strong> 로 향하는 포드 <strong>트래픽</strong>을 eBPF를 사용하여 노드 내 <strong>백엔드 포드로 로컬로 리디렉션</strong>할 수 있도록 하는 Cilium의 로컬 리디렉션 정책을 구성하는 방법을 설명합니다.</li>
  <li>백엔드 포드의 네임스페이스는 정책의 네임스페이스와 일치해야 합니다.</li>
  <li>CiliumLocalRedirectPolicy는 CustomResourceDefinition으로 구성되어 있습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--namespace</span> kube-system <span class="nt">--reuse-values</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">localRedirectPolicy</span><span class="o">=</span><span class="nb">true</span>

<span class="nv">$ </span>kubectl rollout restart deploy cilium-operator <span class="nt">-n</span> kube-system
<span class="c"># =&gt; deployment.apps/cilium-operator restarted</span>
<span class="nv">$ </span>kubectl rollout restart ds cilium <span class="nt">-n</span> kube-system
<span class="c"># =&gt; daemonset.apps/cilium restarted</span>

<span class="c">#</span>
<span class="nv">$ </span>wget https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/kubernetes-local-redirect/node-local-dns.yaml

<span class="nv">$ kubedns</span><span class="o">=</span><span class="si">$(</span>kubectl get svc kube-dns <span class="nt">-n</span> kube-system <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.spec.clusterIP<span class="o">}</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/__PILLAR__DNS__SERVER__/</span><span class="nv">$kubedns</span><span class="s2">/g;"</span> node-local-dns.yaml
<span class="nv">$ </span>vi <span class="nt">-d</span> nodelocaldns.yaml node-local-dns.yaml
</code></pre></div></div>

<ul>
  <li>nodelocaldns.yaml과 node-local-dns.yaml의 diff 결과 
<img src="/assets/2025/cilium/w3/20250803_cilium_w3_22.png" alt="img.png" />
<img src="/assets/2025/cilium/w3/20250803_cilium_w3_23.png" alt="img_1.png" /></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">## before</span>
<span class="c"># args: [ "-localip", "169.254.20.10,10.96.0.10", "-conf", "/etc/Corefile", "-upstreamsvc", "kube-dns-upstream" ]</span>

<span class="c">## after</span>
<span class="c"># args: [ "-localip", "169.254.20.10,10.96.0.10", "-conf", "/etc/Corefile", "-upstreamsvc", "kube-dns-upstream", "-skipteardown=true", "-setupinterface=false", "-setupiptables=false" ]</span>


<span class="c"># 배포</span>
<span class="c"># Modify Node-local DNS cache’s deployment yaml to pass these additional arguments to node-cache: </span>
<span class="c">## -skipteardown=true, -setupinterface=false, and -setupiptables=false.</span>

<span class="c"># Modify Node-local DNS cache’s deployment yaml to put it in non-host namespace by setting hostNetwork: false for the daemonset.</span>
<span class="c"># In the Corefile, bind to 0.0.0.0 instead of the static IP.</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> node-local-dns.yaml
<span class="c"># =&gt; serviceaccount/node-local-dns configured</span>
<span class="c">#    service/kube-dns-upstream configured</span>
<span class="c">#    configmap/node-local-dns configured</span>
<span class="c">#    daemonset.apps/node-local-dns configured</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl edit cm <span class="nt">-n</span> kube-system node-local-dns <span class="c"># log, debug 추가</span>
<span class="c"># =&gt; configmap/node-local-dns edited</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system rollout restart ds node-local-dns
<span class="c"># =&gt; daemonset.apps/node-local-dns restarted</span>

<span class="nv">$ </span>kubectl describe cm <span class="nt">-n</span> kube-system node-local-dns
<span class="c"># =&gt; ...</span>
<span class="c">#    cluster.local:53 {</span>
<span class="c">#        log</span>
<span class="c">#        debug</span>
<span class="c">#        errors</span>
<span class="c">#        cache {</span>
<span class="c">#                success 9984 30</span>
<span class="c">#                denial 9984 5</span>
<span class="c">#        }</span>
<span class="c">#        reload</span>
<span class="c">#        loop</span>
<span class="c">#        bind 0.0.0.0</span>
<span class="c">#        forward . __PILLAR__CLUSTER__DNS__ {</span>
<span class="c">#                force_tcp</span>
<span class="c">#        }</span>
<span class="c">#        prometheus :9253</span>
<span class="c">#        health</span>
<span class="c">#        }</span>
<span class="c">#    ...</span>
<span class="c">#    .:53 {</span>
<span class="c">#        log</span>
<span class="c">#        debug</span>
<span class="c">#        errors</span>
<span class="c">#        cache 30</span>
<span class="c">#        reload</span>
<span class="c">#        loop</span>
<span class="c">#        bind 0.0.0.0</span>
<span class="c">#        forward . __PILLAR__UPSTREAM__SERVERS__</span>
<span class="c">#        prometheus :9253</span>
<span class="c">#        }</span>
<span class="c">#    ...</span>

<span class="c">#</span>
<span class="nv">$ </span>wget https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/kubernetes-local-redirect/node-local-dns-lrp.yaml
<span class="nv">$ </span><span class="nb">cat </span>node-local-dns-lrp.yaml
<span class="c"># =&gt; apiVersion: "cilium.io/v2"</span>
<span class="c">#    kind: CiliumLocalRedirectPolicy</span>
<span class="c">#    metadata:</span>
<span class="c">#      name: "nodelocaldns"</span>
<span class="c">#      namespace: kube-system</span>
<span class="c">#    spec:</span>
<span class="c">#      redirectFrontend:</span>
<span class="c">#        serviceMatcher:</span>
<span class="c">#          serviceName: kube-dns</span>
<span class="c">#          namespace: kube-system</span>
<span class="c">#      redirectBackend:</span>
<span class="c">#        localEndpointSelector:</span>
<span class="c">#          matchLabels:</span>
<span class="c">#            k8s-app: node-local-dns</span>
<span class="c">#        toPorts:</span>
<span class="c">#          - port: "53"</span>
<span class="c">#            name: dns</span>
<span class="c">#            protocol: UDP</span>
<span class="c">#          - port: "53"</span>
<span class="c">#            name: dns-tcp</span>
<span class="c">#            protocol: TCP</span>
        
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/kubernetes-local-redirect/node-local-dns-lrp.yaml
<span class="c"># =&gt; ciliumlocalredirectpolicy.cilium.io/nodelocaldns created</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get CiliumLocalRedirectPolicy <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE     NAME           AGE</span>
<span class="c">#    kube-system   nodelocaldns   8s</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium-dbg lrp list
<span class="c"># =&gt; LRP namespace   LRP name       FrontendType                Matching Service</span>
<span class="c">#    kube-system     nodelocaldns   clusterIP + all svc ports   kube-system/kube-dns</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium-dbg service list | <span class="nb">grep </span>LocalRedirect
<span class="c"># =&gt; 16   10.96.0.10:53/UDP       LocalRedirect   1 =&gt; 172.20.0.73:53/UDP (active)</span>
<span class="c">#    17   10.96.0.10:53/TCP       LocalRedirect   1 =&gt; 172.20.0.73:53/TCP (active)</span>

<span class="c"># logs</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system logs <span class="nt">-l</span> k8s-app<span class="o">=</span>kube-dns <span class="nt">-f</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system logs <span class="nt">-l</span> k8s-app<span class="o">=</span>node-local-dns <span class="nt">-f</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> nslookup www.google.com
<span class="c"># =&gt; Server:         10.96.0.10</span>
<span class="c">#    Address:        10.96.0.10#53</span>
<span class="c">#    </span>
<span class="c">#    Non-authoritative answer:</span>
<span class="c">#    Name:   www.google.com</span>
<span class="c">#    Address: 142.250.206.228</span>
<span class="c">#    Name:   www.google.com</span>
<span class="c">#    Address: 2404:6800:400a:804::2004</span>

<span class="c"># kube-dns 로그 확인</span>
<span class="c"># =&gt; [INFO] 172.20.1.178:55860 - 32731 "A IN www.google.com.default.svc.cluster.local. tcp 58 false 65535" NXDOMAIN qr,aa,rd 151 0.002254584s</span>
<span class="c">#    [INFO] 172.20.1.178:55860 - 50477 "A IN www.google.com.svc.cluster.local. tcp 50 false 65535" NXDOMAIN qr,aa,rd 143 0.000426625s</span>
<span class="c">#    [INFO] 172.20.1.178:55860 - 42463 "A IN www.google.com.cluster.local. tcp 46 false 65535" NXDOMAIN qr,aa,rd 139 0.000225583s</span>

<span class="c"># node-local-dns 로그 확인</span>
<span class="c"># =&gt; [INFO] 172.20.1.20:52275 - 32731 "A IN www.google.com.default.svc.cluster.local. udp 58 false 512" NXDOMAIN qr,aa,rd 151 0.009171834s</span>
<span class="c">#    [INFO] 172.20.1.20:60077 - 50477 "A IN www.google.com.svc.cluster.local. udp 50 false 512" NXDOMAIN qr,aa,rd 143 0.001657537s</span>
<span class="c">#    [INFO] 172.20.1.20:48089 - 42463 "A IN www.google.com.cluster.local. udp 46 false 512" NXDOMAIN qr,aa,rd 139 0.001401951s</span>
<span class="c">#    [INFO] 172.20.1.20:58721 - 18703 "A IN www.google.com. udp 32 false 512" NOERROR qr,rd,ra 62 0.046337824s</span>
<span class="c">#    [INFO] 172.20.1.20:42914 - 43270 "AAAA IN www.google.com. udp 32 false 512" NOERROR qr,rd,ra 74 0.042382055s</span>

<span class="c"># 한번더 dns 조회</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> nslookup www.google.com
<span class="c"># =&gt; Server:         10.96.0.10</span>
<span class="c">#    Address:        10.96.0.10#53</span>
<span class="c">#    </span>
<span class="c">#    Non-authoritative answer:</span>
<span class="c">#    Name:   www.google.com</span>
<span class="c">#    Address: 142.250.206.228</span>
<span class="c">#    Name:   www.google.com</span>
<span class="c">#    Address: 2404:6800:400a:804::2004</span>

<span class="c"># kube-dns 로그 확인</span>
<span class="c"># =&gt; (로그 없음)</span>

<span class="c"># node-local-dns 로그 확인</span>
<span class="c"># =&gt; [INFO] 172.20.1.20:52275 - 32731 "A IN www.google.com.default.svc.cluster.local. udp 58 false 512" NXDOMAIN qr,aa,rd 151 0.009171834s</span>
<span class="c">#    [INFO] 172.20.1.20:60077 - 50477 "A IN www.google.com.svc.cluster.local. udp 50 false 512" NXDOMAIN qr,aa,rd 143 0.001657537s</span>
<span class="c">#    [INFO] 172.20.1.20:48089 - 42463 "A IN www.google.com.cluster.local. udp 46 false 512" NXDOMAIN qr,aa,rd 139 0.001401951s</span>
<span class="c">#    [INFO] 172.20.1.20:58721 - 18703 "A IN www.google.com. udp 32 false 512" NOERROR qr,rd,ra 62 0.046337824s</span>
<span class="c">#    [INFO] 172.20.1.20:42914 - 43270 "AAAA IN www.google.com. udp 32 false 512" NOERROR qr,rd,ra 74 0.042382055s</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 연속 조회시 node-local-dns에 캐시가 되어서 kube-dns의 조회가 줄어듬을 확인할 수 있습니다.&lt;/span&gt;</span>

<span class="c"># nodelocaldns 에 캐시된 정보로 바로 질의 응답 확인!</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system logs <span class="nt">-l</span> k8s-app<span class="o">=</span>node-local-dns <span class="nt">-f</span>
<span class="c"># =&gt; [INFO] 172.20.1.20:52275 - 32731 "A IN www.google.com.default.svc.cluster.local. udp 58 false 512" NXDOMAIN qr,aa,rd 151 0.009171834s</span>
<span class="c">#    [INFO] 172.20.1.20:60077 - 50477 "A IN www.google.com.svc.cluster.local. udp 50 false 512" NXDOMAIN qr,aa,rd 143 0.001657537s</span>
<span class="c">#    [INFO] 172.20.1.20:48089 - 42463 "A IN www.google.com.cluster.local. udp 46 false 512" NXDOMAIN qr,aa,rd 139 0.001401951s</span>
<span class="c">#    [INFO] 172.20.1.20:58721 - 18703 "A IN www.google.com. udp 32 false 512" NOERROR qr,rd,ra 62 0.046337824s</span>
<span class="c">#    [INFO] 172.20.1.20:42914 - 43270 "AAAA IN www.google.com. udp 32 false 512" NOERROR qr,rd,ra 74 0.042382055s</span>
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w3/20250803_cilium_w3_24.png" alt="img.png" class="image-center" /></p>

<hr />

<h2 id="마치며">마치며</h2>

<p>이번 포스트에서는 노드의 파드 들간 통신과 외부와의 통신, DNS 요청을 처리하는 방법에 대해 알아보았습니다.
네트워크는 볼때마다 어려운것 같습니다. :sweat_smile: 
하지만 조금씩 이해가 되고, 익숙해지는 것 같습니다. 한걸음 한걸음 나아가고 있는것이 느껴집니다.</p>

<p>다양한 주제에 걸쳐 배웠는데, 모든 파트에서 수 많은 사람들이 조금이라도 네트워크를 효율적으로 하기위해서
애쓴 흔적들을 볼 수 있었습니다. 그런 분들이 있어서 지금 이렇게 인터넷을 사용하고 클라우드를 이용할 수 있으니
한번도 뵌적은 없지만 그분들에게 감사의 마음을 전합니다. :pray:</p>

<hr />

<h2 id="부록">부록</h2>

<h3 id="k9s-주요-단축키">K9s 주요 단축키</h3>

<table>
  <thead>
    <tr>
      <th><strong>Action</strong></th>
      <th><strong>Command</strong></th>
      <th><strong>Comment</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Show active keyboard mnemonics and help</td>
      <td><code class="language-plaintext highlighter-rouge">?</code></td>
      <td> </td>
    </tr>
    <tr>
      <td>Show all available resource alias</td>
      <td><code class="language-plaintext highlighter-rouge">ctrl-a</code></td>
      <td> </td>
    </tr>
    <tr>
      <td>To bail out of K9s</td>
      <td><code class="language-plaintext highlighter-rouge">:quit</code> <code class="language-plaintext highlighter-rouge">:q</code> <code class="language-plaintext highlighter-rouge">ctrl-c</code></td>
      <td> </td>
    </tr>
    <tr>
      <td>To go up/back to the previous view</td>
      <td><code class="language-plaintext highlighter-rouge">esc</code></td>
      <td>If you have crumbs on, this will go to the previous one</td>
    </tr>
    <tr>
      <td>View a Kubernetes resource using singular/plural or short-name</td>
      <td><code class="language-plaintext highlighter-rouge">:pod</code></td>
      <td>accepts singular, plural, short-name or alias ie pod or pods</td>
    </tr>
    <tr>
      <td>View a Kubernetes resource in a given namespace</td>
      <td><code class="language-plaintext highlighter-rouge">:pod ns-x</code></td>
      <td> </td>
    </tr>
    <tr>
      <td>View filtered pods (New v0.30.0!)</td>
      <td><code class="language-plaintext highlighter-rouge">:pod /fred</code></td>
      <td>View all pods filtered by fred</td>
    </tr>
    <tr>
      <td>View labeled pods (New v0.30.0!)</td>
      <td><code class="language-plaintext highlighter-rouge">:pod app=fred,env=dev</code></td>
      <td>View all pods with labels matching app=fred and env=dev</td>
    </tr>
    <tr>
      <td>View pods in a given context (New v0.30.0!)</td>
      <td><code class="language-plaintext highlighter-rouge">:pod @ctx1</code></td>
      <td>View all pods in context ctx1. Switches out your current k9s context!</td>
    </tr>
    <tr>
      <td>Filter out a resource view given a filter</td>
      <td><code class="language-plaintext highlighter-rouge">/filter</code></td>
      <td>Regex2 supported ie <code class="language-plaintext highlighter-rouge">fred</code></td>
    </tr>
    <tr>
      <td>Inverse regex filter</td>
      <td><code class="language-plaintext highlighter-rouge">/! filter</code></td>
      <td>Keep everything that <em>doesn’t</em> match.</td>
    </tr>
    <tr>
      <td>Filter resource view by labels</td>
      <td><code class="language-plaintext highlighter-rouge">/-l label-selector</code></td>
      <td> </td>
    </tr>
    <tr>
      <td>Fuzzy find a resource given a filter</td>
      <td><code class="language-plaintext highlighter-rouge">/-f filter</code></td>
      <td> </td>
    </tr>
    <tr>
      <td>Bails out of view/command/filter mode</td>
      <td><code class="language-plaintext highlighter-rouge">&lt;esc&gt;</code></td>
      <td> </td>
    </tr>
    <tr>
      <td>Key mapping to describe, view, edit, view logs,…</td>
      <td><code class="language-plaintext highlighter-rouge">d</code>, <code class="language-plaintext highlighter-rouge">v</code>, <code class="language-plaintext highlighter-rouge">e</code>, <code class="language-plaintext highlighter-rouge">l</code>,…</td>
      <td> </td>
    </tr>
    <tr>
      <td>To view and switch to another Kubernetes context (Pod view)</td>
      <td><code class="language-plaintext highlighter-rouge">:ctx</code></td>
      <td> </td>
    </tr>
    <tr>
      <td>To view and switch directly to another Kubernetes context (Last used view)</td>
      <td><code class="language-plaintext highlighter-rouge">:ctx context-name</code></td>
      <td> </td>
    </tr>
    <tr>
      <td>To view and switch to another Kubernetes namespace</td>
      <td><code class="language-plaintext highlighter-rouge">:ns</code></td>
      <td> </td>
    </tr>
    <tr>
      <td>To switch back to the last active command (like how “cd -“ works)</td>
      <td><code class="language-plaintext highlighter-rouge">-</code></td>
      <td>Navigation that adds breadcrumbs to the bottom are not commands</td>
    </tr>
    <tr>
      <td>To go back and forward through the command history</td>
      <td>back: <code class="language-plaintext highlighter-rouge">[</code>, forward: <code class="language-plaintext highlighter-rouge">]</code></td>
      <td>Same as above</td>
    </tr>
    <tr>
      <td>To view all saved resources</td>
      <td><code class="language-plaintext highlighter-rouge">:screendump</code> or <code class="language-plaintext highlighter-rouge">:sd</code></td>
      <td> </td>
    </tr>
    <tr>
      <td>To delete a resource (TAB and ENTER to confirm)</td>
      <td><code class="language-plaintext highlighter-rouge">ctrl-d</code></td>
      <td> </td>
    </tr>
    <tr>
      <td>To kill a resource (no confirmation dialog, equivalent to kubectl delete –now)</td>
      <td><code class="language-plaintext highlighter-rouge">ctrl-k</code></td>
      <td> </td>
    </tr>
    <tr>
      <td>Launch pulses view</td>
      <td><code class="language-plaintext highlighter-rouge">:pulses</code> or <code class="language-plaintext highlighter-rouge">:pu</code></td>
      <td> </td>
    </tr>
    <tr>
      <td>Launch XRay view</td>
      <td><code class="language-plaintext highlighter-rouge">:xray RESOURCE [NAMESPACE]</code></td>
      <td>RESOURCE can be one of po, <strong>svc</strong>, dp, rs, sts, ds, NAMESPACE is optional</td>
    </tr>
    <tr>
      <td>Launch Popeye view</td>
      <td><code class="language-plaintext highlighter-rouge">:popeye</code> or <code class="language-plaintext highlighter-rouge">:pop</code></td>
      <td>See <a href="https://github.com/derailed/k9s#popeye">popeye</a></td>
    </tr>
  </tbody>
</table>]]></content><author><name></name></author><category term="cilium" /><category term="kubernetes," /><category term="network," /><category term="linux," /><category term="cilium," /><category term="ipam," /><category term="routing," /><category term="masquerading," /><category term="coredns," /><category term="nodelocaldns" /><summary type="html"><![CDATA[Cilium의 Networking에 대해 살펴보겠습니다. Cilium이 어떻게 노드에 있는 파드들 간의 통신을 처리하는지, IP 주소 할당(IPAM), 라우팅, 마스커레이딩, DNS 설정 등을 다룰 것입니다.]]></summary></entry><entry><title type="html">[Cilium] (Observability) Hubble, Prometheus, Grafana</title><link href="https://sweetlittlebird.github.io/posts/2025-07-27-Cilium-Week2/" rel="alternate" type="text/html" title="[Cilium] (Observability) Hubble, Prometheus, Grafana" /><published>2025-07-27T00:10:18+09:00</published><updated>2025-07-27T00:10:18+09:00</updated><id>https://sweetlittlebird.github.io/posts/Cilium%20-%20Week2</id><content type="html" xml:base="https://sweetlittlebird.github.io/posts/2025-07-27-Cilium-Week2/"><![CDATA[<h2 id="들어가며">들어가며</h2>

<p>이번에는 Hubble, Prometheus, Grafana 등을 이용하여 Cilium의 관측성(Observability)에 대해 살펴보겠습니다.</p>

<hr />

<h2 id="실습-환경-구성">실습 환경 구성</h2>

<ul>
  <li>실습 환경 소개</li>
</ul>

<p>실습 환경은 지난주와 거의 유사합니다. 단, 파드 IP 대역이 <code class="language-plaintext highlighter-rouge">10.244.0.0/16</code>에서 <code class="language-plaintext highlighter-rouge">172.20.0.0/16</code>으로 변경되었습니다.</p>

<p><img src="/assets/2025/cilium/w2/20250727_cilium_w2_1.png" alt="img.png" /></p>

<ul>
  <li>배포 가상 머신은 컨트롤플레인인 k8s-ctr, 워커노드 k8s-w1, k8s-w2로 구성되어 있습니다.
    <ul>
      <li>eth0 : 10.0.2.15 (모든 노드가 동일)</li>
      <li>eth1 : 192.168.10.100~102</li>
    </ul>
  </li>
  <li>초기 프로비저닝시 <code class="language-plaintext highlighter-rouge">kubeadm init</code>과 <code class="language-plaintext highlighter-rouge">join</code> 을 실행하여 클러스터를 구성하며, <strong>이번에는 Cilium CNI가 설치된 상태로 배포됩니다</strong>.</li>
</ul>

<h3 id="실습-환경-배포-파일-작성">실습 환경 배포 파일 작성</h3>

<h4 id="vagrantfile"><strong>Vagrantfile</strong></h4>
<ul>
  <li>가상머신을 정의하고 부팅시 실행할 프로비저닝 설정을 합니다.</li>
</ul>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Variables</span>
<span class="no">K8SV</span> <span class="o">=</span> <span class="s1">'1.33.2-1.1'</span> <span class="c1"># Kubernetes Version : apt list -a kubelet , ex) 1.32.5-1.1</span>
<span class="no">CONTAINERDV</span> <span class="o">=</span> <span class="s1">'1.7.27-1'</span> <span class="c1"># Containerd Version : apt list -a containerd.io , ex) 1.6.33-1</span>
<span class="no">CILIUMV</span> <span class="o">=</span> <span class="s1">'1.17.6'</span> <span class="c1"># Cilium CNI Version : https://github.com/cilium/cilium/tags</span>
<span class="no">N</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1"># max number of worker nodes</span>

<span class="c1"># Base Image  https://portal.cloud.hashicorp.com/vagrant/discover/bento/ubuntu-24.04</span>
<span class="no">BOX_IMAGE</span> <span class="o">=</span> <span class="s2">"bento/ubuntu-24.04"</span>
<span class="no">BOX_VERSION</span> <span class="o">=</span> <span class="s2">"202502.21.0"</span>

<span class="no">Vagrant</span><span class="p">.</span><span class="nf">configure</span><span class="p">(</span><span class="s2">"2"</span><span class="p">)</span> <span class="k">do</span> <span class="o">|</span><span class="n">config</span><span class="o">|</span>
  <span class="c1">#-ControlPlane Node</span>
  <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">define</span> <span class="s2">"k8s-ctr"</span> <span class="k">do</span> <span class="o">|</span><span class="n">subconfig</span><span class="o">|</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="no">BOX_IMAGE</span>

    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box_version</span> <span class="o">=</span> <span class="no">BOX_VERSION</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provider</span> <span class="s2">"virtualbox"</span> <span class="k">do</span> <span class="o">|</span><span class="n">vb</span><span class="o">|</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--groups"</span><span class="p">,</span> <span class="s2">"/Cilium-Lab"</span><span class="p">]</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--nicpromisc2"</span><span class="p">,</span> <span class="s2">"allow-all"</span><span class="p">]</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">name</span> <span class="o">=</span> <span class="s2">"k8s-ctr"</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">cpus</span> <span class="o">=</span> <span class="mi">2</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">memory</span> <span class="o">=</span> <span class="mi">2048</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">linked_clone</span> <span class="o">=</span> <span class="kp">true</span>
    <span class="k">end</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">host_name</span> <span class="o">=</span> <span class="s2">"k8s-ctr"</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.10.100"</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="mi">60000</span><span class="p">,</span> <span class="ss">auto_correct: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">id: </span><span class="s2">"ssh"</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">synced_folder</span> <span class="s2">"./"</span><span class="p">,</span> <span class="s2">"/vagrant"</span><span class="p">,</span> <span class="ss">disabled: </span><span class="kp">true</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"init_cfg.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">K8SV</span><span class="p">,</span> <span class="no">CONTAINERDV</span> <span class="p">]</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"k8s-ctr.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">N</span><span class="p">,</span> <span class="no">CILIUMV</span> <span class="p">]</span>
  <span class="k">end</span>

  <span class="c1">#-Worker Nodes Subnet1</span>
  <span class="p">(</span><span class="mi">1</span><span class="o">..</span><span class="no">N</span><span class="p">).</span><span class="nf">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">i</span><span class="o">|</span>
    <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">define</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span> <span class="k">do</span> <span class="o">|</span><span class="n">subconfig</span><span class="o">|</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="no">BOX_IMAGE</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box_version</span> <span class="o">=</span> <span class="no">BOX_VERSION</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provider</span> <span class="s2">"virtualbox"</span> <span class="k">do</span> <span class="o">|</span><span class="n">vb</span><span class="o">|</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--groups"</span><span class="p">,</span> <span class="s2">"/Cilium-Lab"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--nicpromisc2"</span><span class="p">,</span> <span class="s2">"allow-all"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">name</span> <span class="o">=</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">cpus</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">memory</span> <span class="o">=</span> <span class="mi">1536</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">linked_clone</span> <span class="o">=</span> <span class="kp">true</span>
      <span class="k">end</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">host_name</span> <span class="o">=</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.10.10</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="s2">"6000</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span> <span class="ss">auto_correct: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">id: </span><span class="s2">"ssh"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">synced_folder</span> <span class="s2">"./"</span><span class="p">,</span> <span class="s2">"/vagrant"</span><span class="p">,</span> <span class="ss">disabled: </span><span class="kp">true</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"init_cfg.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">K8SV</span><span class="p">,</span> <span class="no">CONTAINERDV</span><span class="p">]</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"k8s-w.sh"</span>
    <span class="k">end</span>
  <span class="k">end</span>
<span class="k">end</span>
</code></pre></div></div>

<h4 id="init_cfgsh"><strong>init_cfg.sh</strong></h4>
<ul>
  <li>프로비저닝시 vagrant가 실행할 초기 설정 스크립트입니다. arguments로 Kubernetes 버전과 Containerd 버전등을 받아서 설치합니다.</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>

<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config Start &lt;&lt;&lt;&lt;"</span>

<span class="nb">echo</span> <span class="s2">"[TASK 1] Setting Profile &amp; Bashrc"</span>
<span class="nb">echo</span> <span class="s1">'alias vi=vim'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s2">"sudo su -"</span> <span class="o">&gt;&gt;</span> /home/vagrant/.bashrc
<span class="nb">ln</span> <span class="nt">-sf</span> /usr/share/zoneinfo/Asia/Seoul /etc/localtime <span class="c"># Change Timezone</span>

<span class="nb">echo</span> <span class="s2">"[TASK 2] Disable AppArmor"</span>
systemctl stop ufw <span class="o">&amp;&amp;</span> systemctl disable ufw <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
systemctl stop apparmor <span class="o">&amp;&amp;</span> systemctl disable apparmor <span class="o">&gt;</span>/dev/null 2&gt;&amp;1

<span class="nb">echo</span> <span class="s2">"[TASK 3] Disable and turn off SWAP"</span>
swapoff <span class="nt">-a</span> <span class="o">&amp;&amp;</span> <span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'/swap/s/^/#/'</span> /etc/fstab

<span class="nb">echo</span> <span class="s2">"[TASK 4] Install Packages"</span>
apt update <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
apt-get <span class="nb">install </span>apt-transport-https ca-certificates curl gpg <span class="nt">-y</span> <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1

<span class="c"># Download the public signing key for the Kubernetes package repositories.</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> <span class="nt">-m</span> 755 /etc/apt/keyrings
<span class="nv">K8SMMV</span><span class="o">=</span><span class="si">$(</span><span class="nb">echo</span> <span class="nv">$1</span> | <span class="nb">sed</span> <span class="nt">-En</span> <span class="s1">'s/^([0-9]+\.[0-9]+)\..*/\1/p'</span><span class="si">)</span>
curl <span class="nt">-fsSL</span> https://pkgs.k8s.io/core:/stable:/v<span class="nv">$K8SMMV</span>/deb/Release.key | <span class="nb">sudo </span>gpg <span class="nt">--dearmor</span> <span class="nt">-o</span> /etc/apt/keyrings/kubernetes-apt-keyring.gpg
<span class="nb">echo</span> <span class="s2">"deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v</span><span class="nv">$K8SMMV</span><span class="s2">/deb/ /"</span> <span class="o">&gt;&gt;</span> /etc/apt/sources.list.d/kubernetes.list
curl <span class="nt">-fsSL</span> https://download.docker.com/linux/ubuntu/gpg <span class="nt">-o</span> /etc/apt/keyrings/docker.asc
<span class="nb">echo</span> <span class="s2">"deb [arch=</span><span class="si">$(</span>dpkg <span class="nt">--print-architecture</span><span class="si">)</span><span class="s2"> signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu </span><span class="si">$(</span><span class="nb">.</span> /etc/os-release <span class="o">&amp;&amp;</span> <span class="nb">echo</span> <span class="s2">"</span><span class="nv">$VERSION_CODENAME</span><span class="s2">"</span><span class="si">)</span><span class="s2"> stable"</span> | <span class="nb">tee</span> /etc/apt/sources.list.d/docker.list <span class="o">&gt;</span> /dev/null

<span class="c"># packets traversing the bridge are processed by iptables for filtering</span>
<span class="nb">echo </span>1 <span class="o">&gt;</span> /proc/sys/net/ipv4/ip_forward
<span class="nb">echo</span> <span class="s2">"net.ipv4.ip_forward = 1"</span> <span class="o">&gt;&gt;</span> /etc/sysctl.d/k8s.conf

<span class="c"># enable br_netfilter for iptables </span>
modprobe br_netfilter
modprobe overlay
<span class="nb">echo</span> <span class="s2">"br_netfilter"</span> <span class="o">&gt;&gt;</span> /etc/modules-load.d/k8s.conf
<span class="nb">echo</span> <span class="s2">"overlay"</span> <span class="o">&gt;&gt;</span> /etc/modules-load.d/k8s.conf

<span class="nb">echo</span> <span class="s2">"[TASK 5] Install Kubernetes components (kubeadm, kubelet and kubectl)"</span>
<span class="c"># Update the apt package index, install kubelet, kubeadm and kubectl, and pin their version</span>
apt update <span class="o">&gt;</span>/dev/null 2&gt;&amp;1

<span class="c"># apt list -a kubelet ; apt list -a containerd.io</span>
apt-get <span class="nb">install</span> <span class="nt">-y</span> <span class="nv">kubelet</span><span class="o">=</span><span class="nv">$1</span> <span class="nv">kubectl</span><span class="o">=</span><span class="nv">$1</span> <span class="nv">kubeadm</span><span class="o">=</span><span class="nv">$1</span> containerd.io<span class="o">=</span><span class="nv">$2</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
apt-mark hold kubelet kubeadm kubectl <span class="o">&gt;</span>/dev/null 2&gt;&amp;1

<span class="c"># containerd configure to default and cgroup managed by systemd</span>
containerd config default <span class="o">&gt;</span> /etc/containerd/config.toml
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'s/SystemdCgroup = false/SystemdCgroup = true/g'</span> /etc/containerd/config.toml

<span class="c"># avoid WARN&amp;ERRO(default endpoints) when crictl run  </span>
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; /etc/crictl.yaml
runtime-endpoint: unix:///run/containerd/containerd.sock
image-endpoint: unix:///run/containerd/containerd.sock
</span><span class="no">EOF

</span><span class="c"># ready to install for k8s </span>
systemctl restart containerd <span class="o">&amp;&amp;</span> systemctl <span class="nb">enable </span>containerd
systemctl <span class="nb">enable</span> <span class="nt">--now</span> kubelet

<span class="nb">echo</span> <span class="s2">"[TASK 6] Install Packages &amp; Helm"</span>
<span class="nb">export </span><span class="nv">DEBIAN_FRONTEND</span><span class="o">=</span>noninteractive
apt-get <span class="nb">install</span> <span class="nt">-y</span> bridge-utils sshpass net-tools conntrack ngrep tcpdump ipset arping wireguard jq tree bash-completion unzip kubecolor termshark <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
curl <span class="nt">-s</span> https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash <span class="o">&gt;</span>/dev/null 2&gt;&amp;1

<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div></div>

<h4 id="k8s-ctrsh"><strong>k8s-ctr.sh</strong></h4>
<ul>
  <li><code class="language-plaintext highlighter-rouge">kubeadm init</code>으로 컨트롤플레인을 설정하고, Cilium CNI를 설치합니다. 또한 편의를 위한 <code class="language-plaintext highlighter-rouge">k</code>, <code class="language-plaintext highlighter-rouge">kc</code> 등의 alias를 설정합니다.</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>

<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Controlplane config Start &lt;&lt;&lt;&lt;"</span>

<span class="nb">echo</span> <span class="s2">"[TASK 1] Initial Kubernetes"</span>
curl <span class="nt">--silent</span> <span class="nt">-o</span> /root/kubeadm-init-ctr-config.yaml https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/2w/kubeadm-init-ctr-config.yaml
kubeadm init <span class="nt">--config</span><span class="o">=</span><span class="s2">"/root/kubeadm-init-ctr-config.yaml"</span> <span class="nt">--skip-phases</span><span class="o">=</span>addon/kube-proxy  <span class="o">&gt;</span>/dev/null 2&gt;&amp;1


<span class="nb">echo</span> <span class="s2">"[TASK 2] Setting kube config file"</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> /root/.kube
<span class="nb">cp</span> <span class="nt">-i</span> /etc/kubernetes/admin.conf /root/.kube/config
<span class="nb">chown</span> <span class="si">$(</span><span class="nb">id</span> <span class="nt">-u</span><span class="si">)</span>:<span class="si">$(</span><span class="nb">id</span> <span class="nt">-g</span><span class="si">)</span> /root/.kube/config


<span class="nb">echo</span> <span class="s2">"[TASK 3] Source the completion"</span>
<span class="nb">echo</span> <span class="s1">'source &lt;(kubectl completion bash)'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'source &lt;(kubeadm completion bash)'</span> <span class="o">&gt;&gt;</span> /etc/profile


<span class="nb">echo</span> <span class="s2">"[TASK 4] Alias kubectl to k"</span>
<span class="nb">echo</span> <span class="s1">'alias k=kubectl'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'alias kc=kubecolor'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'complete -F __start_kubectl k'</span> <span class="o">&gt;&gt;</span> /etc/profile


<span class="nb">echo</span> <span class="s2">"[TASK 5] Install Kubectx &amp; Kubens"</span>
git clone https://github.com/ahmetb/kubectx /opt/kubectx <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">ln</span> <span class="nt">-s</span> /opt/kubectx/kubens /usr/local/bin/kubens
<span class="nb">ln</span> <span class="nt">-s</span> /opt/kubectx/kubectx /usr/local/bin/kubectx


<span class="nb">echo</span> <span class="s2">"[TASK 6] Install Kubeps &amp; Setting PS1"</span>
git clone https://github.com/jonmosco/kube-ps1.git /root/kube-ps1 <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="sh">"</span><span class="no">EOT</span><span class="sh">" &gt;&gt; /root/.bash_profile
source /root/kube-ps1/kube-ps1.sh
KUBE_PS1_SYMBOL_ENABLE=true
function get_cluster_short() {
  echo "</span><span class="nv">$1</span><span class="sh">" | cut -d . -f1
}
KUBE_PS1_CLUSTER_FUNCTION=get_cluster_short
KUBE_PS1_SUFFIX=') '
PS1='</span><span class="si">$(</span>kube_ps1<span class="si">)</span><span class="sh">'</span><span class="nv">$PS1</span><span class="sh">
</span><span class="no">EOT
</span>kubectl config rename-context <span class="s2">"kubernetes-admin@kubernetes"</span> <span class="s2">"HomeLab"</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1


<span class="nb">echo</span> <span class="s2">"[TASK 7] Install Cilium CNI"</span>
<span class="nv">NODEIP</span><span class="o">=</span><span class="si">$(</span>ip <span class="nt">-4</span> addr show eth1 | <span class="nb">grep</span> <span class="nt">-oP</span> <span class="s1">'(?&lt;=inet\s)\d+(\.\d+){3}'</span><span class="si">)</span>
helm repo add cilium https://helm.cilium.io/ <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
helm repo update <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
helm <span class="nb">install </span>cilium cilium/cilium <span class="nt">--version</span> <span class="nv">$2</span> <span class="nt">--namespace</span> kube-system <span class="se">\</span>
<span class="nt">--set</span> <span class="nv">k8sServiceHost</span><span class="o">=</span>192.168.10.100 <span class="nt">--set</span> <span class="nv">k8sServicePort</span><span class="o">=</span>6443 <span class="se">\</span>
<span class="nt">--set</span> ipam.mode<span class="o">=</span><span class="s2">"cluster-pool"</span> <span class="nt">--set</span> ipam.operator.clusterPoolIPv4PodCIDRList<span class="o">={</span><span class="s2">"172.20.0.0/16"</span><span class="o">}</span> <span class="nt">--set</span> <span class="nv">ipv4NativeRoutingCIDR</span><span class="o">=</span>172.20.0.0/16 <span class="se">\</span>
<span class="nt">--set</span> <span class="nv">routingMode</span><span class="o">=</span>native <span class="nt">--set</span> <span class="nv">autoDirectNodeRoutes</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> endpointRoutes.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> <span class="nv">kubeProxyReplacement</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> bpf.masquerade<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> <span class="nv">installNoConntrackIptablesRules</span><span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> endpointHealthChecking.enabled<span class="o">=</span><span class="nb">false</span> <span class="nt">--set</span> <span class="nv">healthChecking</span><span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
<span class="nt">--set</span> hubble.enabled<span class="o">=</span><span class="nb">false</span> <span class="nt">--set</span> operator.replicas<span class="o">=</span>1 <span class="nt">--set</span> debug.enabled<span class="o">=</span><span class="nb">true</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1


<span class="nb">echo</span> <span class="s2">"[TASK 8] Install Cilium CLI"</span>
<span class="nv">CILIUM_CLI_VERSION</span><span class="o">=</span><span class="si">$(</span>curl <span class="nt">-s</span> https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt<span class="si">)</span>
<span class="nv">CLI_ARCH</span><span class="o">=</span>amd64
<span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span><span class="si">)</span><span class="s2">"</span> <span class="o">=</span> <span class="s2">"aarch64"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then </span><span class="nv">CLI_ARCH</span><span class="o">=</span>arm64<span class="p">;</span> <span class="k">fi
</span>curl <span class="nt">-L</span> <span class="nt">--fail</span> <span class="nt">--remote-name-all</span> https://github.com/cilium/cilium-cli/releases/download/<span class="k">${</span><span class="nv">CILIUM_CLI_VERSION</span><span class="k">}</span>/cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">tar </span>xzvfC cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz /usr/local/bin
<span class="nb">rm </span>cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz


<span class="nb">echo</span> <span class="s2">"[TASK 9] local DNS with hosts file"</span>
<span class="nb">echo</span> <span class="s2">"192.168.10.100 k8s-ctr"</span> <span class="o">&gt;&gt;</span> /etc/hosts
<span class="k">for</span> <span class="o">((</span> <span class="nv">i</span><span class="o">=</span>1<span class="p">;</span> i&lt;<span class="o">=</span><span class="nv">$1</span><span class="p">;</span> i++  <span class="o">))</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"192.168.10.10</span><span class="nv">$i</span><span class="s2"> k8s-w</span><span class="nv">$i</span><span class="s2">"</span> <span class="o">&gt;&gt;</span> /etc/hosts<span class="p">;</span> <span class="k">done


</span><span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Controlplane Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div></div>

<ul>
  <li>
    <p>부가적으로 <code class="language-plaintext highlighter-rouge">kubeadm-init-ctr-config.yaml</code> 파일은 다음과 같이 작성되어 있습니다.</p>

    <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">kubeadm.k8s.io/v1beta4</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">InitConfiguration</span>
<span class="na">bootstrapTokens</span><span class="pi">:</span>
<span class="pi">-</span> <span class="na">token</span><span class="pi">:</span> <span class="s2">"</span><span class="s">123456.1234567890123456"</span>
  <span class="na">ttl</span><span class="pi">:</span> <span class="s2">"</span><span class="s">0s"</span>
  <span class="na">usages</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s">signing</span>
  <span class="pi">-</span> <span class="s">authentication</span>
<span class="na">localAPIEndpoint</span><span class="pi">:</span>
  <span class="na">advertiseAddress</span><span class="pi">:</span> <span class="s2">"</span><span class="s">192.168.10.100"</span>
<span class="na">nodeRegistration</span><span class="pi">:</span>
  <span class="na">kubeletExtraArgs</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">node-ip</span>
      <span class="na">value</span><span class="pi">:</span> <span class="s2">"</span><span class="s">192.168.10.100"</span>
  <span class="na">criSocket</span><span class="pi">:</span> <span class="s2">"</span><span class="s">unix:///run/containerd/containerd.sock"</span>
<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">kubeadm.k8s.io/v1beta4</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">ClusterConfiguration</span>
<span class="na">kubernetesVersion</span><span class="pi">:</span> <span class="s">v1.33.2</span>
<span class="na">networking</span><span class="pi">:</span>
  <span class="na">podSubnet</span><span class="pi">:</span> <span class="s2">"</span><span class="s">10.244.0.0/16"</span>
  <span class="na">serviceSubnet</span><span class="pi">:</span> <span class="s2">"</span><span class="s">10.96.0.0/16"</span>
</code></pre></div>    </div>
  </li>
</ul>

<h4 id="k8s-wsh"><strong>k8s-w.sh</strong></h4>
<ul>
  <li>워커노드에서 <code class="language-plaintext highlighter-rouge">kubeadm join</code>을 실행하여 컨트롤플레인에 조인합니다.</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>

<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Node config Start &lt;&lt;&lt;&lt;"</span>

<span class="nb">echo</span> <span class="s2">"[TASK 1] K8S Controlplane Join"</span>
curl <span class="nt">--silent</span> <span class="nt">-o</span> /root/kubeadm-join-worker-config.yaml https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/2w/kubeadm-join-worker-config.yaml
<span class="nv">NODEIP</span><span class="o">=</span><span class="si">$(</span>ip <span class="nt">-4</span> addr show eth1 | <span class="nb">grep</span> <span class="nt">-oP</span> <span class="s1">'(?&lt;=inet\s)\d+(\.\d+){3}'</span><span class="si">)</span>
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/NODE_IP_PLACEHOLDER/</span><span class="k">${</span><span class="nv">NODEIP</span><span class="k">}</span><span class="s2">/g"</span> /root/kubeadm-join-worker-config.yaml
kubeadm <span class="nb">join</span> <span class="nt">--config</span><span class="o">=</span><span class="s2">"/root/kubeadm-join-worker-config.yaml"</span> <span class="o">&gt;</span> /dev/null 2&gt;&amp;1

<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Node config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">kubeadm-join-worker-config.yaml</code> 파일은 다음과 같이 작성되어 있습니다.
    <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">kubeadm.k8s.io/v1beta4</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">JoinConfiguration</span>
<span class="na">discovery</span><span class="pi">:</span>
  <span class="na">bootstrapToken</span><span class="pi">:</span>
    <span class="na">token</span><span class="pi">:</span> <span class="s2">"</span><span class="s">123456.1234567890123456"</span>
    <span class="na">apiServerEndpoint</span><span class="pi">:</span> <span class="s2">"</span><span class="s">192.168.10.100:6443"</span>
    <span class="na">unsafeSkipCAVerification</span><span class="pi">:</span> <span class="kc">true</span>
<span class="na">nodeRegistration</span><span class="pi">:</span>
  <span class="na">criSocket</span><span class="pi">:</span> <span class="s2">"</span><span class="s">unix:///run/containerd/containerd.sock"</span>
  <span class="na">kubeletExtraArgs</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">node-ip</span>
      <span class="na">value</span><span class="pi">:</span> <span class="s2">"</span><span class="s">NODE_IP_PLACEHOLDER"</span>
</code></pre></div>    </div>
  </li>
</ul>

<h3 id="실습환경-배포">실습환경 배포</h3>

<ul>
  <li>배포</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>vagrant up
</code></pre></div></div>

<ul>
  <li>[k8s-ctr] 접속 후 기본 정보 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># k8s-ctr 접속</span>
<span class="nv">$ </span>vagrant ssh k8s-ctr
<span class="nt">---</span>
<span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> /etc/hosts
<span class="c"># =&gt; 127.0.0.1 localhost</span>
<span class="c">#    127.0.1.1 vagrant</span>
<span class="c">#    ...</span>
<span class="c">#    127.0.2.1 k8s-ctr k8s-ctr</span>
<span class="c">#    192.168.10.100 k8s-ctr</span>
<span class="c">#    192.168.10.101 k8s-w1</span>
<span class="c">#    192.168.10.102 k8s-w2</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-w1 <span class="nb">hostname</span>
<span class="c"># =&gt; k8s-w1</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-w2 <span class="nb">hostname</span>
<span class="c"># =&gt; k8s-w2</span>

<span class="c">#</span>
<span class="nv">$ </span>ifconfig | <span class="nb">grep</span> <span class="nt">-iEA1</span> <span class="s1">'eth[0-9]:'</span>
<span class="c"># =&gt; eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span>
<span class="c">#            inet 10.0.2.15  netmask 255.255.255.0  broadcast 10.0.2.255</span>
<span class="c">#    --</span>
<span class="c">#    eth1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span>
<span class="c">#            inet 192.168.10.100  netmask 255.255.255.0  broadcast 192.168.10.255</span>

<span class="c"># 클러스터 정보 확인</span>
<span class="nv">$ </span>kubectl cluster-info
<span class="nv">$ </span>kubectl cluster-info dump | <span class="nb">grep</span> <span class="nt">-m</span> 2 <span class="nt">-E</span> <span class="s2">"cluster-cidr|service-cluster-ip-range"</span>
<span class="c"># =&gt;                             "--service-cluster-ip-range=10.96.0.0/16",</span>
<span class="c">#                                "--cluster-cidr=10.244.0.0/16",</span>
<span class="nv">$ </span>kubectl describe cm <span class="nt">-n</span> kube-system kubeadm-config
<span class="nv">$ </span>kubectl describe cm <span class="nt">-n</span> kube-system kubelet-config

<span class="c"># 노드 정보 : 상태, INTERNAL-IP 확인</span>
<span class="nv">$ </span>kubectl get node <span class="nt">-owide</span>
<span class="c"># =&gt; NAME      STATUS   ROLES           AGE   VERSION   INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION     CONTAINER-RUNTIME</span>
<span class="c">#    k8s-ctr   Ready    control-plane   14m   v1.33.2   &lt;span style="color: green;"&gt;192.168.10.100&lt;/span&gt;   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>
<span class="c">#    k8s-w1    Ready    &lt;none&gt;          11m   v1.33.2   &lt;span style="color: green;"&gt;192.168.10.101&lt;/span&gt;   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>
<span class="c">#    k8s-w2    Ready    &lt;none&gt;          10m   v1.33.2   &lt;span style="color: green;"&gt;192.168.10.102&lt;/span&gt;   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>

<span class="c"># 노드별 kubeadm-flags.env 정보 확인</span>
<span class="nv">$ </span><span class="nb">cat</span> /var/lib/kubelet/kubeadm-flags.env
<span class="c"># =&gt; KUBELET_KUBEADM_ARGS="--container-runtime-endpoint=unix:///run/containerd/containerd.sock --node-ip=192.168.10.100 --pod-infra-container-image=registry.k8s.io/pause:3.10"</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> <span class="nb">cat</span> /var/lib/kubelet/kubeadm-flags.env <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>

<span class="c"># 파드 정보 : 상태, 파드 IP 확인</span>
<span class="nv">$ </span>kubectl get nodes <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{range .items[*]}{.metadata.name}{"\t"}{.spec.podCIDR}{"\n"}{end}'</span>
<span class="c"># =&gt; k8s-ctr 10.244.0.0/24</span>
<span class="c">#    k8s-w1  10.244.1.0/24</span>
<span class="c">#    k8s-w2  10.244.2.0/24</span>
<span class="nv">$ </span>kubectl get ciliumnode <span class="nt">-o</span> json | <span class="nb">grep </span>podCIDRs <span class="nt">-A2</span>
<span class="c"># =&gt;                     "podCIDRs": [ "172.20.0.0/24" ],</span>
<span class="c">#    --</span>
<span class="c">#                        "podCIDRs": [ "172.20.1.0/24" ],</span>
<span class="c">#    --</span>
<span class="c">#                        "podCIDRs": [ "172.20.2.0/24" ],</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-A</span> <span class="nt">-owide</span>
<span class="c"># =&gt; NAMESPACE     NAME                               READY   STATUS    RESTARTS   AGE   IP               NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-2rgdx&lt;/span&gt;                       1/1     Running   0          15m   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-envoy-q97fq&lt;/span&gt;                 1/1     Running   0          12m   192.168.10.102   k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-envoy-xzxd6&lt;/span&gt;                 1/1     Running   0          13m   192.168.10.101   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-envoy-zzzw5&lt;/span&gt;                 1/1     Running   0          15m   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-fdqhq&lt;/span&gt;                       1/1     Running   0          12m   192.168.10.102   k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-kv67c&lt;/span&gt;                       1/1     Running   0          13m   192.168.10.101   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-operator-5bc66f5b9b-xps5x&lt;/span&gt;   1/1     Running   0          15m   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-4h2lt           1/1     &lt;span style="color: green;"&gt;Running&lt;/span&gt;   0          15m   172.20.0.233     k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-7m82r           1/1     &lt;span style="color: green;"&gt;Running&lt;/span&gt;   0          15m   172.20.0.167     k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   etcd-k8s-ctr                       1/1     Running   0          16m   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-apiserver-k8s-ctr             1/1     Running   0          16m   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-controller-manager-k8s-ctr    1/1     Running   0          16m   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-scheduler-k8s-ctr             1/1     Running   0          16m   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 cilium CNI가 설치되어있고, CNI가 설치되었기 때문에 coredns가 Running 상태로 시작됨을 알 수 있습니다.&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 또한 kube-proxy가 설치되지 않았고, Cilium이 kube-proxy를 대체하고 있음을 알 수 있습니다.&lt;/span&gt;</span>

<span class="c"># iptables 확인</span>
<span class="nv">$ </span>iptables-save
<span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> filter <span class="nt">-S</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> mangle <span class="nt">-S</span>
</code></pre></div></div>

<ul>
  <li>[k8s-ctr] cilium 설치 정보 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># cilium 상태 확인</span>
<span class="nv">$ </span>which cilium
<span class="c"># =&gt; /usr/local/bin/cilium</span>
<span class="nv">$ </span>cilium status
<span class="c"># =&gt;     /¯¯\</span>
<span class="c">#     /¯¯\__/¯¯\    Cilium:             OK</span>
<span class="c">#     \__/¯¯\__/    Operator:           OK</span>
<span class="c">#     /¯¯\__/¯¯\    Envoy DaemonSet:    OK</span>
<span class="c">#     \__/¯¯\__/    Hubble Relay:       disabled</span>
<span class="c">#        \__/       ClusterMesh:        disabled</span>
<span class="c">#    </span>
<span class="c">#    DaemonSet              cilium                   Desired: 3, Ready: 3/3, Available: 3/3</span>
<span class="c">#    DaemonSet              cilium-envoy             Desired: 3, Ready: 3/3, Available: 3/3</span>
<span class="c">#    Deployment             cilium-operator          Desired: 1, Ready: 1/1, Available: 1/1</span>
<span class="c">#    Containers:            cilium                   Running: 3</span>
<span class="c">#                           cilium-envoy             Running: 3</span>
<span class="c">#                           cilium-operator          Running: 1</span>
<span class="c">#                           clustermesh-apiserver</span>
<span class="c">#                           hubble-relay</span>
<span class="c">#    Cluster Pods:          2/2 managed by Cilium</span>
<span class="c">#    Helm chart version:    1.17.6</span>
<span class="c">#    Image versions         cilium             quay.io/cilium/cilium:v1.17.6@sha256:544de3d4fed7acba72758413812780a4972d47c39035f2a06d6145d8644a3353: 3</span>
<span class="c">#                           cilium-envoy       quay.io/cilium/cilium-envoy:v1.33.4-1752151664-7c2edb0b44cf95f326d628b837fcdd845102ba68@sha256:318eff387835ca2717baab42a84f35a83a5f9e7d519253df87269f80b9ff0171: 3</span>
<span class="c">#                           cilium-operator    quay.io/cilium/operator-generic:v1.17.6@sha256:91ac3bf7be7bed30e90218f219d4f3062a63377689ee7246062fa0cc3839d096: 1</span>
<span class="nv">$ </span>cilium config view
<span class="nv">$ </span>kubectl get cm <span class="nt">-n</span> kube-system cilium-config <span class="nt">-o</span> json | jq

<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg config
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg status <span class="nt">--verbose</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg metrics list

<span class="c">#</span>
<span class="nv">$ </span>kubectl get ciliumendpoints <span class="nt">-A</span>

<span class="c"># monitor</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg monitor
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg monitor <span class="nt">-v</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg monitor <span class="nt">-v</span> <span class="nt">-v</span>

<span class="c">## Filter for only the events related to endpoint</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg monitor <span class="nt">--related-to</span><span class="o">=</span>&lt;<span class="nb">id</span><span class="o">&gt;</span>

<span class="c">## Show notifications only for dropped packet events</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg monitor <span class="nt">--type</span> drop

<span class="c">## Don’t dissect packet payload, display payload in hex information</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg monitor <span class="nt">-v</span> <span class="nt">-v</span> <span class="nt">--hex</span>

<span class="c">## Layer7</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg monitor <span class="nt">-v</span> <span class="nt">--type</span> l7
</code></pre></div></div>

<h3 id="cilium-agent-단축키-지정">Cilium Agent 단축키 지정</h3>

<ul>
  <li><a href="https://sweetlittlebird.github.io/posts/2025-07-20-Cilium-Week1/#%EB%A7%88%EC%B9%98%EB%A9%B0">[Cilium] 실습 환경 구성 및 Cilium 설치</a>의 Cilium CMD Cheatsheet를 참고하여 환경변수와 alias를 지정합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># cilium 파드 이름</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD0</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-ctr <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD1</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-w1  <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD2</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-w2  <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$CILIUMPOD0</span> <span class="nv">$CILIUMPOD1</span> <span class="nv">$CILIUMPOD2</span>
<span class="c"># =&gt; cilium-5kc8d cilium-w9st8 cilium-l8lm7</span>

<span class="c"># 단축키(alias) 지정</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c0</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD0</span><span class="s2"> -n kube-system -c cilium-agent -- cilium"</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c1</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD1</span><span class="s2"> -n kube-system -c cilium-agent -- cilium"</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c2</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD2</span><span class="s2"> -n kube-system -c cilium-agent -- cilium"</span>

<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c0bpf</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD0</span><span class="s2"> -n kube-system -c cilium-agent -- bpftool"</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c1bpf</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD1</span><span class="s2"> -n kube-system -c cilium-agent -- bpftool"</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c2bpf</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD2</span><span class="s2"> -n kube-system -c cilium-agent -- bpftool"</span>
</code></pre></div></div>

<h2 id="network-observability-with-hubble">Network Observability with Hubble</h2>

<h3 id="hubble-소개">Hubble 소개</h3>

<p><img src="/assets/2025/cilium/w2/20250727_cilium_w2_2.png" alt="img.png" class="image-center w-80" /></p>

<ul>
  <li><strong>Hubble</strong>은 Cilium과 eBPF를 기반으로 구축된 <strong>완전히 분산된 네트워킹 및 보안 관측 가능성 플랫폼</strong>입니다.
서비스의 통신 및 동작뿐만 아니라 네트워킹 인프라에 대한 깊은 가시성을 투명하게 제공합니다.</li>
  <li><strong>Hubble</strong>은 오버헤드를 최소화 하는 동적 접근 방식을 제공하며, 다중 클러스터(ClusterMesh) 환경에서도 노드 수준, 컨트롤러 수준 또는
클러스터 간 가시성을 제공할 수 있습니다.</li>
  <li><strong>Hubble API</strong>는 Cilium 에이전트가 실행되는 개별 노드에서 작동합니다. Hubble CLI는 로컬 유닉스 도메인 소켓을 통해 제공되는 Hubble API를 쿼리할 수 있습니다.</li>
  <li><strong>Hubble Relay</strong>를 배포하면 클러스터 메시 시나리오에서 전체 클러스터 또는 여러 클러스터에 대한 가시성을 제공합니다. 이 모드에서는
Hubble CLI를 Hubble Relay에 연결하여 모든 노드에서 수집된 이벤트를 쿼리하거나, Hubble UI를 통해 Hubble 데이터에 접근할 수 있습니다.</li>
  <li>서비스 의존성 및 통신 그래프를 시각화 할 수 있습니다.</li>
  <li>네트워크 정책 모니터링 및 알림을 제공하여 네트워크 통신 실패 등을 모니터링 하고 원인을 파악하는데 도움을 줍니다.</li>
  <li>애플리케이션 성능 모니터링을 통해 서비스 간의 지연 시간, 오류율 등을 측정하고 분석할 수 있습니다.</li>
  <li>보안 정책 모니터링을 통해 네트워크 정책 위반, 의심스러운 트래픽 등을 감지하고 대응할 수 있습니다.</li>
</ul>

<h3 id="hubble-observability-설치">Hubble Observability 설치</h3>

<ul>
  <li>관련 문서 : <a href="https://docs.cilium.io/en/stable/observability/hubble/setup/">docs</a></li>
  <li>설치 전 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>cilium status
<span class="c"># =&gt; ...</span>
<span class="c">#     \__/¯¯\__/    Hubble Relay:       disabled</span>
<span class="c">#    ...</span>
<span class="c">#    Containers:            cilium                   Running: 3</span>
<span class="c">#                           cilium-envoy             Running: 3</span>
<span class="c">#                           cilium-operator          Running: 1</span>
<span class="c">#                           clustermesh-apiserver</span>
<span class="c">#                           hubble-relay</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>cilium config view | <span class="nb">grep</span> <span class="nt">-i</span> hubble
<span class="c"># =&gt; enable-hubble                                     false</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 현재 Hubble이 설치되어 있지 않습니다.&lt;/span&gt;</span>

<span class="nv">$ </span>kubectl get cm <span class="nt">-n</span> kube-system cilium-config <span class="nt">-o</span> json | jq
<span class="c"># =&gt; ...</span>
<span class="c">#        "enable-hubble": "false",</span>
<span class="c">#</span>
<span class="nv">$ </span>kubectl get secret <span class="nt">-n</span> kube-system | <span class="nb">grep</span> <span class="nt">-iE</span> <span class="s1">'cilium-ca|hubble'</span>
<span class="c"># =&gt; (공백) </span>
<span class="nv">$ </span>ss <span class="nt">-tnlp</span> | <span class="nb">grep</span> <span class="nt">-iE</span> <span class="s1">'cilium|hubble'</span> | <span class="nb">tee </span>before.txt
<span class="c"># =&gt; LISTEN 0      4096        127.0.0.1:37303      0.0.0.0:*    users:(("cilium-agent",pid=2853,fd=42))</span>
<span class="c">#    LISTEN 0      4096        127.0.0.1:9234       0.0.0.0:*    users:(("cilium-operator",pid=2153,fd=9))</span>
<span class="c">#    LISTEN 0      4096          0.0.0.0:9964       0.0.0.0:*    users:(("cilium-envoy",pid=2224,fd=25))</span>
<span class="c">#    LISTEN 0      4096          0.0.0.0:9964       0.0.0.0:*    users:(("cilium-envoy",pid=2224,fd=24))</span>
<span class="c">#    LISTEN 0      4096        127.0.0.1:9890       0.0.0.0:*    users:(("cilium-agent",pid=2853,fd=6))</span>
<span class="c">#    LISTEN 0      4096        127.0.0.1:9891       0.0.0.0:*    users:(("cilium-operator",pid=2153,fd=6))</span>
<span class="c">#    LISTEN 0      4096        127.0.0.1:9878       0.0.0.0:*    users:(("cilium-envoy",pid=2224,fd=27))</span>
<span class="c">#    LISTEN 0      4096        127.0.0.1:9878       0.0.0.0:*    users:(("cilium-envoy",pid=2224,fd=26))</span>
<span class="c">#    LISTEN 0      4096        127.0.0.1:9879       0.0.0.0:*    users:(("cilium-agent",pid=2853,fd=51))</span>
<span class="c">#    LISTEN 0      4096                *:9963             *:*    users:(("cilium-operator",pid=2153,fd=7))</span>
</code></pre></div></div>

<ul>
  <li>Hubble 설치</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 설치방안 1 : hubble 활성화, 메트릭 설정 등등</span>
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--namespace</span> kube-system <span class="nt">--reuse-values</span> <span class="se">\</span>
  <span class="nt">--set</span> hubble.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> hubble.relay.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> hubble.ui.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> hubble.ui.service.type<span class="o">=</span>NodePort <span class="se">\</span>
  <span class="nt">--set</span> hubble.ui.service.nodePort<span class="o">=</span>31234 <span class="se">\</span>
  <span class="nt">--set</span> hubble.export.static.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> hubble.export.static.filePath<span class="o">=</span>/var/run/cilium/hubble/events.log <span class="se">\</span>
  <span class="nt">--set</span> prometheus.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> operator.prometheus.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> hubble.metrics.enableOpenMetrics<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> hubble.metrics.enabled<span class="o">=</span><span class="s2">"{dns,drop,tcp,flow,port-distribution,icmp,httpV2:exemplars=true;labelsContext=source_ip</span><span class="se">\,</span><span class="s2">source_namespace</span><span class="se">\,</span><span class="s2">source_workload</span><span class="se">\,</span><span class="s2">destination_ip</span><span class="se">\,</span><span class="s2">destination_namespace</span><span class="se">\,</span><span class="s2">destination_workload</span><span class="se">\,</span><span class="s2">traffic_direction}"</span>
<span class="c"># =&gt; Release "cilium" has been upgraded. Happy Helming!</span>
<span class="c">#    NAME: cilium</span>
<span class="c">#    LAST DEPLOYED: Thu Jul 24 23:16:48 2025</span>
<span class="c">#    NAMESPACE: kube-system</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 2</span>
<span class="c">#    TEST SUITE: None</span>
<span class="c">#    NOTES:</span>
<span class="c">#    You have successfully installed Cilium with Hubble Relay and Hubble UI.</span>
<span class="c">#    </span>
<span class="c">#    Your release version is 1.17.6.  </span>

<span class="c"># 설치방안 2 : hubble 활성화</span>
<span class="nv">$ </span>cilium hubble <span class="nb">enable</span>
<span class="nv">$ </span>cilium hubble <span class="nb">enable</span> <span class="nt">--ui</span>

<span class="c"># cilium status를 통한 hubble 설치 상태 확인</span>
<span class="nv">$ </span>cilium status
<span class="c"># =&gt; ...</span>
<span class="c">#     \__/¯¯\__/    Hubble Relay:       OK</span>
<span class="c">#    ...</span>
<span class="c">#    Deployment             hubble-relay             Desired: 1, Ready: 1/1, Available: 1/1</span>
<span class="c">#    Deployment             hubble-ui                Desired: 1, Ready: 1/1, Available: 1/1</span>
<span class="c">#    Containers:            hubble-relay             Running: 1</span>
<span class="c">#                           hubble-ui                Running: 1</span>

<span class="c"># hubble 관련 설정 정보 확인</span>
<span class="nv">$ </span>cilium config view | <span class="nb">grep</span> <span class="nt">-i</span> hubble
<span class="c"># =&gt; enable-hubble                                     true</span>
<span class="c">#    enable-hubble-open-metrics                        true</span>
<span class="c">#    hubble-disable-tls                                false</span>
<span class="c">#    hubble-export-allowlist</span>
<span class="c">#    hubble-export-denylist</span>
<span class="c">#    hubble-export-fieldmask</span>
<span class="c">#    hubble-export-file-max-backups                    5</span>
<span class="c">#    hubble-export-file-max-size-mb                    10</span>
<span class="c">#    hubble-export-file-path                           /var/run/cilium/hubble/events.log</span>
<span class="c">#    hubble-listen-address                             :4244</span>
<span class="c">#    hubble-metrics                                    dns drop tcp flow port-distribution icmp httpV2:exemplars=true;labelsContext=source_ip,source_namespace,source_workload,destination_ip,destination_namespace,destination_workload,traffic_direction</span>
<span class="c">#    hubble-metrics-server                             :9965</span>
<span class="c">#    hubble-metrics-server-enable-tls                  false</span>
<span class="c">#    hubble-socket-path                                /var/run/cilium/hubble.sock</span>
<span class="c">#    hubble-tls-cert-file                              /var/lib/cilium/tls/hubble/server.crt</span>
<span class="c">#    hubble-tls-client-ca-files                        /var/lib/cilium/tls/hubble/client-ca.crt</span>
<span class="c">#    hubble-tls-key-file                               /var/lib/cilium/tls/hubble/server.key</span>

<span class="c"># config map에서 hubble 관련 설정 정보 확인</span>
<span class="nv">$ </span>kubectl get cm <span class="nt">-n</span> kube-system cilium-config <span class="nt">-o</span> json | <span class="nb">grep</span> <span class="nt">-i</span> hubble
<span class="c"># =&gt;         "enable-hubble": "true",</span>
<span class="c">#            "enable-hubble-open-metrics": "true",</span>
<span class="c">#            "hubble-disable-tls": "false",</span>
<span class="c">#            "hubble-export-allowlist": "",</span>
<span class="c">#    ...</span>

<span class="c"># hubble 관련 secret 정보 확인</span>
<span class="nv">$ </span>kubectl get secret <span class="nt">-n</span> kube-system | <span class="nb">grep</span> <span class="nt">-iE</span> <span class="s1">'cilium-ca|hubble'</span>
<span class="c"># =&gt; cilium-ca                      Opaque                          2      4m57s</span>
<span class="c">#    hubble-relay-client-certs      kubernetes.io/tls               3      4m57s</span>
<span class="c">#    hubble-server-certs            kubernetes.io/tls               3      4m57s</span>

<span class="c"># TCP 포트 4244를 모든 cilium을 실행하는 노드에서 열어야 할 필요가 있음</span>
<span class="nv">$ </span>ss <span class="nt">-tnlp</span> | <span class="nb">grep</span> <span class="nt">-iE</span> <span class="s1">'cilium|hubble'</span> | <span class="nb">tee </span>after.txt
<span class="c"># =&gt; LISTEN 0      4096        127.0.0.1:37303      0.0.0.0:*    users:(("cilium-agent",pid=4891,fd=52))</span>
<span class="c">#    LISTEN 0      4096        127.0.0.1:9234       0.0.0.0:*    users:(("cilium-operator",pid=2153,fd=9))</span>
<span class="c">#    LISTEN 0      4096          0.0.0.0:9964       0.0.0.0:*    users:(("cilium-envoy",pid=2224,fd=25))</span>
<span class="c">#    LISTEN 0      4096          0.0.0.0:9964       0.0.0.0:*    users:(("cilium-envoy",pid=2224,fd=24))</span>
<span class="c">#    LISTEN 0      4096        127.0.0.1:9890       0.0.0.0:*    users:(("cilium-agent",pid=4891,fd=6))</span>
<span class="c">#    LISTEN 0      4096        127.0.0.1:9891       0.0.0.0:*    users:(("cilium-operator",pid=2153,fd=6))</span>
<span class="c">#    LISTEN 0      4096        127.0.0.1:9878       0.0.0.0:*    users:(("cilium-envoy",pid=2224,fd=27))</span>
<span class="c">#    LISTEN 0      4096        127.0.0.1:9878       0.0.0.0:*    users:(("cilium-envoy",pid=2224,fd=26))</span>
<span class="c">#    LISTEN 0      4096        127.0.0.1:9879       0.0.0.0:*    users:(("cilium-agent",pid=4891,fd=62))</span>
<span class="c">#    LISTEN 0      4096                *:4244             *:*    users:(("cilium-agent",pid=4891,fd=55))</span>
<span class="c">#    LISTEN 0      4096                *:9965             *:*    users:(("cilium-agent",pid=4891,fd=34))</span>
<span class="c">#    LISTEN 0      4096                *:9962             *:*    users:(("cilium-agent",pid=4891,fd=7))</span>
<span class="c">#    LISTEN 0      4096                *:9963             *:*    users:(("cilium-operator",pid=2153,fd=7))</span>

<span class="c"># Hubble 실행 전과 후의 리스닝 포트 변경확인</span>
<span class="nv">$ </span>vi <span class="nt">-d</span> before.txt after.txt
<span class="c"># =&gt;   LISTEN 0      4096        127.0.0.1:37303      0.0.0.0:|  LISTEN 0      4096        127.0.0.1:37303      0.0.0.0:</span>
<span class="c">#      LISTEN 0      4096        127.0.0.1:9234       0.0.0.0:|  LISTEN 0      4096        127.0.0.1:9234       0.0.0.0:</span>
<span class="c">#      LISTEN 0      4096          0.0.0.0:9964       0.0.0.0:|  LISTEN 0      4096          0.0.0.0:9964       0.0.0.0:</span>
<span class="c">#      LISTEN 0      4096          0.0.0.0:9964       0.0.0.0:|  LISTEN 0      4096          0.0.0.0:9964       0.0.0.0:</span>
<span class="c">#      LISTEN 0      4096        127.0.0.1:9890       0.0.0.0:|  LISTEN 0      4096        127.0.0.1:9890       0.0.0.0:</span>
<span class="c">#      LISTEN 0      4096        127.0.0.1:9891       0.0.0.0:|  LISTEN 0      4096        127.0.0.1:9891       0.0.0.0:</span>
<span class="c">#      LISTEN 0      4096        127.0.0.1:9878       0.0.0.0:|  LISTEN 0      4096        127.0.0.1:9878       0.0.0.0:</span>
<span class="c">#      LISTEN 0      4096        127.0.0.1:9878       0.0.0.0:|  LISTEN 0      4096        127.0.0.1:9878       0.0.0.0:</span>
<span class="c">#      LISTEN 0      4096        127.0.0.1:9879       0.0.0.0:|  LISTEN 0      4096        127.0.0.1:9879       0.0.0.0:</span>
<span class="c">#      -------------------------------------------------------|  &lt;span style="background-color: green; color: #fff;"&gt;LISTEN 0      4096                *:4244             *:&lt;/span&gt;</span>
<span class="c">#      -------------------------------------------------------|  &lt;span style="background-color: green; color: #fff;"&gt;LISTEN 0      4096                *:9965             *:&lt;/span&gt;</span>
<span class="c">#      -------------------------------------------------------|  &lt;span style="background-color: green; color: #fff;"&gt;LISTEN 0      4096                *:9962             *:&lt;/span&gt;</span>
<span class="c">#      LISTEN 0      4096                *:9963             *:|  LISTEN 0      4096                *:9963             *:</span>

<span class="c"># 각 노드의 4244 포트 오픈 확인</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>ss <span class="nt">-tnlp</span> |grep 4244 <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    LISTEN 0      4096               *:4244             *:*    users:(("cilium-agent",pid=3528,fd=50))</span>
<span class="c">#    &gt;&gt; node : k8s-w2 &lt;&lt;</span>
<span class="c">#    LISTEN 0      4096               *:4244             *:*    users:(("cilium-agent",pid=3268,fd=46))</span>

<span class="c"># Hubble Relay Pod 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>hubble-relay
<span class="c"># =&gt; NAME                           READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    hubble-relay-5dcd46f5c-n4zfx   1/1     Running   0          12m</span>

<span class="nv">$ </span>kc describe pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>hubble-relay
<span class="c"># =&gt; Name:             hubble-relay-5dcd46f5c-n4zfx</span>
<span class="c">#    Namespace:        kube-system</span>
<span class="c">#    Service Account:  hubble-relay</span>
<span class="c">#    Labels:           app.kubernetes.io/name=hubble-relay</span>
<span class="c">#                      app.kubernetes.io/part-of=cilium</span>
<span class="c">#                      k8s-app=hubble-relay</span>
<span class="c">#    ...</span>
<span class="c">#        Image:         quay.io/cilium/hubble-relay:v1.17.6@sha256:7d17ec10b3d37341c18ca56165b2f29a715cb8ee81311fd07088d8bf68c01e60</span>
<span class="c">#    ...</span>

<span class="nv">$ </span>kc get svc,ep <span class="nt">-n</span> kube-system hubble-relay
<span class="c"># =&gt; NAME                   TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE</span>
<span class="c">#    service/hubble-relay   ClusterIP   10.96.207.219   &lt;none&gt;        80/TCP    14m</span>
<span class="c">#    </span>
<span class="c">#    NAME                     ENDPOINTS           AGE</span>
<span class="c">#    endpoints/hubble-relay   172.20.2.214:4245   14m</span>

<span class="c"># hubble-relay 는 hubble-peer 의 서비스(ClusterIP :443)을 통해 모든 노드의 :4244에 요청 가져올 수 있음</span>
<span class="nv">$ </span>kubectl get cm <span class="nt">-n</span> kube-system
<span class="c"># =&gt; NAME                                                   DATA   AGE</span>
<span class="c">#    cilium-config                                          158    23h</span>
<span class="c">#    cilium-envoy-config                                    1      23h</span>
<span class="c">#    ...</span>
<span class="c">#    hubble-relay-config                                    1      17m</span>
<span class="c">#    hubble-ui-nginx                                        1      17m</span>

<span class="nv">$ </span>kubectl describe cm <span class="nt">-n</span> kube-system hubble-relay-config
<span class="c"># =&gt; ...</span>
<span class="c">#    cluster-name: default</span>
<span class="c">#    peer-service: "hubble-peer.kube-system.svc.cluster.local.:443"</span>
<span class="c">#    listen-address: :4245</span>
<span class="c">#    ...</span>

<span class="c"># Hubble Peer Pod 확인</span>
<span class="nv">$ </span>kubectl get svc,ep <span class="nt">-n</span> kube-system hubble-peer
<span class="c"># =&gt; NAME                  TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE</span>
<span class="c">#    service/hubble-peer   ClusterIP   10.96.12.202   &lt;none&gt;        443/TCP   21m</span>
<span class="c">#    </span>
<span class="c">#    NAME                    ENDPOINTS                                                     AGE</span>
<span class="c">#    endpoints/hubble-peer   192.168.10.100:4244,192.168.10.101:4244,192.168.10.102:4244   21m</span>

<span class="c">#</span>
<span class="nv">$ </span>kc describe pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>hubble-ui
<span class="c"># =&gt; ...</span>
<span class="c">#      frontend:</span>
<span class="c">#        Port:           8081/TCP</span>
<span class="c">#        ...</span>
<span class="c">#      backend:</span>
<span class="c">#        Port:           8090/TCP</span>
<span class="c">#        ...</span>

<span class="nv">$ </span>kc describe cm <span class="nt">-n</span> kube-system hubble-ui-nginx
<span class="c"># =&gt; ...</span>
<span class="c">#    nginx.conf:</span>
<span class="c">#    ----</span>
<span class="c">#    server {</span>
<span class="c">#        listen       8081;</span>
<span class="c">#        listen       [::]:8081;</span>
<span class="c">#        server_name  localhost;</span>
<span class="c">#        root /app;</span>
<span class="c">#        index index.html;</span>
<span class="c">#        client_max_body_size 1G;</span>
<span class="c">#    </span>
<span class="c">#        location / {</span>
<span class="c">#            proxy_set_header Host $host;</span>
<span class="c">#            proxy_set_header X-Real-IP $remote_addr;</span>
<span class="c">#    </span>
<span class="c">#            location /api {</span>
<span class="c">#                proxy_http_version 1.1;</span>
<span class="c">#                proxy_pass_request_headers on;</span>
<span class="c">#                proxy_pass http://127.0.0.1:8090;</span>
<span class="c">#            }</span>
<span class="c">#            location / {</span>
<span class="c">#                # double `/index.html` is required here</span>
<span class="c">#                try_files $uri $uri/ /index.html /index.html;</span>
<span class="c">#            }</span>
<span class="c">#    </span>
<span class="c">#            # Liveness probe</span>
<span class="c">#            location /healthz {</span>
<span class="c">#                access_log off;</span>
<span class="c">#                add_header Content-Type text/plain;</span>
<span class="c">#                return 200 'ok';</span>
<span class="c">#            }</span>
<span class="c">#        }</span>
<span class="c">#    }</span>
<span class="c">#    ...</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get svc,ep <span class="nt">-n</span> kube-system hubble-ui
<span class="c"># =&gt; NAME                TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE</span>
<span class="c">#    service/hubble-ui   NodePort   10.96.183.249   &lt;none&gt;        80:31234/TCP   26m</span>
<span class="c">#    </span>
<span class="c">#    NAME                  ENDPOINTS           AGE</span>
<span class="c">#    endpoints/hubble-ui   172.20.1.189:8081   26m</span>

<span class="c"># hubble ui 웹 접속 주소 확인</span>
<span class="nv">$ NODEIP</span><span class="o">=</span><span class="si">$(</span>ip <span class="nt">-4</span> addr show eth1 | <span class="nb">grep</span> <span class="nt">-oP</span> <span class="s1">'(?&lt;=inet\s)\d+(\.\d+){3}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"http://</span><span class="nv">$NODEIP</span><span class="s2">:31234"</span>
<span class="c"># =&gt; http://192.168.10.100:31234</span>
</code></pre></div></div>

<ul>
  <li>
    <p>Hubble ui 접속 테스트 -&gt; 접속 후 kube-system 네임스페이스 선택
<img src="/assets/2025/cilium/w2/20250727_cilium_w2_3.png" alt="img.png" class="image-center" /></p>
  </li>
  <li>
    <p>Hubble Client 설치 - <a href="https://docs.cilium.io/en/stable/observability/hubble/setup/#install-the-hubble-client">docs</a></p>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ HUBBLE_VERSION</span><span class="o">=</span><span class="si">$(</span>curl <span class="nt">-s</span> https://raw.githubusercontent.com/cilium/hubble/master/stable.txt<span class="si">)</span>
<span class="nv">$ HUBBLE_ARCH</span><span class="o">=</span>amd64
<span class="nv">$ </span><span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span><span class="si">)</span><span class="s2">"</span> <span class="o">=</span> <span class="s2">"aarch64"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then </span><span class="nv">HUBBLE_ARCH</span><span class="o">=</span>arm64<span class="p">;</span> <span class="k">fi</span>
<span class="nv">$ </span>curl <span class="nt">-L</span> <span class="nt">--fail</span> <span class="nt">--remote-name-all</span> https://github.com/cilium/hubble/releases/download/<span class="nv">$HUBBLE_VERSION</span>/hubble-linux-<span class="k">${</span><span class="nv">HUBBLE_ARCH</span><span class="k">}</span>.tar.gz<span class="o">{</span>,.sha256sum<span class="o">}</span>
<span class="nv">$ </span><span class="nb">sudo tar </span>xzvfC hubble-linux-<span class="k">${</span><span class="nv">HUBBLE_ARCH</span><span class="k">}</span>.tar.gz /usr/local/bin
<span class="c"># =&gt; hubble</span>
<span class="nv">$ </span>which hubble
<span class="c"># =&gt; /usr/local/bin/hubble</span>
<span class="nv">$ </span>hubble status
<span class="c"># =&gt; failed getting status: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:4245: connect: connection refused"</span>
</code></pre></div></div>

<ul>
  <li>Hubble client를 설치했지만 기본적으로 localhost를 통해 연결을 시도하기 때문에 연결이 되지 않습니다.
포트포워딩을 통해 hubble relay를 통해 연결할 수 있도록 설정합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>cilium hubble port-forward&amp;
<span class="c"># =&gt;   Hubble Relay is available at 127.0.0.1:4245</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 4245 포트가 localhost로 포워딩 되었습니다.&lt;/span&gt;</span>

<span class="nv">$ </span>ss <span class="nt">-tnlp</span> | <span class="nb">grep </span>4245
<span class="c"># =&gt; LISTEN 0      4096        127.0.0.1:4245       0.0.0.0:*    users:(("cilium",pid=3402,fd=7))</span>

<span class="c"># Now you can validate that you can access the Hubble API via the installed CLI</span>
<span class="nv">$ </span>hubble status
<span class="c"># =&gt; Healthcheck (via localhost:4245): Ok</span>
<span class="c">#    Current/Max Flows: 12,285/12,285 (100.00%)</span>
<span class="c">#    Flows/s: 31.55</span>
<span class="c">#    Connected Nodes: 3/3</span>

<span class="c"># hubble (api) server 기본 접속 주소 확인</span>
<span class="nv">$ </span>hubble config view 
<span class="c"># =&gt; ...</span>
<span class="c">#    port-forward-port: "4245"</span>
<span class="c">#    server: localhost:4245</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<h3 id="star-wars-demo를-통한-hubbleui-체험">Star Wars Demo를 통한 Hubble/UI 체험</h3>

<p><img src="/assets/2025/cilium/w2/20250727_cilium_w2_4.png" alt="img.png" class="image-center w-80" />
<em class="image-caption">목표 배포상태</em></p>

<ul>
  <li>스타워즈에서 영감을 받은 예제이며, deathstar, xwing, tiefighter의 세가지 마이크로 서비스로 구성되어 있습니다.</li>
  <li>deathstar는 80포트에서 http 웹서비스를 실행하며, 두 개의 pod 복제본에 걸쳐 로드 밸런싱을 수행합니다.</li>
  <li>deathstar 서비스는 empire의 우주선에 착륙 서비스를 제공하여 착륙 포트 요청을 할 수 있도록 합니다.</li>
  <li>tiefighter는 일반적인 제국 우주선의 착륙 요청 클라이언트 서비스를 나타내며 xwing은 연합 우주선의 착륙 요청 클라이언트 서비스를 나타냅니다.</li>
  <li>deathstar 착륙 서비스에 대한 접근 제어를 위한 다양한 보안 정책을 테스트하기 위하여 구성되었습니다.</li>
</ul>

<h4 id="데모-애플리케이션-배포">데모 애플리케이션 배포</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/minikube/http-sw-app.yaml
<span class="c"># =&gt; service/deathstar created</span>
<span class="c">#    deployment.apps/deathstar created</span>
<span class="c">#    pod/tiefighter created</span>
<span class="c">#    pod/xwing created</span>

<span class="c"># 파드 라벨 labels 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">--show-labels</span>
<span class="c"># =&gt; NAME                        READY   STATUS    RESTARTS   AGE   LABELS</span>
<span class="c">#    deathstar-8c4c77fb7-5zqmp   1/1     Running   0          12h   app.kubernetes.io/name=deathstar,class=deathstar,org=empire,pod-template-hash=8c4c77fb7</span>
<span class="c">#    deathstar-8c4c77fb7-h2rsh   1/1     Running   0          12h   app.kubernetes.io/name=deathstar,class=deathstar,org=empire,pod-template-hash=8c4c77fb7</span>
<span class="c">#    tiefighter                  1/1     Running   0          12h   app.kubernetes.io/name=tiefighter,class=tiefighter,org=empire</span>
<span class="c">#    xwing                       1/1     Running   0          12h   app.kubernetes.io/name=xwing,class=xwing,org=alliance</span>

<span class="nv">$ </span>kubectl get deploy,svc,ep deathstar
<span class="c"># =&gt; NAME                        READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/deathstar   2/2     2            2           12h</span>
<span class="c">#    </span>
<span class="c">#    NAME                TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE</span>
<span class="c">#    service/deathstar   ClusterIP   10.96.153.126   &lt;none&gt;        80/TCP    12h</span>
<span class="c">#    </span>
<span class="c">#    NAME                  ENDPOINTS                        AGE</span>
<span class="c">#    endpoints/deathstar   172.20.1.67:80,172.20.2.251:80   12h</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get ciliumendpoints.cilium.io <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE     NAME                           SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    default       deathstar-8c4c77fb7-5zqmp      46219               ready            172.20.2.251</span>
<span class="c">#    default       deathstar-8c4c77fb7-h2rsh      46219               ready            172.20.1.67</span>
<span class="c">#    default       tiefighter                     50993               ready            172.20.2.254</span>
<span class="c">#    default       xwing                          14847               ready            172.20.2.111</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-7m82r       30923               ready            172.20.0.134</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-dnc5n       30923               ready            172.20.1.13</span>
<span class="c">#    kube-system   hubble-relay-5dcd46f5c-n4zfx   5844                ready            172.20.2.144</span>
<span class="c">#    kube-system   hubble-ui-76d4965bb6-7mcft     14841               ready            172.20.1.30</span>
<span class="nv">$ </span>kubectl get ciliumidentities.cilium.io
<span class="c"># =&gt; NAME    NAMESPACE     AGE</span>
<span class="c">#    10901   default       12h</span>
<span class="c">#    14841   kube-system   37h</span>
<span class="c">#    14847   default       12h</span>
<span class="c">#    30923   kube-system   2d13h</span>
<span class="c">#    46219   default       12h</span>
<span class="c">#    50993   default       12h</span>
<span class="c">#    5844    kube-system   37h</span>

<span class="c"># in a multi-node installation, only the ones running on the same node will be listed</span>
<span class="c"># cilium 엔드포인트 목록 확인. 명령을 실행한 노드의 엔드포인트만 확인 가능합니다.</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium endpoint list
<span class="c"># =&gt; ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])                                                  IPv6   IPv4           STATUS</span>
<span class="c">#               ENFORCEMENT        ENFORCEMENT</span>
<span class="c">#    1332       Disabled           Disabled          1          k8s:node-role.kubernetes.io/control-plane                                                          ready</span>
<span class="c">#                                                               k8s:node.kubernetes.io/exclude-from-external-load-balancers</span>
<span class="c">#                                                               reserved:host</span>
<span class="c">#    1814       Disabled           Disabled          30923      k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=kube-system          172.20.0.134   ready</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.cluster=default</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.serviceaccount=coredns</span>
<span class="c">#                                                               k8s:io.kubernetes.pod.namespace=kube-system</span>
<span class="c">#                                                               k8s:k8s-app=kube-dns</span>
<span class="nv">$ </span>c0 endpoint list
<span class="c"># =&gt; ...</span>
<span class="c">#    1814 Disabled Disabled 30923 k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=kube-system 172.20.0.134   ready</span>
<span class="nv">$ </span>c1 endpoint list
<span class="c"># =&gt; ...</span>
<span class="c">#    507  Disabled Disabled 46219 k8s:app.kubernetes.io/name=deathstar                                       172.20.1.67   ready</span>
<span class="c">#    ...</span>
<span class="c">#    966  Disabled Disabled 30923 k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=kube-system 172.20.1.13   ready</span>
<span class="c">#    ...</span>
<span class="c">#    1864 Disabled Disabled 14841 k8s:app.kubernetes.io/name=hubble-ui                                       172.20.1.30   ready</span>
<span class="nv">$ </span>c2 endpoint list
<span class="c"># =&gt; ENDPOINT POLICY (ingress) POLICY (egress) IDENTITY LABELS (source:key[=value])                                                  IPv6   IPv4           STATUS</span>
<span class="c">#             ENFORCEMENT      ENFORCEMENT</span>
<span class="c">#    309      &lt;span style="color: green;"&gt;Disabled&lt;/span&gt;         &lt;span style="color: green;"&gt;Disabled&lt;/span&gt;        14847    k8s:app.kubernetes.io/name=xwing                                                    172.20.2.111   ready</span>
<span class="c">#    721      &lt;span style="color: green;"&gt;Disabled&lt;/span&gt;         &lt;span style="color: green;"&gt;Disabled&lt;/span&gt;        50993    k8s:app.kubernetes.io/name=tiefighter                                               172.20.2.254   ready</span>
<span class="c">#    1282     &lt;span style="color: green;"&gt;Disabled&lt;/span&gt;         &lt;span style="color: green;"&gt;Disabled&lt;/span&gt;        1        reserved:host                                                                                      ready</span>
<span class="c">#    1391     &lt;span style="color: green;"&gt;Disabled&lt;/span&gt;         &lt;span style="color: green;"&gt;Disabled&lt;/span&gt;        46219    k8s:app.kubernetes.io/name=deathstar                                                172.20.2.251   ready</span>
<span class="c">#                                                       &lt;span style="color: green;"&gt;k8s:class=deathstar&lt;/span&gt;</span>
<span class="c">#                                                       k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default</span>
<span class="c">#                                                       k8s:io.cilium.k8s.policy.cluster=default</span>
<span class="c">#                                                       k8s:io.cilium.k8s.policy.serviceaccount=default</span>
<span class="c">#                                                       k8s:io.kubernetes.pod.namespace=default</span>
<span class="c">#                                                       &lt;span style="color: green;"&gt;k8s:org=empire&lt;/span&gt;</span>
<span class="c">#    3027     &lt;span style="color: green;"&gt;Disabled&lt;/span&gt;         &lt;span style="color: green;"&gt;Disabled&lt;/span&gt;        5844     k8s:app.kubernetes.io/name=hubble-relay                                             172.20.2.144   ready</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 현재 ingress/egress 에 정책(Policy) 없음을 확인 할 수 있습니다. 또한 label을 통해 다양한 정보를 확인할 수 있습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<h4 id="현재-접근상태-확인">현재 접근상태 확인</h4>

<ul>
  <li>deathstar 서비스의 관점에서는 org=empire 라벨이 있는 우주선만 착륙을 요청할 수 있습니다.</li>
  <li>아직까지는 ingress/egress 정책이 없기 때문에 제국 우주선 뿐만 아니라 연합의 우주선 착륙 요청도 허용됩니다.</li>
  <li>아래의 명령을 통해 확인해보겠습니다</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 아래 출력에서 xwing 와 tiefighter 의 IDENTITY 값을 확인합니다.</span>
<span class="nv">$ </span>c1 endpoint list | <span class="nb">grep</span> <span class="nt">-iE</span> <span class="s1">'xwing|tiefighter|deathstar'</span>
<span class="c"># =&gt; 507        Disabled           Disabled          &lt;span style="color: green;"&gt;46219&lt;/span&gt;      k8s:app.kubernetes.io/name=deathstar                                                172.20.1.67   ready</span>
<span class="nv">$ </span>c2 endpoint list | <span class="nb">grep</span> <span class="nt">-iE</span> <span class="s1">'xwing|tiefighter|deathstar'</span>
<span class="c"># =&gt; 309        Disabled           Disabled          &lt;span style="color: green;"&gt;14847&lt;/span&gt;      k8s:app.kubernetes.io/name=xwing                                                    172.20.2.111   ready</span>
<span class="c">#    721        Disabled           Disabled          &lt;span style="color: green;"&gt;50993&lt;/span&gt;      k8s:app.kubernetes.io/name=tiefighter                                               172.20.2.254   ready</span>
<span class="c">#    1391       Disabled           Disabled          &lt;span style="color: green;"&gt;46219&lt;/span&gt;      k8s:app.kubernetes.io/name=deathstar                                                172.20.2.251   ready</span>
<span class="nv">$ XWINGID</span><span class="o">=</span>14847
<span class="nv">$ TIEFIGHTERID</span><span class="o">=</span>50993
<span class="nv">$ DEATHSTARID</span><span class="o">=</span>46219

<span class="c"># 모니터링 준비 : 터미널 3개, 단축키 설정</span>
<span class="c">## 각각 monitor 확인</span>
<span class="nv">$ </span>c0 monitor <span class="nt">-v</span> <span class="nt">-v</span>
<span class="nv">$ </span>c1 monitor <span class="nt">-v</span> <span class="nt">-v</span>
<span class="nv">$ </span>c2 monitor <span class="nt">-v</span> <span class="nt">-v</span>

<span class="c"># 모니터링 준비 : 터미널 1개</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span>

<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--from-identity</span> <span class="nv">$XWINGID</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--protocol</span> udp <span class="nt">--from-identity</span> <span class="nv">$XWINGID</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--protocol</span> tcp <span class="nt">--from-identity</span> <span class="nv">$XWINGID</span>

<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--protocol</span> tcp <span class="nt">--from-identity</span> <span class="nv">$DEATHSTARID</span>

<span class="c"># 호출 시도 1</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>xwing <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPOST</span> deathstar.default.svc.cluster.local/v1/request-landing
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>kubectl <span class="nb">exec </span>xwing <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPOST</span> deathstar.default.svc.cluster.local/v1/request-landing <span class="p">;</span> <span class="nb">sleep </span>5 <span class="p">;</span> <span class="k">done</span>

<span class="c"># 호출 시도 2</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>tiefighter <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPOST</span> deathstar.default.svc.cluster.local/v1/request-landing
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>kubectl <span class="nb">exec </span>tiefighter <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPOST</span> deathstar.default.svc.cluster.local/v1/request-landing <span class="p">;</span> <span class="nb">sleep </span>5 <span class="p">;</span> <span class="k">done</span>

<span class="c">## 모니터링</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--protocol</span> tcp <span class="nt">--from-identity</span> <span class="nv">$TIEFIGHTERID</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--protocol</span> tcp <span class="nt">--from-identity</span> <span class="nv">$DEATHSTARID</span>
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w2/20250727_cilium_w2_5.png" alt="img.png" class="image-center" />
<em class="image-caption">Hubble UI에서 모니터링</em></p>

<p><img src="/assets/2025/cilium/w2/20250727_cilium_w2_6.png" alt="img.png" class="image-center" />
<em class="image-caption">hubble observe에서 모니터링</em></p>

<ul>
  <li>제국군 우주선 tiefighter 뿐만아니라 연합군 우주선 xwing의 착륙 요청도 허용되고 있는것을 확인할 수 있습니다.</li>
</ul>

<h4 id="l3l4-정책-적용">L3/L4 정책 적용</h4>

<ul>
  <li><a href="https://docs.cilium.io/en/stable/gettingstarted/demo/#apply-an-l3-l4-policy">관련문서</a></li>
  <li>L3/L4 정책을 적용하여 제국 우주선만 착륙 요청을 허용하도록 합니다.</li>
</ul>

<p><img src="/assets/2025/cilium/w2/20250727_cilium_w2_7.png" alt="img.png" class="image-center" />
<em class="image-caption">L3/L4 정책 적용 후 목표 상태</em></p>

<ul>
  <li>Cilium의 보안정책은 <strong>Endpoint의 IP주소는 중요하지 않고</strong>, Pod의 <strong>label을 사용하여 보안 정책을 정의</strong>할 수 있습니다.</li>
  <li>아래의 정책을 적용하여 제국 우주선만 착륙 요청을 허용하도록 합니다. 이렇게하면 org=empire 라벨이 있는 Pod만 착륙 요청을 허용하게 되고,
해당 라벨이 없는 파드는 deathstar 서비스에 연결조차 할 수 없습니다. 이 정책은 IP 프로토콜(네트워크 계층 3)와 TCP 프로토콜(전송 계층 4)에만 적용하는
L3/L4 네트워크 보안 정책이라고 합니다.</li>
  <li>참고 : Cilium은 <strong>상태별 연결 추적</strong>을 수행합니다. 
즉, 프론트엔드가 백엔드에 도달할 수 있으면, 동일한 TCP/UDP 연결내의 응답은 자동으로 허용된다는것을 의미합니다.</li>
</ul>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># CiliumNetworkPolicy</span>
<span class="c1">## CiliumNetworkPolicys는 "endpointSelector"를 사용하여 팟 레이블에서 정책이 적용되는 소스와 목적지를 식별합니다. </span>
<span class="c1">## 아래 정책은 TCP 포트 80에서 레이블(org=empire)이 있는 모든 팟에서 레이블(org=empire, class=deathstar)이 있는 데스스타 팟으로 전송되는 트래픽을 화이트리스트로 작성합니다.</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s2">"</span><span class="s">cilium.io/v2"</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">CiliumNetworkPolicy</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s2">"</span><span class="s">rule1"</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">description</span><span class="pi">:</span> <span class="s2">"</span><span class="s">L3-L4</span><span class="nv"> </span><span class="s">policy</span><span class="nv"> </span><span class="s">to</span><span class="nv"> </span><span class="s">restrict</span><span class="nv"> </span><span class="s">deathstar</span><span class="nv"> </span><span class="s">access</span><span class="nv"> </span><span class="s">to</span><span class="nv"> </span><span class="s">empire</span><span class="nv"> </span><span class="s">ships</span><span class="nv"> </span><span class="s">only"</span>
  <span class="na">endpointSelector</span><span class="pi">:</span>
    <span class="na">matchLabels</span><span class="pi">:</span>
      <span class="na">org</span><span class="pi">:</span> <span class="s">empire</span>
      <span class="na">class</span><span class="pi">:</span> <span class="s">deathstar</span>
  <span class="na">ingress</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">fromEndpoints</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">matchLabels</span><span class="pi">:</span>
        <span class="na">org</span><span class="pi">:</span> <span class="s">empire</span>
    <span class="na">toPorts</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">port</span><span class="pi">:</span> <span class="s2">"</span><span class="s">80"</span>
        <span class="na">protocol</span><span class="pi">:</span> <span class="s">TCP</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/minikube/sw_l3_l4_policy.yaml
<span class="c"># =&gt; ciliumnetworkpolicy.cilium.io/rule1 created</span>
<span class="nv">$ </span>kubectl get cnp
<span class="c"># =&gt; NAME    AGE   VALID</span>
<span class="c">#    rule1   8s    True</span>
<span class="nv">$ </span>kubectl get cnp <span class="nt">-o</span> json | jq
<span class="c"># =&gt; ...</span>
<span class="c">#          "spec": {</span>
<span class="c">#            "description": "L3-L4 policy to restrict deathstar access to empire ships only",</span>
<span class="c">#            "endpointSelector": {</span>
<span class="c">#              "matchLabels": {</span>
<span class="c">#                "class": "deathstar",</span>
<span class="c">#                "org": "empire"</span>
<span class="c">#              }</span>
<span class="c">#            },</span>
<span class="c">#            "ingress": [ { </span>
<span class="c">#                 "fromEndpoints": [ { "matchLabels": { "org": "empire" } } ],</span>
<span class="c">#                 "toPorts": [ { "ports": [ { "port": "80", "protocol": "TCP" } ] } ]</span>
<span class="c">#            } ]</span>
<span class="c">#          },</span>
<span class="c">#    ...</span>

<span class="c"># 모니터링</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--type</span> drop

<span class="c"># 호출 시도 1 </span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>xwing <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPOST</span> deathstar.default.svc.cluster.local/v1/request-landing <span class="nt">--connect-timeout</span> 2
<span class="c"># =&gt; command terminated with exit code 28</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 연합군의 우주선 xwing의 착륙 요청은 거부되었습니다!&lt;/span&gt;</span>

<span class="c"># &lt;span style="color: green;"&gt;👉 DROP 된 패킷 모니터링&lt;/span&gt;</span>
<span class="c"># =&gt; (⎈|HomeLab:N/A) root@k8s-ctr:~# hubble observe -f --type drop</span>
<span class="c">#    Jul 26 07:50:53.384: default/xwing:46590 (ID:14847) &lt;&gt; default/deathstar-8c4c77fb7-h2rsh:80 (ID:46219) Policy denied DROPPED (TCP Flags: SYN)</span>
<span class="c">#    Jul 26 07:50:54.407: default/xwing:46590 (ID:14847) &lt;&gt; default/deathstar-8c4c77fb7-h2rsh:80 (ID:46219) Policy denied DROPPED (TCP Flags: SYN)</span>

<span class="c"># 모니터링 </span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--protocol</span> tcp <span class="nt">--from-identity</span> <span class="nv">$DEATHSTARID</span>

<span class="c"># 호출 시도 2</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>tiefighter <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPOST</span> deathstar.default.svc.cluster.local/v1/request-landing
<span class="c"># =&gt; Ship landed</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 제국군의 우주선 tiefighter의 착륙 요청은 허용되었습니다!&lt;/span&gt;</span>

<span class="c"># &lt;span style="color: green;"&gt;👉 허용된 패킷 모니터링&lt;/span&gt;</span>
<span class="c"># =&gt; (⎈|HomeLab:N/A) root@k8s-ctr:~# hubble observe -f --protocol tcp --from-identity $DEATHSTARID</span>
<span class="c">#    Jul 26 07:52:52.016: default/tiefighter:43410 (ID:50993) &lt;- default/deathstar-8c4c77fb7-5zqmp:80 (ID:46219) to-endpoint FORWARDED (TCP Flags: SYN, ACK)</span>
<span class="c">#    Jul 26 07:52:52.016: default/deathstar-8c4c77fb7-5zqmp:80 (ID:46219) &lt;&gt; default/tiefighter (ID:50993) pre-xlate-rev TRACED (TCP)</span>
<span class="c">#    Jul 26 07:52:52.016: default/deathstar-8c4c77fb7-5zqmp:80 (ID:46219) &lt;&gt; default/tiefighter (ID:50993) pre-xlate-rev TRACED (TCP)</span>
<span class="c">#    Jul 26 07:52:52.019: default/tiefighter:43410 (ID:50993) &lt;- default/deathstar-8c4c77fb7-5zqmp:80 (ID:46219) to-endpoint FORWARDED (TCP Flags: ACK, PSH)</span>
<span class="c">#    Jul 26 07:52:52.021: default/tiefighter:43410 (ID:50993) &lt;- default/deathstar-8c4c77fb7-5zqmp:80 (ID:46219) to-endpoint FORWARDED (TCP Flags: ACK, FIN)</span>
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w2/20250727_cilium_w2_8.png" alt="img.png" /></p>

<ul>
  <li>정책을 확인해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># deathstar 에 ingress 에 policy 활성화 확인</span>
<span class="nv">$ </span>c0 endpoint list
<span class="nv">$ </span>c1 endpoint list
<span class="c"># =&gt; ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])                                                  IPv6   IPv4          STATUS</span>
<span class="c">#               ENFORCEMENT        ENFORCEMENT</span>
<span class="c">#    ...</span>
<span class="c">#    507        &lt;span style="color: green;"&gt;Enabled&lt;/span&gt;            Disabled          46219      k8s:app.kubernetes.io/name=deathstar                                                172.20.1.67   ready</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>c2 endpoint list
<span class="c"># =&gt; ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])                                                  IPv6   IPv4           STATUS</span>
<span class="c">#               ENFORCEMENT        ENFORCEMENT</span>
<span class="c">#    ...</span>
<span class="c">#    1391       &lt;span style="color: green;"&gt;Enabled&lt;/span&gt;            Disabled          46219      k8s:app.kubernetes.io/name=deathstar                                                172.20.2.251   ready</span>
<span class="c">#    ...</span>
                                                           
<span class="nv">$ </span>kc describe cnp rule1
<span class="c"># =&gt; ...</span>
<span class="c">#    Spec:</span>
<span class="c">#      Description:  L3-L4 policy to restrict deathstar access to empire ships only</span>
<span class="c">#      Endpoint Selector:</span>
<span class="c">#        Match Labels:</span>
<span class="c">#          Class:  deathstar</span>
<span class="c">#          Org:    empire</span>
<span class="c">#      Ingress:</span>
<span class="c">#        From Endpoints:</span>
<span class="c">#          Match Labels:</span>
<span class="c">#            Org:  empire</span>
<span class="c">#        To Ports:</span>
<span class="c">#          Ports:</span>
<span class="c">#            Port:      80</span>
<span class="c">#            Protocol:  TCP</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<ul>
  <li>Life of a Packet : L7 동작 처리는 cilium-envoy 데몬셋이 담당합니다. <a href="https://docs.cilium.io/en/stable/network/ebpf/lifeofapacket/">Docs</a></li>
</ul>

<p><img src="/assets/2025/cilium/w2/20250727_cilium_w2_9.png" alt="img.png" /></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>kubectl get ds <span class="nt">-n</span> kube-system
<span class="c"># =&gt; NAME           DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE</span>
<span class="c">#    cilium         3         3         3       3            3           kubernetes.io/os=linux   2d17h</span>
<span class="c">#    cilium-envoy   3         3         3       3            3           kubernetes.io/os=linux   2d17h</span>

<span class="nv">$ </span>kubectl get pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium-envoy <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                 READY   STATUS    RESTARTS        AGE     IP               NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    cilium-envoy-q97fq   1/1     Running   3 (3h59m ago)   2d16h   192.168.10.102   k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    cilium-envoy-xzxd6   1/1     Running   3 (3h59m ago)   2d16h   192.168.10.101   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    cilium-envoy-zzzw5   1/1     Running   3 (3h59m ago)   2d17h   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>

<span class="c">#</span>
<span class="nv">$ </span>kc describe ds <span class="nt">-n</span> kube-system cilium-envoy
<span class="c"># =&gt;     Mounts:</span>
<span class="c">#          /sys/fs/bpf from bpf-maps (rw)</span>
<span class="c">#          /var/run/cilium/envoy/ from envoy-config (ro)</span>
<span class="c">#          /var/run/cilium/envoy/artifacts from envoy-artifacts (ro)</span>
<span class="c">#          &lt;span style="color: green;"&gt;/var/run/cilium/envoy/sockets from envoy-sockets (rw)&lt;/span&gt;</span>
<span class="c">#    ...</span>
<span class="c">#       envoy-config:</span>
<span class="c">#        Type:      ConfigMap (a volume populated by a ConfigMap)</span>
<span class="c">#        Name:      &lt;span style="color: green;"&gt;cilium-envoy-config&lt;/span&gt;</span>
<span class="c">#        Optional:  false</span>
<span class="c">#    ...</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> ss <span class="nt">-xnp</span> | <span class="nb">grep</span> <span class="nt">-i</span> <span class="nt">-envoy</span>
<span class="c"># =&gt; u_str  ESTAB  0  0  /var/run/cilium/envoy/sockets/admin.sock  16193  *  16192</span>
<span class="c">#    u_str  ESTAB  0  0  /var/run/cilium/envoy/sockets/admin.sock  17068  *  17067</span>
<span class="c">#    u_str  ESTAB  0  0  /var/run/cilium/envoy/sockets/xds.sock    15993  *  15992  users:(("cilium-agent",pid=1,fd=106))</span>

<span class="nv">$ </span>kc describe cm <span class="nt">-n</span> kube-system cilium-envoy-config
<span class="c"># =&gt; ...</span>
<span class="c">#    Data</span>
<span class="c">#    ====</span>
<span class="c">#    bootstrap-config.json:</span>
<span class="c">#    ----</span>
<span class="c">#    {"admin":{"address":{"pipe":{"path":"/var/run/cilium/envoy/sockets/admin.sock"}}}...</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<h4 id="http-aware-l7-정책-적용-및-테스트">HTTP-aware L7 정책 적용 및 테스트</h4>

<ul>
  <li>HTTP-aware L7 정책을 적용하고 테스트해보겠습니다. <a href="https://docs.cilium.io/en/stable/gettingstarted/demo/#apply-and-test-http-aware-l7-policy">Docs</a></li>
</ul>

<p><img src="/assets/2025/cilium/w2/20250727_cilium_w2_10.png" alt="img.png" class="image-center" /></p>

<ul>
  <li>이전의 간단한 시나리오에서는 tiefighter와 xwing에게 deathstar API에 대한 전체 액세스 권한을 부여하거나, 접속 자체를 차단하는것으로 충분햇습니다.</li>
  <li>하지만 마이크로 서비스 간의 강력한 보안(즉, 최소 권한 격리를 강제하는 것)을 제공하기 위해서는 deathstar API를 호출하는 각 서비스가 운영에 필요한 HTTP 요청만 수행하도록 제한 할 수 있어야 합니다.</li>
  <li>예를 들어 deathstar 서비스가 임의의 제국 우주선이 호출해서는 안 되는 유지보수 API를 제공한다고 가정해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 모니터링 &gt;&gt; Layer3/4 에서는 애플리케이션 상태를 확인 할 수 없음!</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--protocol</span> tcp <span class="nt">--from-identity</span> <span class="nv">$DEATHSTARID</span>
<span class="c"># =&gt; Jul 26 08:29:39.157: default/tiefighter:48472 (ID:50993) &lt;- default/deathstar-8c4c77fb7-h2rsh:80 (ID:46219) to-network FORWARDED (TCP Flags: SYN, ACK)</span>
<span class="c">#    Jul 26 08:29:39.161: default/tiefighter:48472 (ID:50993) &lt;- default/deathstar-8c4c77fb7-h2rsh:80 (ID:46219) to-network FORWARDED (TCP Flags: ACK, PSH)</span>
<span class="c">#    Jul 26 08:29:39.164: default/tiefighter:48472 (ID:50993) &lt;- default/deathstar-8c4c77fb7-h2rsh:80 (ID:46219) to-network FORWARDED (TCP Flags: ACK, FIN)</span>
<span class="c">#    Jul 26 08:29:39.201: default/tiefighter:48472 (ID:50993) &lt;- default/deathstar-8c4c77fb7-h2rsh:80 (ID:46219) to-endpoint FORWARDED (TCP Flags: SYN, ACK)</span>
<span class="c">#    Jul 26 08:29:39.201: default/deathstar-8c4c77fb7-h2rsh:80 (ID:46219) &lt;&gt; default/tiefighter (ID:50993) pre-xlate-rev TRACED (TCP)</span>
<span class="c">#    Jul 26 08:29:39.201: default/deathstar-8c4c77fb7-h2rsh:80 (ID:46219) &lt;&gt; default/tiefighter (ID:50993) pre-xlate-rev TRACED (TCP)</span>
<span class="c">#    Jul 26 08:29:39.205: default/tiefighter:48472 (ID:50993) &lt;- default/deathstar-8c4c77fb7-h2rsh:80 (ID:46219) to-endpoint FORWARDED (TCP Flags: ACK, PSH)</span>
<span class="c">#    Jul 26 08:29:39.207: default/tiefighter:48472 (ID:50993) &lt;- default/deathstar-8c4c77fb7-h2rsh:80 (ID:46219) to-endpoint FORWARDED (TCP Flags: ACK, FIN)</span>

<span class="c"># 호출해서는 안 되는 일부 유지보수 API를 노출</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>tiefighter <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPUT</span> deathstar.default.svc.cluster.local/v1/exhaust-port
<span class="c"># =&gt; Panic: deathstar exploded</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 임의로 호출해서는 안되는 API가 실행되어 deathstar가 폭발했습니다!&lt;/span&gt;</span>
</code></pre></div></div>

<h5 id="cilium을-통한-l7-정책-적용">cilium을 통한 L7 정책 적용</h5>

<ul>
  <li>cilium은 HTTP 계층(L7) 정책을 적용하여 tiefighter가 사용할 수 있는 API URL을 제한할 수 있습니다. 다음은 tiefighter가 POST /v1/request-landing URL에만 액세스할 수 있도록 하는 정책입니다.</li>
</ul>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 기존 rule1 정책을 업데이트 해서 사용</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s2">"</span><span class="s">cilium.io/v2"</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">CiliumNetworkPolicy</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s2">"</span><span class="s">rule1"</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">description</span><span class="pi">:</span> <span class="s2">"</span><span class="s">L7</span><span class="nv"> </span><span class="s">policy</span><span class="nv"> </span><span class="s">to</span><span class="nv"> </span><span class="s">restrict</span><span class="nv"> </span><span class="s">access</span><span class="nv"> </span><span class="s">to</span><span class="nv"> </span><span class="s">specific</span><span class="nv"> </span><span class="s">HTTP</span><span class="nv"> </span><span class="s">call"</span>
  <span class="na">endpointSelector</span><span class="pi">:</span>
    <span class="na">matchLabels</span><span class="pi">:</span>
      <span class="na">org</span><span class="pi">:</span> <span class="s">empire</span>
      <span class="na">class</span><span class="pi">:</span> <span class="s">deathstar</span>
  <span class="na">ingress</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">fromEndpoints</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">matchLabels</span><span class="pi">:</span>
        <span class="na">org</span><span class="pi">:</span> <span class="s">empire</span>
    <span class="na">toPorts</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">port</span><span class="pi">:</span> <span class="s2">"</span><span class="s">80"</span>
        <span class="na">protocol</span><span class="pi">:</span> <span class="s">TCP</span>
      <span class="na">rules</span><span class="pi">:</span>
        <span class="na">http</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">method</span><span class="pi">:</span> <span class="s2">"</span><span class="s">POST"</span>
          <span class="na">path</span><span class="pi">:</span> <span class="s2">"</span><span class="s">/v1/request-landing"</span>
</code></pre></div></div>

<ul>
  <li>tiefigher 에는 착륙 요청만 허용하는 L7 정책 적용후 deathstar 서비스에 착륙 요청을 해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Update the existing rule to apply L7-aware policy to protect deathstar using:</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/minikube/sw_l3_l4_l7_policy.yaml
<span class="c"># =&gt; ciliumnetworkpolicy.cilium.io/rule1 configured</span>
<span class="nv">$ </span>kubectl get cnp
<span class="c"># =&gt; NAME    AGE    VALID</span>
<span class="c">#    rule1   168m   True</span>
<span class="nv">$ </span>kc describe cnp
<span class="c"># =&gt; ...</span>
<span class="c">#    Spec:</span>
<span class="c">#      Description:  L7 policy to restrict access to specific HTTP call</span>
<span class="c">#      Endpoint Selector:</span>
<span class="c">#        Match Labels:</span>
<span class="c">#          Class:  deathstar</span>
<span class="c">#          Org:    empire</span>
<span class="c">#      Ingress:</span>
<span class="c">#        From Endpoints:</span>
<span class="c">#          Match Labels:</span>
<span class="c">#            Org:  empire</span>
<span class="c">#        To Ports:</span>
<span class="c">#          Ports:</span>
<span class="c">#            Port:      80</span>
<span class="c">#            Protocol:  TCP</span>
<span class="c">#          Rules:</span>
<span class="c">#            Http:</span>
<span class="c">#              Method:  POST</span>
<span class="c">#              Path:    /v1/request-landing</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>c0 policy get

<span class="c"># 파드 이름 지정하여 모니터링</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--pod</span> deathstar <span class="nt">--protocol</span> http
Jul 20 01:28:02.184: default/tiefighter:59020 <span class="o">(</span>ID:19274<span class="o">)</span> -&gt; default/deathstar-8c4c77fb7-9klws:80 <span class="o">(</span>ID:318<span class="o">)</span> http-request FORWARDED <span class="o">(</span>HTTP/1.1 POST http://deathstar.default.svc.cluster.local/v1/request-landing<span class="o">)</span>
Jul 20 01:28:02.190: default/tiefighter:59020 <span class="o">(</span>ID:19274<span class="o">)</span> &lt;- default/deathstar-8c4c77fb7-9klws:80 <span class="o">(</span>ID:318<span class="o">)</span> http-response FORWARDED <span class="o">(</span>HTTP/1.1 200 6ms <span class="o">(</span>POST http://deathstar.default.svc.cluster.local/v1/request-landing<span class="o">))</span>

<span class="c"># 착륙 요청을 테스트해보겠습니다.</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>tiefighter <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPOST</span> deathstar.default.svc.cluster.local/v1/request-landing
<span class="c"># =&gt; Ship landed</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 당연히 API 호출에 성공합니다.&lt;/span&gt;</span>
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w2/20250727_cilium_w2_11.png" alt="img.png" /></p>

<ul>
  <li>이번에는 tiefighter가 허용되지 않은 API를 호출해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 파드 이름 지정하여 드랍된 패킷 모니터링</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--pod</span> deathstar <span class="nt">--verdict</span> DROPPED
<span class="c"># =&gt; Jul 26 10:48:17.734: default/tiefighter:40606 (ID:50993) -&gt; default/deathstar-8c4c77fb7-h2rsh:80 (ID:46219) http-request DROPPED (HTTP/1.1 PUT http://deathstar.default.svc.cluster.local/v1/exhaust-port)</span>

<span class="c"># 혹은</span>
<span class="nv">$ </span>c1 monitor <span class="nt">-v</span> <span class="nt">--type</span> l7
<span class="nv">$ </span>c2 monitor <span class="nt">-v</span> <span class="nt">--type</span> l7
<span class="c"># =&gt; &lt;- Request http from 721 ([k8s:app.kubernetes.io/name=tiefighter k8s:class=tiefighter k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default k8s:io.cilium.k8s.policy.cluster=default k8s:io.cilium.k8s.policy.serviceaccount=default k8s:io.kubernetes.pod.namespace=default k8s:org=empire]) to 1391 ([k8s:app.kubernetes.io/name=deathstar k8s:class=deathstar k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default k8s:io.cilium.k8s.policy.cluster=default k8s:io.cilium.k8s.policy.serviceaccount=default k8s:io.kubernetes.pod.namespace=default k8s:org=empire]), identity 50993-&gt;46219, verdict Denied PUT http://deathstar.default.svc.cluster.local/v1/exhaust-port =&gt; 0</span>
<span class="c">#    &lt;- Response http to 721 ([k8s:app.kubernetes.io/name=tiefighter k8s:class=tiefighter k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default k8s:io.cilium.k8s.policy.cluster=default k8s:io.cilium.k8s.policy.serviceaccount=default k8s:io.kubernetes.pod.namespace=default k8s:org=empire]) from 1391 ([k8s:app.kubernetes.io/name=deathstar k8s:class=deathstar k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default k8s:io.cilium.k8s.policy.cluster=default k8s:io.cilium.k8s.policy.serviceaccount=default k8s:io.kubernetes.pod.namespace=default k8s:org=empire]), identity 46219-&gt;50993, verdict Forwarded PUT http://deathstar.default.svc.cluster.local/v1/exhaust-port =&gt; 403</span>

<span class="c"># 앞서 deathstar를 폭파시켰던 tiefighter에게 허용되지 않은 API를 호출해보겠습니다.</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>tiefighter <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPUT</span> deathstar.default.svc.cluster.local/v1/exhaust-port
<span class="c"># =&gt; Access denied</span>
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w2/20250727_cilium_w2_12.png" alt="img.png" class="image-center" />
<em class="image-caption">L7 정책에 의해 허용되지 않은 API 호출이 거부된 모습</em></p>

<ul>
  <li>xwing으로 착륙요청을 해서 위와 차이점을 확인해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 모니터링 : 파드 이름 지정</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--pod</span> xwing

<span class="c"># 호출 시도 : 위와 아래 실행 종료의 차이점을 이해해보자!</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>xwing <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPOST</span> deathstar.default.svc.cluster.local/v1/request-landing <span class="nt">--connect-timeout</span> 2
<span class="c"># =&gt; command terminated with exit code 28</span>

<span class="c"># (⎈|HomeLab:N/A) root@k8s-ctr:~# hubble observe -f --pod xwing</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    Jul 26 10:50:31.048: default/xwing:57832 (ID:14847) -&gt; default/deathstar-8c4c77fb7-h2rsh:80 (ID:46219) to-network FORWARDED (TCP Flags: SYN)</span>
<span class="c">#    Jul 26 10:50:31.049: default/xwing:57832 (ID:14847) &lt;&gt; default/deathstar-8c4c77fb7-h2rsh:80 (ID:46219) policy-verdict:none INGRESS DENIED (TCP Flags: SYN)</span>
<span class="c">#    Jul 26 10:50:31.049: default/xwing:57832 (ID:14847) &lt;&gt; default/deathstar-8c4c77fb7-h2rsh:80 (ID:46219) Policy denied DROPPED (TCP Flags: SYN)</span>
<span class="c">#    ...</span>
<span class="c">#    Jul 26 10:50:32.053: default/xwing:57832 (ID:14847) &lt;&gt; default/deathstar-8c4c77fb7-h2rsh:80 (ID:46219) policy-verdict:none INGRESS DENIED (TCP Flags: SYN)</span>
<span class="c">#    Jul 26 10:50:32.053: default/xwing:57832 (ID:14847) &lt;&gt; default/deathstar-8c4c77fb7-h2rsh:80 (ID:46219) Policy denied DROPPED (TCP Flags: SYN)</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 xwing의 deathstar로의 접근은 TCP (L4) 연결 자체가 차단(DROP)됨을 확인할 수 있습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w2/20250727_cilium_w2_13.png" alt="img.png" class="image-center" />
<em class="image-caption">xwing이 L7 정책 이전에 L4 정책에 의해 deathstar로의 접근이 차단된 모습</em></p>

<ul>
  <li>다음 실습을 위해 리소스를 삭제하겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 다음 실습을 위해 리소스 삭제</span>
<span class="nv">$ </span>kubectl delete <span class="nt">-f</span> https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/minikube/http-sw-app.yaml
<span class="c"># =&gt; service "deathstar" deleted</span>
<span class="c">#    deployment.apps "deathstar" deleted</span>
<span class="c">#    pod "tiefighter" deleted</span>
<span class="c">#    pod "xwing" deleted</span>
<span class="nv">$ </span>kubectl delete cnp rule1
<span class="c"># =&gt; ciliumnetworkpolicy.cilium.io "rule1" deleted</span>

<span class="c"># 삭제 확인</span>
<span class="nv">$ </span>kubectl get cnp
<span class="c"># =&gt; No resources found in default namespace.</span>
</code></pre></div></div>

<h4 id="configuring-hubble-exporter">Configuring Hubble Exporter</h4>

<ul>
  <li>흐름 로그 - <a href="https://docs.cilium.io/en/stable/observability/hubble/configuration/export/">Docs</a></li>
  <li>Hubble Exporter는 나중에 사용할 수 있도록 Hubble flows 로그를 파일에 저장하는 cilium-agent의 기능입니다.</li>
  <li>Hubble Exporter는 file rotation, size limits, filters, field masks를 지원합니다.</li>
  <li>Hubble Exporter는 다음과 같이 설정합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># &lt;span style="color: green;"&gt;👉 이미 cilium 설치할때 적용되어서 실습 과정에는 적용할 필요가 없습니다.&lt;/span&gt;</span>
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--namespace</span> kube-system <span class="nt">--reuse-values</span> <span class="se">\</span>
   <span class="nt">--set</span> hubble.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
   <span class="nt">--set</span> hubble.export.static.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
   <span class="nt">--set</span> hubble.export.static.filePath<span class="o">=</span>/var/run/cilium/hubble/events.log

<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system rollout status ds/cilium
</code></pre></div></div>

<ul>
  <li>Hubble Exporter의 설정을 확인해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get cm <span class="nt">-n</span> kube-system cilium-config <span class="nt">-o</span> json | <span class="nb">grep </span>hubble-export
<span class="nv">$ </span>cilium config view | <span class="nb">grep </span>hubble-export
<span class="c"># =&gt; hubble-export-allowlist</span>
<span class="c">#    hubble-export-denylist</span>
<span class="c">#    hubble-export-fieldmask</span>
<span class="c">#    hubble-export-file-max-backups   5     # rotate된 Hubble export 파일을 유지할 수 있는 최대 개수. (기본값: 5)</span>
<span class="c">#    hubble-export-file-max-size-mb   10    # Hubble export 파일을 rotate할 때의 크기(MB). (기본값: 10)</span>
<span class="c">#    hubble-export-file-path          /var/run/cilium/hubble/events.log   # 대상 로그 파일의 경로. (기본값: /var/run/cilium/hubble/events.log)</span>

<span class="c"># Verify that flow logs are stored in target files</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system <span class="nb">exec </span>ds/cilium <span class="nt">--</span> <span class="nb">tail</span> <span class="nt">-f</span> /var/run/cilium/hubble/events.log
<span class="c"># &lt;span style="color: green;"&gt;👉 로그가 계속 나옵니다.&lt;/span&gt;</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system <span class="nb">exec </span>ds/cilium <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'tail -f /var/run/cilium/hubble/events.log'</span> | jq
<span class="c"># &lt;span style="color: green;"&gt;👉 로그가 json 형태로 계속 나옵니다.&lt;/span&gt;</span>
</code></pre></div></div>

<h2 id="prometheus와-grafana를-통한-모니터링">Prometheus와 Grafana를 통한 모니터링</h2>

<ul>
  <li>Prometheus와 Grafana를 통해 Cilium의 모니터링을 할 수 있습니다. <a href="https://docs.cilium.io/en/stable/observability/grafana/">Docs</a></li>
  <li>널리 알려진 툴들이라 다들 아시겠지만 간략하게 소개해 보겠습니다.
    <ul>
      <li><strong>Prometheus</strong> : 오픈 소스 모니터링 시스템으로, 시계열 데이터베이스를 사용하여 메트릭을 수집하고 저장합니다. 일종의 TSDB(Time Series Database)로, 메트릭을 수집하고 쿼리할 수 있는 강력한 기능을 제공합니다.</li>
      <li><strong>Grafana</strong> : 시각화 도구로, Prometheus와 같은 데이터 소스에서 수집된 메트릭을 대시보드 형태로 시각화할 수 있습니다. 다양한 플러그인을 통해 다양한 데이터 소스를 지원합니다.</li>
    </ul>
  </li>
  <li>추천글
    <ul>
      <li>악분님 프로메테우스 오퍼레이터 소개 - <a href="https://malwareanalysis.tistory.com/566">Blog</a></li>
      <li>hanhorang님 타노스 소개 - <a href="https://hanhorang31.github.io/post/pkos2-4-monitoring/">Blog</a></li>
      <li>[AWS EC2] 프로메테우스 직접 설치 - <a href="https://prometheus.io/docs/prometheus/latest/getting_started/">Docs</a></li>
    </ul>
  </li>
</ul>

<h3 id="샘플-애플리케이션-배포-및-확인">샘플 애플리케이션 배포 및 확인</h3>

<ul>
  <li>Prometheus와 Grafana를 설치하기 전에 샘플 애플리케이션을 배포하고, Cilium의 모니터링을 확인해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 샘플 애플리케이션 배포</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webpod
spec:
  replicas: 2
  selector:
    matchLabels:
      app: webpod
  template:
    metadata:
      labels:
        app: webpod
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - sample-app
            topologyKey: "kubernetes.io/hostname"
      containers:
      - name: webpod
        image: traefik/whoami
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: webpod
  labels:
    app: webpod
spec:
  selector:
    app: webpod
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
  type: ClusterIP
</span><span class="no">EOF

</span><span class="c"># k8s-ctr 노드에 curl-pod 파드 배포</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: curl-pod
  labels:
    app: curl
spec:
  nodeName: k8s-ctr
  containers:
  - name: curl
    image: nicolaka/netshoot
    command: ["tail"]
    args: ["-f", "/dev/null"]
  terminationGracePeriodSeconds: 0
</span><span class="no">EOF
</span></code></pre></div></div>

<ul>
  <li>샘플 애플리케이션이 배포되었는지 확인해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 배포 확인</span>
<span class="nv">$ </span>kubectl get deploy,svc,ep webpod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                     READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES           SELECTOR</span>
<span class="c">#    deployment.apps/webpod   2/2     2            2           41s   webpod       traefik/whoami   app=webpod</span>
<span class="c">#    </span>
<span class="c">#    NAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE   SELECTOR</span>
<span class="c">#    service/webpod   ClusterIP   10.96.147.79   &lt;none&gt;        80/TCP    41s   app=webpod</span>
<span class="c">#    </span>
<span class="c">#    NAME               ENDPOINTS                       AGE</span>
<span class="c">#    endpoints/webpod   172.20.1.4:80,172.20.2.101:80   41s</span>
<span class="nv">$ </span>kubectl get endpointslices <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>webpod
<span class="c"># =&gt; NAME           ADDRESSTYPE   PORTS   ENDPOINTS                 AGE</span>
<span class="c">#    webpod-g9ldp   IPv4          80      172.20.1.4,172.20.2.101   49s</span>
<span class="nv">$ </span>kubectl get ciliumendpoints
<span class="c"># =&gt; NAME                      SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    curl-pod                  472                 ready            172.20.0.43</span>
<span class="c">#    webpod-697b545f57-mvz92   18655               ready            172.20.2.101</span>
<span class="c">#    webpod-697b545f57-ns4sw   18655               ready            172.20.1.4</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium-dbg endpoint list
<span class="c"># =&gt; ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])                                                  IPv6   IPv4           STATUS</span>
<span class="c">#               ENFORCEMENT        ENFORCEMENT</span>
<span class="c">#    272        Disabled           Disabled          472        k8s:app=curl                                                                        172.20.0.43    ready</span>
<span class="c">#                                                               k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.cluster=default</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.serviceaccount=default</span>
<span class="c">#                                                               k8s:io.kubernetes.pod.namespace=default</span>
<span class="c">#    1332       Disabled           Disabled          1          k8s:node-role.kubernetes.io/control-plane                                                          ready</span>
<span class="c">#                                                               k8s:node.kubernetes.io/exclude-from-external-load-balancers</span>
<span class="c">#                                                               reserved:host</span>
<span class="c">#    1814       Disabled           Disabled          30923      k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=kube-system          172.20.0.134   ready</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.cluster=default</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.serviceaccount=coredns</span>
<span class="c">#                                                               k8s:io.kubernetes.pod.namespace=kube-system</span>
<span class="c">#                                                               k8s:k8s-app=kube-dns</span>

<span class="c"># 통신 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl webpod | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod-697b545f57-mvz92</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s webpod | grep Hostname; sleep 1; done'</span>
<span class="c"># =&gt; Hostname: webpod-697b545f57-ns4sw</span>
<span class="c">#    Hostname: webpod-697b545f57-mvz92</span>
<span class="c">#    Hostname: webpod-697b545f57-mvz92</span>
<span class="c">#    Hostname: webpod-697b545f57-ns4sw</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<h3 id="prometheus-와-grafana-설치-및-설정">Prometheus 와 Grafana 설치 및 설정</h3>

<ul>
  <li>이번 예제는 Prometheus와 Grafana를 한번에 설치하는 예제를 따라하며 진행해보겠습니다. <a href="https://www.youtube.com/watch?v=DdWksYq5Pv4">Youtube 영상</a>
    <ul>
      <li>배포 파일에 Grafana에는 Cilium Dashboard가 포함되어 있습니다.</li>
      <li>이번 예제 배포파일에는 Prometheus와 Grafana가 Cilium과 Hubble의 메트릭을 자동으로 수집하고 시각화할 수 있도록 설정되어 있습니다.</li>
    </ul>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/kubernetes/addons/prometheus/monitoring-example.yaml
<span class="c"># =&gt; namespace/cilium-monitoring created</span>
<span class="c">#    serviceaccount/prometheus-k8s created</span>
<span class="c">#    configmap/grafana-config created</span>
<span class="c">#    configmap/grafana-cilium-dashboard created</span>
<span class="c">#    configmap/grafana-cilium-operator-dashboard created</span>
<span class="c">#    configmap/grafana-hubble-dashboard created</span>
<span class="c">#    configmap/grafana-hubble-l7-http-metrics-by-workload created</span>
<span class="c">#    configmap/prometheus created</span>
<span class="c">#    clusterrole.rbac.authorization.k8s.io/prometheus created</span>
<span class="c">#    clusterrolebinding.rbac.authorization.k8s.io/prometheus created</span>
<span class="c">#    service/grafana created</span>
<span class="c">#    service/prometheus created</span>
<span class="c">#    deployment.apps/grafana created</span>
<span class="c">#    deployment.apps/prometheus created</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get deploy,pod,svc,ep <span class="nt">-n</span> cilium-monitoring
<span class="c"># =&gt; NAME                         READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/grafana      0/1     1            0           14s</span>
<span class="c">#    deployment.apps/prometheus   1/1     1            1           14s</span>
<span class="c">#    </span>
<span class="c">#    NAME                              READY   STATUS              RESTARTS   AGE</span>
<span class="c">#    pod/grafana-5c69859d9-7cpvl       0/1     ContainerCreating   0          14s</span>
<span class="c">#    pod/prometheus-6fc896bc5d-9xfll   1/1     Running             0          14s</span>
<span class="c">#    </span>
<span class="c">#    NAME                 TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE</span>
<span class="c">#    service/grafana      ClusterIP   10.96.10.188   &lt;none&gt;        3000/TCP   14s</span>
<span class="c">#    service/prometheus   ClusterIP   10.96.218.78   &lt;none&gt;        9090/TCP   14s</span>
<span class="c">#    </span>
<span class="c">#    NAME                   ENDPOINTS           AGE</span>
<span class="c">#    endpoints/grafana      &lt;none&gt;              14s</span>
<span class="c">#    endpoints/prometheus   172.20.2.115:9090   14s</span>
<span class="nv">$ </span>kubectl get cm <span class="nt">-n</span> cilium-monitoring
<span class="c"># =&gt; NAME                                         DATA   AGE</span>
<span class="c">#    grafana-cilium-dashboard                     1      23s</span>
<span class="c">#    grafana-cilium-operator-dashboard            1      23s</span>
<span class="c">#    grafana-config                               3      24s</span>
<span class="c">#    grafana-hubble-dashboard                     1      23s</span>
<span class="c">#    grafana-hubble-l7-http-metrics-by-workload   1      23s</span>
<span class="c">#    kube-root-ca.crt                             1      24s</span>
<span class="c">#    prometheus                                   1      23s</span>

<span class="c"># 프로메테우스 서버 설정</span>
<span class="nv">$ </span>kc describe cm <span class="nt">-n</span> cilium-monitoring prometheus

<span class="c"># 그라파나 서버 설정</span>
<span class="nv">$ </span>kc describe cm <span class="nt">-n</span> cilium-monitoring grafana-config

<span class="c"># 그파라나 대시보드들 주입을 위한 설정 확인</span>
<span class="nv">$ </span>kc describe cm <span class="nt">-n</span> cilium-monitoring grafana-cilium-dashboard
<span class="nv">$ </span>kc describe cm <span class="nt">-n</span> cilium-monitoring grafana-hubble-dashboard
<span class="c"># &lt;span style="color: green;"&gt;👉 설정 내용이 길어서 캡쳐는 생략하겠습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<h3 id="cilium과-hubble-메트릭-켜기">Cilium과 Hubble 메트릭 켜기</h3>

<ul>
  <li>이번 예제에는 Cilium과 Hubble의 메트릭을 Prometheus와 Grafana가 수집할 수 있도록 설정되어 있습니다.</li>
  <li>하지만 기본적으로 Cilium, Hubble, Cilium Operator의 메트릭은 비활성화되어 있습니다.</li>
  <li>따라서 Prometheus와 Grafana가 Cilium과 Hubble의 메트릭을 수집할 수 있도록 설정을 변경해야 합니다. <a href="https://docs.cilium.io/en/stable/observability/grafana/#deploy-cilium-and-hubble-with-metrics-enabled">Docs</a></li>
  <li>메트릭을 활성화하면 구성요소가 실행중인 모든 노드에 각각 <code class="language-plaintext highlighter-rouge">9962</code>, <code class="language-plaintext highlighter-rouge">9965</code>, <code class="language-plaintext highlighter-rouge">9963</code> 포트가 열립니다.</li>
  <li>Cilium, Hubble, Cilium Operator은 다음 helm 값으로 서로 독립적으로 활성화 할 수 있습니다.
    <ul>
      <li><code class="language-plaintext highlighter-rouge">prometheus.enabled=true</code>: cilium-agent 메트릭 켜기.</li>
      <li><code class="language-plaintext highlighter-rouge">operator.prometheus.enabled=true</code>: cilium-operator 메트릭 켜기.</li>
      <li><code class="language-plaintext highlighter-rouge">hubble.metrics.enabled</code>: 주어진 Hubble 메트릭 목록을 켜기
        <ul>
          <li>Hubble 메트릭 실행을 위해서는 <code class="language-plaintext highlighter-rouge">hubble.enabled=true</code>으로 설정되어 있어야 합니다.</li>
          <li><a href="https://docs.cilium.io/en/stable/observability/metrics/#hubble-exported-metrics">Hubble exported metrics</a>에서 활성화 할 수 있는 Hubble 메트릭을 확인 가능합니다..</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># &lt;span style="color: green;"&gt;👉 이번 예제에서는 이미 활성화 되어있습니다.&lt;/span&gt;</span>
<span class="nv">$ </span>helm <span class="nb">install </span>cilium cilium/cilium <span class="nt">--version</span> 1.17.6 <span class="se">\</span>
   <span class="nt">--namespace</span> kube-system <span class="se">\</span>
   <span class="nt">--set</span> prometheus.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
   <span class="nt">--set</span> operator.prometheus.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
   <span class="nt">--set</span> hubble.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
   <span class="nt">--set</span> hubble.metrics.enableOpenMetrics<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
   <span class="nt">--set</span> hubble.metrics.enabled<span class="o">=</span><span class="s2">"{dns,drop,tcp,flow,port-distribution,icmp,httpV2:exemplars=true;labelsContext=source_ip</span><span class="se">\,</span><span class="s2">source_namespace</span><span class="se">\,</span><span class="s2">source_workload</span><span class="se">\,</span><span class="s2">destination_ip</span><span class="se">\,</span><span class="s2">destination_namespace</span><span class="se">\,</span><span class="s2">destination_workload</span><span class="se">\,</span><span class="s2">traffic_direction}"</span>

<span class="c"># 호스트에 포트 정보 확인</span>
<span class="nv">$ </span>ss <span class="nt">-tnlp</span> | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'9962|9963|9965'</span>
<span class="c"># =&gt; LISTEN 0      4096                *:9962             *:*    users:(("cilium-agent",pid=2870,fd=7))     # cilium 메트릭</span>
<span class="c">#    LISTEN 0      4096                *:9963             *:*    users:(("cilium-operator",pid=1917,fd=7))  # cilium-opeator 메트릭</span>
<span class="c">#    LISTEN 0      4096                *:9965             *:*    users:(("cilium-agent",pid=2870,fd=31))    # hubble 메트릭</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 9963 포트는 cilium-operator 메트릭을 위한 포트로 컨트롤 플레인 노드에서만 열리는듯 합니다.&lt;/span&gt;</span>

<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>ss <span class="nt">-tnlp</span> | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'9962|9963|9965'</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    LISTEN 0      4096               *:9965             *:*    users:(("cilium-agent",pid=2032,fd=39))     # hubble 메트릭</span>
<span class="c">#    LISTEN 0      4096               *:9962             *:*    users:(("cilium-agent",pid=2032,fd=7))      # cilium 메트릭</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w2 &lt;&lt;</span>
<span class="c">#    LISTEN 0      4096               *:9962             *:*    users:(("cilium-agent",pid=2036,fd=7))      # cilium 메트릭</span>
<span class="c">#    LISTEN 0      4096               *:9965             *:*    users:(("cilium-agent",pid=2036,fd=30))     # hubble 메트릭</span>
</code></pre></div></div>

<h3 id="prometheus와-grafana-접속해서-확인">Prometheus와 Grafana 접속해서 확인</h3>

<ul>
  <li>Prometheus와 Grafana를 호스트에서 접속하기 위해 NodePort를 사용하여 접속할 수 있도록 설정하겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>kubectl get svc <span class="nt">-n</span> cilium-monitoring
<span class="c"># =&gt; NAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE</span>
<span class="c">#    grafana      ClusterIP   10.96.10.188   &lt;none&gt;        3000/TCP   10m</span>
<span class="c">#    prometheus   ClusterIP   10.96.218.78   &lt;none&gt;        9090/TCP   10m</span>

<span class="c"># NodePort 설정</span>
<span class="nv">$ </span>kubectl patch svc <span class="nt">-n</span> cilium-monitoring prometheus <span class="nt">-p</span> <span class="s1">'{"spec": {"type": "NodePort", "ports": [{"port": 9090, "targetPort": 9090, "nodePort": 30001}]}}'</span>
<span class="c"># =&gt; service/prometheus patched</span>
<span class="nv">$ </span>kubectl patch svc <span class="nt">-n</span> cilium-monitoring grafana <span class="nt">-p</span> <span class="s1">'{"spec": {"type": "NodePort", "ports": [{"port": 3000, "targetPort": 3000, "nodePort": 30002}]}}'</span>
<span class="c"># =&gt; service/grafana patched</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get svc <span class="nt">-n</span> cilium-monitoring
<span class="c"># =&gt; NAME         TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE</span>
<span class="c">#    grafana      NodePort   10.96.10.188   &lt;none&gt;        3000:30002/TCP   11m</span>
<span class="c">#    prometheus   NodePort   10.96.218.78   &lt;none&gt;        9090:30001/TCP   11m</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 NodePort가 각각 30002, 30001로 설정되었습니다.&lt;/span&gt;</span>

<span class="c"># 접속 주소 확인</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"http://192.168.10.100:30001"</span>  <span class="c"># prometheus</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"http://192.168.10.100:30002"</span>  <span class="c"># grafana</span>
</code></pre></div></div>

<ul>
  <li>간혹 Prometheus의 접속시 서버와 브라우저간의 시간 차이가 발생할 수 있습니다.
    <ul>
      <li>이때는 모든 가상머신을 reboot후 재접속하면 해결되는듯 합니다.</li>
    </ul>
  </li>
  <li>Prometheus 접속 확인
    <ul>
      <li>설정확인
        <ul>
          <li>Status &gt; Configuration에서 Prometheus 설정을 확인할 수 있습니다.</li>
          <li>Status &gt; Service Discovery에서 kubernetes의 통한 서비스 디스커버리를 통해 수집된 대상을 확인할 수 있습니다.</li>
          <li>Status &gt; Targets에서 Cilium, Hubble, Cilium Operator의 메트릭이 수집되고 있는지 확인할 수 있습니다.</li>
        </ul>
      </li>
      <li>기본 쿼리창에서 <code class="language-plaintext highlighter-rouge">cilium_</code>, <code class="language-plaintext highlighter-rouge">cilium_operator_</code>, <code class="language-plaintext highlighter-rouge">hubble_</code>로 시작하는 메트릭을 검색해보면 Cilium, Hubble, Cilium Operator의 메트릭을 확인할 수 있습니다.
<img src="/assets/2025/cilium/w2/20250727_cilium_w2_14.png" alt="img.png" class="image-center" />
<em class="image-caption"><code class="language-plaintext highlighter-rouge">hubble_drop_total</code> 메트릭 검색 예제</em></li>
    </ul>
  </li>
  <li>Grafana 접속 확인
    <ul>
      <li>Configuration &gt; Data Sources에서 Prometheus 서비스의 도메인 주소를 확인할 수 있고, Prometheus에서 수집한 메트릭을 사용하고 있는것을 확인할 수 있습니다.
<img src="/assets/2025/cilium/w2/20250727_cilium_w2_15.png" alt="img.png" class="image-center" /></li>
      <li>Dashboard &gt; General : 미리 설정된 대시보드를 확인할 수 있습니다.
<img src="/assets/2025/cilium/w2/20250727_cilium_w2_16.png" alt="img.png" class="image-center" /></li>
    </ul>
  </li>
  <li>Cilium Metric 대시보드 및 간단 쿼리문 알아보기 : Generic, API, Cilium(BPF, kvstore, NW info, Endpoints, k8s integration)
    <ul>
      <li>Cilium Metric 대시보드는 전체적인 Cilium의 메트릭을 확인할 수 있는 대시보드입니다.</li>
      <li>map ops (average node) 패널 분석
<img src="/assets/2025/cilium/w2/20250727_cilium_w2_17.png" alt="img.png" class="image-center" />
        <ul>
          <li>위의 캡쳐에서 본바와 같이 아래와 같은 PromQL 쿼리문을 사용합니다.
            <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">topk</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="k">avg</span><span class="p">(</span><span class="n">rate</span><span class="p">(</span><span class="n">cilium_bpf_map_ops_total</span><span class="p">{</span><span class="n">k8s_app</span><span class="o">=</span><span class="nv">"cilium"</span><span class="p">,</span> <span class="n">pod</span><span class="o">=~</span><span class="nv">"$pod"</span><span class="p">}[</span><span class="mi">5</span><span class="n">m</span><span class="p">]))</span> <span class="k">by</span> <span class="p">(</span><span class="n">pod</span><span class="p">,</span> <span class="n">map_name</span><span class="p">,</span> <span class="k">operation</span><span class="p">))</span>
</code></pre></div>            </div>
          </li>
          <li>Prometheus에서 위의 쿼리를 바탕으로 쿼리를 해서 분석해 보겠습니다.
            <ul>
              <li><a href="https://docs.cilium.io/en/stable/observability/metrics/">공식문서</a>에서 확인해보면 <code class="language-plaintext highlighter-rouge">cilium_bpf_map_ops_total</code>는
수행된 eBPF Map 작업수를 나타냅니다.
                <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
cilium_bpf_map_ops_total 
<span class="c"># &lt;span style="color: green;"&gt;👉 전체 cilium_bpf_map_ops_total 조회&lt;/span&gt;</span>
cilium_bpf_map_ops_total<span class="o">{</span><span class="nv">k8s_app</span><span class="o">=</span><span class="s2">"cilium"</span><span class="o">}</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s_app이 cilium인 cilium_bpf_map_ops_total 조회&lt;/span&gt;</span>
cilium_bpf_map_ops_total<span class="o">{</span><span class="nv">k8s_app</span><span class="o">=</span><span class="s2">"cilium"</span>, <span class="nv">pod</span><span class="o">=</span><span class="s2">"cilium-4hghz"</span><span class="o">}</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s_app이 cilium이면서 pod 명이 cilium-4hghz인 cilium_bpf_map_ops_total 조회&lt;/span&gt;</span>
  
<span class="c"># 최근 5분 간의 데이터로 증가율 계산</span>
rate<span class="o">(</span>cilium_bpf_map_ops_total<span class="o">{</span><span class="nv">k8s_app</span><span class="o">=</span><span class="s2">"cilium"</span><span class="o">}[</span>5m]<span class="o">)</span> <span class="c"># Graph 확인</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s_app이 cilium인 cilium_bpf_map_ops_total 의 5분간 데이터 증가율 계산&lt;/span&gt;</span>
  
<span class="c"># 여러 시계열(metric series)의 값의 평균</span>
avg<span class="o">(</span>rate<span class="o">(</span>cilium_bpf_map_ops_total<span class="o">{</span><span class="nv">k8s_app</span><span class="o">=</span><span class="s2">"cilium"</span><span class="o">}[</span>5m]<span class="o">))</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s_app이 cilium인 cilium_bpf_map_ops_total 의 5분간 데이터 증가율의 평균&lt;/span&gt;</span>
  
<span class="c"># 집계 함수(예: sum, avg, max, rate)와 함께 사용하여 어떤 레이블(label)을 기준으로 그룹화할지를 지정하는 그룹핑(grouping) </span>
avg<span class="o">(</span>rate<span class="o">(</span>cilium_bpf_map_ops_total<span class="o">{</span><span class="nv">k8s_app</span><span class="o">=</span><span class="s2">"cilium"</span><span class="o">}[</span>5m]<span class="o">))</span> by <span class="o">(</span>pod<span class="o">)</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 pod명으로 그룹핑&lt;/span&gt;</span>
avg<span class="o">(</span>rate<span class="o">(</span>cilium_bpf_map_ops_total<span class="o">{</span><span class="nv">k8s_app</span><span class="o">=</span><span class="s2">"cilium"</span><span class="o">}[</span>5m]<span class="o">))</span> by <span class="o">(</span>pod, map_name<span class="o">)</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 pod명과 map이름으로 그룹핑&lt;/span&gt;</span>
avg<span class="o">(</span>rate<span class="o">(</span>cilium_bpf_map_ops_total<span class="o">{</span><span class="nv">k8s_app</span><span class="o">=</span><span class="s2">"cilium"</span><span class="o">}[</span>5m]<span class="o">))</span> by <span class="o">(</span>pod, map_name, operation<span class="o">)</span> <span class="c"># Graph 확인</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 pod명과 map이름, map 동작으로 그룹핑&lt;/span&gt;</span>
  
<span class="c"># 시계열 중에서 가장 큰 k개를 선택</span>
topk<span class="o">(</span>5, avg<span class="o">(</span>rate<span class="o">(</span>cilium_bpf_map_ops_total<span class="o">{</span><span class="nv">k8s_app</span><span class="o">=</span><span class="s2">"cilium"</span><span class="o">}[</span>5m]<span class="o">)))</span> by <span class="o">(</span>pod, map_name, operation<span class="o">)</span>
topk<span class="o">(</span>5, avg<span class="o">(</span>rate<span class="o">(</span>cilium_bpf_map_ops_total<span class="o">{</span><span class="nv">k8s_app</span><span class="o">=</span><span class="s2">"cilium"</span>, <span class="nv">pod</span><span class="o">=</span><span class="s2">"cilium-4hghz"</span><span class="o">}[</span>5m]<span class="o">)))</span> by <span class="o">(</span>pod, map_name, operation<span class="o">)</span>
</code></pre></div>                </div>
              </li>
            </ul>
          </li>
          <li>Grafana 해당 대시보드 편집해서 Variables을 확인해보겠습니다.
            <ul>
              <li>앞선 PromQL 쿼리문에서 <code class="language-plaintext highlighter-rouge">$pod</code>는 Variables로 설정되어 있습니다. 이를 확인해보겠습니다.</li>
              <li>해당 dashboard &gt; Settings &gt; Variables에서 <code class="language-plaintext highlighter-rouge">$pod</code>를 확인할 수 있습니다.
<img src="/assets/2025/cilium/w2/20250727_cilium_w2_18.png" alt="img.png" class="image-center" /></li>
              <li><code class="language-plaintext highlighter-rouge">label_values(cilium_version, pod)</code>는 Prometheus에서 <code class="language-plaintext highlighter-rouge">cilium_version</code>으로 쿼리해서 얻어지는 label들 중 <code class="language-plaintext highlighter-rouge">pod</code>값을 취함을 의미합니다.
<img src="/assets/2025/cilium/w2/20250727_cilium_w2_19.png" alt="img.png" class="image-center" /></li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Cilium Operator 대시보드 : IPAM 관련 메트릭을 주로 확인할 수 있습니다. IPAM은 IP 주소 관리(IP Address Management)로, Cilium에서 IP 주소를 할당하고 관리하는 기능입니다.</li>
  <li>Hubble 대시보드 : General Processing, Network, Network Policy, HTTP, DNS 관련 메트릭을 확인할 수 있습니다.
    <ul>
      <li>Hubble L7 HTTP Metrics by Workload 대시보드 : HTTP 요청 및 응답에 대한 메트릭을 확인할 수 있습니다.
<img src="/assets/2025/cilium/w2/20250727_cilium_w2_20.png" alt="img.png" /></li>
    </ul>
  </li>
</ul>

<hr />

<h2 id="monitoring--metrics">Monitoring &amp; Metrics</h2>

<h3 id="cilium-metrics-설정-및-수집-방법">Cilium Metrics 설정 및 수집 방법</h3>

<p><a href="https://docs.cilium.io/en/stable/observability/metrics/#cilium-metrics">Docs</a></p>

<ul>
  <li>Cilium Metrics는 Cilium 자체의 상태, 즉 Cilium Agent, Cilium Envoy, Cilium Operator 프로세스에 대한 메트릭을 수집하고 제공합니다.</li>
  <li>Prometheus에서 수집할 수 있도록 하려면 <code class="language-plaintext highlighter-rouge">prometheus.enabled=true</code>로 설정해서 helm chart를 설치해야 합니다.</li>
  <li>Cilium Metrics는 <code class="language-plaintext highlighter-rouge">cilium_</code>라는 접두사를 가진 메트릭을 Prometheus에 제공합니다.</li>
  <li>Envoy Metrics는 <code class="language-plaintext highlighter-rouge">envoy_</code>라는 접두사를 가진 메트릭을 Prometheus에 제공하며, Cilium이 정의한 메트릭은 <code class="language-plaintext highlighter-rouge">cilium_envoy_</code>라는 접두사를 가집니다.</li>
  <li>Kubernetes에서 실행 및 수집될때 pod 이름과 namespace를 포함한 레이블을 추가합니다.</li>
  <li>설정 방법 (본 실습에서는 이미 적용되어 있습니다.)
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>helm <span class="nb">install </span>cilium cilium/cilium <span class="nt">--version</span> 1.17.6 <span class="se">\</span>
  <span class="nt">--namespace</span> kube-system <span class="se">\</span>
  <span class="nt">--set</span> prometheus.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> operator.prometheus.enabled<span class="o">=</span><span class="nb">true</span>

  <span class="c"># The ports can be configured via prometheus.port, envoy.prometheus.port, or operator.prometheus.port respectively.</span>
  <span class="nt">--set</span> prometheus.port
  <span class="nt">--set</span> envoy.prometheus.port
  <span class="nt">--set</span> operator.prometheus.port
  ...
</code></pre></div>    </div>
  </li>
  <li>Metric이 활성화되면 모든 Cilium 구성요소에는 다음과 같은 annotation이 표시됩니다. annotation은 Prometheus가 메트릭을 수집할지 여부를 알리는데 사용됩니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># cilium-agent 데몬셋 파드</span>
<span class="nv">$ </span>kubectl describe pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium | <span class="nb">grep </span>prometheus
<span class="c"># =&gt;                       prometheus.io/port: 9962</span>
<span class="c">#                          prometheus.io/scrape: true</span>
  
<span class="nv">$ </span>curl 192.168.10.100:9962/metrics
<span class="c"># =&gt; # HELP cilium_agent_api_process_time_seconds Duration of processed API calls labeled by path, method and return code.</span>
<span class="c">#    # TYPE cilium_agent_api_process_time_seconds histogram</span>
<span class="c">#    cilium_agent_api_process_time_seconds_bucket{method="DELETE",path="/v1/endpoint",return_code="404",le="0.005"} 3</span>
<span class="c">#    cilium_agent_api_process_time_seconds_bucket{method="DELETE",path="/v1/endpoint",return_code="404",le="0.01"} 3</span>
<span class="c">#    cilium_agent_api_process_time_seconds_bucket{method="DELETE",path="/v1/endpoint",return_code="404",le="0.025"} 3</span>
<span class="c">#    ...</span>
  
<span class="c"># cilium-operator 디플로이먼트 파드 </span>
<span class="nv">$ </span>kubectl describe pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> <span class="nv">name</span><span class="o">=</span>cilium-operator | <span class="nb">grep </span>prometheus
<span class="c"># =&gt; Annotations:          prometheus.io/port: 9963</span>
<span class="c">#                          prometheus.io/scrape: true</span>
  
<span class="nv">$ </span>curl 192.168.10.100:9963/metrics
<span class="c"># =&gt; # HELP certwatcher_read_certificate_errors_total Total number of certificate read errors</span>
<span class="c">#    # TYPE certwatcher_read_certificate_errors_total counter</span>
<span class="c">#    certwatcher_read_certificate_errors_total 0</span>
<span class="c">#    # HELP certwatcher_read_certificate_total Total number of certificate reads</span>
<span class="c">#    # TYPE certwatcher_read_certificate_total counter</span>
<span class="c">#    certwatcher_read_certificate_total 0</span>
<span class="c">#    ...</span>
</code></pre></div>    </div>
  </li>
  <li>Prometheus는  다음의 scrape_configs 섹션의 설정을 기반으로 자동으로 Cilium과 Envoy의 메트릭을 수집합니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kc describe cm <span class="nt">-n</span> cilium-monitoring prometheus
<span class="c"># =&gt; prometheus.yaml:</span>
<span class="c">#    ...</span>
<span class="c">#    scrape_configs:</span>
<span class="c">#      ...    </span>
<span class="c">#      # https://github.com/prometheus/prometheus/blob/master/documentation/examples/prometheus-kubernetes.yml#L156</span>
<span class="c">#      - job_name: 'kubernetes-pods'</span>
<span class="c">#        kubernetes_sd_configs:</span>
<span class="c">#          - role: pod</span>
<span class="c">#        relabel_configs:</span>
<span class="c">#          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]</span>
<span class="c">#            action: keep</span>
<span class="c">#            regex: true</span>
<span class="c">#          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]</span>
<span class="c">#            action: replace</span>
<span class="c">#            target_label: __metrics_path__</span>
<span class="c">#            regex: (.+)</span>
<span class="c">#          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]</span>
<span class="c">#            action: replace</span>
<span class="c">#            regex: (.+):(?:\d+);(\d+)</span>
<span class="c">#            replacement: ${1}:${2}</span>
<span class="c">#            target_label: __address__</span>
<span class="c">#          - action: labelmap</span>
<span class="c">#            regex: __meta_kubernetes_pod_label_(.+)</span>
<span class="c">#          - source_labels: [__meta_kubernetes_namespace]</span>
<span class="c">#            action: replace</span>
<span class="c">#            target_label: namespace</span>
<span class="c">#          - source_labels: [__meta_kubernetes_pod_name]</span>
<span class="c">#            action: replace</span>
<span class="c">#            target_label: pod</span>
<span class="c">#          - source_labels: [__meta_kubernetes_pod_container_port_number]</span>
<span class="c">#            action: keep</span>
<span class="c">#            regex: \d+</span>
<span class="c">#    ...</span>
</code></pre></div>    </div>
  </li>
</ul>

<p><img src="/assets/2025/cilium/w2/20250727_cilium_w2_21.png" alt="img.png" /></p>

<h3 id="hubble-metrics-설정-및-수집-방법">Hubble Metrics 설정 및 수집 방법</h3>

<p><a href="https://docs.cilium.io/en/stable/observability/metrics/#hubble-metrics">Docs</a></p>

<ul>
  <li>Cilium Metric은 Cilium의 상태를 모니터링 할 수 있게 해주지만, Hubble Metric은 Cilium이 관리하는 Kubernetes pod의 네트워크 동작을 연결과 보안과 관련하여 모니터링 할 수 있게 해줍니다.</li>
  <li>설정은 다음과 같습니다. (실습환경에서는 이미 적용되어 있습니다.)
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>helm <span class="nb">install </span>cilium cilium/cilium <span class="nt">--version</span> 1.17.6 <span class="se">\</span>
<span class="nt">--namespace</span> kube-system <span class="se">\</span>
<span class="nt">--set</span> prometheus.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> operator.prometheus.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> hubble.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> hubble.metrics.enableOpenMetrics<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> hubble.metrics.enabled<span class="o">=</span><span class="s2">"{dns,drop,tcp,flow,port-distribution,icmp,httpV2:exemplars=true;labelsContext=source_ip</span><span class="se">\,</span><span class="s2">source_namespace</span><span class="se">\,</span><span class="s2">source_workload</span><span class="se">\,</span><span class="s2">destination_ip</span><span class="se">\,</span><span class="s2">destination_namespace</span><span class="se">\,</span><span class="s2">destination_workload</span><span class="se">\,</span><span class="s2">traffic_direction}"</span>
<span class="nt">--set</span> hubble.metrics.port
</code></pre></div>    </div>
  </li>
  <li>L7 메트릭은 L7 가시성 활성화가 필요합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">hubble.metrics.enabled</code> 설정은 Hubble에서 수집할 메트릭을 지정합니다.
    <ul>
      <li>예를 들어, <code class="language-plaintext highlighter-rouge">hubble.metrics.enabled</code> 값을 Helm 챠트 value에 설정하면, Cilium 챠트는 <code class="language-plaintext highlighter-rouge">hubble-metrics</code>라는 헤드리스 서비스를 생성합니다.</li>
      <li>이 서비스는 <code class="language-plaintext highlighter-rouge">prometheus.io/scrape:'true'</code> annotation을 갖고 있어 Prometheus의 대상이 됩니다.</li>
    </ul>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># hubble-metrics 헤드리스 서비스 정보 확인</span>
<span class="nv">$ </span>kubectl get svc <span class="nt">-n</span> kube-system hubble-metrics
<span class="c"># =&gt; NAME             TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)    AGE</span>
<span class="c">#    hubble-metrics   ClusterIP   None         &lt;none&gt;        9965/TCP   2d</span>
<span class="nv">$ </span>kc describe svc <span class="nt">-n</span> kube-system hubble-metrics
<span class="c"># =&gt; Annotations:              meta.helm.sh/release-name: cilium</span>
<span class="c">#                              meta.helm.sh/release-namespace: kube-system</span>
<span class="c">#                              prometheus.io/port: 9965</span>
<span class="c">#                              prometheus.io/scrape: true</span>
<span class="c">#    ...</span>
<span class="c">#    Endpoints:                192.168.10.102:9965,192.168.10.100:9965,192.168.10.101:9965</span>
<span class="c">#    ...</span>

<span class="nv">$ </span>curl 192.168.10.100:9965/metrics
<span class="c"># =&gt; # HELP grpc_server_handled_total Total number of RPCs completed on the server, regardless of success or failure.</span>
<span class="c">#    # TYPE grpc_server_handled_total counter</span>
<span class="c">#    grpc_server_handled_total{grpc_code="Aborted",grpc_method="Check",grpc_service="grpc.health.v1.Health",grpc_type="unary"} 0</span>
<span class="c">#    grpc_server_handled_total{grpc_code="Aborted",grpc_method="GetAgentEvents",grpc_service="observer.Observer",grpc_type="server_stream"} 0</span>
<span class="c">#    grpc_server_handled_total{grpc_code="Aborted",grpc_method="GetDebugEvents",grpc_service="observer.Observer",grpc_type="server_stream"} 0</span>
<span class="c">#    ...</span>

<span class="c">#</span>
<span class="nv">$ </span>kc describe cm <span class="nt">-n</span> cilium-monitoring prometheus
<span class="c"># =&gt; prometheus.yaml:</span>
<span class="c">#    ...</span>
<span class="c">#    scrape_configs:</span>
<span class="c">#      # https://github.com/prometheus/prometheus/blob/master/documentation/examples/prometheus-kubernetes.yml#L79</span>
<span class="c">#      - job_name: 'kubernetes-endpoints'</span>
<span class="c">#        kubernetes_sd_configs:</span>
<span class="c">#          - role: endpoints</span>
<span class="c">#        relabel_configs:</span>
<span class="c">#          - source_labels: [__meta_kubernetes_pod_label_k8s_app]</span>
<span class="c">#            action: keep</span>
<span class="c">#            regex: cilium</span>
<span class="c">#          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]</span>
<span class="c">#            action: keep</span>
<span class="c">#            regex: true</span>
<span class="c">#          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]</span>
<span class="c">#            action: replace</span>
<span class="c">#            target_label: __scheme__</span>
<span class="c">#            regex: (https?)</span>
<span class="c">#          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]</span>
<span class="c">#            action: replace</span>
<span class="c">#            target_label: __metrics_path__</span>
<span class="c">#            regex: (.+)</span>
<span class="c">#          - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]</span>
<span class="c">#            action: replace</span>
<span class="c">#            target_label: __address__</span>
<span class="c">#            regex: (.+)(?::\d+);(\d+)</span>
<span class="c">#            replacement: $1:$2</span>
<span class="c">#          - action: labelmap</span>
<span class="c">#            regex: __meta_kubernetes_service_label_(.+)</span>
<span class="c">#          - source_labels: [__meta_kubernetes_namespace]</span>
<span class="c">#            action: replace</span>
<span class="c">#            target_label: namespace</span>
<span class="c">#          - source_labels: [__meta_kubernetes_service_name]</span>
<span class="c">#            action: replace</span>
<span class="c">#            target_label: service</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w2/20250727_cilium_w2_22.png" alt="img.png" /></p>

<h2 id="layer-7-protocol-visibility">Layer 7 Protocol Visibility</h2>

<ul>
  <li>Monitoring Datapath State는 기본적으로 L3/L4 패킷에 대한 가시성을 제공합니다.</li>
  <li>HTTP나 DNS같은 L7 프로토콜에 대한 가시성을 제공하기 위해서는 L7 프로토콜 가시성을 활성화해야 합니다.</li>
  <li>L7 트래픽에 대한 가시성을 활성화 하려면 L7 규칙을 지정하는 CiliumNetworkPolicy를 만들어야 합니다.</li>
  <li>CiliumNetworkPolicy는 L7 규칙과 일치하는 트래픽의 흐름이 Cilium에 표시되므로 최종사용자에게 노출될 수 있습니다.</li>
  <li>L7 네트워크 정책은 가시성을 가능하게 할 뿐만 아니라 pod에 들어가고 나가는 트래픽을 제어할 수 있음을 기억해야 합니다.</li>
</ul>

<h3 id="실습">실습</h3>

<ul>
  <li>다음 예제는 DNS(TCP/UDP/53) 및 HTTP(TCP/80 및 TCP/8080) 트래픽을 기본 네임스페이스 내에 표시할 수 있도록 L7 규칙을 지정합니다.</li>
  <li>하나는 DNS 규칙과 하나는 HTTP 규칙을 제공하며, 한 출력 통신을 제외하고 일치하지 않는 모든것을 삭제합니다.</li>
  <li>규칙이 L7 일치 조건이 생략되거나 와일드카드 처리되면 L4 섹션과 일치하는 모든 요청이 허용됩니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 반복 접속 해둔 상태</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s webpod | grep Hostname; sleep 1; done'</span>

<span class="c"># default 네임스페이스에 있는 Pod들의 egress(출방향) 트래픽을 제어하며, L7 HTTP 및 DNS 트래픽에 대한 가시성과 제어를 설정</span>
<span class="c">## method/path 기반 필터링은 안 하지만, HTTP 요청 정보는 Envoy를 통해 기록/관찰됨</span>
<span class="c">## cilium-envoy를 경유하게 됨 (DNS + HTTP 모두 L7 처리 대상)</span>
<span class="c">## 이 정책이 적용되면, 명시된 egress 외의 모든 egress 트래픽은 차단됩니다 (Cilium 정책은 default-deny 모델임)</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: "cilium.io/v2"
kind: CiliumNetworkPolicy
metadata:
  name: "l7-visibility"
spec:
  endpointSelector:
    matchLabels:
      "k8s:io.kubernetes.pod.namespace": default  # default 네임스페이스 안의 모든 Pod에 대해 egress 정책이 적용
  egress:
  - toPorts:
    - ports:
      - port: "53"
        protocol: ANY  # TCP, UDP 둘 다 허용
      rules:
        dns:
        - matchPattern: "*"  # 모든 도메인 조회 허용, L7 가시성 활성화
  - toEndpoints:
    - matchLabels:
        "k8s:io.kubernetes.pod.namespace": default
    toPorts:
    - ports:
      - port: "80"  # default 다른 파드의 HTTP TCP 80 요청 허용
        protocol: TCP
      - port: "8080"  # default 다른 파드의 HTTP TCP 8080 요청 허용
        protocol: TCP
      rules:
        http: [{}]  # 모든 HTTP 요청을 허용, L7 가시성 활성화
</span><span class="no">EOF

</span><span class="nv">$ </span>kubectl get cnp <span class="nt">-o</span> yaml
<span class="c"># =&gt;   kind: CiliumNetworkPolicy</span>
<span class="c">#      ...</span>
<span class="c">#      spec:</span>
<span class="c">#        egress:</span>
<span class="c">#        - toPorts:</span>
<span class="c">#          - ports:</span>
<span class="c">#            - port: "53"</span>
<span class="c">#              protocol: ANY</span>
<span class="c">#            rules:</span>
<span class="c">#              dns:</span>
<span class="c">#              - matchPattern: '*'</span>
<span class="c">#        - toEndpoints:</span>
<span class="c">#          - matchLabels:</span>
<span class="c">#              k8s:io.kubernetes.pod.namespace: default</span>
<span class="c">#          toPorts:</span>
<span class="c">#          - ports:</span>
<span class="c">#            - port: "80"</span>
<span class="c">#              protocol: TCP</span>
<span class="c">#            - port: "8080"</span>
<span class="c">#              protocol: TCP</span>
<span class="c">#            rules:</span>
<span class="c">#              http:</span>
<span class="c">#              - {}</span>
<span class="c">#        endpointSelector:</span>
<span class="c">#          matchLabels:</span>
<span class="c">#            k8s:io.kubernetes.pod.namespace: default</span>
<span class="c">#      ...</span>

<span class="c"># 호출 확인 : cilium-envoy 경유 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nt">-s</span> webpod
<span class="c"># =&gt; Hostname: webpod-697b545f57-mvz92</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: ::1</span>
<span class="c">#    IP: 172.20.2.101</span>
<span class="c">#    IP: fe80::68c6:baff:fe2c:766b</span>
<span class="c">#    &lt;span style="color: green;"&gt;RemoteAddr: 172.20.0.43:39216&lt;/span&gt; # 해당 IP는 curl-pod 의 IP로 cilium-envoy IP로 SNAT 되지 않았음!</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: webpod</span>
<span class="c">#    User-Agent: curl/8.14.1</span>
<span class="c">#    Accept: */*</span>
<span class="c">#    &lt;span style="color: green;"&gt;X-Envoy-Expected-Rq-Timeout-Ms: 3600000&lt;/span&gt;   # cilium-envoy 경유 확인</span>
<span class="c">#    &lt;span style="color: green;"&gt;X-Envoy-Internal: true&lt;/span&gt;</span>
<span class="c">#    X-Forwarded-Proto: http</span>
<span class="c">#    X-Request-Id: 913dbacf-5559-4d13-8855-afaa41979f4e</span>

<span class="c"># 가시성 확인</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">-t</span> l7 <span class="nt">-o</span> compact
<span class="c"># =&gt; Jul 26 14:58:47.953: default/curl-pod:34773 (ID:472) -&gt; kube-system/coredns-674b8bbfcf-7m82r:53 (ID:30923) dns-request proxy FORWARDED (DNS Query webpod.default.svc.cluster.local. AAAA)</span>
<span class="c">#    Jul 26 14:58:47.953: default/curl-pod:34773 (ID:472) -&gt; kube-system/coredns-674b8bbfcf-7m82r:53 (ID:30923) dns-request proxy FORWARDED (DNS Query webpod.default.svc.cluster.local. A)</span>
<span class="c">#    Jul 26 14:58:47.954: default/curl-pod:34773 (ID:472) &lt;- kube-system/coredns-674b8bbfcf-7m82r:53 (ID:30923) dns-response proxy FORWARDED (DNS Answer "10.96.147.79" TTL: 30 (Proxy webpod.default.svc.cluster.local. A))</span>
<span class="c">#    Jul 26 14:58:47.956: default/curl-pod:34773 (ID:472) &lt;- kube-system/coredns-674b8bbfcf-7m82r:53 (ID:30923) dns-response proxy FORWARDED (DNS Answer  TTL: 4294967295 (Proxy webpod.default.svc.cluster.local. AAAA))</span>
<span class="c">#    Jul 26 14:58:47.961: default/curl-pod:52022 (ID:472) -&gt; default/webpod-697b545f57-mvz92:80 (ID:18655) http-request FORWARDED (HTTP/1.1 GET http://webpod/)</span>
<span class="c">#    Jul 26 14:58:47.967: default/curl-pod:52022 (ID:472) &lt;- default/webpod-697b545f57-mvz92:80 (ID:18655) http-response FORWARDED (HTTP/1.1 200 5ms (GET http://webpod/))</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<ul>
  <li>Grafana에서 L7 HTTP Metrics by Workload 대시보드를 확인해보면, HTTP 요청 및 응답에 대한 메트릭을 확인할 수 있습니다.
<img src="/assets/2025/cilium/w2/20250727_cilium_w2_23.png" alt="img.png" class="image-center" />
    <ul>
      <li>이때 현재 label에는 destination_workload가 포함되어있지 않아서 메트릭이 나타나지 않는데 Destination Workload를 임시로 <code class="language-plaintext highlighter-rouge">.*</code> (정규표현식에서 와일드 카드)로 하거나 PromQL에서 해당 부분을 제외하거나 label에 추가하면 메트릭을 확인할 수 있습니다.</li>
    </ul>
  </li>
  <li>Prometheus에서도 <code class="language-plaintext highlighter-rouge">rate(hubble_http_requests_total[5m])</code>를 통해 확인해 보겠습니다. 
<img src="/assets/2025/cilium/w2/20250727_cilium_w2_24.png" alt="img.png" /></li>
</ul>

<h3 id="security-implications-및-실습">Security Implications 및 실습</h3>

<p><a href="https://docs.cilium.io/en/stable/observability/visibility/#security-implications">Docs</a></p>

<ul>
  <li>L7 트래픽 모니터링은 <strong>사용자 이름, 비밀번호, 쿼리 매개변수, API 키</strong> 등 잠재적으로 민감한 정보를 포함할 수 있기 때문에 보안에 주의해야 합니다.</li>
  <li>기본적으로 Hubble은 L7 트래픽의 민감 정보를 필터링하지 않습니다.</li>
  <li>간단한 실습을 해보겠습니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">-t</span> l7
<span class="c"># =&gt; Jul 26 15:50:11.494: default/curl-pod:49308 (ID:472) -&gt; default/webpod-697b545f57-mvz92:80 (ID:18655) http-request FORWARDED (HTTP/1.1 GET http://webpod/?user_id=1234)</span>
<span class="c">#    Jul 26 15:50:11.499: default/curl-pod:49308 (ID:472) &lt;- default/webpod-697b545f57-mvz92:80 (ID:18655) http-response FORWARDED (HTTP/1.1 200 5ms (GET http://webpod/?user_id=1234))</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 아래의 curl 명령으로 보낸 user_id가 그대로 보이는것을 확인할 수 있습니다.&lt;/span&gt;</span>
  
<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'curl -s webpod/?user_id=1234'</span>
  
<span class="c"># 민감정보 미출력 설정</span>
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--namespace</span> kube-system <span class="nt">--reuse-values</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">extraArgs</span><span class="o">=</span><span class="s2">"{--hubble-redact-enabled,--hubble-redact-http-urlquery}"</span>
<span class="c"># =&gt; Release "cilium" has been upgraded. Happy Helming!</span>
<span class="c">#    NAME: cilium</span>
<span class="c">#    LAST DEPLOYED: Sun Jul 27 00:51:08 2025</span>
<span class="c">#    NAMESPACE: kube-system</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 10</span>
<span class="c">#    TEST SUITE: None</span>
<span class="c">#    NOTES:</span>
<span class="c">#    You have successfully installed Cilium with Hubble Relay and Hubble UI.</span>
<span class="c">#    </span>
<span class="c">#    Your release version is 1.17.6.</span>
  
<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'curl -s webpod/?user_id=1234'</span>
  
<span class="c">#</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">-t</span> l7
<span class="c"># =&gt; Jul 26 15:51:49.594: default/curl-pod:53276 (ID:472) -&gt; default/webpod-697b545f57-ns4sw:80 (ID:18655) http-request FORWARDED (HTTP/1.1 GET http://webpod/)</span>
<span class="c">#    Jul 26 15:51:49.601: default/curl-pod:53276 (ID:472) &lt;- default/webpod-697b545f57-ns4sw:80 (ID:18655) http-response FORWARDED (HTTP/1.1 200 9ms (GET http://webpod/))</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 민감정보가 필터링 된것을 확인할 수 있습니다.&lt;/span&gt;</span>
</code></pre></div>    </div>
  </li>
  <li>보안을 강화하기 위해 Cilium은 허블이 레이어 7 흐름에 존재하는 민감한 정보를 처리(제거나 마스킹)할 수 있도록 <code class="language-plaintext highlighter-rouge">--hubble-redact-enabled</code> 옵션을 제공합니다.
    <ul>
      <li>HTTP에서 URL 쿼리 파라메터(GET)을 필터링 하기위해 <code class="language-plaintext highlighter-rouge">--hubble-redact-http-urlquery</code>를 사용 =&gt; URL의 <code class="language-plaintext highlighter-rouge">?query=value</code> 제거
        <ul>
          <li>예시) 설정 전
            <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s2">"method"</span>: <span class="s2">"GET"</span>,
<span class="s2">"url"</span>: <span class="s2">"/user/profile?user_id=1234&amp;token=abcd1234"</span>,
<span class="s2">"status"</span>: 200
</code></pre></div>            </div>
          </li>
          <li>예시) 설정 후 : <code class="language-plaintext highlighter-rouge">--set extraArgs="{--hubble-redact-http-urlquery}”</code>
            <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s2">"method"</span>: <span class="s2">"GET"</span>,
<span class="s2">"url"</span>: <span class="s2">"/user/profile"</span>, <span class="c"># 쿼리 문자열이 제거되어 출력, 민감 정보 보호됨</span>
<span class="s2">"status"</span>: 200
</code></pre></div>            </div>
          </li>
        </ul>
      </li>
      <li>HTTP에서 사용자정보 (basic auth의 아이디 비밀번호) 등을 필터링하기위해 <code class="language-plaintext highlighter-rouge">--hubble-redact-http-userinfo</code>를 사용 =&gt; URL의 <code class="language-plaintext highlighter-rouge">user:pass@</code> 제거</li>
      <li>Kafka에서 API 키를 필터링하려면 <code class="language-plaintext highlighter-rouge">--hubble-redact-kafka-apikey</code> 사용</li>
      <li>HTTP 헤더를 필터링하기 위해서는 허용리스트(<code class="language-plaintext highlighter-rouge">--hubble-redact-http-headers-allow</code>) 또는 거부리스트 (<code class="language-plaintext highlighter-rouge">--hubble-redact-http-headers-deny</code>)를 사용</li>
    </ul>
  </li>
</ul>

<hr />

<h2 id="pwru-packet-where-are-you">pwru (Packet where are you)</h2>

<ul>
  <li>pwru는 eBPF 기반의 linux 커널 디버거입니다. <a href="https://github.com/cilium/pwru">https://github.com/cilium/pwru</a></li>
  <li>주요 특징
    <ul>
      <li>eBPF 기반 네트워크 트레이싱 툴로, 커널 패킷 경로를 실시간으로 모니터링합니다.</li>
      <li>고급 필터링 기능을 제공하여, 관심 있는 패킷만 골라서 추적할 수 있습니다</li>
      <li>네트워크 트러블슈팅, 즉 패킷 손실 및 처리 위치 파악, 다양한 커널 모듈과의 상호작용 등을 이해하는 데 유용합니다.</li>
      <li>커맨드라인에서 다양한 옵션과 PCAP 필터를 적용해서 상세 분석을 할 수 있습니다.</li>
    </ul>
  </li>
</ul>

<h3 id="pwru-설치-및-실행">pwru 설치 및 실행</h3>

<ul>
  <li><a href="https://medium.com/@Nikhil690/debugging-packet-drops-and-kernel-flows-with-pwru-fc03f3d479a4">PWRU: Debugging Packets and Kernel Flows</a>를 바탕으로 실행해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Prerequisites</span>
<span class="nv">$ </span><span class="nb">sudo </span>apt update
<span class="nv">$ </span><span class="nb">sudo </span>apt <span class="nb">install</span> <span class="nt">-y</span> clang llvm gcc make flex bison byacc yacc libpcap-dev golang

<span class="c"># Building PWRU from Source</span>
<span class="c">## Clone the PWRU GitHub repository</span>
<span class="nv">$ </span>git clone https://github.com/cilium/pwru.git
<span class="c"># =&gt; Cloning into 'pwru'...</span>
<span class="c">#    remote: Enumerating objects: 7681, done.</span>
<span class="c">#    remote: Counting objects: 100% (211/211), done.</span>
<span class="c">#    remote: Compressing objects: 100% (127/127), done.</span>
<span class="c">#    remote: Total 7681 (delta 117), reused 94 (delta 83), pack-reused 7470 (from 3)</span>
<span class="c">#    Receiving objects: 100% (7681/7681), 9.40 MiB | 18.12 MiB/s, done.</span>
<span class="c">#    Resolving deltas: 100% (4723/4723), done.</span>

<span class="c">## Navigate to the project directory</span>
<span class="nv">$ </span><span class="nb">cd </span>pwru

<span class="c">## Build the project : Compile the eBPF object files, Build the userspace Go application, Link everything together</span>
<span class="nv">$ </span>make
<span class="c"># =&gt; ...</span>
<span class="c">#    TARGET_GOARCH=&lt;span style="color: green;"&gt;amd64&lt;/span&gt; go generate</span>
<span class="c">#    Generating for &lt;span style="color: green;"&gt;amd64&lt;/span&gt;</span>
<span class="c">#    CC=cc GOARCH=&lt;span style="color: green;"&gt;amd64&lt;/span&gt; CGO_ENABLED=1 go build  \</span>
<span class="c">#            -ldflags "-w -s \</span>
<span class="c">#            -X 'github.com/cilium/pwru/internal/pwru.Version=v1.0.10-pre-110-gbd7ffd8'"</span>
<span class="c">#    # runtime/cgo</span>
<span class="c">#    &lt;span style="background-color: red; color: #fff;"&gt;cc: error: unrecognized command-line option '-m64'&lt;/span&gt;</span>
<span class="c">#    make: *** [Makefile:22: pwru] Error 1</span>
</code></pre></div></div>

<ul>
  <li>M1 Mac에서 빌드할 때는 <code class="language-plaintext highlighter-rouge">-m64</code> 옵션이 문제를 일으키는것 같습니다.</li>
</ul>

<h3 id="빌드-트러블슈팅-및-실행">빌드 트러블슈팅 및 실행</h3>

<ul>
  <li>빌드 로그를 봤을때 자꾸 amd64로 빌드하려고 하는것 같습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">uname</span> <span class="nt">-a</span>
<span class="c"># =&gt; Linux k8s-ctr 6.8.0-53-generic #55-Ubuntu SMP PREEMPT_DYNAMIC Fri Jan 17 15:02:14 UTC 2025 &lt;span style="color: green;"&gt;aarch64 aarch64 aarch64&lt;/span&gt; GNU/Linux</span>
</code></pre></div></div>

<ul>
  <li>하지만 제 환경은 aarch64으로 뭔기 빌드 설정이 잘못된것 같습니다. 빌드 스크립트를 수정하고 PR을 올리면 좋겠지만 시간이 없으므로 arm64로 강제로 빌드해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># (기존) TARGET_GOARCH=amd64 go generate</span>
<span class="nv">$ TARGET_GOARCH</span><span class="o">=</span>arm64 go generate
<span class="c"># =&gt; Generating for arm64</span>

<span class="c"># (기존) CC=cc GOARCH=amd64 CGO_ENABLED=1 go build  \</span>
<span class="c">#         -ldflags "-w -s \</span>
<span class="c">#         -X 'github.com/cilium/pwru/internal/pwru.Version=v1.0.10-pre-110-gbd7ffd8'"</span>
<span class="nv">$ CC</span><span class="o">=</span>cc <span class="nv">GOARCH</span><span class="o">=</span>arm64 <span class="nv">CGO_ENABLED</span><span class="o">=</span>1 go build  <span class="se">\</span>
        <span class="nt">-ldflags</span> <span class="s2">"-w -s </span><span class="se">\</span><span class="s2">
        -X 'github.com/cilium/pwru/internal/pwru.Version=v1.0.10-pre-110-gbd7ffd8'"</span>
<span class="c"># =&gt; # github.com/cilium/pwru</span>
<span class="c">#    /usr/bin/ld: /tmp/go-link-4205941405/000020.o: in function `_cgo_77133bf98b3a_C2func_getaddrinfo':</span>
<span class="c">#    /tmp/go-build/cgo_unix_cgo.cgo2.c:60:(.text+0x30): warning: Using 'getaddrinfo' in statically linked applications requires at runtime the shared libraries from the glibc version used for linking</span>
<span class="c">#    /usr/bin/ld: /root/pwru/internal/libpcap/../../libpcap/libpcap.a(nametoaddr.o): in function `pcap_nametoaddr':</span>
<span class="c">#    /root/pwru/libpcap/./nametoaddr.c:181:(.text+0x8): warning: Using 'gethostbyname' in statically linked applications requires at runtime the shared libraries from the glibc version used for linking</span>
<span class="c">#    /usr/bin/ld: /root/pwru/internal/libpcap/../../libpcap/libpcap.a(nametoaddr.o): in function `pcap_nametonetaddr':</span>
<span class="c">#    /root/pwru/libpcap/./nametoaddr.c:270:(.text+0x104): warning: Using 'getnetbyname_r' in statically linked applications requires at runtime the shared libraries from the glibc version used for linking</span>
<span class="c">#    /usr/bin/ld: /root/pwru/internal/libpcap/../../libpcap/libpcap.a(nametoaddr.o): in function `pcap_nametoproto':</span>
<span class="c">#    /root/pwru/libpcap/./nametoaddr.c:527:(.text+0x4cc): warning: Using 'getprotobyname_r' in statically linked applications requires at runtime the shared libraries from the glibc version used for linking</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 warning이 뜨긴 했지만 빌드가 된것 같습니다.&lt;/span&gt;</span>

<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-l</span> pwru
<span class="c"># =&gt; -rwxr-xr-x 1 root root 8561904 Jul 27 00:39 pwru</span>
</code></pre></div></div>

<ul>
  <li>빌드가 완료되면 <code class="language-plaintext highlighter-rouge">pwru</code> 실행파일이 생성됩니다. 이 파일을 실행하면 PWRU를 사용할 수 있습니다.</li>
  <li>리눅스 커널과 eBPF 서브시스템에 직접 상호작용하기 때문에 root 권한으로 실행해야 합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Running PWRU</span>
<span class="c">## Since PWRU interacts directly with kernel functions and eBPF subsystems, you need root permissions to run it:</span>
<span class="nv">$ </span><span class="nb">sudo</span> ./pwru <span class="o">[</span>options] <span class="o">[</span>pcap-filter]

<span class="c"># ICMP (ping) 패킷을 추적해보겠습니다.</span>
<span class="nv">$ </span><span class="nb">sudo</span> ./pwru <span class="nt">--output-tuple</span> icmp
<span class="c"># =&gt; 2025/07/27 00:40:49 Attaching kprobes (via kprobe)...</span>
<span class="c">#    1669 / 1669 [--------------------------------------------------------] 100.00% 1455 p/s</span>
<span class="c">#    2025/07/27 00:40:50 Attached (ignored 5)</span>
<span class="c">#    2025/07/27 00:40:50 Listening for events..  # &lt;span style="color: green;"&gt;👉 eBPF 설치하는 과정이 종료되고 이벤트를 listening 하고 있습니다.&lt;/span&gt;</span>
<span class="c">#    SKB                CPU PROCESS          NETNS      MARK/x        IFACE       PROTO  MTU   LEN   TUPLE FUNC</span>
<span class="c">#    0xffff00005f10c300 0   ~/bin/ping:42701 4026531840 0               0         0x0000 1500  84    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     ip_send_skb</span>
<span class="c">#    0xffff00005f10c300 0   ~/bin/ping:42701 4026531840 0               0         0x0000 1500  84    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     __ip_local_out</span>
<span class="c">#    0xffff00005f10c300 0   ~/bin/ping:42701 4026531840 0               0         0x0800 1500  84    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     nf_hook_slow</span>
<span class="c">#    0xffff00005f10c300 0   ~/bin/ping:42701 4026531840 c00             0         0x0800 1500  84    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     ip_output</span>
<span class="c">#    0xffff00005f10c300 0   ~/bin/ping:42701 4026531840 c00           eth0:2      0x0800 1500  84    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     nf_hook_slow</span>
<span class="c">#    0xffff00005f10c300 0   ~/bin/ping:42701 4026531840 c00           eth0:2      0x0800 1500  84    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     apparmor_ip_postroute</span>
<span class="c">#    0xffff00005f10c300 0   ~/bin/ping:42701 4026531840 c00           eth0:2      0x0800 1500  84    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     ip_finish_output</span>
<span class="c">#    0xffff00005f10c300 0   ~/bin/ping:42701 4026531840 c00           eth0:2      0x0800 1500  84    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     __ip_finish_output</span>
<span class="c">#    0xffff00005f10c300 0   ~/bin/ping:42701 4026531840 c00           eth0:2      0x0800 1500  84    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     ip_finish_output2</span>
<span class="c">#    0xffff00005f10c300 0   ~/bin/ping:42701 4026531840 c00           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     __dev_queue_xmit</span>
<span class="c">#    0xffff00005f10c300 0   ~/bin/ping:42701 4026531840 c00           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     qdisc_pkt_len_init</span>
<span class="c">#    0xffff00005f10c300 0   ~/bin/ping:42701 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     netdev_core_pick_tx</span>
<span class="c">#    0xffff00005f10c300 0   ~/bin/ping:42701 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     dev_qdisc_enqueue</span>
<span class="c">#    0xffff00005f10c300 0   ~/bin/ping:42701 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     __skb_get_hash</span>
<span class="c">#    0xffff00005f10c300 1   ~/sbin/sshd:6275 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     sch_direct_xmit</span>
<span class="c">#    0xffff00005f10c300 1   ~/sbin/sshd:6275 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     validate_xmit_skb_list</span>
<span class="c">#    0xffff00005f10c300 1   ~/sbin/sshd:6275 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     validate_xmit_skb</span>
<span class="c">#    0xffff00005f10c300 1   ~/sbin/sshd:6275 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     netif_skb_features</span>
<span class="c">#    0xffff00005f10c300 1   ~/sbin/sshd:6275 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     skb_network_protocol</span>
<span class="c">#    0xffff00005f10c300 1   ~/sbin/sshd:6275 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     validate_xmit_xfrm</span>
<span class="c">#    0xffff00005f10c300 1   ~/sbin/sshd:6275 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     dev_hard_start_xmit</span>
<span class="c">#    0xffff00005f10c300 1   ~/sbin/sshd:6275 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     skb_clone_tx_timestamp</span>
<span class="c">#    0xffff00005f10c300 1   ~/sbin/sshd:6275 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     napi_consume_skb</span>
<span class="c">#    0xffff00005f10c300 1   ~/sbin/sshd:6275 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     skb_release_head_state</span>
<span class="c">#    0xffff00005f10c300 1   ~/sbin/sshd:6275 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     sock_wfree</span>
<span class="c">#    0xffff00005f10c300 1   ~/sbin/sshd:6275 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     skb_release_data</span>
<span class="c">#    0xffff00005f10c300 1   ~/sbin/sshd:6275 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     skb_free_head</span>
<span class="c">#    0xffff00005f10c300 1   ~/sbin/sshd:6275 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     napi_skb_cache_put</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 0             eth0:2      0x0800 1500  84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     inet_gro_receive</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 0             eth0:2      0x0800 1500  84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     skb_defer_rx_timestamp</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 0             eth0:2      0x0800 1500  98    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     skb_ensure_writable</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 1500  84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     ip_rcv_core</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 1500  84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     nf_hook_slow</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 1500  84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     nf_ip_checksum</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 1500  84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     __skb_checksum_complete</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 1500  84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     ip_route_input_noref</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 1500  84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     ip_route_input_slow</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 1500  84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     fib_validate_source</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 1500  84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     __fib_validate_source</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 65536 84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     ip_local_deliver</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 65536 84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     nf_hook_slow</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 65536 84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     ip_local_deliver_finish</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 65536 64    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     ip_protocol_deliver_rcu</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 65536 64    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     raw_local_deliver</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 65536 64    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     raw_v4_input</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 65536 64    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     skb_clone</span>
<span class="c">#    0xffff00005f10c400 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 65536 64    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     raw_rcv</span>
<span class="c">#    0xffff00005f10c400 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 65536 64    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     skb_push</span>
<span class="c">#    0xffff00005f10c400 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 65536 84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     ipv4_pktinfo_prepare</span>
<span class="c">#    0xffff00005f10c400 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 1500  84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     sock_queue_rcv_skb_reason</span>
<span class="c">#    0xffff00005f10c400 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 1500  84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     sk_filter_trim_cap</span>
<span class="c">#    0xffff00005f10c400 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 1500  84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     security_sock_rcv_skb</span>
<span class="c">#    0xffff00005f10c400 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 1500  84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     apparmor_socket_sock_rcv_skb</span>
<span class="c">#    0xffff00005f10c400 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 1500  84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     __sock_queue_rcv_skb</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 65536 64    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     icmp_rcv</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 65536 56    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     ping_rcv</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 65536 56    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     skb_push</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 65536 64    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     kfree_skb_reason(SKB_DROP_REASON_NO_SOCKET)</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 65536 64    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     skb_release_head_state</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 1500  64    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     skb_release_data</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 1500  64    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     kfree_skbmem</span>
<span class="c">#    0xffff00005f10c400 1   &lt;empty&gt;:42701    4026531840 300             0         0x0800 0     84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     __sock_recv_cmsgs</span>
<span class="c">#    0xffff00005f10c400 1   &lt;empty&gt;:42701    4026531840 300             0         0x0800 0     84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     __sock_recv_timestamp</span>
<span class="c">#    0xffff00005f10c400 1   &lt;empty&gt;:42701    4026531840 300             0         0x0800 0     84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     skb_free_datagram</span>
<span class="c">#    0xffff00005f10c400 1   &lt;empty&gt;:42701    4026531840 300             0         0x0800 0     84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     consume_skb</span>
<span class="c">#    0xffff00005f10c400 1   &lt;empty&gt;:42701    4026531840 300             0         0x0800 0     84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     skb_release_head_state</span>
<span class="c">#    0xffff00005f10c400 1   &lt;empty&gt;:42701    4026531840 300             0         0x0800 0     84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     sock_rfree</span>
<span class="c">#    0xffff00005f10c400 1   &lt;empty&gt;:42701    4026531840 300             0         0x0800 0     84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     skb_release_data</span>
<span class="c">#    0xffff00005f10c400 1   &lt;empty&gt;:42701    4026531840 300             0         0x0800 0     84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     skb_free_head</span>
<span class="c">#    0xffff00005f10c400 1   &lt;empty&gt;:42701    4026531840 300             0         0x0800 0     84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     kfree_skbmem</span>

<span class="c"># 다른 터미널에서 ping 명령어를 실행해보겠습니다.</span>
<span class="nv">$ </span>ping <span class="nt">-c</span> 1 8.8.8.8
<span class="c"># =&gt; PING 8.8.8.8 (8.8.8.8) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 8.8.8.8: icmp_seq=1 ttl=255 time=38.7 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 8.8.8.8 ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 38.740/38.740/38.740/0.000 ms</span>
</code></pre></div></div>

<ul>
  <li>ping 한번 보냈을 뿐인데 엄청난 량의 정보가 나왔습니다. 자세한 자료는 아래의 참고 자료를 참고해보시기 바랍니다.</li>
  <li>참고 자료
    <ul>
      <li><a href="https://nuguni.tistory.com/97">네트워크 패킷 추적 도구 - PWRU: Packet, Where Are You?</a></li>
      <li><a href="https://cilium.io/blog/2023/03/22/packet-where-are-you/">Going from Packet Where Aren’t You to pwru</a></li>
      <li><a href="https://medium.com/@Nikhil690/debugging-packet-drops-and-kernel-flows-with-pwru-fc03f3d479a4">PWRU: Debugging Packets and Kernel Flows</a></li>
    </ul>
  </li>
</ul>

<hr />

<h2 id="마치며">마치며</h2>

<p>이번 포스트에서는 Cilium의 관측성(Observability)을 위한 Hubble과 Prometheus/Grafana 연동, 각종 메트릭 그리고 PWRU를 설치하고 사용해보았습니다.
굉장히 많은 정보량에 압도되었습니다. 그래도 차근차근 따라가면서 실습해보니 Cilium의 관측성 기능을 이해하는데 큰 도움이 되었습니다.</p>

<p>관측성 도구들은 정말 강력하고 유용한 기능이지만 민감한 정보가 노출될 수 있기 때문에, 프로덕션 환경에서는 주의해서 사용해야 할 것 같습니다.
특히 끊임없이 새로운 기술이 나오고, 새로운 툴들이 나오고, 쉽게 설치하고 버전을 바꾸고 하는 현실에서
사소한 설정하나로 정보 유출이 발생할 수 있다는 점이 무섭기도 합니다. 
개발환경이나 내부에서 충분히 테스트하고 검증한 후에 프로덕션 환경에 적용하는 것이 중요할 것 같습니다.</p>

<p>이제 조금씩 회사 업무에도 Cilium을 적용하고 있어서 이번에 학습한 관측성 기능들을 활용해서
Cilium을 더 잘 이해하고, 문제를 해결하는데 도움이 될 것 같습니다.
이번 주도 스터디 준비해주신 모든 분들께 감사드립니다. :bow:</p>]]></content><author><name></name></author><category term="cilium" /><category term="kubernetes," /><category term="network," /><category term="linux," /><category term="cilium," /><category term="observability," /><category term="hubble," /><category term="prometheus," /><category term="grafana" /><summary type="html"><![CDATA[이번에는 Hubble, Prometheus, Grafana를 이용하여 Cilium의 Observability를 살펴보겠습니다.]]></summary></entry><entry><title type="html">[Cilium] 실습 환경 구성 및 Cilium 설치</title><link href="https://sweetlittlebird.github.io/posts/2025-07-20-Cilium-Week1/" rel="alternate" type="text/html" title="[Cilium] 실습 환경 구성 및 Cilium 설치" /><published>2025-07-20T00:10:18+09:00</published><updated>2025-07-20T00:10:18+09:00</updated><id>https://sweetlittlebird.github.io/posts/Cilium%20-%20Week1</id><content type="html" xml:base="https://sweetlittlebird.github.io/posts/2025-07-20-Cilium-Week1/"><![CDATA[<h2 id="들어가며">들어가며</h2>

<p>오랜만에 다시 스터디를 시작합니다.
이번에도 CloudNet@ 팀에서 진행하는 스터디로 고맙게도 스터디에 참여할 수 있게 되었습니다.
이번 스터디는 Cilium의 공식문서를 기반으로 실습해보는 스터디입니다.
Cilium 한가지 주제로 진행되는 만큼 깊고 진하게 학습할 수 있을것 같아 기대가 됩니다.</p>

<p>첫주차에는 실습 환경을 구성하고 Cilium을 설치하는 방법을 알아보겠습니다.</p>

<hr />

<h2 id="실습-환경-구성">실습 환경 구성</h2>

<h3 id="실습-환경-구성-준비">실습 환경 구성 준비</h3>

<p>저는 MacOS를 사용하고 있기때문에 homebrew를 이용하여 VirtualBox와 Vagrant를 설치하였습니다.</p>

<ul>
  <li>VirtualBox 설치</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install</span> <span class="nt">--cask</span> virtualbox
<span class="c"># =&gt; 🍺  virtualbox was successfully installed!</span>

<span class="nv">$ </span>VBoxManage <span class="nt">--version</span>
<span class="c"># =&gt; 7.1.10r169112</span>
</code></pre></div></div>

<ul>
  <li>Vagrant 설치</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install</span> <span class="nt">--cask</span> vagrant
<span class="c"># =&gt; 🍺  vagrant was successfully installed!</span>

<span class="nv">$ </span>vagrant version
<span class="c"># =&gt; Installed Version: 2.4.7</span>
<span class="c">#    Latest Version: 2.4.7</span>
<span class="c">#    </span>
<span class="c">#    You're running an up-to-date version of Vagrant!</span>
</code></pre></div></div>

<h3 id="실습-환경-소개">실습 환경 소개</h3>

<p>실습 환경을 도식화하면 다음과 같습니다.</p>

<p><img src="/assets/2025/cilium/w1/20250720_cilium_w1_1.png" alt="img.png" /></p>

<ul>
  <li>배포 가상 머신은 컨트롤플레인인 k8s-ctr, 워커노드 k8s-w1, k8s-w2로 구성되어 있습니다.
    <ul>
      <li>eth0 : 10.0.2.15 (모든 노드가 동일)</li>
      <li>eth1 : 192.168.10.100~102</li>
    </ul>
  </li>
  <li>초기 프로비저닝시 <code class="language-plaintext highlighter-rouge">kubeadm init</code>과 <code class="language-plaintext highlighter-rouge">join</code> 을 실행하여 클러스터를 구성하며, 초기에는 <strong>CNI가 설치되어 있지 않습니다</strong>.</li>
</ul>

<h3 id="실습-환경-배포-파일-작성">실습 환경 배포 파일 작성</h3>

<h4 id="vagrantfile"><strong>Vagrantfile</strong></h4>
<ul>
  <li>가상머신을 정의하고 부팅시 실행할 프로비저닝 설정을 합니다.</li>
</ul>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Variables</span>
<span class="no">K8SV</span> <span class="o">=</span> <span class="s1">'1.33.2-1.1'</span> <span class="c1"># Kubernetes Version : apt list -a kubelet , ex) 1.32.5-1.1</span>
<span class="no">CONTAINERDV</span> <span class="o">=</span> <span class="s1">'1.7.27-1'</span> <span class="c1"># Containerd Version : apt list -a containerd.io , ex) 1.6.33-1</span>
<span class="no">N</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1"># max number of worker nodes</span>

<span class="c1"># Base Image  https://portal.cloud.hashicorp.com/vagrant/discover/bento/ubuntu-24.04</span>
<span class="c1">## Rocky linux Image https://portal.cloud.hashicorp.com/vagrant/discover/rockylinux</span>
<span class="no">BOX_IMAGE</span> <span class="o">=</span> <span class="s2">"bento/ubuntu-24.04"</span>
<span class="no">BOX_VERSION</span> <span class="o">=</span> <span class="s2">"202502.21.0"</span>

<span class="no">Vagrant</span><span class="p">.</span><span class="nf">configure</span><span class="p">(</span><span class="s2">"2"</span><span class="p">)</span> <span class="k">do</span> <span class="o">|</span><span class="n">config</span><span class="o">|</span>
<span class="c1">#-ControlPlane Node</span>
    <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">define</span> <span class="s2">"k8s-ctr"</span> <span class="k">do</span> <span class="o">|</span><span class="n">subconfig</span><span class="o">|</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="no">BOX_IMAGE</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box_version</span> <span class="o">=</span> <span class="no">BOX_VERSION</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provider</span> <span class="s2">"virtualbox"</span> <span class="k">do</span> <span class="o">|</span><span class="n">vb</span><span class="o">|</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--groups"</span><span class="p">,</span> <span class="s2">"/Cilium-Lab"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--nicpromisc2"</span><span class="p">,</span> <span class="s2">"allow-all"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">name</span> <span class="o">=</span> <span class="s2">"k8s-ctr"</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">cpus</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">memory</span> <span class="o">=</span> <span class="mi">2048</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">linked_clone</span> <span class="o">=</span> <span class="kp">true</span>
      <span class="k">end</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">host_name</span> <span class="o">=</span> <span class="s2">"k8s-ctr"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.10.100"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="mi">60000</span><span class="p">,</span> <span class="ss">auto_correct: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">id: </span><span class="s2">"ssh"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">synced_folder</span> <span class="s2">"./"</span><span class="p">,</span> <span class="s2">"/vagrant"</span><span class="p">,</span> <span class="ss">disabled: </span><span class="kp">true</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"init_cfg.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">K8SV</span><span class="p">,</span> <span class="no">CONTAINERDV</span><span class="p">]</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"k8s-ctr.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">N</span> <span class="p">]</span>
    <span class="k">end</span>

<span class="c1">#-Worker Nodes Subnet1</span>
  <span class="p">(</span><span class="mi">1</span><span class="o">..</span><span class="no">N</span><span class="p">).</span><span class="nf">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">i</span><span class="o">|</span>
    <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">define</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span> <span class="k">do</span> <span class="o">|</span><span class="n">subconfig</span><span class="o">|</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="no">BOX_IMAGE</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box_version</span> <span class="o">=</span> <span class="no">BOX_VERSION</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provider</span> <span class="s2">"virtualbox"</span> <span class="k">do</span> <span class="o">|</span><span class="n">vb</span><span class="o">|</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--groups"</span><span class="p">,</span> <span class="s2">"/Cilium-Lab"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--nicpromisc2"</span><span class="p">,</span> <span class="s2">"allow-all"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">name</span> <span class="o">=</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">cpus</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">memory</span> <span class="o">=</span> <span class="mi">1536</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">linked_clone</span> <span class="o">=</span> <span class="kp">true</span>
      <span class="k">end</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">host_name</span> <span class="o">=</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.10.10</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="s2">"6000</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span> <span class="ss">auto_correct: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">id: </span><span class="s2">"ssh"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">synced_folder</span> <span class="s2">"./"</span><span class="p">,</span> <span class="s2">"/vagrant"</span><span class="p">,</span> <span class="ss">disabled: </span><span class="kp">true</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"init_cfg.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">K8SV</span><span class="p">,</span> <span class="no">CONTAINERDV</span><span class="p">]</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"k8s-w.sh"</span>
    <span class="k">end</span>
  <span class="k">end</span>
<span class="k">end</span>
</code></pre></div></div>

<h4 id="init_cfgsh"><strong>init_cfg.sh</strong></h4>
<ul>
  <li>프로비저닝시 vagrant가 실행할 초기 설정 스크립트입니다. arguments로 Kubernetes 버전과 Containerd 버전등을 받아서 설치합니다.</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>

<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config Start &lt;&lt;&lt;&lt;"</span>

<span class="nb">echo</span> <span class="s2">"[TASK 1] Setting Profile &amp; Change Timezone"</span>
<span class="nb">echo</span> <span class="s1">'alias vi=vim'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s2">"sudo su -"</span> <span class="o">&gt;&gt;</span> /home/vagrant/.bashrc
<span class="nb">ln</span> <span class="nt">-sf</span> /usr/share/zoneinfo/Asia/Seoul /etc/localtime

<span class="nb">echo</span> <span class="s2">"[TASK 2] Disable AppArmor"</span>
systemctl stop ufw <span class="o">&amp;&amp;</span> systemctl disable ufw <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
systemctl stop apparmor <span class="o">&amp;&amp;</span> systemctl disable apparmor <span class="o">&gt;</span>/dev/null 2&gt;&amp;1

<span class="nb">echo</span> <span class="s2">"[TASK 3] Disable and turn off SWAP"</span>
swapoff <span class="nt">-a</span> <span class="o">&amp;&amp;</span> <span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'/swap/s/^/#/'</span> /etc/fstab

<span class="nb">echo</span> <span class="s2">"[TASK 4] Install Packages"</span>
apt update <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
apt-get <span class="nb">install </span>apt-transport-https ca-certificates curl gpg <span class="nt">-y</span> <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1

<span class="c"># Download the public signing key for the Kubernetes package repositories.</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> <span class="nt">-m</span> 755 /etc/apt/keyrings
<span class="nv">K8SMMV</span><span class="o">=</span><span class="si">$(</span><span class="nb">echo</span> <span class="nv">$1</span> | <span class="nb">sed</span> <span class="nt">-En</span> <span class="s1">'s/^([0-9]+\.[0-9]+)\..*/\1/p'</span><span class="si">)</span>
curl <span class="nt">-fsSL</span> https://pkgs.k8s.io/core:/stable:/v<span class="nv">$K8SMMV</span>/deb/Release.key | <span class="nb">sudo </span>gpg <span class="nt">--dearmor</span> <span class="nt">-o</span> /etc/apt/keyrings/kubernetes-apt-keyring.gpg
<span class="nb">echo</span> <span class="s2">"deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v</span><span class="nv">$K8SMMV</span><span class="s2">/deb/ /"</span> <span class="o">&gt;&gt;</span> /etc/apt/sources.list.d/kubernetes.list
curl <span class="nt">-fsSL</span> https://download.docker.com/linux/ubuntu/gpg <span class="nt">-o</span> /etc/apt/keyrings/docker.asc
<span class="nb">echo</span> <span class="s2">"deb [arch=</span><span class="si">$(</span>dpkg <span class="nt">--print-architecture</span><span class="si">)</span><span class="s2"> signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu </span><span class="si">$(</span><span class="nb">.</span> /etc/os-release <span class="o">&amp;&amp;</span> <span class="nb">echo</span> <span class="s2">"</span><span class="nv">$VERSION_CODENAME</span><span class="s2">"</span><span class="si">)</span><span class="s2"> stable"</span> | <span class="nb">tee</span> /etc/apt/sources.list.d/docker.list <span class="o">&gt;</span> /dev/null

<span class="c"># packets traversing the bridge are processed by iptables for filtering</span>
<span class="nb">echo </span>1 <span class="o">&gt;</span> /proc/sys/net/ipv4/ip_forward
<span class="nb">echo</span> <span class="s2">"net.ipv4.ip_forward = 1"</span> <span class="o">&gt;&gt;</span> /etc/sysctl.d/k8s.conf

<span class="c"># enable br_netfilter for iptables </span>
modprobe br_netfilter
modprobe overlay
<span class="nb">echo</span> <span class="s2">"br_netfilter"</span> <span class="o">&gt;&gt;</span> /etc/modules-load.d/k8s.conf
<span class="nb">echo</span> <span class="s2">"overlay"</span> <span class="o">&gt;&gt;</span> /etc/modules-load.d/k8s.conf

<span class="nb">echo</span> <span class="s2">"[TASK 5] Install Kubernetes components (kubeadm, kubelet and kubectl)"</span>
<span class="c"># Update the apt package index, install kubelet, kubeadm and kubectl, and pin their version</span>
apt update <span class="o">&gt;</span>/dev/null 2&gt;&amp;1

<span class="c"># apt list -a kubelet ; apt list -a containerd.io</span>
apt-get <span class="nb">install</span> <span class="nt">-y</span> <span class="nv">kubelet</span><span class="o">=</span><span class="nv">$1</span> <span class="nv">kubectl</span><span class="o">=</span><span class="nv">$1</span> <span class="nv">kubeadm</span><span class="o">=</span><span class="nv">$1</span> containerd.io<span class="o">=</span><span class="nv">$2</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
apt-mark hold kubelet kubeadm kubectl <span class="o">&gt;</span>/dev/null 2&gt;&amp;1

<span class="c"># containerd configure to default and cgroup managed by systemd</span>
containerd config default <span class="o">&gt;</span> /etc/containerd/config.toml
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'s/SystemdCgroup = false/SystemdCgroup = true/g'</span> /etc/containerd/config.toml

<span class="c"># avoid WARN&amp;ERRO(default endpoints) when crictl run  </span>
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; /etc/crictl.yaml
runtime-endpoint: unix:///run/containerd/containerd.sock
image-endpoint: unix:///run/containerd/containerd.sock
</span><span class="no">EOF

</span><span class="c"># ready to install for k8s </span>
systemctl restart containerd <span class="o">&amp;&amp;</span> systemctl <span class="nb">enable </span>containerd
systemctl <span class="nb">enable</span> <span class="nt">--now</span> kubelet

<span class="nb">echo</span> <span class="s2">"[TASK 6] Install Packages &amp; Helm"</span>
apt-get <span class="nb">install</span> <span class="nt">-y</span> bridge-utils sshpass net-tools conntrack ngrep tcpdump ipset arping wireguard jq tree bash-completion unzip kubecolor <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
curl <span class="nt">-s</span> https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash <span class="o">&gt;</span>/dev/null 2&gt;&amp;1

<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div></div>

<h4 id="k8s-ctrsh"><strong>k8s-ctr.sh</strong></h4>
<ul>
  <li><code class="language-plaintext highlighter-rouge">kubeadm init</code>으로 컨트롤플레인을 설정하고, 편의를 위한 <code class="language-plaintext highlighter-rouge">k</code>, <code class="language-plaintext highlighter-rouge">kc</code> 등의 alias를 설정합니다.</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>

<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Controlplane config Start &lt;&lt;&lt;&lt;"</span>

<span class="nb">echo</span> <span class="s2">"[TASK 1] Initial Kubernetes"</span>
kubeadm init <span class="nt">--token</span> 123456.1234567890123456 <span class="nt">--token-ttl</span> 0 <span class="nt">--pod-network-cidr</span><span class="o">=</span>10.244.0.0/16 <span class="nt">--service-cidr</span><span class="o">=</span>10.96.0.0/16 <span class="nt">--apiserver-advertise-address</span><span class="o">=</span>192.168.10.100 <span class="nt">--cri-socket</span><span class="o">=</span>unix:///run/containerd/containerd.sock <span class="o">&gt;</span>/dev/null 2&gt;&amp;1


<span class="nb">echo</span> <span class="s2">"[TASK 2] Setting kube config file"</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> /root/.kube
<span class="nb">cp</span> <span class="nt">-i</span> /etc/kubernetes/admin.conf /root/.kube/config
<span class="nb">chown</span> <span class="si">$(</span><span class="nb">id</span> <span class="nt">-u</span><span class="si">)</span>:<span class="si">$(</span><span class="nb">id</span> <span class="nt">-g</span><span class="si">)</span> /root/.kube/config


<span class="nb">echo</span> <span class="s2">"[TASK 3] Source the completion"</span>
<span class="nb">echo</span> <span class="s1">'source &lt;(kubectl completion bash)'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'source &lt;(kubeadm completion bash)'</span> <span class="o">&gt;&gt;</span> /etc/profile


<span class="nb">echo</span> <span class="s2">"[TASK 4] Alias kubectl to k"</span>
<span class="nb">echo</span> <span class="s1">'alias k=kubectl'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'alias kc=kubecolor'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'complete -F __start_kubectl k'</span> <span class="o">&gt;&gt;</span> /etc/profile


<span class="nb">echo</span> <span class="s2">"[TASK 5] Install Kubectx &amp; Kubens"</span>
git clone https://github.com/ahmetb/kubectx /opt/kubectx <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">ln</span> <span class="nt">-s</span> /opt/kubectx/kubens /usr/local/bin/kubens
<span class="nb">ln</span> <span class="nt">-s</span> /opt/kubectx/kubectx /usr/local/bin/kubectx


<span class="nb">echo</span> <span class="s2">"[TASK 6] Install Kubeps &amp; Setting PS1"</span>
git clone https://github.com/jonmosco/kube-ps1.git /root/kube-ps1 <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="sh">"</span><span class="no">EOT</span><span class="sh">" &gt;&gt; /root/.bash_profile
source /root/kube-ps1/kube-ps1.sh
KUBE_PS1_SYMBOL_ENABLE=true
function get_cluster_short() {
  echo "</span><span class="nv">$1</span><span class="sh">" | cut -d . -f1
}
KUBE_PS1_CLUSTER_FUNCTION=get_cluster_short
KUBE_PS1_SUFFIX=') '
PS1='</span><span class="si">$(</span>kube_ps1<span class="si">)</span><span class="sh">'</span><span class="nv">$PS1</span><span class="sh">
</span><span class="no">EOT
</span>kubectl config rename-context <span class="s2">"kubernetes-admin@kubernetes"</span> <span class="s2">"HomeLab"</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1


<span class="nb">echo</span> <span class="s2">"[TASK 6] Install Kubeps &amp; Setting PS1"</span>
<span class="nb">echo</span> <span class="s2">"192.168.10.100 k8s-ctr"</span> <span class="o">&gt;&gt;</span> /etc/hosts
<span class="k">for</span> <span class="o">((</span> <span class="nv">i</span><span class="o">=</span>1<span class="p">;</span> i&lt;<span class="o">=</span><span class="nv">$1</span><span class="p">;</span> i++  <span class="o">))</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"192.168.10.10</span><span class="nv">$i</span><span class="s2"> k8s-w</span><span class="nv">$i</span><span class="s2">"</span> <span class="o">&gt;&gt;</span> /etc/hosts<span class="p">;</span> <span class="k">done


</span><span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Controlplane Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div></div>

<h4 id="k8s-wsh"><strong>k8s-w.sh</strong></h4>
<ul>
  <li>워커노드에서 <code class="language-plaintext highlighter-rouge">kubeadm join</code>을 실행하여 컨트롤플레인에 조인합니다.</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>

<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Node config Start &lt;&lt;&lt;&lt;"</span>

<span class="nb">echo</span> <span class="s2">"[TASK 1] K8S Controlplane Join"</span> 
kubeadm <span class="nb">join</span> <span class="nt">--token</span> 123456.1234567890123456 <span class="nt">--discovery-token-unsafe-skip-ca-verification</span> 192.168.10.100:6443  <span class="o">&gt;</span>/dev/null 2&gt;&amp;1

<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Node config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div></div>

<h3 id="실습-환경-배포">실습 환경 배포</h3>

<ul>
  <li>실습 환경 배포를 위한 파일이 준비되었으니 <code class="language-plaintext highlighter-rouge">vagrant up</code> 명령을 이용하여 가상 머신을 배포하겠습니다.</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>vagrant up
<span class="c"># =&gt; Bringing machine 'k8s-ctr' up with 'virtualbox' provider...</span>
<span class="c">#    Bringing machine 'k8s-w1' up with 'virtualbox' provider...</span>
<span class="c">#    Bringing machine 'k8s-w2' up with 'virtualbox' provider...</span>
<span class="c">#    ==&gt; k8s-ctr: Box 'bento/ubuntu-24.04' could not be found. Attempting to find and install...</span>
<span class="c">#        k8s-ctr: Box Provider: virtualbox</span>
<span class="c">#        k8s-ctr: Box Version: 202502.21.0</span>
<span class="c">#    ==&gt; k8s-ctr: Loading metadata for box 'bento/ubuntu-24.04'</span>
<span class="c">#        k8s-ctr: URL: https://vagrantcloud.com/api/v2/vagrant/bento/ubuntu-24.04</span>
<span class="c">#    ==&gt; k8s-ctr: Adding box 'bento/ubuntu-24.04' (v202502.21.0) for provider: virtualbox (arm64)</span>
<span class="c">#        k8s-ctr: Downloading: https://vagrantcloud.com/bento/boxes/ubuntu-24.04/versions/202502.21.0/providers/virtualbox/arm64/vagrant.box</span>
<span class="c">#    ==&gt; k8s-ctr: Successfully added box 'bento/ubuntu-24.04' (v202502.21.0) for 'virtualbox (arm64)'!</span>
<span class="c">#    ==&gt; k8s-ctr: Preparing master VM for linked clones...</span>
<span class="c">#    ...</span>
<span class="c">#        k8s-w2: &gt;&gt;&gt;&gt; K8S Node config End &lt;&lt;&lt;&lt;</span>
</code></pre></div></div>

<ul>
  <li>배포 후 각 노드에 ssh로 접속하여 ip를 확인해 보겠습니다.</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>ctr w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> vagrant ssh k8s-<span class="nv">$i</span> <span class="nt">-c</span> <span class="s1">'ip -c -4 addr show dev eth0'</span><span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span> <span class="c">#</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-ctr &lt;&lt;</span>
<span class="c">#    2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span>
<span class="c">#        altname enp0s8</span>
<span class="c">#        inet 10.0.2.15/24 metric 100 brd 10.0.2.255 scope global dynamic eth0</span>
<span class="c">#           valid_lft 85500sec preferred_lft 85500sec</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span>
<span class="c">#        altname enp0s8</span>
<span class="c">#        inet 10.0.2.15/24 metric 100 brd 10.0.2.255 scope global dynamic eth0</span>
<span class="c">#           valid_lft 85707sec preferred_lft 85707sec</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w2 &lt;&lt;</span>
<span class="c">#    2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span>
<span class="c">#        altname enp0s8</span>
<span class="c">#        inet 10.0.2.15/24 metric 100 brd 10.0.2.255 scope global dynamic eth0</span>
<span class="c">#           valid_lft 85781sec preferred_lft 85781sec</span>
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">k8s-ctr</code> 노드에 접속하여 기본 정보를 확인해 보겠습니다.</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>vagrant ssh k8s-ctr
<span class="nt">---</span>
<span class="c"># =&gt; Welcome to Ubuntu 24.04.2 LTS (GNU/Linux 6.8.0-53-generic aarch64)</span>
<span class="c">#    ...</span>
<span class="c">#    (⎈|HomeLab:N/A) root@k8s-ctr:~#</span>
<span class="nv">$ </span><span class="nb">whoami</span>
<span class="c"># =&gt; root</span>
<span class="nv">$ </span><span class="nb">pwd</span>
<span class="c"># =&gt; /root</span>
<span class="nv">$ </span>hostnamectl
<span class="c"># =&gt;  Static hostname: k8s-ctr</span>
<span class="c">#           Icon name: computer-vm</span>
<span class="c">#             Chassis: vm</span>
<span class="c">#          Machine ID: 3d6bd65db7dd43d392b2d5229abb5654</span>
<span class="c">#             Boot ID: 2d9ede04fd294425988e58c588dd201c</span>
<span class="c">#      Virtualization: qemu</span>
<span class="c">#    Operating System: Ubuntu 24.04.2 LTS</span>
<span class="c">#              Kernel: Linux 6.8.0-53-generic</span>
<span class="c">#        Architecture: arm64</span>
<span class="nv">$ </span>htop

<span class="nv">$ </span><span class="nb">cat</span> /etc/hosts
<span class="c"># =&gt; 127.0.0.1 localhost</span>
<span class="c">#    127.0.1.1 vagrant</span>
<span class="c">#    ...</span>
<span class="c">#    127.0.2.1 k8s-ctr k8s-ctr</span>
<span class="c">#    192.168.10.100 k8s-ctr</span>
<span class="c">#    192.168.10.101 k8s-w1</span>
<span class="c">#    192.168.10.102 k8s-w2</span>
<span class="nv">$ </span>ping <span class="nt">-c</span> 1 k8s-w1
<span class="c"># =&gt; PING k8s-w1 (192.168.10.101) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from k8s-w1 (192.168.10.101): icmp_seq=1 ttl=64 time=0.795 ms</span>
<span class="c">#    </span>
<span class="c">#    --- k8s-w1 ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 0.795/0.795/0.795/0.000 ms</span>
<span class="nv">$ </span>ping <span class="nt">-c</span> 1 k8s-w2
<span class="c"># =&gt; PING k8s-w2 (192.168.10.102) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from k8s-w2 (192.168.10.102): icmp_seq=1 ttl=64 time=1.20 ms</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-w1 <span class="nb">hostname</span>
<span class="c"># =&gt; k8s-w1</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-w2 <span class="nb">hostname</span>
<span class="c"># =&gt; k8s-w2</span>

<span class="c"># vagrant ssh 로 접속 시 tcp 연결 정보 : NAT Mode 10.0.2.2(GateWay)</span>
<span class="nv">$ </span>ss <span class="nt">-tnp</span> |grep sshd
<span class="c"># =&gt; ESTAB 0      0           [::ffff:10.0.2.15]:22          [::ffff:10.0.2.2]:63578 users:((&amp;quot;sshd&amp;quot;,pid=5141,fd=4),(&amp;quot;sshd&amp;quot;,pid=5094,fd=4))</span>

<span class="c"># nic 정보</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> addr
<span class="c"># =&gt; 1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span>
<span class="c">#       ...</span>
<span class="c">#    2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span>
<span class="c">#        link/ether 08:00:27:71:19:d8 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        altname enp0s8</span>
<span class="c">#        inet 10.0.2.15/24 metric 100 brd 10.0.2.255 scope global dynamic eth0</span>
<span class="c">#           valid_lft 82445sec preferred_lft 82445sec</span>
<span class="c">#    3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span>
<span class="c">#        link/ether 08:00:27:da:24:93 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        altname enp0s9</span>
<span class="c">#        inet 192.168.10.100/24 brd 192.168.10.255 scope global eth1</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>

<span class="c"># default 라우팅 정보 </span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.100</span>

<span class="c"># dns 서버 정보 : NAT Mode 10.0.2.3</span>
<span class="nv">$ </span>resolvectl
<span class="c"># =&gt; Global</span>
<span class="c">#             Protocols: -LLMNR -mDNS -DNSOverTLS DNSSEC=no/unsupported</span>
<span class="c">#      resolv.conf mode: stub</span>
<span class="c">#    </span>
<span class="c">#    Link 2 (eth0)</span>
<span class="c">#        Current Scopes: DNS</span>
<span class="c">#             Protocols: +DefaultRoute -LLMNR -mDNS -DNSOverTLS DNSSEC=no/unsupported</span>
<span class="c">#    Current DNS Server: 10.0.2.3</span>
<span class="c">#           DNS Servers: 10.0.2.3</span>
<span class="c">#    </span>
<span class="c">#    Link 3 (eth1)</span>
<span class="c">#        Current Scopes: none</span>
<span class="c">#             Protocols: -DefaultRoute -LLMNR -mDNS -DNSOverTLS DNSSEC=no/unsupported</span>
<span class="nv">$ </span><span class="nb">exit</span>
<span class="nt">---</span>
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">k8s-ctr</code> k8s 정보 확인</li>
</ul>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 클러스터 정보 확인</span>
<span class="nv">$ </span>kubectl cluster-info
<span class="c"># =&gt; Kubernetes control plane is running at https://192.168.10.100:6443</span>
<span class="c">#    CoreDNS is running at https://192.168.10.100:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</span>
<span class="c">#    </span>
<span class="c">#    To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.</span>

<span class="c"># 노드 정보 : 상태, INTERNAL-IP 확인</span>
<span class="nv">$ </span>kubectl get node <span class="nt">-owide</span>
<span class="c"># =&gt; NAME      STATUS     ROLES           AGE   VERSION   INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION     CONTAINER-RUNTIME</span>
<span class="c">#    k8s-ctr   NotReady   control-plane   2d    v1.33.2   192.168.10.100   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>
<span class="c">#    k8s-w1    NotReady   &lt;none&gt;          2d    v1.33.2   10.0.2.15        &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>
<span class="c">#    k8s-w2    NotReady   &lt;none&gt;          2d    v1.33.2   10.0.2.15        &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>

<span class="c"># 파드 정보 : 상태, 파드 IP 확인 - kube-proxy 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-A</span> <span class="nt">-owide</span>
<span class="c"># =&gt; NAMESPACE     NAME                              READY   STATUS    RESTARTS      AGE   IP               NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-79mbb          0/1     Pending   0             2d    &lt;none&gt;           &lt;none&gt;    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-rtx95          0/1     Pending   0             2d    &lt;none&gt;           &lt;none&gt;    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   etcd-k8s-ctr                      1/1     Running   1 (12m ago)   2d    192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-apiserver-k8s-ctr            1/1     Running   1 (12m ago)   2d    192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-controller-manager-k8s-ctr   1/1     Running   1 (12m ago)   2d    192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-proxy-hdffr                  1/1     Running   1 (11m ago)   2d    10.0.2.15        k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-proxy-r96sz                  1/1     Running   1 (12m ago)   2d    192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-proxy-swgmb                  1/1     Running   1 (11m ago)   2d    10.0.2.15        k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-scheduler-k8s-ctr            1/1     Running   1 (12m ago)   2d    192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>

<span class="c"># 단축어 확인(kc = kubecolor) &amp; coredns 파드 상태 확인</span>
<span class="nv">$ </span>k  describe pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>kube-dns
<span class="c"># =&gt; Name:                 coredns-674b8bbfcf-79mbb</span>
<span class="c">#    Namespace:            kube-system</span>
<span class="c">#    Priority:             2000000000</span>
<span class="c">#    Priority Class Name:  system-cluster-critical</span>
<span class="c">#    Service Account:      coredns</span>
<span class="c">#    Node:                 &lt;none&gt;</span>
<span class="c">#    Labels:               k8s-app=kube-dns</span>
<span class="c">#                          pod-template-hash=674b8bbfcf</span>
<span class="c">#    Annotations:          &lt;none&gt;</span>
<span class="c">#    Status:               Pending</span>
<span class="c">#    IP:</span>
<span class="c">#    IPs:                  &lt;none&gt;</span>
<span class="c">#    Controlled By:        ReplicaSet/coredns-674b8bbfcf</span>
<span class="c">#    Containers:</span>
<span class="c">#      coredns:</span>
<span class="c">#        Image:       registry.k8s.io/coredns/coredns:v1.12.0</span>
<span class="c">#        Ports:       53/UDP, 53/TCP, 9153/TCP</span>
<span class="c">#        Host Ports:  0/UDP, 0/TCP, 0/TCP</span>
<span class="c">#        Args:</span>
<span class="c">#          -conf</span>
<span class="c">#          /etc/coredns/Corefile</span>
<span class="c">#        Limits:</span>
<span class="c">#          memory:  170Mi</span>
<span class="c">#        Requests:</span>
<span class="c">#          cpu:        100m</span>
<span class="c">#          memory:     70Mi</span>
<span class="c">#        Liveness:     http-get http://:8080/health delay=60s timeout=5s period=10s #success=1 #failure=5</span>
<span class="c">#        Readiness:    http-get http://:8181/ready delay=0s timeout=1s period=10s #success=1 #failure=3</span>
<span class="c">#        Environment:  &lt;none&gt;</span>
<span class="c">#        Mounts:</span>
<span class="c">#          /etc/coredns from config-volume (ro)</span>
<span class="c">#          /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-vrqlj (ro)</span>
<span class="c">#    Conditions:</span>
<span class="c">#      Type           Status</span>
<span class="c">#      PodScheduled   False</span>
<span class="c">#    Volumes:</span>
<span class="c">#      config-volume:</span>
<span class="c">#        Type:      ConfigMap (a volume populated by a ConfigMap)</span>
<span class="c">#        Name:      coredns</span>
<span class="c">#        Optional:  false</span>
<span class="c">#      kube-api-access-vrqlj:</span>
<span class="c">#        Type:                    Projected (a volume that contains injected data from multiple sources)</span>
<span class="c">#        TokenExpirationSeconds:  3607</span>
<span class="c">#        ConfigMapName:           kube-root-ca.crt</span>
<span class="c">#        Optional:                false</span>
<span class="c">#        DownwardAPI:             true</span>
<span class="c">#    QoS Class:                   Burstable</span>
<span class="c">#    Node-Selectors:              kubernetes.io/os=linux</span>
<span class="c">#    Tolerations:                 CriticalAddonsOnly op=Exists</span>
<span class="c">#                                 node-role.kubernetes.io/control-plane:NoSchedule</span>
<span class="c">#                                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s</span>
<span class="c">#                                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s</span>
<span class="c">#    Events:</span>
<span class="c">#      Type     Reason            Age                  From               Message</span>
<span class="c">#      ----     ------            ----                 ----               -------</span>
<span class="c">#      Warning  FailedScheduling  7m18s (x2 over 12m)  default-scheduler  0/3 nodes are available: 3 node(s) had untolerated taint {node.kubernetes.io/not-ready: }. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.</span>
<span class="c">#      Warning  FailedScheduling  47h(x12 over 2d)    default-scheduler  0/3 nodes are available: 3 node(s) had untolerated taint {node.kubernetes.io/not-ready: }. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>kc describe pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>kube-dns
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">k8s-ctr</code> INTERNAL-IP 변경 설정</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> /var/lib/kubelet/kubeadm-flags.env
<span class="c"># =&gt; KUBELET_KUBEADM_ARGS="--container-runtime-endpoint=unix:///run/containerd/containerd.sock --pod-infra-container-image=registry.k8s.io/pause:3.10"</span>

<span class="c"># INTERNAL-IP 변경 설정</span>
<span class="nv">$ NODEIP</span><span class="o">=</span><span class="si">$(</span>ip <span class="nt">-4</span> addr show eth1 | <span class="nb">grep</span> <span class="nt">-oP</span> <span class="s1">'(?&lt;=inet\s)\d+(\.\d+){3}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/^</span><span class="se">\(</span><span class="s2">KUBELET_KUBEADM_ARGS=</span><span class="se">\"\)</span><span class="s2">/</span><span class="se">\1</span><span class="s2">--node-ip=</span><span class="k">${</span><span class="nv">NODEIP</span><span class="k">}</span><span class="s2"> /"</span> /var/lib/kubelet/kubeadm-flags.env
<span class="nv">$ </span>systemctl daemon-reexec <span class="o">&amp;&amp;</span> systemctl restart kubelet

<span class="nv">$ </span><span class="nb">cat</span> /var/lib/kubelet/kubeadm-flags.env
<span class="c"># =&gt; KUBELET_KUBEADM_ARGS="--node-ip=192.168.10.100 --container-runtime-endpoint=unix:///run/containerd/containerd.sock --pod-infra-container-image=registry.k8s.io/pause:3.10"</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get node <span class="nt">-owide</span>
<span class="c"># =&gt; NAME      STATUS     ROLES           AGE   VERSION   INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION     CONTAINER-RUNTIME</span>
<span class="c">#    k8s-ctr   NotReady   control-plane   2d    v1.33.2   192.168.10.100   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>
<span class="c">#    k8s-w1    NotReady   &lt;none&gt;          2d    v1.33.2   10.0.2.15        &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>
<span class="c">#    k8s-w2    NotReady   &lt;none&gt;          2d    v1.33.2   10.0.2.15        &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">k8s-w1</code>, <code class="language-plaintext highlighter-rouge">k8s-w2</code> 에도 위와 동일한 방법으로 INTERNAL-IP를 192.168.10.x로 변경합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">k8s-w1/w2</code> 설정 완료 후 INTERNAL-IP 확인</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl get node <span class="nt">-owide</span>
<span class="c"># =&gt; NAME      STATUS     ROLES           AGE   VERSION   INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION     CONTAINER-RUNTIME</span>
<span class="c">#    k8s-ctr   NotReady   control-plane   2d    v1.33.2   192.168.10.100   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>
<span class="c">#    k8s-w1    NotReady   &lt;none&gt;          2d    v1.33.2   192.168.10.101   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>
<span class="c">#    k8s-w2    NotReady   &lt;none&gt;          2d    v1.33.2   192.168.10.102   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>

<span class="nv">$ </span>kubectl get pod <span class="nt">-A</span> <span class="nt">-owide</span>
<span class="c"># =&gt; NAMESPACE     NAME                              READY   STATUS    RESTARTS      AGE   IP               NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-79mbb          0/1     Pending   0             2d    &lt;none&gt;           &lt;none&gt;    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-rtx95          0/1     Pending   0             2d    &lt;none&gt;           &lt;none&gt;    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   etcd-k8s-ctr                      1/1     Running   1 (27m ago)   2d    192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-apiserver-k8s-ctr            1/1     Running   1 (27m ago)   2d    192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-controller-manager-k8s-ctr   1/1     Running   1 (27m ago)   2d    192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-proxy-hdffr                  1/1     Running   1 (26m ago)   2d    192.168.10.101   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-proxy-r96sz                  1/1     Running   1 (27m ago)   2d    192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-proxy-swgmb                  1/1     Running   1 (26m ago)   2d    192.168.10.102   k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-scheduler-k8s-ctr            1/1     Running   1 (27m ago)   2d    192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">k8s-ctr</code> static pod의 IP 변경 설정</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>tree /etc/kubernetes/manifests
<span class="c"># =&gt; /etc/kubernetes/manifests</span>
<span class="c">#    ├── etcd.yaml</span>
<span class="c">#    ├── kube-apiserver.yaml</span>
<span class="c">#    ├── kube-controller-manager.yaml</span>
<span class="c">#    └── kube-scheduler.yaml</span>

<span class="c"># etcd 정보 확인</span>
<span class="nv">$ </span><span class="nb">cat</span> /etc/kubernetes/manifests/etcd.yaml
<span class="c"># =&gt;   ...</span>
<span class="c">#      volumes:</span>
<span class="c">#      - hostPath:</span>
<span class="c">#          path: /etc/kubernetes/pki/etcd</span>
<span class="c">#          type: DirectoryOrCreate</span>
<span class="c">#        name: etcd-certs</span>
<span class="c">#      - hostPath:</span>
<span class="c">#          path: /var/lib/etcd</span>
<span class="c">#          type: DirectoryOrCreate</span>
<span class="c">#        name: etcd-data</span>
<span class="c">#      ...</span>

<span class="nv">$ </span>tree /var/lib/etcd/
<span class="c"># =&gt; /var/lib/etcd/</span>
<span class="c">#    └── member</span>
<span class="c">#        ├── snap</span>
<span class="c">#        │   ├── 0000000000000003-0000000000002711.snap</span>
<span class="c">#        │   └── db</span>
<span class="c">#        └── wal</span>
<span class="c">#            ├── 0000000000000000-0000000000000000.wal</span>
<span class="c">#            └── 0.tmp</span>

<span class="c"># k8s-ctr 재부팅</span>
<span class="nv">$ </span>reboot
</code></pre></div></div>

<hr />

<h2 id="flannel-cni">Flannel CNI</h2>

<h3 id="flannel-소개">Flannel 소개</h3>

<ul>
  <li>Flannel은 쿠버네티스의 네트워크 요구사항을 충족하는 가장 간단하고 사용하기 쉬운 오버레이 네트워크 플러그인입니다.</li>
  <li>Flannel은 가상 네트워크를 생성하여 파드 간 통신을 가능하게 하며, VXLAN, UDP, Host-GW 등 다양한 백엔드를 지원합니다. 이 중에서는 VXLAN 사용이 가장 권장됩니다.</li>
  <li>VXLAN(Virtual eXtensible Local Area Network)은 물리적인 네트워크 환경 위에 논리적인 가상 네트워크를 구성하는 기술로, UDP 8472 포트를 통해 노드 간 터널링 방식으로 통신합니다.</li>
</ul>

<p><img src="/assets/2025/cilium/w1/20250720_cilium_w1_2.png" alt="img.png" class="image-center" />
<em class="image-caption">Flannel 구조 (출처: 추가예정)</em></p>

<ul>
  <li>위 그림처럼 파드의 eth0 네트워크 인터페이스는 호스트 네임스페이스의 veth 인터페이스와 연결되고, veth는 cni0와 연결됩니다.</li>
  <li>같은 노드 내에서는 cni0 브릿지를 통해 파드 간 통신이 이루어지며, 다른 노드와의 통신은 VXLAN을 통해 처리됩니다.</li>
  <li>VXLAN 경로에서는 cni0 브릿지를 거쳐 flannel.1 인터페이스로 패킷이 전달되고, flannel.1은 호스트의 eth0을 통해 다른 노드로 전송합니다. 이때 <strong>flannel.1은 VTEP(Vxlan Tunnel End Point)</strong> 역할을 하며, 패킷을 캡슐화하여 대상 노드의 IP로 전송하고, 도착한 노드에서는 캡슐을 해제해 해당 파드로 전달합니다.</li>
  <li>각 노드는 파드에 할당할 수 있는 IP 네트워크 대역을 가지고 있으며, flannel을 통해 ETCD나 Kubernetes API에 전달된 정보를 바탕으로 모든 노드는 자신의 라우팅 테이블을 업데이트합니다. 이를 통해 서로 다른 노드의 파드끼리도 내부 IP 주소로 통신할 수 있습니다.</li>
</ul>

<h3 id="flannel-설치-및-확인">Flannel 설치 및 확인</h3>

<ul>
  <li>설치 전 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># IP 주소 범위 확인</span>
<span class="nv">$ </span>kubectl cluster-info dump | <span class="nb">grep</span> <span class="nt">-m</span> 2 <span class="nt">-E</span> <span class="s2">"cluster-cidr|service-cluster-ip-range"</span>
<span class="c"># =&gt;                             "--service-cluster-ip-range=10.96.0.0/16",</span>
<span class="c">#                                "--cluster-cidr=10.244.0.0/16",</span>

<span class="c"># coredns 파드 상태 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>kube-dns <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                       READY   STATUS    RESTARTS   AGE     IP       NODE     NOMINATED NODE   READINESS GATES</span>
<span class="c">#    coredns-674b8bbfcf-79mbb   0/1     &lt;span style="color: green;"&gt;Pending&lt;/span&gt;   0          2d14h   &lt;none&gt;   &lt;none&gt;   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    coredns-674b8bbfcf-rtx95   0/1     &lt;span style="color: green;"&gt;Pending&lt;/span&gt;   0          2d14h   &lt;none&gt;   &lt;none&gt;   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    &lt;span style="color: green;"&gt;👉 CNI가 설치되지 않아서 Pending 상태입니다&lt;/span&gt;</span>

<span class="c">#</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> <span class="nb">link</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 08:00:27:71:19:d8 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 08:00:27:da:24:93 brd ff:ff:ff:ff:ff:ff</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.100</span>
<span class="nv">$ </span>brctl show
<span class="c"># =&gt; &lt;span style="color: green;"&gt;없음&lt;/span&gt;</span>

<span class="nv">$ </span>ip <span class="nt">-c</span> addr
<span class="c"># =&gt; ...</span>
<span class="c">#    2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span>
<span class="c">#        link/ether 08:00:27:71:19:d8 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet 10.0.2.15/24 metric 100 brd 10.0.2.255 scope global dynamic eth0</span>
<span class="c">#           valid_lft 85957sec preferred_lft 85957sec</span>
<span class="c">#    3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span>
<span class="c">#        link/ether 08:00:27:da:24:93 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet 192.168.10.100/24 brd 192.168.10.255 scope global eth1</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="nv">$ </span>ifconfig | <span class="nb">grep</span> <span class="nt">-iEA1</span> <span class="s1">'eth[0-9]:'</span>
<span class="c"># =&gt; eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span>
<span class="c">#            inet 10.0.2.15  netmask 255.255.255.0  broadcast 10.0.2.255</span>
<span class="c">#    --</span>
<span class="c">#    eth1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span>
<span class="c">#            inet 192.168.10.100  netmask 255.255.255.0  broadcast 192.168.10.255</span>

<span class="c">#</span>
<span class="nv">$ </span>iptables-save
<span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> filter <span class="nt">-S</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> mangle <span class="nt">-S</span>

<span class="c"># flannel 설치 후 비교를 위해 설치 전의 iptables 설정을 저장합니다.</span>
<span class="nv">$ </span>iptables-save <span class="o">&gt;</span> iptables-before-flannel.txt

<span class="c">#</span>
<span class="nv">$ </span>tree /etc/cni/net.d/
<span class="c"># =&gt; /etc/cni/net.d/</span>
<span class="c">#    </span>
<span class="c">#    0 directories, 0 files</span>
</code></pre></div></div>

<ul>
  <li>Flannel 설치</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># helm에 의한 namespace 생성 오류 방지를 위해 kube-flannel 네임스페이스를 수동으로 생성합니다.</span>
<span class="nv">$ </span>kubectl create ns kube-flannel
<span class="c"># =&gt; namespace/kube-flannel created</span>
<span class="nv">$ </span>kubectl label <span class="nt">--overwrite</span> ns kube-flannel pod-security.kubernetes.io/enforce<span class="o">=</span>privileged
<span class="c"># =&gt; namespace/kube-flannel labeled</span>

<span class="nv">$ </span>helm repo add flannel https://flannel-io.github.io/flannel/
<span class="c"># =&gt; "flannel" has been added to your repositories</span>
<span class="nv">$ </span>helm repo list
<span class="c"># =&gt; NAME    URL</span>
<span class="c">#    flannel https://flannel-io.github.io/flannel/</span>

<span class="nv">$ </span>helm search repo flannel
<span class="c"># =&gt; NAME            CHART VERSION   APP VERSION     DESCRIPTION</span>
<span class="c">#    flannel/flannel v0.27.1         v0.27.1         Install Flannel Network Plugin.</span>
<span class="nv">$ </span>helm show values flannel/flannel
<span class="c"># =&gt; ...</span>
<span class="c">#    podCidr: "10.244.0.0/16"</span>
<span class="c">#    ...</span>
<span class="c">#      cniBinDir: "/opt/cni/bin"</span>
<span class="c">#      cniConfDir: "/etc/cni/net.d"</span>
<span class="c">#      skipCNIConfigInstallation: false</span>
<span class="c">#      enableNFTables: false</span>
<span class="c">#      args:</span>
<span class="c">#      - "--ip-masq"</span>
<span class="c">#      - "--kube-subnet-mgr"</span>
<span class="c">#      backend: "vxlan"</span>
<span class="c">#    ...</span>

<span class="c"># k8s 관련 트래픽 통신 동작하는 nic 지정</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> &gt; flannel-values.yaml
podCidr: "10.244.0.0/16"

flannel:
  args:
  - "--ip-masq"
  - "--kube-subnet-mgr"
  - "--iface=eth1"  
</span><span class="no">EOF

</span><span class="c"># helm 설치</span>
<span class="nv">$ </span>helm <span class="nb">install </span>flannel <span class="nt">--namespace</span> kube-flannel flannel/flannel <span class="nt">-f</span> flannel-values.yaml
<span class="c"># =&gt; NAME: flannel</span>
<span class="c">#    LAST DEPLOYED: Mon Jan 19 13:52:04 2025</span>
<span class="c">#    NAMESPACE: kube-flannel</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 1</span>
<span class="c">#    TEST SUITE: None</span>
<span class="nv">$ </span>helm list <span class="nt">-A</span>
<span class="c"># =&gt; NAME    NAMESPACE       REVISION        UPDATED                                 STATUS          CHART           APP VERSION</span>
<span class="c">#    flannel kube-flannel    1               2025-01-19 13:52:04.427781204 +0900 KST deployed        flannel-v0.27.1 v0.27.1</span>

<span class="c"># 확인 : install-cni-plugin, install-cni</span>
<span class="nv">$ </span>kc describe pod <span class="nt">-n</span> kube-flannel <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>flannel
<span class="c"># =&gt; Name:                 kube-flannel-ds-5fm6l</span>
<span class="c">#    Namespace:            kube-flannel</span>
<span class="c">#    Priority:             2000001000</span>
<span class="c">#    Priority Class Name:  system-node-critical</span>
<span class="c">#    Service Account:      flannel</span>
<span class="c">#    Node:                 &lt;span style="color: green;"&gt;k8s-w1/192.168.10.101&lt;/span&gt;</span>
<span class="c">#    Start Time:           Sat, 19 Jul 2025 13:52:06 +0900</span>
<span class="c">#    Labels:               app=flannel</span>
<span class="c">#                          controller-revision-hash=66c5c78475</span>
<span class="c">#                          pod-template-generation=1</span>
<span class="c">#                          tier=node</span>
<span class="c">#    Annotations:          &lt;none&gt;</span>
<span class="c">#    Status:               Running</span>
<span class="c">#    IP:                   192.168.10.101</span>
<span class="c">#    IPs:</span>
<span class="c">#      IP:           192.168.10.101</span>
<span class="c">#    Controlled By:  DaemonSet/kube-flannel-ds</span>
<span class="c">#    Init Containers:</span>
<span class="c">#      install-cni-plugin:</span>
<span class="c">#      ...</span>
<span class="c">#      install-cni:</span>
<span class="c">#      ....</span>
<span class="c">#    Containers:</span>
<span class="c">#      kube-flannel:</span>
<span class="c">#        Container ID:  containerd://c6a1e24ae6193491289908c4b10a8ce6f9a36e000114aaf61dc60da43bdc50ca</span>
<span class="c">#        Image:         ghcr.io/flannel-io/flannel:v0.27.1</span>
<span class="c">#        Image ID:      ghcr.io/flannel-io/flannel@sha256:0c95c822b690f83dc827189d691015f92ab7e249e238876b56442b580c492d85</span>
<span class="c">#        Port:          &lt;none&gt;</span>
<span class="c">#        Host Port:     &lt;none&gt;</span>
<span class="c">#    ...</span>
<span class="c">#    Name:                 kube-flannel-ds-dstmv</span>
<span class="c">#    Namespace:            kube-flannel</span>
<span class="c">#    Priority:             2000001000</span>
<span class="c">#    Priority Class Name:  system-node-critical</span>
<span class="c">#    Service Account:      flannel</span>
<span class="c">#    Node:                 &lt;span style="color: green;"&gt;k8s-w2/192.168.10.102&lt;/span&gt;</span>
<span class="c">#    Start Time:           Sat, 19 Jul 2025 13:52:05 +0900</span>
<span class="c">#    ...</span>
<span class="c">#    IP:                   192.168.10.102</span>
<span class="c">#    ...</span>
<span class="c">#    Name:                 kube-flannel-ds-lsf7h</span>
<span class="c">#    Namespace:            kube-flannel</span>
<span class="c">#    Priority:             2000001000</span>
<span class="c">#    Priority Class Name:  system-node-critical</span>
<span class="c">#    Service Account:      flannel</span>
<span class="c">#    Node:                 &lt;span style="color: green;"&gt;k8s-ctr/192.168.10.100&lt;/span&gt;</span>
<span class="c">#    Start Time:           Sat, 19 Jul 2025 13:52:04 +0900</span>
<span class="c">#    Labels:               app=flannel</span>
<span class="c">#                          controller-revision-hash=66c5c78475</span>
<span class="c">#                          pod-template-generation=1</span>
<span class="c">#                          tier=node</span>
<span class="c">#    Annotations:          &lt;none&gt;</span>
<span class="c">#    Status:               Running</span>
<span class="c">#    IP:                   192.168.10.100</span>
<span class="c">#    ...</span>

<span class="nv">$ </span>tree /opt/cni/bin/ <span class="c"># flannel</span>
<span class="c"># =&gt; /opt/cni/bin/</span>
<span class="c">#    ├── bandwidth</span>
<span class="c">#    ├── bridge</span>
<span class="c">#    ├── dhcp</span>
<span class="c">#    ├── dummy</span>
<span class="c">#    ├── firewall</span>
<span class="c">#    ├── flannel</span>
<span class="c">#    ├── host-device</span>
<span class="c">#    ├── host-local</span>
<span class="c">#    ├── ipvlan</span>
<span class="c">#    ├── LICENSE</span>
<span class="c">#    ├── loopback</span>
<span class="c">#    ├── macvlan</span>
<span class="c">#    ├── portmap</span>
<span class="c">#    ├── ptp</span>
<span class="c">#    ├── README.md</span>
<span class="c">#    ├── sbr</span>
<span class="c">#    ├── static</span>
<span class="c">#    ├── tap</span>
<span class="c">#    ├── tuning</span>
<span class="c">#    ├── vlan</span>
<span class="c">#    └── vrf</span>
<span class="c">#    </span>
<span class="c">#    1 directory, 21 files</span>
<span class="nv">$ </span>tree /etc/cni/net.d/
<span class="c"># =&gt; /etc/cni/net.d/</span>
<span class="c">#    └── 10-flannel.conflist</span>
<span class="c">#    </span>
<span class="c">#    1 directory, 1 file</span>
<span class="nv">$ </span><span class="nb">cat</span> /etc/cni/net.d/10-flannel.conflist | jq
<span class="c"># =&gt; {</span>
<span class="c">#      "name": "cbr0",</span>
<span class="c">#      "cniVersion": "0.3.1",</span>
<span class="c">#      "plugins": [</span>
<span class="c">#        {</span>
<span class="c">#          "type": "flannel",</span>
<span class="c">#          "delegate": {</span>
<span class="c">#            "hairpinMode": true,</span>
<span class="c">#            "isDefaultGateway": true</span>
<span class="c">#          }</span>
<span class="c">#        },</span>
<span class="c">#        {</span>
<span class="c">#          "type": "portmap",</span>
<span class="c">#          "capabilities": {</span>
<span class="c">#            "portMappings": true</span>
<span class="c">#          }</span>
<span class="c">#        }</span>
<span class="c">#      ]</span>
<span class="c">#    }</span>
<span class="nv">$ </span>kc describe cm <span class="nt">-n</span> kube-flannel kube-flannel-cfg
<span class="c"># =&gt; ...</span>
<span class="c">#    net-conf.json:</span>
<span class="c">#    ----</span>
<span class="c">#    {</span>
<span class="c">#      "Network": "10.244.0.0/16",</span>
<span class="c">#      "Backend": {</span>
<span class="c">#        "Type": "vxlan"</span>
<span class="c">#      }</span>
<span class="c">#    }</span>

<span class="c"># 설치 전과 비교해보겠습니다.</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> <span class="nb">link</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 08:00:27:71:19:d8 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 08:00:27:da:24:93 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    &lt;span style="color: green;"&gt;4: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default&lt;/span&gt;</span>
<span class="c">#    &lt;span style="color: green;"&gt;    link/ether aa:3f:e5:cd:ae:92 brd ff:ff:ff:ff:ff:ff&lt;/span&gt;</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route | <span class="nb">grep </span>10.244.
<span class="c"># =&gt; 10.244.1.0/24 via 10.244.1.0 dev flannel.1 onlink</span>
<span class="c">#    10.244.2.0/24 via 10.244.2.0 dev flannel.1 onlink</span>

<span class="nv">$ </span>ping <span class="nt">-c</span> 1 10.244.1.0
<span class="c"># =&gt; PING 10.244.1.0 (10.244.1.0) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 10.244.1.0: icmp_seq=1 ttl=64 time=1.31 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 10.244.1.0 ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 1.314/1.314/1.314/0.000 ms</span>
<span class="nv">$ </span>ping <span class="nt">-c</span> 1 10.244.2.0
<span class="c"># =&gt; PING 10.244.2.0 (10.244.2.0) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 10.244.2.0: icmp_seq=1 ttl=64 time=1.31 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 10.244.2.0 ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 1.312/1.312/1.312/0.000 ms</span>

<span class="nv">$ </span>brctl show
<span class="nv">$ </span>iptables-save
<span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> filter <span class="nt">-S</span>
<span class="nv">$ </span>iptables-save <span class="o">&gt;</span> iptables-after-flannel.txt
<span class="c"># 설치 전과 후의 iptables 설정을 비교합니다.</span>
<span class="nv">$ </span>diff <span class="nt">-u</span> iptables-before-flannel.txt iptables-after-flannel.txt

<span class="c"># k8s-w1, k8s-w2 정보 확인</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> <span class="nb">link</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> route <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> brctl show <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
</code></pre></div></div>

<h3 id="샘플-애플리케이션-배포-및-확인">샘플 애플리케이션 배포 및 확인</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 샘플 애플리케이션 배포</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webpod
spec:
  replicas: 2
  selector:
    matchLabels:
      app: webpod
  template:
    metadata:
      labels:
        app: webpod
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - sample-app
            topologyKey: "kubernetes.io/hostname"
      containers:
      - name: webpod
        image: traefik/whoami
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: webpod
  labels:
    app: webpod
spec:
  selector:
    app: webpod
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
  type: ClusterIP
</span><span class="no">EOF
</span><span class="c"># =&gt; deployment.apps/webpod created</span>
<span class="c">#    service/webpod created</span>

<span class="c"># k8s-ctr 노드에 curl-pod 파드 배포</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: curl-pod
  labels:
    app: curl
spec:
  nodeName: k8s-ctr
  containers:
    - name: curl
      image: alpine/curl
      command: ["sleep", "36000"]
</span><span class="no">EOF
</span><span class="c"># =&gt; pod/curl-pod created</span>

<span class="c"># 컨트롤플레인 노드(k8s-ctr)에서 파드 확인</span>
<span class="nv">$ </span>crictl ps
<span class="c"># =&gt; CONTAINER     IMAGE         CREATED        STATE   NAME                    ATTEMPT POD ID        POD                               NAMESPACE</span>
<span class="c">#    ba7ddc59fa138 1fb7da88b3320 1 second ago   Running curl                    0       a87775d3d7098 &lt;span style="color: green;"&gt;curl-pod&lt;/span&gt;                          default</span>
<span class="c">#    2c095a0d795b7 83a2e3e54aa1e 19 minutes ago Running kube-flannel            0       49d7f057d7491 kube-flannel-ds-lsf7h             kube-flannel</span>
<span class="c">#    13ff95772dd16 738e99dbd7325 35 minutes ago Running kube-proxy              3       0ce95a5226767 kube-proxy-r96sz                  kube-system</span>
<span class="c">#    625a7ec089f93 c03972dff86ba 35 minutes ago Running kube-scheduler          3       7691ca47ac391 kube-scheduler-k8s-ctr            kube-system</span>
<span class="c">#    3b02267780926 ef439b94d49d4 35 minutes ago Running kube-controller-manager 3       232075758b77f kube-controller-manager-k8s-ctr   kube-system</span>
<span class="c">#    f956731d12744 31747a36ce712 35 minutes ago Running etcd                    3       7ac2514bac9cb etcd-k8s-ctr                      kube-system</span>
<span class="c">#    9f50506b3ca66 c0425f3fe3fbf 35 minutes ago Running kube-apiserver          3       d5246dd2d31b9 kube-apiserver-k8s-ctr            kube-system</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 curl-pod는 nodeName: 을 통해 컨트롤플레인 노드(k8s-ctr)에 배포되었습니다.&lt;/span&gt;</span>

<span class="c"># 워커 노드(k8s-w1, k8s-w2)에서 파드 확인</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>crictl ps <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; CONTAINER     IMAGE         CREATED        STATE   NAME                    ATTEMPT POD ID        POD                       NAMESPACE</span>
<span class="c">#    c934a221a4fec ab541801c8cc5 57 seconds ago Running webpod                  0       7323e0f4eced8 &lt;span style="color: green;"&gt;webpod-697b545f57-7j5vt&lt;/span&gt;   default</span>
<span class="c">#    c6a1e24ae6193 83a2e3e54aa1e 20 minutes ago Running kube-flannel            0       3a86bc505126a kube-flannel-ds-5fm6l     kube-flannel</span>
<span class="c">#    b55a66b5cd0a6 738e99dbd7325 35 minutes ago Running kube-proxy              2       8bc7a54488b35 kube-proxy-hdffr          kube-system</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w2 &lt;&lt;</span>
<span class="c">#    CONTAINER     IMAGE         CREATED        STATE   NAME                    ATTEMPT POD ID              POD                        NAMESPACE</span>
<span class="c">#    54658fa9cfc29 ab541801c8cc5 58 seconds ago Running webpod                  0       8dec7a5a7aed1 &lt;span style="color: green;"&gt;webpod-697b545f57-sdv4l&lt;/span&gt;    default</span>
<span class="c">#    9b2a414ee1acc f72407be9e08c 19 minutes ago Running coredns                 0       23071bf7a21e4 coredns-674b8bbfcf-rtx95   kube-system</span>
<span class="c">#    e1c86c4fa20fe f72407be9e08c 20 minutes ago Running coredns                 0       757397c6bcd8f coredns-674b8bbfcf-79mbb   kube-system</span>
<span class="c">#    eeac62c8beba7 83a2e3e54aa1e 20 minutes ago Running kube-flannel            0       1b4ba4f721424 kube-flannel-ds-dstmv      kube-flannel</span>
<span class="c">#    0a6112c11e948 738e99dbd7325 35 minutes ago Running kube-proxy              2       f9f19975aed04 kube-proxy-swgmb           kube-system</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 webpod는 별도로 nodeName: 을 지정하지 않았기 때문에 워커 노드(k8s-w1, k8s-w2)에 배포되었습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<ul>
  <li>확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 배포 확인</span>
<span class="nv">$ </span>kubectl get deploy,svc,ep webpod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                     READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES           SELECTOR</span>
<span class="c">#    deployment.apps/webpod   2/2     2            2           18m   webpod       traefik/whoami   app=webpod</span>
<span class="c">#    </span>
<span class="c">#    NAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE   SELECTOR</span>
<span class="c">#    service/webpod   ClusterIP   10.96.62.184   &lt;none&gt;        80/TCP    18m   app=webpod</span>
<span class="c">#    </span>
<span class="c">#    NAME               ENDPOINTS                     AGE</span>
<span class="c">#    endpoints/webpod   10.244.1.2:80,10.244.2.4:80   18m</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl api-resources | <span class="nb">grep</span> <span class="nt">-i</span> endpoint
<span class="c"># =&gt; endpoints                           ep           v1                                true         Endpoints</span>
<span class="c">#    endpointslices                                   discovery.k8s.io/v1               true         EndpointSlice</span>

<span class="nv">$ </span>kubectl get endpointslices <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>webpod
<span class="c"># =&gt; NAME           ADDRESSTYPE   PORTS   ENDPOINTS               AGE</span>
<span class="c">#    webpod-9pfs7   IPv4          80      10.244.2.4,10.244.1.2   18m</span>

<span class="c"># 배포 전과 비교해보겠습니다.</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> <span class="nb">link</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 08:00:27:71:19:d8 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 08:00:27:da:24:93 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    4: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default</span>
<span class="c">#        link/ether aa:3f:e5:cd:ae:92 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    5: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether b2:e2:a2:aa:4e:5c brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    &lt;span style="color: green;"&gt;6: veth0911be7c@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default qlen 1000&lt;/span&gt;</span>
<span class="c">#    &lt;span style="color: green;"&gt;    link/ether 6a:8b:92:5e:74:b3 brd ff:ff:ff:ff:ff:ff link-netns cni-15400ffe-d5f7-c6c2-78d9-dbbbc2f08db7&lt;/span&gt;</span>
<span class="nv">$ </span>brctl show
<span class="c"># =&gt; bridge name     bridge id               STP enabled     interfaces</span>
<span class="c">#    cni0            8000.b2e2a2aa4e5c       no              veth0911be7c</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 veth 인터페이스를 통해 파드와 연결된 cni0 브릿지가 생성되었습니다.&lt;/span&gt;</span>
<span class="nv">$ </span>iptables-save
<span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span>
<span class="nv">$ </span>iptables-save <span class="o">&gt;</span> iptables-after-deployment.txt
<span class="nv">$ </span>diff iptables-after-flannel.txt iptables-after-deployment.txt
<span class="c"># =&gt; ...</span>
<span class="c">#    62a63,64</span>
<span class="c">#    &gt; :KUBE-SEP-PQBQBGZJJ5FKN3TB - [0:0]</span>
<span class="c">#    &gt; :KUBE-SEP-R5LRHDMUTGTM635J - [0:0]</span>
<span class="c">#    66a69</span>
<span class="c">#    &gt; :KUBE-SVC-CNZCPOCNCNOROALA - [0:0]</span>
<span class="c">#    92a96,99</span>
<span class="c">#    &gt; -A KUBE-SEP-PQBQBGZJJ5FKN3TB -s 10.244.1.2/32 -m comment --comment "default/webpod" -j KUBE-MARK-MASQ</span>
<span class="c">#    &gt; -A KUBE-SEP-PQBQBGZJJ5FKN3TB -p tcp -m comment --comment "default/webpod" -m tcp -j DNAT --to-destination 10.244.1.2:80</span>
<span class="c">#    &gt; -A KUBE-SEP-R5LRHDMUTGTM635J -s 10.244.2.4/32 -m comment --comment "default/webpod" -j KUBE-MARK-MASQ</span>
<span class="c">#    &gt; -A KUBE-SEP-R5LRHDMUTGTM635J -p tcp -m comment --comment "default/webpod" -m tcp -j DNAT --to-destination 10.244.2.4:80</span>
<span class="c">#    98a106</span>
<span class="c">#    &gt; -A KUBE-SERVICES -d 10.96.62.184/32 -p tcp -m comment --comment "default/webpod cluster IP" -m tcp --dport 80 -j KUBE-SVC-CNZCPOCNCNOROALA</span>
<span class="c">#    103a112,114</span>
<span class="c">#    &gt; -A KUBE-SVC-CNZCPOCNCNOROALA ! -s 10.244.0.0/16 -d 10.96.62.184/32 -p tcp -m comment --comment "default/webpod cluster IP" -m tcp --dport 80 -j KUBE-MARK-MASQ</span>
<span class="c">#    &gt; -A KUBE-SVC-CNZCPOCNCNOROALA -m comment --comment "default/webpod -&gt; 10.244.1.2:80" -m statistic --mode random --probability 0.50000000000 -j KUBE-SEP-PQBQBGZJJ5FKN3TB</span>
<span class="c">#    &gt; -A KUBE-SVC-CNZCPOCNCNOROALA -m comment --comment "default/webpod -&gt; 10.244.2.4:80" -j KUBE-SEP-R5LRHDMUTGTM635J</span>
<span class="c">#    ...</span>

<span class="c"># k8s-w1, k8s-w2 정보 확인</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> <span class="nb">link</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    ...</span>
<span class="c">#    5: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 56:8b:b8:09:e1:a0 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    6: veth52205e86@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether ba:b1:d5:a8:5e:c6 brd ff:ff:ff:ff:ff:ff link-netns cni-42b4483c-e253-de82-a5c3-2cbf657cc6ed</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w2 &lt;&lt;</span>
<span class="c">#    ...</span>
<span class="c">#    5: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether b6:aa:16:04:b0:58 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    6: veth605dad7b@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 36:5a:70:ff:de:e9 brd ff:ff:ff:ff:ff:ff link-netns cni-e020c420-373a-900d-bf44-34fbe4622f7e</span>
<span class="c">#    7: veth002efe84@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether be:86:35:e2:1a:5d brd ff:ff:ff:ff:ff:ff link-netns cni-af271963-86ee-26b6-35b9-39173672cd1a</span>
<span class="c">#    8: veth1dce6530@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether fa:d9:af:04:69:e2 brd ff:ff:ff:ff:ff:ff link-netns cni-ca1eedc6-43ff-e346-318d-ba345e0ba532</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> route <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> brctl show <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
</code></pre></div></div>

<ul>
  <li>통신 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>webpod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                      READY   STATUS    RESTARTS   AGE   IP           NODE     NOMINATED NODE   READINESS GATES</span>
<span class="c">#    webpod-697b545f57-7j5vt   1/1     Running   0          24m   10.244.1.2   k8s-w1   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-697b545f57-sdv4l   1/1     Running   0          24m   10.244.2.4   k8s-w2   &lt;none&gt;           &lt;none&gt;</span>
<span class="nv">$ POD1IP</span><span class="o">=</span>10.244.1.2
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nv">$POD1IP</span>
<span class="c"># =&gt; Hostname: webpod-697b545f57-7j5vt</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: ::1</span>
<span class="c">#    IP: 10.244.1.2</span>
<span class="c">#    IP: fe80::dc28:1fff:fe46:abd0</span>
<span class="c">#    RemoteAddr: 10.244.0.2:46774</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: 10.244.1.2</span>
<span class="c">#    User-Agent: curl/8.14.1</span>
<span class="c">#    Accept: */*</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get svc,ep webpod
<span class="c"># =&gt; NAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE</span>
<span class="c">#    service/webpod   ClusterIP   10.96.62.184   &lt;none&gt;        80/TCP    25m</span>
<span class="c">#    </span>
<span class="c">#    NAME               ENDPOINTS                     AGE</span>
<span class="c">#    endpoints/webpod   10.244.1.2:80,10.244.2.4:80   25m</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl webpod
<span class="c"># =&gt; Hostname: webpod-697b545f57-7j5vt</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: ::1</span>
<span class="c">#    IP: 10.244.1.2</span>
<span class="c">#    IP: fe80::dc28:1fff:fe46:abd0</span>
<span class="c">#    RemoteAddr: 10.244.0.2:55684</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: webpod</span>
<span class="c">#    User-Agent: curl/8.14.1</span>
<span class="c">#    Accept: */*</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl webpod | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod-697b545f57-7j5vt</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s webpod | grep Hostname; sleep 1; done'</span>
<span class="c"># =&gt; Hostname: webpod-697b545f57-7j5vt</span>
<span class="c">#    Hostname: webpod-697b545f57-sdv4l</span>
<span class="c">#    Hostname: webpod-697b545f57-7j5vt</span>
<span class="c">#    ...</span>

<span class="c"># Service 동작 처리에 iptables 규칙 활용 확인 &gt;&gt; Service 가 100개 , 1000개 , 10000개 증가 되면???</span>
<span class="nv">$ </span>kubectl get svc webpod <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.spec.clusterIP}"</span>
<span class="c"># =&gt; 10.96.62.184</span>
<span class="nv">$ SVCIP</span><span class="o">=</span><span class="si">$(</span>kubectl get svc webpod <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.spec.clusterIP}"</span><span class="si">)</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span> | <span class="nb">grep</span> <span class="nv">$SVCIP</span>
<span class="c"># =&gt; -A KUBE-SERVICES -d 10.96.62.184/32 -p tcp -m comment --comment "default/webpod cluster IP" -m tcp --dport 80 -j KUBE-SVC-CNZCPOCNCNOROALA</span>
<span class="c">#    -A KUBE-SVC-CNZCPOCNCNOROALA ! -s 10.244.0.0/16 -d 10.96.62.184/32 -p tcp -m comment --comment "default/webpod cluster IP" -m tcp --dport 80 -j KUBE-MARK-MASQ</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span> | <span class="nb">grep</span> <span class="nv">$SVCIP</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    -A KUBE-SERVICES -d 10.96.62.184/32 -p tcp -m comment --comment "default/webpod cluster IP" -m tcp --dport 80 -j KUBE-SVC-CNZCPOCNCNOROALA</span>
<span class="c">#    -A KUBE-SVC-CNZCPOCNCNOROALA ! -s 10.244.0.0/16 -d 10.96.62.184/32 -p tcp -m comment --comment "default/webpod cluster IP" -m tcp --dport 80 -j KUBE-MARK-MASQ</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w2 &lt;&lt;</span>
<span class="c">#    -A KUBE-SERVICES -d 10.96.62.184/32 -p tcp -m comment --comment "default/webpod cluster IP" -m tcp --dport 80 -j KUBE-SVC-CNZCPOCNCNOROALA</span>
<span class="c">#    -A KUBE-SVC-CNZCPOCNCNOROALA ! -s 10.244.0.0/16 -d 10.96.62.184/32 -p tcp -m comment --comment "default/webpod cluster IP" -m tcp --dport 80 -j KUBE-MARK-MASQ</span>
</code></pre></div></div>

<ul>
  <li>대규모 환경에서 iptables 단점
    <ul>
      <li>kube-proxy에 의해 생성되는 iptables 규칙이 많아질수록 성능 저하가 발생할 수 있습니다.</li>
      <li>특히, 많은 수의 서비스가 있는 경우 iptables 규칙이 급격히 증가하여 성능에 영향을 미칠 수 있습니다.</li>
      <li>테스트 클러스터에서 3800개 노드의 19000개 파드를 배포한 결과, iptables 규칙이 24,000개 이상 생성되었습니다.</li>
      <li>이로 인한 성능 저하는 다음과 같습니다.
        <ul>
          <li>통신 연결시 1.2ms의 지연이 발생했습니다.</li>
          <li>클러스터의 iptables 규칙 갱신이 5분 이상 소요되었습니다.</li>
          <li>53%의 CPU 오버헤드가 발생했습니다.</li>
        </ul>
      </li>
      <li>이러한 문제로 인해 iptables를 사용하지 않고 eBPF을 사용하는 cilium 과 같은 CNI 플러그인이 대안으로 인기를 얻고 있습니다.</li>
    </ul>
  </li>
</ul>

<h2 id="cilium-cni">Cilium CNI</h2>

<h3 id="cilium-cni-소개">Cilium CNI 소개</h3>

<ul>
  <li><strong>Cilium</strong>은 기존의 복잡한 네트워크 스택을 <strong>eBPF</strong>를 통해 <strong>간소화</strong>하고, <strong>빠르게 처리</strong>할 수 있도록 하는 CNI 플러그인입니다.</li>
  <li>iptables 기반의 kube-proxy를 대체하여, 앞서 살펴본 기존의 Iptables 기반의 CNI 플러그인 들의 단점을 대부분 해결할 수 있습니다.</li>
</ul>

<p><img src="/assets/2024/kans-3th/w8/20241026_kans_w8_5.png" alt="img.png" class="image-center w-80" />
<em class="image-caption"><a href="https://isovalent.com/blog/post/migrating-from-metallb-to-cilium/">https://isovalent.com/blog/post/migrating-from-metallb-to-cilium/</a></em></p>

<ul>
  <li>Cilium eBPF는 추가적인 코드 수정이나 설정 변경없이, 리눅스 커널에서 동작하는 Bytecode를 자유롭게 프로그래밍하여 커널에 로딩시켜 동작이 가능합니다. <a href="https://www.youtube.com/watch?v=qsnR-s4XuGo&amp;t=1059s">링크</a>
<img src="/assets/2025/cilium/w1/20250720_cilium_w1_19.png" alt="img.png" /></li>
  <li>또한 eBPF는 모든 패킷을 가로채기 위해서 수신 NIC의 ingress TC(<a href="https://netbeez.net/blog/how-to-use-the-linux-traffic-control/">Traffic Control</a>) hooks를 사용할 수 있습니다.
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_6.png" alt="img.png" class="image-center w-60" />
<em class="image-caption">NIC의 TC Hooks에 eBPF 프로그램이 attach 된 예</em></li>
  <li>Cilium은 터널모드(VXLAN, GENEVE), 네이티브 라우팅 모드의 2가지 네트워크 모드를 제공합니다. <a href="https://docs.cilium.io/en/stable/network/concepts/routing/">Docs</a>
    <ul>
      <li><strong>터널모드</strong> : Cilium이 VXLAN(UDP 8472), GENEVE(UDP 6081) 인터페이스를 만들어서 이들을 통해 트래픽을 전달합니다. Encapsulation 모드라고도 합니다.</li>
      <li><strong>네이티브 라우팅 모드</strong> : Cilium가 패킷 전달을 위해 구성을 변경하지 않고, 외부에서 제공되는 패킷 전달 방법(클라우드 또는 BGP 라우팅등)을 사용합니다. Direct Routing 모드라고도 합니다.
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_7.png" alt="img.png" class="image-center w-80" />
<img src="/assets/2025/cilium/w1/20250720_cilium_w1_16.png" alt="img.png" /></li>
    </ul>
  </li>
  <li>2021년 10월 Cilium은 CNCF에 채택되었습니다. <a href="https://cilium.io/blog/2021/10/13/cilium-joins-cncf/">링크</a></li>
  <li>Googke GKE dataplane과 AWS EKS Anywhere에서 기본 CNI로 Cilium을 사용하고 있습니다. <a href="https://isovalent.com/blog/post/2021-09-aws-eks-anywhere-chooses-cilium/">링크</a></li>
  <li>Cilium은 Kube-Proxy를 100% 대체 가능합니다.
    <ul>
      <li>iptables를 거의 사용하지 않고도 동작하며, 이를 통해 성능을 향상시킬 수 있습니다.</li>
      <li>하지만 istio, FHRP, VRRP 등과 같이 iptables 기능을 활용하는 동작들은 이슈가 발생할 수 있으며, 차츰 해결해 나가고 있습니다.</li>
      <li>동작 소개 1 - <a href="https://www.youtube.com/watch?v=yKPNmhckJHY">Youtube</a></li>
      <li>동작 소개 2 : ByteDance 사례 - <a href="https://www.youtube.com/watch?v=cKPW67D7X10">Youtube</a>, <a href="https://kccncchn2025.sched.com/event/1x5hK/simplifying-the-networking-and-security-stack-with-cilium-hubble-and-tetragon-liyi-huang-isovalent-at-cisco-kaixi-fan-bytedance">CNCF</a></li>
    </ul>
  </li>
  <li>구성요소 - <a href="https://ssup2.github.io/blog-software/docs/theory-analysis/kubernetes-cilium-plugin/">링크</a>
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_8.png" alt="img.png" class="image-center w-80" />
<em class="image-caption">Cilium 아키텍쳐 - <a href="https://github.com/cilium/cilium">출처</a></em>
    <ul>
      <li>Cilium <strong>Operator</strong> : K8S 클러스터에 대한 한 번씩 처리해야 하는 작업을 관리합니다.</li>
      <li>Cilium <strong>Agent</strong> : 데몬셋으로 실행, K8S API 설정으로 부터 ‘네트워크 설정, 네트워크 정책, 서비스 부하분산, 모니터링’ 등을 수행하며, eBPF 프로그램을 관리합니다.</li>
      <li>Cilium <strong>Client</strong> (CLI) : Cilium 커멘드툴로 eBPF maps 에 직접 접속하여 상태를 확인할 수 있습니다.</li>
      <li><strong>Hubble</strong> : 네트워크와 보안 모니터링 플랫폼 역할을 하여, Server, Relay, Client, Graphical UI 로 구성되어 있습니다.</li>
      <li><strong>Data Store</strong> : Cilium Agent 간의 상태를 저장하고 전파하는 데이터 저장소, 2가지 종류 중 선택(K8S CRDs, Key-Value Store)할 수 있습니다.
<img src="/assets/2025/cilium/w1/20250720_cilium_w1_17.png" alt="img.png" />
<img src="/assets/2025/cilium/w1/20250720_cilium_w1_18.png" alt="img_1.png" /></li>
    </ul>
  </li>
</ul>

<h3 id="cilium-cni-설치">Cilium CNI 설치</h3>

<h4 id="cilium-시스템-요구-사항-확인---공식-문서">Cilium 시스템 요구 사항 확인 - <a href="https://docs.cilium.io/en/stable/operations/system_requirements/">공식 문서</a></h4>

<ul>
  <li>AMD64 또는 AArch64 CPU 아키텍처를 사용하는 호스트</li>
  <li><a href="https://docs.cilium.io/en/stable/operations/system_requirements/#linux-kernel">Linux 커널</a> 5.4 이상 또는 동등 버전(예: RHEL 8.6의 경우 4.18)
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">arch</span>
<span class="c"># =&gt; aarch64</span>
      
<span class="nv">$ </span><span class="nb">uname</span> <span class="nt">-r</span>
<span class="c"># =&gt; 6.8.0-53-generic</span>
</code></pre></div>    </div>
  </li>
  <li>커널 구성 옵션 활성화
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># [커널 구성 옵션] 기본 요구 사항 </span>
<span class="nv">$ </span><span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'CONFIG_BPF|CONFIG_BPF_SYSCALL|CONFIG_NET_CLS_BPF|CONFIG_BPF_JIT|CONFIG_NET_CLS_ACT|CONFIG_NET_SCH_INGRESS|CONFIG_CRYPTO_SHA1|CONFIG_CRYPTO_USER_API_HASH|CONFIG_CGROUPS|CONFIG_CGROUP_BPF|CONFIG_PERF_EVENTS|CONFIG_SCHEDSTATS'</span> /boot/config-<span class="si">$(</span><span class="nb">uname</span> <span class="nt">-r</span><span class="si">)</span>
<span class="c"># =&gt; CONFIG_BPF=y</span>
<span class="c">#    CONFIG_BPF_SYSCALL=y</span>
<span class="c">#    CONFIG_BPF_JIT=y</span>
<span class="c">#    CONFIG_BPF_JIT_ALWAYS_ON=y</span>
<span class="c">#    CONFIG_BPF_JIT_DEFAULT_ON=y</span>
<span class="c">#    CONFIG_BPF_UNPRIV_DEFAULT_OFF=y</span>
<span class="c">#    # CONFIG_BPF_PRELOAD is not set</span>
<span class="c">#    CONFIG_BPF_LSM=y</span>
<span class="c">#    CONFIG_CGROUPS=y</span>
<span class="c">#    CONFIG_CGROUP_BPF=y</span>
<span class="c">#    CONFIG_PERF_EVENTS=y</span>
<span class="c">#    CONFIG_NET_SCH_INGRESS=m</span>
<span class="c">#    CONFIG_NET_CLS_BPF=m</span>
<span class="c">#    CONFIG_NET_CLS_ACT=y</span>
<span class="c">#    CONFIG_BPF_STREAM_PARSER=y</span>
<span class="c">#    CONFIG_CRYPTO_SHA1=y</span>
<span class="c">#    CONFIG_CRYPTO_USER_API_HASH=m</span>
<span class="c">#    CONFIG_CRYPTO_SHA1_ARM64_CE=m</span>
<span class="c">#    CONFIG_SCHEDSTATS=y</span>
<span class="c">#    CONFIG_BPF_EVENTS=y</span>
<span class="c">#    CONFIG_BPF_KPROBE_OVERRIDE=y</span>
    
<span class="c"># [커널 구성 옵션] Requirements for Tunneling and Routing</span>
<span class="nv">$ </span><span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'CONFIG_VXLAN=y|CONFIG_VXLAN=m|CONFIG_GENEVE=y|CONFIG_GENEVE=m|CONFIG_FIB_RULES=y'</span> /boot/config-<span class="si">$(</span><span class="nb">uname</span> <span class="nt">-r</span><span class="si">)</span>
<span class="nv">$ CONFIG_FIB_RULES</span><span class="o">=</span>y <span class="c"># 커널에 내장됨</span>
<span class="nv">$ CONFIG_VXLAN</span><span class="o">=</span>m <span class="c"># 모듈로 컴파일됨 → 커널에 로드해서 사용</span>
<span class="nv">$ CONFIG_GENEVE</span><span class="o">=</span>m <span class="c"># 모듈로 컴파일됨 → 커널에 로드해서 사용</span>
    
<span class="c">## (참고) 커널 로드</span>
<span class="nv">$ </span>lsmod | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'vxlan|geneve'</span>
<span class="c"># =&gt; vxlan                 147456  0</span>
<span class="c">#    ip6_udp_tunnel         16384  1 vxlan</span>
<span class="c">#    udp_tunnel             36864  1 vxlan</span>
<span class="nv">$ </span>modprobe geneve
<span class="nv">$ </span>lsmod | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'vxlan|geneve'</span>
<span class="c"># =&gt; geneve                 45056  0</span>
<span class="c">#    vxlan                 147456  0</span>
<span class="c">#    ip6_udp_tunnel         16384  2 geneve,vxlan</span>
<span class="c">#    udp_tunnel             36864  2 geneve,vxlan</span>
    
<span class="c"># [커널 구성 옵션] Requirements for L7 and FQDN Policies</span>
<span class="nv">$ </span><span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'CONFIG_NETFILTER_XT_TARGET_TPROXY|CONFIG_NETFILTER_XT_TARGET_MARK|CONFIG_NETFILTER_XT_TARGET_CT|CONFIG_NETFILTER_XT_MATCH_MARK|CONFIG_NETFILTER_XT_MATCH_SOCKET'</span> /boot/config-<span class="si">$(</span><span class="nb">uname</span> <span class="nt">-r</span><span class="si">)</span>
<span class="c"># =&gt; CONFIG_NETFILTER_XT_TARGET_CT=m</span>
<span class="c">#    CONFIG_NETFILTER_XT_TARGET_MARK=m</span>
<span class="c">#    CONFIG_NETFILTER_XT_TARGET_TPROXY=m</span>
<span class="c">#    CONFIG_NETFILTER_XT_MATCH_MARK=m</span>
<span class="c">#    CONFIG_NETFILTER_XT_MATCH_SOCKET=m</span>
    
<span class="c"># [커널 구성 옵션] Requirements for Netkit Device Mode</span>
<span class="nv">$ </span><span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'CONFIG_NETKIT=y|CONFIG_NETKIT=m'</span> /boot/config-<span class="si">$(</span><span class="nb">uname</span> <span class="nt">-r</span><span class="si">)</span>
<span class="c"># =&gt; CONFIG_NETKIT=y</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>고급 기능 동작을 위한 최소 커널 버전 - <a href="https://docs.cilium.io/en/stable/operations/system_requirements/#required-kernel-versions-for-advanced-features">Docs</a></p>

    <table>
      <thead>
        <tr>
          <th><strong>Cilium Feature</strong></th>
          <th><strong>Minimum Kernel Version</strong></th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><a href="https://docs.cilium.io/en/stable/security/network/encryption-wireguard/#encryption-wg">WireGuard Transparent Encryption</a></td>
          <td>&gt;= 5.6</td>
        </tr>
        <tr>
          <td>Full support for <a href="https://docs.cilium.io/en/stable/network/kubernetes/kubeproxy-free/#session-affinity">Session Affinity</a></td>
          <td>&gt;= 5.7</td>
        </tr>
        <tr>
          <td>BPF-based proxy redirection</td>
          <td>&gt;= 5.7</td>
        </tr>
        <tr>
          <td>Socket-level LB bypass in pod netns</td>
          <td>&gt;= 5.7</td>
        </tr>
        <tr>
          <td>L3 devices</td>
          <td>&gt;= 5.8</td>
        </tr>
        <tr>
          <td><strong>BPF-based host routing</strong></td>
          <td><strong>&gt;= 5.10</strong></td>
        </tr>
        <tr>
          <td><a href="https://docs.cilium.io/en/stable/network/multicast/#enable-multicast">Multicast Support in Cilium (Beta)</a> (AMD64)</td>
          <td>&gt;= 5.10</td>
        </tr>
        <tr>
          <td>IPv6 BIG TCP support</td>
          <td>&gt;= 5.19</td>
        </tr>
        <tr>
          <td><a href="https://docs.cilium.io/en/stable/network/multicast/#enable-multicast">Multicast Support in Cilium (Beta)</a> (AArch64)</td>
          <td>&gt;= 6.0</td>
        </tr>
        <tr>
          <td><strong>IPv4 BIG TCP support</strong></td>
          <td><strong>&gt;= 6.3</strong></td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>Cilium 동작(Node 간)을 위한 방화벽 규칙 : 해당 포트 인/아웃 허용 필요 - <a href="https://docs.cilium.io/en/stable/operations/system_requirements/#firewall-rules">Docs</a></li>
  <li><strong>Mounted eBPF filesystem</strong> : 일부 배포판 마운트되어 있음, 혹은 Cilium 설치 시 마운트 시도 - <a href="https://docs.cilium.io/en/stable/operations/system_requirements/#mounted-ebpf-filesystem">Docs</a>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># eBPF 파일 시스템 마운트 확인</span>
<span class="nv">$ </span>mount | <span class="nb">grep</span> /sys/fs/bpf
<span class="c"># =&gt; bpf on /sys/fs/bpf type bpf (rw,nosuid,nodev,noexec,relatime,mode=700)</span>
</code></pre></div>    </div>
  </li>
  <li><strong>Privileges</strong> : Cilium 동작을 위해서 관리자 수준 권한 필요 - <a href="https://docs.cilium.io/en/stable/operations/system_requirements/#privileges">Docs</a>
    <ul>
      <li>cilium은 네트워킹 작업과 보안 정책을 구현하는 eBPF 프로그램 설치를 위해 리눅스 커널과 상호작용합니다. 
이 작업은 관리자 권한이 필요하며, cilium은 이를 위해 <code class="language-plaintext highlighter-rouge">CAP_SYS_ADMIN</code> 권한을 사용합니다. 또한 해당 권한은 cilium-agent 컨테이너에 부여되어야 합니다.</li>
      <li>가장 편리한 방법은 cilium-agent를 <code class="language-plaintext highlighter-rouge">root</code> 사용자나 privileged 모드로 실행하는 것입니다.</li>
      <li>cilium은 또한 호스트 네트워킹 네임스페이스에 대한 접근을 필요로 합니다. 따라서 cilium 파드는 호스트 네트워킹 네임스페이스에 직접 사용할 수 있도록 설정되어야 합니다.</li>
    </ul>
  </li>
</ul>

<h4 id="kube-proxy-제거">kube-proxy 제거</h4>

<ul>
  <li>기존 Flannel CNI를 제거합니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>helm uninstall <span class="nt">-n</span> kube-flannel flannel
<span class="c"># =&gt; release "flannel" uninstalled</span>
<span class="nv">$ </span>helm list <span class="nt">-A</span>
<span class="c"># =&gt; NAME    NAMESPACE       REVISION        UPDATED STATUS  CHART   APP VERSION</span>
  
<span class="c">#</span>
<span class="nv">$ </span>kubectl get all <span class="nt">-n</span> kube-flannel
<span class="nv">$ </span><span class="o">=&gt;</span> No resources found <span class="k">in </span>kube-flannel namespace.
<span class="nv">$ </span>kubectl delete ns kube-flannel
<span class="c"># =&gt; namespace "kube-flannel" deleted</span>
  
<span class="nv">$ </span>kubectl get pod <span class="nt">-A</span> <span class="nt">-owide</span>
</code></pre></div>    </div>
  </li>
  <li>k8s-ctr, k8s-w1, k8s-w2 모든 노드에서 아래 실행하여 flannel 관련된 인터페이스를 제거합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 제거 전 확인</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> <span class="nb">link</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    4: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default</span>
<span class="c">#        link/ether aa:3f:e5:cd:ae:92 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    5: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 1e:a9:44:a0:00:e1 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    6: veth322e34b5@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 8e:ea:40:c5:46:a7 brd ff:ff:ff:ff:ff:ff link-netns cni-62beabc5-97a9-e6cf-7f8f-bd4de413d33c</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> <span class="nb">link</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    ...</span>
<span class="c">#    4: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default</span>
<span class="c">#        link/ether c2:b2:62:af:c2:93 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    5: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 06:8a:4c:62:12:de brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    6: vethd8fb7cb1@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether e2:3f:03:c3:be:a2 brd ff:ff:ff:ff:ff:ff link-netns cni-81f15ae4-4a35-bce7-f755-657f3b8e39ea</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w2 &lt;&lt;</span>
<span class="c">#    ...</span>
<span class="c">#    4: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default</span>
<span class="c">#        link/ether 02:dd:56:d3:f6:3f brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    5: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 06:57:05:39:42:57 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    6: veth390f8e9e@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 5a:23:ff:ba:28:90 brd ff:ff:ff:ff:ff:ff link-netns cni-a27cec88-43c0-acf5-0bc5-f64e945bded3</span>
<span class="c">#    7: veth357a49b9@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether b6:6c:69:43:29:a6 brd ff:ff:ff:ff:ff:ff link-netns cni-36af9b39-bcb8-ad52-beb5-4b67475b404f</span>
<span class="c">#    8: vethf9bb5584@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 4a:7c:ab:42:e7:ca brd ff:ff:ff:ff:ff:ff link-netns cni-29e132ee-4860-b74c-c4f5-d5d27b341b83</span>

<span class="nv">$ </span>brctl show
<span class="c"># =&gt; bridge name     bridge id               STP enabled     interfaces</span>
<span class="c">#    cni0            8000.1ea944a000e1       no              veth322e34b5</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> brctl show <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    bridge name     bridge id               STP enabled     interfaces</span>
<span class="c">#    cni0            8000.068a4c6212de       no              vethd8fb7cb1</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w2 &lt;&lt;</span>
<span class="c">#    bridge name     bridge id               STP enabled     interfaces</span>
<span class="c">#    cni0            8000.065705394257       no              veth357a49b9</span>
<span class="c">#                                                            veth390f8e9e</span>
<span class="c">#                                                            vethf9bb5584</span>

<span class="nv">$ </span>ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.244.0.0/24 dev cni0 proto kernel scope link src 10.244.0.1</span>
<span class="c">#    10.244.1.0/24 via 10.244.1.0 dev flannel.1 onlink</span>
<span class="c">#    10.244.2.0/24 via 10.244.2.0 dev flannel.1 onlink</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.100</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> route <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.244.0.0/24 via 10.244.0.0 dev flannel.1 onlink</span>
<span class="c">#    10.244.1.0/24 dev cni0 proto kernel scope link src 10.244.1.1</span>
<span class="c">#    10.244.2.0/24 via 10.244.2.0 dev flannel.1 onlink</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.101</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w2 &lt;&lt;</span>
<span class="c">#    default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.244.0.0/24 via 10.244.0.0 dev flannel.1 onlink</span>
<span class="c">#    10.244.1.0/24 via 10.244.1.0 dev flannel.1 onlink</span>
<span class="c">#    10.244.2.0/24 dev cni0 proto kernel scope link src 10.244.2.1</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.102</span>

<span class="c"># vnic 제거</span>
<span class="nv">$ </span>ip <span class="nb">link </span>del flannel.1
<span class="nv">$ </span>ip <span class="nb">link </span>del cni0

<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>ip <span class="nb">link </span>del flannel.1 <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>ip <span class="nb">link </span>del cni0 <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>

<span class="c"># 제거 확인</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> <span class="nb">link</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    6: veth322e34b5@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 8e:ea:40:c5:46:a7 brd ff:ff:ff:ff:ff:ff link-netns cni-62beabc5-97a9-e6cf-7f8f-bd4de413d33c</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 flannel.1과 cni0가 삭제되었습니다.&lt;/span&gt;</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> <span class="nb">link</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>

<span class="nv">$ </span>brctl show
<span class="c"># =&gt; &lt;span style="color: green;"&gt;없음&lt;/span&gt;</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> brctl show <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    &gt;&gt; node : k8s-w2 &lt;&lt;</span>

<span class="nv">$ </span>ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.100</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> route <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.101</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w2 &lt;&lt;</span>
<span class="c">#    default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.102</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 flannel.1과 cni0가 삭제되어, 관련 라우팅 정보가 삭제되었습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<ul>
  <li>기존 kube-proxy를 제거합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system delete ds kube-proxy
<span class="c"># =&gt; daemonset.apps "kube-proxy" deleted</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system delete cm kube-proxy
<span class="c"># =&gt; configmap "kube-proxy" deleted</span>

<span class="c"># 배포된 파드의 IP는 남겨져 있습니다.</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-A</span> <span class="nt">-owide</span>
<span class="c"># =&gt; NAMESPACE     NAME                              READY   STATUS             RESTARTS         AGE     IP               NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    default       curl-pod                          1/1     Running            1 (143m ago)     3h1m    10.244.0.3       k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    default       webpod-697b545f57-7j5vt           1/1     Running            1 (142m ago)     3h2m    10.244.1.3       k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    default       webpod-697b545f57-sdv4l           1/1     Running            1 (142m ago)     3h2m    10.244.2.7       k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-79mbb          0/1     CrashLoopBackOff   27 (4m ago)      2d17h   10.244.2.5       k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-rtx95          0/1     CrashLoopBackOff   27 (4m26s ago)   2d17h   10.244.2.6       k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   etcd-k8s-ctr                      1/1     Running            4 (143m ago)     2d17h   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-apiserver-k8s-ctr            1/1     Running            4 (143m ago)     2d17h   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-controller-manager-k8s-ctr   1/1     Running            4 (143m ago)     2d17h   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-scheduler-k8s-ctr            1/1     Running            4 (143m ago)     2d17h   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl webpod
<span class="c"># =&gt; curl: (6) Could not resolve host: webpod</span>
<span class="c">#    command terminated with exit code 6</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 kube-proxy와 CNI의 삭제로 coredns가 동작하지 않아서 webpod 서비스에 접근할 수 없습니다.&lt;/span&gt;</span>

<span class="c">#</span>
<span class="nv">$ </span>iptables-save

<span class="c"># Run on each node with root permissions:</span>
<span class="nv">$ </span>iptables-save | <span class="nb">grep</span> <span class="nt">-v</span> KUBE | <span class="nb">grep</span> <span class="nt">-v</span> FLANNEL | iptables-restore
<span class="nv">$ </span>iptables-save

<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w1 <span class="s2">"sudo iptables-save | grep -v KUBE | grep -v FLANNEL | sudo iptables-restore"</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w1 <span class="nb">sudo </span>iptables-save

<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w2 <span class="s2">"sudo iptables-save | grep -v KUBE | grep -v FLANNEL | sudo iptables-restore"</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w2 <span class="nb">sudo </span>iptables-save

<span class="c">#</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                      READY   STATUS    RESTARTS       AGE     IP           NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    curl-pod                  1/1     Running   1 (155m ago)   3h14m   10.244.0.3   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-697b545f57-7j5vt   1/1     Running   1 (155m ago)   3h14m   10.244.1.3   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-697b545f57-sdv4l   1/1     Running   1 (155m ago)   3h14m   10.244.2.7   k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
</code></pre></div></div>

<ul>
  <li>노드별 파드에 할당되는 IPAM(PodCIDR) 정보를 확인해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#--allocate-node-cidrs=true 로 설정된 kube-controller-manager에서 CIDR을 자동 할당함</span>
<span class="nv">$ </span>kubectl get nodes <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{range .items[*]}{.metadata.name}{"\t"}{.spec.podCIDR}{"\n"}{end}'</span>
<span class="c"># =&gt; k8s-ctr 10.244.0.0/24</span>
<span class="c">#    k8s-w1  10.244.1.0/24</span>
<span class="c">#    k8s-w2  10.244.2.0/24</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                      READY   STATUS    RESTARTS       AGE     IP           NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    curl-pod                  1/1     Running   1 (157m ago)   3h15m   10.244.0.3   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-697b545f57-7j5vt   1/1     Running   1 (156m ago)   3h16m   10.244.1.3   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-697b545f57-sdv4l   1/1     Running   1 (156m ago)   3h16m   10.244.2.7   k8s-w2    &lt;none&gt;           &lt;none&gt;</span>

<span class="c">#</span>
<span class="nv">$ </span>kc describe pod <span class="nt">-n</span> kube-system kube-controller-manager-k8s-ctr
<span class="c"># =&gt; ...</span>
<span class="c">#       Command:</span>
<span class="c">#          kube-controller-manager</span>
<span class="c">#          --allocate-node-cidrs=true</span>
<span class="c">#          --cluster-cidr=10.244.0.0/16</span>
<span class="c">#          --service-cluster-ip-range=10.96.0.0/16</span>
<span class="c">#    ... </span>
</code></pre></div></div>

<h4 id="cilium-cni-설치-with-helm">Cilium CNI 설치 with Helm</h4>

<ul>
  <li>관련 문서 : <a href="https://docs.cilium.io/en/stable/helm-reference/">Helm</a>, <a href="https://docs.cilium.io/en/stable/network/concepts/masquerading/">Masquering</a>, <a href="https://docs.cilium.io/en/stable/network/concepts/ipam/cluster-pool/">ClusterScope</a>, <a href="https://docs.cilium.io/en/stable/network/concepts/routing/">Routing</a></li>
  <li>Cilium 1.17.5 Helm Chart - <a href="https://artifacthub.io/packages/helm/cilium/cilium/1.17.5">ArtifactHub</a>를 사용하여 설치합니다.
<img src="/assets/2025/cilium/w1/20250720_cilium_w1_3.png" alt="img.png" /></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Cilium 설치 with Helm</span>
<span class="nv">$ </span>helm repo add cilium https://helm.cilium.io/
<span class="c"># =&gt; "cilium" has been added to your repositories</span>

<span class="c"># 모든 NIC 지정 + bpf.masq=true + NoIptablesRules</span>
<span class="nv">$ </span>helm <span class="nb">install </span>cilium cilium/cilium <span class="nt">--version</span> 1.17.5 <span class="nt">--namespace</span> kube-system <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">k8sServiceHost</span><span class="o">=</span>192.168.10.100 <span class="nt">--set</span> <span class="nv">k8sServicePort</span><span class="o">=</span>6443 <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">kubeProxyReplacement</span><span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">routingMode</span><span class="o">=</span>native <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">autoDirectNodeRoutes</span><span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> ipam.mode<span class="o">=</span><span class="s2">"cluster-pool"</span> <span class="se">\</span>
  <span class="nt">--set</span> ipam.operator.clusterPoolIPv4PodCIDRList<span class="o">={</span><span class="s2">"172.20.0.0/16"</span><span class="o">}</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">ipv4NativeRoutingCIDR</span><span class="o">=</span>172.20.0.0/16 <span class="se">\</span>
  <span class="nt">--set</span> endpointRoutes.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">installNoConntrackIptablesRules</span><span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> bpf.masquerade<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> ipv6.enabled<span class="o">=</span><span class="nb">false</span>
<span class="c"># =&gt; NAME: cilium</span>
<span class="c">#    LAST DEPLOYED: Sat Jul 19 17:34:05 2025</span>
<span class="c">#    NAMESPACE: kube-system</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 1</span>
<span class="c">#    TEST SUITE: None</span>
<span class="c">#    NOTES:</span>
<span class="c">#    You have successfully installed Cilium with Hubble.</span>
<span class="c">#    </span>
<span class="c">#    Your release version is 1.17.5.</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>helm get values cilium <span class="nt">-n</span> kube-system
<span class="c"># =&gt; USER-SUPPLIED VALUES:</span>
<span class="c">#    autoDirectNodeRoutes: true</span>
<span class="c">#    bpf:</span>
<span class="c">#      masquerade: true</span>
<span class="c">#    endpointRoutes:</span>
<span class="c">#      enabled: true</span>
<span class="c">#    installNoConntrackIptablesRules: true</span>
<span class="c">#    ipam:</span>
<span class="c">#      mode: cluster-pool</span>
<span class="c">#      operator:</span>
<span class="c">#        clusterPoolIPv4PodCIDRList:</span>
<span class="c">#        - 172.20.0.0/16</span>
<span class="c">#    ipv4NativeRoutingCIDR: 172.20.0.0/16</span>
<span class="c">#    ipv6:</span>
<span class="c">#      enabled: false</span>
<span class="c">#    k8sServiceHost: 192.168.10.100</span>
<span class="c">#    k8sServicePort: 6443</span>
<span class="c">#    kubeProxyReplacement: true</span>
<span class="c">#    routingMode: native</span>
<span class="nv">$ </span>helm list <span class="nt">-A</span>
<span class="c"># =&gt; NAME    NAMESPACE       REVISION        UPDATED                                 STATUS          CHART           APP VERSION</span>
<span class="c">#    cilium  kube-system     1               2025-07-19 17:34:05.700270399 +0900 KST deployed        cilium-1.17.5   1.17.5</span>
<span class="nv">$ </span>kubectl get crd
<span class="c"># =&gt; No resources found</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> kubectl get pod <span class="nt">-A</span>
<span class="c"># =&gt; Every 2.0s: kubectl get pod -A                                                                                                                 k8s-ctr: Sat Jul 19 17:36:42 2025</span>
<span class="c">#    </span>
<span class="c">#    NAMESPACE     NAME                               READY   STATUS    RESTARTS       AGE</span>
<span class="c">#    default       curl-pod                           1/1     Running   1 (166m ago)   3h24m</span>
<span class="c">#    default       webpod-697b545f57-7j5vt            1/1     Running   1 (165m ago)   3h25m</span>
<span class="c">#    default       webpod-697b545f57-sdv4l            1/1     Running   1 (165m ago)   3h25m</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-envoy-b2mn9&lt;/span&gt;                 1/1     Running   0              2m36s</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-envoy-dgdmn&lt;/span&gt;                 1/1     Running   0              2m36s</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-envoy-pjn95&lt;/span&gt;                 1/1     Running   0              2m36s</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-fl689&lt;/span&gt;                       1/1     Running   0              2m36s</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-mqnkn&lt;/span&gt;                       1/1     Running   0              2m36s</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-operator-865bc7f457-hpwvh&lt;/span&gt;   1/1     Running   0              2m36s</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-operator-865bc7f457-v5k84&lt;/span&gt;   1/1     Running   0              2m36s</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-zz9k4&lt;/span&gt;                       1/1     Running   0              2m36s</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-7q52c           1/1     &lt;span style="color: green;"&gt;Running&lt;/span&gt;   0              52s</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-bvsfb           1/1     &lt;span style="color: green;"&gt;Running&lt;/span&gt;   0              66s</span>
<span class="c">#    kube-system   etcd-k8s-ctr                       1/1     Running   4 (166m ago)   2d18h</span>
<span class="c">#    kube-system   kube-apiserver-k8s-ctr             1/1     Running   4 (166m ago)   2d18h</span>
<span class="c">#    kube-system   kube-controller-manager-k8s-ctr    1/1     Running   4 (166m ago)   2d18h</span>
<span class="c">#    kube-system   kube-scheduler-k8s-ctr             1/1     Running   4 (166m ago)   2d18h</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 cilium 관련된 파드가 배포되었고 coredns 파드도 정상적으로 동작합니다.&lt;/span&gt;</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium-dbg status <span class="nt">--verbose</span>
<span class="c"># =&gt; KubeProxyReplacement:   True   [eth0    10.0.2.15 fd17:625c:f037:2:a00:27ff:fe71:19d8 fe80::a00:27ff:fe71:19d8, eth1   192.168.10.102 fe80::a00:27ff:fe79:58ac (Direct Routing)]</span>
<span class="c">#    ...</span>
<span class="c">#    Routing:                Network: Native   Host: BPF</span>
<span class="c">#    ...</span>
<span class="c">#    Masquerading:           BPF   [eth0, eth1]   172.20.0.0/16 [IPv4: Enabled, IPv6: Disabled]</span>
<span class="c">#    ...</span>

<span class="c"># 노드에 iptables 확인</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span>
<span class="c"># =&gt; -P PREROUTING ACCEPT</span>
<span class="c">#    -P INPUT ACCEPT</span>
<span class="c">#    -P OUTPUT ACCEPT</span>
<span class="c">#    -P POSTROUTING ACCEPT</span>
<span class="c">#    -N CILIUM_OUTPUT_nat</span>
<span class="c">#    -N CILIUM_POST_nat</span>
<span class="c">#    -N CILIUM_PRE_nat</span>
<span class="c">#    -N KUBE-KUBELET-CANARY</span>
<span class="c">#    -A PREROUTING -m comment --comment "cilium-feeder: CILIUM_PRE_nat" -j CILIUM_PRE_nat</span>
<span class="c">#    -A OUTPUT -m comment --comment "cilium-feeder: CILIUM_OUTPUT_nat" -j CILIUM_OUTPUT_nat</span>
<span class="c">#    -A POSTROUTING -m comment --comment "cilium-feeder: CILIUM_POST_nat" -j CILIUM_POST_nat</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>

<span class="nv">$ </span>iptables-save
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>iptables-save <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span> 
</code></pre></div></div>

<ul>
  <li>PodCIDR IPAM 확인해보겠습니다. - <a href="https://docs.cilium.io/en/stable/network/concepts/ipam/cluster-pool/">ClusterScope</a></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>kubectl get nodes <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{range .items[*]}{.metadata.name}{"\t"}{.spec.podCIDR}{"\n"}{end}'</span>
<span class="c"># =&gt; k8s-ctr 10.244.0.0/24</span>
<span class="c">#    k8s-w1  10.244.1.0/24</span>
<span class="c">#    k8s-w2  10.244.2.0/24</span>

<span class="c"># 파드 IP 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                      READY   STATUS    RESTARTS       AGE     IP           NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    curl-pod                  1/1     Running   1 (172m ago)   3h30m   10.244.0.3   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-697b545f57-7j5vt   1/1     Running   1 (171m ago)   3h30m   10.244.1.3   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-697b545f57-sdv4l   1/1     Running   1 (171m ago)   3h30m   10.244.2.7   k8s-w2    &lt;none&gt;           &lt;none&gt;</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get ciliumnodes
<span class="c"># =&gt; NAME      CILIUMINTERNALIP   INTERNALIP       AGE</span>
<span class="c">#    k8s-ctr   172.20.2.68        192.168.10.100   6m11s</span>
<span class="c">#    k8s-w1    172.20.1.88        192.168.10.101   6m50s</span>
<span class="c">#    k8s-w2    172.20.0.235       192.168.10.102   7m8s</span>
<span class="nv">$ </span>kubectl get ciliumnodes <span class="nt">-o</span> json | <span class="nb">grep </span>podCIDRs <span class="nt">-A2</span>
<span class="c"># =&gt;                     "podCIDRs": [</span>
<span class="c">#                            "172.20.2.0/24"</span>
<span class="c">#                        ],</span>
<span class="c">#    --</span>
<span class="c">#                        "podCIDRs": [</span>
<span class="c">#                            "172.20.1.0/24"</span>
<span class="c">#                        ],</span>
<span class="c">#    --</span>
<span class="c">#                        "podCIDRs": [</span>
<span class="c">#                            "172.20.0.0/24"</span>
<span class="c">#                        ],</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl rollout restart deployment webpod
<span class="c"># =&gt; deployment.apps/webpod restarted</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                      READY   STATUS    RESTARTS       AGE     IP             NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    curl-pod                  1/1     Running   1 (172m ago)   3h31m   10.244.0.3     k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-86f878c468-448pc   1/1     Running   0              11s     172.20.0.202   k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-86f878c468-ttbs2   1/1     Running   0              15s     172.20.1.123   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>

<span class="c"># k8s-ctr 노드에 curl-pod 파드 배포</span>
<span class="nv">$ </span>kubectl delete pod curl-pod <span class="nt">--grace-period</span><span class="o">=</span>0
<span class="c"># =&gt; pod "curl-pod" deleted</span>

<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: curl-pod
  labels:
    app: curl
spec:
  nodeName: k8s-ctr
  containers:
  - name: curl
    image: nicolaka/netshoot
    command: ["tail"]
    args: ["-f", "/dev/null"]
  terminationGracePeriodSeconds: 0
</span><span class="no">EOF
</span><span class="c"># =&gt; pod/curl-pod created</span>

<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                      READY   STATUS    RESTARTS   AGE   IP             NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    curl-pod                  1/1     Running   0          33s   172.20.2.15    k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-86f878c468-448pc   1/1     Running   0          66s   172.20.0.202   k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-86f878c468-ttbs2   1/1     Running   0          70s   172.20.1.123   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="nv">$ </span>kubectl get ciliumendpoints
<span class="c"># =&gt; NAME                      SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    curl-pod                  5180                ready            172.20.2.15</span>
<span class="c">#    webpod-86f878c468-448pc   34270               ready            172.20.0.202</span>
<span class="c">#    webpod-86f878c468-ttbs2   34270               ready            172.20.1.123</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium-dbg endpoint list
<span class="c"># =&gt; ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])                                                  IPv6   IPv4           STATUS</span>
<span class="c">#               ENFORCEMENT        ENFORCEMENT</span>
<span class="c">#    60         Disabled           Disabled          20407      k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=kube-system          172.20.0.167   ready</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.cluster=default</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.serviceaccount=coredns</span>
<span class="c">#                                                               k8s:io.kubernetes.pod.namespace=kube-system</span>
<span class="c">#                                                               k8s:k8s-app=kube-dns</span>
<span class="c">#    71         Disabled           Disabled          4          reserved:health                                                                     172.20.0.114   ready</span>
<span class="c">#    1368       Disabled           Disabled          20407      k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=kube-system          172.20.0.92    ready</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.cluster=default</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.serviceaccount=coredns</span>
<span class="c">#                                                               k8s:io.kubernetes.pod.namespace=kube-system</span>
<span class="c">#                                                               k8s:k8s-app=kube-dns</span>
<span class="c">#    2533       Disabled           Disabled          1          reserved:host                                                                                      ready</span>
<span class="c">#    2605       Disabled           Disabled          34270      k8s:app=webpod                                                                      172.20.0.202   ready</span>
<span class="c">#                                                               k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.cluster=default</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.serviceaccount=default</span>
<span class="c">#                                                               k8s:io.kubernetes.pod.namespace=default</span>

<span class="c"># 통신 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl webpod | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod-86f878c468-448pc</span>

</code></pre></div></div>

<h3 id="cilium-설치-확인">Cilium 설치 확인</h3>

<ul>
  <li>cilium cli를 설치하여 Cilium 상태를 확인해 보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># cilium cli 설치</span>
<span class="nv">$ CILIUM_CLI_VERSION</span><span class="o">=</span><span class="si">$(</span>curl <span class="nt">-s</span> https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt<span class="si">)</span>
<span class="nv">$ CLI_ARCH</span><span class="o">=</span>amd64
<span class="nv">$ </span><span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span><span class="si">)</span><span class="s2">"</span> <span class="o">=</span> <span class="s2">"aarch64"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then </span><span class="nv">CLI_ARCH</span><span class="o">=</span>arm64<span class="p">;</span> <span class="k">fi</span>
<span class="nv">$ </span>curl <span class="nt">-L</span> <span class="nt">--fail</span> <span class="nt">--remote-name-all</span> https://github.com/cilium/cilium-cli/releases/download/<span class="k">${</span><span class="nv">CILIUM_CLI_VERSION</span><span class="k">}</span>/cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nv">$ </span><span class="nb">tar </span>xzvfC cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz /usr/local/bin
<span class="c"># =&gt; cilium</span>
<span class="nv">$ </span><span class="nb">rm </span>cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz

<span class="c"># cilium 상태 확인</span>
<span class="nv">$ </span>which cilium
<span class="c"># =&gt; /usr/local/bin/cilium</span>
<span class="nv">$ </span>cilium status
<span class="c"># =&gt;     /¯¯\</span>
<span class="c">#     /¯¯\__/¯¯\    Cilium:             OK</span>
<span class="c">#     \__/¯¯\__/    Operator:           OK</span>
<span class="c">#     /¯¯\__/¯¯\    Envoy DaemonSet:    OK</span>
<span class="c">#     \__/¯¯\__/    Hubble Relay:       disabled</span>
<span class="c">#        \__/       ClusterMesh:        disabled</span>
<span class="c">#    </span>
<span class="c">#    DaemonSet              cilium                   Desired: 3, Ready: 3/3, Available: 3/3</span>
<span class="c">#    DaemonSet              cilium-envoy             Desired: 3, Ready: 3/3, Available: 3/3</span>
<span class="c">#    Deployment             cilium-operator          Desired: 2, Ready: 2/2, Available: 2/2</span>
<span class="c">#    Containers:            cilium                   Running: 3</span>
<span class="c">#                           cilium-envoy             Running: 3</span>
<span class="c">#                           cilium-operator          Running: 2</span>
<span class="c">#                           clustermesh-apiserver</span>
<span class="c">#                           hubble-relay</span>
<span class="c">#    Cluster Pods:          5/5 managed by Cilium</span>
<span class="c">#    Helm chart version:    1.17.5</span>
<span class="c">#    Image versions         cilium             quay.io/cilium/cilium:v1.17.5@sha256:baf8541723ee0b72d6c489c741c81a6fdc5228940d66cb76ef5ea2ce3c639ea6: 3</span>
<span class="c">#                           cilium-envoy       quay.io/cilium/cilium-envoy:v1.32.6-1749271279-0864395884b263913eac200ee2048fd985f8e626@sha256:9f69e290a7ea3d4edf9192acd81694089af048ae0d8a67fb63bd62dc1d72203e: 3</span>
<span class="c">#                           cilium-operator    quay.io/cilium/operator-generic:v1.17.5@sha256:f954c97eeb1b47ed67d08cc8fb4108fb829f869373cbb3e698a7f8ef1085b09e: 2</span>
<span class="nv">$ </span>cilium config view
<span class="c"># =&gt; ...</span>
<span class="c">#    cluster-pool-ipv4-cidr                            172.20.0.0/16</span>
<span class="c">#    default-lb-service-ipam                           lbipam</span>
<span class="c">#    ipam                                              cluster-pool</span>
<span class="c">#    ipam-cilium-node-update-rate                      15s</span>
<span class="c">#    iptables-random-fully                             false</span>
<span class="c">#    ipv4-native-routing-cidr                          172.20.0.0/16</span>
<span class="c">#    kube-proxy-replacement                            true</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>kubectl get cm <span class="nt">-n</span> kube-system cilium-config <span class="nt">-o</span> json | jq

<span class="c">#</span>
<span class="nv">$ </span>cilium config <span class="nb">set </span>debug <span class="nb">true</span> <span class="o">&amp;&amp;</span> watch kubectl get pod <span class="nt">-A</span>
<span class="c"># =&gt; ✨ Patching ConfigMap cilium-config with debug=true...</span>
<span class="c">#    ♻️  Restarted Cilium pods</span>
<span class="nv">$ </span>cilium config view | <span class="nb">grep</span> <span class="nt">-i</span> debug
<span class="c"># =&gt; debug                                             true</span>
<span class="c">#    debug-verbose</span>

<span class="c"># cilium daemon = cilium-dbg</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg config
<span class="c"># =&gt; ##### Read-write configurations #####</span>
<span class="c">#    ConntrackAccounting               : Disabled</span>
<span class="c">#    ConntrackLocal                    : Disabled</span>
<span class="c">#    Debug                             : Disabled</span>
<span class="c">#    DebugLB                           : Disabled</span>
<span class="c">#    DebugPolicy                       : Enabled</span>
<span class="c">#    DropNotification                  : Enabled</span>
<span class="c">#    MonitorAggregationLevel           : Medium</span>
<span class="c">#    PolicyAccounting                  : Enabled</span>
<span class="c">#    PolicyAuditMode                   : Disabled</span>
<span class="c">#    PolicyTracing                     : Disabled</span>
<span class="c">#    PolicyVerdictNotification         : Enabled</span>
<span class="c">#    SourceIPVerification              : Enabled</span>
<span class="c">#    TraceNotification                 : Enabled</span>
<span class="c">#    MonitorNumPages                   : 64</span>
<span class="c">#    PolicyEnforcement                 : default</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg status <span class="nt">--verbose</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    KubeProxyReplacement:   True   [eth0    10.0.2.15 fd17:625c:f037:2:a00:27ff:fe71:19d8 fe80::a00:27ff:fe71:19d8, eth1   192.168.10.102 fe80::a00:27ff:fe79:58ac (Direct Routing)]</span>
<span class="c">#    Routing:                Network: Native   Host: BPF</span>
<span class="c">#    Attach Mode:            TCX</span>
<span class="c">#    Device Mode:            veth</span>
<span class="c">#    ...</span>
<span class="c">#    KubeProxyReplacement Details:</span>
<span class="c">#      Status:                 True</span>
<span class="c">#      Socket LB:              Enabled</span>
<span class="c">#      Socket LB Tracing:      Enabled</span>
<span class="c">#      Socket LB Coverage:     Full</span>
<span class="c">#      Devices:                eth0    10.0.2.15 fd17:625c:f037:2:a00:27ff:fe71:19d8 fe80::a00:27ff:fe71:19d8, eth1   192.168.10.102 fe80::a00:27ff:fe79:58ac (Direct Routing)</span>
<span class="c">#      Mode:                   SNAT</span>
<span class="c">#      Backend Selection:      Random</span>
<span class="c">#      Session Affinity:       Enabled</span>
<span class="c">#      Graceful Termination:   Enabled</span>
<span class="c">#      NAT46/64 Support:       Disabled</span>
<span class="c">#      XDP Acceleration:       Disabled</span>
<span class="c">#      Services:</span>
<span class="c">#      - ClusterIP:      Enabled</span>
<span class="c">#      - NodePort:       Enabled (Range: 30000-32767)</span>
<span class="c">#      - LoadBalancer:   Enabled</span>
<span class="c">#      - externalIPs:    Enabled</span>
<span class="c">#      - HostPort:       Enabled</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<ul>
  <li>cilium_host, cilium_net, cilium_health 등의 네트워크 기본 정보를 확인해보겠습니다.</li>
</ul>

<p><img src="/assets/2025/cilium/w1/20250720_cilium_w1_4.png" alt="img.png" class="image-center" />
<img src="/assets/2025/cilium/w1/20250720_cilium_w1_5.png" alt="img_1.png" class="image-center w-50" />
<a href="https://arthurchiao.art/blog/ctrip-network-arch-evolution/" class="image-caption">출처 : https://arthurchiao.art/blog/ctrip-network-arch-evolution/</a></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> addr
<span class="c"># =&gt; ...</span>
<span class="c">#    7: cilium_net@cilium_host: &lt;BROADCAST,MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span>
<span class="c">#        link/ether 4e:28:ea:3e:83:e0 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet6 fe80::4c28:eaff:fe3e:83e0/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    8: cilium_host@cilium_net: &lt;BROADCAST,MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span>
<span class="c">#        link/ether 22:ad:62:34:21:8e brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet 172.20.2.68/32 scope global cilium_host</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#        inet6 fe80::20ad:62ff:fe34:218e/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    12: lxcc4a3ffff7931@if11: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span>
<span class="c">#        link/ether 76:62:d3:8d:58:1f brd ff:ff:ff:ff:ff:ff link-netns cni-ca74ac02-08e1-9092-74ad-f60026576c19</span>
<span class="c">#        inet6 fe80::7462:d3ff:fe8d:581f/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    14: lxc_health@if13: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span>
<span class="c">#        link/ether ca:67:c2:a6:88:89 brd ff:ff:ff:ff:ff:ff link-netnsid 2</span>
<span class="c">#        inet6 fe80::c867:c2ff:fea6:8889/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> addr <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>

<span class="c">#</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> addr show cilium_net
<span class="c"># =&gt; 7: cilium_net@cilium_host: &lt;BROADCAST,MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span>
<span class="c">#        link/ether 4e:28:ea:3e:83:e0 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet6 fe80::4c28:eaff:fe3e:83e0/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> addr show cilium_host
<span class="c"># =&gt; 8: cilium_host@cilium_net: &lt;BROADCAST,MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span>
<span class="c">#        link/ether 22:ad:62:34:21:8e brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet 172.20.2.68/32 scope global cilium_host</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#        inet6 fe80::20ad:62ff:fe34:218e/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> addr show cilium_net  <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> addr show cilium_host <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>

<span class="c"># lxc_health 인터페이스는 veth 로 cilium(NET NS 0, 호스트와 다름)과 veth pair 이다 - 링크</span>
<span class="c"># cilium 인터페이스에 파드 IP가 할당되어 있으며, cilium-health-responder 로 동작한다</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> addr show lxc_health
<span class="c"># =&gt; 14: lxc_health@if13: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span>
<span class="c">#        link/ether ca:67:c2:a6:88:89 brd ff:ff:ff:ff:ff:ff link-netnsid 2</span>
<span class="c">#        inet6 fe80::c867:c2ff:fea6:8889/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> addr show lxc_health  <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>

<span class="c"># IP 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium-dbg status <span class="nt">--verbose</span>
<span class="c"># =&gt; ....</span>
<span class="c">#    Name              IP              Node   Endpoints</span>
<span class="c">#      k8s-w2 (localhost):</span>
<span class="c">#        Host connectivity to 192.168.10.102:   &lt;span style="color: green;"&gt;# &lt;-- NodeIP&lt;/span&gt;</span>
<span class="c">#          ICMP to stack:   OK, RTT=440.958µs</span>
<span class="c">#          HTTP to agent:   OK, RTT=539.708µs</span>
<span class="c">#        Endpoint connectivity to 172.20.0.114: &lt;span style="color: green;"&gt;# &lt;-- HealthIP&lt;/span&gt;</span>
<span class="c">#          ICMP to stack:   OK, RTT=189µs</span>
<span class="c">#          HTTP to agent:   OK, RTT=502µs</span>
<span class="c">#      k8s-ctr:</span>
<span class="c">#        Host connectivity to 192.168.10.100:   &lt;span style="color: green;"&gt;# &lt;-- NodeIP&lt;/span&gt;</span>
<span class="c">#          ICMP to stack:   OK, RTT=1.011167ms</span>
<span class="c">#          HTTP to agent:   OK, RTT=1.071083ms</span>
<span class="c">#        Endpoint connectivity to 172.20.2.223: &lt;span style="color: green;"&gt;# &lt;-- HealthIP&lt;/span&gt;</span>
<span class="c">#          ICMP to stack:   OK, RTT=1.027125ms</span>
<span class="c">#          HTTP to agent:   OK, RTT=7.677708ms</span>
<span class="c">#      k8s-w1:</span>
<span class="c">#        Host connectivity to 192.168.10.101:   &lt;span style="color: green;"&gt;# &lt;-- NodeIP&lt;/span&gt;</span>
<span class="c">#          ICMP to stack:   OK, RTT=888.417µs</span>
<span class="c">#          HTTP to agent:   OK, RTT=1.167333ms</span>
<span class="c">#        Endpoint connectivity to 172.20.1.229: &lt;span style="color: green;"&gt;# &lt;-- HealthIP&lt;/span&gt;</span>
<span class="c">#          ICMP to stack:   OK, RTT=1.806167ms</span>
<span class="c">#          HTTP to agent:   OK, RTT=1.903ms</span>
<span class="c">#    ....</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium-dbg endpoint list | <span class="nb">grep </span>health
<span class="c"># =&gt; 2955  Disabled  Disabled  4  reserved:health  172.20.0.114  ready                                                             172.20.1.40    ready </span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium-dbg status <span class="nt">--all-addresses</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    Allocated addresses:</span>
<span class="c">#      172.20.0.114 (health)</span>
<span class="c">#      172.20.0.167 (kube-system/coredns-674b8bbfcf-bvsfb [restored])</span>
<span class="c">#      172.20.0.202 (default/webpod-86f878c468-448pc [restored])</span>
<span class="c">#      172.20.0.235 (router)</span>
<span class="c">#      172.20.0.92 (kube-system/coredns-674b8bbfcf-7q52c [restored])</span>
<span class="c">#    ...</span>

<span class="c"># Check health info in CT/NAT tables : ICMP records in Conntrack (CT) table and NAT table</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium bpf ct list global | <span class="nb">grep </span>ICMP |head <span class="nt">-n4</span>
<span class="c"># =&gt; ICMP IN 192.168.10.101:19430 -&gt; 172.20.0.114:0 expires=11874 Packets=0 Bytes=0 RxFlagsSeen=0x00 LastRxReport=11814 TxFlagsSeen=0x00 LastTxReport=11814 Flags=0x0000 [ ] RevNAT=0 SourceSecurityID=6 IfIndex=0 BackendID=0</span>
<span class="c">#    ICMP IN 192.168.10.101:0 -&gt; 172.20.0.114:0 related expires=11874 Packets=0 Bytes=0 RxFlagsSeen=0x00 LastRxReport=11814 TxFlagsSeen=0x00 LastTxReport=0 Flags=0x0000 [ ] RevNAT=0 SourceSecurityID=6 IfIndex=0 BackendID=0</span>
<span class="c">#    ICMP IN 192.168.10.101:2374 -&gt; 172.20.0.114:0 expires=11535 Packets=0 Bytes=0 RxFlagsSeen=0x00 LastRxReport=11475 TxFlagsSeen=0x00 LastTxReport=11475 Flags=0x0000 [ ] RevNAT=0 SourceSecurityID=6 IfIndex=0 BackendID=0</span>
<span class="c">#    ICMP IN 192.168.10.101:47855 -&gt; 172.20.0.114:0 expires=11415 Packets=0 Bytes=0 RxFlagsSeen=0x00 LastRxReport=11355 TxFlagsSeen=0x00 LastTxReport=11355 Flags=0x0000 [ ] RevNAT=0 SourceSecurityID=6 IfIndex=0 BackendID=0</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium bpf nat list | <span class="nb">grep </span>ICMP |head <span class="nt">-n4</span>
<span class="c"># =&gt; ICMP OUT 192.168.10.102:35430 -&gt; 172.20.1.229:0 XLATE_SRC 192.168.10.102:35430 Created=164sec ago NeedsCT=1</span>
<span class="c">#    ICMP IN 172.20.2.223:0 -&gt; 192.168.10.102:47029 XLATE_DST 192.168.10.102:47029 Created=464sec ago NeedsCT=1</span>
<span class="c">#    ICMP IN 172.20.2.223:0 -&gt; 192.168.10.102:52326 XLATE_DST 192.168.10.102:52326 Created=54sec ago NeedsCT=1</span>
<span class="c">#    ICMP OUT 192.168.10.102:47029 -&gt; 172.20.2.223:0 XLATE_SRC 192.168.10.102:47029 Created=464sec ago NeedsCT=1</span>
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w1/20250720_cilium_w1_6.png" alt="img.png" class="image-center" />
<em class="image-caption"><a href="https://arthurchiao.art/blog/cilium-code-health-probe">node 및 endpoint health check 절차</a></em></p>

<ul>
  <li>routing 정보 확인해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Native-Routing + autoDirectNodeRoutes=true</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route | <span class="nb">grep </span>172.20 | <span class="nb">grep </span>eth1
<span class="c"># =&gt; 172.20.0.0/24 via 192.168.10.102 dev eth1 proto kernel</span>
<span class="c">#    172.20.1.0/24 via 192.168.10.101 dev eth1 proto kernel</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> route | <span class="nb">grep </span>172.20 | <span class="nb">grep </span>eth1 <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>

<span class="c"># hostNetwork 를 사용하지 않는 파드의 경우 endpointRoutes.enabled=true 설정으로 lxcY 인터페이스 생성됨</span>
<span class="nv">$ </span>kubectl get ciliumendpoints <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE     NAME                       SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    default       curl-pod                   5180                ready            172.20.2.15</span>
<span class="c">#    default       webpod-86f878c468-448pc    34270               ready            172.20.0.202</span>
<span class="c">#    default       webpod-86f878c468-ttbs2    34270               ready            172.20.1.123</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-7q52c   20407               ready            172.20.0.92</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-bvsfb   20407               ready            172.20.0.167</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route | <span class="nb">grep </span>lxc
<span class="c"># =&gt; 172.20.2.15 dev lxcc4a3ffff7931 proto kernel scope link</span>
<span class="c">#    172.20.2.223 dev lxc_health proto kernel scope link</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> route | <span class="nb">grep </span>lxc <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
</code></pre></div></div>

<ul>
  <li>보다 상세한 내용은 <a href="https://docs.cilium.io/en/stable/network/kubernetes/kubeproxy-free/">공식문서</a>를 참고하세요.</li>
</ul>

<hr />

<h2 id="통신-확인">통신 확인</h2>

<h3 id="노드간-파드---파드-통신">노드간 ‘파드 -&gt; 파드’ 통신</h3>

<ul>
  <li><a href="https://docs.cilium.io/en/stable/network/ebpf/lifeofapacket/">참고</a> <a href="https://velog.io/@_gyullbb/Cilium">추천 글</a></li>
</ul>

<p><img src="/assets/2025/cilium/w1/20250720_cilium_w1_7.png" alt="img.png" class="image-center" />
<em class="image-caption">파드에서 빠져나갈 때</em></p>

<p><img src="/assets/2025/cilium/w1/20250720_cilium_w1_8.png" alt="img_1.png" class="image-center" />
<em class="image-caption">파드로 들어올 때</em></p>

<ul>
  <li>cilium 정보 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 먼저 아래의 cheatsheet을 참고하여 c0, c0bpf 등의 단축키(alias)를 지정한 후에 진행합니다.</span>

<span class="c"># 엔드포인트 정보 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                      READY   STATUS    RESTARTS   AGE     IP             NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    curl-pod                  1/1     Running   0          3h40m   172.20.2.15    k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-86f878c468-448pc   1/1     Running   0          3h41m   &lt;span style="color: green;"&gt;172.20.0.202&lt;/span&gt;   k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-86f878c468-ttbs2   1/1     Running   0          3h41m   172.20.1.123   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="nv">$ </span>kubectl get svc,ep webpod
<span class="c"># =&gt; NAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE</span>
<span class="c">#    service/webpod   ClusterIP   10.96.62.184   &lt;none&gt;        80/TCP    7h12m</span>
<span class="c">#    </span>
<span class="c">#    NAME               ENDPOINTS                         AGE</span>
<span class="c">#    endpoints/webpod   172.20.0.202:80,172.20.1.123:80   7h12m</span>

<span class="c"># 첫번째 webpod의 IP 주소를 WEBPOD1IP 변수에 저장합니다.</span>
<span class="nv">$ WEBPOD1IP</span><span class="o">=</span>172.20.0.202

<span class="c"># BPF maps : 목적지 파드와 통신 시 어느곳으로 보내야 될지 확인할 수 있다</span>
<span class="nv">$ </span>c0 map get cilium_ipcache
<span class="nv">$ </span>c0 map get cilium_ipcache | <span class="nb">grep</span> <span class="nv">$WEBPOD1IP</span>
<span class="c"># =&gt; 172.20.0.202/32     identity=34270 encryptkey=0 tunnelendpoint=192.168.10.102 flags=&lt;none&gt;   sync</span>

<span class="c"># curl-pod 의 LXC 변수 지정</span>
<span class="c"># $ LXC=&lt;k8s-ctr의 가장 나중에 lxc 이름(lxc_health 제외)&gt;</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route | <span class="nb">grep </span>lxc
<span class="c"># =&gt; 172.20.2.15 dev &lt;span style="color: green;"&gt;lxcc4a3ffff7931&lt;/span&gt; proto kernel scope link</span>
<span class="c">#    172.20.2.223 dev lxc_health proto kernel scope link</span>
<span class="nv">$ LXC</span><span class="o">=</span>lxcc4a3ffff7931

<span class="c"># Node’s eBPF programs</span>
<span class="c">## list of eBPF programs</span>
<span class="nv">$ </span>c0bpf net show
<span class="nv">$ </span>c0bpf net show | <span class="nb">grep</span> <span class="nv">$LXC</span> 
<span class="c"># =&gt; lxcc4a3ffff7931(12) tcx/ingress cil_from_container prog_id 1212 link_id 22</span>
<span class="c">#    lxcc4a3ffff7931(12) tcx/egress cil_to_container prog_id 1214 link_id 23 </span>

<span class="c">## Use bpftool prog show id to view additional information about a program, including a list of attached eBPF maps:</span>
<span class="c"># $ c0bpf prog show id &lt;출력된 prog id 입력&gt;</span>
<span class="nv">$ </span>c0bpf prog show <span class="nb">id </span>1214
<span class="c"># =&gt; 1214: sched_cls  name cil_to_container  tag 0b3125767ba1861c  gpl</span>
<span class="c">#            loaded_at 2025-07-19T08:50:37+0000  uid 0</span>
<span class="c">#            xlated 1448B  jited 1144B  memlock 4096B  map_ids 219,41,218</span>
<span class="c">#            btf_id 468</span>

<span class="nv">$ </span>c0bpf map list
<span class="c"># =&gt; ...</span>
<span class="c">#    41: percpu_hash  name cilium_metrics  flags 0x1</span>
<span class="c">#            key 8B  value 16B  max_entries 1024  memlock 19024B</span>
<span class="c">#    ...</span>
<span class="c">#    227: array  name .rodata.config  flags 0x480</span>
<span class="c">#            key 4B  value 52B  max_entries 1  memlock 8192B</span>
<span class="c">#            btf_id 496  frozen</span>
<span class="c">#    228: prog_array  name cilium_calls_ne  flags 0x0</span>
<span class="c">#            key 4B  value 4B  max_entries 50  memlock 720B</span>
<span class="c">#            owner_prog_type sched_cls  owner jited</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<ul>
  <li>다른 노드 간 ‘파드 -&gt; 파드’ 통신을 확인해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># vagrant ssh k8s-w1 , # vagrant ssh k8s-w2 각각 터미널 접속 후 아래 실행</span>
<span class="nv">$ </span>ngrep <span class="nt">-tW</span> byline <span class="nt">-d</span> eth1 <span class="s1">''</span> <span class="s1">'tcp port 80'</span>

<span class="c"># [k8s-ctr] curl-pod 에서 curl 요청 시도</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nv">$WEBPOD1IP</span>
<span class="c"># 각각 터미널에서 출력 확인 : 파드의 소스 IP와 목적지 IP가 다른 노드의 서버 NIC에서 확인! : Native-Routung </span>
<span class="c"># =&gt; ####</span>
<span class="c">#    T 2025/07/19 21:36:42.198609 172.20.2.15:46708 -&gt; 172.20.0.202:80 [AP] #4</span>
<span class="c">#    GET / HTTP/1.1.</span>
<span class="c">#    ...</span>
<span class="c">#    ##</span>
<span class="c">#    T 2025/07/19 21:36:42.200368 172.20.0.202:80 -&gt; 172.20.2.15:46708 [AP] #6</span>
<span class="c">#    HTTP/1.1 200 OK.</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w1/20250720_cilium_w1_9.png" alt="img.png" class="image-center" /></p>

<h3 id="노드간-파드---서비스-통신">노드간 ‘파드 -&gt; 서비스’ 통신</h3>

<ul>
  <li>참고 : <a href="https://velog.io/@haruband/K8SCilium-Socket-Based-LoadBalancing-%EA%B8%B0%EB%B2%95">[K8S/Cilium] Socket-Based LoadBalancing 기법</a></li>
</ul>

<p><img src="/assets/2025/cilium/w1/20250720_cilium_w1_10.png" alt="img.png" class="image-center" />
<em class="image-caption">네트워크기반 로드밸런싱 vs 소켓기반 로드밸런싱 비교</em></p>

<ul>
  <li>Pod1 안에서 동작하는 앱이 <strong>connect() 시스템콜</strong>을 이용하여 소켓을 연결할 때 목적지 주소가 서비스 주소(10.10.8.55)이면 소켓의 목적지 주소를 바로 백엔드 주소(10.0.0.31)로 설정합니다.</li>
  <li>이후 앱에서 해당 소켓을 통해 보내는 모든 패킷의 목적지 주소는 이미 백엔드 주소(10.0.0.31)로 설정되어 있기 때문에 중간에 <strong>DNAT 변환 및 역변환 과정이 필요없어집니다.</strong></li>
  <li><strong>Destination NAT</strong> 변환은 시스템 콜 레벨에서 발생하며, 패킷이 커널에 의해 생성되기도 전에 수행됩니다.</li>
  <li><strong>Socket operations</strong> : <strong>BPF socket operations program</strong> 은 <strong>root cgroup 에 연결</strong>되며 TCP <strong>event</strong>(ESTABLISHED) 에서 실행됩니다.</li>
  <li>
    <p><strong>Socket send/recv</strong> : Socket send/recv hook 은 <strong>TCP</strong> socket 의 모든 <strong>송수신</strong> 작업에서 실행되며, <strong>hook</strong> 에서 <strong>검사/삭제/리다이렉션</strong>을 할 수 있습니다.
<img src="/assets/2025/cilium/w1/20250720_cilium_w1_11.png" alt="img.png" class="image-center" />
<em class="image-caption">https://cilium.io/blog/2020/11/10/ebpf-future-of-networking/</em></p>
  </li>
  <li>파드 네임스페이스에서 Socket-Based LoadBalancing 기법을 그림으로 정리해보면 아래와 같습니다.</li>
</ul>

<p><img src="/assets/2025/cilium/w1/20250720_cilium_w1_12.png" alt="img.png" class="image-center" />
<em class="image-caption">출처 : <a href="https://velog.io/@haruband/K8SCilium-Socket-Based-LoadBalancing-%EA%B8%B0%EB%B2%95">[K8S/Cilium] Socket-Based LoadBalancing 기법</a></em></p>

<ul>
  <li>그림상의 좌측은 네트워크 기반 로드밸런싱 기법을 사용한 경우이고, 우측은 소켓 기반 로드밸런싱 기법을 사용한 경우입니다.</li>
  <li>
    <p>소켓 기반 로드밸런싱 기법은 네트워크 기반 로드밸런싱 기법과 비교하여 DNAT 변환 및 역변환 과정이 필요 없기 때문에 성능이 향상됩니다.</p>
  </li>
  <li>connect() 와 sendto() 소켓 함수에 연결된 프로그램(connect4, sendmsg4)에서는 소켓의 목적지 주소를 백엔드 주소와 포트로 변환하고, cilium_lb4_backends 맵에 백엔드 주소와 포트를 등록해놓습니다.</li>
  <li>
    <p>이후 recvmsg() 소켓 함수에 연결된 프로그램(recvmsg4)에서는 cilium_lb4_reverse_nat 맵을 이용해서 목적지 주소와 포트를 다시 서비스 주소와 포트로 변환합니다.
<img src="/assets/2025/cilium/w1/20250720_cilium_w1_14.png" alt="img.png" class="image-center" />
<em class="image-caption">https://k8s.networkop.co.uk/services/clusterip/dataplane/ebpf/</em></p>
  </li>
  <li>실습 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># curl 호출</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl webpod

<span class="c"># 신규 터미널 : 파드에서 SVC(ClusterIP) 접속 시 tcpdump 로 확인 : ClusterIP가 소켓 레벨에서 이미 Endpoint 로 변경되었음을 확인!</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>curl-pod <span class="nt">--</span> tcpdump <span class="nt">-enni</span> any <span class="nt">-q</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    14:09:05.318403 eth0  Out ifindex 11 d6:ab:bb:21:3a:93 172.20.2.15.40982 &gt; 172.20.1.123.80: tcp 0</span>
<span class="c">#    14:09:05.319286 eth0  In  ifindex 11 76:62:d3:8d:58:1f 172.20.1.123.80 &gt; 172.20.2.15.40982: tcp 0</span>
<span class="c">#    ...</span>

<span class="c"># Socket-Based LoadBalancing 관련 설정들 확인</span>
<span class="nv">$ </span>c0 status <span class="nt">--verbose</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    KubeProxyReplacement Details:</span>
<span class="c">#      Status:                 True</span>
<span class="c">#      Socket LB:              Enabled</span>
<span class="c">#      Socket LB Tracing:      Enabled</span>
<span class="c">#      Socket LB Coverage:     Full</span>
<span class="c">#      Devices:                eth0    10.0.2.15 fd17:625c:f037:2:a00:27ff:fe71:19d8 fe80::a00:27ff:fe71:19d8, eth1   192.168.10.100 fe80::a00:27ff:feda:2493 (Direct Routing)</span>
<span class="c">#      Mode:                   SNAT</span>
<span class="c">#      Backend Selection:      Random</span>
<span class="c">#      Session Affinity:       Enabled</span>
<span class="c">#      Graceful Termination:   Enabled</span>
<span class="c">#      NAT46/64 Support:       Disabled</span>
<span class="c">#      XDP Acceleration:       Disabled</span>
<span class="c">#      Services:</span>
<span class="c">#      - ClusterIP:      Enabled</span>
<span class="c">#      - NodePort:       Enabled (Range: 30000-32767)</span>
<span class="c">#      - LoadBalancer:   Enabled</span>
  
<span class="c"># syscall 호출 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>curl-pod <span class="nt">--</span> strace <span class="nt">-c</span> curl <span class="nt">-s</span> webpod
<span class="c"># =&gt; ...</span>
<span class="c">#    % time     seconds  usecs/call     calls    errors syscall</span>
<span class="c">#    ------ ----------- ----------- --------- --------- ----------------</span>
<span class="c">#     &lt;span style="color: green;"&gt;19.00    0.001003         334         3         1 connect&lt;/span&gt;</span>
<span class="c">#     15.97    0.000843         281         3           sendto</span>
<span class="c">#     15.82    0.000835          23        35           munmap</span>
<span class="c">#     10.59    0.000559          93         6         3 recvfrom</span>
<span class="c">#     10.33    0.000545           8        63           mmap</span>
<span class="c">#      7.58    0.000400           8        47        30 openat</span>
<span class="c">#      4.32    0.000228          10        22           close</span>
<span class="c">#      3.87    0.000204          20        10           lseek</span>
<span class="c">#      2.94    0.000155           6        24           fcntl</span>
<span class="c">#      2.56    0.000135           4        28           rt_sigaction</span>
<span class="c">#      1.46    0.000077           8         9           ppoll</span>
<span class="c">#      1.23    0.000065          16         4           socket</span>
<span class="c">#      0.72    0.000038          12         3         3 ioctl</span>
<span class="c">#      0.68    0.000036          36         1           newfstatat</span>
<span class="c">#      0.63    0.000033           2        14           mprotect</span>
<span class="c">#      &lt;span style="color: green;"&gt;0.63    0.000033           1        27           read&lt;/span&gt;</span>
<span class="c">#      0.55    0.000029           9         3           readv</span>
<span class="c">#      0.21    0.000011           0        12           fstat</span>
<span class="c">#      0.21    0.000011           0        14           rt_sigprocmask</span>
<span class="c">#      0.17    0.000009           9         1           writev</span>
<span class="c">#      0.15    0.000008           1         5           setsockopt</span>
<span class="c">#      &lt;span style="color: green;"&gt;0.15    0.000008           1         5           getsockname&lt;/span&gt;</span>
<span class="c">#      0.09    0.000005           5         1           eventfd2</span>
<span class="c">#      0.06    0.000003           0         4           brk</span>
<span class="c">#      0.04    0.000002           2         1           getrandom</span>
<span class="c">#      &lt;span style="color: green;"&gt;0.04    0.000002           2         1           getsockopt&lt;/span&gt;</span>
<span class="c">#      0.02    0.000001           1         1           getgid</span>
<span class="c">#      0.00    0.000000           0         1           set_tid_address</span>
<span class="c">#      0.00    0.000000           0         1           getuid</span>
<span class="c">#      0.00    0.000000           0         2           geteuid</span>
<span class="c">#      0.00    0.000000           0         1           getegid</span>
<span class="c">#      0.00    0.000000           0         1           execve</span>
<span class="c">#    ------ ----------- ----------- --------- --------- ----------------</span>
<span class="c">#    100.00    0.005278          14       353        37 total</span>

<span class="c"># 상세 출력</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>curl-pod <span class="nt">--</span> strace <span class="nt">-s</span> 65535 <span class="nt">-f</span> <span class="nt">-tt</span> curl <span class="nt">-s</span> webpod

<span class="c"># 특정 이벤트 필터링 : -e</span>
<span class="c">## connect 로 출력되는 10.96.62.184 는 webpod Service 의 ClusterIP입니다.</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>curl-pod <span class="nt">--</span> strace <span class="nt">-e</span> <span class="nv">trace</span><span class="o">=</span>connect     curl <span class="nt">-s</span> webpod
<span class="c"># =&gt; connect(5, {sa_family=AF_INET, sin_port=htons(80), sin_addr=inet_addr("10.96.62.184")}, 16) = 0</span>
<span class="c">#    connect(4, {sa_family=AF_INET, sin_port=htons(80), sin_addr=inet_addr("10.96.62.184")}, 16) = -1 EINPROGRESS (Operation in progress)</span>
<span class="c">#    ...</span>

<span class="c">## connect 로 출력되는 172.20.2.15 는 curl-pod 의 파드 IP입니다. -&gt; 목적지 webpod 파드 IP가 아닙니다.</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>curl-pod <span class="nt">--</span> strace <span class="nt">-e</span> <span class="nv">trace</span><span class="o">=</span>getsockname curl <span class="nt">-s</span> webpod
<span class="c"># =&gt; getsockname(4, {sa_family=AF_INET, sin_port=htons(52951), sin_addr=inet_addr("172.20.2.15")}, [128 =&gt; 16]) = 0</span>
<span class="c">#    getsockname(5, {sa_family=AF_INET, sin_port=htons(42089), sin_addr=inet_addr("172.20.2.15")}, [16]) = 0</span>
<span class="c">#    getsockname(4, {sa_family=AF_INET, sin_port=htons(60934), sin_addr=inet_addr("172.20.2.15")}, [128 =&gt; 16]) = 0</span>
<span class="c">#    getsockname(4, {sa_family=AF_INET, sin_port=htons(60934), sin_addr=inet_addr("172.20.2.15")}, [128 =&gt; 16]) = 0</span>
<span class="c">#    getsockname(4, {sa_family=AF_INET, sin_port=htons(60934), sin_addr=inet_addr("172.20.2.15")}, [128 =&gt; 16]) = 0</span>

<span class="nv">$ </span>kubectl <span class="nb">exec </span>curl-pod <span class="nt">--</span> strace <span class="nt">-e</span> <span class="nv">trace</span><span class="o">=</span>getsockopt curl <span class="nt">-s</span> webpod
<span class="c"># =&gt; getsockopt(4, SOL_SOCKET, SO_ERROR, [0], [4]) = 0 # 소켓 연결 성공</span>
</code></pre></div></div>

<ul>
  <li>strace를 통해 위와 같이 IP 변환에 대해 알아보려 했지만 
실제로는 소켓 레벨에서 이미 변환이 완료되어 있기 때문에 strace로는 확인할 수 없습니다.</li>
  <li>이는 eBPF를 통해 시스템 콜을 줄여 성능을 향상시키는 Cilium의 특징 중 하나입니다.</li>
  <li>ℹ️ 참고로  strace는 시스템 콜을 추적하는 도구로 다음과 같은 기능들로 사용할 수 있습니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 중단점 트레이싱 : -ttt(첫 열에 기준시간으로부터 흐른 시간 표시) , -T(마지막 필드 time에 시스템 콜에 걸린 시간을 표시) , -p PID(프로세스 ID가 PID 인 프로세스를 트레이싱)</span>
<span class="nv">$ </span>strace <span class="nt">-ttt</span> <span class="nt">-T</span> <span class="nt">-p</span> 1884
  
<span class="c"># 시스템 콜별 통계</span>
<span class="nv">$ </span>strace <span class="nt">-c</span> <span class="nt">-p</span> 1884
  
<span class="c"># 프로그램 실행시 시스템 콜 추적</span>
<span class="nv">$ </span>strace <span class="nb">ls</span>
  
<span class="c"># 옵션 사용해보기 : -s(출력 string 결과 최댓값 지정), -tt(첫 열에 기준시간으로부터 흐른 시간 표시, ms단위), -f(멀티 스레드,멀티 프로레스의 자식 프로세스의 시스템 콜 추적)</span>
<span class="nv">$ </span>strace <span class="nt">-s</span> 65535 <span class="nt">-f</span> <span class="nt">-T</span> <span class="nt">-tt</span> <span class="nt">-o</span> &lt;파일명&gt; <span class="nt">-p</span> &lt;pid&gt;
  
<span class="c"># hostname 명령 분석하기 : -o &lt;파일명&gt; 출력 결과를 파일로 떨구기</span>
<span class="nv">$ </span>strace <span class="nt">-s</span> 65535 <span class="nt">-f</span> <span class="nt">-T</span> <span class="nt">-tt</span> <span class="nt">-o</span> hostname_f_trace <span class="nb">hostname</span> <span class="nt">-f</span>
  
<span class="c"># 특정 이벤트 : -e</span>
<span class="nv">$ </span>strace <span class="nt">-e</span> <span class="nv">trace</span><span class="o">=</span>connect curl ipinfo.io
</code></pre></div>    </div>
  </li>
</ul>

<h3 id="cilium-사용시-주의사항">Cilium 사용시 주의사항</h3>

<ul>
  <li>소켓 기반 로드밸런싱 이용시 Istio(EnvoyProxy)와 같은 사이드카 우회문제가 있을 수 있습니다. <a href="https://velog.io/@haruband/K8S-Cilium-Socket-based-LoadBalancing-%EC%97%90-%EC%9D%98%ED%95%9C-Istio-Envoy-%EC%9A%B0%ED%9A%8C-%EB%AC%B8%EC%A0%9C-%EB%B6%84%EC%84%9D">링크</a>
<img src="/assets/2025/cilium/w1/20250720_cilium_w1_15.png" alt="img.png" />
    <ul>
      <li>앞서 확인한것 처럼 서비스의 IP가 이미 백엔드 IP로 변환되었기 때문에, 서비스 IP기반으로 동작하는 모든 필터가 우회되는 현상입니다.</li>
      <li>해결 방안은 파드 네임스페이스에서는 소켓 기반 로드밸런싱을 사용하지 않는 것입니다. 즉, 호스트 네임스페이스만 사용하게 설정하는 것입니다
        <ul>
          <li>HTTP의 경우 Envoy의 HTTP 필터가 HTTP 패킷의 host 헤더를 필터링하여 패킷의 목적지 주소를 서비스 IP에서 백엔드 IP로 변환을 잘 합니다.</li>
          <li>하지만, HTTP가 아닌 일반 TCP 서비스 (예) Telnet 등)은 위 환경에서 문제가 발생합니다.</li>
        </ul>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 설정</span>
<span class="nv">$ VERSION</span><span class="o">=</span>1.17.5
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--version</span> <span class="nv">$VERSION</span> <span class="nt">--namespace</span> kube-system <span class="nt">--reuse-values</span> <span class="se">\</span>
  <span class="nt">--set</span> socketLB.hostNamespaceOnly<span class="o">=</span><span class="nb">true</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system rollout restart ds/cilium
<span class="c"># =&gt; daemonset.apps/cilium restarted</span>
  
<span class="nv">$ </span>cilium config view | <span class="nb">grep </span>bpf-lb-sock-hostns-only
<span class="c"># =&gt; bpf-lb-sock-hostns-only                           true</span>
  
<span class="c"># 확인</span>
<span class="c"># 지속적으로 접속 트래픽 발생</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>kubectl <span class="nb">exec </span>curl-pod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nv">$SVCIP</span> | <span class="nb">grep </span>Hostname<span class="p">;</span><span class="nb">echo</span> <span class="s2">"-----"</span><span class="p">;</span><span class="nb">sleep </span>1<span class="p">;</span><span class="k">done</span>
<span class="c"># =&gt; Hostname: webpod-86f878c468-448pc</span>
<span class="c">#    -----</span>
<span class="c">#    Hostname: webpod-86f878c468-ttbs2</span>
<span class="c">#    -----</span>
<span class="c">#    Hostname: webpod-86f878c468-ttbs2</span>
<span class="c">#    ...</span>
  
<span class="c"># 파드에서 SVC(ClusterIP) 접속 시 tcpdump 로 확인 &gt;&gt; 파드 내부 캡쳐인데, SVC(10.96.62.184) 트래픽이 보인다!</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>curl-pod <span class="nt">--</span> tcpdump <span class="nt">-enni</span> any <span class="nt">-q</span>
<span class="c"># =&gt; 14:38:41.369005 eth0  Out ifindex 11 d6:ab:bb:21:3a:93 172.20.2.15.52976 &gt; &lt;span style="color: green;"&gt;10.96.62.184.80&lt;/span&gt;: tcp 0</span>
<span class="c">#    14:38:41.369050 eth0  Out ifindex 11 d6:ab:bb:21:3a:93 172.20.2.15.52976 &gt; &lt;span style="color: green;"&gt;10.96.62.184.80&lt;/span&gt;: tcp 76</span>
<span class="c">#    14:38:41.369767 eth0  In  ifindex 11 76:62:d3:8d:58:1f &lt;span style="color: green;"&gt;10.96.62.184.80&lt;/span&gt; &gt; 172.20.2.15.52976: tcp 0</span>
<span class="c">#    14:38:41.370802 eth0  In  ifindex 11 76:62:d3:8d:58:1f &lt;span style="color: green;"&gt;10.96.62.184.80&lt;/span&gt; &gt; 172.20.2.15.52976: tcp 327</span>
<span class="c">#    ...	</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li>Service ClusterIP로 NFS나 SMB 같은 프로토콜을 사용하면 문제가 발생할 수 있습니다. (Longhorn, Portworx, Robin 등) - <a href="https://docs.cilium.io/en/stable/network/kubernetes/kubeproxy-free/#limitations">Docs</a>, <a href="https://github.com/cilium/cilium/issues/21541">Issue</a>
    <ul>
      <li>Cilium의 eBPF를 통한 kube-proxy 대체 기능은 socket기반 로드밸런싱을 사용하기 때문에, 앞서 살펴본것 처럼 서비스 IP가 백엔드 IP로 변환되어 사용됩니다.</li>
      <li>NFS나 SMB 프로토콜은 서비스 IP를 사용하여 통신하기 때문에, socket기반 로드밸런싱을 사용하면 문제가 발생할 수 있습니다.
이 문제는 Longhorn, Portworx, Robin 등과 같은 스토리지 시스템에서 발생할 수 있으며, <code class="language-plaintext highlighter-rouge">ReadWriteMany</code> 모드를 사용하는 다른 스토리지 시스템에서도 발생할 수 있습니다.</li>
      <li>이를 해결하기 위해서는 다음의 패치들이 커널에 포함되어있어야 합니다.
        <ul>
          <li><code class="language-plaintext highlighter-rouge">0bdf399342c5 ("net: Avoid address overwrite in kernel_connect")</code></li>
          <li><code class="language-plaintext highlighter-rouge">86a7e0b69bd5 ("net: prevent rewrite of msg_name in sock_sendmsg()")</code></li>
          <li><code class="language-plaintext highlighter-rouge">01b2885d9415 ("net: Save and restore msg_namelen in sock_sendmsg")</code></li>
          <li><code class="language-plaintext highlighter-rouge">cedc019b9f26 ("smb: use kernel_connect() and kernel_bind()")</code> (SMB only)</li>
        </ul>
      </li>
      <li>위의 패치들은 많은 안정화 커널버전에 백포트 되었으며, 아래의 배포판 중 해당 버전 이상에서는 해결되었습니다.
        <ul>
          <li><strong>Ubuntu</strong>: <code class="language-plaintext highlighter-rouge">5.4.0-187-generic</code>, <code class="language-plaintext highlighter-rouge">5.15.0-113-generic</code>, <code class="language-plaintext highlighter-rouge">6.5.0-41-generic</code> or newer.</li>
          <li><strong>RHEL 8</strong>: <code class="language-plaintext highlighter-rouge">4.18.0-553.8.1.el8_10.x86_64</code> or newer (RHEL 8.10+).</li>
          <li><strong>RHEL 9</strong>: <code class="language-plaintext highlighter-rouge">kernel-5.14.0-427.31.1.el9_4</code> or newer (RHEL 9.4+).</li>
        </ul>
      </li>
      <li>보다 자세한 사항은 <a href="https://github.com/cilium/cilium/issues/21541">Github Issue 21541</a>를 확인하세요.</li>
    </ul>
  </li>
  <li>Cilium은 kubernetes의 중추적인 역할을 하는 kube-proxy를 대체하기 때문에, Linux Network Stack을 사용하는 애플리케이션 등을
적용시 꼭 사전 검증이 필요합니다.</li>
</ul>

<hr />

<h2 id="마치며">마치며</h2>

<p>이번 주에는 가장 기본적인 CNI인 Flannel과 가장 고도화된 CNI 중의 하나인 Cilium을 살펴보았습니다.
한번에 두가지를 비교해 보면서 Cilium의 특징과 장점을 확인하는 시간이었습니다.
또한 Cilium이 기능적으로 혁신적이고 최근 기술인 만큼 아직 엣지 케이스가 많이 남아있다는 것도 알 수 있었습니다.</p>

<p>줌 영상 스터디로 한번 설명을 듣고, 정리된 실습자료를 따라하는데 시간이 쭉쭉 가고, 이해가 잘 안 가는 부분이 많은데, 
스터디를 준비해주시는 CloudNet@ 팀 분들이 얼마나 정성과 시간을 쏟았을지 감사한 마음이 듭니다.</p>

<p>마지막으로 실습환경을 삭제하며 마치겠습니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>vagrant destroy <span class="nt">-f</span> <span class="o">&amp;&amp;</span> <span class="nb">rm</span> <span class="nt">-rf</span> .vagrant
</code></pre></div></div>

<hr />

<ul>
  <li>💁 참고 : Cilium CMD Cheatsheet
    <ul>
      <li>Cheatsheet - <a href="https://docs.cilium.io/en/stable/cheatsheet/">Docs</a></li>
      <li>CMD References - <a href="https://docs.cilium.io/en/stable/cmdref/">Docs</a></li>
    </ul>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># cilium 파드 이름</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD0</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-ctr <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD1</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-w1  <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD2</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-w2  <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$CILIUMPOD0</span> <span class="nv">$CILIUMPOD1</span> <span class="nv">$CILIUMPOD2</span>
  
<span class="c"># 단축키(alias) 지정</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c0</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD0</span><span class="s2"> -n kube-system -c cilium-agent -- cilium"</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c1</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD1</span><span class="s2"> -n kube-system -c cilium-agent -- cilium"</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c2</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD2</span><span class="s2"> -n kube-system -c cilium-agent -- cilium"</span>
  
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c0bpf</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD0</span><span class="s2"> -n kube-system -c cilium-agent -- bpftool"</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c1bpf</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD1</span><span class="s2"> -n kube-system -c cilium-agent -- bpftool"</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c2bpf</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD2</span><span class="s2"> -n kube-system -c cilium-agent -- bpftool"</span>
  
<span class="c"># endpoint</span>
<span class="nv">$ </span>c0 endpoint list
<span class="nv">$ </span>c0 endpoint list <span class="nt">-o</span> json
<span class="nv">$ </span>c1 endpoint list
<span class="nv">$ </span>c2 endpoint list
  
<span class="nv">$ </span>c1 endpoint get &lt;<span class="nb">id</span><span class="o">&gt;</span>
<span class="nv">$ </span>c1 endpoint log &lt;<span class="nb">id</span><span class="o">&gt;</span>
  
<span class="c">## Enable debugging output on the cilium-dbg monitor for this endpoint</span>
<span class="nv">$ </span>c1 endpoint config &lt;<span class="nb">id</span><span class="o">&gt;</span> <span class="nv">Debug</span><span class="o">=</span><span class="nb">true</span>
  
<span class="c"># monitor</span>
<span class="nv">$ </span>c1 monitor
<span class="nv">$ </span>c1 monitor <span class="nt">-v</span>
<span class="nv">$ </span>c1 monitor <span class="nt">-v</span> <span class="nt">-v</span>
  
<span class="c">## Filter for only the events related to endpoint</span>
<span class="nv">$ </span>c1 monitor <span class="nt">--related-to</span><span class="o">=</span>&lt;<span class="nb">id</span><span class="o">&gt;</span>
  
<span class="c">## Show notifications only for dropped packet events</span>
<span class="nv">$ </span>c1 monitor <span class="nt">--type</span> drop
  
<span class="c">## Don’t dissect packet payload, display payload in hex information</span>
<span class="nv">$ </span>c1 monitor <span class="nt">-v</span> <span class="nt">-v</span> <span class="nt">--hex</span>
  
<span class="c">## Layer7</span>
<span class="nv">$ </span>c1 monitor <span class="nt">-v</span> <span class="nt">--type</span> l7
  
<span class="c"># Manage IP addresses and associated information - IP List</span>
<span class="nv">$ </span>c0 ip list
  
<span class="c"># IDENTITY :  1(host), 2(world), 4(health), 6(remote), 파드마다 개별 ID</span>
<span class="nv">$ </span>c0 ip list <span class="nt">-n</span>
  
<span class="c"># Retrieve information about an identity</span>
<span class="nv">$ </span>c0 identity list
  
<span class="c"># 엔드포인트 기준 ID</span>
<span class="nv">$ </span>c0 identity list <span class="nt">--endpoints</span>
  
<span class="c"># 엔드포인트 설정 확인 및 변경</span>
<span class="nv">$ </span>c0 endpoint config &lt;엔트포인트ID&gt;
  
<span class="c"># 엔드포인트 상세 정보 확인</span>
<span class="nv">$ </span>c0 endpoint get &lt;엔트포인트ID&gt;
  
<span class="c"># 엔드포인트 로그 확인</span>
<span class="nv">$ </span>c0 endpoint log &lt;엔트포인트ID&gt;
  
<span class="c"># Show bpf filesystem mount details</span>
<span class="nv">$ </span>c0 bpf fs show
  
<span class="c"># bfp 마운트 폴더 확인</span>
<span class="nv">$ </span>tree /sys/fs/bpf
  
<span class="c"># Get list of loadbalancer services</span>
<span class="nv">$ </span>c0 service list
<span class="nv">$ </span>c1 service list
<span class="nv">$ </span>c2 service list
  
<span class="c">## Or you can get the loadbalancer information using bpf list</span>
<span class="nv">$ </span>c0 bpf lb list
<span class="nv">$ </span>c1 bpf lb list
<span class="nv">$ </span>c2 bpf lb list
  
<span class="c">## List reverse NAT entries</span>
<span class="nv">$ </span>c1 bpf lb list <span class="nt">--revnat</span>
<span class="nv">$ </span>c2 bpf lb list <span class="nt">--revnat</span>
  
<span class="c"># List connection tracking entries</span>
<span class="nv">$ </span>c0 bpf ct list global
<span class="nv">$ </span>c1 bpf ct list global
<span class="nv">$ </span>c2 bpf ct list global
  
<span class="c"># Flush connection tracking entries</span>
<span class="nv">$ </span>c0 bpf ct flush
<span class="nv">$ </span>c1 bpf ct flush
<span class="nv">$ </span>c2 bpf ct flush
  
<span class="c"># List all NAT mapping entries</span>
<span class="nv">$ </span>c0 bpf nat list
<span class="nv">$ </span>c1 bpf nat list
<span class="nv">$ </span>c2 bpf nat list
  
<span class="c"># Flush all NAT mapping entries</span>
<span class="nv">$ </span>c0 bpf nat flush
<span class="nv">$ </span>c1 bpf nat flush
<span class="nv">$ </span>c2 bpf nat flush
  
<span class="c"># Manage the IPCache mappings for IP/CIDR &lt;-&gt; Identity</span>
<span class="nv">$ </span>c0 bpf ipcache list# Display cgroup metadata maintained by Cilium
<span class="nv">$ </span>c0 cgroups list
<span class="nv">$ </span>c1 cgroups list
<span class="nv">$ </span>c2 cgroups list
  
<span class="c"># List all open BPF maps</span>
<span class="nv">$ </span>c0 map list
<span class="nv">$ </span>c1 map list <span class="nt">--verbose</span>
<span class="nv">$ </span>c2 map list <span class="nt">--verbose</span>
  
<span class="nv">$ </span>c1 map events cilium_lb4_services_v2
<span class="nv">$ </span>c1 map events cilium_lb4_reverse_nat
<span class="nv">$ </span>c1 map events cilium_lxc
<span class="nv">$ </span>c1 map events cilium_ipcache
  
<span class="c"># List all metrics</span>
<span class="nv">$ </span>c1 metrics list
  
<span class="c"># List contents of a policy BPF map : Dump all policy maps</span>
<span class="nv">$ </span>c0 bpf policy get <span class="nt">--all</span>
<span class="nv">$ </span>c1 bpf policy get <span class="nt">--all</span> <span class="nt">-n</span>
<span class="nv">$ </span>c2 bpf policy get <span class="nt">--all</span> <span class="nt">-n</span>
  
<span class="c"># Dump StateDB contents as JSON</span>
<span class="nv">$ </span>c0 statedb dump
  
<span class="c">#</span>
<span class="nv">$ </span>c0 shell <span class="nt">--</span> db/show devices
<span class="nv">$ </span>c1 shell <span class="nt">--</span> db/show devices
<span class="nv">$ </span>c2 shell <span class="nt">--</span> db/show devices 
</code></pre></div>    </div>
  </li>
</ul>]]></content><author><name></name></author><category term="cilium" /><category term="kubernetes," /><category term="network," /><category term="linux," /><category term="cilium" /><summary type="html"><![CDATA[Cilium CNI를 실습하기 위한 환경을 구성하고 Cilium을 설치하는 방법을 알아봅니다.]]></summary></entry><entry><title type="html">MacOS 업데이트 후 Magnet이 자동 시작이 안 될 때 해결 방법</title><link href="https://sweetlittlebird.github.io/posts/2025-06-28-MacOS-%EC%97%85%EB%8D%B0%EC%9D%B4%ED%8A%B8-%ED%9B%84-Magnet%EC%9D%B4-%EC%9E%90%EB%8F%99-%EC%8B%9C%EC%9E%91%EC%9D%B4-%EC%95%88-%EB%90%A0-%EB%95%8C-%ED%95%B4%EA%B2%B0-%EB%B0%A9%EB%B2%95/" rel="alternate" type="text/html" title="MacOS 업데이트 후 Magnet이 자동 시작이 안 될 때 해결 방법" /><published>2025-06-28T10:00:00+09:00</published><updated>2025-06-28T10:00:00+09:00</updated><id>https://sweetlittlebird.github.io/posts/MacOS%20%EC%97%85%EB%8D%B0%EC%9D%B4%ED%8A%B8%20%ED%9B%84%20Magnet%EC%9D%B4%20%EC%9E%90%EB%8F%99%20%EC%8B%9C%EC%9E%91%EC%9D%B4%20%EC%95%88%20%EB%90%A0%20%EB%95%8C%20%ED%95%B4%EA%B2%B0%20%EB%B0%A9%EB%B2%95</id><content type="html" xml:base="https://sweetlittlebird.github.io/posts/2025-06-28-MacOS-%EC%97%85%EB%8D%B0%EC%9D%B4%ED%8A%B8-%ED%9B%84-Magnet%EC%9D%B4-%EC%9E%90%EB%8F%99-%EC%8B%9C%EC%9E%91%EC%9D%B4-%EC%95%88-%EB%90%A0-%EB%95%8C-%ED%95%B4%EA%B2%B0-%EB%B0%A9%EB%B2%95/"><![CDATA[<h2 id="들어가며">들어가며</h2>

<p><img src="/assets/2025/2025-06-28/img.png" alt="img.png" class="w-20 image-center" /></p>

<p>Magnet은 MacOS에서 창 관리를 도와주는 유용한 앱입니다. 
유료 앱이고 Mac App Store에서 구매해야 하지만, 그만한 가치를 제공합니다.
무료로 사용할 수 있는 <a href="https://rectangleapp.com/">Rectangle</a>과 같은 대안도 있지만, 
무상 업데이트를 계속 해주고 있고 Mac App Store에서 구매할 수 있기 때문에 믿을 수 있어서
계속 사용하고 있습니다.</p>

<p>하지만 MacOS 업데이트 후 Magnet이 자동으로 시작되지 않는 문제가 발생할 수 있습니다. 이 글에서는 이 문제를 해결하는 방법을 알아보겠습니다.</p>

<h2 id="문제-발생">문제 발생</h2>

<p>MacOS Ventura에서 Sequoia로 업데이트한 후 Magnet이 기능은 정상적으로 동작하지만,
자동으로 시작되지 않는 문제가 발생했습니다.
시스템 설정에서 
<code class="language-plaintext highlighter-rouge">시스템 설정 &gt; 일반 &gt; 로그인 항목</code>에 Magnet이 등록되어있지 않고 
<code class="language-plaintext highlighter-rouge">시스템 설정 &gt; 일반 &gt; 로그인 항목 &gt; + 버튼</code>을 눌러서 Magnet을 추가해도 추가되지 않았습니다.</p>

<p>수동으로 켜면 되지만 매번 수동으로 켜는 것은 번거롭기 때문에
문제 해결 방법을 찾아보았습니다.</p>

<h2 id="해결-방법">해결 방법</h2>

<p><a href="https://www.reddit.com/r/MacOS/comments/101s7d3/magnet_app_does_not_start_on_boot/">레딧 글</a>에서 해결방법을 찾아서
여기에 남겨 봅니다.</p>

<ol>
  <li>접근성 권한 재설정
    <ul>
      <li>Magnet 종료 → <code class="language-plaintext highlighter-rouge">시스템 설정 &gt; 개인정보 보호 및 보안 &gt; 접근성</code>에서 Magnet 비활성화 및 제거</li>
    </ul>
  </li>
  <li>앱 및 설정 파일 완전 삭제
    <ul>
      <li>Magnet 앱을 응용 프로그램 폴더에서 삭제.</li>
      <li>~/Library/Preferences 폴더에서 com.crowdcafe.windowmagnet.plist 파일 삭제.</li>
      <li>휴지통 비우기 및 Mac 재시동.</li>
    </ul>
  </li>
  <li>앱 재설치 및 권한 재부여
    <ul>
      <li>App Store에서 Magnet 최신 버전 다운로드 및 설치.</li>
      <li>Magnet 실행 후 접근성 권한 요청 시, 반드시 허용.</li>
      <li>Magnet 환경설정에서 ‘로그인 시 자동 실행(Launch at Login)’ 옵션 활성화.</li>
    </ul>
  </li>
  <li>문제 지속 시
    <ul>
      <li>위 과정을 반복해도 문제가 계속된다면, Magnet 개발사에 버그 리포트 제출</li>
    </ul>
  </li>
</ol>

<h2 id="마치며">마치며</h2>

<p>이 방법으로 Magnet이 자동으로 시작되지 않는 문제를 해결할 수 있었습니다.
블로그 글을 쓰다보니 해결하는 방법보다 부가적인 내용을 더 많이 작성한 것 같습니다.
이게 맞나 싶긴한데 반년동안 방치했던 블로그를 다시 시작하는 의미로
작성해봅니다. 다음번에는 더 유익한 글로 찾아뵙기를 기원해봅니다. :pray:</p>

<p>ps. 업데이트 후 Magnet에 설정기능이 굉장히 강력해진것을 발견했습니다.
무상으로 이렇게 좋은 기능을 제공해주다니 개발사에 감사할 따름입니다.</p>

<p><img src="/assets/2025/2025-06-28/20250628_magnet.png" alt="img.png" class="w-80 image-center" /></p>]]></content><author><name></name></author><category term="macos," /><category term="troubleshooting" /><category term="macos," /><category term="magnet," /><category term="troubleshooting" /><summary type="html"><![CDATA[Magnet은 MacOS에서 창 관리를 도와주는 유용한 앱입니다. MacOS 업데이트 후 Magnet이 자동으로 시작되지 않는 문제를 해결하는 방법을 알아봅니다.]]></summary></entry><entry><title type="html">[CI/CD] Jenkins CI/ArgoCD + K8S</title><link href="https://sweetlittlebird.github.io/posts/2024-12-22-CICD-Lite-Week3/" rel="alternate" type="text/html" title="[CI/CD] Jenkins CI/ArgoCD + K8S" /><published>2024-12-22T00:01:18+09:00</published><updated>2024-12-22T00:01:18+09:00</updated><id>https://sweetlittlebird.github.io/posts/CICD%20Lite%20-%20Week3</id><content type="html" xml:base="https://sweetlittlebird.github.io/posts/2024-12-22-CICD-Lite-Week3/"><![CDATA[<h2 id="들어가며">들어가며</h2>

<p>이번 주에는 ArgoCD와 Jenkins를 사용하여 Kubernetes로의 배포를 하는 CI/CD를 구성해보겠습니다.</p>

<h2 id="jenkins-ciargocd--k8s">Jenkins CI/ArgoCD + K8S</h2>

<h3 id="실습환경-구성">실습환경 구성</h3>

<ul>
  <li>이번에는 개발 PC에 Jenkins와 Gogs를 설치하고, Kind를 사용하여 Kubernetes 클러스터를 구성하고 ArgoCD를 설치하여 CI/CD를 구성해보겠습니다.</li>
</ul>

<h4 id="jenkins-gogs-설치">Jenkins, Gogs 설치</h4>

<ul>
  <li>Jenkins의 경우 1주차에서 설치하였지만 다시 한번 되짚어 보겠습니다.</li>
  <li>또한 이번에는 Gitlab 클라우드 서비스 대신, 자체 PC에 Gogs를 설치하여 사용해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 작업 디렉토리 생성 후 이동</span>
<span class="nv">$ </span><span class="nb">mkdir </span>cicd-labs
<span class="nv">$ </span><span class="nb">cd </span>cicd-labs

<span class="c"># </span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh"> &gt; docker-compose.yaml
services:

  jenkins:
    container_name: jenkins
    image: jenkins/jenkins
    restart: unless-stopped
    networks:
      - cicd-network
    ports:
      - "8080:8080"
      - "50000:50000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - jenkins_home:/var/jenkins_home

  gogs:
    container_name: gogs
    image: gogs/gogs
    restart: unless-stopped
    networks:
      - cicd-network
    ports:
      - "10022:22"
      - "3000:3000"
    volumes:
      - gogs-data:/data

volumes:
  jenkins_home:
  gogs-data:

networks:
  cicd-network:
    driver: bridge
</span><span class="no">EOT


</span><span class="c"># 배포</span>
<span class="nv">$ </span>docker compose up <span class="nt">-d</span>
<span class="c"># =&gt; [+] Running 2/2</span>
<span class="c">#     ⠿ Container jenkins  Started  0.5s</span>
<span class="c">#     ⠿ Container gogs     Started  0.5s</span>
<span class="nv">$ </span>docker compose ps
<span class="c"># =&gt; NAME                COMMAND                  SERVICE             STATUS              PORTS</span>
<span class="c">#    gogs                &amp;quot;/app/gogs/docker/st…&amp;quot;   gogs                running (healthy)   0.0.0.0:10022-&amp;gt;22/tcp, 0.0.0.0:3000-&amp;gt;3000/tcp</span>
<span class="c">#    jenkins             &amp;quot;/usr/bin/tini -- /u…&amp;quot;   jenkins             running             0.0.0.0:8080-&amp;gt;8080/tcp, 0.0.0.0:50000-&amp;gt;50000/tcp</span>

<span class="c"># 기본 정보 확인</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>gogs jenkins <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; container : </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker compose <span class="nb">exec</span> <span class="nv">$i</span> sh <span class="nt">-c</span> <span class="s2">"whoami &amp;&amp; pwd"</span><span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; container : gogs &amp;lt;&amp;lt;</span>
<span class="c">#    root</span>
<span class="c">#    /app/gogs</span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; container : jenkins &amp;lt;&amp;lt;</span>
<span class="c">#    jenkins</span>
<span class="c">#    /</span>

<span class="c"># 도커를 이용하여 각 컨테이너로 접속</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins bash
<span class="nv">$ </span><span class="nb">exit</span>

<span class="nv">$ </span>docker compose <span class="nb">exec </span>gogs bash
<span class="nv">$ </span><span class="nb">exit</span>
</code></pre></div></div>

<h4 id="jenkins-컨테이너-초기설정">Jenkins 컨테이너 초기설정</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Jenkins 초기 암호 확인</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins <span class="nb">cat</span> /var/jenkins_home/secrets/initialAdminPassword
<span class="c"># =&gt; 3da38dccc7d14d1a8bee4b02c4e09da8</span>

<span class="c"># Jenkins 웹 접속 주소 확인 : 계정 / 암호 입력 &gt;&gt; **admin / qwe123**</span>
<span class="nv">$ </span>open <span class="s2">"http://127.0.0.1:8080"</span> <span class="c"># macOS</span>

<span class="c"># (참고) 로그 확인 : 플러그인 설치 과정 확인</span>
<span class="nv">$ </span>docker compose logs jenkins <span class="nt">-f</span>

<span class="c"># IP 확인 (MacOS 기준)</span>
<span class="nv">$ </span>ifconfig | <span class="nb">grep</span> <span class="s2">"inet "</span> | <span class="nb">grep</span> <span class="nt">-v</span> 127.0.0
<span class="c"># =&gt; inet &lt;span style="color: red;"&gt;10.0.4.3&lt;/span&gt; netmask 0xffffff00 broadcast 10.0.4.255</span>
<span class="c"># 또는</span>
<span class="nv">$ </span>ipconfig getifaddr en0
<span class="c"># =&gt; &lt;span style="color: red;"&gt;10.0.4.3&lt;/span&gt;</span>
</code></pre></div></div>

<ul>
  <li>Jenkins URL 설정</li>
</ul>

<p>앞서 확인한 IP 주소를 이용하여 Jenkins URL을 설정합니다.</p>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_1.png" alt="img.png" /></p>

<ul>
  <li>1주차때와 마찬가지로 Docker-out-of-Docker를 사용하겠습니다. 자세한 내용은 <a href="https://sweetlittlebird.github.io/posts/2024-12-08-CICD-Lite-Week1/#jenkins-%EC%86%8C%EA%B0%9C">1주차 내용</a>을 참고하세요.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Jenkins 컨테이너 내부에 도커 실행 파일 설치</span>
<span class="nv">$ </span>docker compose <span class="nb">exec</span> <span class="nt">--privileged</span> <span class="nt">-u</span> root jenkins bash
<span class="nt">-----------------------------------------------------</span>
<span class="nv">$ </span><span class="nb">id</span>

<span class="nv">$ </span>curl <span class="nt">-fsSL</span> https://download.docker.com/linux/debian/gpg <span class="nt">-o</span> /etc/apt/keyrings/docker.asc
<span class="c"># =&gt; uid=0(root) gid=0(root) groups=0(root)</span>
<span class="nv">$ </span><span class="nb">chmod </span>a+r /etc/apt/keyrings/docker.asc
<span class="nv">$ </span><span class="nb">echo</span> <span class="se">\</span>
  <span class="s2">"deb [arch=</span><span class="si">$(</span>dpkg <span class="nt">--print-architecture</span><span class="si">)</span><span class="s2"> signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/debian </span><span class="se">\</span><span class="s2">
  </span><span class="si">$(</span><span class="nb">.</span> /etc/os-release <span class="o">&amp;&amp;</span> <span class="nb">echo</span> <span class="s2">"</span><span class="nv">$VERSION_CODENAME</span><span class="s2">"</span><span class="si">)</span><span class="s2"> stable"</span> | <span class="se">\</span>
  <span class="nb">tee</span> /etc/apt/sources.list.d/docker.list <span class="o">&gt;</span> /dev/null
<span class="nv">$ </span>apt-get update <span class="o">&amp;&amp;</span> apt <span class="nb">install </span>docker-ce-cli curl tree jq yq <span class="nt">-y</span>

<span class="nv">$ </span>docker info
<span class="c"># =&gt; Client: Docker Engine - Community</span>
<span class="c">#     Version:    27.4.1</span>
<span class="c">#     Context:    default</span>
<span class="c">#     Debug Mode: false</span>
<span class="c">#     Plugins:</span>
<span class="c">#      buildx: Docker Buildx (Docker Inc.)</span>
<span class="c">#        Version:  v0.19.3</span>
<span class="c">#        Path:     /usr/libexec/docker/cli-plugins/docker-buildx</span>
<span class="c">#      compose: Docker Compose (Docker Inc.)</span>
<span class="c">#        Version:  v2.32.1</span>
<span class="c">#        Path:     /usr/libexec/docker/cli-plugins/docker-compose</span>
<span class="c">#    </span>
<span class="c">#    Server:</span>
<span class="c">#     Containers: 29</span>
<span class="c">#      Running: 2</span>
<span class="c">#      Paused: 0</span>
<span class="c">#      Stopped: 27</span>
<span class="c">#     Images: 42</span>
<span class="c">#     Server Version: 20.10.12</span>
<span class="c">#     Storage Driver: overlay2</span>
<span class="c">#      Backing Filesystem: extfs</span>
<span class="c">#      Supports d_type: true</span>
<span class="c">#      Native Overlay Diff: true</span>
<span class="c">#      userxattr: false</span>
<span class="c">#     Logging Driver: json-file</span>
<span class="c">#     Cgroup Driver: cgroupfs</span>
<span class="c">#     Cgroup Version: 2</span>
<span class="c">#     ...</span>
<span class="c">#     Insecure Registries:</span>
<span class="c">#      hubproxy.docker.internal:5000</span>
<span class="c">#      127.0.0.0/8</span>
<span class="c">#     Live Restore Enabled: false</span>
<span class="nv">$ </span>docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE             COMMAND                  CREATED        STATUS                    PORTS                                              NAMES</span>
<span class="c">#    110494b9ca48   gogs/gogs         &amp;quot;/app/gogs/docker/st…&amp;quot;   14 hours ago   Up 37 minutes (healthy)   0.0.0.0:3000-&amp;gt;3000/tcp, 0.0.0.0:10022-&amp;gt;22/tcp      gogs</span>
<span class="c">#    8b7c591c828d   jenkins/jenkins   &amp;quot;/usr/bin/tini -- /u…&amp;quot;   14 hours ago   Up 37 minutes             0.0.0.0:8080-&amp;gt;8080/tcp, 0.0.0.0:50000-&amp;gt;50000/tcp   jenkins</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 DooD이기 때문에 호스트에서 동작중인 컨테이너가 보입니다.&lt;/span&gt;</span>
<span class="nv">$ </span>which docker
<span class="c"># =&gt; /usr/bin/docker</span>

<span class="c"># Jenkins 컨테이너 내부에서 root가 아닌 jenkins 유저도 docker를 실행할 수 있도록 권한을 부여</span>
<span class="nv">$ </span>groupadd <span class="nt">-g</span> 2000 <span class="nt">-f</span> docker  <span class="c"># macOS(Container)</span>
<span class="c"># $ groupadd -g 1001 -f docker  # Windows WSL2(Container) &gt;&gt; cat /etc/group 에서 docker 그룹ID를 지정</span>

<span class="nv">$ </span><span class="nb">chgrp </span>docker /var/run/docker.sock
<span class="nv">$ </span><span class="nb">chmod </span>g+w /var/run/docker.sock
<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-l</span> /var/run/docker.sock
<span class="c"># =&gt; srwxrwxr-x 1 root docker 0 Oct 01 06:03 /var/run/docker.sock</span>
<span class="nv">$ </span>usermod <span class="nt">-aG</span> docker jenkins
<span class="nv">$ </span><span class="nb">cat</span> /etc/group | <span class="nb">grep </span>docker
<span class="c"># =&gt; docker:x:2000:jenkins</span>

<span class="nb">exit</span>
<span class="nt">--------------------------------------------</span>

<span class="c"># jenkins item 실행 시 docker 명령 실행 권한 에러 발생 : Jenkins 컨테이너 재기동으로 위 설정 내용을 Jenkins app 에도 적용 필요</span>
<span class="nv">$ </span>docker compose restart jenkins
<span class="c"># =&gt; [+] Running 1/1</span>
<span class="c">#     ⠿ Container jenkins  Started    0.9s</span>
<span class="c"># $ sudo docker compose restart jenkins  # Windows 경우 이후부터 sudo 붙여서 실행하자</span>

<span class="c"># jenkins user로 docker 명령 실행 확인</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins <span class="nb">id</span>
<span class="c"># =&gt; uid=1000(jenkins) gid=1000(jenkins) groups=1000(jenkins),2000(docker)</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins docker info
<span class="c"># =&gt; Client: Docker Engine - Community</span>
<span class="c">#     Version:    27.4.1</span>
<span class="c">#     ...</span>
<span class="c">#    </span>
<span class="c">#    Server:</span>
<span class="c">#     Containers: 29</span>
<span class="c">#      Running: 2</span>
<span class="c">#      Paused: 0</span>
<span class="c">#      Stopped: 27</span>
<span class="c">#     Images: 42</span>
<span class="c">#     Server Version: 20.10.12</span>
<span class="c">#     ...</span>
<span class="c">#     Live Restore Enabled: false</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE             COMMAND                  CREATED        STATUS                    PORTS                                              NAMES</span>
<span class="c">#    110494b9ca48   gogs/gogs         &amp;quot;/app/gogs/docker/st…&amp;quot;   14 hours ago   Up 41 minutes (healthy)   0.0.0.0:3000-&amp;gt;3000/tcp, 0.0.0.0:10022-&amp;gt;22/tcp      gogs</span>
<span class="c">#    8b7c591c828d   jenkins/jenkins   &amp;quot;/usr/bin/tini -- /u…&amp;quot;   14 hours ago   Up 57 seconds             0.0.0.0:8080-&amp;gt;8080/tcp, 0.0.0.0:50000-&amp;gt;50000/tcp   jenkins</span>
</code></pre></div></div>

<ul>
  <li>OS 재부팅시에 jenkins 컨테이너에서 docker 실행이 실패하는 경우가 있는데, 그럴 경우 아래와 같이 docker 그룹을 다시 지정합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 소켓 파일의 권한 확인</span>
<span class="nv">$ </span>docker compose <span class="nb">exec</span> <span class="nt">--privileged</span> <span class="nt">-u</span> root jenkins <span class="nb">ls</span> <span class="nt">-l</span> /var/run/docker.sock
<span class="c"># =&gt; srwxr-xr-x 1 root root 0 Oct 01 05:22 /var/run/docker.sock</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 그룹이 root로 복구되어있습니다. docker 그룹으로 다시 변경해야 합니다.&lt;/span&gt;</span>

<span class="c"># 소켓 파일에 docker 그룹을 다시 지정</span>
<span class="nv">$ </span>docker compose <span class="nb">exec</span> <span class="nt">--privileged</span> <span class="nt">-u</span> root jenkins <span class="nb">chgrp </span>docker /var/run/docker.sock

<span class="c"># 소켓 파일에 docker 그룹 쓰기권한 다시 지정</span>
<span class="nv">$ </span>docker compose <span class="nb">exec</span> <span class="nt">--privileged</span> <span class="nt">-u</span> root jenkins <span class="nb">chmod </span>g+w /var/run/docker.sock

<span class="c"># 확인</span>
<span class="nv">$ </span>docker compose <span class="nb">exec</span> <span class="nt">--privileged</span> <span class="nt">-u</span> root jenkins <span class="nb">ls</span> <span class="nt">-l</span> /var/run/docker.sock
<span class="c"># =&gt; srwxrwxr-x 1 root docker 0 Oct 01 05:22 /var/run/docker.sock</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins docker info
</code></pre></div></div>

<h4 id="gogs-초기-설정">Gogs 초기 설정</h4>

<ul>
  <li>초기설정을 위해 웹 접속을 합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 초기 설정 웹 접속</span>
<span class="nv">$ </span>open <span class="s2">"http://127.0.0.1:3000/install"</span> <span class="c"># macOS</span>
<span class="c"># 웹 브라우저에서 http://127.0.0.1:3000/install 접속 # Windows</span>
</code></pre></div></div>

<ul>
  <li>다음과 같이 설정값을 변경합니다.
    <ul>
      <li>Database Type : SQLite3</li>
      <li>Application URL : <code class="language-plaintext highlighter-rouge">http://&lt;앞에서 확인한 IP&gt;:3000/</code></li>
      <li>Default Branch : main</li>
      <li>관리자 계정 설정 클릭 : username : devops, password : qwe123, email입력
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_2.png" alt="img.png" /></li>
    </ul>
  </li>
  <li>Install Gogs 버튼 클릭 =&gt; 관리자 계정으로 로그인</li>
</ul>

<h5 id="access-token-발행">Access Token 발행</h5>

<ul>
  <li>로그인 후 Your Settings &gt; Applications &gt; Generate New Token 클릭 &gt; Token Name(devops) &gt; Generate Token 클릭하여 토큰을 발행합니다.</li>
  <li>발행된 토큰(<code class="language-plaintext highlighter-rouge">a85f33b7fd28ac1ed83c3233fc4ca3a67c04c296</code>)을 복사하여 안전한 곳에 기록해둡니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_3.png" alt="img.png" /></p>

<h5 id="repository-생성">Repository 생성</h5>

<ul>
  <li>우측상단의 <code class="language-plaintext highlighter-rouge">+</code> 버튼을 클릭하여 나오는 메뉴에서 New Repository를 클릭해서 새로운 Repository를 다음과 같이 2개 생성합니다.</li>
  <li><strong>개발팀용</strong>
    <ul>
      <li>Repository Name : <strong>dev-app</strong></li>
      <li>Visibility : (<strong>Check</strong>) This repository is <strong>Private</strong></li>
      <li>.gitignore : <strong>Python</strong></li>
      <li>Readme : Default → (Check) initialize this repository with selected files and template</li>
    </ul>

    <p>⇒ Create Repository 클릭 =&gt; Repo 주소 확인 (<code class="language-plaintext highlighter-rouge">http://10.0.4.3:3000/devops/dev-apps.git</code>)</p>
  </li>
  <li><strong>데브옵스팀용</strong>
    <ul>
      <li>Repository Name : <strong>ops-deploy</strong></li>
      <li>Visibility : (<strong>체크</strong>) This repository is <strong>Private</strong></li>
      <li>Readme : Default → (체크) initialize this repository with selected files and template</li>
    </ul>

    <p>⇒ Create Repository 클릭 =&gt; Repo 주소 확인 (<code class="language-plaintext highlighter-rouge">http://10.0.4.3:3000/devops/ops-deploy.git</code>)</p>
  </li>
</ul>

<h5 id="gogs-실습을-위해-호스트-pc의-git-설정">Gogs 실습을 위해 호스트 PC의 git 설정</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># (옵션) GIT 인증 정보 초기화</span>
<span class="nv">$ </span>git credential-cache <span class="nb">exit</span>

<span class="c">#</span>
<span class="c"># $ git clone &lt;각자 Gogs dev-app repo 주소&gt;</span>
<span class="nv">$ </span>git clone http://10.0.4.3:3000/devops/dev-app.git
<span class="c"># =&gt; Cloning into 'dev-app'...</span>
<span class="c">#    Username for 'http://10.0.4.3:3000': devops</span>
<span class="c">#    Password for 'http://a@10.0.4.3:3000': # &lt;span style="color: green;"&gt;앞서 발급받은 access key 입력&lt;/span&gt;</span>

<span class="c">#    remote: Enumerating objects: 4, done.</span>
<span class="c">#    remote: Counting objects: 100% (4/4), done.</span>
<span class="c">#    remote: Compressing objects: 100% (3/3), done.</span>
<span class="c">#    remote: Total 4 (delta 0), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    Unpacking objects: 100% (4/4), 705 bytes | 352.00 KiB/s, done.</span>

<span class="c">#</span>
<span class="nv">$ </span><span class="nb">cd </span>dev-app

<span class="c">#</span>
<span class="nv">$ </span>git config user.name <span class="s2">"devops"</span>
<span class="nv">$ </span>git config user.email <span class="s2">"a@a.com"</span>
<span class="nv">$ </span>git config init.defaultBranch main
<span class="nv">$ </span>git config credential.helper store

<span class="c">#</span>
<span class="nv">$ </span>git branch
<span class="c"># =&gt; * main</span>
<span class="nv">$ </span>git remote <span class="nt">-v</span>
<span class="c"># =&gt; origin  http://10.0.4.3:3000/devops/dev-app.git (fetch)</span>
<span class="c">#    origin  http://10.0.4.3:3000/devops/dev-app.git (push)</span>

<span class="c"># server.py 파일 작성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> server.py <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
from http.server import ThreadingHTTPServer, BaseHTTPRequestHandler
from datetime import datetime
import socket

class RequestHandler(BaseHTTPRequestHandler):
    def do_GET(self):
        self.send_response(200)
        self.send_header('Content-type', 'text/plain')
        self.end_headers()
        
        now = datetime.now()
        hostname = socket.gethostname()
        response_string = now.strftime("The time is %-I:%M:%S %p, VERSION 0.0.1</span><span class="se">\n</span><span class="sh">")
        response_string += f"Server hostname: {hostname}</span><span class="se">\n</span><span class="sh">"
        self.wfile.write(bytes(response_string, "utf-8")) 

def startServer():
    try:
        server = ThreadingHTTPServer(('', 80), RequestHandler)
        print("Listening on " + ":".join(map(str, server.server_address)))
        server.serve_forever()
    except KeyboardInterrupt:
        server.shutdown()

if __name__ == "__main__":
    startServer()
</span><span class="no">EOF

</span><span class="c"># Dockerfile 생성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Dockerfile <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
FROM python:3.12
ENV PYTHONUNBUFFERED 1
COPY . /app
WORKDIR /app 
CMD python3 server.py
</span><span class="no">EOF

</span><span class="c"># VERSION 파일 생성</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"0.0.1"</span> <span class="o">&gt;</span> VERSION

<span class="c">#</span>
<span class="nv">$ </span>git status
<span class="c"># =&gt; On branch main</span>
<span class="c">#    Your branch is up to date with 'origin/main'.</span>
<span class="c">#    </span>
<span class="c">#    Untracked files:</span>
<span class="c">#      (use &amp;quot;git add &amp;lt;file&amp;gt;...&amp;quot; to include in what will be committed)</span>
<span class="c">#            Dockerfile</span>
<span class="c">#            VERSION</span>
<span class="c">#            server.py</span>
<span class="c">#    </span>
<span class="c">#    nothing added to commit but untracked files present (use &amp;quot;git add&amp;quot; to track)</span>
<span class="nv">$ </span>git add <span class="nb">.</span>
<span class="nv">$ </span>git commit <span class="nt">-m</span> <span class="s2">"Add dev-app"</span>
<span class="c"># =&gt; [main 3531233] Add dev-app</span>
<span class="c">#     3 files changed, 32 insertions(+)</span>
<span class="c">#     create mode 100644 Dockerfile</span>
<span class="c">#     create mode 100644 VERSION</span>
<span class="c">#     create mode 100644 server.py</span>
<span class="nv">$ </span>git push <span class="nt">-u</span> origin main
<span class="c"># =&gt; Enumerating objects: 6, done.</span>
<span class="c">#    Counting objects: 100% (6/6), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (4/4), done.</span>
<span class="c">#    Writing objects: 100% (5/5), 900 bytes | 900.00 KiB/s, done.</span>
<span class="c">#    Total 5 (delta 0), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To http://10.0.4.3:3000/devops/dev-app.git</span>
<span class="c">#       5c906c3..3531233  main -&amp;gt; main</span>
<span class="c">#    branch 'main' set up to track 'origin/main'.</span>
</code></pre></div></div>

<ul>
  <li>Gogs Repo에서 확인
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_4.png" alt="img.png" /></li>
</ul>

<h4 id="도커-허브--설정">도커 허브  설정</h4>

<ul>
  <li>도커 허브에 로그인하여 dev-app이라는 Repository를 생성합니다. 도커허브 소개와 Repository 생성은 <a href="https://sweetlittlebird.github.io/posts/2024-12-08-CICD-Lite-Week1/#docker-hub-%EC%86%8C%EA%B0%9C">1주차 내용</a>을 참고하세요.</li>
  <li>배포를 편하게 하기위해 Token도 발급하여 사용해보겠습니다.
    <ol>
      <li>계정 &gt; Account Settings &gt; Security 클릭
  <img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_5.png" alt="img.png" class="image-center" /></li>
      <li>New Access Token 클릭
        <ul>
          <li>Token Name : devops</li>
          <li>Expireation date : 만료일을 적절히 선택합니다.</li>
          <li>권한은 Read, Write, Delete를 선택합니다.</li>
          <li>Create 클릭하여 토큰을 생성하고, 발급된 토큰을 복사하여 안전한 곳에 저장합니다.
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_6.png" alt="img.png" class="image-center" />
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_7.png" alt="img_1.png" class="image-center" /></li>
          <li>발급된 토큰 : <code class="language-plaintext highlighter-rouge">dckr_****</code></li>
        </ul>
      </li>
    </ol>
  </li>
</ul>

<hr />

<h3 id="jenkins-ci--k8s-kind">Jenkins CI + K8S (Kind)</h3>

<h4 id="kind-소개-및-설치">Kind 소개 및 설치</h4>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_8.png" alt="img.png" class="w-20 image-center" /></p>

<ul>
  <li>Kind는 Kubernetes in Docker의 줄임말로, 로컬 환경에서 쉽게 Kubernetes 클러스터를 구성할 수 있도록 도와주는 도구입니다.</li>
  <li>이름처럼 Docker를 이용하여 Kubernetes 클러스터를 구성하며, Docker를 이용하기 때문에 다양한 환경에서 쉽게 사용할 수 있습니다.</li>
  <li>Kind는 HA를 포함한 멀티노드를 지원하지만, 테스트와 실험적인 목적으로만 사용하기를 추천합니다.</li>
  <li>Kind는 클러스터를 구성하기 위해 kubeadm을 사용합니다.</li>
  <li><a href="https://sweetlittlebird.github.io/posts/2024-09-07-KANS-Study-Week2/#kind-%EC%86%8C%EA%B0%9C-%EB%B0%8F-%EC%84%A4%EC%B9%98">Kind 소개 및 설치</a>, <a href="https://kind.sigs.k8s.io/docs/user/quick-start/">Kind 공식문서</a></li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_9.png" alt="img.png" class="image-center" />
<em class="image-caption">Kind 구성도</em></p>

<h5 id="kind-및-툴-설치">Kind 및 툴 설치</h5>

<ul>
  <li>필수 툴 설치</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Install Kind</span>
<span class="nv">$ </span>brew <span class="nb">install </span>kind
<span class="nv">$ </span>kind <span class="nt">--version</span>
<span class="c"># =&gt; kind version 0.26.0</span>

<span class="c"># Install kubectl</span>
<span class="nv">$ </span>brew <span class="nb">install </span>kubernetes-cli
<span class="nv">$ </span>kubectl version <span class="nt">--client</span><span class="o">=</span><span class="nb">true</span>
<span class="c"># =&gt; Client Version: v1.31.0</span>
<span class="c">#    Kustomize Version: v5.4.2</span>
<span class="c">#    Kubecolor Version: v0.4.0</span>

<span class="c">## kubectl -&gt; k 단축키 설정</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"alias kubectl=kubecolor"</span> <span class="o">&gt;&gt;</span> ~/.zshrc

<span class="c"># Install Helm</span>
<span class="nv">$ </span>brew <span class="nb">install </span>helm
<span class="nv">$ </span>helm version
<span class="c"># =&gt; version.BuildInfo{Version:&amp;quot;v3.15.4&amp;quot;, GitCommit:&amp;quot;fa9efb07d9d8debbb4306d72af76a383895aa8c4&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;, GoVersion:&amp;quot;go1.22.6&amp;quot;}</span>
</code></pre></div></div>

<ul>
  <li>(권장) 유용한 툴 설치</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 툴 설치</span>
<span class="nv">$ </span>brew <span class="nb">install </span>krew
<span class="nv">$ </span>brew <span class="nb">install </span>kube-ps1
<span class="nv">$ </span>brew <span class="nb">install </span>kubectx

<span class="c"># kubectl 출력 시 하이라이트 처리</span>
<span class="nv">$ </span>brew <span class="nb">install </span>kubecolor
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"alias kubectl=kubecolor"</span> <span class="o">&gt;&gt;</span> ~/.zshrc
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"compdef kubecolor=kubectl"</span> <span class="o">&gt;&gt;</span> ~/.zshrc

<span class="c"># krew 플러그인 설치</span>
<span class="nv">$ </span>kubectl krew <span class="nb">install </span>neat stren
</code></pre></div></div>

<h5 id="kind-기본-사용---클러스터-배포-및-확인">Kind 기본 사용 - 클러스터 배포 및 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 클러스터 배포 전 확인</span>
<span class="nv">$ </span>docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE             COMMAND                  CREATED        STATUS                 PORTS                                              NAMES</span>
<span class="c">#    110494b9ca48   gogs/gogs         &amp;quot;/app/gogs/docker/st…&amp;quot;   19 hours ago   Up 5 hours (healthy)   0.0.0.0:3000-&amp;gt;3000/tcp, 0.0.0.0:10022-&amp;gt;22/tcp      gogs</span>
<span class="c">#    8b7c591c828d   jenkins/jenkins   &amp;quot;/usr/bin/tini -- /u…&amp;quot;   19 hours ago   Up 4 hours             0.0.0.0:8080-&amp;gt;8080/tcp, 0.0.0.0:50000-&amp;gt;50000/tcp   jenkins</span>

<span class="c"># Create a cluster with kind</span>
<span class="nv">$ </span>kind create cluster
<span class="c"># =&gt; Creating cluster &amp;quot;kind&amp;quot; ...</span>
<span class="c">#     ✓ Ensuring node image (kindest/node:v1.32.0) 🖼</span>
<span class="c">#     ✓ Preparing nodes 📦</span>
<span class="c">#     ✓ Writing configuration 📜</span>
<span class="c">#     ✓ Starting control-plane 🕹️</span>
<span class="c">#     ✓ Installing CNI 🔌</span>
<span class="c">#     ✓ Installing StorageClass 💾</span>
<span class="c">#    Set kubectl context to &amp;quot;kind-kind&amp;quot;</span>
<span class="c">#    You can now use your cluster with:</span>
<span class="c">#    </span>
<span class="c">#    kubectl cluster-info --context kind-kind</span>
<span class="c">#    </span>
<span class="c">#    Not sure what to do next? 😅  Check out https://kind.sigs.k8s.io/docs/user/quick-start/</span>

<span class="c"># 클러스터 배포 확인</span>
<span class="nv">$ </span>kind get clusters
<span class="c"># =&gt; kind</span>
<span class="nv">$ </span>kind get nodes
<span class="c"># =&gt; kind-control-plane</span>
<span class="nv">$ </span>kubectl cluster-info
<span class="c"># =&gt; Kubernetes control plane is running at https://127.0.0.1:64234</span>
<span class="c">#    CoreDNS is running at https://127.0.0.1:64234/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</span>
<span class="c">#    </span>
<span class="c">#    To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.</span>

<span class="c"># 노드 정보 확인</span>
<span class="nv">$ </span>kubectl get node <span class="nt">-o</span> wide
<span class="c"># =&gt; NAME                 STATUS   ROLES           AGE   VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE                         KERNEL-VERSION     CONTAINER-RUNTIME</span>
<span class="c">#    kind-control-plane   Ready    control-plane   63s   v1.32.0   172.20.0.2    &amp;lt;none&amp;gt;        Debian GNU/Linux 12 (bookworm)   5.10.76-linuxkit   containerd://1.7.24</span>

<span class="c"># 파드 정보 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE            NAME                                         READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    kube-system          coredns-668d6bf9bc-8pqmk                     1/1     Running   0          67s</span>
<span class="c">#    kube-system          coredns-668d6bf9bc-9ngw2                     1/1     Running   0          67s</span>
<span class="c">#    kube-system          etcd-kind-control-plane                      1/1     Running   0          74s</span>
<span class="c">#    kube-system          kindnet-zlwz2                                1/1     Running   0          67s</span>
<span class="c">#    kube-system          kube-apiserver-kind-control-plane            1/1     Running   0          74s</span>
<span class="c">#    kube-system          kube-controller-manager-kind-control-plane   1/1     Running   0          74s</span>
<span class="c">#    kube-system          kube-proxy-nbp2t                             1/1     Running   0          67s</span>
<span class="c">#    kube-system          kube-scheduler-kind-control-plane            1/1     Running   0          74s</span>
<span class="c">#    local-path-storage   local-path-provisioner-58cc7856b6-wl6z8      1/1     Running   0          67s</span>
<span class="nv">$ </span>kubectl get componentstatuses
<span class="c"># =&gt; NAME                 STATUS    MESSAGE   ERROR</span>
<span class="c">#    controller-manager   Healthy   ok</span>
<span class="c">#    scheduler            Healthy   ok</span>
<span class="c">#    etcd-0               Healthy   ok</span>

<span class="c"># 컨트롤플레인 (컨테이너) 노드 1대가 실행</span>
<span class="nv">$ </span>docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE                  COMMAND                  CREATED              STATUS                 PORTS                                              NAMES</span>
<span class="c">#    3d4063180754   kindest/node:v1.32.0   &amp;quot;/usr/local/bin/entr…&amp;quot;   About a minute ago   Up About a minute      127.0.0.1:64234-&amp;gt;6443/tcp                          kind-control-plane</span>
<span class="c">#    110494b9ca48   gogs/gogs              &amp;quot;/app/gogs/docker/st…&amp;quot;   19 hours ago         Up 5 hours (healthy)   0.0.0.0:3000-&amp;gt;3000/tcp, 0.0.0.0:10022-&amp;gt;22/tcp      gogs</span>
<span class="c">#    8b7c591c828d   jenkins/jenkins        &amp;quot;/usr/bin/tini -- /u…&amp;quot;   19 hours ago         Up 4 hours             0.0.0.0:8080-&amp;gt;8080/tcp, 0.0.0.0:50000-&amp;gt;50000/tcp   jenkins</span>
<span class="nv">$ </span>docker images
<span class="c"># =&gt; REPOSITORY                                                                   TAG           IMAGE ID       CREATED         SIZE</span>
<span class="c">#    kindest/node                                                                 &amp;lt;none&amp;gt;        b5a8f8764a3e   7 days ago      1.05GB</span>

<span class="c"># kube config 파일 확인</span>
<span class="nv">$ </span><span class="nb">cat</span> ~/.kube/config
<span class="c"># 혹은</span>
<span class="c"># $ cat $KUBECONFIG # KUBECONFIG 변수 지정 사용 시</span>

<span class="c"># nginx 파드 배포 및 확인 : 컨트롤플레인 노드인데 파드가 배포 될까요?</span>
<span class="nv">$ </span>kubectl run nginx <span class="nt">--image</span><span class="o">=</span>nginx:alpine
<span class="c"># =&gt; pod/nginx created</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME    READY   STATUS    RESTARTS   AGE   IP           NODE                 NOMINATED NODE   READINESS GATES</span>
<span class="c">#    nginx   1/1     Running   0          10s   10.244.0.5   kind-control-plane   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>

<span class="c"># 노드에 Taints 정보 확인</span>
<span class="nv">$ </span>kubectl describe node | <span class="nb">grep </span>Taints
<span class="c"># =&gt; Taints:             &amp;lt;none&amp;gt;</span>

<span class="c"># 클러스터 삭제</span>
<span class="nv">$ </span>kind delete cluster
<span class="c"># =&gt; Deleting cluster &amp;quot;kind&amp;quot; ...</span>
<span class="c">#    Deleted nodes: [&amp;quot;kind-control-plane&amp;quot;]</span>

<span class="c"># kube config 삭제 확인</span>
<span class="nv">$ </span><span class="nb">cat</span> ~/.kube/config
<span class="c"># 혹은</span>
<span class="c"># $ cat $KUBECONFIG # KUBECONFIG 변수 지정 사용 시</span>
</code></pre></div></div>

<h4 id="kind로-kubernetes-클러스터-배포---3노드">Kind로 Kubernetes 클러스터 배포 - 3노드</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 클러스터 배포 전 확인</span>
<span class="nv">$ </span>docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE             COMMAND                  CREATED        STATUS                 PORTS                                              NAMES</span>
<span class="c">#    110494b9ca48   gogs/gogs         &amp;quot;/app/gogs/docker/st…&amp;quot;   19 hours ago   Up 5 hours (healthy)   0.0.0.0:3000-&amp;gt;3000/tcp, 0.0.0.0:10022-&amp;gt;22/tcp      gogs</span>
<span class="c">#    8b7c591c828d   jenkins/jenkins   &amp;quot;/usr/bin/tini -- /u…&amp;quot;   19 hours ago   Up 4 hours             0.0.0.0:8080-&amp;gt;8080/tcp, 0.0.0.0:50000-&amp;gt;50000/tcp   jenkins</span>

<span class="c"># 방안1 : 환경변수 지정</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">KUBECONFIG</span><span class="o">=</span><span class="nv">$PWD</span>/kubeconfig

<span class="c"># Create a cluster with kind</span>
<span class="c"># $ MyIP=&lt;각자 자신의 PC IP&gt;</span>
<span class="nv">$ MyIP</span><span class="o">=</span>10.0.4.3

<span class="nv">$ </span><span class="nb">cd</span> ..
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> kind-3node.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
networking:
  apiServerAddress: "</span><span class="nv">$MyIP</span><span class="sh">"
nodes:
- role: control-plane
  extraPortMappings:
  - containerPort: 30000
    hostPort: 30000
  - containerPort: 30001
    hostPort: 30001
  - containerPort: 30002
    hostPort: 30002
  - containerPort: 30003
    hostPort: 30003
- role: worker
- role: worker
</span><span class="no">EOF
</span><span class="nv">$ </span>kind create cluster <span class="nt">--config</span> kind-3node.yaml <span class="nt">--name</span> myk8s <span class="nt">--image</span> kindest/node:v1.30.6
<span class="c"># =&gt; Creating cluster &amp;quot;myk8s&amp;quot; ...</span>
<span class="c">#     ✓ Ensuring node image (kindest/node:v1.30.6) 🖼</span>
<span class="c">#     ✓ Preparing nodes 📦 📦 📦</span>
<span class="c">#     ✓ Writing configuration 📜</span>
<span class="c">#     ✓ Starting control-plane 🕹️</span>
<span class="c">#     ✓ Installing CNI 🔌</span>
<span class="c">#     ✓ Installing StorageClass 💾</span>
<span class="c">#     ✓ Joining worker nodes 🚜</span>
<span class="c">#    Set kubectl context to &amp;quot;kind-myk8s&amp;quot;</span>
<span class="c">#    You can now use your cluster with:</span>
<span class="c">#    </span>
<span class="c">#    kubectl cluster-info --context kind-myk8s</span>
<span class="c">#    </span>
<span class="c">#    Thanks for using kind! 😊</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kind get nodes <span class="nt">--name</span> myk8s
<span class="c"># =&gt; myk8s-control-plane</span>
<span class="c">#    myk8s-worker</span>
<span class="c">#    myk8s-worker2</span>
<span class="nv">$ </span>kubens default
<span class="c"># =&gt; Context &amp;quot;kind-myk8s&amp;quot; modified.</span>
<span class="c">#    Active namespace is &amp;quot;default&amp;quot;.</span>

<span class="c"># kind 는 별도 도커 네트워크 생성 후 사용 : 기본값 172.18.0.0/16</span>
<span class="nv">$ </span>docker network <span class="nb">ls</span>
<span class="c"># =&gt; NETWORK ID     NAME                     DRIVER    SCOPE</span>
<span class="c">#    8204a0851463   host                     host      local</span>
<span class="c">#    3bbcc6aa8f38   kind                     bridge    local</span>
<span class="nv">$ </span>docker inspect kind | jq
<span class="c"># =&gt; [</span>
<span class="c">#      {</span>
<span class="c">#        &amp;quot;Name&amp;quot;: &amp;quot;kind&amp;quot;,</span>
<span class="c">#        &amp;quot;Id&amp;quot;: &amp;quot;3bbcc6aa8f388f86f02478f41de1e4dd917e5812b6cf6257972e4af0bedf5021&amp;quot;,</span>
<span class="c">#        &amp;quot;Created&amp;quot;: &amp;quot;2024-10-01T11:37:09.195259833Z&amp;quot;,</span>
<span class="c">#        &amp;quot;Scope&amp;quot;: &amp;quot;local&amp;quot;,</span>
<span class="c">#        &amp;quot;Driver&amp;quot;: &amp;quot;bridge&amp;quot;,</span>
<span class="c">#        &amp;quot;EnableIPv6&amp;quot;: true,</span>
<span class="c">#        &amp;quot;IPAM&amp;quot;: {</span>
<span class="c">#          &amp;quot;Driver&amp;quot;: &amp;quot;default&amp;quot;,</span>
<span class="c">#          &amp;quot;Options&amp;quot;: {},</span>
<span class="c">#          &amp;quot;Config&amp;quot;: [</span>
<span class="c">#            {</span>
<span class="c">#              &amp;quot;Subnet&amp;quot;: &amp;quot;172.20.0.0/16&amp;quot;,</span>
<span class="c">#              &amp;quot;Gateway&amp;quot;: &amp;quot;172.20.0.1&amp;quot;</span>
<span class="c">#            }</span>
<span class="c">#          ]</span>
<span class="c">#        },</span>
<span class="c">#        &amp;quot;Internal&amp;quot;: false,</span>
<span class="c">#        &amp;quot;Attachable&amp;quot;: false,</span>
<span class="c">#        &amp;quot;Ingress&amp;quot;: false,</span>
<span class="c">#        &amp;quot;ConfigFrom&amp;quot;: {</span>
<span class="c">#          &amp;quot;Network&amp;quot;: &amp;quot;&amp;quot;</span>
<span class="c">#        },</span>
<span class="c">#        &amp;quot;ConfigOnly&amp;quot;: false,</span>
<span class="c">#        &amp;quot;Containers&amp;quot;: {</span>
<span class="c">#          &amp;quot;35739bf3542771236d47fd4dcb27da13814184a3de57c7203904f66ecbab4710&amp;quot;: {</span>
<span class="c">#            &amp;quot;Name&amp;quot;: &amp;quot;myk8s-worker&amp;quot;,</span>
<span class="c">#            &amp;quot;EndpointID&amp;quot;: &amp;quot;5de8e9e48e611f2c4cb908649f5dcdf63c82d624b85f85a6573ced7cbd454554&amp;quot;,</span>
<span class="c">#            &amp;quot;MacAddress&amp;quot;: &amp;quot;02:42:ac:14:00:03&amp;quot;,</span>
<span class="c">#            &amp;quot;IPv4Address&amp;quot;: &amp;quot;172.20.0.3/16&amp;quot;,</span>
<span class="c">#          },</span>
<span class="c">#          &amp;quot;48023a25d056141b00747f14ff52da2b46c46c0d0edbeb714dedd1f3c71360e4&amp;quot;: {</span>
<span class="c">#            &amp;quot;Name&amp;quot;: &amp;quot;myk8s-control-plane&amp;quot;,</span>
<span class="c">#            &amp;quot;EndpointID&amp;quot;: &amp;quot;9d51136474882d6ca7a4aabe7291e26527f44c3b88c7191b654506fdf1d65c84&amp;quot;,</span>
<span class="c">#            &amp;quot;MacAddress&amp;quot;: &amp;quot;02:42:ac:14:00:04&amp;quot;,</span>
<span class="c">#            &amp;quot;IPv4Address&amp;quot;: &amp;quot;172.20.0.4/16&amp;quot;,</span>
<span class="c">#          },</span>
<span class="c">#          &amp;quot;fefdfb00a2228f646119483a24503e1dc8bd74292e462fc9fa2ef3446004b4af&amp;quot;: {</span>
<span class="c">#            &amp;quot;Name&amp;quot;: &amp;quot;myk8s-worker2&amp;quot;,</span>
<span class="c">#            &amp;quot;EndpointID&amp;quot;: &amp;quot;c669ce7940abb8722b7ac41cc533c260838d31881c915a49147829e9d28a746c&amp;quot;,</span>
<span class="c">#            &amp;quot;MacAddress&amp;quot;: &amp;quot;02:42:ac:14:00:02&amp;quot;,</span>
<span class="c">#            &amp;quot;IPv4Address&amp;quot;: &amp;quot;172.20.0.2/16&amp;quot;,</span>
<span class="c">#          }</span>
<span class="c">#        },</span>
<span class="c">#        &amp;quot;Options&amp;quot;: {</span>
<span class="c">#          &amp;quot;com.docker.network.bridge.enable_ip_masquerade&amp;quot;: &amp;quot;true&amp;quot;,</span>
<span class="c">#          &amp;quot;com.docker.network.driver.mtu&amp;quot;: &amp;quot;1500&amp;quot;</span>
<span class="c">#        },</span>
<span class="c">#        &amp;quot;Labels&amp;quot;: {}</span>
<span class="c">#      }</span>
<span class="c">#    ]</span>

<span class="c"># k8s api 주소 확인 : 어떻게 로컬에서 접속이 되는 걸까?</span>
<span class="nv">$ </span>kubectl cluster-info
<span class="c"># =&gt; Kubernetes control plane is running at https://10.0.4.3:51235</span>
<span class="c">#    CoreDNS is running at https://10.0.4.3:51235/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</span>
<span class="c">#    </span>
<span class="c">#    To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 docker가 10.0.4.3:51235 접속시 kind 컨테이너의 6443 포트로 포워딩 해주고&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   ~/.kube/config 에서 10.0.4.3:51235를 apiserver 주소로 지정하고 있기 때문에 접속이 가능합니다.&lt;/span&gt;</span>

<span class="c"># 노드 정보 확인 : CRI 는 containerd 사용</span>
<span class="nv">$ </span>kubectl get node <span class="nt">-o</span> wide
<span class="c"># =&gt; NAME                  STATUS   ROLES           AGE     VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE                         KERNEL-VERSION     CONTAINER-RUNTIME</span>
<span class="c">#    myk8s-control-plane   Ready    control-plane   3m8s    v1.30.6   172.20.0.4    &amp;lt;none&amp;gt;        Debian GNU/Linux 12 (bookworm)   5.10.76-linuxkit   containerd://1.7.18</span>
<span class="c">#    myk8s-worker          Ready    &amp;lt;none&amp;gt;          2m48s   v1.30.6   172.20.0.3    &amp;lt;none&amp;gt;        Debian GNU/Linux 12 (bookworm)   5.10.76-linuxkit   containerd://1.7.18</span>
<span class="c">#    myk8s-worker2         Ready    &amp;lt;none&amp;gt;          2m48s   v1.30.6   172.20.0.2    &amp;lt;none&amp;gt;        Debian GNU/Linux 12 (bookworm)   5.10.76-linuxkit   containerd://1.7.18</span>

<span class="c"># 파드 정보 확인 : CNI 는 kindnet 사용</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-A</span> <span class="nt">-o</span> wide
<span class="c"># =&gt; NAMESPACE            NAME                                          READY   STATUS    RESTARTS   AGE     IP           NODE                  NOMINATED NODE   READINESS GATES</span>
<span class="c">#    kube-system          coredns-55cb58b774-m7h2c                      1/1     Running   0          3m7s    10.244.0.2   myk8s-control-plane   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          coredns-55cb58b774-z88v5                      1/1     Running   0          3m7s    10.244.0.3   myk8s-control-plane   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          etcd-myk8s-control-plane                      1/1     Running   0          3m22s   172.20.0.4   myk8s-control-plane   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          kindnet-mp6mj                                 1/1     Running   0          3m7s    172.20.0.4   myk8s-control-plane   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          kindnet-q2k9w                                 1/1     Running   0          3m4s    172.20.0.2   myk8s-worker2         &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          kindnet-t99c4                                 1/1     Running   0          3m4s    172.20.0.3   myk8s-worker          &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          kube-apiserver-myk8s-control-plane            1/1     Running   0          3m21s   172.20.0.4   myk8s-control-plane   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          kube-controller-manager-myk8s-control-plane   1/1     Running   0          3m21s   172.20.0.4   myk8s-control-plane   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          kube-proxy-f85sx                              1/1     Running   0          3m7s    172.20.0.4   myk8s-control-plane   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          kube-proxy-ltckc                              1/1     Running   0          3m4s    172.20.0.2   myk8s-worker2         &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          kube-proxy-njr42                              1/1     Running   0          3m4s    172.20.0.3   myk8s-worker          &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          kube-scheduler-myk8s-control-plane            1/1     Running   0          3m21s   172.20.0.4   myk8s-control-plane   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    local-path-storage   local-path-provisioner-7d4d9bdcc5-jhl5h       1/1     Running   0          3m7s    10.244.0.4   myk8s-control-plane   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>

<span class="c"># 쿠버네티스 네임스페이스 확인 &gt;&gt; 도커 컨테이너에서 배운 네임스페이스와 다릅니다!</span>
<span class="nv">$ </span>kubectl get namespaces
<span class="c"># =&gt; NAME                 STATUS   AGE</span>
<span class="c">#    default              Active   3m42s</span>
<span class="c">#    kube-node-lease      Active   3m42s</span>
<span class="c">#    kube-public          Active   3m42s</span>
<span class="c">#    kube-system          Active   3m42s</span>
<span class="c">#    local-path-storage   Active   3m35s</span>

<span class="c"># 컨트롤플레인/워커 노드(컨테이너) 확인 : 도커 컨테이너 이름은 myk8s-control-plane , myk8s-worker/worker-2 임을 확인</span>
<span class="nv">$ </span>docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE                  COMMAND                  CREATED         STATUS                 PORTS                                                            NAMES</span>
<span class="c">#    35739bf35427   kindest/node:v1.30.6   &amp;quot;/usr/local/bin/entr…&amp;quot;   4 minutes ago   Up 4 minutes                                                                            myk8s-worker</span>
<span class="c">#    48023a25d056   kindest/node:v1.30.6   &amp;quot;/usr/local/bin/entr…&amp;quot;   4 minutes ago   Up 4 minutes           0.0.0.0:30000-30003-&amp;gt;30000-30003/tcp, 10.0.4.3:51235-&amp;gt;6443/tcp   myk8s-control-plane</span>
<span class="c">#    fefdfb00a222   kindest/node:v1.30.6   &amp;quot;/usr/local/bin/entr…&amp;quot;   4 minutes ago   Up 4 minutes                                                                            myk8s-worker2</span>
<span class="nv">$ </span>docker images

<span class="c"># 디버그용 내용 출력에 ~/.kube/config 권한 인증 로드</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-v6</span>
<span class="c"># =&gt; I1221 20:19:47.265879   56969 loader.go:395] Config loaded from file:  /Users/anonym/Documents/GitHub/cicd-lite/w3/1/dev-app/kubeconfig</span>
<span class="c">#    I1221 20:19:47.354543   56969 round_trippers.go:553] GET https://10.0.4.3:51235/api/v1/namespaces/default/pods?limit=500 200 OK in 79 milliseconds</span>
<span class="c">#    No resources found in default namespace.</span>

<span class="c"># kube config 파일 확인</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="nv">$KUBECONFIG</span>
<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-l</span> <span class="nv">$KUBECONFIG</span>
<span class="c"># =&gt; .rw------- anonym staff 5.5 KB Sat Oct 01 20:16:21 2024  /Users/user/Documents/GitHub/cicd-lite/w3/1/dev-app/kubeconfig</span>
</code></pre></div></div>

<h5 id="kube-ops-view-설치">kube-ops-view 설치</h5>

<ul>
  <li>kube-ops-view는 쿠버네티스 클러스터의 상태를 시각적으로 보여주는 대시보드입니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># kube-ops-view</span>
<span class="c"># helm show values geek-cookbook/kube-ops-view</span>
<span class="nv">$ </span>helm repo add geek-cookbook https://geek-cookbook.github.io/charts/
<span class="nv">$ </span>helm <span class="nb">install </span>kube-ops-view geek-cookbook/kube-ops-view <span class="nt">--version</span> 1.2.2 <span class="nt">--set</span> service.main.type<span class="o">=</span>NodePort,service.main.ports.http.nodePort<span class="o">=</span>30001 <span class="nt">--set</span> env.TZ<span class="o">=</span><span class="s2">"Asia/Seoul"</span> <span class="nt">--namespace</span> kube-system

<span class="c"># 설치 확인</span>
<span class="nv">$ </span>kubectl get deploy,pod,svc,ep <span class="nt">-n</span> kube-system <span class="nt">-l</span> app.kubernetes.io/instance<span class="o">=</span>kube-ops-view
<span class="c"># =&gt; NAME                            READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/kube-ops-view   1/1     1            1           25s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                 READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/kube-ops-view-796947d6dc-6b6xx   1/1     Running   0          25s</span>
<span class="c">#    </span>
<span class="c">#    NAME                    TYPE       CLUSTER-IP    EXTERNAL-IP   PORT(S)          AGE</span>
<span class="c">#    service/kube-ops-view   NodePort   10.96.18.59   &amp;lt;none&amp;gt;        8080:30001/TCP   25s</span>
<span class="c">#    </span>
<span class="c">#    NAME                      ENDPOINTS         AGE</span>
<span class="c">#    endpoints/kube-ops-view   10.244.1.2:8080   25s</span>

<span class="c"># kube-ops-view 접속 URL 확인 (1.5 , 2 배율)</span>
<span class="nv">$ </span>open <span class="s2">"http://127.0.0.1:30001/#scale=1.5"</span>
<span class="nv">$ </span>open <span class="s2">"http://127.0.0.1:30001/#scale=2"</span>
</code></pre></div></div>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_10.png" alt="img.png" class="w-80 image-center" /></p>

<h5 id="클러스터-삭제">클러스터 삭제</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 클러스터 삭제</span>
<span class="nv">$ </span>kind delete cluster <span class="nt">--name</span> myk8s
<span class="c"># =&gt; Deleting cluster &amp;quot;myk8s&amp;quot; ...</span>
<span class="c">#    Deleted nodes: [&amp;quot;myk8s-worker&amp;quot; &amp;quot;myk8s-control-plane&amp;quot; &amp;quot;myk8s-worker2&amp;quot;]</span>
<span class="nv">$ </span>docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE             COMMAND                  CREATED        STATUS                 PORTS                                              NAMES</span>
<span class="c">#    110494b9ca48   gogs/gogs         &amp;quot;/app/gogs/docker/st…&amp;quot;   19 hours ago   Up 6 hours (healthy)   0.0.0.0:3000-&amp;gt;3000/tcp, 0.0.0.0:10022-&amp;gt;22/tcp      gogs</span>
<span class="c">#    8b7c591c828d   jenkins/jenkins   &amp;quot;/usr/bin/tini -- /u…&amp;quot;   19 hours ago   Up 5 hours             0.0.0.0:8080-&amp;gt;8080/tcp, 0.0.0.0:50000-&amp;gt;50000/tcp   jenkins</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="nv">$KUBECONFIG</span>
<span class="nv">$ </span><span class="nb">unset </span>KUBECONFIG
</code></pre></div></div>

<h4 id="jenkins-설정--plugin-설치-자격증명-설정">Jenkins 설정 : Plugin 설치, 자격증명 설정</h4>

<ul>
  <li>Jenkins Plugin 설치 : Dashboard &gt; Manage Jenkins &gt; Plugins &gt; Available plugins 탭에서 설치
    <ul>
      <li><strong>Pipeline Stage View</strong> - <a href="https://plugins.jenkins.io/pipeline-stage-view/">Docs</a></li>
      <li><strong>Docker Pipeline</strong> : building, testing, and using Docker images from Jenkins Pipeline - <a href="https://plugins.jenkins.io/docker-workflow/">Docs</a></li>
      <li><strong>Gogs</strong> : Webhook Plugin - <a href="https://plugins.jenkins.io/gogs-webhook/">Docs</a>
        <ul>
          <li>예시 : <code class="language-plaintext highlighter-rouge">http(s)://&lt;&lt; jenkins-server &gt;&gt;/gogs-webhook/?job=&lt;&lt;jobname&gt;&gt;</code></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>자격증명 설정 : Dashboard &gt; Manage Jenkins &gt; Credentials &gt; Global &gt; Add Credentials 에서 추가
    <ol>
      <li>Gogs Repo 자격증명 설정 : <strong>gogs-crd</strong>
        <ul>
          <li>Kind : Username with password</li>
          <li>Username : <code class="language-plaintext highlighter-rouge">devops</code></li>
          <li>Password : <code class="language-plaintext highlighter-rouge">&lt;Gogs 토큰&gt;</code></li>
          <li>ID : <code class="language-plaintext highlighter-rouge">gogs-crd</code></li>
        </ul>
      </li>
      <li>도커 허브 자격증명 설정 : <strong>dockerhub-crd</strong>
        <ul>
          <li>Kind : Username with password</li>
          <li>Username : <code class="language-plaintext highlighter-rouge">&lt;도커 계정명&gt;</code></li>
          <li>Password : <code class="language-plaintext highlighter-rouge">&lt;도커 계정 암호 혹은 토큰&gt;</code></li>
          <li>ID : <code class="language-plaintext highlighter-rouge">dockerhub-crd</code></li>
        </ul>
      </li>
      <li>k8s(kind) 자격증명 설정 : <strong>k8s-crd</strong>
        <ul>
          <li>Kind : <code class="language-plaintext highlighter-rouge">Secret file</code></li>
          <li>File : <code class="language-plaintext highlighter-rouge">&lt;kubeconfig 파일 업로드&gt;</code></li>
          <li>ID : <code class="language-plaintext highlighter-rouge">k8s-crd</code></li>
        </ul>
      </li>
    </ol>
  </li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_11.png" alt="img.png" class="image-center" />
<em class="image-caption">Jenkins 자격증명 설정 결과</em></p>

<h5 id="jenkins-item-생성-pipeline">Jenkins item 생성 (Pipeline)</h5>

<ul>
  <li>간단한 Pipeline 스크립트를 작성하여 gogs와 도커허브의 자격증명이 잘 연동됨을 확인해보겠습니다.</li>
  <li>아래의 Pipeline 스크립트를 <code class="language-plaintext highlighter-rouge">pipeline-ci</code>라는 이름으로 생성합니다.</li>
</ul>

<div class="language-gradle highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pipeline</span> <span class="o">{</span>
    <span class="n">agent</span> <span class="n">any</span>
    <span class="n">environment</span> <span class="o">{</span>
        <span class="n">DOCKER_IMAGE</span> <span class="o">=</span> <span class="s1">'&lt;자신의 도커 허브 계정&gt;/dev-app'</span> <span class="c1">// Docker 이미지 이름</span>
    <span class="o">}</span>
    <span class="n">stages</span> <span class="o">{</span>
        <span class="n">stage</span><span class="o">(</span><span class="s1">'Checkout'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                 <span class="n">git</span> <span class="nl">branch:</span> <span class="s1">'main'</span><span class="o">,</span>
                 <span class="nl">url:</span> <span class="s1">'http://&lt;PC의 IP&gt;:3000/devops/dev-app.git'</span><span class="o">,</span>  <span class="c1">// Git에서 코드 체크아웃</span>
                 <span class="nl">credentialsId:</span> <span class="s1">'gogs-crd'</span>  <span class="c1">// Credentials ID</span>
            <span class="o">}</span>
        <span class="o">}</span>
        <span class="n">stage</span><span class="o">(</span><span class="s1">'Read VERSION'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">script</span> <span class="o">{</span>
                    <span class="c1">// VERSION 파일 읽기</span>
                    <span class="kt">def</span> <span class="n">version</span> <span class="o">=</span> <span class="n">readFile</span><span class="o">(</span><span class="s1">'VERSION'</span><span class="o">).</span><span class="na">trim</span><span class="o">()</span>
                    <span class="n">echo</span> <span class="s2">"Version found: ${version}"</span>
                    <span class="c1">// 환경 변수 설정</span>
                    <span class="n">env</span><span class="o">.</span><span class="na">DOCKER_TAG</span> <span class="o">=</span> <span class="n">version</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
        <span class="n">stage</span><span class="o">(</span><span class="s1">'Docker Build and Push'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">script</span> <span class="o">{</span>
                    <span class="n">docker</span><span class="o">.</span><span class="na">withRegistry</span><span class="o">(</span><span class="s1">'https://index.docker.io/v1/'</span><span class="o">,</span> <span class="s1">'dockerhub-crd'</span><span class="o">)</span> <span class="o">{</span>
                        <span class="c1">// DOCKER_TAG 사용</span>
                        <span class="kt">def</span> <span class="n">appImage</span> <span class="o">=</span> <span class="n">docker</span><span class="o">.</span><span class="na">build</span><span class="o">(</span><span class="s2">"${DOCKER_IMAGE}:${DOCKER_TAG}"</span><span class="o">)</span>
                        <span class="n">appImage</span><span class="o">.</span><span class="na">push</span><span class="o">()</span>
                        <span class="n">appImage</span><span class="o">.</span><span class="na">push</span><span class="o">(</span><span class="s2">"latest"</span><span class="o">)</span>
                    <span class="o">}</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
    <span class="n">post</span> <span class="o">{</span>
        <span class="n">success</span> <span class="o">{</span>
            <span class="n">echo</span> <span class="s2">"Docker image ${DOCKER_IMAGE}:${DOCKER_TAG} has been built and pushed successfully!"</span>
        <span class="o">}</span>
        <span class="n">failure</span> <span class="o">{</span>
            <span class="n">echo</span> <span class="s2">"Pipeline failed. Please check the logs."</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<ul>
  <li>지금 빌드 =&gt; 콘솔 Output 확인
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_12.png" alt="img.png" class="image-center" /></li>
  <li>도커 허브 확인
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_13.png" alt="img.png" class="image-center" />
    <ul>
      <li>자격증명들이 잘 연동되어, 파이프라인에서 지정한것 처럼 버전명의 태그(0.0.1)과 latest 태그가 잘 생성되었습니다!</li>
    </ul>
  </li>
</ul>

<h4 id="kubernetes-클러스터에-응용프로그램-배포하기">Kubernetes 클러스터에 응용프로그램 배포하기</h4>

<ul>
  <li>Jenkins Pipeline을 통해 Kubernetes 클러스터에 응용프로그램을 배포해보겠습니다.</li>
  <li>먼저 Kubernetes 클러스터에 배포할때 사용하는 deployment에 대해 알아보겠습니다.</li>
</ul>

<h5 id="deployment-소개">Deployment 소개</h5>

<script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
<div class="mermaid">
  graph TD
      subgraph Deployment
          subgraph ReplicaSet
              direction TB
              subgraph Pod[Pod]
                  direction LR
                  Container1(Container)
                  Container2(Container)
              end
              subgraph Pod2[Pod]
                  direction LR
                  Container3(Container)
                  Container4(Container)
              end
              subgraph Pod3[Pod]
                  direction LR
                  Container5(Container)
              end
          end
      end
  classDef Pod fill:#fff,stroke:#ccc,stroke-width:2px;
  classDef ReplicaSet fill:#fff,stroke:#ccc,stroke-width:2px;
  classDef Deployment fill:#fff,stroke:#ccc,stroke-width:2px;
  class Pod,Pod2,Pod3 Pod;
  class Deployment Deployment;
  </div>
<p><em class="image-caption">Kubernetes 배포 구조</em></p>

<ul>
  <li>Kubernetes를 배포하는 최소단위는 <strong>Pod</strong>이며, <strong>하나 이상의 컨테이너로 구성</strong>됩니다.</li>
  <li>Pod는 <strong>ReplicaSet</strong>에 의해 관리되며, ReplicaSet은 <strong>Pod의 수를 유지하도록 관리</strong>합니다.</li>
  <li>
    <p><strong>Deployment</strong>는 <strong>ReplicaSet을 관리하며, Pod의 배포 및 업데이트를 관리</strong>합니다.</p>
  </li>
  <li>Kubernetes는 manifest라는 yaml 파일을 통해 리소스를 정의하고, 선언형 방식으로 원하는 상태를 선언시 해당 상태를 충족시키기 위해 클러스터를 조정합니다.</li>
  <li>아래는 kubernetes의 manifest의 구조입니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apiVersion: ...   <span class="c"># &lt;span style="color: green;"&gt;👉 리소스를 만드는데 사용할 Kubernetes API 버전&lt;/span&gt;</span>
kind: ...         <span class="c"># &lt;span style="color: green;"&gt;👉 만들고자 하는 리소스의 종류&lt;/span&gt;</span>
metadata:
    ...           <span class="c"># &lt;span style="color: green;"&gt;👉 리소스를 식별하는 고유 데이터와 상태와 관련없는 메타데이터&lt;/span&gt;</span>
spec:
    ...           <span class="c"># &lt;span style="color: green;"&gt;👉 리소스의 원하는 상태를 정의&lt;/span&gt;</span>
</code></pre></div>    </div>
  </li>
</ul>

<h5 id="deployment-배포-실습">Deployment 배포 실습</h5>

<ul>
  <li>
    <p>앞서 작성한 Jenkins Pipeline을 통해 빌드된 도커 이미지를 Kubernetes 클러스터에 응용프로그램을 배포해보겠습니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 디플로이먼트 오브젝트 배포 : 리플리카(파드 2개), 컨테이너 이미지 &gt;&gt; 아래 도커 계정 부분만 변경해서 배포해보자</span>
<span class="c">#$ DHUSER=&lt;도커 허브 계정명&gt;</span>
<span class="nv">$ DHUSER</span><span class="o">=</span>sweetlittlebird
  
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: timeserver
spec:
  replicas: 2
  selector:
    matchLabels:
      pod: timeserver-pod
  template:
    metadata:
      labels:
        pod: timeserver-pod
    spec:
      containers:
      - name: timeserver-container
        image: docker.io/</span><span class="nv">$DHUSER</span><span class="sh">/dev-app:0.0.1
</span><span class="no">EOF
</span><span class="c"># =&gt; deployment.apps/timeserver created</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> kubectl get deploy,pod <span class="nt">-o</span> wide
  
<span class="c"># 배포 상태 확인 : kube-ops-view 웹 확인</span>
<span class="nv">$ </span>kubectl get deploy,pod <span class="nt">-o</span> wide
<span class="c"># =&gt; NAME                         READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS             IMAGES                                    SELECTOR</span>
<span class="c">#    deployment.apps/timeserver   0/2     2            0           45s   timeserver-container   docker.io/sweetlittlebird/dev-app:0.0.1   pod=timeserver-pod</span>
<span class="c">#    </span>
<span class="c">#    NAME                              READY   STATUS             RESTARTS   AGE   IP           NODE            NOMINATED NODE   READINESS GATES</span>
<span class="c">#    pod/timeserver-5b5ff6d859-s282p   0/1     &lt;span style="color: red;"&gt;ImagePullBackOff&lt;/span&gt;   0          45s   10.244.2.2   myk8s-worker2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    pod/timeserver-5b5ff6d859-v7gs7   0/1     &lt;span style="color: red;"&gt;ImagePullBackOff&lt;/span&gt;   0          45s   10.244.1.2   myk8s-worker    &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 배포상태가 ImagePullBackOff로 배포가 되지 않았습니다.&lt;/span&gt;</span>
  
<span class="nv">$ </span>kubectl describe pod
<span class="c"># =&gt; Name:             timeserver-5b5ff6d859-s282p</span>
<span class="c">#    ...</span>
<span class="c">#    Events:</span>
<span class="c">#      Type     Reason     Age                    From               Message</span>
<span class="c">#      ----     ------     ----                   ----               -------</span>
<span class="c">#      Normal   Scheduled  5m38s                  default-scheduler  Successfully assigned default/timeserver-5b5ff6d859-s282p to myk8s-worker2</span>
<span class="c">#      Normal   Pulling    4m4s (x4 over 5m37s)   kubelet            Pulling image &amp;quot;docker.io/sweetlittlebird/dev-app:0.0.1&amp;quot;</span>
<span class="c">#      Warning  Failed     4m3s (x4 over 5m35s)   kubelet            Failed to pull image &amp;quot;docker.io/sweetlittlebird/dev-app:0.0.1&amp;quot;: failed to pull and unpack image &amp;quot;docker.io/sweetlittlebird/dev-app:0.0.1&amp;quot;: failed to resolve reference &amp;quot;docker.io/sweetlittlebird/dev-app:0.0.1&amp;quot;: pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed</span>
<span class="c">#      Warning  Failed     4m3s (x4 over 5m35s)   kubelet            Error: ErrImagePull</span>
<span class="c">#      Warning  Failed     3m48s (x6 over 5m35s)  kubelet            Error: ImagePullBackOff</span>
<span class="c">#      Normal   BackOff    22s (x20 over 5m35s)   kubelet            Back-off pulling image &amp;quot;docker.io/sweetlittlebird/dev-app:0.0.1&amp;quot;```</span>
</code></pre></div>    </div>
  </li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_14.png" alt="img.png" class="image-center" />
<em class="image-caption">Kube-Ops-View를 통해 살펴본 Kubernetes 클러스터에 timeserver 배포 실패</em></p>

<ul>
  <li>위와 같이 Image pull error가 나면서 배포가 실패했습니다.</li>
  <li><code class="language-plaintext highlighter-rouge">kubectl describe pod</code>를 통해 확인한 결과, <code class="language-plaintext highlighter-rouge">pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed</code>와 같은 메시지가 나타나고
이는 Kubernetes 클러스터에서 도커 이미지를 pull할 때 도커 허브에 인증 토큰이 되어있지 않아서 발생한 문제를 의미합니다.</li>
  <li>도커 허브의 인증토큰을 등록하고 다시 시도해보겠습니다.</li>
</ul>

<h4 id="k8s에-docker-hub-인증토큰-등록-후-다시-배포">K8S에 Docker Hub 인증토큰 등록 후 다시 배포</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># k8s secret : 도커 자격증명 설정</span>
 
<span class="nv">$ </span>kubectl get secret <span class="nt">-A</span>  <span class="c"># 기존 시크릿 확인</span>
<span class="c"># =&gt; NAMESPACE     NAME                                  TYPE                            DATA   AGE</span>
<span class="c">#    kube-system   bootstrap-token-abcdef                bootstrap.kubernetes.io/token   6      164m</span>
<span class="c">#    kube-system   sh.helm.release.v1.kube-ops-view.v1   helm.sh/release.v1              1      25m</span>

<span class="c">#$ DHUSER=&lt;도커 허브 계정&gt;</span>
<span class="c">#$ DHPASS=&lt;도커 허브 암호 혹은 토큰&gt;</span>

<span class="nv">$ DHUSER</span><span class="o">=</span>sweetlittlebird
<span class="nv">$ DHPASS</span><span class="o">=</span>dckr_<span class="k">****</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$DHUSER</span> <span class="nv">$DHPASS</span>
<span class="c"># =&gt; sweetlittlebird dckr_****</span>

<span class="c"># 도커 허브 시크릿 생성</span>
<span class="nv">$ </span>kubectl create secret docker-registry dockerhub-secret <span class="se">\</span>
  <span class="nt">--docker-server</span><span class="o">=</span>https://index.docker.io/v1/ <span class="se">\</span>
  <span class="nt">--docker-username</span><span class="o">=</span><span class="nv">$DHUSER</span> <span class="se">\</span>
  <span class="nt">--docker-password</span><span class="o">=</span><span class="nv">$DHPASS</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get secret
<span class="c"># =&gt; NAME               TYPE                             DATA   AGE</span>
<span class="c">#    dockerhub-secret   kubernetes.io/dockerconfigjson   1      8s</span>
<span class="nv">$ </span>kubectl describe secret
<span class="c"># =&gt; Name:         dockerhub-secret</span>
<span class="c">#    Namespace:    default</span>
<span class="c">#    Labels:       &amp;lt;none&amp;gt;</span>
<span class="c">#    Annotations:  &amp;lt;none&amp;gt;</span>
<span class="c">#    </span>
<span class="c">#    Type:  kubernetes.io/dockerconfigjson</span>
<span class="c">#    </span>
<span class="c">#    Data</span>
<span class="c">#    ====</span>
<span class="c">#    .dockerconfigjson:  205 bytes</span>
<span class="nv">$ </span>kubectl get secrets <span class="nt">-o</span> yaml | kubectl neat  <span class="c"># base64 인코딩 확인</span>
<span class="c"># =&gt; apiVersion: v1</span>
<span class="c">#    items:</span>
<span class="c">#    - apiVersion: v1</span>
<span class="c">#      data:</span>
<span class="c">#        .dockerconfigjson: eyJhdXRocyI6eyJodHRwczovL2luZGV4LmRvY2tlci5pby92MS8iOnsidXNlcm5hbWUiOiJzZWNyZXRsaXR0bGViaXJkIiwicGFzc3dvcmQiOiJkY2tyX3BhdF9QdWNpVTRIMFBPZVpYWGNvV1VNd1ozTVpZVEUiLCJhdXRoIjoiYzJWamNtVjBiR2wwZEd4bFltbHlaRHBrWTJ0eVgzQmhkRjlRZFdOcFZUUklNRkJQWlZwWVdHTnZWMVZOZDFvelRWcFpWRVU9In19fQ==</span>
<span class="c">#      kind: Secret</span>
<span class="c">#      metadata:</span>
<span class="c">#        name: dockerhub-secret</span>
<span class="c">#        namespace: default</span>
<span class="c">#      type: kubernetes.io/dockerconfigjson</span>
<span class="c">#    kind: List</span>
<span class="c">#    metadata: {}</span>

<span class="nv">$ SECRET</span><span class="o">=</span><span class="nv">eyJhdXRocyI6eyJodHRwczovL2luZGV4LmRvY2tlci5pby92MS8iOnsidXNlcm5hbWUiOiJzZWNyZXRsaXR0bGViaXJkIiwicGFzc3dvcmQiOiJkY2tyX3BhdF9QdWNpVTRIMFBPZVpYWGNvV1VNd1ozTVpZVEUiLCJhdXRoIjoiYzJWamNtVjBiR2wwZEd4bFltbHlaRHBrWTJ0eVgzQmhkRjlRZFdOcFZUUklNRkJQWlZwWVdHTnZWMVZOZDFvelRWcFpWRVU9In19fQ</span><span class="o">==</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"</span><span class="nv">$SECRET</span><span class="s2">"</span> | <span class="nb">base64</span> <span class="nt">-d</span> <span class="p">;</span> <span class="nb">echo</span>
<span class="c"># =&gt; {&amp;quot;auths&amp;quot;:{&amp;quot;https://index.docker.io/v1/&amp;quot;:{&amp;quot;username&amp;quot;:&amp;quot;sweetlittlebird&amp;quot;,&amp;quot;password&amp;quot;:&amp;quot;dckr_****&amp;quot;,&amp;quot;auth&amp;quot;:&amp;quot;c2VjcmV0bGl0dGxlYmlyZDpkY2tyX3BhdF9QdWNpVTRIMFBPZVpYWGNvV1VNd1ozTVpZVEU=&amp;quot;}}}</span>

<span class="c"># 도커허브 인증 토큰이 등록되었으니 다시 배포해보겠습니다.</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: timeserver
spec:
  replicas: 2
  selector:
    matchLabels:
      pod: timeserver-pod
  template:
    metadata:
      labels:
        pod: timeserver-pod
    spec:
      containers:
      - name: timeserver-container
        image: docker.io/</span><span class="nv">$DHUSER</span><span class="sh">/dev-app:0.0.1
      imagePullSecrets:
      - name: dockerhub-secret
</span><span class="no">EOF
</span><span class="nv">$ </span>watch <span class="nt">-d</span> kubectl get deploy,pod <span class="nt">-o</span> wide

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get deploy,pod
<span class="c"># =&gt; NAME                         READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/timeserver   2/2     2            2           39s</span>
<span class="c">#    </span>
<span class="c">#    NAME                              READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/timeserver-549cc9bc89-k6n6g   1/1     Running   0          39s</span>
<span class="c">#    pod/timeserver-549cc9bc89-kdmgx   1/1     Running   0          39s</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 배포가 잘 되었습니다!&lt;/span&gt;</span>

<span class="c"># 접속을 위한 curl 파드 생성</span>
<span class="nv">$ </span>kubectl run curl-pod <span class="nt">--image</span><span class="o">=</span>curlimages/curl:latest <span class="nt">--command</span> <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s2">"while true; do sleep 3600; done"</span>
<span class="c"># =&gt; pod/curl-pod created</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                          READY   STATUS    RESTARTS   AGE    IP           NODE            NOMINATED NODE   READINESS GATES</span>
<span class="c">#    curl-pod                      1/1     Running   0          22s    10.244.2.6   myk8s-worker2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    timeserver-549cc9bc89-k6n6g   1/1     Running   0          103s   10.244.2.5   myk8s-worker2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    timeserver-549cc9bc89-kdmgx   1/1     Running   0          103s   10.244.1.6   myk8s-worker    &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>

<span class="c"># timeserver 파드 IP 1개 확인 후 접속 확인</span>
<span class="c">#$ PODIP1=&lt;timeserver-Y 파드 IP&gt;</span>
<span class="nv">$ PODIP1</span><span class="o">=</span>10.244.2.5

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nv">$PODIP1</span>
<span class="c"># =&gt; The time is 2:51:54 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-k6n6g</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nv">$PODIP1</span>
<span class="c"># =&gt; The time is 2:52:03 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-k6n6g</span>

<span class="c"># 로그 확인</span>
<span class="nv">$ </span>kubectl logs deploy/timeserver
<span class="nv">$ </span>kubectl logs deploy/timeserver <span class="nt">-f</span>
<span class="nv">$ </span>kubectl stern deploy/timeserver
<span class="nv">$ </span>kubectl stern <span class="nt">-l</span> <span class="nv">pod</span><span class="o">=</span>timeserver-pod
</code></pre></div></div>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_15.png" alt="img.png" class="image-center" /></p>

<ul>
  <li>kube-ops-view를 통해서도 배포가 잘 되었음을 확인할 수 있습니다.</li>
  <li>파드 1개 삭제 후 동작을 확인해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="c">#$ POD1NAME=&lt;파드 1개 이름&gt;</span>
<span class="nv">$ POD1NAME</span><span class="o">=</span>timeserver-549cc9bc89-k6n6g

<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                          READY   STATUS    RESTARTS   AGE    IP           NODE            NOMINATED NODE   READINESS GATES</span>
<span class="c">#    curl-pod                      1/1     Running   0          22s    10.244.2.6   myk8s-worker2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    timeserver-549cc9bc89-k6n6g   1/1     Running   0          103s   10.244.2.5   myk8s-worker2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    timeserver-549cc9bc89-kdmgx   1/1     Running   0          103s   10.244.1.6   myk8s-worker    &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="nv">$ </span>kubectl delete pod <span class="nv">$POD1NAME</span> <span class="o">&amp;&amp;</span> kubectl get pod <span class="nt">-w</span>
<span class="c"># =&gt; pod &amp;quot;timeserver-549cc9bc89-k6n6g&amp;quot; deleted              # &lt;span style="color: green;"&gt;👉 분명히 timeserver 파드 1개를 삭제하였는데&lt;/span&gt;</span>
<span class="c">#    NAME                          READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    curl-pod                      1/1     Running   0          115s</span>
<span class="c">#    timeserver-549cc9bc89-kdmgx   1/1     Running   0          7m20s</span>
<span class="c">#    timeserver-549cc9bc89-pvm5k   1/1     Running   0          31s   # &lt;span style="color: green;"&gt;👉 다시 새로운 파드가 생성되었습니다.&lt;/span&gt;</span>

<span class="c"># 셀프 힐링 , 파드 IP 변경 -&gt; 고정 진입점(고정 IP/도메인네임) 필요 =&gt; Service</span>
<span class="nv">$ </span>kubectl get deploy,rs,pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                         READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS             IMAGES                                    SELECTOR</span>
<span class="c">#    deployment.apps/timeserver   2/2     2            2           10m   timeserver-container   docker.io/sweetlittlebird/dev-app:0.0.1   pod=timeserver-pod</span>
<span class="c">#    </span>
<span class="c">#    NAME                                    DESIRED   CURRENT   READY   AGE   CONTAINERS             IMAGES                                    SELECTOR</span>
<span class="c">#    replicaset.apps/timeserver-549cc9bc89   2         2         2       10m   timeserver-container   docker.io/sweetlittlebird/dev-app:0.0.1   pod=timeserver-pod,pod-template-hash=549cc9bc89</span>
<span class="c">#    </span>
<span class="c">#    NAME                              READY   STATUS    RESTARTS   AGE     IP           NODE            NOMINATED NODE   READINESS GATES</span>
<span class="c">#    pod/curl-pod                      1/1     Running   0          4m56s   10.244.2.7   myk8s-worker2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    pod/timeserver-549cc9bc89-kdmgx   1/1     Running   0          10m     10.244.1.6   myk8s-worker    &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    pod/timeserver-549cc9bc89-pvm5k   1/1     Running   0          3m32s   10.244.2.8   myk8s-worker2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
</code></pre></div></div>

<ul>
  <li>위와 같이 파드가 삭제되면 ReplicaSet에 의해 새로운 파드가 생성되는 것을 확인할 수 있습니다.</li>
  <li>이때 IP가 변경되어 새로운 파드가 생성되는데, 이렇게 되면 매번 파드가 생성될때 마다 IP가 변경되어 서비스를 제공하기 어렵습니다.</li>
  <li>이를 해결하기 위해 <strong>Service</strong>를 사용합니다.</li>
</ul>

<h5 id="service-소개">Service 소개</h5>

<ul>
  <li><strong>Service</strong>는 Pod의 집합에 대한 고정된 진입점을 제공합니다. 앞서 살펴본것과 같이 Pod는 생성/삭제되면 IP가 변경되는데, 이를 Service를 통해 고정된 IP로 접근할 수 있습니다.</li>
  <li>Deployment를 통해 Pod가 여러 개 생성되면, Service는 이들을 하나의 집합으로 묶어서 부하분산(Load Balancing)을 제공합니다.</li>
  <li>Service는 Deployment를 대상으로 하지않고, Pod를 대상으로 합니다. Pod의 Label Selector를 통해 Service는 Pod를 선택합니다. 
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_16.png" alt="img.png" class="image-center" />
<em class="image-caption">Service와 Deployment, Pod manifest의 관계</em></li>
  <li>Service는 다음과 같은 종류가 있습니다.
    <ul>
      <li><strong>ClusterIP</strong> : 클러스터 내부에서만 접근 가능합니다.</li>
      <li><strong>NodePort</strong> : 클러스터 내부에서는 물론 외부에서 접근 가능합니다. 이때 파드가 동작하는 노드 IP의 지정된 포트로 접근 가능합니다.</li>
      <li><strong>LoadBalancer</strong> : 클라우드 제공자의 로드밸런서를 사용하여 외부에서 접근 가능합니다.</li>
    </ul>
  </li>
</ul>

<h5 id="service-배포-실습">Service 배포 실습</h5>

<ul>
  <li>간단한 서비스를 배포해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 서비스 생성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Service
metadata:
  name: timeserver
spec:
  selector:
    pod: timeserver-pod
  ports:
  - port: 80
    targetPort: 80
    protocol: TCP
    nodePort: 30000
  type: NodePort
</span><span class="no">EOF
</span><span class="c"># =&gt; service/timeserver created</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get service,ep timeserver <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                 TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE   SELECTOR</span>
<span class="c">#    service/timeserver   NodePort   10.96.204.127   &amp;lt;none&amp;gt;        80:30000/TCP   13s   pod=timeserver-pod</span>
<span class="c">#    </span>
<span class="c">#    NAME                   ENDPOINTS                     AGE</span>
<span class="c">#    endpoints/timeserver   10.244.1.6:80,10.244.2.8:80   13s</span>

<span class="c"># Service(ClusterIP)로 접속 확인 : 도메인네임 방식</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl timeserver
<span class="c"># =&gt; The time is 3:29:30 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl timeserver.default.svc.cluster.local
<span class="c"># =&gt; The time is 3:29:33 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-pvm5k</span>

<span class="c"># Service(ClusterIP)로 접속 확인 : 클러스터 IP 방식</span>
<span class="nv">$ </span>kubectl get svc timeserver <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.spec.clusterIP<span class="o">}</span>
<span class="c"># =&gt; 10.96.204.127</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="si">$(</span>kubectl get svc timeserver <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.spec.clusterIP<span class="o">}</span><span class="si">)</span>
<span class="c"># =&gt; The time is 3:29:40 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-pvm5k</span>

<span class="c"># Service(NodePort)로 접속 확인 "노드IP:NodePort"</span>
<span class="nv">$ </span>curl http://127.0.0.1:30000
<span class="c"># =&gt; The time is 3:32:43 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-&lt;span style="color: red;"&gt;kdmgx&lt;/span&gt;</span>
<span class="nv">$ </span>curl http://127.0.0.1:30000
<span class="c"># =&gt; The time is 3:32:59 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-&lt;span style="color: red;"&gt;pvm5k&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 서비스가 2개의 Pod 사이를 Load balancing 하는것을 확인 할 수 있습니다.&lt;/span&gt;</span>

<span class="c"># 반복 접속 해두기 : 부하분산 확인</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 http://127.0.0.1:30000 | <span class="nb">grep </span>name <span class="p">;</span> <span class="nb">sleep </span>1 <span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; Server hostname: timeserver-549cc9bc89-kdmgx</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-kdmgx</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#    ...</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span>  <span class="k">do </span>curl <span class="nt">-s</span> http://127.0.0.1:30000 | <span class="nb">grep </span>name<span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;   54 Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#      46 Server hostname: timeserver-549cc9bc89-kdmgx</span>

<span class="c"># 파드 복제복 증가 : service endpoint 대상에 자동 추가</span>
<span class="nv">$ </span>kubectl scale deployment timeserver <span class="nt">--replicas</span> 4
<span class="c"># =&gt; deployment.apps/timeserver scaled</span>
<span class="nv">$ </span>kubectl get service,ep timeserver <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                 TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE   SELECTOR</span>
<span class="c">#    service/timeserver   NodePort   10.96.204.127   &amp;lt;none&amp;gt;        80:30000/TCP   37m   pod=timeserver-pod</span>
<span class="c">#    </span>
<span class="c">#    NAME                   ENDPOINTS                                               AGE</span>
<span class="c">#    endpoints/timeserver   10.244.1.6:80,10.244.1.7:80,10.244.2.8:80 + 1 more...   37m</span>

<span class="c"># 반복 접속 해두기 : 부하분산 확인</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 http://127.0.0.1:30000 | <span class="nb">grep </span>name <span class="p">;</span> <span class="nb">sleep </span>1 <span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-h9q6p</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-h9q6p</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-xlbck</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-kdmgx</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-xlbck</span>
<span class="c">#    ...</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span>  <span class="k">do </span>curl <span class="nt">-s</span> http://127.0.0.1:30000 | <span class="nb">grep </span>name<span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;   29 Server hostname: timeserver-549cc9bc89-xlbck</span>
<span class="c">#      27 Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#      22 Server hostname: timeserver-549cc9bc89-kdmgx</span>
<span class="c">#      22 Server hostname: timeserver-549cc9bc89-h9q6p</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 파드 수 만큼 자동으로 로드밸런싱 되는것을 확인 할 수 있습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<h5 id="앱-업데이트-후-재배포">앱 업데이트 후 재배포</h5>

<ul>
  <li>샘플 앱의 server.py와 VERSION 파일을 업데이트하고, Jenkins Pipeline을 통해 새로운 버전을 배포해보겠습니다.</li>
  <li>먼저 샘플 앱의 업데이트를 진행합니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 업데이트</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s1">'s/0.0.1/0.0.2/g'</span> server.py
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"0.0.2"</span> <span class="o">&gt;</span> VERSION
<span class="nv">$ </span>git add <span class="nb">.</span>
<span class="nv">$ </span>git commit <span class="nt">-m</span> <span class="s2">"Update to 0.0.2"</span>
<span class="c"># =&gt; main c17ce89] Update to 0.0.2</span>
<span class="c">#     2 files changed, 2 insertions(+), 2 deletions(-)</span>
<span class="nv">$ </span>git push origin main
<span class="c"># =&gt; Enumerating objects: 7, done.</span>
<span class="c">#    Counting objects: 100% (7/7), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (3/3), done.</span>
<span class="c">#    Writing objects: 100% (4/4), 332 bytes | 332.00 KiB/s, done.</span>
<span class="c">#    Total 4 (delta 2), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To http://10.0.4.3:3000/devops/dev-app.git</span>
<span class="c">#       3531233..c17ce89  main -&amp;gt; main</span>
</code></pre></div>    </div>
  </li>
  <li>Jenkins에서 Build Now를 클릭하여 통해 새로운 버전을 docker hub에 업로드 합니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_17.png" alt="img.png" /></p>

<ul>
  <li>새로운 버전이 docker hub에 업로드 되었으니, Kubernetes 클러스터에 배포해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 파드 복제복 증가</span>
<span class="nv">$ </span>kubectl scale deployment timeserver <span class="nt">--replicas</span> 4
<span class="c"># =&gt; deployment.apps/timeserver scaled</span>
<span class="nv">$ </span>kubectl get service,ep timeserver <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                 TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE   SELECTOR</span>
<span class="c">#    service/timeserver   NodePort   10.96.204.127   &amp;lt;none&amp;gt;        80:30000/TCP   45m   pod=timeserver-pod</span>
<span class="c">#    </span>
<span class="c">#    NAME                   ENDPOINTS                                               AGE</span>
<span class="c">#    endpoints/timeserver   10.244.1.6:80,10.244.1.7:80,10.244.2.8:80 + 1 more...   45m</span>

<span class="c"># 반복 접속 해두기 : 부하분산 확인</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 http://127.0.0.1:30000 | <span class="nb">grep </span>name <span class="p">;</span> <span class="nb">sleep </span>1 <span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; Server hostname: timeserver-549cc9bc89-kdmgx</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-h9q6p</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-kdmgx</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-xlbck</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#    ...</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span>  <span class="k">do </span>curl <span class="nt">-s</span> http://127.0.0.1:30000 | <span class="nb">grep </span>name<span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;   32 Server hostname: timeserver-549cc9bc89-xlbck</span>
<span class="c">#      27 Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#      25 Server hostname: timeserver-549cc9bc89-kdmgx</span>
<span class="c">#      16 Server hostname: timeserver-549cc9bc89-h9q6p</span>

<span class="c"># 업데이트를 배포하기 위해서 kubectl set image를 통해 컨테이너 이미지를 변경합니다.</span>
<span class="c"># $ kubectl set image deployment timeserver timeserver-container=$DHUSER/dev-app:0.0.Y &amp;&amp; watch -d "kubectl get deploy,ep timeserver; echo; kubectl get rs,pod"</span>
<span class="nv">$ </span>kubectl <span class="nb">set </span>image deployment timeserver timeserver-container<span class="o">=</span><span class="nv">$DHUSER</span>/dev-app:0.0.2 <span class="o">&amp;&amp;</span> watch <span class="nt">-d</span> <span class="s2">"kubectl get deploy,ep timeserver; echo; kubectl get rs,pod"</span>
<span class="c"># =&gt; Every 2.0s: kubectl get deploy,ep timeserver; echo; kubectl get rs,pod                                                                 Balthazar.local: Sun Oct 01 01:17:30 2024</span>
<span class="c">#    ...</span>
<span class="c">#    </span>
<span class="c">#    NAME                              READY   STATUS        RESTARTS   AGE</span>
<span class="c">#    pod/timeserver-549cc9bc89-h9q6p   1/1     Terminating   0          11m</span>
<span class="c">#    pod/timeserver-549cc9bc89-kdmgx   1/1     Terminating   0          88m</span>
<span class="c">#    pod/timeserver-549cc9bc89-pvm5k   1/1     Terminating   0          81m</span>
<span class="c">#    pod/timeserver-549cc9bc89-xlbck   1/1     Terminating   0          11m</span>
<span class="c">#    pod/timeserver-6f476fdbf-f8hw5    1/1     Running       0          9s</span>
<span class="c">#    pod/timeserver-6f476fdbf-k5fsn    1/1     Running       0          9s</span>
<span class="c">#    pod/timeserver-6f476fdbf-qq465    1/1     Running       0          4s</span>
<span class="c">#    pod/timeserver-6f476fdbf-tvrl5    1/1     Running       0          3s</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 기존 버전의 파드가 종료되고 새로운 파드가 replica 수 만큼 생성 되는 것을 확인 할 수 있습니다.&lt;/span&gt;</span>

<span class="c"># 롤링업데이트를 확인하기 위해 별도의 터미널에서 다음의 명령을 입력합니다.</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 http://127.0.0.1:30000<span class="p">;</span> <span class="nb">sleep </span>1 <span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    The time is 4:17:24 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#    The time is 4:17:25 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-xlbck</span>
<span class="c">#    The time is 4:17:26 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-xlbck</span>
<span class="c">#    The time is 4:17:27 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#    The time is 4:17:28 PM, VERSION 0.0.2</span>
<span class="c">#    Server hostname: timeserver-6f476fdbf-k5fsn</span>
<span class="c">#    The time is 4:17:29 PM, VERSION 0.0.2</span>
<span class="c">#    Server hostname: timeserver-6f476fdbf-qq465</span>
<span class="c">#    The time is 4:17:30 PM, VERSION 0.0.2</span>
<span class="c">#    Server hostname: timeserver-6f476fdbf-tvrl5</span>
<span class="c">#    The time is 4:17:31 PM, VERSION 0.0.2</span>
<span class="c">#    Server hostname: timeserver-6f476fdbf-f8hw5</span>
<span class="c">#    The time is 4:17:32 PM, VERSION 0.0.2</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 롤링업데이트를 통해 서비스 중단 없이 배포가 잘 됨을 확인 할 수 있습니다.&lt;/span&gt;</span>


<span class="c"># 롤링 업데이트 확인</span>
<span class="nv">$ </span>kubectl get deploy,rs,pod,svc,ep <span class="nt">-owide</span>

<span class="c"># kubectl get deploy $DEPLOYMENT_NAME</span>
<span class="nv">$ </span>kubectl get deploy timeserver
<span class="c"># =&gt; NAME         READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    timeserver   4/4     4            4           90m</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 READY는 전체 replica 중 몇 개의 파드가 서비스가 가능한지 알려줍니다.&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;    UP-TO-DATE는 몇 개의 파드가 현재의 버전(상태)인지 알려줍니다.&lt;/span&gt;</span>

<span class="nv">$ </span>kubectl get pods <span class="nt">-l</span> <span class="nv">pod</span><span class="o">=</span>timeserver-pod
<span class="c"># =&gt; NAME                         READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    timeserver-6f476fdbf-f8hw5   1/1     Running   0          3m3s</span>
<span class="c">#    timeserver-6f476fdbf-k5fsn   1/1     Running   0          3m3s</span>
<span class="c">#    timeserver-6f476fdbf-qq465   1/1     Running   0          2m58s</span>
<span class="c">#    timeserver-6f476fdbf-tvrl5   1/1     Running   0          2m57s</span>
</code></pre></div></div>

<h4 id="gogs-webhook을-통해-jenkins-pipeline-자동화">Gogs Webhook을 통해 Jenkins Pipeline 자동화</h4>

<ul>
  <li>Jenkins Pipeline을 통해 새로운 버전을 배포하는 과정을 자동화하기 위해 Gogs Webhook을 설정해보겠습니다.</li>
  <li>git push를 통해 새로운 버전을 업로드하면, Gogs Webhook을 통해 Jenkins Pipeline이 자동으로 실행되어 새로운 버전의 도커 이미지가 docker hub에 업로드되도록 합니다.</li>
</ul>

<h5 id="gogs-설정-수정-및-webhook-설정">Gogs 설정 수정 및 Webhook 설정</h5>

<ul>
  <li>
    <p>먼저 gogs 컨테이너의 app.ini 파일을 수정하여 jenkins가 gogs에 접근할 수 있도록 설정합니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># app.ini 파일 수정</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>gogs vi /data/gogs/conf/app.ini
</code></pre></div>    </div>

    <div class="language-ini highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># app.ini
</span><span class="err">...</span>
<span class="nn">[security]</span>
<span class="py">INSTALL_LOCK</span> <span class="p">=</span> <span class="s">true</span>
<span class="py">SECRET_KEY</span>   <span class="p">=</span> <span class="s">atxaUPQcbAEwpIu</span>
<span class="py">LOCAL_NETWORK_ALLOWLIST</span> <span class="p">=</span> <span class="s">10.0.4.3 # 각자 자신의 PC IP</span>
<span class="err">...</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>Gogs 컨테이너를 재기동합니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker compose restart gogs
</code></pre></div>    </div>
  </li>
  <li>
    <p>Gogs 에서 Webhook을 설정합니다.</p>
    <ol>
      <li>Repository를 선택후 우측의 Settings &gt; Webhooks &gt; Add a new webhook에서 Gogs를 선택합니다.
  <img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_18.png" alt="img.png" /></li>
      <li>Payload URL : <code class="language-plaintext highlighter-rouge">http://&lt;Jenkins의 IP = PC의 IP&gt;:8080/gogs-webhook/?job=SCM-Pipeline/</code></li>
      <li>Content Type : <code class="language-plaintext highlighter-rouge">application/json</code></li>
      <li>Secret : <code class="language-plaintext highlighter-rouge">qwe123</code></li>
      <li>When should this webhook be triggered? : Just the push event</li>
      <li>Active : 체크</li>
      <li>Add Webhook을 클릭하여 웹훅을 저장합니다.</li>
    </ol>
  </li>
</ul>

<h5 id="jenkins에서-gogs-webhook을-통한-pipeline-생성">Jenkins에서 Gogs Webhook을 통한 Pipeline 생성</h5>

<ul>
  <li>이번에는 Jenkins에서 앞서 생성한 Gogs Webhook을 통해 새로운 버전을 배포하는 Pipeline을 생성해보겠습니다.</li>
  <li>Dashboard &gt; New Item 을 선택합니다.
    <ul>
      <li>item name : SCM-Pipeline</li>
      <li>item type : Pipeline</li>
      <li>OK를 클릭합니다.</li>
    </ul>
  </li>
  <li>Pipeline 설정을 다음과 같이 설정합니다.
    <ul>
      <li>GitHub project : <code class="language-plaintext highlighter-rouge">http://&lt;PC의 IP&gt;:3000/&lt;Gogs 계정명&gt;/dev-app.git</code></li>
      <li>Use Gogs secret : <code class="language-plaintext highlighter-rouge">qwe123</code></li>
      <li>Build Triggers : Build when a change is pushed to Gogs 체크</li>
      <li>Pipeline script from SCM
        <ul>
          <li>SCM : Git
            <ul>
              <li>Repo URL : <code class="language-plaintext highlighter-rouge">http://&lt;PC의 IP&gt;:3000/&lt;Gogs 계정명&gt;/dev-app.git</code></li>
              <li>Credentials : <code class="language-plaintext highlighter-rouge">devops/*</code></li>
              <li>Branch : <code class="language-plaintext highlighter-rouge">*/main</code></li>
            </ul>
          </li>
          <li>Script Path : <code class="language-plaintext highlighter-rouge">Jenkinsfile</code> 
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_19.png" alt="img.png" /></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h5 id="jenkinsfile-작성-후-git-push">Jenkinsfile 작성 후 Git Push</h5>

<ul>
  <li>Jenkinsfile을 작성합니다.</li>
</ul>

<div class="language-groovy highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pipeline</span> <span class="o">{</span>
    <span class="n">agent</span> <span class="n">any</span>
    <span class="n">environment</span> <span class="o">{</span>
        <span class="n">DOCKER_IMAGE</span> <span class="o">=</span> <span class="s1">'&lt;자신의 도커 허브 계정&gt;/dev-app'</span> <span class="c1">// Docker 이미지 이름</span>
    <span class="o">}</span>
    <span class="n">stages</span> <span class="o">{</span>
        <span class="n">stage</span><span class="o">(</span><span class="s1">'Checkout'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                 <span class="n">git</span> <span class="nl">branch:</span> <span class="s1">'main'</span><span class="o">,</span>
                 <span class="nl">url:</span> <span class="s1">'http://&lt;PC의 IP&gt;:3000/devops/dev-app.git'</span><span class="o">,</span>  <span class="c1">// Git에서 코드 체크아웃</span>
                 <span class="nl">credentialsId:</span> <span class="s1">'gogs-crd'</span>  <span class="c1">// Credentials ID</span>
            <span class="o">}</span>
        <span class="o">}</span>
        <span class="n">stage</span><span class="o">(</span><span class="s1">'Read VERSION'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">script</span> <span class="o">{</span>
                    <span class="c1">// VERSION 파일 읽기</span>
                    <span class="kt">def</span> <span class="n">version</span> <span class="o">=</span> <span class="n">readFile</span><span class="o">(</span><span class="s1">'VERSION'</span><span class="o">).</span><span class="na">trim</span><span class="o">()</span>
                    <span class="n">echo</span> <span class="s2">"Version found: ${version}"</span>
                    <span class="c1">// 환경 변수 설정</span>
                    <span class="n">env</span><span class="o">.</span><span class="na">DOCKER_TAG</span> <span class="o">=</span> <span class="n">version</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
        <span class="n">stage</span><span class="o">(</span><span class="s1">'Docker Build and Push'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">script</span> <span class="o">{</span>
                    <span class="n">docker</span><span class="o">.</span><span class="na">withRegistry</span><span class="o">(</span><span class="s1">'https://index.docker.io/v1/'</span><span class="o">,</span> <span class="s1">'dockerhub-crd'</span><span class="o">)</span> <span class="o">{</span>
                        <span class="c1">// DOCKER_TAG 사용</span>
                        <span class="kt">def</span> <span class="n">appImage</span> <span class="o">=</span> <span class="n">docker</span><span class="o">.</span><span class="na">build</span><span class="o">(</span><span class="s2">"${DOCKER_IMAGE}:${DOCKER_TAG}"</span><span class="o">)</span>
                        <span class="n">appImage</span><span class="o">.</span><span class="na">push</span><span class="o">()</span>
                        <span class="n">appImage</span><span class="o">.</span><span class="na">push</span><span class="o">(</span><span class="s2">"latest"</span><span class="o">)</span>
                    <span class="o">}</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
    <span class="n">post</span> <span class="o">{</span>
        <span class="n">success</span> <span class="o">{</span>
            <span class="n">echo</span> <span class="s2">"Docker image ${DOCKER_IMAGE}:${DOCKER_TAG} has been built and pushed successfully!"</span>
        <span class="o">}</span>
        <span class="n">failure</span> <span class="o">{</span>
            <span class="n">echo</span> <span class="s2">"Pipeline failed. Please check the logs."</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<ul>
  <li>VERSION 파일과 server.py 파일을 0.0.2 =&gt; 0.0.3으로 수정합니다.</li>
  <li>작성된 파일 push</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"VERSION </span><span class="si">$(</span><span class="nb">cat </span>VERSION<span class="si">)</span><span class="s2"> Changed"</span> <span class="o">&amp;&amp;</span> git push <span class="nt">-u</span> origin main
</code></pre></div></div>

<ul>
  <li>Push와 거의 동시에 Jenkins에서 Build가 시작되고 성공적으로 빌드가 되었습니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_20.png" alt="img.png" /></p>

<ul>
  <li>Docker hub에도 0.0.3 버전이 업로드 잘 되었습니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_21.png" alt="img.png" /></p>

<ul>
  <li>Gogs에서 Repository &gt; Settings &gt; Webhooks &gt; 웹훅 클릭하면 웹훅 전달 로그를 확인할 수 있습니다.
Gogs =&gt; Jenkins의 방향으로 Webhook이 전달되었음을 확인할 수 있습니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_22.png" alt="img.png" /></p>

<ul>
  <li>마지막으로 Kubernetes 클러스터에서 새로운 버전을 배포하겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl <span class="nb">set </span>image deployment timeserver timeserver-container<span class="o">=</span><span class="nv">$DHUSER</span>/dev-app:0.0.3 <span class="o">&amp;&amp;</span> watch <span class="nt">-d</span> <span class="s2">"kubectl get deploy,ep timeserver; echo; kubectl get rs,pod"</span>
</code></pre></div></div>

<hr />

<h3 id="jenkins-cicd--k8s-kind">Jenkins CI/CD + K8S (Kind)</h3>

<ul>
  <li>이번에는 Jenkins에서 바로 Kubernetes 클러스터에 배포할 수 있도록 하는 실습을 진행해보겠습니다.</li>
  <li>Jenkins 컨테이너 내부에 필요한 툴(kubectl, helm)을 설치 하겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Install kubectl, helm</span>
<span class="nv">$ </span>docker compose <span class="nb">exec</span> <span class="nt">--privileged</span> <span class="nt">-u</span> root jenkins bash
<span class="nt">--------------------------------------------</span>
<span class="c">#curl -LO "https://dl.k8s.io/release/v1.31.0/bin/linux/amd64/kubectl" </span>
<span class="nv">$ </span>curl <span class="nt">-LO</span> <span class="s2">"https://dl.k8s.io/release/</span><span class="si">$(</span>curl <span class="nt">-L</span> <span class="nt">-s</span> https://dl.k8s.io/release/stable.txt<span class="si">)</span><span class="s2">/bin/linux/arm64/kubectl"</span>  <span class="c"># macOS</span>
<span class="c"># $ curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"  # WindowOS</span>

<span class="nv">$ </span><span class="nb">install</span> <span class="nt">-o</span> root <span class="nt">-g</span> root <span class="nt">-m</span> 0755 kubectl /usr/local/bin/kubectl
<span class="nv">$ </span>kubectl version <span class="nt">--client</span><span class="o">=</span><span class="nb">true</span>
<span class="c"># =&gt; Client Version: v1.32.0</span>
<span class="c">#    Kustomize Version: v5.5.0</span>

<span class="c">#</span>
<span class="nv">$ </span>curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
<span class="nv">$ </span>helm version
<span class="c"># =&gt; version.BuildInfo{Version:&amp;quot;v3.16.4&amp;quot;, GitCommit:&amp;quot;7877b45b63f95635153b29a42c0c2f4273ec45ca&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;, GoVersion:&amp;quot;go1.22.7&amp;quot;}</span>

<span class="nv">$ </span><span class="nb">exit</span>
<span class="nt">--------------------------------------------</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins kubectl version <span class="nt">--client</span><span class="o">=</span><span class="nb">true</span>
<span class="c"># =&gt; Client Version: v1.32.0</span>
<span class="c">#    Kustomize Version: v5.5.0</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins helm version
<span class="c"># =&gt; version.BuildInfo{Version:&amp;quot;v3.16.4&amp;quot;, GitCommit:&amp;quot;7877b45b63f95635153b29a42c0c2f4273ec45ca&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;, GoVersion:&amp;quot;go1.22.7&amp;quot;}</span>
</code></pre></div></div>

<ul>
  <li>Jenkins Item 생성(Pipeline) : item name(k8s-cmd)</li>
</ul>

<div class="language-gradle highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pipeline</span> <span class="o">{</span>
    <span class="n">agent</span> <span class="n">any</span>
    <span class="n">environment</span> <span class="o">{</span>
        <span class="n">KUBECONFIG</span> <span class="o">=</span> <span class="n">credentials</span><span class="o">(</span><span class="s1">'k8s-crd'</span><span class="o">)</span>
    <span class="o">}</span>
    <span class="n">stages</span> <span class="o">{</span>
        <span class="n">stage</span><span class="o">(</span><span class="s1">'List Pods'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">sh</span> <span class="s1">'''
                # Fetch and display Pods
                kubectl get pods -A --kubeconfig "$KUBECONFIG"
                '''</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_23.png" alt="img.png" /></p>

<h5 id="jenkins를-이용한-blue-green-배포-실습">Jenkins를 이용한 blue-green 배포 실습</h5>

<ul>
  <li>디플로이먼트 / 서비스 yaml 파일 작성 - http-echo 및 코드 push</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># </span>
<span class="nv">$ </span><span class="nb">cd </span>dev-app

<span class="c">#</span>
<span class="nv">$ </span><span class="nb">mkdir </span>deploy

<span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> deploy/echo-server-blue.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: apps/v1
kind: Deployment
metadata:
  name: echo-server-blue
spec:
  replicas: 2
  selector:
    matchLabels:
      app: echo-server
      version: blue
  template:
    metadata:
      labels:
        app: echo-server
        version: blue
    spec:
      containers:
      - name: echo-server
        image: hashicorp/http-echo
        args:
        - "-text=Hello from Blue"
        ports:
        - containerPort: 5678
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> deploy/echo-server-service.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: v1
kind: Service
metadata:
  name: echo-server-service
spec:
  selector:
    app: echo-server
    version: blue
  ports:
  - protocol: TCP
    port: 80
    targetPort: 5678
    nodePort: 30000
  type: NodePort
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> deploy/echo-server-green.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: apps/v1
kind: Deployment
metadata:
  name: echo-server-green
spec:
  replicas: 2
  selector:
    matchLabels:
      app: echo-server
      version: green
  template:
    metadata:
      labels:
        app: echo-server
        version: green
    spec:
      containers:
      - name: echo-server
        image: hashicorp/http-echo
        args:
        - "-text=Hello from Green"
        ports:
        - containerPort: 5678
</span><span class="no">EOF

</span><span class="c">#</span>
<span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"Add echo server yaml"</span> <span class="o">&amp;&amp;</span> git push <span class="nt">-u</span> origin main
<span class="c"># =&gt; main 76adc73] Add echo server yaml</span>
<span class="c">#     3 files changed, 60 insertions(+)</span>
<span class="c">#     create mode 100644 deploy/echo-server-blue.yaml</span>
<span class="c">#     create mode 100644 deploy/echo-server-green.yaml</span>
<span class="c">#     create mode 100644 deploy/echo-server-service.yaml</span>
<span class="c">#    Enumerating objects: 7, done.</span>
<span class="c">#    Counting objects: 100% (7/7), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (6/6), done.</span>
<span class="c">#    Writing objects: 100% (6/6), 789 bytes | 789.00 KiB/s, done.</span>
<span class="c">#    Total 6 (delta 2), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To http://10.0.4.3:3000/devops/dev-app.git</span>
<span class="c">#       60f336b..76adc73  main -&amp;gt; main</span>
<span class="c">#    branch 'main' set up to track 'origin/main'.</span>
</code></pre></div></div>

<ul>
  <li>Jenkins에서 Pipeline을 작성하여 배포해 보겠습니다.</li>
  <li>먼저, 이전 실습에서 배포한 deployment와 service를 삭제합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl delete deploy,svc timeserver
<span class="c"># =&gt; deployment.apps &amp;quot;timeserver&amp;quot; deleted</span>
<span class="c">#    service &amp;quot;timeserver&amp;quot; deleted</span>
</code></pre></div></div>

<ul>
  <li>반복접속을 미리 실행해둡니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 별도의 터미널에서 실행</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 http://127.0.0.1:30000 <span class="p">;</span> <span class="nb">echo</span> <span class="p">;</span> <span class="nb">sleep </span>1  <span class="p">;</span> kubectl get deploy <span class="nt">-owide</span> <span class="p">;</span> <span class="nb">echo</span> <span class="p">;</span> kubectl get svc,ep echo-server-service <span class="nt">-owide</span> <span class="p">;</span> <span class="nb">echo</span> <span class="s2">"------------"</span> <span class="p">;</span> <span class="k">done</span>
<span class="c"># 혹은 </span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 http://127.0.0.1:30000 <span class="p">;</span> <span class="nb">date</span> <span class="p">;</span> <span class="nb">echo</span> <span class="s2">"------------"</span> <span class="p">;</span> <span class="nb">sleep </span>1 <span class="p">;</span> <span class="k">done</span>
</code></pre></div></div>

<ul>
  <li>Jenkins에서 Pipeline 생성 : item name(k8s-bluegreen)</li>
</ul>

<div class="language-gradle highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pipeline</span> <span class="o">{</span>
    <span class="n">agent</span> <span class="n">any</span>

    <span class="n">environment</span> <span class="o">{</span>
        <span class="n">KUBECONFIG</span> <span class="o">=</span> <span class="n">credentials</span><span class="o">(</span><span class="s1">'k8s-crd'</span><span class="o">)</span>
    <span class="o">}</span>

    <span class="n">stages</span> <span class="o">{</span>
        <span class="n">stage</span><span class="o">(</span><span class="s1">'Checkout'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                 <span class="n">git</span> <span class="nl">branch:</span> <span class="s1">'main'</span><span class="o">,</span>
                 <span class="nl">url:</span> <span class="s1">'http://&lt;PC의 IP&gt;:3000/devops/dev-app.git'</span><span class="o">,</span>  <span class="c1">// Git에서 코드 체크아웃</span>
                 <span class="nl">credentialsId:</span> <span class="s1">'gogs-crd'</span>  <span class="c1">// Credentials ID</span>
            <span class="o">}</span>
        <span class="o">}</span>

        <span class="n">stage</span><span class="o">(</span><span class="s1">'container image build'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">echo</span> <span class="s2">"container image build"</span>
            <span class="o">}</span>
        <span class="o">}</span>

        <span class="n">stage</span><span class="o">(</span><span class="s1">'container image upload'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">echo</span> <span class="s2">"container image upload"</span>
            <span class="o">}</span>
        <span class="o">}</span>

        <span class="n">stage</span><span class="o">(</span><span class="s1">'k8s deployment blue version'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">sh</span> <span class="s2">"kubectl apply -f ./deploy/echo-server-blue.yaml --kubeconfig $KUBECONFIG"</span>
                <span class="n">sh</span> <span class="s2">"kubectl apply -f ./deploy/echo-server-service.yaml --kubeconfig $KUBECONFIG"</span>
            <span class="o">}</span>
        <span class="o">}</span>

        <span class="n">stage</span><span class="o">(</span><span class="s1">'approve green version'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">input</span> <span class="nl">message:</span> <span class="s1">'approve green version'</span><span class="o">,</span> <span class="nl">ok:</span> <span class="s2">"Yes"</span>
            <span class="o">}</span>
        <span class="o">}</span>

        <span class="n">stage</span><span class="o">(</span><span class="s1">'k8s deployment green version'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
	        	<span class="n">sh</span> <span class="s2">"kubectl apply -f ./deploy/echo-server-green.yaml --kubeconfig $KUBECONFIG"</span>
            <span class="o">}</span>
        <span class="o">}</span>

        <span class="n">stage</span><span class="o">(</span><span class="s1">'approve version switching'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">script</span> <span class="o">{</span>
                    <span class="n">returnValue</span> <span class="o">=</span> <span class="n">input</span> <span class="nl">message:</span> <span class="s1">'Green switching?'</span><span class="o">,</span> <span class="nl">ok:</span> <span class="s2">"Yes"</span><span class="o">,</span> <span class="nl">parameters:</span> <span class="o">[</span><span class="n">booleanParam</span><span class="o">(</span><span class="nl">defaultValue:</span> <span class="kc">true</span><span class="o">,</span> <span class="nl">name:</span> <span class="s1">'IS_SWITCHED'</span><span class="o">)]</span>
                    <span class="k">if</span> <span class="o">(</span><span class="n">returnValue</span><span class="o">)</span> <span class="o">{</span>
                        <span class="n">sh</span> <span class="s2">"kubectl patch svc echo-server-service -p '{\"spec\": {\"selector\": {\"version\": \"green\"}}}' --kubeconfig $KUBECONFIG"</span>
                    <span class="o">}</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>

        <span class="n">stage</span><span class="o">(</span><span class="s1">'Blue Rollback'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">script</span> <span class="o">{</span>
                    <span class="n">returnValue</span> <span class="o">=</span> <span class="n">input</span> <span class="nl">message:</span> <span class="s1">'Blue Rollback?'</span><span class="o">,</span> <span class="nl">parameters:</span> <span class="o">[</span><span class="n">choice</span><span class="o">(</span><span class="nl">choices:</span> <span class="o">[</span><span class="s1">'done'</span><span class="o">,</span> <span class="s1">'rollback'</span><span class="o">],</span> <span class="nl">name:</span> <span class="s1">'IS_ROLLBACk'</span><span class="o">)]</span>
                    <span class="k">if</span> <span class="o">(</span><span class="n">returnValue</span> <span class="o">==</span> <span class="s2">"done"</span><span class="o">)</span> <span class="o">{</span>
                        <span class="n">sh</span> <span class="s2">"kubectl delete -f ./deploy/echo-server-blue.yaml --kubeconfig $KUBECONFIG"</span>
                    <span class="o">}</span>
                    <span class="k">if</span> <span class="o">(</span><span class="n">returnValue</span> <span class="o">==</span> <span class="s2">"rollback"</span><span class="o">)</span> <span class="o">{</span>
                        <span class="n">sh</span> <span class="s2">"kubectl patch svc echo-server-service -p '{\"spec\": {\"selector\": {\"version\": \"blue\"}}}' --kubeconfig $KUBECONFIG"</span>
                    <span class="o">}</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<ul>
  <li>Build Now로 배포 후 동작을 확인합니다.
    <ul>
      <li>blue 버전이 배포된 다음 green 버전을 배포할지 승인 여부를 묻습니다.
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_24.png" alt="img.png" /></li>
      <li>승인하면 green 버전이 배포됩니다. 하지만 아직 트래픽은 Blue로만 흐릅니다.
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl get deploy <span class="nt">-owide</span> <span class="p">;</span> <span class="nb">echo</span> <span class="p">;</span> kubectl get svc,ep echo-server-service <span class="nt">-owide</span>
<span class="c"># =&gt; Hello from Blue</span>
<span class="c">#    </span>
<span class="c">#    NAME                READY   UP-TO-DATE   AVAILABLE   AGE     CONTAINERS    IMAGES                SELECTOR</span>
<span class="c">#    echo-server-blue    2/2     2            2           3m46s   echo-server   hashicorp/http-echo   app=echo-server,version=blue</span>
<span class="c">#    echo-server-green   2/2     2            2           31s     echo-server   hashicorp/http-echo   app=echo-server,version=green</span>
<span class="c">#    </span>
<span class="c">#    NAME                          TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE     SELECTOR</span>
<span class="c">#    service/echo-server-service   NodePort   10.96.40.148   &amp;lt;none&amp;gt;        80:30000/TCP   3m45s   app=echo-server,version=blue</span>
<span class="c">#    </span>
<span class="c">#    NAME                            ENDPOINTS                         AGE</span>
<span class="c">#    endpoints/echo-server-service   10.244.1.8:5678,10.244.2.8:5678   3m45s</span>
</code></pre></div>        </div>
      </li>
      <li>green으로 배포할지 승인하면 마침내 green으로 트래픽이 전달 됩니다. 
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_25.png" alt="img.png" />
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl get deploy <span class="nt">-owide</span> <span class="p">;</span> <span class="nb">echo</span> <span class="p">;</span> kubectl get svc,ep echo-server-service <span class="nt">-owide</span>
<span class="c"># =&gt; Hello from Green</span>
<span class="c">#    </span>
<span class="c">#    NAME                READY   UP-TO-DATE   AVAILABLE   AGE     CONTAINERS    IMAGES                SELECTOR</span>
<span class="c">#    echo-server-blue    2/2     2            2           6m14s   echo-server   hashicorp/http-echo   app=echo-server,version=blue</span>
<span class="c">#    echo-server-green   2/2     2            2           2m59s   echo-server   hashicorp/http-echo   app=echo-server,version=green</span>
<span class="c">#    </span>
<span class="c">#    NAME                          TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE     SELECTOR</span>
<span class="c">#    service/echo-server-service   NodePort   10.96.40.148   &amp;lt;none&amp;gt;        80:30000/TCP   6m13s   app=echo-server,version=green</span>
<span class="c">#    </span>
<span class="c">#    NAME                            ENDPOINTS                         AGE</span>
<span class="c">#    endpoints/echo-server-service   10.244.1.9:5678,10.244.2.9:5678   6m13s</span>
</code></pre></div>        </div>
      </li>
      <li>마지막으로 blue를 롤백할지 물으며, 승인하면 blue가 삭제 됩니다.
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># =&gt; Hello from Green</span>
<span class="c">#    </span>
<span class="c">#    NAME                READY   UP-TO-DATE   AVAILABLE   AGE     CONTAINERS    IMAGES                SELECTOR</span>
<span class="c">#    echo-server-green   2/2     2            2           4m55s   echo-server   hashicorp/http-echo   app=echo-server,version=green</span>
<span class="c">#    </span>
<span class="c">#    NAME                          TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE    SELECTOR</span>
<span class="c">#    service/echo-server-service   NodePort   10.96.40.148   &amp;lt;none&amp;gt;        80:30000/TCP   8m9s   app=echo-server,version=green</span>
<span class="c">#    </span>
<span class="c">#    NAME                            ENDPOINTS                         AGE</span>
<span class="c">#    endpoints/echo-server-service   10.244.1.9:5678,10.244.2.9:5678   8m9s</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li>실습 완료 후 삭제</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl delete deploy echo-server-blue echo-server-green
<span class="nv">$ </span>kubectl delete svc echo-server-service
</code></pre></div></div>

<h3 id="jenkins-ci--argocd--k8s-kind">Jenkins CI + ArgoCD + K8S (Kind)</h3>

<h4 id="argocd-소개">ArgoCD 소개</h4>

<ul>
  <li>ArgoCD는 GitOps를 지원하는 CD 도구로, Kubernetes 클러스터에 배포된 애플리케이션의 상태를 지속적으로 모니터링하고,
Git 저장소에 정의된 상태와 실제 상태가 일치하지 않을 경우 자동으로 동기화하여 애플리케이션을 원하는 상태로 유지하는 툴입니다.</li>
  <li>ArgoCD의 아키텍쳐
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_26.png" alt="img.png" /></li>
  <li>ArgoCD는 배포된 애플리케이션의 상태인 Kubernetes manifest를 다음의 방식들로 정의할 수 있습니다.
    <ul>
      <li><a href="https://kustomize.io/">Kustomize</a> 애플리케이션</li>
      <li><a href="https://helm.sh/">helm</a> chart</li>
      <li><a href="https://jsonnet.org/">jsonnet</a> 파일</li>
      <li>yaml/json manifest 파일이 있는 디렉터리</li>
      <li>기타 config management plugin에서 정의한 파일</li>
    </ul>
  </li>
  <li>자세한 사항은 <a href="https://argoproj.github.io/">공식 홈페이지</a>나 <a href="https://malwareanalysis.tistory.com/tag/ArgoCD">악분님 ArgoCD 정리 블로그</a>를 참고해주세요.</li>
</ul>

<h4 id="argocd-설치-및-기본설정">ArgoCD 설치 및 기본설정</h4>

<ul>
  <li>ArgoCD를 설치하고 기본 설정을 진행해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 네임스페이스 생성 및 파라미터 파일 작성</span>
<span class="nv">$ </span>kubectl create ns argocd
<span class="c"># =&gt; namespace/argocd created</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; argocd-values.yaml
dex:
  enabled: false

server:
  service:
    type: NodePort
    nodePortHttps: 30002
</span><span class="no">EOF

</span><span class="c"># 설치</span>
<span class="nv">$ </span>helm repo add argo https://argoproj.github.io/argo-helm
<span class="c"># =&gt; &amp;quot;argo&amp;quot; has been added to your repositories</span>
<span class="nv">$ </span>helm <span class="nb">install </span>argocd argo/argo-cd <span class="nt">--version</span> 7.7.10 <span class="nt">-f</span> argocd-values.yaml <span class="nt">--namespace</span> argocd
<span class="c"># =&gt; NAME: argocd</span>
<span class="c">#    LAST DEPLOYED: Sun Oct 01 16:53:42 2024</span>
<span class="c">#    NAMESPACE: argocd</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 1</span>
<span class="c">#    TEST SUITE: None</span>
<span class="c">#    NOTES:</span>
<span class="c">#    In order to access the server UI you have the following options:</span>
<span class="c">#    </span>
<span class="c">#    1. kubectl port-forward service/argocd-server -n argocd 8080:443</span>
<span class="c">#        and then open the browser on http://localhost:8080 and accept the certificate</span>
<span class="c">#    </span>
<span class="c">#    2. enable ingress in the values file `server.ingress.enabled` and either</span>
<span class="c">#          - Add the annotation for ssl passthrough: https://argo-cd.readthedocs.io/en/stable/operator-manual/ingress/#option-1-ssl-passthrough</span>
<span class="c">#          - Set the `configs.params.&amp;quot;server.insecure&amp;quot;` in the values file and terminate SSL at your ingress: https://argo-cd.readthedocs.io/en/stable/operator-manual/ingress/#option-2-multiple-ingress-objects-and-hosts</span>
<span class="c">#    </span>
<span class="c">#    After reaching the UI the first time you can login with username: admin and the random password generated during the installation. You can find the password by running:</span>
<span class="c">#    kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath=&amp;quot;{.data.password}&amp;quot; | base64 -d</span>
<span class="c">#    (You should delete the initial secret afterwards as suggested by the Getting Started Guide: https://argo-cd.readthedocs.io/en/stable/getting_started/#4-login-using-the-cli)</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get pod,svc,ep <span class="nt">-n</span> argocd
<span class="c"># =&gt; NAME                                                    READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/argocd-application-controller-0                     1/1     Running   0          4m55s</span>
<span class="c">#    pod/argocd-applicationset-controller-856f6bd788-zvtd2   1/1     Running   0          4m55s</span>
<span class="c">#    pod/argocd-notifications-controller-764b9d6597-z4mrx    1/1     Running   0          4m55s</span>
<span class="c">#    pod/argocd-redis-5c67786686-qwx8f                       1/1     Running   0          4m55s</span>
<span class="c">#    pod/argocd-repo-server-c9f8b6dbf-jpjcq                  1/1     Running   0          4m55s</span>
<span class="c">#    pod/argocd-server-7bff46b6bd-7n6vx                      1/1     Running   0          4m55s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                       TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE</span>
<span class="c">#    service/argocd-applicationset-controller   ClusterIP   10.96.166.245   &amp;lt;none&amp;gt;        7000/TCP                     4m55s</span>
<span class="c">#    service/argocd-redis                       ClusterIP   10.96.46.103    &amp;lt;none&amp;gt;        6379/TCP                     4m55s</span>
<span class="c">#    service/argocd-repo-server                 ClusterIP   10.96.117.132   &amp;lt;none&amp;gt;        8081/TCP                     4m55s</span>
<span class="c">#    service/argocd-server                      NodePort    10.96.75.70     &amp;lt;none&amp;gt;        80:30080/TCP,443:30002/TCP   4m55s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                         ENDPOINTS                           AGE</span>
<span class="c">#    endpoints/argocd-applicationset-controller   10.244.2.13:7000                    4m55s</span>
<span class="c">#    endpoints/argocd-redis                       10.244.2.12:6379                    4m55s</span>
<span class="c">#    endpoints/argocd-repo-server                 10.244.1.11:8081                    4m55s</span>
<span class="c">#    endpoints/argocd-server                      10.244.1.10:8080,10.244.1.10:8080   4m55s</span>
<span class="nv">$ </span>kubectl get crd | <span class="nb">grep </span>argo
<span class="c"># =&gt; applications.argoproj.io      2024-10-01T07:54:01Z</span>
<span class="c">#    applicationsets.argoproj.io   2024-10-01T07:54:01Z</span>
<span class="c">#    appprojects.argoproj.io       2024-10-01T07:54:01Z</span>

<span class="c"># 최초 접속 암호 확인</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> argocd get secret argocd-initial-admin-secret <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.data.password}"</span> | <span class="nb">base64</span> <span class="nt">-d</span> <span class="p">;</span><span class="nb">echo</span>
<span class="c"># =&gt; ZaQfvE9xrehyKxvl</span>

<span class="c"># Argo CD 웹 접속 주소 확인 : 초기 암호 입력 (admin 계정)</span>
<span class="nv">$ </span>open <span class="s2">"https://127.0.0.1:30002"</span> <span class="c"># macOS</span>
<span class="c">## Windows OS경우 직접 웹 브라우저에서 https://127.0.0.1:30002 접속</span>
</code></pre></div></div>

<ul>
  <li>Argo CD 웹 접속 확인 - 위에서 확인한 초기 비밀번호로 로그인합니다.
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_27.png" alt="img.png" class="image-center" />
<em class="image-caption">Argo CD 웹 초기 화면</em>
    <ul>
      <li>User Info &gt; Update password로 admin 계정 암호를 변경합니다. (qwe12345)</li>
    </ul>
  </li>
  <li>Settings &gt; Clusters, Projects, Accounts 등 기본정보를 확인해봅니다.</li>
  <li>실습을 위해 ops-deploy Repo를 등록해보겠습니다.
    <ul>
      <li>Settings &gt; Repositories &gt; Connect Repo 클릭
        <ul>
          <li>connection method : VIA HTTPS</li>
          <li>Type : git</li>
          <li>Project : default</li>
          <li>Repo URL : http://<PC의 IP="">:3000/devops/ops-deploy</PC의></li>
          <li>Username : devops</li>
          <li>Password : <Gogs 토큰=""></Gogs></li>
        </ul>

        <p>=&gt;  입력 후 CONNECT 클릭
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_28.png" alt="img.png" /></p>
      </li>
      <li>모든 정보가 정확하여 연결이 되면 연결상태가 Successful로 등록됩니다.</li>
    </ul>
  </li>
</ul>

<h4 id="helm-chart를-통한-배포-실습">Helm chart를 통한 배포 실습</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">mkdir </span>nginx-chart
<span class="nv">$ </span><span class="nb">cd </span>nginx-chart

<span class="nv">$ </span><span class="nb">mkdir </span>templates

<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> templates/configmap.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: v1
kind: ConfigMap
metadata:
  name: 
data:
  index.html: |
</span><span class="no">
EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> templates/deployment.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: apps/v1
kind: Deployment
metadata:
  name: 
spec:
  replicas: 
  selector:
    matchLabels:
      app: 
  template:
    metadata:
      labels:
        app: 
    spec:
      containers:
      - name: nginx
        image: :
        ports:
        - containerPort: 80
        volumeMounts:
        - name: index-html
          mountPath: /usr/share/nginx/html/index.html
          subPath: index.html
      volumes:
      - name: index-html
        configMap:
          name: 
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> templates/service.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: v1
kind: Service
metadata:
  name: 
spec:
  selector:
    app: 
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
    nodePort: 30000
  type: NodePort
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> values.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
indexHtml: |
  &lt;!DOCTYPE html&gt;
  &lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Welcome to Nginx!&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;h1&gt;Hello, Kubernetes!&lt;/h1&gt;
    &lt;p&gt;Nginx version 1.26.1&lt;/p&gt;
  &lt;/body&gt;
  &lt;/html&gt;

image:
  repository: nginx
  tag: 1.26.1

replicaCount: 1
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Chart.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: v2
name: nginx-chart
description: A Helm chart for deploying Nginx with custom index.html
type: application
version: 1.0.0
appVersion: "1.26.1"
</span><span class="no">EOF

</span><span class="c"># 이전 timeserver/service(nodeport) 삭제</span>
<span class="nv">$ </span>kubectl delete deploy,svc <span class="nt">--all</span>

<span class="c"># 직접 배포 해보기</span>
<span class="nv">$ </span>helm <span class="nb">install </span>dev-nginx <span class="nb">.</span> <span class="nt">-f</span> values.yaml
<span class="c"># =&gt; NAME: dev-nginx</span>
<span class="c">#    LAST DEPLOYED: Sun Oct 01 19:54:23 2024</span>
<span class="c">#    NAMESPACE: default</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 1</span>
<span class="c">#    TEST SUITE: None</span>
<span class="nv">$ </span>helm list
<span class="c"># =&gt; NAME       NAMESPACE REVISION  UPDATED                             STATUS    CHART             APP VERSION</span>
<span class="c">#    dev-nginx  default   1         2024-10-01 19:54:23.03644 +0900 KST deployed  nginx-chart-1.0.0 1.26.1     </span>
<span class="nv">$ </span>kubectl get deploy,svc,ep,cm dev-nginx <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                        READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES         SELECTOR</span>
<span class="c">#    deployment.apps/dev-nginx   1/1     1            1           4s    nginx        nginx:1.26.1   app=dev-nginx</span>
<span class="c">#    </span>
<span class="c">#    NAME                TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE   SELECTOR</span>
<span class="c">#    service/dev-nginx   NodePort   10.96.79.233   &amp;lt;none&amp;gt;        80:30000/TCP   4s    app=dev-nginx</span>
<span class="c">#    </span>
<span class="c">#    NAME                  ENDPOINTS        AGE</span>
<span class="c">#    endpoints/dev-nginx   10.244.1.16:80   4s</span>
<span class="c">#    </span>
<span class="c">#    NAME                  DATA   AGE</span>
<span class="c">#    configmap/dev-nginx   1      4s</span>

<span class="c">#</span>
<span class="nv">$ </span>curl http://127.0.0.1:30000
<span class="c"># =&gt; &lt;!DOCTYPE html&amp;gt;</span>
<span class="c">#    &amp;lt;html&amp;gt;</span>
<span class="c">#    &amp;lt;head&amp;gt;</span>
<span class="c">#      &amp;lt;title&amp;gt;Welcome to Nginx!&amp;lt;/title&amp;gt;</span>
<span class="c">#    &amp;lt;/head&amp;gt;</span>
<span class="c">#    &amp;lt;body&amp;gt;</span>
<span class="c">#      &amp;lt;h1&amp;gt;Hello, Kubernetes!&amp;lt;/h1&amp;gt;</span>
<span class="c">#      &amp;lt;p&amp;gt;Nginx version 1.26.1&amp;lt;/p&amp;gt;</span>
<span class="c">#    &amp;lt;/body&amp;gt;</span>
<span class="c">#    &amp;lt;/html&amp;gt;</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> http://127.0.0.1:30000 | <span class="nb">grep </span>version
<span class="c"># =&gt;   &amp;lt;p&amp;gt;Nginx version 1.26.1&amp;lt;/p&amp;gt;</span>
<span class="nv">$ </span>open http://127.0.0.1:30000

<span class="c"># value 값 변경 후 적용 해보기 : version/tag, replicaCount</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> values.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
indexHtml: |
  &lt;!DOCTYPE html&gt;
  &lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Welcome to Nginx!&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;h1&gt;Hello, Kubernetes!&lt;/h1&gt;
    &lt;p&gt;Nginx version 1.26.2&lt;/p&gt;
  &lt;/body&gt;
  &lt;/html&gt;

image:
  repository: nginx
  tag: 1.26.2

replicaCount: 2
</span><span class="no">EOF

</span><span class="c"># helm chart 업그레이드 적용</span>
<span class="nv">$ </span>helm upgrade dev-nginx <span class="nb">.</span> <span class="nt">-f</span> values.yaml
<span class="c"># =&gt; Release &amp;quot;dev-nginx&amp;quot; has been upgraded. Happy Helming!</span>
<span class="c">#    NAME: dev-nginx</span>
<span class="c">#    LAST DEPLOYED: Sun Oct 01 19:56:59 2024</span>
<span class="c">#    NAMESPACE: default</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 2</span>
<span class="c">#    TEST SUITE: None</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>helm list
<span class="c"># =&gt; NAME            NAMESPACE       REVISION        UPDATED                                 STATUS          CHART                   APP VERSION</span>
<span class="c">#    dev-nginx       default         2               2024-10-01 19:56:59.30731 +0900 KST     deployed        nginx-chart-1.0.0       1.26.1</span>
<span class="nv">$ </span>kubectl get deploy,svc,ep,cm dev-nginx <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                        READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES         SELECTOR</span>
<span class="c">#    deployment.apps/dev-nginx   &lt;span style="color: red;"&gt;2/2     2            2&lt;/span&gt;           38s   nginx        &lt;span style="color: red;"&gt;nginx:1.26.2&lt;/span&gt;   app=dev-nginx</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 Replica가 2개로 늘어나서 파드가 2개가 되었고 버전 1.26.2가 적용되었습니다.&lt;/span&gt;</span>
<span class="nv">$ </span>curl http://127.0.0.1:30000
<span class="c"># =&gt; &amp;lt;!DOCTYPE html&amp;gt;</span>
<span class="c">#    &amp;lt;html&amp;gt;</span>
<span class="c">#    &amp;lt;head&amp;gt;</span>
<span class="c">#      &amp;lt;title&amp;gt;Welcome to Nginx!&amp;lt;/title&amp;gt;</span>
<span class="c">#    &amp;lt;/head&amp;gt;</span>
<span class="c">#    &amp;lt;body&amp;gt;</span>
<span class="c">#      &amp;lt;h1&amp;gt;Hello, Kubernetes!&amp;lt;/h1&amp;gt;</span>
<span class="c">#      &amp;lt;p&amp;gt;Nginx version 1.26.2&amp;lt;/p&amp;gt;</span>
<span class="c">#    &amp;lt;/body&amp;gt;</span>
<span class="c">#    &amp;lt;/html&amp;gt;</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> http://127.0.0.1:30000 | <span class="nb">grep </span>version
<span class="c"># =&gt;   &amp;lt;p&amp;gt;Nginx version 1.26.2&amp;lt;/p&amp;gt;</span>
<span class="nv">$ </span>open http://127.0.0.1:30000

<span class="c"># 확인 후 삭제</span>
<span class="nv">$ </span>helm uninstall dev-nginx
</code></pre></div></div>

<h5 id="repoops-deploy-에-nginx-helm-chart-를-argo-cd를-통한-배포-1">Repo(ops-deploy) 에 nginx helm chart 를 Argo CD를 통한 배포 1</h5>

<ul>
  <li>git 작업</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">mkdir </span>cicd-labs
<span class="nv">$ </span><span class="nb">cd </span>cicd-labs
<span class="nv">$ </span>git clone http://10.0.4.3:3000/devops/ops-deploy.git
<span class="c"># =&gt; Cloning into 'ops-deploy'...</span>
<span class="c">#    remote: Enumerating objects: 3, done.</span>
<span class="c">#    remote: Counting objects: 100% (3/3), done.</span>
<span class="c">#    remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    Unpacking objects: 100% (3/3), 228 bytes | 114.00 KiB/s, done.</span>
<span class="nv">$ </span><span class="nb">cd </span>ops-deploy

<span class="c">#</span>
<span class="nv">$ </span>git config user.name <span class="s2">"devops"</span>
<span class="nv">$ </span>git config user.email <span class="s2">"a@a.com"</span>
<span class="nv">$ </span>git config init.defaultBranch main
<span class="nv">$ </span>git config credential.helper store

<span class="c">#</span>
<span class="nv">$ VERSION</span><span class="o">=</span>1.26.1
<span class="nv">$ </span><span class="nb">mkdir </span>nginx-chart
<span class="nv">$ </span><span class="nb">mkdir </span>nginx-chart/templates

<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> nginx-chart/VERSION <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
</span><span class="nv">$VERSION</span><span class="sh">
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> nginx-chart/templates/configmap.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: v1
kind: ConfigMap
metadata:
  name: 
data:
  index.html: |
</span><span class="no">
EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> nginx-chart/templates/deployment.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: apps/v1
kind: Deployment
metadata:
  name: 
spec:
  replicas: 
  selector:
    matchLabels:
      app: 
  template:
    metadata:
      labels:
        app: 
    spec:
      containers:
      - name: nginx
        image: :
        ports:
        - containerPort: 80
        volumeMounts:
        - name: index-html
          mountPath: /usr/share/nginx/html/index.html
          subPath: index.html
      volumes:
      - name: index-html
        configMap:
          name: 
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> nginx-chart/templates/service.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: v1
kind: Service
metadata:
  name: 
spec:
  selector:
    app: 
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
    nodePort: 30000
  type: NodePort
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> nginx-chart/values-dev.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
indexHtml: |
  &lt;!DOCTYPE html&gt;
  &lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Welcome to Nginx!&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;h1&gt;Hello, Kubernetes!&lt;/h1&gt;
    &lt;p&gt;DEV : Nginx version </span><span class="nv">$VERSION</span><span class="sh">&lt;/p&gt;
  &lt;/body&gt;
  &lt;/html&gt;

image:
  repository: nginx
  tag: </span><span class="nv">$VERSION</span><span class="sh">

replicaCount: 1
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> nginx-chart/values-prd.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
indexHtml: |
  &lt;!DOCTYPE html&gt;
  &lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Welcome to Nginx!&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;h1&gt;Hello, Kubernetes!&lt;/h1&gt;
    &lt;p&gt;PRD : Nginx version </span><span class="nv">$VERSION</span><span class="sh">&lt;/p&gt;
  &lt;/body&gt;
  &lt;/html&gt;

image:
  repository: nginx
  tag: </span><span class="nv">$VERSION</span><span class="sh">

replicaCount: 2
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> nginx-chart/Chart.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: v2
name: nginx-chart
description: A Helm chart for deploying Nginx with custom index.html
type: application
version: 1.0.0
appVersion: "</span><span class="nv">$VERSION</span><span class="sh">"
</span><span class="no">EOF

</span><span class="nv">$ </span>tree nginx-chart
<span class="c"># =&gt; nginx-chart</span>
<span class="c">#    ├── Chart.yaml</span>
<span class="c">#    ├── VERSION</span>
<span class="c">#    ├── templates</span>
<span class="c">#    │   ├── configmap.yaml</span>
<span class="c">#    │   ├── deployment.yaml</span>
<span class="c">#    │   └── service.yaml</span>
<span class="c">#    ├── values-dev.yaml</span>
<span class="c">#    └── values-prd.yaml</span>

<span class="c">#</span>
<span class="nv">$ </span>git status <span class="o">&amp;&amp;</span> git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"Add nginx helm chart"</span> <span class="o">&amp;&amp;</span> git push <span class="nt">-u</span> origin main
<span class="c"># =&gt; On branch main</span>
<span class="c">#    Your branch is up to date with 'origin/main'.</span>
<span class="c">#    </span>
<span class="c">#    Untracked files:</span>
<span class="c">#      (use &amp;quot;git add &amp;lt;file&amp;gt;...&amp;quot; to include in what will be committed)</span>
<span class="c">#            nginx-chart/</span>
<span class="c">#    </span>
<span class="c">#    nothing added to commit but untracked files present (use &amp;quot;git add&amp;quot; to track)</span>
<span class="c">#    [main 2bcfda2] Add nginx helm chart</span>
<span class="c">#     7 files changed, 88 insertions(+)</span>
<span class="c">#     create mode 100644 nginx-chart/Chart.yaml</span>
<span class="c">#     create mode 100644 nginx-chart/VERSION</span>
<span class="c">#     create mode 100644 nginx-chart/templates/configmap.yaml</span>
<span class="c">#     create mode 100644 nginx-chart/templates/deployment.yaml</span>
<span class="c">#     create mode 100644 nginx-chart/templates/service.yaml</span>
<span class="c">#     create mode 100644 nginx-chart/values-dev.yaml</span>
<span class="c">#     create mode 100644 nginx-chart/values-prd.yaml</span>
<span class="c">#    Enumerating objects: 12, done.</span>
<span class="c">#    Counting objects: 100% (12/12), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (10/10), done.</span>
<span class="c">#    Writing objects: 100% (11/11), 1.44 KiB | 1.44 MiB/s, done.</span>
<span class="c">#    Total 11 (delta 1), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To http://10.0.4.3:3000/devops/ops-deploy.git</span>
<span class="c">#       f7dc047..2bcfda2  main -&amp;gt; main</span>
<span class="c">#    branch 'main' set up to track 'origin/main'.</span>
</code></pre></div></div>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_29.png" alt="img.png" /></p>

<h5 id="argo-cd에-app-등록">Argo CD에 App 등록</h5>

<ul>
  <li>ArgoCD에서 Application &gt; New App을 클릭하여 애플리케이션을 등록합니다.
    <ul>
      <li>GENERAL
        <ul>
          <li>App Name : dev-nginx</li>
          <li>Project Name : default</li>
          <li>SYNC POLICY : Manual</li>
          <li>SYNC OPTIONS : AUTO-CREATE NAMESPACE(Check)</li>
        </ul>
      </li>
      <li>Source
        <ul>
          <li>Repo URL : <code class="language-plaintext highlighter-rouge">&lt;설정되어 있는 것 선택&gt;</code> (http://10.0.4.3:3000/devops/ops-deploy)</li>
          <li>Revision : HEAD</li>
          <li>PATH : nginx-chart</li>
        </ul>
      </li>
      <li>DESTINATION
        <ul>
          <li>Cluster URL : <code class="language-plaintext highlighter-rouge">&lt;기본값&gt;</code></li>
          <li>NAMESPACE : dev-nginx</li>
        </ul>
      </li>
      <li>HELM
        <ul>
          <li>Values files : values-dev.yaml 
=&gt; 작성 후 상단 CREATE 클릭</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_30.png" alt="img.png" class="image-center" />
<em class="image-caption">Argo CD Application 등록 직후</em></p>

<ul>
  <li>등록 직후에는 git에 등록된 manifest 파일의 내용과 현재 k8s의 상태가 다르기 때문에 <code class="language-plaintext highlighter-rouge">OutOfSync</code> 상태로 표시됩니다.</li>
  <li>dev-nginx를 클릭해서 보면 리소스의 배치와 어떤 리소스가 <code class="language-plaintext highlighter-rouge">OutOfSync</code>인지 표시가 됩니다.</li>
  <li>다음 명령을 입력해서 application의 배포상태를 확인해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>kubectl get applications <span class="nt">-n</span> argocd
<span class="c"># =&gt; NAME        SYNC STATUS   HEALTH STATUS</span>
<span class="c">#    dev-nginx   OutOfSync     Missing</span>

<span class="nv">$ </span>kubectl describe applications <span class="nt">-n</span> argocd dev-nginx
<span class="c"># =&gt; ...</span>
<span class="c">#    Events:</span>
<span class="c">#      Type    Reason           Age    From                           Message</span>
<span class="c">#      ----    ------           ----   ----                           -------</span>
<span class="c">#      Normal  ResourceCreated  7m38s  argocd-server                  admin created application</span>
<span class="c">#      Normal  ResourceUpdated  7m     argocd-application-controller  Updated sync status:  -&amp;gt; Unknown</span>
<span class="c">#      Normal  ResourceUpdated  6m58s  argocd-application-controller  Updated health status:  -&amp;gt; Healthy</span>
<span class="c">#      Normal  ResourceUpdated  3m35s  argocd-application-controller  Updated sync status: Unknown -&amp;gt; OutOfSync</span>
<span class="c">#      Normal  ResourceUpdated  3m35s  argocd-application-controller  Updated health status: Healthy -&amp;gt; Missing</span>

<span class="c"># 반복 접속 시도</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 http://127.0.0.1:30000 <span class="p">;</span> <span class="nb">date</span> <span class="p">;</span> <span class="nb">echo</span> <span class="s2">"------------"</span> <span class="p">;</span> <span class="nb">sleep </span>1 <span class="p">;</span> <span class="k">done</span>
</code></pre></div></div>

<ul>
  <li>ArgoCD에서 DIFF 버튼을 클릭하면 현재 상태와 git에 등록된 상태를 비교할 수 있습니다.
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_31.png" alt="img.png" class="image-center" />
<em class="image-caption">Argo CD Application DIFF 화면</em></li>
  <li>SYNC 버튼을 클릭하여 git의 manifest에 지정된 상태와 k8s의 상태를 동기화 해보겠습니다.
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_32.png" alt="img.png" /></li>
  <li>동기화가 완료되면 다음과 같이 노란색 화살표 아이콘 대신 녹색 체크표시가 나면서 <code class="language-plaintext highlighter-rouge">Synced</code> 상태로 변경됩니다. 
또한 동시에 Kubernetes에 NGINX가 배포가 잘 되었습니다.
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_33.png" alt="img.png" class="image-center" />
<em class="image-caption">Argo CD Application 동기화 완료</em></li>
</ul>

<h5 id="코드-수정-후-반영-확인">코드 수정 후 반영 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ VERSION</span><span class="o">=</span>1.26.2

<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> nginx-chart/VERSION <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
</span><span class="nv">$VERSION</span><span class="sh">
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> nginx-chart/values-dev.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
indexHtml: |
  &lt;!DOCTYPE html&gt;
  &lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Welcome to Nginx!&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;h1&gt;Hello, Kubernetes!&lt;/h1&gt;
    &lt;p&gt;DEV : Nginx version </span><span class="nv">$VERSION</span><span class="sh">&lt;/p&gt;
  &lt;/body&gt;
  &lt;/html&gt;

image:
  repository: nginx
  tag: </span><span class="nv">$VERSION</span><span class="sh">

replicaCount: 2
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> nginx-chart/values-prd.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
indexHtml: |
  &lt;!DOCTYPE html&gt;
  &lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Welcome to Nginx!&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;h1&gt;Hello, Kubernetes!&lt;/h1&gt;
    &lt;p&gt;PRD : Nginx version </span><span class="nv">$VERSION</span><span class="sh">&lt;/p&gt;
  &lt;/body&gt;
  &lt;/html&gt;

image:
  repository: nginx
  tag: </span><span class="nv">$VERSION</span><span class="sh">

replicaCount: 2
</span><span class="no">EOF

</span><span class="c">#</span>
<span class="nv">$ </span>git status <span class="o">&amp;&amp;</span> git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"Update nginx version </span><span class="si">$(</span><span class="nb">cat </span>nginx-chart/VERSION<span class="si">)</span><span class="s2">"</span> <span class="o">&amp;&amp;</span> git push <span class="nt">-u</span> origin main
<span class="c"># =&gt; On branch main</span>
<span class="c">#    Your branch is up to date with 'origin/main'.</span>
<span class="c">#    </span>
<span class="c">#    Changes not staged for commit:</span>
<span class="c">#      (use &amp;quot;git add &amp;lt;file&amp;gt;...&amp;quot; to update what will be committed)</span>
<span class="c">#      (use &amp;quot;git restore &amp;lt;file&amp;gt;...&amp;quot; to discard changes in working directory)</span>
<span class="c">#            modified:   nginx-chart/VERSION</span>
<span class="c">#            modified:   nginx-chart/values-dev.yaml</span>
<span class="c">#            modified:   nginx-chart/values-prd.yaml</span>
<span class="c">#    </span>
<span class="c">#    no changes added to commit (use &amp;quot;git add&amp;quot; and/or &amp;quot;git commit -a&amp;quot;)</span>
<span class="c">#    [main e1b02a2] Update nginx version 1.26.2</span>
<span class="c">#     3 files changed, 6 insertions(+), 6 deletions(-)</span>
<span class="c">#    Enumerating objects: 11, done.</span>
<span class="c">#    Counting objects: 100% (11/11), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (5/5), done.</span>
<span class="c">#    Writing objects: 100% (6/6), 589 bytes | 589.00 KiB/s, done.</span>
<span class="c">#    Total 6 (delta 2), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To http://10.0.4.3:3000/devops/ops-deploy.git</span>
<span class="c">#       2bcfda2..e1b02a2  main -&amp;gt; main</span>
<span class="c">#    branch 'main' set up to track 'origin/main'.</span>
</code></pre></div></div>

<ul>
  <li>Argo CD 웹 확인 =&gt; REFRESH 클릭
    <ul>
      <li>ArgoCD는 주기적으로 동기화 되나 바로 확인하려면 REFRESH 버튼을 클릭해야 합니다. (기본 주기는 3분)
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_34.png" alt="img.png" class="image-center" /></li>
      <li>DIFF로 확인하면 manifest 파일의 변경사항이 나타납니다.
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_35.png" alt="img.png" class="image-center" /></li>
    </ul>
  </li>
  <li>SYNC &gt; SYNCHRONIZE를 클릭하여 동기화 해보겠습니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 배포확인</span>
<span class="nv">$ </span>kubectl get all <span class="nt">-n</span> dev-nginx <span class="nt">-o</span> wide
<span class="c"># =&gt; NAME                             READY   STATUS    RESTARTS   AGE   IP           NODE            NOMINATED NODE   READINESS GATES</span>
<span class="c">#    pod/dev-nginx-5db658bd4f-nfldn   1/1     Running   0          8s    10.244.1.7   myk8s-worker    &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    pod/dev-nginx-5db658bd4f-rxmfz   1/1     Running   0          10s   10.244.2.6   myk8s-worker2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    </span>
<span class="c">#    NAME                TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE   SELECTOR</span>
<span class="c">#    service/dev-nginx   NodePort   10.96.233.99   &amp;lt;none&amp;gt;        80:30000/TCP   16m   app=dev-nginx</span>
<span class="c">#    </span>
<span class="c">#    NAME                        READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES         SELECTOR</span>
<span class="c">#    deployment.apps/dev-nginx   2/2     2            2           16m   nginx        &lt;span style="color: red;"&gt;nginx:1.26.2&lt;/span&gt;   app=dev-nginx</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 변경된 버전이 잘 배포되었습니다.&lt;/span&gt;</span>
<span class="c">#    </span>
<span class="c">#    NAME                                   DESIRED   CURRENT   READY   AGE   CONTAINERS   IMAGES         SELECTOR</span>
<span class="c">#    replicaset.apps/dev-nginx-5db658bd4f   2         2         2       11s   nginx        nginx:1.26.2   app=dev-nginx,pod-template-hash=5db658bd4f</span>
<span class="c">#    replicaset.apps/dev-nginx-77d44dfbf6   0         0         0       16m   nginx        nginx:1.26.1   app=dev-nginx,pod-template-hash=77d44dfbf6</span>
</code></pre></div>    </div>
  </li>
  <li>여기에서 replicaset은 기존 1.26.1이 남아있는데 그것은 ArgoCD가 Rollback을 지원하기 위해 기존 replicaset을 남겨서 관리하기 때문입니다.</li>
  <li>몇개의 history를 남길지는 설정에서 변경할 수 있습니다.</li>
  <li>ArgoCD웹 에서 APP 삭제하고 아래의 명령으로 삭제 진행상황을 확인합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>watch <span class="nt">-d</span> kubectl get all <span class="nt">-n</span> dev-nginx <span class="nt">-o</span> wide
</code></pre></div></div>

<h4 id="argocd-declarative-setup으로-배포-실습">ArgoCD Declarative Setup으로 배포 실습</h4>

<ul>
  <li>이번에는 ArgoCD 애플리케이션 자체를 yaml로 생성해보겠습니다.</li>
  <li>이를 통해 애플리케이션을 생성하고 배포하는 과정을 자동화할 수 있습니다.</li>
  <li>자세한 사항은 다음 공식 문서를 참고하세요. <a href="https://argo-cd.readthedocs.io/en/stable/operator-manual/declarative-setup/">ArgoCD Declarative Setup - Project, applications, ArgoCD Settings - Docs</a></li>
  <li>dev-nginx App 생성 및 Auto SYNC</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Declarative 방식으로 ArgoCD App 생성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: dev-nginx
  namespace: argocd
  finalizers:
  - resources-finalizer.argocd.argoproj.io
spec:
  project: default
  source:
    helm:
      valueFiles:
      - values-dev.yaml
    path: nginx-chart
    repoURL: http://10.0.4.3:3000/devops/ops-deploy
    targetRevision: HEAD
  syncPolicy:
    automated:
      prune: true
    syncOptions:
    - CreateNamespace=true
  destination:
    namespace: dev-nginx
    server: https://kubernetes.default.svc
</span><span class="no">EOF
</span><span class="c"># =&gt; application.argoproj.io/dev-nginx created</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get applications <span class="nt">-n</span> argocd dev-nginx
<span class="c"># =&gt; NAME        SYNC STATUS   HEALTH STATUS</span>
<span class="c">#    dev-nginx   Synced        Healthy</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 automated sync 정책이어서 배포 직후 동기화 된 상태가 됩니다.&lt;/span&gt;</span>
<span class="nv">$ </span>kubectl get applications <span class="nt">-n</span> argocd dev-nginx <span class="nt">-o</span> yaml | kubectl neat
<span class="nv">$ </span>kubectl describe applications <span class="nt">-n</span> argocd dev-nginx
<span class="c"># =&gt; ...</span>
<span class="c">#    Events:</span>
<span class="c">#      Type    Reason              Age   From                           Message</span>
<span class="c">#      ----    ------              ----  ----                           -------</span>
<span class="c">#      Normal  ResourceUpdated     80s   argocd-application-controller  Updated sync status:  -&amp;gt; Unknown</span>
<span class="c">#      Normal  ResourceUpdated     80s   argocd-application-controller  Updated health status:  -&amp;gt; Healthy</span>
<span class="c">#      Normal  OperationStarted    57s   argocd-application-controller  Initiated automated sync to 'e1b02a29e47a839ebcc93e46ee9da1f2d5320148'</span>
<span class="c">#      Normal  ResourceUpdated     57s   argocd-application-controller  Updated sync status: Unknown -&amp;gt; OutOfSync</span>
<span class="c">#      Normal  ResourceUpdated     57s   argocd-application-controller  Updated health status: Healthy -&amp;gt; Missing</span>
<span class="c">#      Normal  ResourceUpdated     57s   argocd-application-controller  Updated sync status: OutOfSync -&amp;gt; Synced</span>
<span class="c">#      Normal  ResourceUpdated     57s   argocd-application-controller  Updated health status: Missing -&amp;gt; Progressing</span>
<span class="c">#      Normal  OperationCompleted  57s   argocd-application-controller  Sync operation to e1b02a29e47a839ebcc93e46ee9da1f2d5320148 succeeded</span>
<span class="c">#      Normal  ResourceUpdated     55s   argocd-application-controller  Updated health status: Progressing -&amp;gt; Healthy</span>
<span class="nv">$ </span>kubectl get pod,svc,ep,cm <span class="nt">-n</span> dev-nginx
<span class="c"># =&gt; NAME                             READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/dev-nginx-5db658bd4f-blcr6   1/1     Running   0          74s</span>
<span class="c">#    pod/dev-nginx-5db658bd4f-k984k   1/1     Running   0          74s</span>
<span class="c">#    </span>
<span class="c">#    NAME                TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE</span>
<span class="c">#    service/dev-nginx   NodePort   10.96.176.134   &amp;lt;none&amp;gt;        80:30000/TCP   74s</span>
<span class="c">#    </span>
<span class="c">#    NAME                  ENDPOINTS                     AGE</span>
<span class="c">#    endpoints/dev-nginx   10.244.1.8:80,10.244.2.8:80   74s</span>
<span class="c">#    </span>
<span class="c">#    NAME                         DATA   AGE</span>
<span class="c">#    configmap/dev-nginx          1      74s</span>
<span class="c">#    configmap/kube-root-ca.crt   1      24m</span>

<span class="c">#</span>
<span class="nv">$ </span>curl http://127.0.0.1:30000
<span class="c"># =&gt; &amp;lt;!DOCTYPE html&amp;gt;</span>
<span class="c">#    &amp;lt;html&amp;gt;</span>
<span class="c">#    &amp;lt;head&amp;gt;</span>
<span class="c">#      &amp;lt;title&amp;gt;Welcome to Nginx!&amp;lt;/title&amp;gt;</span>
<span class="c">#    &amp;lt;/head&amp;gt;</span>
<span class="c">#    &amp;lt;body&amp;gt;</span>
<span class="c">#      &amp;lt;h1&amp;gt;Hello, Kubernetes!&amp;lt;/h1&amp;gt;</span>
<span class="c">#      &amp;lt;p&amp;gt;DEV : Nginx version 1.26.2&amp;lt;/p&amp;gt;</span>
<span class="c">#    &amp;lt;/body&amp;gt;</span>
<span class="c">#    &amp;lt;/html&amp;gt;</span>
<span class="nv">$ </span>open http://127.0.0.1:30000

<span class="c"># Argo CD App 삭제</span>
<span class="nv">$ </span>kubectl delete applications <span class="nt">-n</span> argocd dev-nginx
<span class="c"># =&gt; application.argoproj.io &amp;quot;dev-nginx&amp;quot; deleted</span>
</code></pre></div></div>

<ul>
  <li>prd-nginx App 생성 및 Auto SYNC</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: prd-nginx
  namespace: argocd
  finalizers:
  - resources-finalizer.argocd.argoproj.io
spec:
  destination:
    namespace: prd-nginx
    server: https://kubernetes.default.svc
  project: default
  source:
    helm:
      valueFiles:
      - values-prd.yaml
    path: nginx-chart
    repoURL: http://10.0.4.3:3000/devops/ops-deploy
    targetRevision: HEAD
  syncPolicy:
    automated:
      prune: true
    syncOptions:
    - CreateNamespace=true
</span><span class="no">EOF
</span><span class="c"># =&gt; application.argoproj.io/prd-nginx created</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get applications <span class="nt">-n</span> argocd prd-nginx
<span class="c"># =&gt; NAME        SYNC STATUS   HEALTH STATUS</span>
<span class="c">#    prd-nginx   Synced        Healthy</span>
<span class="nv">$ </span>kubectl describe applications <span class="nt">-n</span> argocd prd-nginx
<span class="c"># =&gt; ...</span>
<span class="c">#    Events:</span>
<span class="c">#      Type    Reason              Age   From                           Message</span>
<span class="c">#      ----    ------              ----  ----                           -------</span>
<span class="c">#      Normal  ResourceUpdated     28s   argocd-application-controller  Updated sync status:  -&amp;gt; Unknown</span>
<span class="c">#      Normal  ResourceUpdated     28s   argocd-application-controller  Updated health status:  -&amp;gt; Healthy</span>
<span class="c">#      Normal  OperationStarted    18s   argocd-application-controller  Initiated automated sync to 'e1b02a29e47a839ebcc93e46ee9da1f2d5320148'</span>
<span class="c">#      Normal  ResourceUpdated     18s   argocd-application-controller  Updated sync status: Unknown -&amp;gt; OutOfSync</span>
<span class="c">#      Normal  ResourceUpdated     18s   argocd-application-controller  Updated health status: Healthy -&amp;gt; Missing</span>
<span class="c">#      Normal  ResourceUpdated     15s   argocd-application-controller  Updated sync status: OutOfSync -&amp;gt; Synced</span>
<span class="c">#      Normal  ResourceUpdated     15s   argocd-application-controller  Updated health status: Missing -&amp;gt; Progressing</span>
<span class="c">#      Normal  OperationCompleted  15s   argocd-application-controller  Sync operation to e1b02a29e47a839ebcc93e46ee9da1f2d5320148 succeeded</span>
<span class="c">#      Normal  ResourceUpdated     13s   argocd-application-controller  Updated health status: Progressing -&amp;gt; Healthy</span>
<span class="nv">$ </span>kubectl get pod,svc,ep,cm <span class="nt">-n</span> prd-nginx
<span class="c"># =&gt; NAME                             READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/prd-nginx-645b5ffbbf-9jp6g   1/1     Running   0          45s</span>
<span class="c">#    pod/prd-nginx-645b5ffbbf-ch6q2   1/1     Running   0          45s</span>
<span class="c">#    </span>
<span class="c">#    NAME                TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE</span>
<span class="c">#    service/prd-nginx   NodePort   10.96.206.18   &amp;lt;none&amp;gt;        80:30000/TCP   45s</span>
<span class="c">#    </span>
<span class="c">#    NAME                  ENDPOINTS                     AGE</span>
<span class="c">#    endpoints/prd-nginx   10.244.1.9:80,10.244.2.9:80   45s</span>
<span class="c">#    </span>
<span class="c">#    NAME                         DATA   AGE</span>
<span class="c">#    configmap/kube-root-ca.crt   1      47s</span>
<span class="c">#    configmap/prd-nginx          1      45s</span>

<span class="c">#</span>
<span class="nv">$ </span>curl http://127.0.0.1:30000
<span class="c"># =&gt; &amp;lt;!DOCTYPE html&amp;gt;</span>
<span class="c">#    &amp;lt;html&amp;gt;</span>
<span class="c">#    &amp;lt;head&amp;gt;</span>
<span class="c">#      &amp;lt;title&amp;gt;Welcome to Nginx!&amp;lt;/title&amp;gt;</span>
<span class="c">#    &amp;lt;/head&amp;gt;</span>
<span class="c">#    &amp;lt;body&amp;gt;</span>
<span class="c">#      &amp;lt;h1&amp;gt;Hello, Kubernetes!&amp;lt;/h1&amp;gt;</span>
<span class="c">#      &amp;lt;p&amp;gt;PRD : Nginx version 1.26.2&amp;lt;/p&amp;gt;</span>
<span class="c">#    &amp;lt;/body&amp;gt;</span>
<span class="c">#    &amp;lt;/html&amp;gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 PRD nginx가 잘 배포되었습니다.&lt;/span&gt;</span>
<span class="nv">$ </span>open http://127.0.0.1:30000

<span class="c"># Argo CD App 삭제</span>
<span class="nv">$ </span>kubectl delete applications <span class="nt">-n</span> argocd prd-nginx
<span class="c"># =&gt; application.argoproj.io &amp;quot;prd-nginx&amp;quot; deleted</span>
</code></pre></div></div>

<h4 id="argocd를-이용한-full-cicd-구성">ArgoCD를 이용한 Full CI/CD 구성</h4>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_36.png" alt="img.png" /></p>

<ul>
  <li>최종적으로 위와 같이 CI/CD 파이프라인을 구성해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">cd </span>ops-deploy
<span class="nv">$ </span><span class="nb">mkdir </span>dev-app

<span class="c"># 도커 계정 정보</span>
<span class="c">#$ DHUSER=&lt;도커 허브 계정&gt;</span>
<span class="nv">$ DHUSER</span><span class="o">=</span>sweetlittlebird

<span class="c"># 버전 정보 </span>
<span class="nv">$ VERSION</span><span class="o">=</span>0.0.1

<span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> dev-app/VERSION <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
</span><span class="nv">$VERSION</span><span class="sh">
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> dev-app/timeserver.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: apps/v1
kind: Deployment
metadata:
  name: timeserver
spec:
  replicas: 2
  selector:
    matchLabels:
      pod: timeserver-pod
  template:
    metadata:
      labels:
        pod: timeserver-pod
    spec:
      containers:
      - name: timeserver-container
        image: docker.io/</span><span class="nv">$DHUSER</span><span class="sh">/dev-app:</span><span class="nv">$VERSION</span><span class="sh">
      imagePullSecrets:
      - name: dockerhub-secret
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> dev-app/service.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: v1
kind: Service
metadata:
  name: timeserver
spec:
  selector:
    pod: timeserver-pod
  ports:
  - port: 80
    targetPort: 80
    protocol: TCP
    nodePort: 30000
  type: NodePort
</span><span class="no">EOF

</span><span class="c">#</span>
<span class="nv">$ </span>git status <span class="o">&amp;&amp;</span> git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"Add dev-app deployment yaml"</span> <span class="o">&amp;&amp;</span> git push <span class="nt">-u</span> origin main
</code></pre></div></div>

<ul>
  <li>ArgoCD에 app 생성</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: timeserver
  namespace: argocd
  finalizers:
  - resources-finalizer.argocd.argoproj.io
spec:
  project: default
  source:
    path: dev-app
    repoURL: http://10.0.4.3:3000/devops/ops-deploy
    targetRevision: HEAD
  syncPolicy:
    automated:
      prune: true
    syncOptions:
    - CreateNamespace=true
  destination:
    namespace: default
    server: https://kubernetes.default.svc
</span><span class="no">EOF
</span><span class="c"># =&gt; application.argoproj.io/timeserver created</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get applications <span class="nt">-n</span> argocd timeserver
<span class="c"># =&gt; NAME         SYNC STATUS   HEALTH STATUS</span>
<span class="c">#    timeserver   Synced        Healthy</span>
<span class="nv">$ </span>kubectl get applications <span class="nt">-n</span> argocd timeserver <span class="nt">-o</span> yaml | kubectl neat
<span class="nv">$ </span>kubectl describe applications <span class="nt">-n</span> argocd timeserver
<span class="c"># =&gt; ...</span>
<span class="c">#    Events:</span>
<span class="c">#      Type    Reason              Age   From                           Message</span>
<span class="c">#      ----    ------              ----  ----                           -------</span>
<span class="c">#      Normal  OperationStarted    23s   argocd-application-controller  Initiated automated sync to 'd64cb772abc1646bd74abbd47b688eeb6d59d65a'</span>
<span class="c">#      Normal  ResourceUpdated     23s   argocd-application-controller  Updated sync status:  -&amp;gt; OutOfSync</span>
<span class="c">#      Normal  ResourceUpdated     23s   argocd-application-controller  Updated health status:  -&amp;gt; Missing</span>
<span class="c">#      Normal  ResourceUpdated     23s   argocd-application-controller  Updated sync status: OutOfSync -&amp;gt; Synced</span>
<span class="c">#      Normal  OperationCompleted  23s   argocd-application-controller  Sync operation to d64cb772abc1646bd74abbd47b688eeb6d59d65a succeeded</span>
<span class="c">#      Normal  ResourceUpdated     23s   argocd-application-controller  Updated health status: Missing -&amp;gt; Progressing</span>
<span class="c">#      Normal  ResourceUpdated     21s   argocd-application-controller  Updated health status: Progressing -&amp;gt; Healthy</span>
<span class="nv">$ </span>kubectl get deploy,rs,pod
<span class="c"># =&gt; NAME                         READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/timeserver   2/2     2            2           42s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                    DESIRED   CURRENT   READY   AGE</span>
<span class="c">#    replicaset.apps/timeserver-549cc9bc89   2         2         2       42s</span>
<span class="c">#    </span>
<span class="c">#    NAME                              READY   STATUS    RESTARTS      AGE</span>
<span class="c">#    pod/curl-pod                      1/1     Running   2 (51m ago)   21h</span>
<span class="c">#    pod/timeserver-549cc9bc89-5bsfm   1/1     Running   0             42s</span>
<span class="c">#    pod/timeserver-549cc9bc89-rwcsz   1/1     Running   0             42s</span>
<span class="nv">$ </span>kubectl get svc,ep timeserver
<span class="c"># =&gt; NAME                 TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE</span>
<span class="c">#    service/timeserver   NodePort   10.96.45.219   &amp;lt;none&amp;gt;        80:30000/TCP   50s</span>
<span class="c">#    </span>
<span class="c">#    NAME                   ENDPOINTS                       AGE</span>
<span class="c">#    endpoints/timeserver   10.244.1.10:80,10.244.2.10:80   50s</span>

<span class="c">#</span>
<span class="nv">$ </span>curl http://127.0.0.1:30000
<span class="c"># =&gt; The time is 12:16:57 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-5bsfm</span>
<span class="nv">$ </span>open http://127.0.0.1:30000
</code></pre></div></div>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_37.png" alt="img.png" /></p>

<h5 id="dev-app-repo-코드-작업">dev-app Repo 코드 작업</h5>

<ul>
  <li>dev-app Repo에 VERSION 업데이트 시 =&gt; ops-deploy Repo 에 dev-app 에 파일에 버전 정보 업데이트 작업 추가
    <ol>
      <li>기존 버전 정보는 VERSION 파일 내에 정보를 가져와서 변수 지정 : <code class="language-plaintext highlighter-rouge">OLDVER=$(cat dev-app/VERSION)</code></li>
      <li>신규 버전 정보는 environment 도커 태그 정보를 가져와서 변수 지정 : <code class="language-plaintext highlighter-rouge">NEWVER=$(echo ${DOCKER_TAG})</code></li>
      <li>이후 sed 로 ops-deploy Repo 에 dev-app/VERSION, timeserver.yaml 2개 파일에 ‘기존 버전’ → ‘신규 버전’으로 값 변경</li>
      <li>이후 ops-deploy Repo 에 git push ⇒ Argo CD app 가 최대 3분 사이에 변경 확인 후 AutoSync 로 신규 버전 업데이트 진행</li>
    </ol>
  </li>
  <li>아래는 dev-app 에 위치한 Jenkinsfile로 젠킨스에 SCM-Pipeline (SCM:git) 으로 사용되고 있는 파일을 수정해서 실습에 사용하겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Jenkinsfile</span>
pipeline <span class="o">{</span>
    agent any
    environment <span class="o">{</span>
        DOCKER_IMAGE <span class="o">=</span> <span class="s1">'sweetlittlebird/dev-app'</span> // Docker 이미지 이름
        GOGSCRD <span class="o">=</span> credentials<span class="o">(</span><span class="s1">'gogs-crd'</span><span class="o">)</span>
    <span class="o">}</span>
    stages <span class="o">{</span>
        stage<span class="o">(</span><span class="s1">'dev-app Checkout'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                 git branch: <span class="s1">'main'</span>,
                 url: <span class="s1">'http://10.0.4.3:3000/devops/dev-app.git'</span>,  // Git에서 코드 체크아웃
                 credentialsId: <span class="s1">'gogs-crd'</span>  // Credentials ID
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'Read VERSION'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                script <span class="o">{</span>
                    // VERSION 파일 읽기
                    def version <span class="o">=</span> readFile<span class="o">(</span><span class="s1">'VERSION'</span><span class="o">)</span>.trim<span class="o">()</span>
                    <span class="nb">echo</span> <span class="s2">"Version found: </span><span class="k">${</span><span class="nv">version</span><span class="k">}</span><span class="s2">"</span>
                    // 환경 변수 설정
                    env.DOCKER_TAG <span class="o">=</span> version
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'Docker Build and Push'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                script <span class="o">{</span>
                    docker.withRegistry<span class="o">(</span><span class="s1">'https://index.docker.io/v1/'</span>, <span class="s1">'dockerhub-crd'</span><span class="o">)</span> <span class="o">{</span>
                        // DOCKER_TAG 사용
                        def appImage <span class="o">=</span> docker.build<span class="o">(</span><span class="s2">"</span><span class="k">${</span><span class="nv">DOCKER_IMAGE</span><span class="k">}</span><span class="s2">:</span><span class="k">${</span><span class="nv">DOCKER_TAG</span><span class="k">}</span><span class="s2">"</span><span class="o">)</span>
                        appImage.push<span class="o">()</span>
                        appImage.push<span class="o">(</span><span class="s2">"latest"</span><span class="o">)</span>
                    <span class="o">}</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'ops-deploy Checkout'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                 git branch: <span class="s1">'main'</span>,
                 url: <span class="s1">'http://10.0.4.3:3000/devops/ops-deploy.git'</span>,  // Git에서 코드 체크아웃
                 credentialsId: <span class="s1">'gogs-crd'</span>  // Credentials ID
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'ops-deploy version update push'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                sh <span class="s1">'''
                OLDVER=$(cat dev-app/VERSION)
                NEWVER=$(echo ${DOCKER_TAG})
                sed -i -e "s/$OLDVER/$NEWVER/" dev-app/timeserver.yaml
                sed -i -e "s/$OLDVER/$NEWVER/" dev-app/VERSION
                git add ./dev-app
                git config user.name "devops"
                git config user.email "a@a.com"
                git commit -m "version update ${DOCKER_TAG}"
                git push http://${GOGSCRD_USR}:${GOGSCRD_PSW}@10.0.4.3:3000/devops/ops-deploy.git
                '''</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
    post <span class="o">{</span>
        success <span class="o">{</span>
            <span class="nb">echo</span> <span class="s2">"Docker image </span><span class="k">${</span><span class="nv">DOCKER_IMAGE</span><span class="k">}</span><span class="s2">:</span><span class="k">${</span><span class="nv">DOCKER_TAG</span><span class="k">}</span><span class="s2"> has been built and pushed successfully!"</span>
        <span class="o">}</span>
        failure <span class="o">{</span>
            <span class="nb">echo</span> <span class="s2">"Pipeline failed. Please check the logs."</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<ul>
  <li>아래는 dev-app (Repo) 에서 VERSION과 server.py 수정 후 git push를 진행합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># VERSION 파일 수정 : 0.0.4</span>
<span class="c"># server.py 파일 수정 : 0.0.4</span>

<span class="c"># git push : VERSION, server.py, Jenkinsfile</span>
git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"VERSION </span><span class="si">$(</span><span class="nb">cat </span>VERSION<span class="si">)</span><span class="s2"> Changed"</span> <span class="o">&amp;&amp;</span> git push <span class="nt">-u</span> origin main
</code></pre></div></div>
<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_38.png" alt="img.png" /></p>

<ul>
  <li>ArgoCD 웹에서 동작을 확인해보겠습니다.</li>
  <li>Jenkins Pipeline이 실행되면서 dev-app Repo의 버전 정보가 변경되고, ops-deploy Repo의 dev-app/VERSION 파일과 timeserver.yaml 파일이 
변경되어 ArgoCD가 변경사항을 감지하고 자동으로 배포를 진행합니다.</li>
  <li>REFRESH 버튼을 클릭하거나 ArgoCD WebHook 설정시 즉시 반영이 가능합니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_39.png" alt="img.png" /></p>

<ul>
  <li>dev-app Repo에서 몇번 더 버전을 업데이트 해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># VERSION 파일 수정 : 0.0.5</span>
<span class="c"># server.py 파일 수정 : 0.0.5</span>

<span class="c"># git push : VERSION, server.py, Jenkinsfile</span>
<span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"VERSION </span><span class="si">$(</span><span class="nb">cat </span>VERSION<span class="si">)</span><span class="s2"> Changed"</span> <span class="o">&amp;&amp;</span> git push <span class="nt">-u</span> origin main
<span class="c"># =&gt; [main 881d051] VERSION 0.0.5 Changed</span>
<span class="c">#     2 files changed, 2 insertions(+), 2 deletions(-)</span>
<span class="c">#    Enumerating objects: 7, done.</span>
<span class="c">#    Counting objects: 100% (7/7), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (3/3), done.</span>
<span class="c">#    Writing objects: 100% (4/4), 329 bytes | 329.00 KiB/s, done.</span>
<span class="c">#    Total 4 (delta 2), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To http://10.0.4.3:3000/devops/dev-app.git</span>
<span class="c">#       1d4cec2..881d051  main -&amp;gt; main</span>
<span class="c">#    branch 'main' set up to track 'origin/main'.</span>

<span class="c"># 배포 결과 확인</span>
<span class="nv">$ </span>curl http://127.0.0.1:30000
<span class="c"># =&gt; The time is 12:34:14 PM, VERSION 0.0.5</span>
<span class="c">#    Server hostname: timeserver-7546694df7-wds9r</span>
</code></pre></div></div>

<ul>
  <li>CI/CD가 잘 동작하여 최신버전이 배포됨을 확인 할 수 있습니다.</li>
</ul>

<hr />

<h3 id="argo-rollout--k8skind">Argo Rollout + K8S(Kind)</h3>

<ul>
  <li>Argo는 ArgoCD 뿐만 아니라 다양한 프로젝트를 제공하고 있으며, 그중의 하나가 Argo Rollout입니다.</li>
  <li>Argo Rollout은 Kubernetes의 Deployment, StatefulSet, DaemonSet, Job, CronJob 등의 리소스를 대체하여 롤아웃을 관리하는 컨트롤러입니다.</li>
  <li>다음과 같은 기능을 제공합니다. <a href="https://argoproj.github.io/argo-rollouts/concepts/">문서</a>
    <ul>
      <li>Blue-Green 업데이트 전략
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_40.png" alt="img.png" class="image-center" /></li>
      <li>Canary 업데이트 전략
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_41.png" alt="img_1.png" class="image-center" /></li>
      <li>세밀하고 가중치가 부여된 트래픽 전환</li>
      <li>자동화된 롤백 및 프로모션</li>
      <li>수동 판단</li>
      <li>사용자 정의 가능한 메트릭 쿼리 및 비즈니스 KPI 분석</li>
      <li>인그레스 컨트롤러 통합: NGINX, ALB, Apache APISIX</li>
      <li>서비스 메쉬 통합: Istio, Linkerd, SMI</li>
      <li>여러 제공자의 동시 사용: SMI + NGINX, Istio + ALB 등</li>
      <li>메트릭 제공자 통합: Prometheus, Wavefront, Kayenta, Web, Kubernetes Jobs, Datadog, New Relic, Graphite, InfluxDB</li>
    </ul>
  </li>
</ul>

<h5 id="argo-rollout-설치-및-실습">Argo Rollout 설치 및 실습</h5>

<ul>
  <li>Argo Rollout을 설치해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 네임스페이스 생성 및 파라미터 파일 작성</span>
<span class="nv">$ </span>kubectl create ns argo-rollouts
<span class="c"># =&gt; namespace/argo-rollouts created</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh"> &gt; argorollouts-values.yaml
dashboard:
  enabled: true
  service:
    type: NodePort
    nodePort: 30003
</span><span class="no">EOT

</span><span class="c"># 설치</span>
<span class="nv">$ </span>helm <span class="nb">install </span>argo-rollouts argo/argo-rollouts <span class="nt">--version</span> 2.35.1 <span class="nt">-f</span> argorollouts-values.yaml <span class="nt">--namespace</span> argo-rollouts
<span class="c"># =&gt; NAME: argo-rollouts</span>
<span class="c">#    LAST DEPLOYED: Sun Oct 01 23:05:23 2024</span>
<span class="c">#    NAMESPACE: argo-rollouts</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 1</span>
<span class="c">#    TEST SUITE: None</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get all <span class="nt">-n</span> argo-rollouts
<span class="c"># =&gt; NAME                                           READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/argo-rollouts-86469b5878-j6p5k             1/1     Running   0          42s</span>
<span class="c">#    pod/argo-rollouts-86469b5878-vlr6z             1/1     Running   0          43s</span>
<span class="c">#    pod/argo-rollouts-dashboard-7c88d965fc-l6lml   1/1     Running   0          43s</span>
<span class="c">#    </span>
<span class="c">#    NAME                              TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span>
<span class="c">#    service/argo-rollouts-dashboard   NodePort   10.96.195.148   &amp;lt;none&amp;gt;        3100:30003/TCP   43s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                      READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/argo-rollouts             2/2     2            2           43s</span>
<span class="c">#    deployment.apps/argo-rollouts-dashboard   1/1     1            1           43s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                                 DESIRED   CURRENT   READY   AGE</span>
<span class="c">#    replicaset.apps/argo-rollouts-86469b5878             2         2         2       43s</span>
<span class="c">#    replicaset.apps/argo-rollouts-dashboard-7c88d965fc   1         1         1       43s</span>
<span class="nv">$ </span>kubectl get crds
<span class="c"># =&gt; NAME                                   CREATED AT</span>
<span class="c">#    analysisruns.argoproj.io               2024-10-01T14:05:24Z</span>
<span class="c">#    analysistemplates.argoproj.io          2024-10-01T14:05:24Z</span>
<span class="c">#    applications.argoproj.io               2024-10-01T07:54:01Z</span>
<span class="c">#    applicationsets.argoproj.io            2024-10-01T07:54:01Z</span>
<span class="c">#    appprojects.argoproj.io                2024-10-01T07:54:01Z</span>
<span class="c">#    clusteranalysistemplates.argoproj.io   2024-10-01T14:05:24Z</span>
<span class="c">#    experiments.argoproj.io                2024-10-01T14:05:24Z</span>
<span class="c">#    rollouts.argoproj.io                   2024-10-01T14:05:24Z</span>

<span class="c"># Argo rollouts 대시보드 접속 주소 확인</span>
<span class="nv">$ </span>open <span class="s2">"http://127.0.0.1:30003"</span>
</code></pre></div></div>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_42.png" alt="img.png" /></p>

<ul>
  <li>Argo Rollout을 이용해서 배포를 진행해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Run the following command to deploy the initial Rollout and Service:</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/basic/rollout.yaml
<span class="c"># =&gt; rollout.argoproj.io/rollouts-demo created</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/basic/service.yaml
<span class="c"># =&gt; service/rollouts-demo created</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get rollout
<span class="c"># =&gt; NAME            DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    rollouts-demo   5         5         5            5           16s</span>
<span class="nv">$ </span>kubectl describe rollout
<span class="c"># =&gt; ...</span>
<span class="c">#    Events:</span>
<span class="c">#      Type    Reason                  Age   From                 Message</span>
<span class="c">#      ----    ------                  ----  ----                 -------</span>
<span class="c">#      Normal  RolloutAddedToInformer  25s   rollouts-controller  Rollout resource added to informer: default/rollouts-demo</span>
<span class="c">#      Normal  RolloutNotCompleted     25s   rollouts-controller  Rollout not completed, started update to revision 1 (687d76d795)</span>
<span class="c">#      Normal  RolloutUpdated          25s   rollouts-controller  Rollout updated to revision 1</span>
<span class="c">#      Normal  NewReplicaSetCreated    25s   rollouts-controller  Created ReplicaSet rollouts-demo-687d76d795 (revision 1)</span>
<span class="c">#      Normal  ScalingReplicaSet       25s   rollouts-controller  Scaled up ReplicaSet rollouts-demo-687d76d795 (revision 1) from 0 to 5</span>
<span class="c">#      Normal  RolloutCompleted        25s   rollouts-controller  Rollout completed update to revision 1 (687d76d795): Initial deploy</span>

<span class="nv">$ </span>kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>rollouts-demo
<span class="c"># =&gt; NAME                             READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    rollouts-demo-687d76d795-7pbl9   1/1     Running   0          46s</span>
<span class="c">#    rollouts-demo-687d76d795-bnl2c   1/1     Running   0          46s</span>
<span class="c">#    rollouts-demo-687d76d795-ggzsq   1/1     Running   0          46s</span>
<span class="c">#    rollouts-demo-687d76d795-vtnlj   1/1     Running   0          46s</span>
<span class="c">#    rollouts-demo-687d76d795-xmk2x   1/1     Running   0          46s</span>
<span class="nv">$ </span>kubectl get svc,ep rollouts-demo
<span class="c"># =&gt; NAME                    TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE</span>
<span class="c">#    service/rollouts-demo   ClusterIP   10.96.237.173   &amp;lt;none&amp;gt;        80/TCP    47s</span>
<span class="c">#    </span>
<span class="c">#    NAME                      ENDPOINTS                                                        AGE</span>
<span class="c">#    endpoints/rollouts-demo   10.244.1.14:8080,10.244.1.15:8080,10.244.1.16:8080 + 2 more...   47s</span>
<span class="nv">$ </span>kubectl get rollouts rollouts-demo <span class="nt">-o</span> yaml | kubectl neat
<span class="c"># =&gt; ...</span>
<span class="c">#    spec:</span>
<span class="c">#      replicas: 5</span>
<span class="c">#      revisionHistoryLimit: 2</span>
<span class="c">#      selector:</span>
<span class="c">#        matchLabels:</span>
<span class="c">#          app: rollouts-demo</span>
<span class="c">#      strategy:</span>
<span class="c">#        canary:</span>
<span class="c">#          steps:</span>
<span class="c">#          - setWeight: 20</span>
<span class="c">#          - setWeight: 40</span>
<span class="c">#          - pause:</span>
<span class="c">#              duration: 10</span>
<span class="c">#          - setWeight: 60</span>
<span class="c">#          - pause:</span>
<span class="c">#              duration: 10</span>
<span class="c">#          - setWeight: 80</span>
<span class="c">#          - pause:</span>
<span class="c">#              duration: 10</span>
<span class="c">#      ...</span>
</code></pre></div></div>

<ul>
  <li>
    <p>우측상단의 NAMESPACE를 default로 변경하고 rollout-demo를 클릭하면 다음의 rollout 화면이 나타납니다.
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_43.png" alt="img.png" /></p>
  </li>
  <li>
    <p>rollouts-demo:blue를 rollouts-demo:yellow로 변경해서 배포해보겠습니다.</p>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl edit rollouts rollouts-demo
...
     - image: argoproj/rollouts-demo:yellow
...
<span class="c"># =&gt; rollout.argoproj.io/rollouts-demo edited</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 위와 같이 rollouts-demo/blue를 rollouts-demo/yellow로 변경합니다.&lt;/span&gt;</span>

<span class="c"># 파드 label 정보 확인</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>rollouts-demo <span class="nt">-owide</span> <span class="nt">--show-labels</span>
</code></pre></div></div>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_44.png" alt="img.png" /></p>

<ul>
  <li>위와같이 yellow가 20% 만큼 canary 배포되고 정자 상태에 있습니다.</li>
  <li>Promote 버튼을 클릭하여 보겠습니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_45.png" alt="img.png" /></p>

<ul>
  <li>정해진 rollout rule에 따라 10초씩 대기 후 20%씩 canary 배포 비율을 높여서 최종적으로 전체가 yellow로 배포됩니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_46.png" alt="img.png" /></p>

<h2 id="마치며">마치며</h2>

<p>이번주에는 생각보다 실습량이 많아서 시간이 많이 걸렸습니다. 
하지만, K8S에 CI/CD 배포하는것과 ArgoCD와 Argo Rollout을 이용한 CI/CD 파이프라인 구성을 경험해볼 수 있어서 좋았습니다.
특히 ArgoCD와 Argo Rollout은 웹 UI는 조금 날것 느낌이 났지만,
기능이나 컨셉 자체는 좋은것 같고, 
선언적인 방식이나 CLI를 통해서 자동화할 수 있으니 다양하게 활용할 수 있을것 같습니다.</p>

<p>스터디 컨셉이 CI/CD 맛보기여서 가벼운 마음으로 시작했는데
실제 스터디는 가볍지 않았던것 같습니다.<br />
이 맛에 스터디합니다. 
:sweat_smile: 맛보기가 이 정도이니 본편은 얼마나 깊고 넓을지 기대가 됩니다.</p>

<p>연말에 어수선한 가운데 다들 스터디 참여하신 분들 모두 고생 많으셨고, 
진행해주신 가시다님께 감사드립니다.</p>

<p>긴 글 읽어주셔서 감사합니다. 
한 해 마무리 잘 하시고, 건강한 모습으로 내년에 또 뵙기를 기원합니다. :bow::bowing_woman:</p>]]></content><author><name></name></author><category term="kans" /><category term="cicd," /><category term="jenkins," /><category term="git," /><category term="linux" /><summary type="html"><![CDATA[이번 주에는 ArgoCD와 Jenkins를 사용하여 Kubernetes로의 배포를 하는 CI/CD를 구성해보겠습니다.]]></summary></entry><entry><title type="html">[CI/CD] GitHub Actions CI/CD</title><link href="https://sweetlittlebird.github.io/posts/2024-12-14-CICD-Lite-Week2/" rel="alternate" type="text/html" title="[CI/CD] GitHub Actions CI/CD" /><published>2024-12-14T23:01:18+09:00</published><updated>2024-12-14T23:01:18+09:00</updated><id>https://sweetlittlebird.github.io/posts/CICD%20Lite%20-%20Week2</id><content type="html" xml:base="https://sweetlittlebird.github.io/posts/2024-12-14-CICD-Lite-Week2/"><![CDATA[<h2 id="들어가며">들어가며</h2>

<p>이번 주에는 GitHub Actions를 이용한 CI/CD에 대해 알아보겠습니다.</p>

<h2 id="github-actions-cicd">GitHub Actions CI/CD</h2>

<h3 id="github-actions란">GitHub Actions란?</h3>

<ul>
  <li><a href="https://docs.github.com/ko/actions">공식문서</a> -
<a href="https://docs.github.com/ko/actions/about-github-actions/understanding-github-actions">개요</a> -
<a href="https://docs.github.com/ko/billing/managing-billing-for-your-products/managing-billing-for-github-actions">요금</a> -
<a href="https://blog.outsider.ne.kr/1744">GitHub Actions의 다양한 기능 활용하기</a></li>
  <li>GitHub Actions는 GitHub에서 호스팅되는 <strong>지속적 통합(CI) 및 지속적 배포(CD)</strong> 서비스입니다.</li>
  <li>푸시나 풀 리퀘스트와 같은 이벤트에 반응하여 <strong>사용자 지정된 워크플로</strong>를 실행할 수 있습니다. 이를 통해 CI/CD를 GitHub Actions로 구현할 수 있습니다.</li>
  <li>GitHub Actions는 <strong>GitHub Marketplace</strong>에서 기존에 작성된 워크플로를 가져와 사용할 수 있습니다. Slack 알림, AWS 배포 등 다양한 워크플로가 있습니다.</li>
  <li>GitHub Actions는 <strong>YAML</strong> 파일을 사용하여 워크플로를 정의합니다. 워크플로는 <strong>job</strong>으로 구성되며, 각 job은 <strong>step</strong>으로 구성됩니다.
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_1.png" alt="img.png" /></li>
  <li>
    <p>GitHub Actions의 요금은 아래와 같으며 500MB 스토리지와 매월 2000분을 무료로 사용할 수 있습니다.</p>

    <table>
      <thead>
        <tr>
          <th>계획</th>
          <th>스토리지</th>
          <th>분(월)</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>GitHub Free</td>
          <td>500 MB</td>
          <td>2,000</td>
        </tr>
        <tr>
          <td>GitHub Pro</td>
          <td>1GB</td>
          <td>3,000</td>
        </tr>
        <tr>
          <td>조직용 GitHub Free</td>
          <td>500 MB</td>
          <td>2,000</td>
        </tr>
        <tr>
          <td>GitHub Team</td>
          <td>2GB</td>
          <td>3,000</td>
        </tr>
        <tr>
          <td>GitHub Enterprise Cloud</td>
          <td>50GB</td>
          <td>50,000</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<h3 id="첫-github-actions-워크플로-만들기">첫 GitHub Actions 워크플로 만들기</h3>

<ul>
  <li>GitHub Actions는 repository 내의 <code class="language-plaintext highlighter-rouge">.github/workflows</code> 디렉터리에 저장된 워크플로우 정의 파일을 읽어서 실행합니다.</li>
  <li>간단한 GitHub Repository를 만들고 그 안에 워크플로우를 만들어서 테스트 해보겠습니다.
    <ol>
      <li>새로운 Repository 만들기 <a href="https://www.github.com/new">링크</a>
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_2.png" alt="img.png" /></li>
      <li>git clone으로 repository를 로컬로 가져옵니다.
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>git clone https://github.com/sweetlittlebird/2024-cicd-w2-1.git
<span class="nv">$ </span><span class="nb">cd </span>2024-cicd-w2-1
</code></pre></div>        </div>
      </li>
      <li><code class="language-plaintext highlighter-rouge">.github/workflows</code> 디렉터리를 만들고 그 안에 <code class="language-plaintext highlighter-rouge">main.yml</code> 파일을 만듭니다. (파일명은 자유롭게 지정 가능합니다.)
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">mkdir</span> <span class="nt">-p</span> .github/workflows
<span class="nv">$ </span><span class="nb">touch</span> .github/workflows/main.yml
</code></pre></div>        </div>
      </li>
      <li><code class="language-plaintext highlighter-rouge">main.yml</code> 파일에 워크플로우 작성합니다.
        <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># .github/workflows/main.yml</span>
<span class="na">name</span><span class="pi">:</span> <span class="s">Hello World</span>                 <span class="c1"># Github 웹 사이드바 이름</span>
<span class="na">on</span><span class="pi">:</span>
  <span class="na">workflow_dispatch</span><span class="pi">:</span>              <span class="c1"># 수동으로 실행할 수 있는 워크플로우</span>
  <span class="na">push</span><span class="pi">:</span>                           <span class="c1"># push 이벤트 발생 시 실행</span>
     
<span class="na">jobs</span><span class="pi">:</span>
  <span class="na">build</span><span class="pi">:</span>                          <span class="c1"># Jobs 이름</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>        <span class="c1"># 실행 환경</span>
    <span class="na">steps</span><span class="pi">:</span>                        <span class="c1"># Job 내부의 Step 들 </span>
      <span class="pi">-</span> <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/checkout@v3</span> <span class="c1"># actions/checkout 레포지토리의 v3 버전의 워크플로우 사용</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Hello World</span>         <span class="c1"># Step 이름</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">echo "Hello World"</span>     
</code></pre></div>        </div>
      </li>
      <li>GitHub에 push하여 워크플로우를 실행합니다.
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>git add <span class="nb">.</span>
<span class="nv">$ </span>git commit <span class="nt">-m</span> <span class="s2">"GitHub Actions 추가"</span>
<span class="nv">$ </span>git push origin main
</code></pre></div>        </div>
      </li>
      <li>GitHub Repository에서 Actions 탭을 클릭하여 워크플로우를 확인합니다. <a href="https://github.com/sweetlittlebird/2024-cicd-w2-1/actions">링크</a>
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_3.png" alt="img.png" />
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_4.png" alt="img.png" /></li>
    </ol>
  </li>
  <li>워크플로우가 잘 실행되어서 <code class="language-plaintext highlighter-rouge">Hello World</code>가 잘 출력되었습니다.</li>
</ul>

<h4 id="워크플로우를-수동으로-트리거-하기">워크플로우를 수동으로 트리거 하기</h4>

<ul>
  <li>앞서 작성한 워크플로우 처럼 on: workflow_dispatch를 사용하면 워크플로우를 수동으로 실행할 수 있습니다.</li>
  <li>GitHub Repository에서 Actions 탭을 클릭하고 <code class="language-plaintext highlighter-rouge">Run workflow</code> 버튼을 클릭하여 워크플로우를 수동으로 실행할 수 있습니다.
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_5.png" alt="img.png" /></li>
</ul>

<h3 id="직접-개발-후-실행">직접 개발 후 실행</h3>

<ul>
  <li>이번에는 가상머신을 만들고 그 안에서 간단한 웹 서버를 만들어서 GitHub Actions로 배포해보겠습니다.</li>
  <li>가상머신은 Vagrant를 사용하여 만들어 보겠습니다.
    <div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Vagrantfile</span>
<span class="no">Vagrant</span><span class="p">.</span><span class="nf">configure</span><span class="p">(</span><span class="s2">"2"</span><span class="p">)</span> <span class="k">do</span> <span class="o">|</span><span class="n">config</span><span class="o">|</span>
  <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="s2">"ubuntu/jammy64"</span>
  <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="mi">20022</span>
  <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">80</span><span class="p">,</span> <span class="ss">host: </span><span class="mi">20080</span>
  <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">inline: </span><span class="o">&lt;&lt;-</span><span class="no">SHELL</span><span class="sh">
    sudo apt-get update
    sudo apt install -y tree 
</span><span class="no">  SHELL</span>
<span class="k">end</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>위와 같이 Vagrantfile을 작성하고 <code class="language-plaintext highlighter-rouge">vagrant up</code>으로 가상머신을 만들어 줍니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>vagrant up
  
<span class="nv">$ </span>vargrant ssh 
<span class="c"># --------</span>
  
<span class="nv">$ </span>python3 <span class="nt">-V</span>
<span class="c"># =&gt; Python 3.10.12</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> server.py <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
from http.server import ThreadingHTTPServer, BaseHTTPRequestHandler
from datetime import datetime
  
class RequestHandler(BaseHTTPRequestHandler):
    def do_GET(self):
        self.send_response(200)
        self.send_header('Content-type', 'text/plain')
        self.end_headers()
        now = datetime.now()
        response_string = now.strftime("The time is %-I:%M:%S %p, CloudNeta Study.</span><span class="se">\n</span><span class="sh">")
        self.wfile.write(bytes(response_string, "utf-8")) 
  
def startServer():
    try:
        server = ThreadingHTTPServer(('', 80), RequestHandler)
        print("Listening on " + ":".join(map(str, server.server_address)))
        server.serve_forever()
    except KeyboardInterrupt:
        server.shutdown()
  
if __name__== "__main__":
    startServer()
</span><span class="no">EOF
  
</span><span class="nv">$ </span><span class="nb">sudo </span>python3 server.py
  
<span class="c"># 아래 확인 후</span>
<span class="c"># CTRL+C 로 실행 취소</span>
  
<span class="c"># (신규터미널) 서버1 SSH 접속</span>
<span class="nv">$ </span>curl localhost
<span class="c"># =&gt; The time is 2:50:56 PM, CloudNeta Study.</span>
<span class="nv">$ </span><span class="nb">sudo </span>ss <span class="nt">-tnlp</span>
<span class="c"># =&gt; State  Recv-Q Send-Q Local Address:Port Peer Address:PortProcess</span>
<span class="c">#    LISTEN 0      5            0.0.0.0:80        0.0.0.0:*    users:((&amp;quot;python3&amp;quot;,pid=2299,fd=3))</span>
<span class="c">#    LISTEN 0      128          0.0.0.0:22        0.0.0.0:*    users:((&amp;quot;sshd&amp;quot;,pid=1030,fd=3))</span>
  
<span class="c"># --------</span>
</code></pre></div>    </div>
  </li>
  <li>Git 작업
    <ul>
      <li>토큰 발급해두기 : scope (repo, workflow) 필요합니다. 
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_6.png" alt="img.png" /></li>
      <li>Private Repo 신규 생성
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_7.png" alt="img.png" /></li>
      <li>가상머신에서 Git 작업
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ GITUSER</span><span class="o">=</span><span class="s2">"sweetlittlebird"</span>
<span class="nv">$ </span>git config <span class="nt">--global</span> user.name <span class="nv">$GITUSER</span>
<span class="nv">$ </span>git config <span class="nt">--global</span> user.email <span class="s2">"sweetlittlebird@sweetlittlebird.com"</span>
<span class="nv">$ </span>git clone https://github.com/<span class="nv">$GITUSER</span>/2024-cicd-w2-2.git
<span class="c"># =&gt; Cloning into '2024-cicd-w2-2'...</span>
<span class="c">#    Username for 'https://github.com': git</span>
<span class="c">#    Password for 'https://git@github.com':</span>
<span class="c">#    remote: Enumerating objects: 3, done.</span>
<span class="c">#    remote: Counting objects: 100% (3/3), done.</span>
<span class="c">#    remote: Compressing objects: 100% (2/2), done.</span>
<span class="c">#    remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)</span>
<span class="c">#    Receiving objects: 100% (3/3), done.</span>
<span class="nv">$ </span><span class="nb">cp </span>server.py 2024-cicd-w2-2/
<span class="nv">$ </span><span class="nb">cd </span>2024-cicd-w2-2
    
<span class="nv">$ </span>git status
<span class="c"># =&gt; On branch main</span>
<span class="c">#    Your branch is up to date with 'origin/main'.</span>
<span class="c">#    </span>
<span class="c">#    Untracked files:</span>
<span class="c">#      (use &amp;quot;git add &amp;lt;file&amp;gt;...&amp;quot; to include in what will be committed)</span>
<span class="c">#            server.py</span>
<span class="c">#    </span>
<span class="c">#    nothing added to commit but untracked files present (use &amp;quot;git add&amp;quot; to track)</span>
<span class="nv">$ </span>git add <span class="nb">.</span>
<span class="nv">$ </span>git commit <span class="nt">-m</span> <span class="s2">"Initial commit"</span>
<span class="c"># =&gt; [main 30500ca] Initial commit</span>
<span class="c">#     1 file changed, 22 insertions(+)</span>
<span class="c">#     create mode 100644 server.py</span>
<span class="nv">$ </span>git push origin main 
<span class="c"># =&gt; Username for 'https://github.com': git</span>
<span class="c">#    Password for 'https://git@github.com': *** # &lt;span style="color: green;"&gt;👉 ghp로 시작하는 발급해둔 토큰을 사용합니다.&lt;/span&gt; </span>
<span class="c">#    Enumerating objects: 4, done.</span>
<span class="c">#    Counting objects: 100% (4/4), done.</span>
<span class="c">#    Delta compression using up to 2 threads</span>
<span class="c">#    Compressing objects: 100% (3/3), done.</span>
<span class="c">#    Writing objects: 100% (3/3), 665 bytes | 332.00 KiB/s, done.</span>
<span class="c">#    Total 3 (delta 0), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To https://github.com/sweetlittlebird/2024-cicd-w2-2.git</span>
<span class="c">#       ceaed76..30500ca  main -&amp;gt; main</span>
</code></pre></div>        </div>
        <p><img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_8.png" alt="img.png" /></p>
      </li>
    </ul>
  </li>
  <li>서버 실행
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">nohup sudo </span>python3 server.py <span class="o">&gt;</span> server.log 2&gt;&amp;1 &amp;
<span class="nv">$ </span><span class="nb">cat </span>server.log
<span class="c"># =&gt; nohup: ignoring input</span>
<span class="nv">$ </span>curl localhost
<span class="c"># =&gt; The time is 3:13:00 PM, CloudNeta Study.</span>
<span class="nv">$ </span><span class="nb">cat </span>server.log
<span class="c"># =&gt; nohup: ignoring input</span>
<span class="c">#    127.0.0.1 - - [14/Dec/2024 15:13:00] &amp;quot;GET / HTTP/1.1&amp;quot; 200 -</span>
  
<span class="c">#</span>
<span class="nv">$ </span><span class="nb">grep </span>log .gitignore
<span class="c"># =&gt; # Installer logs</span>
<span class="c">#    pip-log.txt</span>
<span class="c">#    *.log          # &lt;span style="color: green;"&gt;👉 로그 파일은 git에서 무시하도록 되어있습니다.&lt;/span&gt;</span>
  
<span class="c">#</span>
<span class="nv">$ </span>git add <span class="nb">.</span>
<span class="nv">$ </span>git commit <span class="nt">-m</span> <span class="s2">"add log file"</span>
<span class="c"># =&gt; nothing to commit, working tree clean  &lt;span style="color: green;"&gt;👉 로그 파일은 git에서 무시하도록 되어있어서 git add . 의 영향을 받지 않습니다.&lt;/span&gt;</span>
<span class="nv">$ </span>git status
<span class="c"># =&gt; nothing to commit, working tree clean</span>
</code></pre></div>    </div>
  </li>
  <li>코드 수정 후 재실행
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/CloudNeta/CICD/g"</span> server.py
  
<span class="c"># 프로세스 종료</span>
<span class="nv">$ </span><span class="nb">sudo </span>ss <span class="nt">-tnlp</span>
<span class="c"># =&gt; State  Recv-Q Send-Q Local Address:Port Peer Address:PortProcess</span>
<span class="c">#    LISTEN 0      128          0.0.0.0:22        0.0.0.0:*    users:(("sshd",pid=883,fd=3))</span>
<span class="c">#    LISTEN 0      5            0.0.0.0:80        0.0.0.0:*    users:((&amp;quot;python3&amp;quot;,pid=2287,fd=3))</span>
<span class="nv">$ </span><span class="nb">sudo </span>fuser <span class="nt">-k</span> <span class="nt">-n</span> tcp 80                 <span class="c"># &lt;span style="color: green;"&gt;👉 80번 포트를 사용하는 프로세스를 종료합니다.&lt;/span&gt;</span>
<span class="c"># =&gt; 80/tcp:               2287</span>
<span class="c">#    [1]+  Killed                  nohup sudo python3 server.py &amp;gt; server.log 2&amp;gt;&amp;amp;1  (wd: ~)</span>
<span class="c">#    (wd now: ~/2024-cicd-w2-2)</span>
<span class="nv">$ </span><span class="nb">sudo </span>ss <span class="nt">-tnlp</span>
<span class="c"># =&gt; State  Recv-Q Send-Q Local Address:Port Peer Address:PortProcess</span>
<span class="c">#    LISTEN 0      128          0.0.0.0:22        0.0.0.0:*    users:(("sshd",pid=883,fd=3))</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 80 포트를 사용하던 python3가 종료되어서 없어졌습니다.&lt;/span&gt;</span>
  
<span class="c"># 재실행</span>
<span class="nv">$ </span><span class="nb">nohup sudo </span>python3 server.py <span class="o">&gt;</span> server.log 2&gt;&amp;1 &amp;
<span class="nv">$ </span>curl localhost
<span class="c"># =&gt; The time is 3:24:23 PM, CICD Study.  # &lt;span style="color: green;"&gt;👉 수정사항이 반영되었습니다.&lt;/span&gt;</span>
</code></pre></div>    </div>
  </li>
  <li>코드 push
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 매번 사용자 인증을 요구하지 않도록 인증 정보를 저장하도록 설정하겠습니다.</span>
<span class="nv">$ </span>git config <span class="nt">--global</span> credential.helper store
  
<span class="c">#</span>
<span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"version update"</span> <span class="o">&amp;&amp;</span> git push origin main
<span class="c"># =&gt; [main 11f7a3d] version update</span>
<span class="c">#     1 file changed, 1 insertion(+), 1 deletion(-)</span>
<span class="c">#    Username for 'https://github.com': git</span>
<span class="c">#    Password for 'https://git@github.com':</span>
<span class="c">#    Enumerating objects: 5, done.</span>
<span class="c">#    Counting objects: 100% (5/5), done.</span>
<span class="c">#    Delta compression using up to 2 threads</span>
<span class="c">#    Compressing objects: 100% (3/3), done.</span>
<span class="c">#    Writing objects: 100% (3/3), 312 bytes | 156.00 KiB/s, done.</span>
<span class="c">#    Total 3 (delta 1), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    remote: Resolving deltas: 100% (1/1), completed with 1 local object.</span>
<span class="c">#    To https://github.com/sweetlittlebird/2024-cicd-w2-2.git</span>
<span class="c">#       30500ca..11f7a3d  main -&amp;gt; main</span>
  
<span class="nv">$ </span>git push origin main
<span class="c"># =&gt; Everything up-to-date</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 인증정보가 저장되어서 별도의 인증과정 없이 사용할 수 있습니다.&lt;/span&gt;</span>
</code></pre></div>    </div>
  </li>
</ul>

<h3 id="github-actions로-배포하기">GitHub Actions로 배포하기</h3>

<ul>
  <li>개인 PC에서 작업 후 Github에 push하면 GitHub Actions를 통해 VM에 배포가 되도록 CI/CD를 구성해보겠습니다.</li>
</ul>

<h5 id="ssh-키-생성">SSH 키 생성</h5>

<ul>
  <li>먼저 가상머신에 ssh 접속을 위해 ssh key를 생성하고 GitHub에 등록합니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cd</span> ~/.ssh
<span class="nv">$ </span>ssh-keygen <span class="nt">-t</span> ed25519
<span class="c"># =&gt; Enter file in which to save the key (/home/vagrant/.ssh/id_ed25519):</span>
<span class="c">#    Enter passphrase (empty for no passphrase): # &lt;span style="color: green;"&gt;👉 비밀번호 없이 엔터만 입력합니다.&lt;/span&gt;</span>
<span class="c">#    Enter same passphrase again:                # &lt;span style="color: green;"&gt;👉 엔터만 입력합니다.&lt;/span&gt;</span>
  
<span class="c"># 생성된 공개키를 로그인 허용 키 목록에 추가합니다</span>
<span class="nv">$ </span><span class="nb">cat </span>id_ed25519.pub  <span class="o">&gt;&gt;</span> authorized_keys     
<span class="nv">$ </span><span class="nb">cat </span>id_ed25519   <span class="c"># &lt;span style="color: green;"&gt;👉 개인키를 복사합니다. 복사한 키는 github secret에 추가할 것입니다.&lt;/span&gt;</span>
</code></pre></div>    </div>
  </li>
</ul>

<h5 id="github에-ssh-키와-가상머신-외부-ip-등록">GitHub에 SSH 키와 가상머신 외부 IP 등록</h5>

<ul>
  <li>GitHub의 Repository에서 <code class="language-plaintext highlighter-rouge">Settings</code> -&gt; <code class="language-plaintext highlighter-rouge">Secrets and variables</code> -&gt; <code class="language-plaintext highlighter-rouge">Actions</code> -&gt; <code class="language-plaintext highlighter-rouge">New repository secret</code>를 클릭하여 아래와 같이 추가합니다.
    <ul>
      <li><code class="language-plaintext highlighter-rouge">SSH_PRIVATE_KEY</code> : 앞에서 복사한 개인키를 추가합니다. 
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_9.png" alt="img.png" /></li>
      <li><code class="language-plaintext highlighter-rouge">EC2_PIP</code> : 가상머신의 외부 IP를 추가합니다. (인터넷에서 접속가능한 IP여야 합니다.)
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_10.png" alt="img.png" /></li>
    </ul>
  </li>
</ul>

<h5 id="내-pc에서-코드-작업">내 PC에서 코드 작업</h5>

<ul>
  <li>
    <p>내 PC에서 작업을 합니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>git clone https://github.com/sweetlittlebird/2024-cicd-w2-2.git
<span class="c"># =&gt; Cloning into '2024-cicd-w2-2'...</span>
<span class="c">#    remote: Enumerating objects: 9, done.</span>
<span class="c">#    remote: Counting objects: 100% (9/9), done.</span>
<span class="c">#    remote: Compressing objects: 100% (7/7), done.</span>
<span class="c">#    remote: Total 9 (delta 1), reused 6 (delta 1), pack-reused 0 (from 0)</span>
<span class="c">#    Receiving objects: 100% (9/9), done.</span>
<span class="c">#    Resolving deltas: 100% (1/1), done.</span>
<span class="nv">$ </span><span class="nb">cd </span>2024-cicd-w2-2
  
<span class="c"># 워크플로우 파일 생성</span>
<span class="nv">$ </span><span class="nb">mkdir</span> <span class="nt">-p</span> .github/workflows/
<span class="nv">$ </span><span class="nb">touch</span> .github/workflows/deploy.yaml
  
<span class="c"># 소스 수정</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s2">"s/CICD/CICD 2w/g"</span> server.py
</code></pre></div>    </div>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">.github/workflows/deploy.yaml</code> 파일을 작성합니다.</p>

    <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># .github/workflows/deploy.yaml</span>
<span class="na">name</span><span class="pi">:</span> <span class="s">CICD1</span>
<span class="na">on</span><span class="pi">:</span>
  <span class="na">workflow_dispatch</span><span class="pi">:</span>
  <span class="na">push</span><span class="pi">:</span>
    <span class="na">branches</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">main</span>
  
<span class="na">jobs</span><span class="pi">:</span>
  <span class="na">deploy</span><span class="pi">:</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Configure the SSH Private Key Secret</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">mkdir -p ~/.ssh/</span>
          <span class="s">echo "${{ secrets.SSH_PRIVATE_KEY }}" &gt; ~/.ssh/id_rsa</span>
          <span class="s">chmod 600 ~/.ssh/id_rsa</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Set Strict Host Key Checking</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">echo "StrictHostKeyChecking=no" &gt; ~/.ssh/config</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Git Pull</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">export MY_HOST="${{ secrets.EC2_PIP }}"</span>
          <span class="s">ssh vagrant@$MY_HOST &lt;&lt; EOF</span>
            <span class="s">cd /home/vagrant/2024-cicd-w2-2 || exit 1</span>
            <span class="s">git pull origin main || exit 1</span>
          <span class="s">EOF</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Run service</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">export MY_HOST="${{ secrets.EC2_PIP }}"</span>
          <span class="s">ssh vagrant@$MY_HOST sudo fuser -k -n tcp 80 || true</span>
          <span class="s">ssh vagrant@$MY_HOST "nohup sudo -E python3 /home/vagrant/2024-cicd-w2-2/server.py &gt; /home/vagrant/2024-cicd-w2-2/server.log 2&gt;&amp;1 &amp;"</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>코드를 push합니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"add workflow"</span> <span class="o">&amp;&amp;</span> git push origin main
</code></pre></div>    </div>
  </li>
  <li>GitHub Actions를 확인해보겠습니다.
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_11.png" alt="img.png" /></li>
  <li>가상머신에서 확인해보겠습니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>vagrant ssh
  
<span class="c">#-------</span>
<span class="nv">$ </span><span class="nb">cd </span>2024-cicd-w2-2/
<span class="nv">$ </span><span class="nb">grep</span> <span class="nt">-i</span> cicd server.py
<span class="c"># =&gt;         response_string = now.strftime(&amp;quot;The time is %-I:%M:%S %p, CICD 2w Study.\n&amp;quot;)</span>
<span class="nv">$ </span><span class="nb">sudo </span>ps <span class="nt">-ef</span> |grep server.py
<span class="c"># =&gt; root        2620       1  0 15:57 ?        00:00:00 sudo -E python3 /home/vagrant/2024-cicd-w2-2/server.py</span>
<span class="c">#    root        2621    2620  0 15:57 ?        00:00:00 python3 /home/vagrant/2024-cicd-w2-2/server.py</span>
<span class="nv">$ </span><span class="nb">tail</span> /home/vagrant/2024-cicd-w2-2/server.log
<span class="c"># =&gt; nohup: ignoring input</span>
<span class="c">#------- </span>
</code></pre></div>    </div>
  </li>
  <li>변경사항을 브라우저로 확인해보겠습니다.
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_12.png" alt="img.png" />
    <ul>
      <li>변경사항이 잘 반영되어서 CICD <code class="language-plaintext highlighter-rouge">2w</code>로 변경되었습니다.</li>
    </ul>
  </li>
</ul>

<h5 id="코드-수정-후-동작-확인">코드 수정 후 동작 확인</h5>

<ul>
  <li>개인 PC에서 코드와 워크플로우를 수정하고 GitHub에 push하여 배포가 잘 되는지 확인해보겠습니다.
    <ul>
      <li>코드 수정
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s2">"s/CICD 2w/CICD1 End/g"</span> server.py
</code></pre></div>        </div>
      </li>
      <li>
        <p>워크플로우 수정</p>

        <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># .github/workflows/deploy.yaml</span>
<span class="na">name</span><span class="pi">:</span> <span class="s">CICD1 End</span>
<span class="na">on</span><span class="pi">:</span>
  <span class="na">workflow_dispatch</span><span class="pi">:</span>
  <span class="na">push</span><span class="pi">:</span>
    <span class="na">branches</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">main</span>
    
<span class="na">jobs</span><span class="pi">:</span>
  <span class="na">deployfinal</span><span class="pi">:</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Configure the SSH Private Key Secret</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">mkdir -p ~/.ssh/</span>
          <span class="s">echo "${{ secrets.SSH_PRIVATE_KEY }}" &gt; ~/.ssh/id_rsa</span>
          <span class="s">chmod 600 ~/.ssh/id_rsa</span>
    
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Set Strict Host Key Checking</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">echo "StrictHostKeyChecking=no" &gt; ~/.ssh/config</span>
    
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Git Pull</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">export MY_HOST="${{ secrets.EC2_PIP }}"</span>
          <span class="s">ssh vagrant@$MY_HOST &lt;&lt; EOF</span>
            <span class="s">cd /home/vagrant/2024-cicd-w2-2 || exit 1</span>
            <span class="s">git pull origin main || exit 1</span>
          <span class="s">EOF</span>
    
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Run service</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">export MY_HOST="${{ secrets.EC2_PIP }}"</span>
          <span class="s">ssh vagrant@$MY_HOST sudo fuser -k -n tcp 80 || true</span>
          <span class="s">ssh vagrant@$MY_HOST "nohup sudo -E python3 /home/vagrant/2024-cicd-w2-2/server.py &gt; /home/vagrant/2024-cicd-w2-2/server.log 2&gt;&amp;1 &amp;"</span>
</code></pre></div>        </div>
      </li>
      <li>코드 push
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"edit workflow"</span> <span class="o">&amp;&amp;</span> git push origin main
    
<span class="c"># [가상머신]</span>
<span class="nv">$ </span><span class="nb">grep</span> <span class="nt">-i</span> cicd server.py
<span class="c"># =&gt;         response_string = now.strftime(&amp;quot;The time is %-I:%M:%S %p, CICD1 End Study.</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 변경된 소스가 서버에 반영되었습니다.&lt;/span&gt;</span>
    
<span class="nv">$ </span><span class="nb">sudo </span>ps <span class="nt">-ef</span> |grep server.py
<span class="c"># =&gt; root        3011       1  0 16:17 ?        00:00:00 sudo -E python3 /home/vagrant/2024-cicd-w2-2/server.py</span>
<span class="c">#    root        3012    3011  0 16:17 ?        00:00:00 python3 /home/vagrant/2024-cicd-w2-2/server.py</span>
<span class="c">#    vagrant     3035    2255  0 16:18 pts/0    00:00:00 grep --color=auto server.py</span>
<span class="nv">$ </span><span class="nb">tail</span> /home/vagrant/2024-cicd-w2-2/server.log
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li>변경사항을 브라우저로 확인해보겠습니다.
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_13.png" alt="img.png" />
    <ul>
      <li>변경사항이 잘 반영되어서 CICD1 End로 변경되었습니다.</li>
    </ul>
  </li>
</ul>

<h3 id="github-actions의-marketplace-활용하기">GitHub Actions의 Marketplace 활용하기</h3>

<ul>
  <li>이번에는 GitHub Actions의 Marketplace에서 다른 액션을 가져와서 사용해보겠습니다.</li>
  <li>Marketplace는 <a href="https://github.com/marketplace">https://github.com/marketplace</a>로 접속할 수 있습니다.</li>
  <li>이번 실습에서 사용할 액션은 ssh와 scp 입니다.</li>
</ul>

<h4 id="ssh-for-github-actions">SSH for GitHub Actions</h4>
<ul>
  <li>관련 주소 : <a href="https://github.com/appleboy/ssh-action">Github</a>, <a href="https://github.com/marketplace/actions/ssh-remote-commands">marketplace</a></li>
  <li>SSH for GitHub Actions는 원격 서버에 SSH로 접속하여 명령을 실행할 수 있습니다.</li>
  <li>앞의 실습처럼 쉘 명령으로 ssh 접속이 가능하지만 이 액션을 사용하면 더 간편하게 사용할 수 있습니다.</li>
  <li>사용 예
    <ol>
      <li>
        <p>아이디/비밀번호로 원격 서버에 접속하여 <code class="language-plaintext highlighter-rouge">whoami</code> 명령을 실행합니다.</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>name: remote ssh <span class="nb">command
</span>on: <span class="o">[</span>push]
<span class="nb">jobs</span>:
  build:
    name: Build
    runs-on: ubuntu-latest
    steps:
      - name: executing remote ssh commands using password
        uses: appleboy/ssh-action@v1.2.0
        with:
          host: <span class="k">${</span><span class="p">{ secrets.HOST </span><span class="k">}</span><span class="o">}</span>
          username: linuxserver.io
          password: <span class="k">${</span><span class="p">{ secrets.PASSWORD </span><span class="k">}</span><span class="o">}</span>
          port: <span class="k">${</span><span class="p">{ secrets.PORT </span><span class="k">}</span><span class="o">}</span>
          script: <span class="nb">whoami</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p>비밀번호 대신 private key를 사용하여 로그인 합니다.</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Using private key</span>
- name: executing remote ssh commands using ssh key
  uses: appleboy/ssh-action@v1.2.0
  with:
    host: <span class="k">${</span><span class="p">{ secrets.HOST </span><span class="k">}</span><span class="o">}</span>
    username: <span class="k">${</span><span class="p">{ secrets.USERNAME </span><span class="k">}</span><span class="o">}</span>
    key: <span class="k">${</span><span class="p">{ secrets.KEY </span><span class="k">}</span><span class="o">}</span>
    port: <span class="k">${</span><span class="p">{ secrets.PORT </span><span class="k">}</span><span class="o">}</span>
    script: <span class="nb">whoami</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p>여러 명령을 실행할 수 있습니다.</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Multiple Commands</span>
- name: multiple <span class="nb">command
  </span>uses: appleboy/ssh-action@v1.2.0
  with:
    host: <span class="k">${</span><span class="p">{ secrets.HOST </span><span class="k">}</span><span class="o">}</span>
    username: <span class="k">${</span><span class="p">{ secrets.USERNAME </span><span class="k">}</span><span class="o">}</span>
    key: <span class="k">${</span><span class="p">{ secrets.KEY </span><span class="k">}</span><span class="o">}</span>
    port: <span class="k">${</span><span class="p">{ secrets.PORT </span><span class="k">}</span><span class="o">}</span>
    script: |
      <span class="nb">whoami
      ls</span> <span class="nt">-al</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p>환경 변수를 쉘에 전달할 수 있습니다.</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Pass environment variable to shell script</span>
- name: pass environment
  uses: appleboy/ssh-action@v1.2.0
  <span class="nb">env</span>:
    FOO: <span class="s2">"BAR"</span>
    BAR: <span class="s2">"FOO"</span>
    SHA: <span class="k">${</span><span class="p">{ github.sha </span><span class="k">}</span><span class="o">}</span>
  with:
    host: <span class="k">${</span><span class="p">{ secrets.HOST </span><span class="k">}</span><span class="o">}</span>
    username: <span class="k">${</span><span class="p">{ secrets.USERNAME </span><span class="k">}</span><span class="o">}</span>
    key: <span class="k">${</span><span class="p">{ secrets.KEY </span><span class="k">}</span><span class="o">}</span>
    port: <span class="k">${</span><span class="p">{ secrets.PORT </span><span class="k">}</span><span class="o">}</span>
    envs: FOO,BAR,SHA
    script: |
      <span class="nb">echo</span> <span class="s2">"I am </span><span class="nv">$FOO</span><span class="s2">"</span>
      <span class="nb">echo</span> <span class="s2">"I am </span><span class="nv">$BAR</span><span class="s2">"</span>
      <span class="nb">echo</span> <span class="s2">"sha: </span><span class="nv">$SHA</span><span class="s2">"</span>
</code></pre></div>        </div>
      </li>
    </ol>
  </li>
  <li>
    <p>워크플로우 설정 후 테스트</p>

    <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># .github/workflows/ssh-deploy.yaml</span>
<span class="na">name</span><span class="pi">:</span> <span class="s">CICD2</span>
<span class="na">on</span><span class="pi">:</span>
  <span class="na">workflow_dispatch</span><span class="pi">:</span>
  <span class="na">push</span><span class="pi">:</span>
    <span class="na">branches</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">main</span>
  
<span class="na">jobs</span><span class="pi">:</span>
  <span class="na">ssh-deploy</span><span class="pi">:</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Github Repository Checkout</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/checkout@v4</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">executing remote ssh commands</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">appleboy/ssh-action@v1.2.0</span>
        <span class="na">env</span><span class="pi">:</span>
          <span class="na">AWS_KEYS</span><span class="pi">:</span> <span class="pi">|</span>
            <span class="s">ACCESSKEY : asdf1234end</span>
            <span class="s">SECRETKEY : qwer1234end</span>
        <span class="na">with</span><span class="pi">:</span>
          <span class="na">host</span><span class="pi">:</span> <span class="s">${{ secrets.EC2_PIP }}</span>
          <span class="na">port</span><span class="pi">:</span> <span class="m">22</span>
          <span class="na">username</span><span class="pi">:</span> <span class="s">vagrant</span>
          <span class="na">key</span><span class="pi">:</span> <span class="s">${{ secrets.SSH_PRIVATE_KEY }}</span>
          <span class="na">envs</span><span class="pi">:</span> <span class="s">AWS_KEYS</span>
          <span class="na">script_stop</span><span class="pi">:</span> <span class="kc">true</span>
          <span class="na">script</span><span class="pi">:</span> <span class="pi">|</span>
            <span class="s">cd /home/vagrant/2024-cicd-w2-2</span>
            <span class="s">echo "$AWS_KEYS" &gt; .env</span>
</code></pre></div>    </div>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"add ssh action test"</span> <span class="o">&amp;&amp;</span> git push origin main
</code></pre></div>    </div>
  </li>
  <li>
    <p>가상머신에서 확인</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-al</span> ~/2024-cicd-w2-2/
<span class="c"># =&gt; total 32</span>
<span class="c">#    drwxrwxr-x 4 vagrant vagrant 4096 Oct 01 16:46 .</span>
<span class="c">#    drwxr-x--- 5 vagrant vagrant 4096 Oct 01 16:46 ..</span>
<span class="c">#    -rw-rw-r-- 1 vagrant vagrant   49 Oct 01 16:46 .env  # &lt;span style="color: green;"&gt;👉 .env파일이 생성되었습니다.&lt;/span&gt;  </span>
<span class="c">#    drwxrwxr-x 8 vagrant vagrant 4096 Oct 01 16:46 .git</span>
<span class="c">#    drwxrwxr-x 3 vagrant vagrant 4096 Oct 01 15:57 .github</span>
<span class="c">#    -rw-rw-r-- 1 vagrant vagrant 3139 Oct 01 15:11 .gitignore</span>
<span class="c">#    -rw-rw-r-- 1 vagrant vagrant    0 Oct 01 16:46 server.log</span>
<span class="c">#    -rw-rw-r-- 1 vagrant vagrant  761 Oct 01 16:17 server.py</span>
<span class="c">#    -rw-rw-r-- 1 vagrant vagrant  759 Oct 01 16:17 server.py-e</span>
<span class="nv">$ </span><span class="nb">cat</span> ~/2024-cicd-w2-2/.env
<span class="c"># =&gt; ACCESSKEY : asdf1234end</span>
<span class="c">#    SECRETKEY : qwer1234end</span>
</code></pre></div>    </div>
  </li>
  <li>GitHub에서 .env가 있는지 확인해보겠습니다.
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_14.png" alt="img.png" />
.env 파일이 Git에는 없습니다! 하지만 가상머신 서버에 .env 파일이 있었던 것은 SSH for GitHub Actions를 통해 전달된 것입니다.</li>
</ul>

<h4 id="scp-for-github-actions">SCP for GitHub Actions</h4>

<ul>
  <li>관련 주소 : <a href="https://github.com/appleboy/scp-action">Github</a>, <a href="https://github.com/marketplace/actions/scp-files">marketplace</a></li>
  <li>SCP for GitHub Actions는 원격 서버로 파일을 전송해주는 액션입니다.</li>
  <li>실습을 통해 기능을 알아보겠습니다.</li>
  <li>server.py 수정하기
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s2">"s/CICD1 End Study/SCP Test/g"</span> server.py
</code></pre></div>    </div>
  </li>
  <li>
    <p>워크플로우 파일 수정하기</p>

    <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># .github/workflows/scp-ssh-deploy.yaml</span>
<span class="na">name</span><span class="pi">:</span> <span class="s">CICD2</span>
<span class="na">on</span><span class="pi">:</span>
  <span class="na">workflow_dispatch</span><span class="pi">:</span>
  <span class="na">push</span><span class="pi">:</span>
    <span class="na">branches</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">main</span>
  
<span class="na">jobs</span><span class="pi">:</span>
  <span class="na">scp-ssh-deploy</span><span class="pi">:</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Github Repository Checkout</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/checkout@v4</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">executing remote ssh commands</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">appleboy/ssh-action@v1.2.0</span>
        <span class="na">env</span><span class="pi">:</span>
          <span class="na">AWS_KEYS</span><span class="pi">:</span> <span class="s">${{ secrets.MYKEYS }}</span>
        <span class="na">with</span><span class="pi">:</span>
          <span class="na">host</span><span class="pi">:</span> <span class="s">${{ secrets.EC2_PIP }}</span>
          <span class="na">username</span><span class="pi">:</span> <span class="s">vagrant</span>
          <span class="na">port</span><span class="pi">:</span> <span class="m">22</span>
          <span class="na">key</span><span class="pi">:</span> <span class="s">${{ secrets.SSH_PRIVATE_KEY }}</span>
          <span class="na">envs</span><span class="pi">:</span> <span class="s">AWS_KEYS</span>
          <span class="na">script_stop</span><span class="pi">:</span> <span class="kc">true</span>
          <span class="na">script</span><span class="pi">:</span> <span class="pi">|</span>
             <span class="s">cd /home/vagrant/2024-cicd-w2-2</span>
             <span class="s">echo "$AWS_KEYS" &gt; .env</span>
             <span class="s">sudo fuser -k -n tcp 80 || true</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">copy file via scp</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">appleboy/scp-action@v0.1.7</span>
        <span class="na">with</span><span class="pi">:</span>
          <span class="na">host</span><span class="pi">:</span> <span class="s">${{ secrets.EC2_PIP }}</span>
          <span class="na">username</span><span class="pi">:</span> <span class="s">vagrant</span>
          <span class="na">port</span><span class="pi">:</span> <span class="m">22</span>
          <span class="na">key</span><span class="pi">:</span> <span class="s">${{ secrets.SSH_PRIVATE_KEY }}</span>
          <span class="na">source</span><span class="pi">:</span> <span class="s">server.py</span>
          <span class="na">target</span><span class="pi">:</span> <span class="s">/home/vagrant/2024-cicd-w2-2</span>
</code></pre></div>    </div>
  </li>
  <li>코드 push하기
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"using scp ssh action"</span> <span class="o">&amp;&amp;</span> git push origin main
</code></pre></div>    </div>
  </li>
  <li>가상서버에서 확인
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 서버 1</span>
<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-al</span> ~/2024-cicd-w2-2/
<span class="c"># =&gt; total 28</span>
<span class="c">#    drwxrwxr-x 4 vagrant vagrant 4096 Dec 14 17:04 .</span>
<span class="c">#    drwxr-x--- 5 vagrant vagrant 4096 Dec 14 17:04 ..</span>
<span class="c">#    -rw-rw-r-- 1 vagrant vagrant    1 Dec 14 17:03 .env</span>
<span class="c">#    drwxrwxr-x 8 vagrant vagrant 4096 Dec 14 17:02 .git</span>
<span class="c">#    drwxrwxr-x 3 vagrant vagrant 4096 Dec 14 15:57 .github</span>
<span class="c">#    -rw-rw-r-- 1 vagrant vagrant 3139 Dec 14 15:11 .gitignore</span>
<span class="c">#    -rw-rw-r-- 1 vagrant vagrant    0 Dec 14 17:02 server.log</span>
<span class="c">#    -rw-r--r-- 1 vagrant vagrant  754 Dec 14 17:03 server.py</span>
<span class="nv">$ </span><span class="nb">cat</span> ~/2024-cicd-w2-2/server.py | <span class="nb">grep </span>SCP
<span class="c"># =&gt;         response_string = now.strftime(&amp;quot;The time is %-I:%M:%S %p, SCP Test.\n&amp;quot;)  </span>
<span class="c"># &lt;span style="color: green;"&gt;👉 변경사항이 잘 반영되었습니다.&lt;/span&gt;</span>
</code></pre></div>    </div>
  </li>
</ul>

<h4 id="최종-실습">최종 실습</h4>

<ul>
  <li>앞서 쉘 명령으로 진행했던 작업을 GitHub Actions의 Marketplace에서 가져온 ssh, scp 액션을 사용하여 진행해보겠습니다.</li>
  <li>내 PC에서 소스 수정하기
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s2">"s/SCP Test/CICD2 End 🥳/g"</span> server.py
</code></pre></div>    </div>
  </li>
  <li>
    <p>워크플로우 수정하기</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># .github/workflows/deploy.yaml</span>
name: CICD2
on:
  workflow_dispatch:
  push:
    branches:
      - main
  
<span class="nb">jobs</span>:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Github Repository Checkout
        uses: actions/checkout@v4
  
      - name: copy file via ssh
        uses: appleboy/scp-action@v0.1.7
        with:
          host: <span class="k">${</span><span class="p">{ secrets.EC2_PIP </span><span class="k">}</span><span class="o">}</span>
          username: vagrant
          port: 22  
          key: <span class="k">${</span><span class="p">{ secrets.SSH_PRIVATE_KEY </span><span class="k">}</span><span class="o">}</span>
          <span class="nb">source</span>: server.py
          target: /home/vagrant
  
      - name: executing remote ssh commands 
        uses: appleboy/ssh-action@v1.2.0
        <span class="nb">env</span>:
          AWS_KEYS: <span class="k">${</span><span class="p">{ secrets.MYKEYS </span><span class="k">}</span><span class="o">}</span>
        with:
          host: <span class="k">${</span><span class="p">{ secrets.EC2_PIP </span><span class="k">}</span><span class="o">}</span>
          username: vagrant
          port: 22
          key: <span class="k">${</span><span class="p">{ secrets.SSH_PRIVATE_KEY </span><span class="k">}</span><span class="o">}</span>
          envs: AWS_KEYS
          script_stop: <span class="nb">true
          </span>script: |
             <span class="nb">cd</span> /home/vagrant/2024-cicd-w2-2
             <span class="nb">echo</span> <span class="s2">"</span><span class="nv">$AWS_KEYS</span><span class="s2">"</span> <span class="o">&gt;</span> .env
             <span class="nb">sudo </span>fuser <span class="nt">-k</span> <span class="nt">-n</span> tcp 80 <span class="o">||</span> <span class="nb">true
             rm </span>server.py
             <span class="nb">cp</span> /home/vagrant/server.py ./
             <span class="nb">nohup sudo</span> <span class="nt">-E</span> python3 /home/vagrant/2024-cicd-w2-2/server.py <span class="o">&gt;</span> /home/vagrant/2024-cicd-w2-2/server.log 2&gt;&amp;1 &amp;
             <span class="nb">echo</span> <span class="s2">"test"</span> <span class="o">&gt;&gt;</span> /home/vagrant/text.txt
</code></pre></div>    </div>
  </li>
  <li>코드 push하기
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"Deploy CICD2 Final"</span> <span class="o">&amp;&amp;</span> git push origin main
</code></pre></div>    </div>
  </li>
  <li>웹으로 접속해서 확인해보겠습니다.
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_15.png" alt="img.png" />
    <ul>
      <li>변경사항이 잘 반영되어서 CICD2 End 🥳로 변경되었습니다.</li>
    </ul>
  </li>
</ul>

<h3 id="github-actions-with-ansible">GitHub Actions with Ansible</h3>

<ul>
  <li>이번에는 GitHub Actions를 사용하여 Ansible을 실행해보겠습니다.</li>
  <li>상세한 Ansible 사용법은 <a href="https://docs.ansible.com/ansible/latest/index.html">Ansible 공식문서</a>를 참고하시고, 이번 실습에서는
간단하게 Ansible을 이용해서 Ping 테스트를 해보겠습니다. (여기에서의 ping은 ansible이 해당 호스트와 통신이 가능한지 확인하는 것이고 일반적인 ping과는 다릅니다.)</li>
  <li>
    <p>워크플로우 작성</p>

    <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># .github/workflows/ansible-deploy.yaml</span>
<span class="na">name</span><span class="pi">:</span> <span class="s">Run Ansible</span>
<span class="na">on</span><span class="pi">:</span>
  <span class="na">workflow_dispatch</span><span class="pi">:</span>
  <span class="na">push</span><span class="pi">:</span>
    <span class="na">branches</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">main</span>
  
<span class="na">jobs</span><span class="pi">:</span>
  <span class="na">run-playbooks</span><span class="pi">:</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Github Repository Checkout</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/checkout@v4</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Setup Python </span><span class="m">3</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/setup-python@v5</span>
        <span class="na">with</span><span class="pi">:</span>
          <span class="na">python-version</span><span class="pi">:</span> <span class="s2">"</span><span class="s">3.8"</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Upgrade Pip &amp; Install Ansible</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">python -m pip install --upgrade pip</span>
          <span class="s">python -m pip install ansible</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Implement the Private SSH Key</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">mkdir -p ~/.ssh/</span>
          <span class="s">echo "$" &gt; ~/.ssh/id_rsa</span>
          <span class="s">chmod 600 ~/.ssh/id_rsa</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Ansible Inventory File for Remote host</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">mkdir -p ./devops/ansible/</span>
          <span class="s">export INVENTORY_FILE=./devops/ansible/inventory.ini</span>
          <span class="s">echo "[my_host_group]" &gt; $INVENTORY_FILE</span>
          <span class="s">echo "$" &gt;&gt; $INVENTORY_FILE</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Ansible Default Configuration File</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">mkdir -p ./devops/ansible/</span>
          <span class="s">cat &lt;&lt;EOF &gt; ./devops/ansible/ansible.cfg</span>
          <span class="s">[defaults]</span>
          <span class="s">ansible_python_interpreter = '/usr/bin/python3'</span>
          <span class="s">ansible_ssh_private_key_file = ~/.ssh/id_rsa</span>
          <span class="s">remote_user = vagrant</span>
          <span class="s">inventory = ./inventory.ini</span>
          <span class="s">host_key_checking = False</span>
          <span class="s">EOF</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Ping Ansible Hosts</span>
        <span class="na">working-directory</span><span class="pi">:</span> <span class="s">./devops/ansible/</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">ansible all -m ping</span>
  
      <span class="c1"># - name: Run Ansible Playbooks</span>
      <span class="c1">#   working-directory: ./devops/ansible/</span>
      <span class="c1">#   run: |</span>
      <span class="c1">#     ansible-playbook install-nginx.yaml</span>
  
      <span class="c1"># - name: Deploy Python via Ansible</span>
      <span class="c1">#   working-directory: ./devops/ansible/</span>
      <span class="c1">#   run: |</span>
      <span class="c1">#     ansible-playbook deploy-python.yaml</span>
</code></pre></div>    </div>
  </li>
  <li>워크플로우 push 하기
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"Deploy Ansible Test"</span> <span class="o">&amp;&amp;</span> git push origin main
</code></pre></div>    </div>
  </li>
  <li>GitHub Actions에서 ping 결과를 확인해보겠습니다.
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_16.png" alt="img.png" />
    <ul>
      <li>정상적으로 ping이 가서 “pong”이라는 응답이 돌아왔습니다.</li>
    </ul>
  </li>
</ul>

<h2 id="마치며">마치며</h2>

<p>지금까지 GitHub Actions의 기본적인 사용하고, Marketplace에서 제공하는 액션 사용해보고, Ansible까지 맛보기로 사용해보았습니다.</p>

<p>GitHub Actions는 일부 제약이 있지만 무료로 편리하게 사용할 수 있고
Marketplace를 통해 다양한 추가기능을 손쉽게 사용할 수 있어서 매력적입니다.</p>

<p>하지만 매번 가상환경을 프로비저닝하고, 필요한 패키지를 설치하는 등의 작업이
시간이 의외로 많이 들어서, 실제 동작 시간이 예상보다 오래 걸릴 수 있다는 점이 있습니다.
또한 Jenkins나 다른 CI/CD 도구들은 실패한 상태의 쉘에 직접 로그인해서 트러블 슈팅을 할 수 있지만,
Github Actions는 그렇게 할 수 없는 점도 아쉽습니다.</p>

<p>그래도 GitHub를 사용하면서 저렴한 가격으로 간단하게 CI/CD를 구성할 수 있다는 점은 매력적인것 같습니다.</p>

<p>추운 날씨에도 애써주신 모든 분들 고생 많으셨습니다. 감사합니다! :bow:</p>]]></content><author><name></name></author><category term="kans" /><category term="cicd," /><category term="jenkins," /><category term="git," /><category term="linux" /><summary type="html"><![CDATA[이번 주에는 GitHub Actions를 이용한 CI/CD에 대해 알아보겠습니다.]]></summary></entry><entry><title type="html">[CI/CD] Jenkins CI/CD + Docker</title><link href="https://sweetlittlebird.github.io/posts/2024-12-08-CICD-Lite-Week1/" rel="alternate" type="text/html" title="[CI/CD] Jenkins CI/CD + Docker" /><published>2024-12-08T00:50:18+09:00</published><updated>2024-12-08T00:50:18+09:00</updated><id>https://sweetlittlebird.github.io/posts/CICD%20Lite%20-%20Week1</id><content type="html" xml:base="https://sweetlittlebird.github.io/posts/2024-12-08-CICD-Lite-Week1/"><![CDATA[<h2 id="들어가며">들어가며</h2>

<p>스터디 시간이 다시 돌아왔습니다. ^^ 이번 스터디는 3주차의 다소 짧은 스터디로 CI/CD에 관련해서 진행됩니다.
즐거운 연말 다시 한번 과제로 달려보겠습니다. :laughing:</p>

<p>이번 주에는 Jenkins와 Git, Docker를 이용하여 CI/CD 파이프라인을 구축해보겠습니다.</p>

<h2 id="jenkins-cicd--docker">Jenkins CI/CD + Docker</h2>

<h3 id="cicd란">CI/CD란?</h3>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_1.png" alt="img.png" class="image-center" />
<em class="image-caption">CI/CD 파이프라인 (출처:<a href="https://blog.devgenius.io/what-is-ci-cd-concept-375cb226cf3d">Dev Genius</a>)</em></p>

<ul>
  <li>CI/CD는 Continuous Integration(지속적 통합)과 Continuous Deployment(지속적 배포)의 약자로 소프트웨어 개발의 계획단계에서 부터 배포/운영까지 전 과정에 걸쳐
자동화된 프로세스를 통해 소프트웨어를 빠르게, 안정적으로 배포할 수 있도록 하는 방법론입니다.</li>
  <li>CI와 CD로 나눠서 살펴보겠습니다.
    <ul>
      <li>CI : 여러 개발자들이 작성한 코드를 하나로 통합하는 코드의 통합을 지속적으로 진행하는 것을 의미합니다.
        <ul>
          <li>CI의 단계 : 계획 -&gt; 코딩 -&gt; 빌드 -&gt; 테스트 -&gt; 패키징</li>
        </ul>
      </li>
      <li>CD : CI를 통해 빌드된 결과물을 배포하고 운영하고, 모니터링을 통해 개선할 점을 파악하는 과정을 지속적으로 진행하는 것을 의미합니다.
        <ul>
          <li>CD의 단계 : 배포 -&gt; 운영 -&gt; 모니터링 -&gt; 피드백</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>CI/CD는 위의 그림과 같이 다양한 툴들로 구성이 되며 이번주에는 Jenkins와 Git, Docker를 이용하여 CI/CD 파이프라인을 구축해보겠습니다.</li>
</ul>

<h3 id="컨테이너를-이용한-어플리케이션-개발">컨테이너를 이용한 어플리케이션 개발</h3>

<p>CI/CD 파이프라인을 구축하기 위해 Docker를 이용하여 어플리케이션을 컨테이너화하겠습니다.</p>

<h4 id="ruby로-특정-문자열-출력하는-간단한-어플리케이션-만들기">ruby로 특정 문자열 출력하는 간단한 어플리케이션 만들기</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nv">$ </span><span class="nb">mkdir </span>1.1 <span class="o">&amp;&amp;</span> <span class="nb">cd </span>1.1
  <span class="nv">$ </span><span class="nb">echo</span> <span class="s1">'puts "Hello Docker!"'</span> <span class="o">&gt;</span> hello.rb
  
  <span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Dockerfile <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
  FROM ruby:3.3
  COPY hello.rb /app/
  WORKDIR /app
  CMD ["ruby", "hello.rb"]
</span><span class="no">  EOF
  
</span>  <span class="c"># 이미지 빌드</span>
  <span class="nv">$ </span>docker build <span class="nt">-t</span> hello <span class="nb">.</span>
  <span class="c"># =&gt; [+] Building 36.6s (9/9) FINISHED</span>
  <span class="nv">$ </span>docker image <span class="nb">ls</span> <span class="nt">-f</span> <span class="nv">reference</span><span class="o">=</span>hello
  <span class="c"># =&gt; REPOSITORY   TAG       IMAGE ID       CREATED          SIZE</span>
  <span class="c">#    hello        latest    d0c55f1ebe18   35 seconds ago   1GB</span>
  
  <span class="c"># 실행</span>
  <span class="nv">$ </span>docker run hello
  <span class="c"># =&gt; Hello Docker!</span>
</code></pre></div></div>

<ul>
  <li>
    <p>코드 수정</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 코드 수정</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"puts 'Hello CloudNet@'"</span> <span class="o">&gt;</span> hello.rb
  
<span class="c"># 컨테이너 이미지 빌드</span>
<span class="nv">$ </span>docker build <span class="nb">.</span> <span class="nt">-t</span> hello:1
<span class="nv">$ </span>docker image <span class="nb">ls</span> <span class="nt">-f</span> <span class="nv">reference</span><span class="o">=</span>hello
<span class="c"># =&gt; REPOSITORY   TAG       IMAGE ID       CREATED         SIZE</span>
<span class="c">#    hello        1         7fe4f428d492   3 seconds ago   1GB</span>
<span class="c">#    hello        latest    d0c55f1ebe18   3 minutes ago   1GB  </span>
<span class="c"># &lt;span style="color: green;"&gt;👉 Latest 태그는 IMAGE ID를 통해 아직 이전의 이미지를 갖고 있는 것을 확인할 수 있습니다.&lt;/span&gt;</span>
  
<span class="c"># 1번 태그에 추가적으로 latest 태그를 붙여보겠습니다.</span>
<span class="nv">$ </span>docker tag hello:1 hello:latest
<span class="nv">$ </span>docker image <span class="nb">ls</span> <span class="nt">-f</span> <span class="nv">reference</span><span class="o">=</span>hello
<span class="c"># =&gt; REPOSITORY   TAG       IMAGE ID       CREATED          SIZE</span>
<span class="c">#    hello        1         7fe4f428d492   36 seconds ago   1GB</span>
<span class="c">#    hello        latest    7fe4f428d492   36 seconds ago   1GB</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 Latest 태그도 동일한 IMAGE ID를 갖게되었습니다.&lt;/span&gt;</span>
  
<span class="c"># 컨테이너 실행</span>
<span class="nv">$ </span>docker run <span class="nt">--rm</span> hello:1
<span class="c"># =&gt; Hello CloudNet@</span>
<span class="nv">$ </span>docker run <span class="nt">--rm</span> hello
<span class="c"># =&gt; Hello CloudNet@</span>
</code></pre></div>    </div>
  </li>
</ul>

<h4 id="compiling-code-in-docker">Compiling code in Docker</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c"># 코드 작성</span>
  <span class="nv">$ </span><span class="nb">mkdir </span>1.2 <span class="o">&amp;&amp;</span> <span class="nb">cd </span>1.2
  
  <span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Hello.java <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
  class Hello {
      public static void main(String[] args) {
          System.out.println("Hello Docker");
      }
  }
</span><span class="no">  EOF
  
</span>  <span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Dockerfile <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
  FROM openjdk
  COPY . /app
  WORKDIR /app
  RUN javac Hello.java    # 컴파일
  CMD java Hello
</span><span class="no">  EOF
  
</span>  <span class="c"># 컨테이너 이미지 빌드</span>
  <span class="nv">$ </span>docker pull openjdk
  <span class="nv">$ </span>docker build <span class="nb">.</span> <span class="nt">-t</span> hello:2 <span class="nt">-t</span> hello:latest
  <span class="c"># =&gt; [+] Building 0.8s (9/9) FINISHED</span>
  <span class="nv">$ </span>docker image <span class="nb">ls</span> <span class="nt">-f</span> <span class="nv">reference</span><span class="o">=</span>hello
  <span class="c"># =&gt; REPOSITORY   TAG       IMAGE ID       CREATED          SIZE</span>
  <span class="c">#    hello        2         ba37ddf45c26   10 seconds ago   487MB</span>
  <span class="c">#    hello        latest    ba37ddf45c26   10 seconds ago   487MB</span>
  <span class="c">#    hello        1         7fe4f428d492   9 minutes ago    1GB</span>
  
  <span class="c"># 컨테이너 실행</span>
  <span class="nv">$ </span>docker run <span class="nt">--rm</span> hello:2
  <span class="c"># =&gt; Hello Docker</span>
  <span class="nv">$ </span>docker run <span class="nt">--rm</span> hello
  <span class="c"># =&gt; Hello Docker</span>
  
  <span class="c"># 컨테이너 이미지 내부에 파일 목록을 보면 어떤가요? 꼭 필요한 파일만 있는가요? 보안적으로 어떨까요?</span>
  <span class="nv">$ </span>docker run <span class="nt">--rm</span> hello <span class="nb">ls</span> <span class="nt">-l</span>
  <span class="c"># =&gt; -rw-r--r-- 1 root root  89 Dec  5 15:04 Dockerfile</span>
  <span class="c">#    -rw-r--r-- 1 root root 416 Dec  5 15:05 Hello.class</span>
  <span class="c">#    -rw-r--r-- 1 root root 111 Dec  5 15:04 Hello.java</span>
  <span class="c"># &lt;span style="color: green;"&gt;👉 꼭 필요한 파일 외에도 Dockerfile, *.java 파일, java 컴파일러 등이 있습니다.&lt;/span&gt;</span>
  <span class="c"># &lt;span style="color: green;"&gt;   이 파일들은 정보 유출이나 공격 대상이 될 수 있기 때문에 컨테이너 이미지에 없어야 합니다.&lt;/span&gt;</span>
  
  <span class="c"># RUN 컴파일 시 소스코드와 java 컴파일러(javac)가 포함되어 있음. 실제 애플리케이션 실행에 필요 없음. </span>
  <span class="nv">$ </span>docker run <span class="nt">--rm</span> hello javac <span class="nt">--help</span>
  <span class="c"># =&gt; Usage: javac &amp;lt;options&amp;gt; &amp;lt;source files&amp;gt;</span>
  <span class="c">#    where possible options include:</span>
  <span class="c">#      @&amp;lt;filename&amp;gt;                  Read options and filenames from file</span>
  <span class="c">#    ...</span>
</code></pre></div></div>

<h4 id="멀티-스테이지-빌드">멀티 스테이지 빌드</h4>
<ul>
  <li>멀티 스테이지 빌드는 빌드를 여러 단계로 나누어서 진행하는 방법입니다.</li>
  <li>각 단계마다 필요한 환경을 구성하여 빌드를 진행하고, 최종적으로 필요한 파일만을 추출하여 불필요한 파일들이 제외된
가볍고 안전한 이미지를 생성할 수 있습니다.
  <img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_2.png" alt="img.png" class="image-center" />
  <em class="image-caption">멀티 스테이지 빌드 동작</em></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c"># 코드 작성</span>
  <span class="nv">$ </span><span class="nb">mkdir </span>1.3 <span class="o">&amp;&amp;</span> <span class="nb">cd </span>1.3
  
  <span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Hello.java <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
  class Hello {
      public static void main(String[] args) {
          System.out.println("Hello Multistage container build");
      }
  }
</span><span class="no">  EOF
  
</span>  <span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Dockerfile <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
  FROM openjdk:11 AS buildstage
  COPY . /app
  WORKDIR /app
  RUN javac Hello.java
  
  FROM openjdk:11-jre-slim
  COPY --from=buildstage /app/Hello.class /app/
  WORKDIR /app
  CMD java Hello
</span><span class="no">  EOF
  
</span>  <span class="c"># 컨테이너 이미지 빌드 : 용량 비교 해보자!</span>
  <span class="nv">$ </span>docker build <span class="nb">.</span> <span class="nt">-t</span> hello:3 <span class="nt">-t</span> hello:latest
  <span class="nv">$ </span>docker image <span class="nb">ls</span> <span class="nt">-f</span> <span class="nv">reference</span><span class="o">=</span>hello
  <span class="c"># =&gt; REPOSITORY   TAG       IMAGE ID       CREATED          SIZE</span>
  <span class="c">#    hello        3         4a058414ac44   11 seconds ago   216MB</span>
  <span class="c">#    hello        latest    4a058414ac44   11 seconds ago   216MB</span>
  <span class="c">#    hello        2         ba37ddf45c26   24 minutes ago   487MB</span>
  <span class="c">#    ...</span>
  <span class="c"># &lt;span style="color: green;"&gt;👉 Compiler가 없는 가벼운 jre 이미지를 사용하여 컨테이너 이미지 크기도 줄어든 것을 확인할 수 있습니다.&lt;/span&gt;</span>
  
  <span class="c"># 컨테이너 실행</span>
  <span class="nv">$ </span>docker run <span class="nt">--rm</span> hello:3
  <span class="c"># =&gt; Hello Multistage container build</span>
  <span class="nv">$ </span>docker run <span class="nt">--rm</span> hello
  <span class="c"># =&gt; Hello Multistage container build</span>
  
  <span class="c"># 컨테이너 이미지 내부에 파일 목록을 보면 어떤가요?</span>
  <span class="nv">$ </span>docker run <span class="nt">--rm</span> hello <span class="nb">ls</span> <span class="nt">-l</span>
  <span class="c"># =&gt; total 4</span>
  <span class="c">#    -rw-r--r-- 1 root root 436 Dec  5 15:26 Hello.class</span>
  <span class="nv">$ </span>docker run <span class="nt">--rm</span> hello javac <span class="nt">--help</span>
  <span class="c"># =&gt; docker: Error response from daemon: OCI runtime create failed: container_linux.go:380: starting container process caused: exec: &amp;quot;javac&amp;quot;: executable file not found in $PATH: unknown.</span>
  <span class="c"># &lt;span style="color: green;"&gt;👉 javac가 없어서 이전보다 안전한것을 알 수 있습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<h4 id="jib로-자바-컨테이너-빌드">Jib로 자바 컨테이너 빌드</h4>
<p><a href="https://cloud.google.com/java/getting-started/jib?hl=ko">문서</a>, 
  <a href="https://colevelup.tistory.com/53">관련 블로그1</a>,
  <a href="https://jh-labs.tistory.com/509">관련 블로그2</a></p>
<ul>
  <li>Jib는 Google에서 만든 오픈소스 도구로, Java 어플리케이션을 컨테이너 이미지로 빌드하는 도구입니다.</li>
  <li>Jib는 docker 없이 컨테이너 이미지를 빌드할 수 있으며, 빌드 속도가 빠르고, 이미지 크기가 작아서 배포가 용이합니다.</li>
  <li>Maven 또는 Gradle 플러그인으로 사용할 수 있습니다.</li>
  <li>기존의 Docker 이미지 빌드 흐름은 다음과 같습니다.
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_3.png" alt="img.png" /></li>
  <li>Jib는 다음과 같이 빌드 흐름이 간소화됩니다.
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_4.png" alt="img.png" />
    <ul>
      <li>빌드와 동시에 이미지가 만들어지고 저장소에 푸시까지 가능합니다.</li>
      <li>Jenkins 등의 CI 서버에 Docker가 없어도 컨테이너 이미지를 빌드할 수 있습니다.</li>
      <li>이미지 레이어 캐싱을 통해 빌드 속도가 빠릅니다.</li>
      <li>이미지 크기가 작아서 배포가 용이합니다.</li>
    </ul>
  </li>
</ul>

<h4 id="어플리케이션-서버-컨테이너화-하기">어플리케이션 서버 컨테이너화 하기</h4>

<ul>
  <li>데모를 위해 HTTP 웹 어플리케이션을 컨테이너화 해보겠습니다.</li>
  <li>다음은 ruby 언어로 작성한 기본적인 웹서버로, 현재 날짜와 시간을 표시합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">mkdir </span>1.4 <span class="o">&amp;&amp;</span> <span class="nb">cd </span>1.4

<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> app.rb <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
require 'sinatra'

get '/' do
  "Hello, World! The time is #{Time.now}"
end
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Dockerfile <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
FROM ruby:3.3
RUN gem install sinatra rackup puma
COPY app.rb /app/
WORKDIR /app
CMD ["ruby", "app.rb", "-o", "0.0.0.0"]
</span><span class="no">EOF

</span><span class="c"># 컨테이너 이미지 빌드</span>

<span class="nv">$ </span>docker build <span class="nb">.</span> <span class="nt">-t</span> timeserver:1 <span class="o">&amp;&amp;</span> docker tag timeserver:1 timeserver:latest
<span class="nv">$ </span>docker image <span class="nb">ls</span> <span class="nt">-f</span> <span class="nv">reference</span><span class="o">=</span>timeserver
<span class="c"># =&gt; REPOSITORY   TAG       IMAGE ID       CREATED          SIZE</span>
<span class="c">#    timeserver   1         6393669e5e68   12 seconds ago   1GB</span>
<span class="c">#    timeserver   latest    6393669e5e68   12 seconds ago   1GB</span>

<span class="c"># 컨테이너 실행</span>
<span class="nv">$ </span>docker run <span class="nt">-d</span> <span class="nt">-p</span> 8080:4567 <span class="nt">--name</span><span class="o">=</span>timeserver timeserver

<span class="c"># 컨테이너 접속 및 로그 확인</span>
<span class="nv">$ </span>curl http://localhost:8080
<span class="c"># =&gt; Hello, World! The time is 2024-10-01 15:28:18 +0000</span>
<span class="nv">$ </span>docker logs timeserver
<span class="c"># =&gt; Puma starting in single mode...</span>
<span class="c">#    * Puma version: 6.5.0 (&amp;quot;Sky's Version&amp;quot;)</span>
<span class="c">#    == Sinatra (v4.1.1) has taken the stage on 4567 for development with backup from Puma</span>
<span class="c">#    * Ruby version: ruby 3.3.6 (2024-10-01 revision 75015d4c1f) [aarch64-linux]</span>
<span class="c">#    *  Min threads: 0</span>
<span class="c">#    *  Max threads: 5</span>
<span class="c">#    *  Environment: development</span>
<span class="c">#    *          PID: 1</span>
<span class="c">#    * Listening on http://0.0.0.0:4567</span>
<span class="c">#    Use Ctrl-C to stop</span>
<span class="c">#    172.17.0.1 - - [01/Oct/2024:15:28:07 +0000] &amp;quot;GET / HTTP/1.1&amp;quot; 200 51 0.0048</span>

<span class="c"># 컨테이너 이미지 내부에 파일 확인</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> timeserver <span class="nb">ls</span> <span class="nt">-l</span>
<span class="c"># =&gt; total 4</span>
<span class="c">#    -rw-r--r-- 1 root root 76 Dec  6 15:20 app.rb</span>
</code></pre></div></div>

<ul>
  <li>도커 컨테이너 내부의 소스코드를 수정해서 반영되는지 확인해보겠습니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_5.png" alt="20241205_cicd_lite_w1_5.png" class="image-center" />
<em class="image-caption">vscode에 docker 확장 설치</em></p>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_6.png" alt="20241205_cicd_lite_w1_6.png" class="image-center" />
<em class="image-caption">timeserver 컨테이너 내부의 app.rb 파일 수정</em></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 컨테이너 이미지 내부에 app.rb 파일 수정 후 반영 확인 : VSCODE 경우 docker 확장프로그램 활용</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> timeserver <span class="nb">cat </span>app.rb
<span class="c"># =&gt; require 'sinatra'</span>
<span class="c">#    </span>
<span class="c">#    get '/' do</span>
<span class="c">#      &amp;quot;Hello, World! 😀 The time is #{Time.now}&amp;quot;</span>
<span class="c">#    end</span>

<span class="c"># 컨테이너 접속 후 확인 </span>
<span class="nv">$ </span>curl http://localhost:8080
<span class="c"># =&gt; Hello, World! The time is 2024-10-01 15:45:09 +0000%</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 수정 사항이 반영되지 않았습니다!&lt;/span&gt;</span>

<span class="c"># 컨테이너 삭제</span>
<span class="nv">$ </span>docker <span class="nb">rm</span> <span class="nt">-f</span> timeserver
</code></pre></div></div>

<ul>
  <li>어플리케이션 수정해서 테스트</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s1">'s#World!#World! 😀 Hello CloudNeta Study!#'</span> app.rb
<span class="nv">$ </span><span class="nb">cat </span>app.rb
<span class="c"># =&gt; require 'sinatra'</span>
<span class="c">#    </span>
<span class="c">#    get '/' do</span>
<span class="c">#      &amp;quot;Hello, World! 😀 Hello CloudNeta Study! The time is #{Time.now}&amp;quot;</span>
<span class="c">#    end</span>

<span class="c"># 컨테이너 이미지 빌드</span>
<span class="nv">$ </span>docker build <span class="nb">.</span> <span class="nt">-t</span> timeserver:2 <span class="nt">-t</span> timeserver:latest
<span class="nv">$ </span>docker image <span class="nb">ls</span> <span class="nt">-f</span> <span class="nv">reference</span><span class="o">=</span>timeserver
<span class="c"># =&gt; REPOSITORY   TAG       IMAGE ID       CREATED          SIZE</span>
<span class="c">#    timeserver   2         80f230757e3c   2 seconds ago    1.01GB</span>
<span class="c">#    timeserver   latest    80f230757e3c   2 seconds ago    1.01GB</span>
<span class="c">#    timeserver   1         c7055ab70155   27 minutes ago   1.01GB</span>

<span class="c"># 컨테이너 실행</span>
<span class="nv">$ </span>docker run <span class="nt">-d</span> <span class="nt">-p</span> 8080:4567 <span class="nt">--name</span><span class="o">=</span>timeserver timeserver
<span class="c"># =&gt; 278108d26b3998c8281add75b631d59a9d44abd4eb3e4f173b0b156d66e5da75</span>

<span class="c"># 컨테이너 접속 및 로그 확인</span>
<span class="nv">$ </span>curl http://localhost:8080
<span class="c"># =&gt; Hello, World! 😀 Hello CloudNeta Study! The time is 2024-10-01 15:55:19 +0000</span>

<span class="c"># 컨테이너 삭제</span>
<span class="nv">$ </span>docker <span class="nb">rm</span> <span class="nt">-f</span> timeserver
</code></pre></div></div>

<h4 id="로컬-개발을-위한-방안">로컬 개발을 위한 방안</h4>

<ul>
  <li>소스를 수정할 때마다 위와 같이 컨테이너 이미지를 빌드하고 실행하는 것은 번거롭습니다.</li>
  <li>이를 편리하게 하기 위해서 로컬 폴더와 컨테이너의 앱 소스를 매핑하고, 코드 내용을 동적으로 반영해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">mkdir </span>1.5 <span class="o">&amp;&amp;</span> <span class="nb">cd </span>1.5

<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> app.rb <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
require 'sinatra/base'

class App &lt; Sinatra::Base
  get '/' do
    "Hello, World! The time is #{Time.now}"
  end
end
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> config.ru <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
require 'rack/unreloader'
require 'sinatra'
Unreloader = Rack::Unreloader.new{App}
Unreloader.require './app.rb'

run Unreloader
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Dockerfile <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
FROM ruby:3.3
RUN gem install sinatra rackup puma </span><span class="se">\</span><span class="sh">
    rack-unreloader # 소스코드 변경시 자동으로 반영하기위한 툴
COPY app.rb config.ru /app/
WORKDIR /app
CMD ["rackup", "--host", "0.0.0.0"]
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> docker-compose.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
services:
  frontend:
    build: .
    command: rackup --host 0.0.0.0
    volumes:
      - type: bind
        source: .
        target: /app
    ports:
      - "8080:9292"
</span><span class="no">EOF

</span><span class="c"># 도커 컴포즈로 컨테이너 빌드</span>
<span class="nv">$ </span>docker compose build 
<span class="c"># 도커 컴포즈로 컨테이너 실행 </span>
<span class="nv">$ </span>docker compose up <span class="nt">-d</span>
<span class="c"># =&gt; [+] Running 1/1</span>
<span class="c">#     ⠿ Container 15-frontend-1  Started 0.4s</span>

<span class="c"># 컴포즈로 실행 시 이미지와 컨테이너 네이밍 규칙을 알아보자!</span>
<span class="nv">$ </span>docker compose ps
<span class="c"># =&gt; NAME                COMMAND                  SERVICE             STATUS              PORTS</span>
<span class="c">#    15-frontend-1       &amp;quot;rackup --host 0.0.0…&amp;quot;   frontend            running             0.0.0.0:8080-&amp;gt;9292/tcp</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 컴포즈로 실행시 현재 디렉터리 이름에서 특수문자를 제외한 것에 컨테이너 이름에 "-1"를 붙이는듯 합니다.&lt;/span&gt;</span>

<span class="nv">$ </span>docker compose images
<span class="c"># =&gt; Container           Repository          Tag                 Image Id            Size</span>
<span class="c">#    15-frontend-1       15_frontend         latest              4aa2b680f319        1.01GB</span>

<span class="c">#</span>
<span class="nv">$ </span>curl http://localhost:8080
<span class="c"># =&gt; Hello, World! The time is 2024-10-01 05:55:18 +0000!!!!!%</span>
<span class="nv">$ </span>docker compose logs
<span class="c"># =&gt; 15-frontend-1  | Puma starting in single mode...</span>
<span class="c">#    15-frontend-1  | * Puma version: 6.5.0 (&amp;quot;Sky's Version&amp;quot;)</span>
<span class="c">#    15-frontend-1  | * Ruby version: ruby 3.3.6 (2024-10-01 revision 75015d4c1f) [aarch64-linux]</span>
<span class="c">#    15-frontend-1  | *  Min threads: 0</span>
<span class="c">#    15-frontend-1  | *  Max threads: 5</span>
<span class="c">#    15-frontend-1  | *  Environment: development</span>
<span class="c">#    15-frontend-1  | *          PID: 1</span>
<span class="c">#    15-frontend-1  | * Listening on http://0.0.0.0:9292</span>
<span class="c">#    15-frontend-1  | Use Ctrl-C to stop</span>
<span class="c">#    15-frontend-1  | 172.23.0.1 - - [01/Oct/2024:03:58:23 +0000] &amp;quot;GET / HTTP/1.1&amp;quot; 200 51 0.0153</span>
</code></pre></div></div>

<ul>
  <li>소스코드 수정 후 반영 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat </span>app.rb
<span class="c"># =&gt; require 'sinatra/base'</span>
<span class="c">#    </span>
<span class="c">#    class App &amp;lt; Sinatra::Base</span>
<span class="c">#      get '/' do</span>
<span class="c">#        &amp;quot;Hello, World! The time is #{Time.now}&amp;quot;</span>
<span class="c">#      end</span>
<span class="c">#    end</span>

<span class="c"># 소스코드 수정</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s1">'s#World!#World! 😀 Hello CloudNeta Study!#'</span> app.rb
<span class="nv">$ </span><span class="nb">cat </span>app.rb
<span class="c"># =&gt; require 'sinatra/base'</span>
<span class="c">#    </span>
<span class="c">#    class App &amp;lt; Sinatra::Base</span>
<span class="c">#      get '/' do</span>
<span class="c">#        &amp;quot;Hello, World! 😀 Hello CloudNeta Study! The time is #{Time.now}!!!!!&amp;quot;</span>
<span class="c">#      end</span>
<span class="c">#    end</span>

<span class="nv">$ </span>curl http://localhost:8080
<span class="c"># =&gt; Hello, World! 😀 Hello CloudNeta Study! The time is 2024-10-01 05:57:05 +0000!!!!!</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 변경사항이 잘 반영되었습니다. :)&lt;/span&gt;</span>

<span class="c"># 컨테이너 중지 및 삭제</span>
<span class="nv">$ </span>docker compose down
</code></pre></div></div>

<h3 id="cicd-실습환경-구성">CI/CD 실습환경 구성</h3>

<ul>
  <li>Jenkins와 Gitlab을 이용하여 CI/CD 파이프라인을 구축해보겠습니다.</li>
  <li>Jenkins는 Docker에 설치해서 사용하고 Gitlab은 <a href="https://www.gitlab.com">gitlab.com</a>를 사용하겠습니다.</li>
</ul>

<h4 id="jenkins-소개">Jenkins 소개</h4>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_7.png" alt="img.png" class="image-center" /></p>
<ul>
  <li>Jenkins는 오픈소스 CI/CD 도구로, 빌드, 테스트, 배포 등의 작업을 자동화할 수 있습니다.</li>
  <li>Jenkins는 CI/CD라는 용어가 있기 전부터 사용되던 도구로, CI/CD에 국한되지 않고 다양한 작업을 자동화할 수 있습니다.</li>
  <li>주요 기능은 다음과 같습니다.
    <ol>
      <li><strong>확장성</strong> : 다양한 플러그인 생태계를 가지고 있어 기능을 확장할 수 있습니다. Git, Docker, Kubernetes 등 다양한 도구 및 플랫폼과 통합할 수 있습니다.</li>
      <li><strong>분산 빌드</strong> : 분산 빌드를 지원하여 여러 머신에서 작업을 실행할 수 있습니다. 이를 통해 부하를 분산시키고 빌드 속도를 높일 수 있습니다.</li>
      <li><strong>자동화된 테스트</strong> : 테스트 실행을 자동화하여 코드 품질에 대한 즉각적인 피드백을 제공합니다. 다양한 테스트 프레임워크 및 도구를 지원합니다.</li>
      <li><strong>코드 파이프라인</strong> : Jenkinsfile을 사용하여 빌드, 테스트, 배포 파이프라인을 코드로 정의할 수 있습니다. 이를 통해 버전 관리와 협업이 용이합니다.</li>
      <li><strong>지속적 통합 및 지속적 배포 (CI/CD)</strong> : 코드 변경 사항을 통합하고, 애플리케이션을 빌드하고, 테스트를 실행하고, 배포하는 과정을 자동화합니다. 이를 통해 일관되고 신뢰할 수 있는 배포 프로세스를 보장합니다.</li>
    </ol>
  </li>
  <li>흔히 사용되는 CI/CD 워크플로우는 다음과 같습니다.
    <ol>
      <li><strong>최신 코드 가져오기</strong> : 개발을 위해 중앙 코드 리포지터리에서 로컬 시스템으로 애플리케이션의 최신 코드를 가져</li>
      <li><strong>단위 테스트 구현과 실행</strong> : 코드 작성 전 단위 테스트 케이스를 먼저 작성</li>
      <li><strong>코드 개발</strong> : 실패한 테스트 케이스를 성공으로 바꾸면서 코드 개발</li>
      <li><strong>단위 테스트 케이스 재실행</strong> : 단위 테스트 케이스 실행 시 통과(성공!)</li>
      <li><strong>코드 푸시와 병합</strong> : 개발 소스 코드를 중앙 리포지터리로 푸시하고, 코드 병합</li>
      <li><strong>코드 병합 후 컴파일</strong> : 변경 함수 코드가 병함되면 전체 애플리케이션이 컴파일된다</li>
      <li><strong>병합된 코드에서 테스트 실행</strong> : 개별 테스트뿐만 아니라 전체 통합 테스트를 실행하여 문제 없는지 확인</li>
      <li><strong>아티팩트 배포</strong> : 애플리케이션을 빌드하고, 애플리케이션 서버의 프로덕션 환경에 배포</li>
      <li><strong>배포 애플리케이션의 E-E 테스트 실행</strong> : 셀레늄 Selenium과 같은 User Interface 자동화 도구를 통해 애플리케이션의 전체 워크플로가 정상 동작하는지 확인하는 종단간 End-to-End 테스트를 실행.</li>
    </ol>
  </li>
  <li>이러한 워크플로우를 코드 커밋/푸시와 같은 이벤트가 발생할 때 자동으로 실행되도록 설정할 수 있습니다.</li>
</ul>

<h5 id="jenkins-컨테이너에서-호스트에-도커-데몬-사용-설정">Jenkins 컨테이너에서 호스트에 도커 데몬 사용 설정</h5>

<ul>
  <li>컨테이너에서 도커를 사용하기 위해서는 DinD(Docker in Docker)를 사용하여 컨테이너 안에서 도커를 실행하거나
DooD(Docker outside of Docker)를 사용하여 호스트의 도커 데몬을 사용할 수 있습니다.</li>
  <li>이번에는 Docker outside of Docker를 사용하여 호스트의 도커 데몬을 사용하겠습니다.
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_8.png" alt="img.png" class="image-center" />
<em class="image-caption">DinD와 DooD 구조 비교</em></li>
</ul>

<h4 id="jenkins-컨테이너-실행-및-설정">Jenkins 컨테이너 실행 및 설정</h4>

<ul>
  <li>먼저 Jenkins 컨테이너를 실행하겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 작업 디렉토리 생성 후 이동</span>
<span class="nv">$ </span><span class="nb">mkdir </span>cicd-labs <span class="o">&amp;&amp;</span> <span class="nb">cd </span>cicd-labs

<span class="c"># </span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh"> &gt; docker-compose.yaml
services:
  jenkins:
    container_name: jenkins
    image: jenkins/jenkins
    restart: unless-stopped
    networks:
      - cicd-network
    ports:
      - "8080:8080"
      - "50000:50000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - jenkins_home:/var/jenkins_home
volumes:
  jenkins_home:
networks:
  cicd-network:
    driver: bridge
</span><span class="no">EOT

</span><span class="c"># 배포</span>
<span class="nv">$ </span>docker compose up <span class="nt">-d</span>
<span class="c"># =&gt; [+] Running 13/13</span>
<span class="c">#     ⠿ jenkins Pulled                                                                                                                                                      13.7s</span>
<span class="c">#    [+] Running 3/3</span>
<span class="c">#     ⠿ Network cicd-labs_cicd-network   Created                                                                                                                             0.0s</span>
<span class="c">#     ⠿ Volume &amp;quot;cicd-labs_jenkins_home&amp;quot;  Created                                                                                                                             0.0s</span>
<span class="c">#     ⠿ Container jenkins                Started</span>
<span class="nv">$ </span>docker compose ps
<span class="c"># =&gt; NAME                COMMAND                  SERVICE             STATUS              PORTS</span>
<span class="c">#    jenkins             &amp;quot;/usr/bin/tini -- /u…&amp;quot;   jenkins             running             0.0.0.0:8080-&amp;gt;8080/tcp, 0.0.0.0:50000-&amp;gt;50000/tcp</span>

<span class="c"># 기본 정보 확인</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>jenkins <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; container : </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker compose <span class="nb">exec</span> <span class="nv">$i</span> sh <span class="nt">-c</span> <span class="s2">"whoami &amp;&amp; pwd"</span><span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; container : jenkins &amp;lt;&amp;lt;</span>
<span class="c">#    jenkins</span>
<span class="c">#    /</span>

<span class="c"># 도커를 이용하여 컨테이너로 접속</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins bash
<span class="nv">$ </span><span class="nb">exit</span>
</code></pre></div></div>

<ul>
  <li>Jenkins 초기 설정을 진행하겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 초기 비밀번호 확인</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins <span class="nb">cat</span> /var/jenkins_home/secrets/initialAdminPassword
<span class="c"># =&gt; dcc757c8c4f14fc09795ed0440baf157</span>

<span class="c"># 브라우저에서 접속하여 초기 비밀번호 입력후 설정 진행 : 계정 / 암호 입력 &gt;&gt; admin / qwe123</span>
<span class="nv">$ </span>open http://localhost:8080
</code></pre></div></div>

<ul>
  <li>jenkins 컨테이너에서 호스트의 도커 데몬을 사용하기 위해 설정을 진행하겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># jenkins 컨테이너에서 호스트의 도커 데몬을 사용하기 위한 설정</span>
<span class="nv">$ </span>docker compose <span class="nb">exec</span> <span class="nt">--privileged</span> <span class="nt">-u</span> root jenkins bash
<span class="nt">-----------------------------------------------------</span>
<span class="nv">$ </span><span class="nb">id</span>
<span class="c"># =&gt; uid=0(root) gid=0(root) groups=0(root)</span>

<span class="nv">$ </span>curl <span class="nt">-fsSL</span> https://download.docker.com/linux/debian/gpg <span class="nt">-o</span> /etc/apt/keyrings/docker.asc
<span class="nv">$ </span><span class="nb">chmod </span>a+r /etc/apt/keyrings/docker.asc
<span class="nv">$ </span><span class="nb">echo</span> <span class="se">\</span>
  <span class="s2">"deb [arch=</span><span class="si">$(</span>dpkg <span class="nt">--print-architecture</span><span class="si">)</span><span class="s2"> signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/debian </span><span class="se">\</span><span class="s2">
  </span><span class="si">$(</span><span class="nb">.</span> /etc/os-release <span class="o">&amp;&amp;</span> <span class="nb">echo</span> <span class="s2">"</span><span class="nv">$VERSION_CODENAME</span><span class="s2">"</span><span class="si">)</span><span class="s2"> stable"</span> | <span class="se">\</span>
  <span class="nb">tee</span> /etc/apt/sources.list.d/docker.list <span class="o">&gt;</span> /dev/null
<span class="nv">$ </span>apt-get update <span class="o">&amp;&amp;</span> apt <span class="nb">install </span>docker-ce-cli curl tree jq <span class="nt">-y</span>

<span class="nv">$ </span>docker info
<span class="c"># =&gt; Client: Docker Engine - Community</span>
<span class="c">#     Version:    27.3.1</span>
<span class="c">#     Context:    default</span>
<span class="c">#     Debug Mode: false</span>
<span class="c">#     Plugins:</span>
<span class="c">#      buildx: Docker Buildx (Docker Inc.)</span>
<span class="c">#        Version:  v0.17.1</span>
<span class="c">#        Path:     /usr/libexec/docker/cli-plugins/docker-buildx</span>
<span class="c">#      compose: Docker Compose (Docker Inc.)</span>
<span class="c">#        Version:  v2.29.7</span>
<span class="c">#        Path:     /usr/libexec/docker/cli-plugins/docker-compose</span>
<span class="c">#    </span>
<span class="c">#    Server:</span>
<span class="c">#     Containers: 27</span>
<span class="c">#      Running: 3</span>
<span class="c">#      Paused: 0</span>
<span class="c">#      Stopped: 24</span>
<span class="c">#     Images: 37</span>
<span class="c">#     Server Version: 20.10.12</span>
<span class="c">#     Storage Driver: overlay2</span>
<span class="c">#      Backing Filesystem: extfs</span>
<span class="c">#      Supports d_type: true</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE                  COMMAND                  CREATED          STATUS          PORTS                                              NAMES</span>
<span class="c">#    06409fe2219f   jenkins/jenkins        &amp;quot;/usr/bin/tini -- /u…&amp;quot;   25 minutes ago   Up 25 minutes   0.0.0.0:8080-&amp;gt;8080/tcp, 0.0.0.0:50000-&amp;gt;50000/tcp   jenkins</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 Docker-out-of-Docker 이기 때문에 호스트 도커 데몬에서 운영되는 컨테이너를 볼 수 있습니다!&lt;/span&gt;</span>
<span class="nv">$ </span>which docker
<span class="c"># =&gt; /usr/bin/docker</span>

<span class="c"># Jenkins 컨테이너 내부에서 root가 아닌 jenkins 유저도 docker를 실행할 수 있도록 권한을 부여</span>
<span class="nv">$ </span>groupadd <span class="nt">-g</span> 2000 <span class="nt">-f</span> docker
<span class="nv">$ </span><span class="nb">chgrp </span>docker /var/run/docker.sock
<span class="nv">$ </span><span class="nb">chmod </span>770 /var/run/docker.sock
<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-l</span> /var/run/docker.sock
<span class="c"># =&gt; srwxr-xr-x 1 root docker 0 Dec  7 03:12 /var/run/docker.sock</span>
<span class="nv">$ </span>usermod <span class="nt">-aG</span> docker jenkins
<span class="nv">$ </span><span class="nb">cat</span> /etc/group | <span class="nb">grep </span>docker
<span class="c"># =&gt; docker:x:2000:jenkins</span>

<span class="nv">$ </span><span class="nb">exit</span>
<span class="nt">--------------------------------------------</span>

<span class="c"># jenkins item 실행 시 docker 명령 실행 권한 에러 발생 : Jenkins 컨테이너 재기동으로 위 설정 내용을 Jenkins app 에도 적용 필요</span>
<span class="nv">$ </span>docker compose restart jenkins
<span class="c"># $ sudo docker compose restart jenkins  # Windows 경우 이후부터 sudo 붙여서 실행</span>

<span class="c"># jenkins user로 docker 명령 실행 확인</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins <span class="nb">id</span>
<span class="c"># =&gt; uid=1000(jenkins) gid=1000(jenkins) groups=1000(jenkins),2000(docker)</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins docker info
<span class="c"># =&gt; Client: Docker Engine - Community</span>
<span class="c">#     Version:    27.3.1</span>
<span class="c">#     Context:    default</span>
<span class="c">#     ...</span>
<span class="c">#    </span>
<span class="c">#    Server:</span>
<span class="c">#     Containers: 27</span>
<span class="c">#      Running: 3</span>
<span class="c">#      Paused: 0</span>
<span class="c">#      Stopped: 24</span>
<span class="c">#     Images: 37</span>
<span class="c">#     Server Version: 20.10.12</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE                  COMMAND                  CREATED          STATUS         PORTS                                              NAMES</span>
<span class="c">#    06409fe2219f   jenkins/jenkins        &amp;quot;/usr/bin/tini -- /u…&amp;quot;   30 minutes ago   Up 2 minutes   0.0.0.0:8080-&amp;gt;8080/tcp, 0.0.0.0:50000-&amp;gt;50000/tcp   jenkins</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<h4 id="gitlab-소개">Gitlab 소개</h4>

<ul>
  <li>Gitlab은 Github와 유사한 Git 기반의 코드 저장소 서비스로, 코드 저장소, 이슈 트래커, CI/CD 파이프라인, 코드 검토 등의 기능을 제공합니다.
<a href="https://www.gitlab.com">Gitlab.com</a></li>
  <li>이번 실습에서는 코드 저장소 기능만 사용하고 Jenkins의 CI/CD 파이프라인을 사용하겠습니다.</li>
  <li>주요 기능
    <ul>
      <li><strong>소스 코드 관리</strong> : GitLab은 Git 기반의 소스 코드 저장소를 제공하여 버전 관리를 쉽게 할 수 있습니다.</li>
      <li><strong>CI/CD 파이프라인</strong> : GitLab은 CI/CD 파이프라인을 통해 코드의 빌드, 테스트, 배포를 자동화할 수 있습니다.</li>
      <li><strong>이슈 트래킹</strong> : 프로젝트의 버그, 기능 요청 등을 관리할 수 있는 이슈 트래킹 시스템을 제공합니다.</li>
      <li><strong>코드 리뷰</strong> : 병합 요청(Merge Request)을 통해 코드 리뷰를 쉽게 진행할 수 있습니다.</li>
      <li><strong>위키</strong> : 프로젝트 관련 문서를 작성하고 관리할 수 있는 위키 기능을 제공합니다.</li>
      <li><strong>프로젝트 관리</strong> : 마일스톤, 보드, 라벨 등을 통해 프로젝트를 체계적으로 관리할 수 있습니다.</li>
      <li><strong>통합 및 확장성</strong> : 다양한 외부 도구와의 통합 및 확장을 지원하여 유연한 개발 환경을 구축할 수 있습니다.</li>
      <li><strong>셀프 호스트 가능</strong> : GitLab은 오픈소스로 제공되어 무료로 자체 서버에 설치하여 사용할 수 있습니다. (일부 기능 차이가 있음)</li>
    </ul>
  </li>
</ul>

<h4 id="gitlab-프로젝트-생성-및-설정">Gitlab 프로젝트 생성 및 설정</h4>

<ul>
  <li>
    <p>Gitlab.com에서 새로운 프로젝트를 생성하겠습니다.
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_9.png" alt="img.png" class="image-center" />
<em class="image-caption">Gitlab 프로젝트 생성</em></p>
  </li>
  <li>
    <p>프로젝트 생성시 프로젝트 이름과 가시성을 설정하고 생성합니다.</p>
    <ul>
      <li><strong>프로젝트 이름</strong> : 2024-cicd-lite-w1</li>
      <li><strong>가시성</strong> : Private</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_10.png" alt="img_1.png" class="image-center" />
<em class="image-caption">Jenkins와 연동을 위해 토큰 발급</em></p>

<ul>
  <li>프로젝트 생성 후 프로젝트 설정에서 CI/CD 파이프라인을 위한 토큰을 발급받습니다.</li>
  <li>프로필 아이콘 클릭 &gt; Preferences &gt; Access Tokens &gt; Add new token을 클릭하여 토큰을 발급받습니다.
    <ul>
      <li><strong>토큰 이름</strong> : jenkins</li>
      <li><strong>권한</strong> : read_repository, write_repository</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_11.png" alt="img_2.png" class="image-center" />
<em class="image-caption">토큰 발급 완료</em></p>

<ul>
  <li>토큰이 완료되면 복사할 수 있습니다. 이후에는 다시 확인할 수 없으므로 잘 기록해두어야 합니다.</li>
</ul>

<h5 id="gitlab에서-소스-받기">Gitlab에서 소스 받기</h5>

<ul>
  <li>소스를 받기 위해 git 주소를 복사합니다.
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_12.png" alt="img.png" class="image-center" />
<em class="image-caption">Gitlab 프로젝트 주소 복사</em></li>
  <li>프로젝트 페이지에 접속 후 Code 버튼을 클릭하고 클립보드 아이콘을 클릭하여 주소를 복사할 수 있습니다.</li>
  <li>복사한 주소로 소스를 받아서 필요한 파일들을 생성해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># &lt;span style="color: green;"&gt;👉 아이디와 비밀번호를 물으면 토큰이름과 발급받은 토큰을 입력하시면 됩니다.&lt;/span&gt;</span>
<span class="nv">$ </span>git clone https://gitlab.com/littlebird/2024-cicd-lite-w1.git
<span class="c"># =&gt; Cloning into '2024-cicd-lite-w1'...</span>
<span class="c">#    Username for 'https://gitlab.com': jenkins</span>
<span class="c">#    Password for 'https://jenkins@gitlab.com': glpat-ABCD1234</span>
<span class="c">#    remote: Enumerating objects: 3, done.</span>
<span class="c">#    remote: Counting objects: 100% (3/3), done.</span>
<span class="c">#    remote: Compressing objects: 100% (2/2), done.</span>
<span class="c">#    remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)</span>
<span class="c">#    Receiving objects: 100% (3/3), done.</span>
<span class="nv">$ </span><span class="nb">cd </span>2024-cicd-lite-w1/

<span class="c"># 소스코드 작성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> app.rb <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
require 'sinatra'

get '/' do
  "Hello, World! The time is #{Time.now}"
end
</span><span class="no">EOF

</span><span class="c"># Dockerfile 작성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Dockerfile <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
FROM ruby:3.3
RUN gem install sinatra rackup puma
COPY app.rb /app/
WORKDIR /app
CMD ["ruby", "app.rb", "-o", "0.0.0.0"]
</span><span class="no">EOF

</span><span class="c"># VERSION 파일 생성</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"0.0.1"</span> <span class="o">&gt;</span> VERSION

<span class="c">#</span>
<span class="nv">$ </span>git add <span class="nb">.</span>
<span class="nv">$ </span>git commit <span class="nt">-m</span> <span class="s2">"Initial commit"</span>
<span class="c"># =&gt; [main 569ce3c] Initial commit</span>
<span class="c">#     3 files changed, 11 insertions(+)</span>
<span class="c">#     create mode 100644 Dockerfile</span>
<span class="c">#     create mode 100644 VERSION</span>
<span class="c">#     create mode 100644 app.rb</span>
<span class="nv">$ </span>git push <span class="nt">-u</span> origin main
<span class="c"># =&gt; Enumerating objects: 6, done.</span>
<span class="c">#    Counting objects: 100% (6/6), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (4/4), done.</span>
<span class="c">#    Writing objects: 100% (5/5), 536 bytes | 536.00 KiB/s, done.</span>
<span class="c">#    Total 5 (delta 0), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To https://gitlab.com/littlebird/2024-cicd-lite-w1.git</span>
<span class="c">#       fe2fb73..569ce3c  main -&amp;gt; main</span>
<span class="c">#    branch 'main' set up to track 'origin/main'.</span>
</code></pre></div></div>

<ul>
  <li>Gitlab 리파지토리에서 확인해보겠습니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_13.png" alt="img.png" /></p>

<ul>
  <li>Gitlab 프로젝트에 소스가 정상적으로 업로드 되었습니다.</li>
</ul>

<h4 id="docker-hub-소개">Docker Hub 소개</h4>

<ul>
  <li><a href="https://hub.docker.com">도커허브(Docker Hub)</a>는 도커 이미지를 저장하고 공유할 수 있는 클라우드 서비스입니다.</li>
  <li>여러 사용자가 자신이 만든 도커 이미지를 서로 자유롭게 공유할 수 있습니다.</li>
  <li>유의 사항
    <ul>
      <li>Docker Hub는 무료로 누구나 업로드 할 수 있기 때문에, 공식(Official) 라벨이 없는 이미지는 보안에 취약할 수 있고, 사용법을 알 수 없거나, 제대로 작동하지 않을 수 있습니다.</li>
      <li>도커 악성 이미지를 통한 취약점 공격 기사 모음
        <ul>
          <li>도커도 이제 공격 통로! 악성 이미지 늘어나고 있다 - <a href="https://www.boannews.com/media/view.asp?idx=93080&amp;page=1&amp;kind=1">링크</a></li>
          <li>도커 환경 공격하는 해커들, 전략을 또 변경했다 - <a href="https://www.boannews.com/media/view.asp?idx=89841&amp;page=1&amp;kind=1">링크</a></li>
          <li>암호화폐 채굴 공격자들, 잘못 설정된 도커 집중 공략 - <a href="https://www.boannews.com/media/view.asp?idx=87427&amp;page=1&amp;kind=1">링크</a></li>
          <li>리눅스 노리던 봇넷 멀웨어 둘, 최근 들어 도커 서버도 노리기 시작 - <a href="https://www.boannews.com/media/view.asp?idx=89205&amp;page=1&amp;kind=1">링크</a></li>
          <li>도커 호스트 감염시켜가며 암호화폐 채굴하는 웜 발견 - <a href="https://www.boannews.com/media/view.asp?idx=83854&amp;page=1&amp;kind=1">링크</a>  *</li>
        </ul>
      </li>
      <li>사용자당 1개의 Private Repository만 무료로 사용할 수 있습니다.</li>
    </ul>
  </li>
  <li>주요 기능
    <ul>
      <li><strong>도커 이미지 저장소</strong> : 도커 이미지를 저장하고 공유할 수 있습니다.</li>
      <li><strong>자동 빌드</strong> : Github, Gitlab과 연동하여 코드가 업데이트 될 때마다 자동으로 이미지를 빌드할 수 있습니다.</li>
      <li><strong>웹훅</strong> : 타 서비스와 연동하여 이벤트가 발생할 때마다 특정 URL로 요청을 보낼 수 있습니다.</li>
      <li><strong>Docker Hub CLI 도구</strong> : 도커 이미지를 커맨드라인으로 관리할 수 있는 도구를 제공합니다.</li>
    </ul>
  </li>
</ul>

<h4 id="docker-hub에-dev-app-private-repo-생성">Docker Hub에 dev-app (private) repo 생성</h4>

<ul>
  <li>Docker Hub에 dev-app이라는 private 리포지토리를 생성하겠습니다.</li>
  <li>Docker Hub에 로그인 후 Repositories &gt; Create Repository를 클릭하여 리포지토리를 생성합니다.
    <ul>
      <li><strong>Repository Name</strong> : dev-app</li>
      <li><strong>Visibility</strong> : Private</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_14.png" alt="img.png" /></p>

<h3 id="jenkins-기본-사용">Jenkins 기본 사용</h3>

<ul>
  <li>Jenkins를 사용하여 CI/CD 파이프라인을 구축해보겠습니다.</li>
  <li>작업 소개
    <ol>
      <li><strong>Trigger</strong> : 작업을 수행하는 시점을 지정합니다.
        <ul>
          <li>작업 수행 태스크 task가 언제 시작될지를 지시할 수 있습니다.</li>
        </ul>
      </li>
      <li><strong>Built step</strong> : 작업을 구성하는 단계별 태스크를 지정합니다.
        <ul>
          <li>특정 목표를 수행하기 위한 태스크를 단계별 step로 구성할 수 있습니다.</li>
          <li>이것을 젠킨스에서는 빌드 스텝 build step이라고 부릅니다.</li>
        </ul>
      </li>
      <li><strong>Post-build action</strong> : 태스크가 완료 후 수행할 명령을 지정합니다.
        <ul>
          <li>예를 들어 작업의 결과(성공 or 실패)를 사용자에게 알려주는 후속 동작이나, 자바 코드를 컴파일한 후 생성된 클래스 파일을 특정 위치로 복사 등의 작업을 수행할 수 있습니다.
     - (참고) 젠킨스의 <strong>빌드</strong> : 젠킨스 작업의 특정 실행 버전
       - 사용자는 젠킨스 작업을 여러번 실행할 수 있는데, 실행될 때마다 <strong>고유 빌드 번호</strong>가 부여됩니다.
       - 작업 실행 중에 생성된 <strong>아티팩트</strong>, <strong>콘솔 로드</strong> 등 특정 실행 버전과 관련된 모든 세부 정보가 해당 빌드 번호로 저장됩니다.</li>
        </ul>
      </li>
    </ol>
  </li>
  <li>첫번째 작업 생성
    <ul>
      <li>name : first</li>
      <li>item type : freestyle project</li>
      <li>Build Steps : Execute shell
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">echo</span> <span class="s2">"docker check"</span> | <span class="nb">tee </span>test.txt
docker ps
</code></pre></div>        </div>
        <p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_15.png" alt="img.png" class="image-center" />
<em class="image-caption">Jenkins 첫번째 작업 생성</em></p>
      </li>
    </ul>
  </li>
  <li>
    <p>“Build Now”(지금 실행) 메뉴를 클릭하여 작업을 실행합니다.
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_16.png" alt="img.png" class="image-center" />
<em class="image-caption">빌드 결과 (Console Output)</em></p>
  </li>
  <li>작업 공간 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins <span class="nb">ls</span> /var/jenkins_home/workspace
<span class="c"># =&gt; first</span>

<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins <span class="nb">ls</span> /var/jenkins_home/workspace/first
<span class="c"># =&gt; test.txt</span>

<span class="c"># 작업 결과 확인</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins <span class="nb">cat</span> /var/jenkins_home/workspace/first/test.txt
<span class="c"># =&gt; docker check</span>
</code></pre></div></div>

<h4 id="jenkins-플러그인-설치">Jenkins 플러그인 설치</h4>

<ul>
  <li>Jenkins 플러그인을 설치하여 더 다양한 기능을 사용할 수 있습니다.</li>
  <li>Dashboard &gt; Manage Jenkins 메뉴를 클릭하고, 플러그인 관리를 클릭합니다.</li>
  <li>Available plugins 를 클릭하여 다양한 플러그인을 설치할 수 있습니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_17.png" alt="img.png" class="image-center" />
<em class="image-caption">Jenkins 플러그인 설치 화면</em></p>

<ul>
  <li>다음의 plugin 을 설치합니다.
    <ul>
      <li><strong>Pipeline Stage View</strong> : 파이프라인 스테이지를 시각적으로 보여주는 플러그인 <a href="https://plugins.jenkins.io/pipeline-stage-view/">링크</a></li>
      <li><strong>Docker Pipeline</strong> : 파이프라인에서 도커를 사용할 수 있도록 지원하는 플러그인 <a href="https://plugins.jenkins.io/docker-workflow/">링크</a></li>
      <li><strong>Gitlab</strong> : Gitlab과 Jenkins를 연동할 수 있도록 지원하는 플러그인 <a href="https://plugins.jenkins.io/gitlab-plugin/">링크</a></li>
    </ul>
  </li>
  <li>Dashboard &gt; Manage Jenkins &gt; Credentials &gt; System &gt; Global credentials (unrestricted) &gt; Add Credentials 를 클릭하여 자격증명을 추가합니다.
    <ul>
      <li>Docker hub 크레덴셜
        <ul>
          <li>Kind : Username with password</li>
          <li>Username : <code class="language-plaintext highlighter-rouge">&lt;docker hub 계정&gt;</code></li>
          <li>Password : <code class="language-plaintext highlighter-rouge">&lt;docker hub 비밀번호 혹은 토큰&gt;</code></li>
          <li>ID : <code class="language-plaintext highlighter-rouge">dockerhub-credentials</code> =&gt; 자격증명 이름으로 pipeline에서 사용됩니다.</li>
        </ul>
      </li>
      <li>Gitlab 저장소 크레덴셜
        <ul>
          <li>Kind : Username with password</li>
          <li>Username : <code class="language-plaintext highlighter-rouge">&lt;gitlab 토큰 이름&gt;</code></li>
          <li>Password : <code class="language-plaintext highlighter-rouge">&lt;gitlab 토큰&gt;</code></li>
          <li>ID : <code class="language-plaintext highlighter-rouge">gitlab-credentials</code> =&gt; 자격증명 이름으로 pipeline에서 사용됩니다.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="파이프라인">파이프라인</h4>

<ul>
  <li>pipeline은 CI/CD 파이프라인을 코드로 정의하는 플러그인 스크립트입니다. <a href="https://www.jenkins.io/doc/book/pipeline/">docs</a></li>
</ul>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_18.png" alt="img.png" /></p>

<ul>
  <li>파이프라인의 <strong>장점</strong>
    <ul>
      <li><strong>코드</strong> : 애플리케이션 CI/CD 프로세스를 코드 형식으로 작성할 수 있고, 해당 코드를 중앙 리포지터리에 저장하여 팀원과 공유 및 작업 가능합니다.</li>
      <li><strong>내구성</strong> : 젠킨스 서비스가 의도적으로 또는 우발적으로 재시작되더라도 문제없이 유지됩니다.</li>
      <li><strong>일시 중지 가능</strong> : 파이프라인을 실행하는 도중 사람의 승인이나 입력을 기다리기 위해 중단하거나 기다리는 것이 가능합니다.</li>
      <li><strong>다양성</strong> : 분기나 반복, 병렬 처리와 같은 다양한 CI/CD 요구 사항을 지원합니다.</li>
    </ul>
  </li>
  <li>파이프라인 용어
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_19.png" alt="img.png" class="image-center" />
    <ul>
      <li><strong>Pipeline(파이프라인)</strong> : 전체 빌드 프로세스를 정의하는 코드</li>
      <li><strong>Node(노드) = Agent</strong> : 파이프라인을 실행하는 시스템</li>
      <li><strong>Stages</strong> : 순차 작업 명세인 stage 들의 묶음</li>
      <li><strong>Stage</strong> : 특정 단계에서 수행되는 작업들의 정의</li>
      <li><strong>Steps</strong> : 파이프라인의 특정 단계에서 수행되는 단일 작업을 의미.</li>
      <li><strong>Post</strong> : 빌드 후 조치, 일반적으로 stages 작업이 끝난 후 추가적인 steps/step</li>
      <li><strong>Directive</strong> - <a href="https://www.jenkins.io/doc/book/pipeline/syntax/#declarative-directives">Docs</a>
        <ul>
          <li><strong>Environment</strong> (key=value) : 파이프라인 내부에서 사용할 환경변수</li>
          <li><strong>Parameters</strong> : 입력 받아야할 변수를 정의 - Type(string, text, choice, password …)</li>
          <li><strong>Triggers</strong> : 파이프라인을 실행하는 조건 설정</li>
          <li><strong>Input</strong> : 파이프라인 실행 중 사용자 입력을 받을 수 있도록 설정</li>
          <li><strong>When</strong> : stage 를 실행 할 조건 설정</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>파이프라인 구성 형태 3가지
    <ol>
      <li><strong>Pipeline Script</strong> : 일반적인 방식으로 Jenkins 파이프라인을 생성하여 Shell Script 형태로 작성 <a href="https://www.jenkins.io/doc/book/pipeline/getting-started/#through-the-classic-ui">링크</a></li>
      <li><strong>Pipeline Script from SCM</strong> : Jenkinsfile을 git 등의 SCM(Source Code Management)에 저장하고, 빌드 시작 시 해당 파일을 읽어 파이프라인을 실행 <a href="https://www.jenkins.io/doc/book/pipeline/getting-started/#defining-a-pipeline-in-scm">링크</a></li>
      <li><strong>Blue Ocean 기반</strong> : Blue Ocean 플러그인을 설치하여 UI로 파이프라인을 구성하면 Jenkinsfile이 자동으로 생성됨 <a href="https://www.jenkins.io/doc/book/pipeline/getting-started/#through-blue-ocean">링크</a></li>
    </ol>
  </li>
  <li>파이프라인 구문 형태 2가지
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_20.png" alt="img.png" class="image-center w-80" />
<em class="image-caption">파이프라인 구문 형태별 구조</em>
    <ol>
      <li><strong>Declarative Pipeline</strong> : 간결하고 가독성이 좋으며, 최근 문법이고, 권장하는 방법. step은 필수로 사용
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pipeline <span class="o">{</span>
   agent any     <span class="c"># Execute this Pipeline or any of its stages, on any available agent.</span>
   stages <span class="o">{</span>
     stage<span class="o">(</span><span class="s1">'Build'</span><span class="o">)</span> <span class="o">{</span>   <span class="c"># Defines the "Build" stage.</span>
         steps <span class="o">{</span>
             //         <span class="c"># Perform some steps related to the "Build" stage.</span>
         <span class="o">}</span>
     <span class="o">}</span>
     stage<span class="o">(</span><span class="s1">'Test'</span><span class="o">)</span> <span class="o">{</span> 
         steps <span class="o">{</span>
             // 
         <span class="o">}</span>
     <span class="o">}</span>
     stage<span class="o">(</span><span class="s1">'Deploy'</span><span class="o">)</span> <span class="o">{</span> 
         steps <span class="o">{</span>
             // 
         <span class="o">}</span>
     <span class="o">}</span>
   <span class="o">}</span>
<span class="o">}</span>
</code></pre></div>        </div>
      </li>
      <li><strong>Scripted Pipeline</strong> : 커스텀이 용이하나 복잡도가 높고, step은 필수가 아님
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>node <span class="o">{</span>             <span class="c"># Execute this Pipeline or any of its stages, on any available agent.</span>
  stage<span class="o">(</span><span class="s1">'Build'</span><span class="o">)</span> <span class="o">{</span> <span class="c"># Defines the "Build" stage. stage blocks are optional in Scripted Pipeline syntax. However, implementing stage blocks in a Scripted Pipeline provides clearer visualization of each stage's subset of tasks/steps in the Jenkins UI.</span>
   //              <span class="c"># Perform some steps related to the "Build" stage.</span>
  <span class="o">}</span>
  stage<span class="o">(</span><span class="s1">'Test'</span><span class="o">)</span> <span class="o">{</span> 
   // 
  <span class="o">}</span>
  stage<span class="o">(</span><span class="s1">'Deploy'</span><span class="o">)</span> <span class="o">{</span> 
   // 
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div>        </div>
      </li>
    </ol>
  </li>
</ul>

<h5 id="jenkins-pipeline-실습">Jenkins Pipeline 실습</h5>

<ul>
  <li>New Item &gt; Pipeline 으로 파이프라인을 생성합니다.
    <ul>
      <li><strong>Name</strong> : First-Pipeline</li>
      <li><strong>Definition</strong> : Pipeline script</li>
      <li><strong>Script</strong> : 아래의 파이프라인 스크립트를 입력합니다.</li>
    </ul>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pipeline <span class="o">{</span>
    agent any

    stages <span class="o">{</span>
        stage<span class="o">(</span><span class="s1">'Hello'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                <span class="nb">echo</span> <span class="s1">'Hello World'</span>
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'Deploy'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                <span class="nb">echo</span> <span class="s2">"Deployed successfully!"</span><span class="p">;</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<ul>
  <li>
    <p>Save 하여 저장후 “Build Now”를 클릭하여 파이프라인을 실행합니다.
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_21.png" alt="img.png" class="image-center" />
<em class="image-caption">파이프라인 실행 결과</em></p>
  </li>
  <li>
    <p>아래 처럼 수정 후 확인: 환경변수 사용, 문자열 보간 → Console Output 확인</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pipeline <span class="o">{</span>
    agent any
    environment <span class="o">{</span> 
        CC <span class="o">=</span> <span class="s1">'clang'</span>
    <span class="o">}</span>
      
    stages <span class="o">{</span>
        stage<span class="o">(</span><span class="s1">'Example'</span><span class="o">)</span> <span class="o">{</span>
            environment <span class="o">{</span> 
                AN_ACCESS_KEY <span class="o">=</span> <span class="s1">'abcdefg'</span>
            <span class="o">}</span>
            steps <span class="o">{</span>
                <span class="nb">echo</span> <span class="s2">"</span><span class="k">${</span><span class="nv">CC</span><span class="k">}</span><span class="s2">"</span><span class="p">;</span>
                sh <span class="s1">'echo ${AN_ACCESS_KEY}'</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div>    </div>

    <p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_22.png" alt="img.png" class="image-center" />
<em class="image-caption">Console Output</em></p>
  </li>
  <li>
    <p>아래 처럼 수정 후 확인: 파이프라인 빌드 시작(트리거) → Console Output 확인</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pipeline <span class="o">{</span>
    agent any
    triggers <span class="o">{</span>
        cron<span class="o">(</span><span class="s1">'H */4 * * 1-5'</span><span class="o">)</span>
    <span class="o">}</span>
    stages <span class="o">{</span>
        stage<span class="o">(</span><span class="s1">'Example'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                <span class="nb">echo</span> <span class="s1">'Hello World'</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div>    </div>

    <p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_23.png" alt="img.png" class="image-center" />
<em class="image-caption">Console Output</em></p>
  </li>
  <li>
    <p>아래 처럼 수정 후 확인: 파라미터와 함께 빌드 → Console Output 확인 ⇒ 다시 한번 더 빌드 클릭 (변수 입력 칸 확인)</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pipeline <span class="o">{</span>
    agent any
    parameters <span class="o">{</span>
        string<span class="o">(</span>name: <span class="s1">'PERSON'</span>, defaultValue: <span class="s1">'Mr Jenkins'</span>, description: <span class="s1">'Who should I say hello to?'</span><span class="o">)</span>
        text<span class="o">(</span>name: <span class="s1">'BIOGRAPHY'</span>, defaultValue: <span class="s1">''</span>, description: <span class="s1">'Enter some information about the person'</span><span class="o">)</span>
        booleanParam<span class="o">(</span>name: <span class="s1">'TOGGLE'</span>, defaultValue: <span class="nb">true</span>, description: <span class="s1">'Toggle this value'</span><span class="o">)</span>
        choice<span class="o">(</span>name: <span class="s1">'CHOICE'</span>, choices: <span class="o">[</span><span class="s1">'One'</span>, <span class="s1">'Two'</span>, <span class="s1">'Three'</span><span class="o">]</span>, description: <span class="s1">'Pick something'</span><span class="o">)</span>
        password<span class="o">(</span>name: <span class="s1">'PASSWORD'</span>, defaultValue: <span class="s1">'SECRET'</span>, description: <span class="s1">'Enter a password'</span><span class="o">)</span>
    <span class="o">}</span>
    stages <span class="o">{</span>
        stage<span class="o">(</span><span class="s1">'Example'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                <span class="nb">echo</span> <span class="s2">"Hello </span><span class="k">${</span><span class="nv">params</span><span class="p">.PERSON</span><span class="k">}</span><span class="s2">"</span>
                <span class="nb">echo</span> <span class="s2">"Biography: </span><span class="k">${</span><span class="nv">params</span><span class="p">.BIOGRAPHY</span><span class="k">}</span><span class="s2">"</span>
                <span class="nb">echo</span> <span class="s2">"Toggle: </span><span class="k">${</span><span class="nv">params</span><span class="p">.TOGGLE</span><span class="k">}</span><span class="s2">"</span>
                <span class="nb">echo</span> <span class="s2">"Choice: </span><span class="k">${</span><span class="nv">params</span><span class="p">.CHOICE</span><span class="k">}</span><span class="s2">"</span>
                <span class="nb">echo</span> <span class="s2">"Password: </span><span class="k">${</span><span class="nv">params</span><span class="p">.PASSWORD</span><span class="k">}</span><span class="s2">"</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>파이프라인 스크립트를 수정하고 저장 후 “Build with Parameters”를 클릭하여 파라미터를 입력하고 빌드를 실행하면
아래와 같이 지정된 파라미터로 빌드를 실행할 수 있습니다.</p>
  </li>
</ul>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_24.png" alt="img.png" class="image-center" />
<em class="image-caption">Build with Parameters 화면</em></p>

<ul>
  <li>
    <p>아래처럼 post (빌드 후 조치) 블록을 추가하여 빌드 후 조치를 설정할 수 있습니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pipeline <span class="o">{</span>
    agent any
    stages <span class="o">{</span>
        stage<span class="o">(</span><span class="s1">'Compile'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                <span class="nb">echo</span> <span class="s2">"Compiled successfully!"</span><span class="p">;</span>
            <span class="o">}</span>
        <span class="o">}</span>
  
        stage<span class="o">(</span><span class="s1">'JUnit'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                <span class="nb">echo</span> <span class="s2">"JUnit passed successfully!"</span><span class="p">;</span>
            <span class="o">}</span>
        <span class="o">}</span>
  
        stage<span class="o">(</span><span class="s1">'Code Analysis'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                <span class="nb">echo</span> <span class="s2">"Code Analysis completed successfully!"</span><span class="p">;</span>
            <span class="o">}</span>
        <span class="o">}</span>
  
        stage<span class="o">(</span><span class="s1">'Deploy'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                <span class="nb">echo</span> <span class="s2">"Deployed successfully!"</span><span class="p">;</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
    post <span class="o">{</span> 
        always <span class="o">{</span> 
            <span class="nb">echo</span> <span class="s1">'I will always say Hello again!'</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div>    </div>

    <p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_25.png" alt="img.png" class="image-center w-80" />
<em class="image-caption">step 별 메시지와 post 메시지</em></p>

    <ul>
      <li>post에는 always 외에도 다음과 같은 옵션을 사용할 수 있습니다.
        <ul>
          <li><strong>always</strong> : 항상 실행</li>
          <li><strong>changed</strong> : 성공 또는 실패가 변경되었을 때 실행</li>
          <li><strong>success</strong> : 성공했을 때 실행</li>
          <li><strong>failure</strong> : 실패했을 때 실행</li>
          <li><strong>unstable</strong> : 불안정한 상태일 때 실행</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>Pipeline Syntax -&gt; Snippet Generator 를 사용하여 파이프라인 스크립트를 생성할 수 있습니다.
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_26.png" alt="img.png" class="image-center w-80" /></p>
  </li>
</ul>

<h5 id="gitlab과-jenkins-pipeline-연동-실습">Gitlab과 Jenkins pipeline 연동 실습</h5>

<ul>
  <li>Gitlab에서 소스를 받아 빌드 후 Docker Hub에 이미지를 업로드하는 파이프라인을 구성해보겠습니다.</li>
  <li>Pipeline script</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pipeline <span class="o">{</span>
    agent any
    environment <span class="o">{</span>
        DOCKER_IMAGE <span class="o">=</span> <span class="s1">'sweetlittlebird/dev-app'</span> // Docker 이미지 이름
    <span class="o">}</span>
    stages <span class="o">{</span>
        stage<span class="o">(</span><span class="s1">'Checkout'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                 git branch: <span class="s1">'main'</span>,
                 url: <span class="s1">'https://gitlab.com/littlebird/2024-cicd-lite-w1.git'</span>,  // Git에서 코드 체크아웃
                 credentialsId: <span class="s1">'gitlab-credentials'</span>  // Credentials ID
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'Read VERSION'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                script <span class="o">{</span>
                    // VERSION 파일 읽기
                    def version <span class="o">=</span> readFile<span class="o">(</span><span class="s1">'VERSION'</span><span class="o">)</span>.trim<span class="o">()</span>
                    <span class="nb">echo</span> <span class="s2">"Version found: </span><span class="k">${</span><span class="nv">version</span><span class="k">}</span><span class="s2">"</span>
                    // 환경 변수 설정
                    env.DOCKER_TAG <span class="o">=</span> version
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'Docker Build and Push'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                script <span class="o">{</span>
                    docker.withRegistry<span class="o">(</span><span class="s1">'https://index.docker.io/v1/'</span>, <span class="s1">'dockerhub-credentials'</span><span class="o">)</span> <span class="o">{</span>
                        // DOCKER_TAG 사용
                        def appImage <span class="o">=</span> docker.build<span class="o">(</span><span class="s2">"</span><span class="k">${</span><span class="nv">DOCKER_IMAGE</span><span class="k">}</span><span class="s2">:</span><span class="k">${</span><span class="nv">DOCKER_TAG</span><span class="k">}</span><span class="s2">"</span><span class="o">)</span>
                        appImage.push<span class="o">()</span>
                    <span class="o">}</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
    post <span class="o">{</span>
        success <span class="o">{</span>
            <span class="nb">echo</span> <span class="s2">"Docker image </span><span class="k">${</span><span class="nv">DOCKER_IMAGE</span><span class="k">}</span><span class="s2">:</span><span class="k">${</span><span class="nv">DOCKER_TAG</span><span class="k">}</span><span class="s2"> has been built and pushed successfully!"</span>
        <span class="o">}</span>
        failure <span class="o">{</span>
            <span class="nb">echo</span> <span class="s2">"Pipeline failed. Please check the logs."</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<ul>
  <li>
    <p>Build Now -&gt; Console Output 확인</p>

    <p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_27.png" alt="img.png" class="image-center w-80" /></p>
  </li>
  <li>
    <p>Docker Hub에서 이미지 확인</p>

    <p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_28.png" alt="img.png" class="image-center" /></p>
  </li>
</ul>

<h4 id="도커-기반-어플리케이션의-cicd-구성">도커 기반 어플리케이션의 CI/CD 구성</h4>

<ul>
  <li>Jenkins와 Gitlab을 사용하여 다음 그림과 같은 형태의 도커 기반 어플리케이션의 CI/CD 파이프라인을 구성해보겠습니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_29.png" alt="img.png" class="image-center w-80" />
<em class="image-caption">목표 CI/CD 파이프라인</em></p>

<h5 id="gitlab에서-jenkins-연동-설정">Gitlab에서 Jenkins 연동 설정</h5>

<ul>
  <li>gitlab 프로젝트 페이지 &gt; Settings &gt; Integrations &gt; Jenkins 연결후 아래의 정보를 입력 합니다.
    <ul>
      <li><strong>Enable integration</strong> : Active 체크</li>
      <li><strong>Trigger</strong> : Push, Merge request 체크</li>
      <li><strong>URL</strong> : <code class="language-plaintext highlighter-rouge">http://&lt;Jenkins접속주소&gt;:&lt;Jenkins포트&gt;</code></li>
      <li><strong>Project name</strong> : <code class="language-plaintext highlighter-rouge">SCM-Pipeline</code> (Jenkins 프로젝트 이름)</li>
      <li><strong>Username</strong> : <code class="language-plaintext highlighter-rouge">&lt;Jenkins 아이디&gt;</code></li>
      <li><strong>Password</strong> : <code class="language-plaintext highlighter-rouge">&lt;Jenkins 비밀번호&gt;</code></li>
    </ul>

    <p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_30.png" alt="img.png" class="image-center" /></p>
  </li>
</ul>

<h5 id="jenkins에서-gitlab-연동-설정">Jenkins에서 Gitlab 연동 설정</h5>

<ul>
  <li>Jenkins Item 생성
    <ul>
      <li>Dashboard &gt; New Item &gt; Pipeline (item name : <code class="language-plaintext highlighter-rouge">SCM-Pipeline</code>)</li>
    </ul>
  </li>
  <li>Build Triggers 설정
    <ul>
      <li>Configuration &gt; Build Triggers
        <ul>
          <li><strong>Build when a change is pushed to GitLab</strong> 체크</li>
          <li><strong>Push Events</strong> 체크</li>
          <li><strong>Accepted Merge Request Events</strong> 체크
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_31.png" alt="img.png" /></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>Jenkins 파일 생성 후 push</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Jenkinsfile <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
pipeline {
    agent any
    environment {
        DOCKER_IMAGE = 'sweetlittlebird/dev-app' // Docker 이미지 이름
    }
    stages {
        stage('Checkout') {
            steps {
                 git branch: 'main',
                 url: 'https://gitlab.com/littlebird/2024-cicd-lite-w1.git',  // Git에서 코드 체크아웃
                 credentialsId: 'gitlab-credentials'  // Credentials ID
            }
        }
        stage('Read VERSION') {
            steps {
                script {
                    // VERSION 파일 읽기
                    def version = readFile('VERSION').trim()
                    echo "Version found: </span><span class="se">\$</span><span class="sh">{version}"
                    // 환경 변수 설정
                    env.DOCKER_TAG = version
                }
            }
        }
        stage('Docker Build and Push') {
            steps {
                script {
                    docker.withRegistry('https://index.docker.io/v1/', 'dockerhub-credentials') {
                        // DOCKER_TAG 사용
                        def appImage = docker.build("</span><span class="se">\$</span><span class="sh">{DOCKER_IMAGE}:</span><span class="se">\$</span><span class="sh">{DOCKER_TAG}")
                        appImage.push()
                    }
                }
            }
        }
    }
    post {
        success {
            echo "Docker image </span><span class="se">\$</span><span class="sh">{DOCKER_IMAGE}:</span><span class="se">\$</span><span class="sh">{DOCKER_TAG} has been built and pushed successfully!"
        }
        failure {
            echo "Pipeline failed. Please check the logs."
        }
    }
}
</span><span class="no">EOF
  
</span><span class="c"># 버전 업데이트</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; VERSION
0.0.2
</span><span class="no">EOF
  
</span><span class="nv">$ </span>git add <span class="nb">.</span>
<span class="nv">$ </span>git commit <span class="nt">-m</span> <span class="s2">"Add Jenkinsfile"</span>
<span class="c"># =&gt; [main e5671f2] Add Jenkinsfile</span>
<span class="c">#     1 file changed, 45 insertions(+)</span>
<span class="c">#     create mode 100644 Jenkinsfile</span>
<span class="nv">$ </span>git push <span class="nt">-u</span> origin main
<span class="c"># =&gt; Enumerating objects: 4, done.</span>
<span class="c">#    Counting objects: 100% (4/4), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (3/3), done.</span>
<span class="c">#    Writing objects: 100% (3/3), 859 bytes | 859.00 KiB/s, done.</span>
<span class="c">#    Total 3 (delta 1), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To https://gitlab.com/littlebird/2024-cicd-lite-w1.git</span>
<span class="c">#       41a6efc..e5671f2  main -&amp;gt; main</span>
<span class="c">#    branch 'main' set up to track 'origin/main'.</span>
</code></pre></div>    </div>
  </li>
  <li>Jenkins 트리거 빌드 확인
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_32.png" alt="img.png" />
    <ul>
      <li>git push에 의해 자동으로 빌드가 잘 되었습니다.</li>
    </ul>
  </li>
  <li>Docker 저장소 확인
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_33.png" alt="img.png" />
    <ul>
      <li>Docker Hub에 수정된 0.0.2 버전의 이미지가 업로드 되었습니다.</li>
    </ul>
  </li>
  <li>
    <p>Gitlab Webhook 기록 확인
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_34.png" alt="img.png" class="image-center" /></p>
  </li>
  <li>
    <p>app.rb 소스와 VERSION 변경 후 Jenkins 트리거 작업 한번 더 확인</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># app.rb 수정</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s1">'s/Hello, World!/Hello, Jenkins! 😀/'</span> app.rb
  
<span class="c"># VERSION 수정</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"0.0.3"</span> <span class="o">&gt;</span> VERSION
  
<span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"Update app.rb and VERSION </span><span class="si">$(</span><span class="nb">cat </span>VERSION<span class="si">)</span><span class="s2">"</span> <span class="o">&amp;&amp;</span> git push <span class="nt">-u</span> origin main
<span class="c"># =&gt; [main a100e97] Update app.rb and VERSION 0.0.3</span>
<span class="c">#     3 files changed, 7 insertions(+), 2 deletions(-)</span>
<span class="c">#     create mode 100644 app.rb-e</span>
<span class="c">#    Enumerating objects: 7, done.</span>
<span class="c">#    Counting objects: 100% (7/7), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (3/3), done.</span>
<span class="c">#    Writing objects: 100% (4/4), 509 bytes | 509.00 KiB/s, done.</span>
<span class="c">#    Total 4 (delta 0), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To https://gitlab.com/littlebird/2024-cicd-lite-w1.git</span>
<span class="c">#       1bd4fcb..a100e97  main -&amp;gt; main</span>
<span class="c">#    branch 'main' set up to track 'origin/main'.</span>
</code></pre></div>    </div>

    <p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_35.png" alt="img.png" /></p>
    <ul>
      <li>빌드가 잘 되고 Docker Hub에 이미지가 업로드 되었습니다.</li>
    </ul>
  </li>
</ul>

<h5 id="jenkins-빌드-후-컨테이너-실행">Jenkins 빌드 후 컨테이너 실행</h5>

<ul>
  <li>Jenkins pipline 빌드 후 Docker 컨테이너를 실행하는 파이프라인을 구성해보겠습니다.</li>
  <li>
    <p>Jenkinsfile 수정</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pipeline <span class="o">{</span>
    agent any
    environment <span class="o">{</span>
        DOCKER_IMAGE <span class="o">=</span> <span class="s1">'sweetlittlebird/dev-app'</span> // Docker 이미지 이름
        CONTAINER_NAME <span class="o">=</span> <span class="s1">'dev-app'</span>  // Docker 컨테이너 이름
    <span class="o">}</span>
    stages <span class="o">{</span>
        stage<span class="o">(</span><span class="s1">'Checkout'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                git branch: <span class="s1">'main'</span>,
                url: <span class="s1">'https://gitlab.com/littlebird/2024-cicd-lite-w1.git'</span>,  // Git에서 코드 체크아웃
                credentialsId: <span class="s1">'gitlab-credentials'</span>  // Credentials ID
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'Read VERSION'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                script <span class="o">{</span>
                    // VERSION 파일 읽기
                    def version <span class="o">=</span> readFile<span class="o">(</span><span class="s1">'VERSION'</span><span class="o">)</span>.trim<span class="o">()</span>
                    <span class="nb">echo</span> <span class="s2">"Version found: </span><span class="k">${</span><span class="nv">version</span><span class="k">}</span><span class="s2">"</span>
                    // 환경 변수 설정
                    env.DOCKER_TAG <span class="o">=</span> version
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'Docker Build and Push'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                script <span class="o">{</span>
                    docker.withRegistry<span class="o">(</span><span class="s1">'https://index.docker.io/v1/'</span>, <span class="s1">'dockerhub-credentials'</span><span class="o">)</span> <span class="o">{</span>
                        // DOCKER_TAG 사용
                        def appImage <span class="o">=</span> docker.build<span class="o">(</span><span class="s2">"</span><span class="k">${</span><span class="nv">DOCKER_IMAGE</span><span class="k">}</span><span class="s2">:</span><span class="k">${</span><span class="nv">DOCKER_TAG</span><span class="k">}</span><span class="s2">"</span><span class="o">)</span>
                        appImage.push<span class="o">()</span>
                    <span class="o">}</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'Check, Stop and Run Docker Container'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                script <span class="o">{</span>
                    // 실행 중인 컨테이너 확인
                    def isRunning <span class="o">=</span> sh<span class="o">(</span>
                        script: <span class="s2">"docker ps -q -f name=</span><span class="k">${</span><span class="nv">CONTAINER_NAME</span><span class="k">}</span><span class="s2">"</span>,
                        returnStdout: <span class="nb">true</span>
                    <span class="o">)</span>.trim<span class="o">()</span>
                      
                    <span class="k">if</span> <span class="o">(</span>isRunning<span class="o">)</span> <span class="o">{</span>
                        <span class="nb">echo</span> <span class="s2">"Container '</span><span class="k">${</span><span class="nv">CONTAINER_NAME</span><span class="k">}</span><span class="s2">' is already running. Stopping it..."</span>
                        // 실행 중인 컨테이너 중지
                        sh <span class="s2">"docker stop </span><span class="k">${</span><span class="nv">CONTAINER_NAME</span><span class="k">}</span><span class="s2">"</span>
                        // 컨테이너 제거
                        sh <span class="s2">"docker rm </span><span class="k">${</span><span class="nv">CONTAINER_NAME</span><span class="k">}</span><span class="s2">"</span>
                        <span class="nb">echo</span> <span class="s2">"Container '</span><span class="k">${</span><span class="nv">CONTAINER_NAME</span><span class="k">}</span><span class="s2">' stopped and removed."</span>
                    <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
                        <span class="nb">echo</span> <span class="s2">"Container '</span><span class="k">${</span><span class="nv">CONTAINER_NAME</span><span class="k">}</span><span class="s2">' is not running."</span>
                    <span class="o">}</span>
                      
                    // 5초 대기
                    <span class="nb">echo</span> <span class="s2">"Waiting for 5 seconds before starting the new container..."</span>
                    <span class="nb">sleep</span><span class="o">(</span>5<span class="o">)</span>
                      
                    // 신규 컨테이너 실행
                    <span class="nb">echo</span> <span class="s2">"Starting a new container '</span><span class="k">${</span><span class="nv">CONTAINER_NAME</span><span class="k">}</span><span class="s2">'..."</span>
                    sh <span class="s2">"""
                    docker run -d --name </span><span class="k">${</span><span class="nv">CONTAINER_NAME</span><span class="k">}</span><span class="s2"> -p 4000:4567 </span><span class="k">${</span><span class="nv">DOCKER_IMAGE</span><span class="k">}</span><span class="s2">:</span><span class="k">${</span><span class="nv">DOCKER_TAG</span><span class="k">}</span><span class="s2">
                    """</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>        
    <span class="o">}</span>
    post <span class="o">{</span>
        success <span class="o">{</span>
            <span class="nb">echo</span> <span class="s2">"Docker image </span><span class="k">${</span><span class="nv">DOCKER_IMAGE</span><span class="k">}</span><span class="s2">:</span><span class="k">${</span><span class="nv">DOCKER_TAG</span><span class="k">}</span><span class="s2"> has been built and pushed successfully!"</span>
        <span class="o">}</span>
        failure <span class="o">{</span>
            <span class="nb">echo</span> <span class="s2">"Pipeline failed. Please check the logs."</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>git commit 후 push</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">echo </span>0.0.4 <span class="o">&gt;</span> VERSION
  
<span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"Update Jenkinsfile </span><span class="si">$(</span><span class="nb">cat </span>VERSION<span class="si">)</span><span class="s2">"</span> <span class="o">&amp;&amp;</span> git push <span class="nt">-u</span> origin main
<span class="c"># =&gt; [main 25e5c95] Update Jenkinsfile 0.0.4</span>
<span class="c">#     2 files changed, 2 insertions(+), 1 deletion(-)</span>
<span class="c">#    Enumerating objects: 7, done.</span>
<span class="c">#    Counting objects: 100% (7/7), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (3/3), done.</span>
<span class="c">#    Writing objects: 100% (4/4), 385 bytes | 385.00 KiB/s, done.</span>
<span class="c">#    Total 4 (delta 2), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To https://gitlab.com/littlebird/2024-cicd-lite-w1.git</span>
<span class="c">#       26c809d..25e5c95  main -&amp;gt; main</span>
<span class="c">#    branch 'main' set up to track 'origin/main'.</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>생성된 컨테이너 접속 확인</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker image <span class="nb">ls</span>
<span class="c"># =&gt; REPOSITORY                                                                   TAG           IMAGE ID       CREATED             SIZE</span>
<span class="c">#    sweetlittlebird/dev-app                                                      0.0.4         2f5f42fa7dd6   9 minutes ago       1.01GB</span>
<span class="c">#    ... </span>
<span class="nv">$ </span>docker ps <span class="nt">--filter</span> <span class="nv">name</span><span class="o">=</span>dev-app
<span class="c"># =&gt; CONTAINER ID   IMAGE                           COMMAND                  CREATED         STATUS         PORTS                  NAMES</span>
<span class="c">#    e5d4760ea725   sweetlittlebird/dev-app:0.0.4   &amp;quot;ruby app.rb -o 0.0.…&amp;quot;   2 minutes ago   Up 2 minutes   0.0.0.0:4000-&amp;gt;80/tcp   dev-app</span>
<span class="nv">$ </span>curl http://localhost:4000
<span class="c"># =&gt; Hello, Jenkins! 😀 The time is 2024-10-01 15:49:44 +0000!!</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>app.rb와 VERSION 수정 후 push 후 컨테이너 접속 후 반영 확인</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># app.rb 수정</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s1">'s/Hello, Jenkins! 😀/Hello, Jenkins again!!! 😎/'</span> app.rb
  
<span class="c"># VERSION 수정</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"0.0.5"</span> <span class="o">&gt;</span> VERSION
  
<span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"Update app.rb and VERSION </span><span class="si">$(</span><span class="nb">cat </span>VERSION<span class="si">)</span><span class="s2">"</span> <span class="o">&amp;&amp;</span> git push <span class="nt">-u</span> origin main
<span class="c"># =&gt; [main 70eaa32] Update app.rb and VERSION 0.0.5</span>
<span class="c">#     3 files changed, 3 insertions(+), 3 deletions(-)</span>
<span class="c">#    Enumerating objects: 7, done.</span>
<span class="c">#    Counting objects: 100% (7/7), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (3/3), done.</span>
<span class="c">#    Writing objects: 100% (4/4), 519 bytes | 519.00 KiB/s, done.</span>
<span class="c">#    Total 4 (delta 0), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To https://gitlab.com/littlebird/2024-cicd-lite-w1.git</span>
<span class="c">#       cc87e97..70eaa32  main -&amp;gt; main</span>
<span class="c">#    branch 'main' set up to track 'origin/main'.</span>
  
<span class="c"># 호스트 PC에서 반복 접속 실행 : 서비스 중단 시간 체크!</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 http://127.0.0.1:4000 <span class="p">;</span> <span class="nb">date</span><span class="p">;</span> <span class="nb">sleep </span>1 <span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; Hello, Jenkins again!!! 😎 The time is 2024-10-01 15:52:25 +0000!!Sun Oct  1 00:52:25 KST 2024</span>
<span class="c">#    Hello, Jenkins again!!! 😎 The time is 2024-10-01 15:52:26 +0000!!Sun Oct  1 00:52:26 KST 2024</span>
<span class="c">#    Sun Oct  1 00:52:27 KST 2024</span>
<span class="c">#    Sun Oct  1 00:52:28 KST 2024</span>
<span class="c">#    Sun Oct  1 00:52:29 KST 2024</span>
<span class="c">#    Sun Oct  1 00:52:30 KST 2024</span>
<span class="c">#    Sun Oct  1 00:52:31 KST 2024</span>
<span class="c">#    Sun Oct  1 00:52:32 KST 2024</span>
<span class="c">#    Hello, Jenkins again!!! 😎 The time is 2024-10-01 15:52:33 +0000!!Sun Oct  1 00:52:33 KST 2024</span>
<span class="c">#    Hello, Jenkins again!!! 😎 The time is 2024-10-01 15:52:34 +0000!!Sun Oct  1 00:52:34 KST 2024</span>
<span class="c">#    Hello, Jenkins again!!! 😎 The time is 2024-10-01 15:52:35 +0000!!Sun Oct  1 00:52:35 KST 2024</span>
</code></pre></div>    </div>
  </li>
  <li>수정사항이 적용은 잘 되었지만 6~7초 가량 서비스가 중단되는 것을 확인할 수 있습니다. 이는 컨테이너 중지 및 재시작 시간이 소요되기 때문입니다.</li>
  <li>이러한 문제를 해결하기 위해 docker swarm이나 kubernetes 등의 컨테이너 오케스트레이션 툴을 사용하여 서비스 중단 없이 배포할 수 있습니다.
이 부분은 다음에 다루도록 하겠습니다.</li>
</ul>

<h2 id="마치며">마치며</h2>

<p>이번 시간에는 Jenkins, Gitlab 등을 사용하여 CI/CD 파이프라인을 구성하는 방법을 알아보았습니다.
다양하게 테스트해보고 싶었는데 생각보다 정리하는데 시간이 많이 소요되어 다양한 예제를 다루지 못한 점이 아쉽습니다.</p>

<p>Jenkins는 예전에 써보고 Teamcity나 Github action을 주로 사용해왔는데, 
다시 사용해보니 Jenkins도 Jenkinsfile과 Pipeline도 지원하고 예전에 비해서 훨씬 좋아진 것 같습니다.
이번 스터디를 통해 Jenkins를 재발견한것 같습니다.
준비해주신 Gasida 님께 감사드립니다.</p>]]></content><author><name></name></author><category term="kans" /><category term="cicd," /><category term="jenkins," /><category term="git," /><category term="linux" /><summary type="html"><![CDATA[Jenkins와 Git, Docker를 이용하여 CI/CD 파이프라인을 구축해보겠습니다.]]></summary></entry></feed>