<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="ko"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://sweetlittlebird.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://sweetlittlebird.github.io/" rel="alternate" type="text/html" hreflang="ko" /><updated>2025-08-10T00:51:15+09:00</updated><id>https://sweetlittlebird.github.io/feed.xml</id><title type="html">Sweet Little Bird</title><subtitle>공부 기록과 개발 이야기를 담은 블로그입니다.</subtitle><entry><title type="html">[Cilium] Networking - 노드의 파드들간 통신 상세 part 2</title><link href="https://sweetlittlebird.github.io/posts/2025-08-10-Cilium-Week4/" rel="alternate" type="text/html" title="[Cilium] Networking - 노드의 파드들간 통신 상세 part 2" /><published>2025-08-10T00:10:18+09:00</published><updated>2025-08-10T00:10:18+09:00</updated><id>https://sweetlittlebird.github.io/posts/Cilium%20-%20Week4</id><content type="html" xml:base="https://sweetlittlebird.github.io/posts/2025-08-10-Cilium-Week4/"><![CDATA[<h2 id="들어가며">들어가며</h2>

<p>이번 포스트에서는 Overlay Network인 VXLAN을 통한 파드간 통신과 Kubernetes 서비스의 외부 노출, LB-IPAM 등을 통한 통신을 살펴보겠습니다.</p>

<hr />

<h2 id="실습-환경-구성">실습 환경 구성</h2>

<ul>
  <li>이번 실습에서는 다음 그림과 같이 k8s-w0를 별도의 네트워크에 배치하고 router를 통해 k8s-w0와 k8s-ctr/w1 노드간 통신을 확인합니다.
<img src="/assets/2025/cilium/w4/20250810_cilium_w4_2.png" alt="img.png" class="image-center" />
    <ul>
      <li>기본 배포 가상 머신 : k8s-ctr, k8s-w1, k8s-w0, router</li>
      <li><strong>router</strong> : router : 192.168.10.0/24 ↔ 192.168.20.0/24 대역 라우팅 역할, k8s 에 join 되지 않은 서버, loop1/loop2 dump 인터페이스 배치</li>
      <li><strong>k8s-w0</strong> : k8s-ctr/w1 노드와 다른 네트워크 대역에 배치됩니다.</li>
      <li>실습 동작에 필요한 static routing이 설저된 상태로 배포 됩니다.</li>
      <li>Cilium CNI v1.18이 설치된 상태로 배포됩니다.</li>
    </ul>
  </li>
</ul>

<h3 id="실습환경-배포-파일">실습환경 배포 파일</h3>

<ul>
  <li>
    <p><strong>Vagrantfile</strong> : 가상머신 정의, 부팅 시 초기 프로비저닝 설정을 포함하는 Vagrantfile입니다.</p>

    <div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Variables</span>
<span class="no">K8SV</span> <span class="o">=</span> <span class="s1">'1.33.2-1.1'</span> <span class="c1"># Kubernetes Version : apt list -a kubelet , ex) 1.32.5-1.1</span>
<span class="no">CONTAINERDV</span> <span class="o">=</span> <span class="s1">'1.7.27-1'</span> <span class="c1"># Containerd Version : apt list -a containerd.io , ex) 1.6.33-1</span>
<span class="no">CILIUMV</span> <span class="o">=</span> <span class="s1">'1.18.0'</span> <span class="c1"># Cilium CNI Version : https://github.com/cilium/cilium/tags</span>
<span class="no">N</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># max number of worker nodes</span>
  
<span class="c1"># Base Image  https://portal.cloud.hashicorp.com/vagrant/discover/bento/ubuntu-24.04</span>
<span class="no">BOX_IMAGE</span> <span class="o">=</span> <span class="s2">"bento/ubuntu-24.04"</span>
<span class="no">BOX_VERSION</span> <span class="o">=</span> <span class="s2">"202502.21.0"</span>
  
<span class="no">Vagrant</span><span class="p">.</span><span class="nf">configure</span><span class="p">(</span><span class="s2">"2"</span><span class="p">)</span> <span class="k">do</span> <span class="o">|</span><span class="n">config</span><span class="o">|</span>
<span class="c1">#-ControlPlane Node</span>
    <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">define</span> <span class="s2">"k8s-ctr"</span> <span class="k">do</span> <span class="o">|</span><span class="n">subconfig</span><span class="o">|</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="no">BOX_IMAGE</span>
        
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box_version</span> <span class="o">=</span> <span class="no">BOX_VERSION</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provider</span> <span class="s2">"virtualbox"</span> <span class="k">do</span> <span class="o">|</span><span class="n">vb</span><span class="o">|</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--groups"</span><span class="p">,</span> <span class="s2">"/Cilium-Lab"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--nicpromisc2"</span><span class="p">,</span> <span class="s2">"allow-all"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">name</span> <span class="o">=</span> <span class="s2">"k8s-ctr"</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">cpus</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">memory</span> <span class="o">=</span> <span class="mi">2560</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">linked_clone</span> <span class="o">=</span> <span class="kp">true</span>
      <span class="k">end</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">host_name</span> <span class="o">=</span> <span class="s2">"k8s-ctr"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.10.100"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="mi">60000</span><span class="p">,</span> <span class="ss">auto_correct: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">id: </span><span class="s2">"ssh"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">synced_folder</span> <span class="s2">"./"</span><span class="p">,</span> <span class="s2">"/vagrant"</span><span class="p">,</span> <span class="ss">disabled: </span><span class="kp">true</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/4w/init_cfg.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">K8SV</span><span class="p">,</span> <span class="no">CONTAINERDV</span> <span class="p">]</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/4w/k8s-ctr.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">N</span><span class="p">,</span> <span class="no">CILIUMV</span><span class="p">,</span> <span class="no">K8SV</span> <span class="p">]</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/4w/route-add1.sh"</span>
    <span class="k">end</span>
  
<span class="c1">#-Worker Nodes Subnet1</span>
  <span class="p">(</span><span class="mi">1</span><span class="o">..</span><span class="no">N</span><span class="p">).</span><span class="nf">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">i</span><span class="o">|</span>
    <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">define</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span> <span class="k">do</span> <span class="o">|</span><span class="n">subconfig</span><span class="o">|</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="no">BOX_IMAGE</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box_version</span> <span class="o">=</span> <span class="no">BOX_VERSION</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provider</span> <span class="s2">"virtualbox"</span> <span class="k">do</span> <span class="o">|</span><span class="n">vb</span><span class="o">|</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--groups"</span><span class="p">,</span> <span class="s2">"/Cilium-Lab"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--nicpromisc2"</span><span class="p">,</span> <span class="s2">"allow-all"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">name</span> <span class="o">=</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">cpus</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">memory</span> <span class="o">=</span> <span class="mi">1536</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">linked_clone</span> <span class="o">=</span> <span class="kp">true</span>
      <span class="k">end</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">host_name</span> <span class="o">=</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.10.10</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="s2">"6000</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span> <span class="ss">auto_correct: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">id: </span><span class="s2">"ssh"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">synced_folder</span> <span class="s2">"./"</span><span class="p">,</span> <span class="s2">"/vagrant"</span><span class="p">,</span> <span class="ss">disabled: </span><span class="kp">true</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/4w/init_cfg.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">K8SV</span><span class="p">,</span> <span class="no">CONTAINERDV</span><span class="p">]</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/4w/k8s-w.sh"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/4w/route-add1.sh"</span>
    <span class="k">end</span>
  <span class="k">end</span>
  
<span class="c1">#-Router Node</span>
    <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">define</span> <span class="s2">"router"</span> <span class="k">do</span> <span class="o">|</span><span class="n">subconfig</span><span class="o">|</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="no">BOX_IMAGE</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box_version</span> <span class="o">=</span> <span class="no">BOX_VERSION</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provider</span> <span class="s2">"virtualbox"</span> <span class="k">do</span> <span class="o">|</span><span class="n">vb</span><span class="o">|</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--groups"</span><span class="p">,</span> <span class="s2">"/Cilium-Lab"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">name</span> <span class="o">=</span> <span class="s2">"router"</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">cpus</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">memory</span> <span class="o">=</span> <span class="mi">768</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">linked_clone</span> <span class="o">=</span> <span class="kp">true</span>
      <span class="k">end</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">host_name</span> <span class="o">=</span> <span class="s2">"router"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.10.200"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="mi">60009</span><span class="p">,</span> <span class="ss">auto_correct: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">id: </span><span class="s2">"ssh"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.20.200"</span><span class="p">,</span> <span class="ss">auto_config: </span><span class="kp">false</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">synced_folder</span> <span class="s2">"./"</span><span class="p">,</span> <span class="s2">"/vagrant"</span><span class="p">,</span> <span class="ss">disabled: </span><span class="kp">true</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/4w/router.sh"</span>
    <span class="k">end</span>
  
<span class="c1">#-Worker Nodes Subnet2</span>
    <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">define</span> <span class="s2">"k8s-w0"</span> <span class="k">do</span> <span class="o">|</span><span class="n">subconfig</span><span class="o">|</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="no">BOX_IMAGE</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box_version</span> <span class="o">=</span> <span class="no">BOX_VERSION</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provider</span> <span class="s2">"virtualbox"</span> <span class="k">do</span> <span class="o">|</span><span class="n">vb</span><span class="o">|</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--groups"</span><span class="p">,</span> <span class="s2">"/Cilium-Lab"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--nicpromisc2"</span><span class="p">,</span> <span class="s2">"allow-all"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">name</span> <span class="o">=</span> <span class="s2">"k8s-w0"</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">cpus</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">memory</span> <span class="o">=</span> <span class="mi">1536</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">linked_clone</span> <span class="o">=</span> <span class="kp">true</span>
      <span class="k">end</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">host_name</span> <span class="o">=</span> <span class="s2">"k8s-w0"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.20.100"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="mi">60010</span><span class="p">,</span> <span class="ss">auto_correct: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">id: </span><span class="s2">"ssh"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">synced_folder</span> <span class="s2">"./"</span><span class="p">,</span> <span class="s2">"/vagrant"</span><span class="p">,</span> <span class="ss">disabled: </span><span class="kp">true</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/4w/init_cfg.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">K8SV</span><span class="p">,</span> <span class="no">CONTAINERDV</span><span class="p">]</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/4w/k8s-w.sh"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/4w/route-add2.sh"</span>
    <span class="k">end</span>
<span class="k">end</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>init_cfg.sh</strong> : args 참고하여 초기 설정을 수행하는 스크립트입니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config Start &lt;&lt;&lt;&lt;"</span>
  
<span class="nb">echo</span> <span class="s2">"[TASK 1] Setting Profile &amp; Bashrc"</span>
<span class="nb">echo</span> <span class="s1">'alias vi=vim'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s2">"sudo su -"</span> <span class="o">&gt;&gt;</span> /home/vagrant/.bashrc
<span class="nb">ln</span> <span class="nt">-sf</span> /usr/share/zoneinfo/Asia/Seoul /etc/localtime <span class="c"># Change Timezone</span>
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 2] Disable AppArmor"</span>
systemctl stop ufw <span class="o">&amp;&amp;</span> systemctl disable ufw <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
systemctl stop apparmor <span class="o">&amp;&amp;</span> systemctl disable apparmor <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 3] Disable and turn off SWAP"</span>
swapoff <span class="nt">-a</span> <span class="o">&amp;&amp;</span> <span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'/swap/s/^/#/'</span> /etc/fstab
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 4] Install Packages"</span>
apt update <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
apt-get <span class="nb">install </span>apt-transport-https ca-certificates curl gpg <span class="nt">-y</span> <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="c"># Download the public signing key for the Kubernetes package repositories.</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> <span class="nt">-m</span> 755 /etc/apt/keyrings
<span class="nv">K8SMMV</span><span class="o">=</span><span class="si">$(</span><span class="nb">echo</span> <span class="nv">$1</span> | <span class="nb">sed</span> <span class="nt">-En</span> <span class="s1">'s/^([0-9]+\.[0-9]+)\..*/\1/p'</span><span class="si">)</span>
curl <span class="nt">-fsSL</span> https://pkgs.k8s.io/core:/stable:/v<span class="nv">$K8SMMV</span>/deb/Release.key | <span class="nb">sudo </span>gpg <span class="nt">--dearmor</span> <span class="nt">-o</span> /etc/apt/keyrings/kubernetes-apt-keyring.gpg
<span class="nb">echo</span> <span class="s2">"deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v</span><span class="nv">$K8SMMV</span><span class="s2">/deb/ /"</span> <span class="o">&gt;&gt;</span> /etc/apt/sources.list.d/kubernetes.list
curl <span class="nt">-fsSL</span> https://download.docker.com/linux/ubuntu/gpg <span class="nt">-o</span> /etc/apt/keyrings/docker.asc
<span class="nb">echo</span> <span class="s2">"deb [arch=</span><span class="si">$(</span>dpkg <span class="nt">--print-architecture</span><span class="si">)</span><span class="s2"> signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu </span><span class="si">$(</span><span class="nb">.</span> /etc/os-release <span class="o">&amp;&amp;</span> <span class="nb">echo</span> <span class="s2">"</span><span class="nv">$VERSION_CODENAME</span><span class="s2">"</span><span class="si">)</span><span class="s2"> stable"</span> | <span class="nb">tee</span> /etc/apt/sources.list.d/docker.list <span class="o">&gt;</span> /dev/null
  
<span class="c"># packets traversing the bridge are processed by iptables for filtering</span>
<span class="nb">echo </span>1 <span class="o">&gt;</span> /proc/sys/net/ipv4/ip_forward
<span class="nb">echo</span> <span class="s2">"net.ipv4.ip_forward = 1"</span> <span class="o">&gt;&gt;</span> /etc/sysctl.d/k8s.conf
  
<span class="c"># enable br_netfilter for iptables </span>
modprobe br_netfilter
modprobe overlay
<span class="nb">echo</span> <span class="s2">"br_netfilter"</span> <span class="o">&gt;&gt;</span> /etc/modules-load.d/k8s.conf
<span class="nb">echo</span> <span class="s2">"overlay"</span> <span class="o">&gt;&gt;</span> /etc/modules-load.d/k8s.conf
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 5] Install Kubernetes components (kubeadm, kubelet and kubectl)"</span>
<span class="c"># Update the apt package index, install kubelet, kubeadm and kubectl, and pin their version</span>
apt update <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="c"># apt list -a kubelet ; apt list -a containerd.io</span>
apt-get <span class="nb">install</span> <span class="nt">-y</span> <span class="nv">kubelet</span><span class="o">=</span><span class="nv">$1</span> <span class="nv">kubectl</span><span class="o">=</span><span class="nv">$1</span> <span class="nv">kubeadm</span><span class="o">=</span><span class="nv">$1</span> containerd.io<span class="o">=</span><span class="nv">$2</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
apt-mark hold kubelet kubeadm kubectl <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="c"># containerd configure to default and cgroup managed by systemd</span>
containerd config default <span class="o">&gt;</span> /etc/containerd/config.toml
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'s/SystemdCgroup = false/SystemdCgroup = true/g'</span> /etc/containerd/config.toml
  
<span class="c"># avoid WARN&amp;ERRO(default endpoints) when crictl run  </span>
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; /etc/crictl.yaml
runtime-endpoint: unix:///run/containerd/containerd.sock
image-endpoint: unix:///run/containerd/containerd.sock
</span><span class="no">EOF
  
</span><span class="c"># ready to install for k8s </span>
systemctl restart containerd <span class="o">&amp;&amp;</span> systemctl <span class="nb">enable </span>containerd
systemctl <span class="nb">enable</span> <span class="nt">--now</span> kubelet
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 6] Install Packages &amp; Helm"</span>
<span class="nb">export </span><span class="nv">DEBIAN_FRONTEND</span><span class="o">=</span>noninteractive
apt-get <span class="nb">install</span> <span class="nt">-y</span> bridge-utils sshpass net-tools conntrack ngrep tcpdump ipset arping wireguard jq yq tree bash-completion unzip kubecolor termshark <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
curl <span class="nt">-s</span> https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>k8s-ctr.sh</strong> : kubeadm init를 통하여 kubernetes controlplane 노드를 설정하고 Cilium CNI 설치, 편리성 설정(k, kc)하는 스크립트입니다. local-path-storageclass와 metrics-server도 설치합니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Controlplane config Start &lt;&lt;&lt;&lt;"</span>
  
<span class="nb">echo</span> <span class="s2">"[TASK 1] Initial Kubernetes"</span>
curl <span class="nt">--silent</span> <span class="nt">-o</span> /root/kubeadm-init-ctr-config.yaml https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/kubeadm-init-ctr-config.yaml
<span class="nv">K8SMMV</span><span class="o">=</span><span class="si">$(</span><span class="nb">echo</span> <span class="nv">$3</span> | <span class="nb">sed</span> <span class="nt">-En</span> <span class="s1">'s/^([0-9]+\.[0-9]+\.[0-9]+).*/\1/p'</span><span class="si">)</span>
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/K8S_VERSION_PLACEHOLDER/v</span><span class="k">${</span><span class="nv">K8SMMV</span><span class="k">}</span><span class="s2">/g"</span> /root/kubeadm-init-ctr-config.yaml
kubeadm init <span class="nt">--config</span><span class="o">=</span><span class="s2">"/root/kubeadm-init-ctr-config.yaml"</span>  <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 2] Setting kube config file"</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> /root/.kube
<span class="nb">cp</span> <span class="nt">-i</span> /etc/kubernetes/admin.conf /root/.kube/config
<span class="nb">chown</span> <span class="si">$(</span><span class="nb">id</span> <span class="nt">-u</span><span class="si">)</span>:<span class="si">$(</span><span class="nb">id</span> <span class="nt">-g</span><span class="si">)</span> /root/.kube/config
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 3] Source the completion"</span>
<span class="nb">echo</span> <span class="s1">'source &lt;(kubectl completion bash)'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'source &lt;(kubeadm completion bash)'</span> <span class="o">&gt;&gt;</span> /etc/profile
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 4] Alias kubectl to k"</span>
<span class="nb">echo</span> <span class="s1">'alias k=kubectl'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'alias kc=kubecolor'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'complete -F __start_kubectl k'</span> <span class="o">&gt;&gt;</span> /etc/profile
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 5] Install Kubectx &amp; Kubens"</span>
git clone https://github.com/ahmetb/kubectx /opt/kubectx <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">ln</span> <span class="nt">-s</span> /opt/kubectx/kubens /usr/local/bin/kubens
<span class="nb">ln</span> <span class="nt">-s</span> /opt/kubectx/kubectx /usr/local/bin/kubectx
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 6] Install Kubeps &amp; Setting PS1"</span>
git clone https://github.com/jonmosco/kube-ps1.git /root/kube-ps1 <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="sh">"</span><span class="no">EOT</span><span class="sh">" &gt;&gt; /root/.bash_profile
source /root/kube-ps1/kube-ps1.sh
KUBE_PS1_SYMBOL_ENABLE=true
function get_cluster_short() {
  echo "</span><span class="nv">$1</span><span class="sh">" | cut -d . -f1
}
KUBE_PS1_CLUSTER_FUNCTION=get_cluster_short
KUBE_PS1_SUFFIX=') '
PS1='</span><span class="si">$(</span>kube_ps1<span class="si">)</span><span class="sh">'</span><span class="nv">$PS1</span><span class="sh">
</span><span class="no">EOT
</span>kubectl config rename-context <span class="s2">"kubernetes-admin@kubernetes"</span> <span class="s2">"HomeLab"</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 7] Install Cilium CNI"</span>
<span class="nv">NODEIP</span><span class="o">=</span><span class="si">$(</span>ip <span class="nt">-4</span> addr show eth1 | <span class="nb">grep</span> <span class="nt">-oP</span> <span class="s1">'(?&lt;=inet\s)\d+(\.\d+){3}'</span><span class="si">)</span>
helm repo add cilium https://helm.cilium.io/ <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
helm repo update <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
helm <span class="nb">install </span>cilium cilium/cilium <span class="nt">--version</span> <span class="nv">$2</span> <span class="nt">--namespace</span> kube-system <span class="se">\</span>
<span class="nt">--set</span> <span class="nv">k8sServiceHost</span><span class="o">=</span>192.168.10.100 <span class="nt">--set</span> <span class="nv">k8sServicePort</span><span class="o">=</span>6443 <span class="se">\</span>
<span class="nt">--set</span> ipam.mode<span class="o">=</span><span class="s2">"cluster-pool"</span> <span class="nt">--set</span> ipam.operator.clusterPoolIPv4PodCIDRList<span class="o">={</span><span class="s2">"172.20.0.0/16"</span><span class="o">}</span> <span class="nt">--set</span> <span class="nv">ipv4NativeRoutingCIDR</span><span class="o">=</span>172.20.0.0/16 <span class="se">\</span>
<span class="nt">--set</span> <span class="nv">routingMode</span><span class="o">=</span>native <span class="nt">--set</span> <span class="nv">autoDirectNodeRoutes</span><span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> <span class="nv">kubeProxyReplacement</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> bpf.masquerade<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> <span class="nv">installNoConntrackIptablesRules</span><span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> endpointHealthChecking.enabled<span class="o">=</span><span class="nb">false</span> <span class="nt">--set</span> <span class="nv">healthChecking</span><span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
<span class="nt">--set</span> hubble.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> hubble.relay.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> hubble.ui.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> hubble.ui.service.type<span class="o">=</span>NodePort <span class="nt">--set</span> hubble.ui.service.nodePort<span class="o">=</span>30003 <span class="se">\</span>
<span class="nt">--set</span> prometheus.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> operator.prometheus.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> hubble.metrics.enableOpenMetrics<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> hubble.metrics.enabled<span class="o">=</span><span class="s2">"{dns,drop,tcp,flow,port-distribution,icmp,httpV2:exemplars=true;labelsContext=source_ip</span><span class="se">\,</span><span class="s2">source_namespace</span><span class="se">\,</span><span class="s2">source_workload</span><span class="se">\,</span><span class="s2">destination_ip</span><span class="se">\,</span><span class="s2">destination_namespace</span><span class="se">\,</span><span class="s2">destination_workload</span><span class="se">\,</span><span class="s2">traffic_direction}"</span> <span class="se">\</span>
<span class="nt">--set</span> operator.replicas<span class="o">=</span>1 <span class="nt">--set</span> debug.enabled<span class="o">=</span><span class="nb">true</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 8] Install Cilium / Hubble CLI"</span>
<span class="nv">CILIUM_CLI_VERSION</span><span class="o">=</span><span class="si">$(</span>curl <span class="nt">-s</span> https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt<span class="si">)</span>
<span class="nv">CLI_ARCH</span><span class="o">=</span>amd64
<span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span><span class="si">)</span><span class="s2">"</span> <span class="o">=</span> <span class="s2">"aarch64"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then </span><span class="nv">CLI_ARCH</span><span class="o">=</span>arm64<span class="p">;</span> <span class="k">fi
</span>curl <span class="nt">-L</span> <span class="nt">--fail</span> <span class="nt">--remote-name-all</span> https://github.com/cilium/cilium-cli/releases/download/<span class="k">${</span><span class="nv">CILIUM_CLI_VERSION</span><span class="k">}</span>/cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">tar </span>xzvfC cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz /usr/local/bin
<span class="nb">rm </span>cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz
  
<span class="nv">HUBBLE_VERSION</span><span class="o">=</span><span class="si">$(</span>curl <span class="nt">-s</span> https://raw.githubusercontent.com/cilium/hubble/master/stable.txt<span class="si">)</span>
<span class="nv">HUBBLE_ARCH</span><span class="o">=</span>amd64
<span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span><span class="si">)</span><span class="s2">"</span> <span class="o">=</span> <span class="s2">"aarch64"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then </span><span class="nv">HUBBLE_ARCH</span><span class="o">=</span>arm64<span class="p">;</span> <span class="k">fi
</span>curl <span class="nt">-L</span> <span class="nt">--fail</span> <span class="nt">--remote-name-all</span> https://github.com/cilium/hubble/releases/download/<span class="nv">$HUBBLE_VERSION</span>/hubble-linux-<span class="k">${</span><span class="nv">HUBBLE_ARCH</span><span class="k">}</span>.tar.gz <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">tar </span>xzvfC hubble-linux-<span class="k">${</span><span class="nv">HUBBLE_ARCH</span><span class="k">}</span>.tar.gz /usr/local/bin
<span class="nb">rm </span>hubble-linux-<span class="k">${</span><span class="nv">HUBBLE_ARCH</span><span class="k">}</span>.tar.gz
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 9] Remove node taint"</span>
kubectl taint nodes k8s-ctr node-role.kubernetes.io/control-plane-
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 10] local DNS with hosts file"</span>
<span class="nb">echo</span> <span class="s2">"192.168.10.100 k8s-ctr"</span> <span class="o">&gt;&gt;</span> /etc/hosts
<span class="nb">echo</span> <span class="s2">"192.168.10.200 router"</span> <span class="o">&gt;&gt;</span> /etc/hosts
<span class="nb">echo</span> <span class="s2">"192.168.20.100 k8s-w0"</span> <span class="o">&gt;&gt;</span> /etc/hosts
<span class="k">for</span> <span class="o">((</span> <span class="nv">i</span><span class="o">=</span>1<span class="p">;</span> i&lt;<span class="o">=</span><span class="nv">$1</span><span class="p">;</span> i++  <span class="o">))</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"192.168.10.10</span><span class="nv">$i</span><span class="s2"> k8s-w</span><span class="nv">$i</span><span class="s2">"</span> <span class="o">&gt;&gt;</span> /etc/hosts<span class="p">;</span> <span class="k">done
  
  
</span><span class="nb">echo</span> <span class="s2">"[TASK 11] Dynamically provisioning persistent local storage with Kubernetes"</span>
kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.31/deploy/local-path-storage.yaml <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
kubectl patch storageclass local-path <span class="nt">-p</span> <span class="s1">'{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 12] Install Prometheus &amp; Grafana"</span>
kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/cilium/cilium/1.18.0/examples/kubernetes/addons/prometheus/monitoring-example.yaml <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
kubectl patch svc <span class="nt">-n</span> cilium-monitoring prometheus <span class="nt">-p</span> <span class="s1">'{"spec": {"type": "NodePort", "ports": [{"port": 9090, "targetPort": 9090, "nodePort": 30001}]}}'</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
kubectl patch svc <span class="nt">-n</span> cilium-monitoring grafana <span class="nt">-p</span> <span class="s1">'{"spec": {"type": "NodePort", "ports": [{"port": 3000, "targetPort": 3000, "nodePort": 30002}]}}'</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="c"># echo "[TASK 12] Install Prometheus Stack"</span>
<span class="c"># helm repo add prometheus-community https://prometheus-community.github.io/helm-charts  &gt;/dev/null 2&gt;&amp;1</span>
<span class="c"># cat &lt;&lt;EOT &gt; monitor-values.yaml</span>
<span class="c"># prometheus:</span>
<span class="c">#   prometheusSpec:</span>
<span class="c">#     scrapeInterval: "15s"</span>
<span class="c">#     evaluationInterval: "15s"</span>
<span class="c">#   service:</span>
<span class="c">#     type: NodePort</span>
<span class="c">#     nodePort: 30001</span>
  
<span class="c"># grafana:</span>
<span class="c">#   defaultDashboardsTimezone: Asia/Seoul</span>
<span class="c">#   adminPassword: prom-operator</span>
<span class="c">#   service:</span>
<span class="c">#     type: NodePort</span>
<span class="c">#     nodePort: 30002</span>
  
<span class="c"># alertmanager:</span>
<span class="c">#   enabled: false</span>
<span class="c"># defaultRules:</span>
<span class="c">#   create: false</span>
<span class="c"># prometheus-windows-exporter:</span>
<span class="c">#   prometheus:</span>
<span class="c">#     monitor:</span>
<span class="c">#       enabled: false</span>
<span class="c"># EOT</span>
<span class="c"># helm install kube-prometheus-stack prometheus-community/kube-prometheus-stack --version 75.15.1 \</span>
<span class="c">#   -f monitor-values.yaml --create-namespace --namespace monitoring  &gt;/dev/null 2&gt;&amp;1</span>
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 13] Install Metrics-server"</span>
helm repo add metrics-server https://kubernetes-sigs.github.io/metrics-server/  <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
helm upgrade <span class="nt">--install</span> metrics-server metrics-server/metrics-server <span class="nt">--set</span> <span class="s1">'args[0]=--kubelet-insecure-tls'</span> <span class="nt">-n</span> kube-system  <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 14] Install k9s"</span>
<span class="nv">CLI_ARCH</span><span class="o">=</span>amd64
<span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span><span class="si">)</span><span class="s2">"</span> <span class="o">=</span> <span class="s2">"aarch64"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then </span><span class="nv">CLI_ARCH</span><span class="o">=</span>arm64<span class="p">;</span> <span class="k">fi
</span>wget https://github.com/derailed/k9s/releases/latest/download/k9s_linux_<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.deb <span class="nt">-O</span> /tmp/k9s_linux_<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.deb  <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
apt <span class="nb">install</span> /tmp/k9s_linux_<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.deb  <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Controlplane Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div>    </div>

    <ul>
      <li>
        <p><strong>kubeadm-init-ctr-config.yaml</strong></p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  apiVersion: kubeadm.k8s.io/v1beta4
  kind: InitConfiguration
  bootstrapTokens:
  - token: <span class="s2">"123456.1234567890123456"</span>
    ttl: <span class="s2">"0s"</span>
    usages:
    - signing
    - authentication
  localAPIEndpoint:
    advertiseAddress: <span class="s2">"192.168.10.100"</span>
  nodeRegistration:
    kubeletExtraArgs:
      - name: node-ip
        value: <span class="s2">"192.168.10.100"</span>
    criSocket: <span class="s2">"unix:///run/containerd/containerd.sock"</span>
  <span class="nt">---</span>
  apiVersion: kubeadm.k8s.io/v1beta4
  kind: ClusterConfiguration
  kubernetesVersion: <span class="s2">"K8S_VERSION_PLACEHOLDER"</span>
  networking:
    podSubnet: <span class="s2">"10.244.0.0/16"</span>
    serviceSubnet: <span class="s2">"10.96.0.0/16"</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li><strong>k8s-w.sh</strong> : kubernetes worker 노드 설정, kubeadm join 등을 수행하는  스크립트입니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Node config Start &lt;&lt;&lt;&lt;"</span>
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 1] K8S Controlplane Join"</span>
curl <span class="nt">--silent</span> <span class="nt">-o</span> /root/kubeadm-join-worker-config.yaml https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/2w/kubeadm-join-worker-config.yaml
<span class="nv">NODEIP</span><span class="o">=</span><span class="si">$(</span>ip <span class="nt">-4</span> addr show eth1 | <span class="nb">grep</span> <span class="nt">-oP</span> <span class="s1">'(?&lt;=inet\s)\d+(\.\d+){3}'</span><span class="si">)</span>
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/NODE_IP_PLACEHOLDER/</span><span class="k">${</span><span class="nv">NODEIP</span><span class="k">}</span><span class="s2">/g"</span> /root/kubeadm-join-worker-config.yaml
kubeadm <span class="nb">join</span> <span class="nt">--config</span><span class="o">=</span><span class="s2">"/root/kubeadm-join-worker-config.yaml"</span> <span class="o">&gt;</span> /dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Node config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div>    </div>
    <ul>
      <li>
        <p><strong>kubeadm-join-worker-config.yaml</strong></p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apiVersion: kubeadm.k8s.io/v1beta4
kind: JoinConfiguration
discovery:
  bootstrapToken:
    token: <span class="s2">"123456.1234567890123456"</span>
    apiServerEndpoint: <span class="s2">"192.168.10.100:6443"</span>
    unsafeSkipCAVerification: <span class="nb">true
</span>nodeRegistration:
  criSocket: <span class="s2">"unix:///run/containerd/containerd.sock"</span>
  kubeletExtraArgs:
    - name: node-ip
      value: <span class="s2">"NODE_IP_PLACEHOLDER"</span>    
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>route-add1.sh</strong> : k8s node 들이 내부망과 통신을 위한 route 설정 스크립트입니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Route Add Config Start &lt;&lt;&lt;&lt;"</span>
  
<span class="nb">chmod </span>600 /etc/netplan/01-netcfg.yaml
<span class="nb">chmod </span>600 /etc/netplan/50-vagrant.yaml
  
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh">&gt;&gt; /etc/netplan/50-vagrant.yaml
      routes:
      - to: 192.168.20.0/24
        via: 192.168.10.200
      - to: 172.20.0.0/16
        via: 192.168.10.200
      - to: 10.10.0.0/16
        via: 192.168.10.200
</span><span class="no">EOT
  
</span>netplan apply
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Route Add Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>route-add2.sh</strong> : k8s node 들이 내부망과 통신을 위한 route 설정 스크립트입니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Route Add Config Start &lt;&lt;&lt;&lt;"</span>
  
<span class="nb">chmod </span>600 /etc/netplan/01-netcfg.yaml
<span class="nb">chmod </span>600 /etc/netplan/50-vagrant.yaml
  
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh">&gt;&gt; /etc/netplan/50-vagrant.yaml
      routes:
      - to: 192.168.10.0/24
        via: 192.168.20.200
      - to: 172.20.0.0/16
        via: 192.168.20.200
      - to: 10.10.0.0/16
        via: 192.168.20.200
</span><span class="no">EOT
  
</span>netplan apply
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Route Add Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>router.sh</strong> : router 역할과 추가적으로 웹서버 역할을 하는 서버의 초기 설정을 담당합니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config Start &lt;&lt;&lt;&lt;"</span>
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 0] Setting eth2"</span>
<span class="nb">chmod </span>600 /etc/netplan/01-netcfg.yaml
<span class="nb">chmod </span>600 /etc/netplan/50-vagrant.yaml
  
<span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOT</span><span class="sh"> &gt;&gt; /etc/netplan/50-vagrant.yaml
    eth2:
      addresses:
      - 192.168.20.200/24
</span><span class="no">EOT
  
</span>netplan apply
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 1] Setting Profile &amp; Bashrc"</span>
<span class="nb">echo</span> <span class="s1">'alias vi=vim'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s2">"sudo su -"</span> <span class="o">&gt;&gt;</span> /home/vagrant/.bashrc
<span class="nb">ln</span> <span class="nt">-sf</span> /usr/share/zoneinfo/Asia/Seoul /etc/localtime
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 2] Disable AppArmor"</span>
systemctl stop ufw <span class="o">&amp;&amp;</span> systemctl disable ufw <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
systemctl stop apparmor <span class="o">&amp;&amp;</span> systemctl disable apparmor <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 3] Add Kernel setting - IP Forwarding"</span>
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'s/#net.ipv4.ip_forward=1/net.ipv4.ip_forward=1/g'</span> /etc/sysctl.conf
sysctl <span class="nt">-p</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 4] Setting Dummy Interface"</span>
modprobe dummy
ip <span class="nb">link </span>add loop1 <span class="nb">type </span>dummy
ip <span class="nb">link set </span>loop1 up
ip addr add 10.10.1.200/24 dev loop1
  
ip <span class="nb">link </span>add loop2 <span class="nb">type </span>dummy
ip <span class="nb">link set </span>loop2 up
ip addr add 10.10.2.200/24 dev loop2
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 5] Install Packages"</span>
<span class="nb">export </span><span class="nv">DEBIAN_FRONTEND</span><span class="o">=</span>noninteractive
apt update <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
apt-get <span class="nb">install </span>net-tools jq yq tree ngrep tcpdump arping termshark <span class="nt">-y</span> <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
  
<span class="nb">echo</span> <span class="s2">"[TASK 6] Install Apache"</span>
apt <span class="nb">install </span>apache2 <span class="nt">-y</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"&lt;h1&gt;Web Server : </span><span class="si">$(</span><span class="nb">hostname</span><span class="si">)</span><span class="s2">&lt;/h1&gt;"</span> <span class="o">&gt;</span> /var/www/html/index.html
  
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div>    </div>
  </li>
</ul>

<h3 id="실습환경-배포-및-분석-툴-설치">실습환경 배포 및 분석 툴 설치</h3>

<ul>
  <li>
    <p>실습환경 배포</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>vagrant up
<span class="c"># =&gt; ...    </span>
<span class="c">#        k8s-w0: &gt;&gt;&gt;&gt; Initial Config End &lt;&lt;&lt;&lt;</span>
<span class="c">#    ==&gt; k8s-w0: Running provisioner: shell...</span>
<span class="c">#        k8s-w0: Running: /var/folders/7k/qy6rsdds57z3tmyn9_7hhd8r0000gn/T/vagrant-shell20250807-27868-fg24bd.sh</span>
<span class="c">#        k8s-w0: &gt;&gt;&gt;&gt; K8S Node config Start &lt;&lt;&lt;&lt;</span>
<span class="c">#        k8s-w0: [TASK 1] K8S Controlplane Join</span>
<span class="c">#        k8s-w0: &gt;&gt;&gt;&gt; K8S Node config End &lt;&lt;&lt;&lt;</span>
<span class="c">#    ==&gt; k8s-w0: Running provisioner: shell...</span>
<span class="c">#        k8s-w0: Running: /var/folders/7k/qy6rsdds57z3tmyn9_7hhd8r0000gn/T/vagrant-shell20250807-27868-fzndov.sh</span>
<span class="c">#        k8s-w0: &gt;&gt;&gt;&gt; Route Add Config Start &lt;&lt;&lt;&lt;</span>
<span class="c">#        k8s-w0: &gt;&gt;&gt;&gt; Route Add Config End &lt;&lt;&lt;&lt;</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>기본정보 확인</p>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># k8s-ctr 노드에 접속</span>
<span class="nv">$ </span>vagrant ssh k8s-ctr

<span class="nt">---------------------------------</span>

<span class="c"># k9s 설치</span>
<span class="nv">$ CLI_ARCH</span><span class="o">=</span>amd64
<span class="nv">$ </span><span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span><span class="si">)</span><span class="s2">"</span> <span class="o">=</span> <span class="s2">"aarch64"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then </span><span class="nv">CLI_ARCH</span><span class="o">=</span>arm64<span class="p">;</span> <span class="k">fi</span>
<span class="nv">$ </span>wget https://github.com/derailed/k9s/releases/latest/download/k9s_linux_<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.deb <span class="nt">-O</span> /tmp/k9s_linux_<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.deb
<span class="nv">$ </span>apt <span class="nb">install</span> /tmp/k9s_linux_<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.deb
<span class="nv">$ </span>k9s <span class="c"># node/pod 정보 확인 - metrics-server 설치되어 있어서, cpu/mem 확인 가능</span>

<span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> /etc/hosts
<span class="c"># =&gt; 127.0.2.1 k8s-ctr k8s-ctr</span>
<span class="c">#    192.168.10.100 k8s-ctr</span>
<span class="c">#    192.168.20.100 k8s-w0</span>
<span class="c">#    192.168.10.101 k8s-w1</span>
<span class="c">#    192.168.10.200 router</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-w0 <span class="nb">hostname</span>
<span class="c"># =&gt; k8s-w0</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s-w0는 k8s-ctr과 다른 네트워크에 있지만 정적 route 설정이 되어 있어서 접속이 가능합니다.&lt;/span&gt;</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-w1 <span class="nb">hostname</span>
<span class="c"># =&gt; k8s-w1</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@router <span class="nb">hostname</span>
<span class="c"># =&gt; router</span>

<span class="c"># 클러스터 정보 확인</span>
<span class="nv">$ </span>kubectl cluster-info
<span class="c"># =&gt; Kubernetes control plane is running at https://192.168.10.100:6443</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>kubectl cluster-info dump | <span class="nb">grep</span> <span class="nt">-m</span> 2 <span class="nt">-E</span> <span class="s2">"cluster-cidr|service-cluster-ip-range"</span>
<span class="c"># =&gt;                             "--service-cluster-ip-range=10.96.0.0/16",</span>
<span class="c">#                                "--cluster-cidr=10.244.0.0/16",                           </span>

<span class="nv">$ </span>kubectl describe cm <span class="nt">-n</span> kube-system kubeadm-config
<span class="c"># =&gt; ...</span>
<span class="c">#      podSubnet: 10.244.0.0/16</span>
<span class="c">#      serviceSubnet: 10.96.0.0/16</span>
<span class="nv">$ </span>kubectl describe cm <span class="nt">-n</span> kube-system kubelet-config

<span class="c"># 노드 정보 : 상태, INTERNAL-IP 확인</span>
<span class="nv">$ </span>ifconfig | <span class="nb">grep</span> <span class="nt">-iEA1</span> <span class="s1">'eth[0-9]:'</span>
<span class="c"># =&gt; eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span>
<span class="c">#            inet 10.0.2.15  netmask 255.255.255.0  broadcast 10.0.2.255</span>
<span class="c">#    --</span>
<span class="c">#    eth1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span>
<span class="c">#            inet 192.168.10.100  netmask 255.255.255.0  broadcast 192.168.10.255</span>
<span class="nv">$ </span>kubectl get node <span class="nt">-owide</span>
<span class="c"># =&gt; NAME      STATUS   ROLES           AGE     VERSION   INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION     CONTAINER-RUNTIME</span>
<span class="c">#    k8s-ctr   Ready    control-plane   9m41s   v1.33.2   192.168.10.100   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>
<span class="c">#    k8s-w0    Ready    &lt;none&gt;          4m37s   v1.33.2   192.168.20.100   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>
<span class="c">#    k8s-w1    Ready    &lt;none&gt;          7m13s   v1.33.2   192.168.10.101   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>

<span class="c"># 파드 정보 : 상태, 파드 IP 확인</span>
<span class="nv">$ </span>kubectl get nodes <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{range .items[*]}{.metadata.name}{"\t"}{.spec.podCIDR}{"\n"}{end}'</span>
<span class="c"># =&gt; k8s-ctr 10.244.0.0/24</span>
<span class="c">#    k8s-w0  10.244.3.0/24</span>
<span class="c">#    k8s-w1  10.244.1.0/24</span>
<span class="nv">$ </span>kubectl get ciliumnode <span class="nt">-o</span> json | <span class="nb">grep </span>podCIDRs <span class="nt">-A2</span>
<span class="c"># =&gt;                     "podCIDRs": [</span>
<span class="c">#                            "172.20.0.0/24"</span>
<span class="c">#                        ],</span>
<span class="c">#    --</span>
<span class="c">#                        "podCIDRs": [</span>
<span class="c">#                            "172.20.2.0/24"</span>
<span class="c">#                        ],</span>
<span class="c">#    --</span>
<span class="c">#                        "podCIDRs": [</span>
<span class="c">#                            "172.20.1.0/24"</span>
<span class="c">#                        ],</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-A</span> <span class="nt">-owide</span>
<span class="c"># =&gt; NAMESPACE            NAME                                      READY   STATUS    RESTARTS   AGE     IP               NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    cilium-monitoring    grafana-5c69859d9-n82rg                   1/1     Running   0          10m     172.20.0.209     k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    cilium-monitoring    prometheus-6fc896bc5d-m82wl               1/1     Running   0          10m     172.20.0.230     k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          cilium-c8265                              1/1     Running   0          10m     192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          cilium-envoy-2x4fb                        1/1     Running   0          7m54s   192.168.10.101   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          cilium-envoy-fktjl                        1/1     Running   0          5m18s   192.168.20.100   k8s-w0    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          cilium-envoy-gw7cw                        1/1     Running   0          10m     192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          cilium-h5k5g                              1/1     Running   0          5m18s   192.168.20.100   k8s-w0    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          cilium-operator-76788cffb7-8nhzr          1/1     Running   0          10m     192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          cilium-tzlkp                              1/1     Running   0          7m54s   192.168.10.101   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          coredns-674b8bbfcf-bkc4b                  1/1     Running   0          10m     172.20.0.42      k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          coredns-674b8bbfcf-jdxtw                  1/1     Running   0          10m     172.20.0.185     k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          etcd-k8s-ctr                              1/1     Running   0          10m     192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          hubble-relay-5b48c999f9-vh8jq             1/1     Running   0          10m     172.20.0.156     k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          hubble-ui-655f947f96-vv266                2/2     Running   0          10m     172.20.0.147     k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          kube-apiserver-k8s-ctr                    1/1     Running   0          10m     192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          kube-controller-manager-k8s-ctr           1/1     Running   0          10m     192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          kube-proxy-5qw8d                          1/1     Running   0          10m     192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          kube-proxy-7z4ds                          1/1     Running   0          7m54s   192.168.10.101   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          kube-proxy-twtfn                          1/1     Running   0          5m18s   192.168.20.100   k8s-w0    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          kube-scheduler-k8s-ctr                    1/1     Running   0          10m     192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system          metrics-server-5dd7b49d79-25cdj           1/1     Running   0          9m59s   172.20.0.253     k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    local-path-storage   local-path-provisioner-74f9666bc9-rxvrq   1/1     Running   0          10m     172.20.0.103     k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="nv">$ </span>kubectl get ciliumendpoints <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE            NAME                                      SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    cilium-monitoring    grafana-5c69859d9-n82rg                   9513                ready            172.20.0.209</span>
<span class="c">#    cilium-monitoring    prometheus-6fc896bc5d-m82wl               47077               ready            172.20.0.230</span>
<span class="c">#    kube-system          coredns-674b8bbfcf-bkc4b                  2750                ready            172.20.0.42</span>
<span class="c">#    kube-system          coredns-674b8bbfcf-jdxtw                  2750                ready            172.20.0.185</span>
<span class="c">#    kube-system          hubble-relay-5b48c999f9-vh8jq             17251               ready            172.20.0.156</span>
<span class="c">#    kube-system          hubble-ui-655f947f96-vv266                10805               ready            172.20.0.147</span>
<span class="c">#    kube-system          metrics-server-5dd7b49d79-25cdj           14866               ready            172.20.0.253</span>
<span class="c">#    local-path-storage   local-path-provisioner-74f9666bc9-rxvrq   11456               ready            172.20.0.103</span>

<span class="c"># ipam 모드 확인</span>
<span class="nv">$ </span>cilium config view | <span class="nb">grep</span> ^ipam
<span class="c"># =&gt; ipam                                              cluster-pool</span>

<span class="c"># iptables 확인</span>
<span class="nv">$ </span>iptables-save
<span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> filter <span class="nt">-S</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> mangle <span class="nt">-S</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> raw <span class="nt">-S</span>
</code></pre></div></div>

<ul>
  <li>[k8s-ctr] cilium 설치정보 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># cilium 상태 확인</span>
<span class="nv">$ </span>kubectl get cm <span class="nt">-n</span> kube-system cilium-config <span class="nt">-o</span> json | jq
<span class="nv">$ </span>cilium status
<span class="nv">$ </span>cilium config view
<span class="c"># =&gt; ...</span>
<span class="c">#    auto-direct-node-routes                           true</span>
<span class="c">#    ...</span>
<span class="c">#    routing-mode                                      native</span>
<span class="c">#    ...</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg status <span class="nt">--verbose</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg metrics list

<span class="c"># monitor</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg monitor
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg monitor <span class="nt">-v</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg monitor <span class="nt">-v</span> <span class="nt">-v</span>

<span class="c">## Filter for only the events related to endpoint</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg monitor <span class="nt">--related-to</span><span class="o">=</span>&lt;<span class="nb">id</span><span class="o">&gt;</span>

<span class="c">## Show notifications only for dropped packet events</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg monitor <span class="nt">--type</span> drop

<span class="c">## Don’t dissect packet payload, display payload in hex information</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg monitor <span class="nt">-v</span> <span class="nt">-v</span> <span class="nt">--hex</span>

<span class="c">## Layer7</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg monitor <span class="nt">-v</span> <span class="nt">--type</span> l7
</code></pre></div></div>

<ul>
  <li>네트워크 정보 확인 : <code class="language-plaintext highlighter-rouge">autoDirectNodeRoutes=true</code> 동작 이해</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># router 네트워크 인터페이스 정보 확인</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router ip <span class="nt">-br</span> <span class="nt">-c</span> <span class="nt">-4</span> addr
<span class="c"># =&gt; lo               UNKNOWN        127.0.0.1/8</span>
<span class="c">#    eth0             UP             10.0.2.15/24 metric 100</span>
<span class="c">#    eth1             UP             192.168.10.200/24</span>
<span class="c">#    eth2             UP             192.168.20.200/24</span>
<span class="c">#    loop1            UNKNOWN        10.10.1.200/24</span>
<span class="c">#    loop2            UNKNOWN        10.10.2.200/24</span>

<span class="c"># k8s node 네트워크 인터페이스 정보 확인</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> <span class="nt">-4</span> addr show dev eth1
<span class="c"># =&gt; 3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span>
<span class="c">#        altname enp0s9</span>
<span class="c">#        inet 192.168.10.100/24 brd 192.168.10.255 scope global eth1</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w1 ip <span class="nt">-c</span> <span class="nt">-4</span> addr show dev eth1
<span class="c"># =&gt; 3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span>
<span class="c">#        altname enp0s9</span>
<span class="c">#        inet 192.168.10.101/24 brd 192.168.10.255 scope global eth1</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w0 ip <span class="nt">-c</span> <span class="nt">-4</span> addr show dev eth1
<span class="c"># =&gt; 3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span>
<span class="c">#        altname enp0s9</span>
<span class="c">#        inet 192.168.20.100/24 brd 192.168.20.255 scope global eth1</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>

<span class="c"># 라우팅 정보 확인</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@router ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.10.1.0/24 dev loop1 proto kernel scope link src 10.10.1.200</span>
<span class="c">#    10.10.2.0/24 dev loop2 proto kernel scope link src 10.10.2.200</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.200</span>
<span class="c">#    192.168.20.0/24 dev eth2 proto kernel scope link src 192.168.20.200</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route | <span class="nb">grep </span>static
<span class="c"># =&gt; 10.10.0.0/16 via 192.168.10.200 dev eth1 proto static</span>
<span class="c">#    172.20.0.0/16 via 192.168.10.200 dev eth1 proto static</span>
<span class="c">#    192.168.20.0/24 via 192.168.10.200 dev eth1 proto static</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 192.168.10.0/24와 192.168.20.0/24 네트워크의 routing 등을 위해서 router에 static route 설정이 되어 있습니다.&lt;/span&gt;</span>

<span class="c">## --set routingMode=native --set autoDirectNodeRoutes=true 동작을 정확히 이해해보자!</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route
<span class="c"># =&gt; 10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    &lt;span style="color: green;"&gt;10.10.0.0/16 via 192.168.10.200 dev eth1 proto static&lt;/span&gt;</span>
<span class="c">#    172.20.0.0/24 via 172.20.0.201 dev cilium_host proto kernel src 172.20.0.201</span>
<span class="c">#    &lt;span style="color: green;"&gt;172.20.0.0/16 via 192.168.10.200 dev eth1 proto static&lt;/span&gt;</span>
<span class="c">#    172.20.0.201 dev cilium_host proto kernel scope link</span>
<span class="c">#    172.20.1.0/24 via 192.168.10.101 dev eth1 proto kernel</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.100</span>
<span class="c">#    &lt;span style="color: green;"&gt;192.168.20.0/24 via 192.168.10.200 dev eth1 proto static&lt;/span&gt;</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w1 ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    &lt;span style="color: green;"&gt;10.10.0.0/16 via 192.168.10.200 dev eth1 proto static&lt;/span&gt;</span>
<span class="c">#    172.20.0.0/24 via 192.168.10.100 dev eth1 proto kernel</span>
<span class="c">#    &lt;span style="color: green;"&gt;172.20.0.0/16 via 192.168.10.200 dev eth1 proto static&lt;/span&gt;</span>
<span class="c">#    172.20.1.0/24 via 172.20.1.197 dev cilium_host proto kernel src 172.20.1.197</span>
<span class="c">#    172.20.1.197 dev cilium_host proto kernel scope link</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.101</span>
<span class="c">#    &lt;span style="color: green;"&gt;192.168.20.0/24 via 192.168.10.200 dev eth1 proto static&lt;/span&gt;</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w0 ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    &lt;span style="color: green;"&gt;10.10.0.0/16 via 192.168.20.200 dev eth1 proto static&lt;/span&gt;</span>
<span class="c">#    &lt;span style="color: green;"&gt;172.20.0.0/16 via 192.168.20.200 dev eth1 proto static&lt;/span&gt;</span>
<span class="c">#    172.20.2.0/24 via 172.20.2.25 dev cilium_host proto kernel src 172.20.2.25</span>
<span class="c">#    172.20.2.25 dev cilium_host proto kernel scope link</span>
<span class="c">#    &lt;span style="color: green;"&gt;192.168.10.0/24 via 192.168.20.200 dev eth1 proto static&lt;/span&gt;</span>
<span class="c">#    192.168.20.0/24 dev eth1 proto kernel scope link src 192.168.20.100</span>

<span class="c"># 통신 확인</span>
<span class="nv">$ </span>ping <span class="nt">-c</span> 1 10.10.1.200     <span class="c"># router loop1 </span>
<span class="c"># =&gt; PING 10.10.1.200 (10.10.1.200) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 10.10.1.200: icmp_seq=1 ttl=64 time=0.780 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 10.10.1.200 ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 0.780/0.780/0.780/0.000 ms</span>
<span class="nv">$ </span>ping <span class="nt">-c</span> 1 192.168.20.100  <span class="c"># k8s-w0 eth1</span>
<span class="c"># =&gt; PING 192.168.20.100 (192.168.20.100) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 192.168.20.100: icmp_seq=1 ttl=63 time=1.82 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 192.168.20.100 ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 1.821/1.821/1.821/0.000 ms</span>

<span class="c"># 목적지까지 경우하는 라우팅 정보 제공</span>
<span class="c">## Path MTU (pmtu): 출발지에서 목적지까지 모든 네트워크 경로 상에서 통과할 수 있는 최대 패킷 크기(Byte), IP fragmentation 없이 전송 가능한 가장 큰 패킷 크기를 의미.</span>
<span class="c">## pmtu 1500: 전체 경로의 최소 MTU는 1500 , hops 2: 총 2단계 라우터/노드를 거쳐서 도달 , back 2: 응답도 동일한 hop 수로 돌아옴 </span>
<span class="nv">$ </span>tracepath <span class="nt">-n</span> 192.168.20.100
<span class="c"># =&gt;  1?: [LOCALHOST]                      pmtu 1500</span>
<span class="c">#     1:  192.168.10.200                                        2.759ms</span>
<span class="c">#     1:  192.168.10.200                                        0.994ms</span>
<span class="c">#     2:  192.168.20.100                                        1.461ms reached</span>
<span class="c">#         Resume: pmtu 1500 hops 2 back 2</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s-ctr(192.168.10.100)에서 k8s-w0(192.168.20.100)은 다른 네트워크이기 때문에&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   직접적으로 통신할 수 없고, router(192.168.10.200)를 거쳐서 routing되어 통신이 됩니다.&lt;/span&gt;</span>
</code></pre></div></div>

<hr />

<h2 id="native-routing-mode">Native Routing Mode</h2>

<h3 id="샘플-애플리케이션-배포-및-확인">샘플 애플리케이션 배포 및 확인</h3>

<ul>
  <li>샘플 애플리케이션 배포 : <code class="language-plaintext highlighter-rouge">cilium-dbg</code></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 샘플 애플리케이션 배포</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webpod
spec:
  replicas: 3
  selector:
    matchLabels:
      app: webpod
  template:
    metadata:
      labels:
        app: webpod
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - sample-app
            topologyKey: "kubernetes.io/hostname"
      containers:
      - name: webpod
        image: traefik/whoami
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: webpod
  labels:
    app: webpod
spec:
  selector:
    app: webpod
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
  type: ClusterIP
</span><span class="no">EOF
</span><span class="c"># =&gt; deployment.apps/webpod created</span>
<span class="c">#    service/webpod created</span>

<span class="c"># k8s-ctr 노드에 curl-pod 파드 배포</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: curl-pod
  labels:
    app: curl
spec:
  nodeName: k8s-ctr
  containers:
  - name: curl
    image: nicolaka/netshoot
    command: ["tail"]
    args: ["-f", "/dev/null"]
  terminationGracePeriodSeconds: 0
</span><span class="no">EOF
</span><span class="c"># =&gt; pod/curl-pod created</span>
</code></pre></div></div>

<ul>
  <li>확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 배포 확인</span>
<span class="nv">$ </span>kubectl get deploy,svc,ep webpod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                     READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES           SELECTOR</span>
<span class="c">#    deployment.apps/webpod   3/3     3            3           53s   webpod       traefik/whoami   app=webpod</span>
<span class="c">#    </span>
<span class="c">#    NAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE   SELECTOR</span>
<span class="c">#    service/webpod   ClusterIP   10.96.129.95   &lt;none&gt;        80/TCP    53s   app=webpod</span>
<span class="c">#    </span>
<span class="c">#    NAME               ENDPOINTS                                        AGE</span>
<span class="c">#    endpoints/webpod   172.20.0.131:80,172.20.1.217:80,172.20.2.73:80   53s</span>
<span class="nv">$ </span>kubectl get endpointslices <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>webpod
<span class="c"># =&gt; NAME           ADDRESSTYPE   PORTS   ENDPOINTS                               AGE</span>
<span class="c">#    webpod-njp7j   IPv4          80      172.20.0.131,172.20.2.73,172.20.1.217   65s</span>
<span class="nv">$ </span>kubectl get ciliumendpoints <span class="c"># IP 확인</span>
<span class="c"># =&gt; NAME                      SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    curl-pod                  21500               ready            172.20.0.89</span>
<span class="c">#    webpod-697b545f57-b46tz   17081               ready            172.20.0.131          # &lt;span style="color: green;"&gt;k8s-wctr&lt;/span&gt;</span>
<span class="c">#    webpod-697b545f57-66grn   17081               ready            172.20.1.217          # &lt;span style="color: green;"&gt;k8s-w1&lt;/span&gt;</span>
<span class="c">#    webpod-697b545f57-24ck5   17081               ready            172.20.2.73           # &lt;span style="color: green;"&gt;k8s-w0&lt;/span&gt;</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg ip list
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg endpoint list

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg service list
<span class="c"># =&gt; ...</span>
<span class="c">#    20   10.96.129.95:80/TCP     ClusterIP      1 =&gt; 172.20.0.131:80/TCP (active)</span>
<span class="c">#                                                2 =&gt; 172.20.1.217:80/TCP (active)</span>
<span class="c">#                                                3 =&gt; 172.20.2.73:80/TCP (active)</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg bpf lb list
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg bpf lb list | <span class="nb">grep </span>10.96.129.95
<span class="c"># =&gt; 10.96.129.95:80/TCP (3)        172.20.2.73:80/TCP (20) (3)</span>
<span class="c">#    10.96.129.95:80/TCP (0)        0.0.0.0:0 (20) (0) [ClusterIP, non-routable]</span>
<span class="c">#    10.96.129.95:80/TCP (1)        172.20.0.131:80/TCP (20) (1)</span>
<span class="c">#    10.96.129.95:80/TCP (2)        172.20.1.217:80/TCP (20) (2)</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 cilium의 load balancer가 각 파드의 IP을 확인하고, 해당 IP로 요청을 전달합니다.&lt;/span&gt;</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg bpf nat list

<span class="c"># map</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg map list | <span class="nb">grep</span> <span class="nt">-v</span> <span class="s1">'0             0'</span>
<span class="c"># =&gt; Name                           Num entries   Num errors   Cache enabled</span>
<span class="c">#    cilium_policy_v2_03166         3             0            true</span>
<span class="c">#    cilium_policy_v2_01270         3             0            true</span>
<span class="c">#    cilium_policy_v2_01641         3             0            true</span>
<span class="c">#    cilium_policy_v2_01688         3             0            true</span>
<span class="c">#    cilium_lb4_reverse_nat         20            0            true</span>
<span class="c">#    cilium_lxc                     13            0            true</span>
<span class="c">#    cilium_policy_v2_02965         3             0            true</span>
<span class="c">#    cilium_runtime_config          256           0            true</span>
<span class="c">#    cilium_ipcache_v2              22            0            true</span>
<span class="c">#    cilium_policy_v2_00459         2             0            true</span>
<span class="c">#    cilium_policy_v2_00222         3             0            true</span>
<span class="c">#    cilium_policy_v2_03535         3             0            true</span>
<span class="c">#    cilium_policy_v2_02230         3             0            true</span>
<span class="c">#    cilium_lb4_services_v2         45            0            true</span>
<span class="c">#    cilium_lb4_backends_v3         16            0            true</span>
<span class="c">#    cilium_lb4_reverse_sk          9             0            true</span>
<span class="c">#    cilium_policy_v2_00745         3             0            true</span>
<span class="c">#    cilium_policy_v2_01678         3             0            true</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg map get cilium_lb4_services_v2
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg map get cilium_lb4_services_v2 | <span class="nb">grep </span>10.96.129.95
<span class="c"># =&gt; Key                            Value                     State   Error</span>
<span class="c">#    10.96.129.95:80/TCP (3)        15 0[0] (20) [0x0 0x0]</span>
<span class="c">#    10.96.129.95:80/TCP (2)        16 0[0] (20) [0x0 0x0]</span>
<span class="c">#    10.96.129.95:80/TCP (0)        0 3[0] (20) [0x0 0x0]</span>
<span class="c">#    10.96.129.95:80/TCP (1)        14 0[0] (20) [0x0 0x0]   </span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg map get cilium_lb4_backends_v3
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg map get cilium_lb4_reverse_nat
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg map get cilium_ipcache_v2
</code></pre></div></div>

<h3 id="통신-확인-및-hubble로-모니터링">통신 확인 및 hubble로 모니터링</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 통신 확인 : 문제 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl webpod | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod-697b545f57-66grn</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s --connect-timeout 1 webpod | grep Hostname; echo "---" ; sleep 1; done'</span>
<span class="c"># =&gt; ---</span>
<span class="c">#    Hostname: webpod-697b545f57-b46tz</span>
<span class="c">#    ---</span>
<span class="c">#    Hostname: webpod-697b545f57-66grn</span>
<span class="c">#    ---  # &lt;span style="color: green;"&gt;👉 k8s-w0 노드에 배포된 webpod 파드에 대해서는 통신이 되지 않습니다.&lt;/span&gt;</span>
<span class="c">#    ---</span>
<span class="c">#    Hostname: webpod-697b545f57-b46tz</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s-ctr 노드와 k8s-w1 노드에 배포된 webpod 파드에 대해서는 통신이 되지만,&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   k8s-w0 노드에 배포된 webpod 파드에 대해서는 통신이 되지 않습니다.&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   왜냐하면, 노드간의 통신은 router에서 정적 라우팅을 통해 통신이 가능하지만,&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   파드 간의 통신에 대해서는 routing 처리가 되어있지 않기 때문입니다.&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   이번 포스트에서는 Encapsulation Mode를 통해 이 문제를 해결해보고&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   다음 포스트에서 Native Routing Mode를 통해 이 문제를 해결해보겠습니다.&lt;/span&gt;</span>

<span class="c"># k8s-w0 노드에 배포된 webpod 파드 IP 지정</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">WEBPOD</span><span class="o">=</span><span class="si">$(</span>kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>webpod <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-w0 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].status.podIP}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$WEBPOD</span>
<span class="c"># =&gt; 172.20.2.73</span>

<span class="c"># 신규 터미널 [router]</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> any icmp <span class="nt">-nn</span>

<span class="c"># </span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> ping <span class="nt">-c</span> 2 <span class="nt">-w</span> 1 <span class="nt">-W</span> 1 <span class="nv">$WEBPOD</span>

<span class="c"># 신규 터미널 [router] : 라우팅이 어떻게 되는가?</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> any icmp <span class="nt">-nn</span>
<span class="c"># =&gt; 14:29:00.156370 eth1  In  IP 172.20.0.89 &gt; 172.20.2.73: ICMP echo request, id 35, seq 1, length 64</span>
<span class="c">#    14:29:00.156388 eth0  Out IP 172.20.0.89 &gt; 172.20.2.73: ICMP echo request, id 35, seq 1, length 64</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s-ctr 노드의 파드(172.20.0.89)에서 k8s-w0 노드의 파드(172.20.2.73)로 ping을 보내면,&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   서로간의 라우팅이 되어있지 않기 때문에 ping이 실패합니다.&lt;/span&gt;</span>

<span class="c"># 신규 터미널 [router]</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route
<span class="nv">$ </span>ip route get 172.20.2.36   <span class="c"># &lt;span style="color: green;"&gt;👉 172.20.2.36으로 통신할때 사용되는 라우팅 정보 확인하는 명령어&lt;/span&gt;</span>
<span class="c"># =&gt; 172.20.2.36 via 10.0.2.2 dev eth0 src 10.0.2.15 uid 0</span>

<span class="c"># [k8s-ctr]에서 반복 호출</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s --connect-timeout 1 webpod | grep Hostname; echo "---" ; sleep 1; done'</span>

<span class="c"># 신규 터미널 [router]</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> any tcp port 80 <span class="nt">-nn</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s-w0노드의 파드로 통신을 시도하여 통신이 안 될 때 마다 router의 tcpdump에 통신이 안 되는 로그가 찍힙니다.&lt;/span&gt;</span>

<span class="c"># hubble 확인</span>
<span class="c"># hubble ui 웹 접속 주소 확인 : default 네임스페이스 확인</span>
<span class="nv">$ NODEIP</span><span class="o">=</span><span class="si">$(</span>ip <span class="nt">-4</span> addr show eth1 | <span class="nb">grep</span> <span class="nt">-oP</span> <span class="s1">'(?&lt;=inet\s)\d+(\.\d+){3}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"http://</span><span class="nv">$NODEIP</span><span class="s2">:30003"</span>
<span class="c"># =&gt; http://192.168.10.100:30003</span>

<span class="c"># hubble relay 포트 포워딩 실행</span>
<span class="nv">$ </span>cilium hubble port-forward&amp;
<span class="c"># =&gt; ℹ️  Hubble Relay is available at 127.0.0.1:4245</span>
<span class="nv">$ </span>hubble status
<span class="c"># =&gt; Healthcheck (via localhost:4245): Ok</span>

<span class="c"># flow log 모니터링</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--protocol</span> tcp <span class="nt">--pod</span> curl-pod
<span class="c"># =&gt; ...</span>
<span class="c">#    Aug  9 05:38:54.615: default/curl-pod:46490 (ID:21500) -&gt; default/webpod-697b545f57-66grn:80 (ID:17081) to-network FORWARDED (TCP Flags: ACK, FIN)</span>
<span class="c">#    Aug  9 05:38:54.618: default/curl-pod:46490 (ID:21500) &lt;- default/webpod-697b545f57-66grn:80 (ID:17081) to-endpoint FORWARDED (TCP Flags: ACK, FIN)</span>
<span class="c">#    Aug  9 05:38:54.618: default/curl-pod:46490 (ID:21500) -&gt; default/webpod-697b545f57-66grn:80 (ID:17081) to-network FORWARDED (TCP Flags: ACK)</span>
<span class="c">#    Aug  9 05:38:55.627: default/curl-pod (ID:21500) &lt;&gt; 10.96.129.95:80 (world) pre-xlate-fwd TRACED (TCP)</span>
<span class="c">#    Aug  9 05:38:55.627: default/curl-pod (ID:21500) &lt;&gt; &lt;span style="color: green;"&gt;default/webpod-697b545f57-24ck5:80&lt;/span&gt; (ID:17081) post-xlate-fwd TRANSLATED (TCP)</span>
<span class="c">#    Aug  9 05:38:55.628: default/curl-pod:37198 (ID:21500) -&gt; &lt;span style="color: green;"&gt;default/webpod-697b545f57-24ck5:80&lt;/span&gt; (ID:17081) to-network FORWARDED &lt;span style="color: green;"&gt;(TCP Flags: SYN)&lt;/span&gt;</span>
<span class="c">#    &lt;span style="color: green;"&gt;👉 k8s-w0 노드에 배포된 webpod 파드(default/webpod-697b545f57-24ck5)로 통신을 시도할 때,&lt;/span&gt;</span>
<span class="c">#    &lt;span style="color: green;"&gt;    라우팅이 되지 않아 SYN 패킷에 대한 ACK 패킷이 오지 않기 때문에, 통신이 되지 않습니다.&lt;/span&gt;</span>
<span class="c">#    Aug  9 05:38:57.528: default/curl-pod:46498 (ID:21500) -&gt; default/webpod-697b545f57-66grn:80 (ID:17081) to-endpoint FORWARDED (TCP Flags: SYN)</span>
<span class="c">#    Aug  9 05:38:57.528: default/curl-pod:46498 (ID:21500) &lt;- default/webpod-697b545f57-66grn:80 (ID:17081) to-network FORWARDED (TCP Flags: SYN, ACK)</span>
<span class="c">#    Aug  9 05:38:57.528: default/curl-pod:46498 (ID:21500) -&gt; default/webpod-697b545f57-66grn:80 (ID:17081) to-endpoint FORWARDED (TCP Flags: ACK)</span>
<span class="c">#    Aug  9 05:38:57.529: default/curl-pod:46498 (ID:21500) -&gt; default/webpod-697b545f57-66grn:80 (ID:17081) to-endpoint FORWARDED (TCP Flags: ACK, PSH)</span>
</code></pre></div></div>

<hr />

<h2 id="overlay-network-encapsulated-mode">Overlay Network (Encapsulated) Mode</h2>

<ul>
  <li>앞에서 살펴본 것과 같이 k8s-ctr 노드와 k8s-w0 노드가 다른 네트워크에 있는 경우,
라우팅 장비에서 라우팅 룰을 추가해서 노드간에는 통신이 가능하지만,
파드 간의 통신은 라우팅 룰이 없기 때문에 통신이 되지 않습니다.</li>
  <li>이러한 경우에도 파드 간의 통신을 가능하게 하기 위해서 Cilium에서는 Overlay Network(Encapsulated) Mode를 제공합니다.</li>
  <li>VXLAN과 GENEVE 등을 지원하는데, 이번 포스트에서는 VXLAN을 통해 통신이 되도록 해보겠습니다.</li>
</ul>

<h3 id="vxlan-설정">VXLAN 설정</h3>

<p><a href="https://docs.cilium.io/en/stable/network/concepts/routing/">Docs</a></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># [커널 구성 옵션] Requirements for Tunneling and Routing</span>
<span class="nv">$ </span><span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'CONFIG_VXLAN=y|CONFIG_VXLAN=m|CONFIG_GENEVE=y|CONFIG_GENEVE=m|CONFIG_FIB_RULES=y'</span> /boot/config-<span class="si">$(</span><span class="nb">uname</span> <span class="nt">-r</span><span class="si">)</span>
<span class="nv">CONFIG_FIB_RULES</span><span class="o">=</span>y <span class="c"># 커널에 내장됨</span>
<span class="nv">CONFIG_VXLAN</span><span class="o">=</span>m <span class="c"># 모듈로 컴파일됨 → 커널에 로드해서 사용</span>
<span class="nv">CONFIG_GENEVE</span><span class="o">=</span>m <span class="c"># 모듈로 컴파일됨 → 커널에 로드해서 사용</span>

<span class="c">#  커널 로드</span>
<span class="nv">$ </span>lsmod | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'vxlan|geneve'</span>
<span class="nv">$ </span>modprobe vxlan <span class="c"># modprobe geneve</span>
<span class="nv">$ </span>lsmod | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'vxlan|geneve'</span>
<span class="c"># =&gt; vxlan                 147456  0</span>
<span class="c">#    ip6_udp_tunnel         16384  1 vxlan</span>
<span class="c">#    udp_tunnel             36864  1 vxlan</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 modprobe 명령어로 커널 모듈이 로딩 되어 vxlan과 필요 모듈들이 활성화 되었습니다.&lt;/span&gt;</span>

<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w0 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>modprobe vxlan <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    &gt;&gt; node : k8s-w0 &lt;&lt;</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w0 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>lsmod | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'vxlan|geneve'</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    vxlan                 147456  0</span>
<span class="c">#    ip6_udp_tunnel         16384  1 vxlan</span>
<span class="c">#    udp_tunnel             36864  1 vxlan</span>
<span class="c">#    &gt;&gt; node : k8s-w0 &lt;&lt;</span>
<span class="c">#    vxlan                 147456  0</span>
<span class="c">#    ip6_udp_tunnel         16384  1 vxlan</span>
<span class="c">#    udp_tunnel             36864  1 vxlan</span>

<span class="c"># k8s-w1 노드에 배포된 webpod 파드 IP 지정</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">WEBPOD1</span><span class="o">=</span><span class="si">$(</span>kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>webpod <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-w1 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].status.podIP}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$WEBPOD1</span>
<span class="c"># =&gt; 172.20.1.217</span>

<span class="c"># 반복 ping 실행해두기</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> ping <span class="nv">$WEBPOD1</span>


<span class="c"># 업그레이드</span>
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--namespace</span> kube-system <span class="nt">--version</span> 1.18.0 <span class="nt">--reuse-values</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">routingMode</span><span class="o">=</span>tunnel <span class="nt">--set</span> <span class="nv">tunnelProtocol</span><span class="o">=</span>vxlan <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">autoDirectNodeRoutes</span><span class="o">=</span><span class="nb">false</span> <span class="nt">--set</span> <span class="nv">installNoConntrackIptablesRules</span><span class="o">=</span><span class="nb">false</span>
<span class="c"># =&gt; Release "cilium" has been upgraded. Happy Helming!</span>
<span class="c">#    ...</span>

<span class="c"># 설정을 적용하기 위해서 Cilium DaemonSet을 재시작합니다.</span>
<span class="nv">$ </span>kubectl rollout restart <span class="nt">-n</span> kube-system ds/cilium

<span class="c"># 설정 확인</span>
<span class="nv">$ </span>cilium features status
<span class="nv">$ </span>cilium features status | <span class="nb">grep </span>datapath_network
<span class="c"># =&gt; Cilium   Agents</span>
<span class="c">#    Uniform  Name                             Labels              k8s-ctr  k8s-w0  k8s-w1</span>
<span class="c">#    Yes      cilium_feature_datapath_network  mode=&lt;span style="color: green;"&gt;overlay-vxlan&lt;/span&gt;  1        1        1</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium status | <span class="nb">grep</span> ^Routing
<span class="c"># =&gt; Routing:                 Network: &lt;span style="color: green;"&gt;Tunnel [vxlan]&lt;/span&gt;   Host: BPF</span>
<span class="nv">$ </span>cilium config view | <span class="nb">grep </span>tunnel
<span class="c"># =&gt; routing-mode                                      &lt;span style="color: green;"&gt;tunnel&lt;/span&gt;</span>
<span class="c">#    tunnel-protocol                                   &lt;span style="color: green;"&gt;vxlan&lt;/span&gt;</span>
<span class="c">#    tunnel-source-port-range                          0-0</span>

<span class="c"># cilium_vxlan 확인</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> addr show dev cilium_vxlan
<span class="c"># =&gt; 26: cilium_vxlan: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN group default</span>
<span class="c">#        link/ether 42:59:64:e0:f6:38 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet6 fe80::4059:64ff:fee0:f638/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w0 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> addr show dev cilium_vxlan <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    8: cilium_vxlan: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN group default</span>
<span class="c">#        link/ether 02:c4:af:d7:83:fc brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet6 fe80::c4:afff:fed7:83fc/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w0 &lt;&lt;</span>
<span class="c">#    8: cilium_vxlan: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN group default</span>
<span class="c">#        link/ether ee:f6:72:2b:b9:b9 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet6 fe80::ecf6:72ff:fe2b:b9b9/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>

<span class="c"># 라우팅 정보 확인 : k8s node 간 다른 네트워크 대역에 있더라도, 파드의 네트워크 대역 정보가 라우팅에 올라왔다!</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route | <span class="nb">grep </span>cilium_host
<span class="c"># =&gt; 172.20.0.0/24 via 172.20.0.201 dev cilium_host proto kernel src 172.20.0.201</span>
<span class="c">#    172.20.0.201 dev cilium_host proto kernel scope link</span>
<span class="c">#    172.20.1.0/24 via 172.20.0.201 dev cilium_host proto kernel src 172.20.0.201 mtu 1450</span>
<span class="c">#    172.20.2.0/24 via 172.20.0.201 dev cilium_host proto kernel src 172.20.0.201 mtu 1450 </span>

<span class="nv">$ </span>ip route get 172.20.1.10
<span class="c"># =&gt; 172.20.1.10 dev cilium_host src 172.20.0.201 uid 0</span>
<span class="c">#        cache mtu 1450</span>
<span class="nv">$ </span>ip route get 172.20.2.10
<span class="c"># =&gt; 172.20.2.10 dev cilium_host src 172.20.0.201 uid 0</span>
<span class="c">#        cache mtu 1450</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 MTU는 Maximum Transmission Unit의 약자로, 네트워크에서 전송할 수 있는 최대 패킷 크기를 의미합니다.&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   본래의 MTU는 1500이지만, VXLAN이 이미 50 bytes를 사용하기 때문에&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   최대 1450 bytes까지 전송할 수 있는것을 확인할 수 있습니다.&lt;/span&gt;</span>

<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w0 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> route | <span class="nb">grep </span>cilium_host <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    172.20.0.0/24 via 172.20.1.197 dev cilium_host proto kernel src 172.20.1.197 mtu 1450</span>
<span class="c">#    172.20.1.0/24 via 172.20.1.197 dev cilium_host proto kernel src 172.20.1.197</span>
<span class="c">#    172.20.1.197 dev cilium_host proto kernel scope link</span>
<span class="c">#    172.20.2.0/24 via 172.20.1.197 dev cilium_host proto kernel src 172.20.1.197 mtu 1450</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w0 &lt;&lt;</span>
<span class="c">#    172.20.0.0/24 via 172.20.2.25 dev cilium_host proto kernel src 172.20.2.25 mtu 1450</span>
<span class="c">#    172.20.1.0/24 via 172.20.2.25 dev cilium_host proto kernel src 172.20.2.25 mtu 1450</span>
<span class="c">#    172.20.2.0/24 via 172.20.2.25 dev cilium_host proto kernel src 172.20.2.25</span>
<span class="c">#    172.20.2.25 dev cilium_host proto kernel scope link</span>

<span class="c"># cilium 파드 이름 지정</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD0</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-ctr <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD1</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-w1  <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD2</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-w0  <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$CILIUMPOD0</span> <span class="nv">$CILIUMPOD1</span> <span class="nv">$CILIUMPOD2</span>
<span class="c"># =&gt; cilium-4jf9p cilium-dqgbw cilium-sqx45</span>

<span class="c"># router 역할 IP 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$CILIUMPOD0</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium status <span class="nt">--all-addresses</span> | <span class="nb">grep </span>router
<span class="c"># =&gt;   172.20.0.201 (router)</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$CILIUMPOD1</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium status <span class="nt">--all-addresses</span> | <span class="nb">grep </span>router
<span class="c"># =&gt;   172.20.1.197 (router)</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$CILIUMPOD2</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium status <span class="nt">--all-addresses</span> | <span class="nb">grep </span>router
<span class="c"># =&gt;   172.20.2.25 (router)</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg bpf ipcache list
<span class="c"># =&gt; IP PREFIX/ADDRESS   IDENTITY</span>
<span class="c">#    ...</span>
<span class="c">#    172.20.0.201/32     identity=6 encryptkey=0 tunnelendpoint=192.168.10.100 flags=hastunnel</span>
<span class="c">#    172.20.2.25/32      identity=6 encryptkey=0 tunnelendpoint=192.168.20.100 flags=hastunnel</span>
<span class="c">#    172.20.1.197/32     identity=1 encryptkey=0 tunnelendpoint=0.0.0.0 flags=&lt;none&gt;</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nv">$CILIUMPOD0</span> <span class="nt">--</span> cilium-dbg bpf ipcache list
<span class="c"># =&gt; IP PREFIX/ADDRESS   IDENTITY</span>
<span class="c">#    ...</span>
<span class="c">#    172.20.0.201/32     identity=1 encryptkey=0 tunnelendpoint=0.0.0.0 flags=&lt;none&gt;</span>
<span class="c">#    172.20.2.25/32      identity=6 encryptkey=0 tunnelendpoint=192.168.20.100 flags=hastunnel</span>
<span class="c">#    172.20.1.197/32     identity=6 encryptkey=0 tunnelendpoint=192.168.10.101 flags=hastunnel</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nv">$CILIUMPOD1</span> <span class="nt">--</span> cilium-dbg bpf ipcache list
<span class="c"># =&gt; IP PREFIX/ADDRESS   IDENTITY</span>
<span class="c">#    ...</span>
<span class="c">#    172.20.1.197/32     identity=1 encryptkey=0 tunnelendpoint=0.0.0.0 flags=&lt;none&gt;</span>
<span class="c">#    172.20.0.201/32     identity=6 encryptkey=0 tunnelendpoint=192.168.10.100 flags=hastunnel</span>
<span class="c">#    172.20.2.25/32      identity=6 encryptkey=0 tunnelendpoint=192.168.20.100 flags=hastunnel</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nv">$CILIUMPOD2</span> <span class="nt">--</span> cilium-dbg bpf ipcache list
<span class="c"># =&gt; IP PREFIX/ADDRESS   IDENTITY</span>
<span class="c">#    ...</span>
<span class="c">#    172.20.0.201/32     identity=6 encryptkey=0 tunnelendpoint=192.168.10.100 flags=hastunnel</span>
<span class="c">#    172.20.2.25/32      identity=1 encryptkey=0 tunnelendpoint=0.0.0.0 flags=&lt;none&gt;</span>
<span class="c">#    172.20.1.197/32     identity=6 encryptkey=0 tunnelendpoint=192.168.10.101 flags=hastunnel</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium-dbg bpf socknat list
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nv">$CILIUMPOD0</span> <span class="nt">--</span> cilium-dbg bpf socknat list
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nv">$CILIUMPOD1</span> <span class="nt">--</span> cilium-dbg bpf socknat list
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nv">$CILIUMPOD2</span> <span class="nt">--</span> cilium-dbg bpf socknat list
</code></pre></div></div>

<h3 id="파드간-통신-확인">파드간 통신 확인</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 통신 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl webpod | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod-697b545f57-b46tz</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s --connect-timeout 1 webpod | grep Hostname; echo "---" ; sleep 1; done'</span>
<span class="c"># =&gt; ---</span>
<span class="c">#    Hostname: webpod-697b545f57-b46tz</span>
<span class="c">#    ---</span>
<span class="c">#    Hostname: webpod-697b545f57-24ck5  # &lt;span style="color: green;"&gt;👉 k8s-w0 노드에 배포된 webpod 파드에 대해서도 통신이 됩니다.&lt;/span&gt;</span>
<span class="c">#    ---</span>
<span class="c">#    Hostname: webpod-697b545f57-66grn</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 VXLAN 설정 후 이전에는 통신이 되지 않던 k8s-w0 노드에 배포된 webpod 파드에 대해서도 통신이 됩니다.&lt;/span&gt;</span>

<span class="c"># k8s-w0 노드에 배포된 webpod 파드 IP 지정</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">WEBPOD</span><span class="o">=</span><span class="si">$(</span>kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>webpod <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-w0 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].status.podIP}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$WEBPOD</span>
<span class="c"># =&gt; 172.20.2.73</span>

<span class="c"># 신규 터미널 [router]</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> any udp port 8472 <span class="nt">-nn</span>

<span class="c"># [k8s-ctr] 에서 ping 실행</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> ping <span class="nt">-c</span> 2 <span class="nt">-w</span> 1 <span class="nt">-W</span> 1 <span class="nv">$WEBPOD</span>
<span class="c"># =&gt; PING 172.20.2.73 (172.20.2.73) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 172.20.2.73: icmp_seq=1 ttl=63 time=1.77 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 172.20.2.73 ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 1.769/1.769/1.769/0.000 ms</span>
<span class="c">#    command terminated with exit code 1</span>

<span class="c"># [router]에서 tcpdump 확인 (VXLAN 포트 8472/udp로 통신이 되는지 확인)</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> any udp port 8472 <span class="nt">-nn</span>
<span class="c"># =&gt; 16:17:25.514596 eth1  In  IP 192.168.10.100.56046 &gt; 192.168.20.100.8472: OTV, flags [I] (0x08), overlay 0, instance 21500</span>
<span class="c">#    IP 172.20.0.89 &gt; 172.20.2.73: ICMP echo request, id 11684, seq 1, length 64</span>
<span class="c">#    16:17:25.514636 eth2  Out IP 192.168.10.100.56046 &gt; 192.168.20.100.8472: OTV, flags [I] (0x08), overlay 0, instance 21500</span>
<span class="c">#    IP 172.20.0.89 &gt; 172.20.2.73: ICMP echo request, id 11684, seq 1, length 64</span>
<span class="c">#    16:17:25.515307 eth2  In  IP 192.168.20.100.59302 &gt; 192.168.10.100.8472: OTV, flags [I] (0x08), overlay 0, instance 17081</span>
<span class="c">#    IP 172.20.2.73 &gt; 172.20.0.89: ICMP echo reply, id 11684, seq 1, length 64</span>
<span class="c">#    16:17:25.515315 eth1  Out IP &lt;span style="color: green;"&gt;192.168.20.100.59302 &gt; 192.168.10.100.8472&lt;/span&gt;: OTV, flags [I] (0x08), overlay 0, instance 17081</span>
<span class="c">#    IP &lt;span style="color: green;"&gt;172.20.2.73 &gt; 172.20.0.89&lt;/span&gt;: ICMP echo reply, id 11684, seq 1, length 64</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 VXLAN을 통해 파드 IP간 통신이 노드간 IP로 캡슐화되어 통신이 되는 것을 확인할 수 있습니다.&lt;/span&gt;</span>

<span class="c"># 신규 터미널 [router] : 라우팅이 어떻게 되는가?</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> any icmp <span class="nt">-nn</span>
<span class="c"># =&gt; (없음)</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 VXLAN을 통해 캡슐화된 패킷으로 통신이 되기 때문에 직접적으로 ICMP(ping) 패킷은 보이지 않습니다.&lt;/span&gt;</span>

<span class="c"># 반복 접속</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl webpod | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod-697b545f57-b46tz</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s --connect-timeout 1 webpod | grep Hostname; echo "---" ; sleep 1; done'</span>

<span class="c"># 신규 터미널 [router]</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> any udp port 8472 <span class="nt">-w</span> /tmp/vxlan.pcap
<span class="nv">$ </span>tshark <span class="nt">-r</span> /tmp/vxlan.pcap <span class="nt">-d</span> udp.port<span class="o">==</span>8472,vxlan
<span class="c"># =&gt;     1   0.000000  172.20.0.89 → 172.20.2.73  TCP 130 53224 → 80 [SYN] Seq=0 Win=64860 Len=0 MSS=1410 SACK_PERM TSval=2585589520 TSecr=0 WS=128</span>
<span class="c">#        2   0.000015  172.20.0.89 → 172.20.2.73  TCP 130 [TCP Retransmission] 53224 → 80 [SYN] Seq=0 Win=64860 Len=0 MSS=1410 SACK_PERM TSval=2585589520 TSecr=0 WS=128</span>
<span class="c">#        3   0.000633  172.20.2.73 → 172.20.0.89  TCP 130 80 → 53224 [SYN, ACK] Seq=0 Ack=1 Win=64308 Len=0 MSS=1410 SACK_PERM TSval=3020660677 TSecr=2585589520 WS=128</span>
<span class="c">#        4   0.000637  172.20.2.73 → 172.20.0.89  TCP 130 [TCP Retransmission] 80 → 53224 [SYN, ACK] Seq=0 Ack=1 Win=64308 Len=0 MSS=1410 SACK_PERM TSval=3020660677 TSecr=2585589520 WS=128</span>
<span class="c">#        5   0.001244  172.20.0.89 → 172.20.2.73  TCP 122 53224 → 80 [ACK] Seq=1 Ack=1 Win=64896 Len=0 TSval=2585589521 TSecr=3020660677</span>
<span class="c">#        6   0.001245  172.20.0.89 → 172.20.2.73  TCP 122 [TCP Dup ACK 5#1] 53224 → 80 [ACK] Seq=1 Ack=1 Win=64896 Len=0 TSval=2585589521 TSecr=3020660677</span>
<span class="c">#        7   0.002239  172.20.0.89 → 172.20.2.73  HTTP 192 GET / HTTP/1.1</span>
<span class="c">#        8   0.002247  172.20.0.89 → 172.20.2.73  TCP 192 [TCP Retransmission] 53224 → 80 [PSH, ACK] Seq=1 Ack=1 Win=64896 Len=70 TSval=2585589522 TSecr=3020660677</span>
<span class="c">#        9   0.002625  172.20.2.73 → 172.20.0.89  TCP 122 80 → 53224 [ACK] Seq=1 Ack=71 Win=64256 Len=0 TSval=3020660679 TSecr=2585589522</span>
<span class="c">#       10   0.002628  172.20.2.73 → 172.20.0.89  TCP 122 [TCP Dup ACK 9#1] 80 → 53224 [ACK] Seq=1 Ack=71 Win=64256 Len=0 TSval=3020660679 TSecr=2585589522</span>
<span class="c">#       11   0.004215  172.20.2.73 → 172.20.0.89  HTTP 441 HTTP/1.1 200 OK  (text/plain)</span>
<span class="c">#       12   0.004221  172.20.2.73 → 172.20.0.89  TCP 441 [TCP Retransmission] 80 → 53224 [PSH, ACK] Seq=1 Ack=71 Win=64256 Len=319 TSval=3020660680 TSecr=2585589522</span>
<span class="c">#       13   0.004783  172.20.0.89 → 172.20.2.73  TCP 122 53224 → 80 [ACK] Seq=71 Ack=320 Win=64640 Len=0 TSval=2585589525 TSecr=3020660680</span>
<span class="c">#       14   0.004785  172.20.0.89 → 172.20.2.73  TCP 122 [TCP Dup ACK 13#1] 53224 → 80 [ACK] Seq=71 Ack=320 Win=64640 Len=0 TSval=2585589525 TSecr=3020660680</span>
<span class="c">#       15   0.005245  172.20.0.89 → 172.20.2.73  TCP 122 53224 → 80 [FIN, ACK] Seq=71 Ack=320 Win=64640 Len=0 TSval=2585589525 TSecr=3020660680</span>
<span class="c">#       16   0.005248  172.20.0.89 → 172.20.2.73  TCP 122 [TCP Retransmission] 53224 → 80 [FIN, ACK] Seq=71 Ack=320 Win=64640 Len=0 TSval=2585589525 TSecr=3020660680</span>
<span class="c">#       17   0.005631  172.20.2.73 → 172.20.0.89  TCP 122 80 → 53224 [FIN, ACK] Seq=320 Ack=72 Win=64256 Len=0 TSval=3020660682 TSecr=2585589525</span>
<span class="c">#       18   0.005633  172.20.2.73 → 172.20.0.89  TCP 122 [TCP Retransmission] 80 → 53224 [FIN, ACK] Seq=320 Ack=72 Win=64256 Len=0 TSval=3020660682 TSecr=2585589525</span>
<span class="c">#       19   0.006526  172.20.0.89 → 172.20.2.73  TCP 122 53224 → 80 [ACK] Seq=72 Ack=321 Win=64640 Len=0 TSval=2585589526 TSecr=3020660682</span>
<span class="c">#       20   0.006529  172.20.0.89 → 172.20.2.73  TCP 122 [TCP Dup ACK 19#1] 53224 → 80 [ACK] Seq=72 Ack=321 Win=64640 Len=0 TSval=2585589526 TSecr=3020660682</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 tshark로도 VXLAN 캡슐화된 패킷을 해석할 수 있지만 조금 더 원활한 해석을 위해서 termshark를 사용해보겠습니다.&lt;/span&gt;</span>

<span class="nv">$ </span>termshark <span class="nt">-r</span> /tmp/vxlan.pcap
<span class="c"># =&gt; termshark 2.4.0  |  vxlan.pcap                                                         Analysis    Misc</span>
<span class="c">#    ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓</span>
<span class="c">#    ┃Filter:                                                                               &lt;Apply&gt; &lt;Recent&gt; ┃</span>
<span class="c">#    ┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛</span>
<span class="c">#     No. -  Time -      Source -           Dest -             Proto -  Length -  Info -                     ▲</span>
<span class="c">#     2      0.000015    192.168.10.100     192.168.20.100     UDP      130       56560 → 8472 Len=82</span>
<span class="c">#     3      0.000633    192.168.20.100     192.168.10.100     UDP      130       38192 → 8472 Len=82        █</span>
<span class="c">#     4      0.000637    192.168.20.100     192.168.10.100     UDP      130       38192 → 8472 Len=82</span>
<span class="c">#     5      0.001244    192.168.10.100     192.168.20.100     UDP      122       56560 → 8472 Len=74</span>
<span class="c">#     6      0.001245    192.168.10.100     192.168.20.100     UDP      122       56560 → 8472 Len=74</span>
<span class="c">#     7      0.002239    192.168.10.100     192.168.20.100     UDP      192       56560 → 8472 Len=144       ▼</span>
<span class="c">#    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>
<span class="c">#    [+] Frame 2: 130 bytes on wire (1040 bits), 130 bytes captured (1040 bits) [=]</span>
<span class="c">#    [+] Linux cooked capture v2</span>
<span class="c">#    [+] Internet Protocol Version 4, Src: 192.168.10.100, Dst: 192.168.20.100</span>
<span class="c">#    [+] User Datagram Protocol, Src Port: 56560, Dst Port: 8472</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 기본 termshark 명령어로는 VXLAN 캡슐화된 패킷을 해석할 수 없어서 8472/udp로 캡슐화된 패킷이 보이지 않습니다.&lt;/span&gt;</span>

<span class="nv">$ </span>termshark <span class="nt">-r</span> /tmp/vxlan.pcap <span class="nt">-d</span> udp.port<span class="o">==</span>8472,vxlan
<span class="c"># =&gt; termshark 2.4.0  |  vxlan.pcap                                                         Analysis    Misc</span>
<span class="c">#    ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓</span>
<span class="c">#    ┃Filter:                                                                               &lt;Apply&gt; &lt;Recent&gt; ┃</span>
<span class="c">#    ┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛</span>
<span class="c">#     No. Time - Source - Dest -   Prot Lengt Info -                                                         ▲</span>
<span class="c">#     1   0.0000 172.20.0 172.20.2 TCP  130   53224 → 80 [SYN] Seq=0 Win=64860 Len=0 MSS=1410 SACK_PERM TSva</span>
<span class="c">#     2   0.0000 172.20.0 172.20.2 TCP  130   [TCP Retransmission] 53224 → 80 [SYN] Seq=0 Win=64860 Len=0 MS █</span>
<span class="c">#     3   0.0006 172.20.2 172.20.0 TCP  130   80 → 53224 [SYN, ACK] Seq=0 Ack=1 Win=64308 Len=0 MSS=1410 SAC</span>
<span class="c">#     4   0.0006 172.20.2 172.20.0 TCP  130   [TCP Retransmission] 80 → 53224 [SYN, ACK] Seq=0 Ack=1 Win=643</span>
<span class="c">#     5   0.0012 172.20.0 172.20.2 TCP  122   53224 → 80 [ACK] Seq=1 Ack=1 Win=64896 Len=0 TSval=2585589521</span>
<span class="c">#     6   0.0012 172.20.0 172.20.2 TCP  122   [TCP Dup ACK 5#1] 53224 → 80 [ACK] Seq=1 Ack=1 Win=64896 Len=0</span>
<span class="c">#     7   0.0022 172.20.0 172.20.2 HTTP 192   GET / HTTP/1.1</span>
<span class="c">#     8   0.0022 172.20.0 172.20.2 TCP  192   [TCP Retransmission] 53224 → 80 [PSH, ACK] Seq=1 Ack=1 Win=648</span>
<span class="c">#     9   0.0026 172.20.2 172.20.0 TCP  122   80 → 53224 [ACK] Seq=1 Ack=71 Win=64256 Len=0 TSval=3020660679</span>
<span class="c">#     10  0.0026 172.20.2 172.20.0 TCP  122   [TCP Dup ACK 9#1] 80 → 53224 [ACK] Seq=1 Ack=71 Win=64256 Len=</span>
<span class="c">#     11  0.0042 172.20.2 172.20.0 HTTP 441   HTTP/1.1 200 OK  (text/plain)                                  ▼</span>
<span class="c">#    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>
<span class="c">#    [+] Frame 7: 192 bytes on wire (1536 bits), 192 bytes captured (1536 bits)</span>
<span class="c">#    [+] Linux cooked capture v2 [=]</span>
<span class="c">#    [+] Internet Protocol Version 4, &lt;span style="color: green; border: 2px solid rgba(255, 0, 0, 0.5); padding: 1px 4px;"&gt;Src: 192.168.10.100, Dst: 192.168.20.100&lt;/span&gt;</span>
<span class="c">#    [+] User Datagram Protocol, Src Port: 56560, Dst Port: 8472</span>
<span class="c">#    [+] &lt;span style="color: green; border: 2px solid rgba(255, 0, 0, 0.5); padding: 1px 4px;"&gt;Virtual eXtensible Local Area Network&lt;/span&gt;</span>
<span class="c">#    [+] Ethernet II, Src: 46:02:28:c8:e7:b6 (46:02:28:c8:e7:b6), Dst: ca:7a:5c:b2:2c:4a (ca:7a:5c:b2:2c:4a)</span>
<span class="c">#    [+] Internet Protocol Version 4, Src: &lt;span style="color: green; border: 2px solid rgba(255, 0, 0, 0.5); padding: 1px 4px;"&gt;172.20.0.89, Dst: 172.20.2.73&lt;/span&gt;</span>
<span class="c">#    [+] Transmission Control Protocol, Src Port: 53224, Dst Port: 80, Seq: 1, Ack: 1, Len: 70</span>
<span class="c">#    [-] Hypertext Transfer Protocol</span>
<span class="c">#      [+] GET / HTTP/1.1</span>
<span class="c">#          Host: webpod</span>
<span class="c">#          User-Agent: curl/8.14.1</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 -d udp.port==8472,vxlan 옵션을 통해 VXLAN 캡슐화된 패킷을 해석할 수 있습니다.&lt;/span&gt;</span>

<span class="c"># 신규 터미널 [k8s-ctr] hubble flow log 모니터링 : overlay 통신 모드 확인!</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--protocol</span> tcp <span class="nt">--pod</span> curl-pod
<span class="c"># =&gt; ...</span>
<span class="c">#    Aug  9 07:34:42.262: default/curl-pod:37272 (ID:21500) -&gt; default/webpod-697b545f57-24ck5:80 (ID:17081) &lt;span style="color: green;"&gt;to-overlay FORWARDED&lt;/span&gt; (TCP Flags: SYN)</span>
<span class="c">#    Aug  9 07:34:42.263: default/curl-pod:37272 (ID:21500) &lt;- default/webpod-697b545f57-24ck5:80 (ID:17081) to-endpoint FORWARDED (TCP Flags: SYN, ACK)</span>
<span class="c">#    Aug  9 07:34:42.263: default/curl-pod:37272 (ID:21500) -&gt; default/webpod-697b545f57-24ck5:80 (ID:17081) &lt;span style="color: green;"&gt;to-overlay FORWARDED&lt;/span&gt; (TCP Flags: ACK)</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w4/20250810_cilium_w4_3.png" alt="img.png" class="image-center" />
<em class="image-caption">파드에서 나갈때 패킷 흐름</em></p>

<p><img src="/assets/2025/cilium/w4/20250810_cilium_w4_4.png" alt="img_1.png" class="image-center" />
<em class="image-caption">파드로 인입시 패킷 흐름</em></p>

<ul>
  <li>이상과 같이 VXLAN을 통해서 파드간 통신이 가능해졌습니다. 하지만 VXLAN 등의 캡슐화 기술을 사용하게 되면, 다음의 단점이 있습니다.
    <ul>
      <li>50 bytes의 캡슐화 오버헤드가 발생합니다. (MTU 감소 및 그로인한 패킷 fragmentation 발생 가능성)</li>
      <li>캡슐화 및 디캡슐화 과정에서 CPU 리소스가 소모됩니다.</li>
      <li>같은 네트워크 대역에 있더라도 VXLAN을 통해 캡슐화 됩니다.</li>
    </ul>
  </li>
  <li>VXLAN은 별도의 네트워크 설정 없이 노드간 통신이 가능하다는 장점이 있지만, 위와 같은 문제들로 인프라적인 지원이 가능하다면 Native Routing을 사용하는 것이 좋습니다.</li>
  <li>MTU(Maximum Transmission Unit)는 네트워크에서 전송할 수 있는 최대 패킷 크기를 의미합니다. VXLAN을 사용하면 MTU가 감소하게 되며, 이는 패킷이 분할(fragmentation)되어 전송될 수 있음을 의미합니다. 따라서, VXLAN을 사용할 때는 MTU 설정을 주의 깊게 관리해야 합니다.</li>
  <li>MTU에 대한 간단한 실험을 하고 다음 단계로 넘어가겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># -M do : Don't Fragment (DF) 플래그를 설정하여 조각화 방지</span>
<span class="c"># -s 1472 : 페이로드(payload) 크기, 즉 ICMP 데이터 크기</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> ping <span class="nt">-M</span> <span class="k">do</span> <span class="nt">-s</span> 1472 <span class="nv">$WEBPOD</span>
<span class="c"># =&gt; PING 172.20.2.73 (172.20.2.73) 1472(1500) bytes of data.</span>
<span class="c">#    ping: sendmsg: Message too large</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 ping 명령어를 통해 VXLAN 에 의한 MTU (1450 bytes)보다 큰 1500 bytes를 강제로 전송하면 &lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   "ping: sendmsg: Message too large" 에러가 발생합니다.&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   즉, MTU보다 큰 패킷은 전송할 수 없음을 확인할 수 있으며, MTU 단위로 패킷이 분할(fragmentation)되어 전송됩니다.&lt;/span&gt;</span>
</code></pre></div></div>

<h3 id="도전과제2-vxlan-대신-geneve-모드-사용"><code class="language-plaintext highlighter-rouge">도전과제2.</code> VXLAN 대신 GENEVE 모드 사용</h3>

<ul>
  <li>Cilium은 VXLAN 외에도 GENEVE 모드를 지원합니다. GENEVE는 VXLAN보다 더 유연하고 확장 가능한 캡슐화 프로토콜입니다.</li>
</ul>

<h4 id="geneve-소개">GENEVE 소개</h4>

<ul>
  <li>GENEVE(Generic Network Virtualization Encapsulation)는 VXLAN/NVGRE 등과 유사한 네트워크 가상화 캡슐화 프로토콜로 좀 더 발전된 기능을 제공합니다.</li>
  <li>주요 특징은 다음과 같습니다.
<img src="/assets/2025/cilium/w4/20250810_cilium_w4_17.png" alt="img.png" class="image-center w-80" />
<em class="image-caption">Geneve 헤더 구조 - <a href="https://www.redhat.com/en/blog/what-geneve">출처</a></em>
    <ul>
      <li><strong>확장성 높은 옵션 필드(TLV:Type-Length-Value)</strong> : 고정 헤더 구조에서 벗어나  유동적으로 다양한 옵션을 추가할 수 있어 다양한 환경과 요구사항에 맞는 발전이 가능합니다. (단, 늘어난 헤더 크기가 오버헤드로 작용합니다.)</li>
      <li><strong>UDP 기반 처리</strong> : VXLAN과 마찬가지로 UDP 6081 포트를 사용하며, 하드웨어·소프트웨어에서 호환성이 뛰어납니다.</li>
      <li><strong>표준화된 프로토콜</strong> : Cisco 주도로 만들어진 VXLAN과 달리, 처음부터 IETF에서 <strong>범람하는 캡슐화 프로토콜을 통합할 목적으로 만든</strong> 프로토콜로, 더 널리 채택될 가능성이 높습니다.</li>
      <li><strong>확장 가능한 서비스</strong> : 정책, 전송 보안, 서비스 체이닝 등 다양한 서비스에 대한 확장성을 제공하며, SDN(Software Defined Networking) 환경에서 유용합니다.</li>
      <li><strong>하드웨어 오프로드</strong> : VXLAN도 NIC 오프로드를 지원하지만, Geneve는 설계시 부터 하드웨어 오프로드를 고려하여 설계되어, 성능이 향상될 수 있습니다.</li>
    </ul>
  </li>
</ul>

<h4 id="geneve-실습">GENEVE 실습</h4>

<ul>
  <li>실습을 통해 GENEVE 모드를 사용하여 파드 간 통신을 설정해보겠습니다.</li>
</ul>

<h5 id="geneve-모드-설정">GENEVE 모드 설정</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># GENEVE 커널 모듈 로드</span>
<span class="nv">$ </span>lsmod | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'vxlan|geneve'</span>
<span class="c"># =&gt; vxlan                 147456  0</span>
<span class="c">#    ip6_udp_tunnel         16384  1 vxlan</span>
<span class="c">#    udp_tunnel             36864  1 vxlan</span>
<span class="nv">$ </span>modprobe geneve
<span class="nv">$ </span>lsmod | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'vxlan|geneve'</span>
<span class="c"># =&gt; &lt;span style="color: green; padding: 2px 3px; border: 2px solid red; margin: 0 -5px;"&gt;geneve                 45056  0&lt;/span&gt;</span>
<span class="c">#    vxlan                 147456  0</span>
<span class="c">#    ...</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w0 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>modprobe geneve <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    &gt;&gt; node : k8s-w0 &lt;&lt;</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w0 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>lsmod | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'vxlan|geneve'</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    &lt;span style="color: green; padding: 2px 3px; border: 2px solid red; margin: 0 -5px;"&gt;geneve                 45056  0&lt;/span&gt;</span>
<span class="c">#    vxlan                 147456  0</span>
<span class="c">#    ip6_udp_tunnel         16384  2 &lt;span style="color: green; padding: 2px 3px; border: 2px solid red; margin: 0 -5px;"&gt;geneve&lt;/span&gt;,vxlan</span>
<span class="c">#    udp_tunnel             36864  2 &lt;span style="color: green; padding: 2px 3px; border: 2px solid red; margin: 0 -5px;"&gt;geneve&lt;/span&gt;,vxlan</span>
<span class="c">#    &gt;&gt; node : k8s-w0 &lt;&lt;</span>
<span class="c">#    &lt;span style="color: green; padding: 2px 3px; border: 2px solid red; margin: 0 -5px;"&gt;geneve                 45056  0&lt;/span&gt;</span>
<span class="c">#    vxlan                 147456  0</span>
<span class="c">#    ip6_udp_tunnel         16384  2 &lt;span style="color: green; padding: 2px 3px; border: 2px solid red; margin: 0 -5px;"&gt;geneve&lt;/span&gt;,vxlan</span>
<span class="c">#    udp_tunnel             36864  2 &lt;span style="color: green; padding: 2px 3px; border: 2px solid red; margin: 0 -5px;"&gt;geneve&lt;/span&gt;,vxlan</span>

<span class="c"># k8s-w1 노드에 배포된 webpod 파드 IP 지정</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">WEBPOD1</span><span class="o">=</span><span class="si">$(</span>kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>webpod <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-w1 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].status.podIP}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$WEBPOD1</span>
<span class="c"># =&gt; 172.20.1.198</span>

<span class="c"># 반복 ping 실행해두기</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> ping <span class="nv">$WEBPOD1</span>


<span class="c"># 업그레이드</span>
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--namespace</span> kube-system <span class="nt">--version</span> 1.18.0 <span class="nt">--reuse-values</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">routingMode</span><span class="o">=</span>tunnel <span class="nt">--set</span> <span class="nv">tunnelProtocol</span><span class="o">=</span>geneve <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">autoDirectNodeRoutes</span><span class="o">=</span><span class="nb">false</span> <span class="nt">--set</span> <span class="nv">installNoConntrackIptablesRules</span><span class="o">=</span><span class="nb">false</span>
<span class="c"># =&gt; Release "cilium" has been upgraded. Happy Helming!</span>
<span class="c">#    ...</span>

<span class="c"># 설정을 적용하기 위해서 Cilium DaemonSet을 재시작합니다.</span>
<span class="nv">$ </span>kubectl rollout restart <span class="nt">-n</span> kube-system ds/cilium
<span class="c"># =&gt; daemonset.apps/cilium restarted</span>

<span class="c"># 설정 확인</span>
<span class="nv">$ </span>cilium features status
<span class="nv">$ </span>cilium features status | <span class="nb">grep </span>datapath_network
<span class="c"># =&gt; Cilium   Agents</span>
<span class="c">#    Uniform  Name                             Labels              k8s-ctr  k8s-w0  k8s-w1</span>
<span class="c">#    Yes      cilium_feature_datapath_network                                         mode=&lt;span style="color: green; padding: 2px 3px; border: 2px solid red; margin: 0 -5px;"&gt;overlay-geneve&lt;/span&gt;                               1        1       1</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">--</span> cilium status | <span class="nb">grep</span> ^Routing
<span class="c"># =&gt; Routing:                 Network: &lt;span style="color: green; padding: 2px 3px; border: 2px solid red; margin: 0 -5px;"&gt;Tunnel [geneve]&lt;/span&gt;   Host: BPF</span>
<span class="nv">$ </span>cilium config view | <span class="nb">grep </span>tunnel
<span class="c"># =&gt; routing-mode                                      tunnel</span>
<span class="c">#    tunnel-protocol                                   geneve</span>
<span class="c">#    tunnel-source-port-range                          0-0</span>

<span class="c"># cilium_geneve 확인</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> addr show dev cilium_geneve
<span class="c"># =&gt; 29: cilium_geneve: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN group default</span>
<span class="c">#        link/ether 9e:6f:d6:29:71:60 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet6 fe80::9c6f:d6ff:fe29:7160/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w0 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> addr show dev cilium_geneve <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    11: cilium_geneve: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN group default</span>
<span class="c">#        link/ether c2:bd:d4:eb:63:fd brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet6 fe80::c0bd:d4ff:feeb:63fd/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w0 &lt;&lt;</span>
<span class="c">#    11: cilium_geneve: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UNKNOWN group default</span>
<span class="c">#        link/ether 0e:fd:73:c8:6f:37 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet6 fe80::cfd:73ff:fec8:6f37/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>

<span class="c"># 라우팅 정보 확인 : k8s node 간 다른 네트워크 대역에 있더라도, 파드의 네트워크 대역 정보가 라우팅에 올라왔다!</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route | <span class="nb">grep </span>cilium_host
<span class="c"># =&gt; 172.20.0.0/24 via 172.20.0.201 dev cilium_host proto kernel src 172.20.0.201</span>
<span class="c">#    172.20.0.201 dev cilium_host proto kernel scope link</span>
<span class="c">#    172.20.1.0/24 via 172.20.0.201 dev cilium_host proto kernel src 172.20.0.201 mtu 1450</span>
<span class="c">#    172.20.2.0/24 via 172.20.0.201 dev cilium_host proto kernel src 172.20.0.201 mtu 1450 </span>

<span class="nv">$ </span>ip route get 172.20.1.10
<span class="c"># =&gt; 172.20.1.10 dev cilium_host src 172.20.0.201 uid 0</span>
<span class="c">#        cache mtu 1450</span>
<span class="nv">$ </span>ip route get 172.20.2.10
<span class="c"># =&gt; 172.20.2.10 dev cilium_host src 172.20.0.201 uid 0</span>
<span class="c">#        cache mtu 1450</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 geneve도 VXLAN과 마찬가지로 50 bytes의 캡슐화 오버헤드가 발생하는것 같습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<ul>
  <li>커널 모듈을 로드하고, helm을 통해 GENEVE 모드 설정을 바꾸고, daemonset을 재시작하는것 만으로 
간단하게 VXLAN 모드에서 GENEVE 모드로 변경할 수 있었습니다.</li>
  <li>VXLAN 모드로 변경할때와 마찬가지로 <strong>daemonset이 재시작 되는 동안 파드간 통신이 중단</strong>되는것을 확인할 수 있었습니다.
운영 환경에서는 주의가 필요합니다.</li>
</ul>

<h5 id="파드간-통신-확인-1">파드간 통신 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># k8s-w0 노드에 배포된 webpod 파드 IP 지정</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">WEBPOD</span><span class="o">=</span><span class="si">$(</span>kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>webpod <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-w0 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].status.podIP}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$WEBPOD</span>
<span class="c"># =&gt; 172.20.2.73</span>

<span class="c"># 신규 터미널 [router]</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> any udp port 8472 <span class="nt">-nn</span>

<span class="c"># [k8s-ctr] 에서 ping 실행</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> ping <span class="nt">-c</span> 2 <span class="nt">-w</span> 1 <span class="nt">-W</span> 1 <span class="nv">$WEBPOD</span>
<span class="c"># =&gt; PING 172.20.2.73 (172.20.2.73) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 172.20.2.73: icmp_seq=1 ttl=63 time=4.10 ms</span>
<span class="c">#    64 bytes from 172.20.2.73: icmp_seq=2 ttl=63 time=1.47 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 172.20.2.73 ping statistics ---</span>
<span class="c">#    2 packets transmitted, 2 received, 0% packet loss, time 1000ms</span>
<span class="c">#    rtt min/avg/max/mdev = 1.473/2.786/4.100/1.313 ms</span>

<span class="c"># [router]에서 tcpdump 확인 (GENEVE 포트 6081/udp로 통신이 되는지 확인)</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> any udp port 6081 <span class="nt">-nn</span>
<span class="c"># =&gt; 00:17:18.537335 eth1  In  IP 192.168.10.100.54038 &gt; 192.168.20.100.6081: Geneve, Flags [none], vni 0x53fc: IP 172.20.0.89 &gt; 172.20.2.73: ICMP echo request, id 59783, seq 1, length 64</span>
<span class="c">#    00:17:18.537385 eth2  Out IP 192.168.10.100.54038 &gt; 192.168.20.100.6081: Geneve, Flags [none], vni 0x53fc: IP 172.20.0.89 &gt; 172.20.2.73: ICMP echo request, id 59783, seq 1, length 64</span>
<span class="c">#    00:17:18.538608 eth2  In  IP 192.168.20.100.61597 &gt; 192.168.10.100.6081: Geneve, Flags [none], vni 0x42b9: IP 172.20.2.73 &gt; 172.20.0.89: ICMP echo reply, id 59783, seq 1, length 64</span>
<span class="c">#    00:17:18.538616 eth1  Out IP &lt;span style="color: green;"&gt;192.168.20.100.61597 &gt; 192.168.10.100.6081&lt;/span&gt;: &lt;span style="color: green;"&gt;Geneve&lt;/span&gt;, Flags [none], vni 0x42b9: IP &lt;span style="color: green;"&gt;172.20.2.73 &gt; 172.20.0.89&lt;/span&gt;: ICMP echo reply, id 59783, seq 1, length 64</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 GENEVE을 통해 파드 IP간 통신이 노드간 IP로 캡슐화되어 통신이 되는 것을 확인할 수 있습니다.&lt;/span&gt;</span>

<span class="c"># 신규 터미널 [router] : 라우팅이 어떻게 되는가?</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> any icmp <span class="nt">-nn</span>
<span class="c"># =&gt; (없음)</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 GENEVE을 통해 캡슐화된 패킷으로 통신이 되기 때문에 직접적으로 ICMP(ping) 패킷은 보이지 않습니다.&lt;/span&gt;</span>

<span class="c"># 반복 접속</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl webpod | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod-697b545f57-b46tz</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s --connect-timeout 1 webpod | grep Hostname; echo "---" ; sleep 1; done'</span>

<span class="c"># 신규 터미널 [router]</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> any udp port 6081 <span class="nt">-w</span> /tmp/geneve.pcap
<span class="nv">$ </span>tshark <span class="nt">-r</span> /tmp/geneve.pcap <span class="nt">-d</span> udp.port<span class="o">==</span>6081,geneve
<span class="c"># =&gt;     1   0.000000  172.20.0.89 → 172.20.2.73  TCP 130 44270 → 80 [SYN] Seq=0 Win=64860 Len=0 MSS=1410 SACK_PERM TSval=2614161702 TSecr=0 WS=128</span>
<span class="c">#        2   0.000026  172.20.0.89 → 172.20.2.73  TCP 130 [TCP Retransmission] 44270 → 80 [SYN] Seq=0 Win=64860 Len=0 MSS=1410 SACK_PERM TSval=2614161702 TSecr=0 WS=128</span>
<span class="c">#        3   0.000809  172.20.2.73 → 172.20.0.89  TCP 130 80 → 44270 [SYN, ACK] Seq=0 Ack=1 Win=64308 Len=0 MSS=1410 SACK_PERM TSval=3049232850 TSecr=2614161702 WS=128</span>
<span class="c">#        4   0.000817  172.20.2.73 → 172.20.0.89  TCP 130 [TCP Retransmission] 80 → 44270 [SYN, ACK] Seq=0 Ack=1 Win=64308 Len=0 MSS=1410 SACK_PERM TSval=3049232850 TSecr=2614161702 WS=128</span>
<span class="c">#        5   0.001933  172.20.0.89 → 172.20.2.73  TCP 122 44270 → 80 [ACK] Seq=1 Ack=1 Win=64896 Len=0 TSval=2614161704 TSecr=3049232850</span>
<span class="c">#        6   0.001940  172.20.0.89 → 172.20.2.73  TCP 122 [TCP Dup ACK 5#1] 44270 → 80 [ACK] Seq=1 Ack=1 Win=64896 Len=0 TSval=2614161704 TSecr=3049232850</span>
<span class="c">#        7   0.002279  172.20.0.89 → 172.20.2.73  HTTP 192 GET / HTTP/1.1</span>
<span class="c">#        8   0.002446  172.20.0.89 → 172.20.2.73  TCP 192 [TCP Retransmission] 44270 → 80 [PSH, ACK] Seq=1 Ack=1 Win=64896 Len=70 TSval=2614161705 TSecr=3049232850</span>
<span class="c">#        9   0.004700  172.20.2.73 → 172.20.0.89  TCP 122 80 → 44270 [ACK] Seq=1 Ack=71 Win=64256 Len=0 TSval=3049232852 TSecr=2614161705</span>
<span class="c">#       10   0.004712  172.20.2.73 → 172.20.0.89  TCP 122 [TCP Dup ACK 9#1] 80 → 44270 [ACK] Seq=1 Ack=71 Win=64256 Len=0 TSval=3049232852 TSecr=2614161705</span>
<span class="c">#       11   0.005871  172.20.2.73 → 172.20.0.89  HTTP 441 HTTP/1.1 200 OK  (text/plain)</span>
<span class="c">#       12   0.005874  172.20.2.73 → 172.20.0.89  TCP 441 [TCP Retransmission] 80 → 44270 [PSH, ACK] Seq=1 Ack=71 Win=64256 Len=319 TSval=3049232855 TSecr=2614161705</span>
<span class="c">#       13   0.006514  172.20.0.89 → 172.20.2.73  TCP 122 44270 → 80 [ACK] Seq=71 Ack=320 Win=64640 Len=0 TSval=2614161709 TSecr=3049232855</span>
<span class="c">#       14   0.006527  172.20.0.89 → 172.20.2.73  TCP 122 [TCP Dup ACK 13#1] 44270 → 80 [ACK] Seq=71 Ack=320 Win=64640 Len=0 TSval=2614161709 TSecr=3049232855</span>
<span class="c">#       15   0.006916  172.20.0.89 → 172.20.2.73  TCP 122 44270 → 80 [FIN, ACK] Seq=71 Ack=320 Win=64640 Len=0 TSval=2614161709 TSecr=3049232855</span>
<span class="c">#       16   0.006922  172.20.0.89 → 172.20.2.73  TCP 122 [TCP Retransmission] 44270 → 80 [FIN, ACK] Seq=71 Ack=320 Win=64640 Len=0 TSval=2614161709 TSecr=3049232855</span>
<span class="c">#       17   0.007468  172.20.2.73 → 172.20.0.89  TCP 122 80 → 44270 [FIN, ACK] Seq=320 Ack=72 Win=64256 Len=0 TSval=3049232856 TSecr=2614161709</span>
<span class="c">#       18   0.007474  172.20.2.73 → 172.20.0.89  TCP 122 [TCP Retransmission] 80 → 44270 [FIN, ACK] Seq=320 Ack=72 Win=64256 Len=0 TSval=3049232856 TSecr=2614161709</span>
<span class="c">#       19   0.008120  172.20.0.89 → 172.20.2.73  TCP 122 44270 → 80 [ACK] Seq=72 Ack=321 Win=64640 Len=0 TSval=2614161710 TSecr=3049232856</span>
<span class="c">#       20   0.008125  172.20.0.89 → 172.20.2.73  TCP 122 [TCP Dup ACK 19#1] 44270 → 80 [ACK] Seq=72 Ack=321 Win=64640 Len=0 TSval=2614161710 TSecr=3049232856</span>
<span class="c">#       ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 tshark로도 GENEVE 캡슐화된 패킷을 해석할 수 있지만 조금 더 원활한 해석을 위해서 termshark를 사용해보겠습니다.&lt;/span&gt;</span>

<span class="nv">$ </span>termshark <span class="nt">-r</span> /tmp/geneve.pcap <span class="nt">-d</span> udp.port<span class="o">==</span>6081,geneve
<span class="c"># =&gt; termshark 2.4.0  |  geneve.pcap                                                                                                                                  Analysis    Misc</span>
<span class="c">#    ┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓</span>
<span class="c">#    ┃Filter:                                                                                                                                                         &lt;Apply&gt; &lt;Recent&gt; ┃</span>
<span class="c">#    ┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛</span>
<span class="c">#     No. - Time -    Source -     Dest -       Proto - Length - Info -                                                                                                                ▲</span>
<span class="c">#     1     0.000000  172.20.0.89  172.20.2.73  TCP     130      44270 → 80 [SYN] Seq=0 Win=64860 Len=0 MSS=1410 SACK_PERM TSval=2614161702 TSecr=0 WS=128</span>
<span class="c">#     2     0.000026  172.20.0.89  172.20.2.73  TCP     130      [TCP Retransmission] 44270 → 80 [SYN] Seq=0 Win=64860 Len=0 MSS=1410 SACK_PERM TSval=2614161702 TSecr=0 WS=128</span>
<span class="c">#     3     0.000809  172.20.2.73  172.20.0.89  TCP     130      80 → 44270 [SYN, ACK] Seq=0 Ack=1 Win=64308 Len=0 MSS=1410 SACK_PERM TSval=3049232850 TSecr=2614161702 WS=128         █</span>
<span class="c">#     4     0.000817  172.20.2.73  172.20.0.89  TCP     130      [TCP Retransmission] 80 → 44270 [SYN, ACK] Seq=0 Ack=1 Win=64308 Len=0 MSS=1410 SACK_PERM TSval=3049232850 TSecr=2614</span>
<span class="c">#     5     0.001933  172.20.0.89  172.20.2.73  TCP     122      44270 → 80 [ACK] Seq=1 Ack=1 Win=64896 Len=0 TSval=2614161704 TSecr=3049232850</span>
<span class="c">#     6     0.001940  172.20.0.89  172.20.2.73  TCP     122      [TCP Dup ACK 5#1] 44270 → 80 [ACK] Seq=1 Ack=1 Win=64896 Len=0 TSval=2614161704 TSecr=3049232850</span>
<span class="c">#     7     0.002279  172.20.0.89  172.20.2.73  HTTP    192      GET / HTTP/1.1</span>
<span class="c">#     8     0.002446  172.20.0.89  172.20.2.73  TCP     192      [TCP Retransmission] 44270 → 80 [PSH, ACK] Seq=1 Ack=1 Win=64896 Len=70 TSval=2614161705 TSecr=3049232850</span>
<span class="c">#     9     0.004700  172.20.2.73  172.20.0.89  TCP     122      80 → 44270 [ACK] Seq=1 Ack=71 Win=64256 Len=0 TSval=3049232852 TSecr=2614161705</span>
<span class="c">#     10    0.004712  172.20.2.73  172.20.0.89  TCP     122      [TCP Dup ACK 9#1] 80 → 44270 [ACK] Seq=1 Ack=71 Win=64256 Len=0 TSval=3049232852 TSecr=2614161705</span>
<span class="c">#     11    0.005871  172.20.2.73  172.20.0.89  HTTP    441      HTTP/1.1 200 OK  (text/plain)                                                                                         ▼</span>
<span class="c">#    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>
<span class="c">#    [+] Linux cooked capture v2</span>
<span class="c">#    [+] Internet Protocol Version 4, &lt;span style="color: green; padding: 2px 3px; border: 2px solid red; margin: 0 -5px;"&gt;Src: 192.168.10.100, Dst: 192.168.20.100&lt;/span&gt;</span>
<span class="c">#    [+] User Datagram Protocol, Src Port: 41753, Dst Port: 6081</span>
<span class="c">#    [+] &lt;span style="color: green; padding: 2px 3px; border: 2px solid red; margin: 0 -5px;"&gt;Generic Network Virtualization Encapsulation&lt;/span&gt;, VNI: 0x0053fc [=]</span>
<span class="c">#    [+] Ethernet II, Src: 46:02:28:c8:e7:b6 (46:02:28:c8:e7:b6), Dst: ca:7a:5c:b2:2c:4a (ca:7a:5c:b2:2c:4a)</span>
<span class="c">#    [+] Internet Protocol Version 4, Src: &lt;span style="color: green; padding: 2px 3px; border: 2px solid red; margin: 0 -5px;"&gt;172.20.0.89, Dst: 172.20.2.73&lt;/span&gt;</span>
<span class="c">#    [+] Transmission Control Protocol, Src Port: 44270, Dst Port: 80, Seq: 1, Ack: 1, Len: 70</span>
<span class="c">#    [-] Hypertext Transfer Protocol</span>
<span class="c">#      [+] GET / HTTP/1.1</span>
<span class="c">#          Host: webpod</span>
<span class="c">#          User-Agent: curl/8.14.1</span>
<span class="c">#          Accept: */*</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 -d udp.port==6081,geneve 옵션을 통해 VXLAN 캡슐화된 패킷을 해석할 수 있습니다.&lt;/span&gt;</span>

<span class="c"># 신규 터미널 [k8s-ctr] hubble flow log 모니터링 : overlay 통신 모드 확인!</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--protocol</span> tcp <span class="nt">--pod</span> curl-pod
<span class="c"># =&gt; ...</span>
<span class="c">#    Aug  9 15:29:04.546: default/curl-pod:53356 (ID:21500) -&gt; default/webpod-697b545f57-66grn:80 (ID:17081) to-overlay FORWARDED (TCP Flags: SYN)</span>
<span class="c">#    Aug  9 15:29:04.548: default/curl-pod:53356 (ID:21500) &lt;- default/webpod-697b545f57-66grn:80 (ID:17081) to-endpoint FORWARDED (TCP Flags: SYN, ACK)</span>
<span class="c">#    Aug  9 15:29:04.548: default/curl-pod:53356 (ID:21500) -&gt; default/webpod-697b545f57-66grn:80 (ID:17081) to-overlay FORWARDED (TCP Flags: ACK)</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<ul>
  <li>GENEVE 모드로 변경한 후에도 파드 간 통신이 정상적으로 이루어지는 것을 확인할 수 있었습니다.</li>
</ul>

<hr />

<h2 id="k8s-service">K8S Service</h2>

<h3 id="클러스터-내부를-외부에-노출하는-방법의-발전단계">클러스터 내부를 외부에 노출하는 방법의 발전단계</h3>

<ol>
  <li>파드 생성 : K8S 클러스터 내부에서만 접속
  <img src="/assets/2025/cilium/w4/20250810_cilium_w4_5.png" alt="img.png" class="image-left" /><br /></li>
  <li>서비스(<strong>Cluster</strong> Type) 연결 : K8S 클러스터 내부에서만 접속
<img src="/assets/2025/cilium/w4/20250810_cilium_w4_6.png" alt="img_1.png" class="image-left" />
    <ul>
      <li>동일한 애플리케이션의 다수의 파드의 접속을 용이하게 하기 위한 서비스에 접속</li>
      <li><strong>고정 접속(호출)</strong> 방법을 제공 : 흔히 말하는 ‘<strong>고정 Virtual IP</strong>’ 와 ‘<strong>Domain주소</strong>’ 생성<br /><br /></li>
    </ul>
  </li>
  <li>서비스(<strong>NodePort</strong> Type) 연결 : 외부 클라이언트가 서비스를 통해서 클러스터 내부의 파드로 접속
<img src="/assets/2025/cilium/w4/20250810_cilium_w4_7.png" alt="img_2.png" class="image-left" />
    <ul>
      <li>서비스(<strong>NodePort</strong> Type)의 일부 단점을 보완한 서비스(<strong>LoadBalancer</strong> Type) 도 있습니다.</li>
    </ul>
  </li>
</ol>

<h3 id="service-종류">Service 종류</h3>

<h4 id="clusterip-타입">ClusterIP 타입</h4>

<p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_1.png" alt="img.png" class="w-80 image-center" /></p>

<ul>
  <li>동일한 애플리케이션을 실행하는 여러 Pod에 접속을 용이하기 위해 사용합니다.</li>
  <li>ClusterIP는 Cluster 내부에서만 접근이 가능하며 외부에서는 접근이 불가능합니다.</li>
  <li>iptables 의 NAT 기능을 이용하여 Pod에 접근하며, 동일한 iptables 분산룰을 각 노드에 적용합니다.</li>
</ul>

<h4 id="nodeport-타입">NodePort 타입</h4>

<p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_2.png" alt="img.png" class="w-80 image-center" /></p>

<ul>
  <li>NodePort는 ClusterIP와 같이 Cluster 내부에서 접근이 가능하며, 외부에서도 접근이 가능합니다.</li>
  <li>NodePort도 ClusterIP와 같이 iptables의 NAT 기능을 이용하여 Pod에 접근하며, 각 노드에 NodePort를 할당합니다.</li>
  <li>외부에서는 NodePort를 통해 각 노드에 접근 할 수 있습니다.</li>
</ul>

<h4 id="loadbalancer-타입">LoadBalancer 타입</h4>

<p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_3.png" alt="img.png" class="w-80 image-center" /></p>

<ul>
  <li>LoadBalancer도 외부에서 접근이 가능하며, 클라우드 서비스에서 제공하는 LoadBalancer를 사용합니다. (AWS의 경우 ELB(Elastic Load Balancer)가 사용됩니다.)</li>
  <li>온프레미스 환경에서도 MetalLB와 같은 LoadBalancer를 사용할 수 있습니다.</li>
</ul>

<h3 id="서비스의-구조">서비스의 구조</h3>

<p>서비스를 선언시 <code class="language-plaintext highlighter-rouge">port</code>와 <code class="language-plaintext highlighter-rouge">targetPort</code>, 그리고 <code class="language-plaintext highlighter-rouge">label selector</code> 를 사용합니다. 각각의 역할은 다음과 같습니다.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">port</code> : 서비스가 listen 할 포트를 지정합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">targetPort</code> : 대상 파드의 port를 지정합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">label selector</code>  : 대상 파드를 특정합니다.</li>
</ul>

<p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_7.png" alt="img.png" /></p>

<h3 id="kube-proxy-모드">kube-proxy 모드</h3>

<ul>
  <li>kube-proxy는 쿠버네티스 클러스터에서 서비스의 트래픽을 파드로 라우팅하는 역할을 합니다.</li>
  <li><strong>선택사항이지만</strong>, 반드시 kube-proxy를 대체할 수 있는 대안이 배포되어야 합니다. (예) cilium 등)</li>
  <li>kube-proxy는 서비스 통신 동작에 대한 설정을 관리합니다. 데몬셋으로 배포되어 모든 노드에 파드가 생성됩니다.</li>
  <li>kube-proxy 모드의 종류는 userspace proxy 모드, iptables proxy 모드, ipvs proxy 모드, nftables proxy 모드 등이 있습니다.</li>
</ul>

<h4 id="userspace-proxy-모드-현재는-미사용">userspace proxy 모드 (현재는 미사용)</h4>

<p><img src="/assets/2025/cilium/w4/20250810_cilium_w4_8.png" alt="img.png" class="image-center w-80" />
<em class="image-caption">출처 : <a href="https://medium.com/finda-tech/kubernetes-%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EC%A0%95%EB%A6%AC-fccd4fd0ae6">https://medium.com/finda-tech/kubernetes-네트워크-정리-fccd4fd0ae6</a></em></p>

<ul>
  <li>기초적인 모드이며 사용자 영역의 kube-proxy를 통해 NIC1으로 들어온 패킷을 NIC2로 전달하여 목적 파드로 전달합니다.</li>
  <li>이렇게 하는 과정에서 커널영역(netfilter)과 사용자영역(kube-proxy)를 오가는 과정에서 스위칭에 의한 오버헤드가 발생하는 단점이 있습니다.</li>
</ul>

<h4 id="iptables-proxy-모드">iptables proxy 모드</h4>

<p><img src="/assets/2025/cilium/w4/20250810_cilium_w4_9.png" alt="img.png" class="image-center w-80" />
<em class="image-caption">출처 : <a href="https://medium.com/finda-tech/kubernetes-%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EC%A0%95%EB%A6%AC-fccd4fd0ae6">https://medium.com/finda-tech/kubernetes-네트워크-정리-fccd4fd0ae6</a></em></p>

<ul>
  <li>쿠버네티스 설치시 기본 모드이며, userspace proxy 모드와는 달리 kube-proxy는 트래픽 전달에 직접 관여하지는 않고, netfilter(iptables)를 사용하여 트래픽을 전달합니다.</li>
  <li>iptables proxy 모드는 트래픽 전달 과정에서 kube-proxy를 경유하지 않고, 커널 영역과 사용자 영역 전환이 필요하지 않아서, 유저스페이스 proxy 모드에 비해 오버헤드가 줄어듭니다.</li>
  <li>단점으로는 iptables 규칙이 많아 질 경우 모든 규칙 평가 하는데 지연이 발생할 수 있습니다.</li>
  <li>또한 장애시 모든 규칙을 확인하기 어려워 장애 처리에 불리합니다.</li>
</ul>

<h4 id="ipvs-proxy-모드">ipvs proxy 모드</h4>

<p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_10.png" alt="img.png" /></p>

<ul>
  <li>IPVS Mode는 Linue Kernel에서 제공하는 L4 Load Balacner인 IPVS가 Service Proxy 역할을 수행하는 Mode입니다.</li>
  <li>Packet Load Balancing 수행시 IPVS가 iptables보다 높은 성능을 보이기 때문에 IPVS Mode는 iptables Mode보다 높은 성능을 보여준다</li>
  <li>IPVS 프록시 모드는 iptables 모드와 유사한 netfilter hook 기능을 기반으로 하지만, 해시 테이블을 기본 데이터 구조로 사용하고 <strong>커널 스페이스</strong>에서 동작하여 효율 적으로 동작합니다.</li>
  <li>다른 프록시 모드와 비교했을 때, IPVS 모드는 높은 네트워크 트래픽 처리량도 지원합니다.</li>
</ul>

<h4 id="nftables-proxy-모드">nftables proxy 모드</h4>
<ul>
  <li>nftables 는 iptables를 대체하기 위해 개발된 패킷 필터링 프레임워크로, iptables 보다 더 유연하고 강력한 규칙 설정을 제공합니다.</li>
  <li>하지만 아직  실험적으로 개발중인 단계로 실무에서는 ipvs proxy 모드를 권장합니다.</li>
</ul>

<h4 id="ebpf-모드--xdp">eBPF 모드 + XDP</h4>

<p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_11.png" alt="img.png" class="w-90 image-center" /></p>

<ul>
  <li>앞에서 알아보았던 모든 모드들이 netfilter 기반인데 반해, eBPF 모드 +  XDP 는 netfilter 전 단계에서 트래픽 라우팅을 처리하여 훨씬 효율 적입니다. calico나 cilium을 사용하여서 eBPF 모드를 사용할 수 있습니다.</li>
</ul>

<hr />

<h2 id="service-lb-ipam">Service LB-IPAM</h2>

<p><img src="/assets/2025/cilium/w4/20250810_cilium_w4_10.png" alt="img.png" class="image-center" />
<em class="image-caption">출처 : <a href="https://isovalent.com/blog/post/migrating-from-metallb-to-cilium/#load-balancer-ipam">https://isovalent.com/blog/post/migrating-from-metallb-to-cilium/</a></em></p>

<ul>
  <li>LoadBalancer IP Address Management (LB IPAM) 소개 - <a href="https://docs.cilium.io/en/stable/network/lb-ipam/">Docs</a>, <a href="https://www.youtube.com/watch?v=amC00re6-5k">Youtube</a>
    <ul>
      <li>LB-IPAM은 Cilium에서 제공하는 LoadBalancer IP Address Management 기능으로 LoadBalancer 서비스의 External-IP 를 관리합니다. 이 기능은 AWS 등의 클라우드 제공업체에서 제공하는 기능이지만
Private Cloud 환경에서는 K8S 자체에서는 지원하지 않기 때문에 MetalLB와 같은 솔루션을 사용해야 합니다.</li>
      <li>Cilium은 LB-IPAM을 통해서 MetalLB와 같은 솔루션 없이도 LoadBalancer 서비스를 지원합니다.</li>
      <li>LB-IPAM은 <code class="language-plaintext highlighter-rouge">Cilium BGP Control Plane</code> 및 <code class="language-plaintext highlighter-rouge">L2 Announcements</code> / <code class="language-plaintext highlighter-rouge">L2 Aware LB</code> 등의 기능과 함께 사용됩니다. LB-IPAM이 서비스 객체 및 기타 기능에 IP를 할당하고, <code class="language-plaintext highlighter-rouge">L2 Announcements</code>를 통해서 IP를 노출하고, <code class="language-plaintext highlighter-rouge">L2 Aware LB</code>를 통해서 IP를 라우팅합니다.</li>
      <li>LB IPAM은 항상 활성화되어 있지만 휴면 상태입니다. 첫 번째 IP 풀이 클러스터에 추가되면 컨트롤러가 활성화됩니다.</li>
      <li>기능
        <ul>
          <li>Service Selectors - <a href="https://docs.cilium.io/en/stable/network/lb-ipam/#service-selectors">Docs</a></li>
          <li>Disabling a Pool - <a href="https://docs.cilium.io/en/stable/network/lb-ipam/#disabling-a-pool">Docs</a></li>
          <li>Service 사용 확인 - <a href="https://docs.cilium.io/en/stable/network/lb-ipam/#services">Docs</a></li>
          <li>LoadBalancerClass : BGP or L2 지정 - <a href="https://docs.cilium.io/en/stable/network/lb-ipam/#loadbalancerclass">Docs</a></li>
          <li>Requesting IPs : 특정 Service에 EX-IP를 직접 설정 - <a href="https://docs.cilium.io/en/stable/network/lb-ipam/#loadbalancerclass">Docs</a></li>
          <li>Sharing Keys : EX-IP 1개를 각기 다른 Port 를 통해서 사용 - <a href="https://docs.cilium.io/en/stable/network/lb-ipam/#requesting-ips">Docs</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>[k8s 클러스터 내부] webpod 서비스를 LoadBalancer Type 설정 with Cilium LB IPAM</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl get CiliumLoadBalancerIPPool <span class="nt">-A</span>
<span class="c"># =&gt; No resources found</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 아직 등록된 IP Pool이 없으므로, CiliumLoadBalancerIPPool 리소스가 없습니다.&lt;/span&gt;</span>

<span class="c"># cilium ip pool 생성</span>
<span class="c"># 충돌나지 않는지 대역 확인 할 것!</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: "cilium.io/v2"  # v1.17 : cilium.io/v2alpha1
kind: CiliumLoadBalancerIPPool
metadata:
  name: "cilium-lb-ippool"
spec:
  blocks:
  - start: "192.168.10.211"
    stop:  "192.168.10.215"
</span><span class="no">EOF
</span><span class="c"># =&gt; ciliumloadbalancerippool.cilium.io/cilium-lb-ippool created</span>

<span class="nv">$ </span>kubectl get CiliumLoadBalancerIPPool <span class="nt">-A</span>
<span class="c"># =&gt; NAME               DISABLED   CONFLICTING   IPS AVAILABLE   AGE</span>
<span class="c">#    cilium-lb-ippool   false      False         5               13s</span>

<span class="c"># CiliumLoadBalancerIPPool 축약어 : ippools,ippool,lbippool,lbippools</span>
<span class="nv">$ </span>kubectl api-resources | <span class="nb">grep</span> <span class="nt">-i</span> CiliumLoadBalancerIPPool
<span class="c"># =&gt; ciliumloadbalancerippools           ippools,ippool,lbippool,lbippools   cilium.io/v2                      false        CiliumLoadBalancerIPPool</span>

<span class="nv">$ </span>kubectl get ippools
<span class="c"># =&gt; NAME               DISABLED   CONFLICTING   IPS AVAILABLE   AGE</span>
<span class="c">#    cilium-lb-ippool   false      False         5               101s</span>

<span class="c"># webpod 서비스를 LoadBalancer Type 변경 설정</span>
<span class="nv">$ </span>kubectl patch svc webpod <span class="nt">-p</span> <span class="s1">'{"spec":{"type":"LoadBalancer"}}'</span>
<span class="c"># =&gt; service/webpod patched</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get svc webpod
<span class="c"># =&gt; NAME     TYPE           CLUSTER-IP     EXTERNAL-IP      PORT(S)        AGE</span>
<span class="c">#    webpod   LoadBalancer   10.96.129.95   &lt;span style="color: green;"&gt;192.168.10.211&lt;/span&gt;   80:32203/TCP   3h17m</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 webpod 서비스가 LoadBalancer Type으로 변경되었으며, EXTERNAL-IP로 Cilium LB IP Pool에서 할당된 IP가 설정되었습니다.&lt;/span&gt;</span>

<span class="c"># LBIP로 curl 요청 확인 : k8s 노드들에서 LB EXIP로 통신 가능!</span>
<span class="nv">$ </span>kubectl get svc webpod <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.loadBalancer.ingress[0].ip}'</span>
<span class="c"># =&gt; 192.168.10.211</span>
<span class="nv">$ LBIP</span><span class="o">=</span><span class="si">$(</span>kubectl get svc webpod <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.loadBalancer.ingress[0].ip}'</span><span class="si">)</span>

<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LBIP</span>
<span class="c"># =&gt; Hostname: webpod-697b545f57-b46tz</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: ::1</span>
<span class="c">#    IP: 172.20.0.131</span>
<span class="c">#    IP: fe80::48ca:7aff:fee8:da55</span>
<span class="c">#    RemoteAddr: 172.20.0.201:38068</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: 192.168.10.211</span>
<span class="c">#    User-Agent: curl/8.5.0</span>
<span class="c">#    Accept: */*</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nv">$LBIP</span>
<span class="c"># =&gt; Hostname: webpod-697b545f57-b46tz</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: ::1</span>
<span class="c">#    IP: 172.20.0.131</span>
<span class="c">#    IP: fe80::48ca:7aff:fee8:da55</span>
<span class="c">#    RemoteAddr: 172.20.0.89:33706</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: 192.168.10.211</span>
<span class="c">#    User-Agent: curl/8.14.1</span>
<span class="c">#    Accept: */*</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nv">$LBIP</span> | <span class="nb">grep </span>Hostname   <span class="c"># 대상 파드 이름 출력</span>
<span class="c"># =&gt; Hostname: webpod-697b545f57-b46tz</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nv">$LBIP</span> | <span class="nb">grep </span>RemoteAddr <span class="c"># 대상 파드 입장에서 소스 IP 출력(Layer3)</span>
<span class="c"># =&gt; RemoteAddr: 172.20.0.89:46452</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 curl-pod의 파드 IP가 소스 IP로 출력됩니다.&lt;/span&gt;</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LBIP</span> | <span class="nb">grep </span>RemoteAddr <span class="c"># k8s-ctr 노드에서 curl 요청시 소스 IP 출력</span>
<span class="c"># =&gt; RemoteAddr: 172.20.0.201:35196</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s-ctr 노드의 cilium_host의 IP가 출력됩니다.&lt;/span&gt;</span>

<span class="c"># 반복 접속 : </span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nv">$LBIP</span> | <span class="nb">grep </span>Hostname<span class="p">;</span> <span class="nb">sleep </span>0.1<span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span>  <span class="k">do </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nv">$LBIP</span> | <span class="nb">grep </span>Hostname<span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;      38 Hostname: webpod-697b545f57-66grn</span>
<span class="c">#         35 Hostname: webpod-697b545f57-b46tz</span>
<span class="c">#         27 Hostname: webpod-697b545f57-24ck5</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 각 노드의 webpod 파드로 Loadbalancing이 잘 이루어지고 있습니다.&lt;/span&gt;</span>

<span class="c"># IP 할당 확인</span>
<span class="nv">$ </span>kubectl get ippools
<span class="c"># =&gt; NAME               DISABLED   CONFLICTING   IPS AVAILABLE   AGE</span>
<span class="c">#    cilium-lb-ippool   false      False         4               8m</span>
<span class="nv">$ </span>kubectl get ippools <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[*].status.conditions[?(@.type!="cilium.io/PoolConflict")]}'</span> | jq
<span class="c"># =&gt; {</span>
<span class="c">#      "lastTransitionTime": "2025-08-09T08:27:06Z",</span>
<span class="c">#      "message": "5",</span>
<span class="c">#      "observedGeneration": 1,</span>
<span class="c">#      "reason": "noreason",</span>
<span class="c">#      "status": "Unknown",</span>
<span class="c">#      "type": "cilium.io/IPsTotal"</span>
<span class="c">#    }</span>
<span class="c">#    {</span>
<span class="c">#      "lastTransitionTime": "2025-08-09T08:27:06Z",</span>
<span class="c">#      "message": "4",</span>
<span class="c">#      "observedGeneration": 1,</span>
<span class="c">#      "reason": "noreason",</span>
<span class="c">#      "status": "Unknown",</span>
<span class="c">#      "type": "cilium.io/IPsAvailable"</span>
<span class="c">#    }</span>
<span class="c">#    {</span>
<span class="c">#      "lastTransitionTime": "2025-08-09T08:27:06Z",</span>
<span class="c">#      "message": "1",</span>
<span class="c">#      "observedGeneration": 1,</span>
<span class="c">#      "reason": "noreason",</span>
<span class="c">#      "status": "Unknown",</span>
<span class="c">#      "type": "cilium.io/IPsUsed"</span>
<span class="c">#    }</span>

<span class="nv">$ </span>kubectl get svc webpod <span class="nt">-o</span> json | jq
<span class="nv">$ </span>kubectl get svc webpod <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status}'</span> | jq
<span class="c"># =&gt; {</span>
<span class="c">#      "conditions": [</span>
<span class="c">#        {</span>
<span class="c">#          "lastTransitionTime": "2025-08-09T08:29:01Z",</span>
<span class="c">#          "message": "",</span>
<span class="c">#          "reason": "satisfied",</span>
<span class="c">#          "status": "True",</span>
<span class="c">#          "type": "cilium.io/IPAMRequestSatisfied"</span>
<span class="c">#        }</span>
<span class="c">#      ],</span>
<span class="c">#      "loadBalancer": {</span>
<span class="c">#        "ingress": [</span>
<span class="c">#          {</span>
<span class="c">#            "ip": "192.168.10.211",</span>
<span class="c">#            "ipMode": "VIP"</span>
<span class="c">#          }</span>
<span class="c">#        ]</span>
<span class="c">#      }</span>
<span class="c">#    }</span>
</code></pre></div></div>

<ul>
  <li>[k8s 클러스터 외부] webpod 서비스를 LoadBalancer External IP로 호출 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># router : K8S 외부에서 통신 불가! </span>
<span class="nv">$ LBIP</span><span class="o">=</span>192.168.10.211
<span class="nv">$ </span>curl <span class="nt">--connect-timeout</span> 1 <span class="nv">$LBIP</span>
<span class="c"># =&gt; curl: (28) Failed to connect to 192.168.10.211 port 80 after 1002 ms: Timeout was reached</span>
<span class="nv">$ </span>arping <span class="nt">-i</span> eth1 <span class="nv">$LBIP</span> <span class="nt">-c</span> 1
<span class="c"># =&gt; ARPING 192.168.10.211</span>
<span class="c">#    Timeout</span>
<span class="nv">$ </span>arping <span class="nt">-i</span> eth1 <span class="nv">$LBIP</span> <span class="nt">-c</span> 100000
<span class="c"># =&gt; ARPING 192.168.10.211</span>
<span class="c">#    Timeout</span>
<span class="c">#    Timeout</span>
<span class="c">#    Timeout</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 클러스터 외부에서는 webpod 서비스의 LoadBalancer External IP로 통신이 불가능합니다.&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   LB External IP가 외부로 광고(Announcement) 되지 않기 때문입니다.&lt;/span&gt;</span>
</code></pre></div></div>

<hr />

<h2 id="cilium-l2-announcement">Cilium L2 Announcement</h2>

<h3 id="참고-metallb-layer2-모드">(참고) MetalLB Layer2 모드</h3>

<ul>
  <li><a href="https://metallb.universe.tf/concepts/layer2/">Docs</a></li>
  <li>MetalLB는 Layer2 모드에서 BGP를 사용하지 않고, ARP(IPv4) 또는 NDP(IPv6)를 사용하여 IP 주소를 광고합니다.</li>
  <li>하나의 노드 (Leader Node)에서만 IP 주소를 광고하며, Leader Node가 장애가 발생하면 다른 노드가 Leader Node로 승격되어 IP 주소를 광고합니다.</li>
  <li>MetalLB의 장점은 별도의 하드웨어나 라우팅 장치가 없어도 어떠한 이더넷 네트워크에서도 동작한다는 점입니다.</li>
  <li>
    <p>아래는 MetalLB Layer2 모드에서 GARP 패킷을 통해 VIP(Virtual IP : 서비스의 IP)를 광고하는 예시입니다.
<img src="/assets/2025/cilium/w4/20250810_cilium_w4_11.png" alt="img.png" class="image-center w-80" />
<img src="/assets/2025/cilium/w4/20250810_cilium_w4_12.png" alt="img_1.png" class="image-center w-80" /></p>
  </li>
  <li>MetalLB Layer 2 모드에서는 기본적으로 모든 트래픽이 Leader Node로 전달되며, kube-proxy 등을 통해 각 노드로 트래픽이 분산됩니다.</li>
  <li>
    <p>이로 인해 Leader Node에 장애가 발생하면 트래픽이 중단될 수 있습니다.
<img src="/assets/2025/cilium/w4/20250810_cilium_w4_13.png" alt="img_2.png" class="image-center w-80" /></p>
  </li>
  <li>Leader Node가 장애가 발생하면, 다른 노드가 Leader Node로 승격되어 IP 주소를 광고합니다. 
이때 새로운 Leader Node가 IP 주소를 GARP로 광고하기 전에 일정 시간 동안 트래픽이 중단될 수 있습니다.
<img src="/assets/2025/cilium/w4/20250810_cilium_w4_14.png" alt="img_3.png" class="image-center w-80" /></li>
</ul>

<h3 id="cilium-layer-2-l2-announcement-using-arp">Cilium Layer 2 (L2) Announcement Using ARP</h3>

<ul>
  <li><a href="https://docs.cilium.io/en/stable/network/l2-announcements/">Docs</a></li>
  <li>L2 Announcements은 로컬 영역 네트워크에서 서비스를 가시화하고 도달할 수 있도록 하는 기능입니다.</li>
  <li>이 기능은 주로 사무실이나 캠퍼스 네트워크와 같은 BGP 기반 라우팅 없이 네트워크 내에서 
온프레미스 배포를 목적으로 합니다.</li>
  <li>이 기능을 사용하면 ExternalIPs 또는 LoadBalancer IP에 대한 ARP 쿼리에 응답합니다. 
이러한 IP는 여러 노드에 있는 VIP(Virtual IP)이므로 각 서비스에 대해 한 번에 하나의 노드가 
ARP 쿼리에 응답하고 MAC 주소로 응답합니다. 
이 노드는 서비스 로드 밸런싱 기능으로 로드 밸런싱을 수행하여 north/south(내부&lt;=&gt;외부) 로드 밸런서 역할을 합니다.</li>
  <li>이 기능의 장점은 각 서비스가 고유한 IP를 사용할 수 있어 여러 서비스가 동일한 포트 번호를 사용할 
수 있다는 점입니다. NodePort를 사용할 때 트래픽을 보낼 호스트를 결정하는 것은 클라이언트의 몫이며, 
노드가 다운되면 IP+Port 조합을 사용할 수 없게 됩니다. L2 Announcements를 통해 서비스 VIP는 다른 노드로 마이그레이션하면 계속 작동하게 됩니다.
<img src="/assets/2025/cilium/w4/20250810_cilium_w4_15.png" alt="img.png" class="image-center" />
<img src="/assets/2025/cilium/w4/20250810_cilium_w4_16.png" alt="img_1.png" class="image-center" /></li>
</ul>

<h5 id="k8s-클러스터-외부-webpod-서비스를-loadbalancer-external-ip로-호출확인">[k8s 클러스터 외부] webpod 서비스를 LoadBalancer External IP로 호출확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 모니터링 : router VM</span>
<span class="nv">$ </span>arping <span class="nt">-i</span> eth1 <span class="nv">$LBIP</span> <span class="nt">-c</span> 100000
<span class="c"># =&gt; ARPING 192.168.10.211</span>
<span class="c">#    Timeout</span>
<span class="c">#    Timeout</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 설정 업그레이드 및 CiliumL2AnnouncementPolicy을 통해 정책 설정 시점부터 통신이 됩니다.&lt;/span&gt;</span>
<span class="c">#    60 bytes from 08:00:27:8e:9b:f8 (192.168.10.211): index=0 time=1.101 msec</span>
<span class="c">#    60 bytes from 08:00:27:8e:9b:f8 (192.168.10.211): index=1 time=1.967 msec</span>
<span class="c">#    ...</span>

<span class="c"># 설정 업그레이드</span>
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--namespace</span> kube-system <span class="nt">--version</span> 1.18.0 <span class="nt">--reuse-values</span> <span class="se">\</span>
   <span class="nt">--set</span> l2announcements.enabled<span class="o">=</span><span class="nb">true</span> 
<span class="c"># =&gt; Release "cilium" has been upgraded. Happy Helming!</span>

<span class="nv">$ </span>kubectl rollout restart <span class="nt">-n</span> kube-system ds/cilium
<span class="nv">$ </span>watch <span class="nt">-d</span> kubectl get pod <span class="nt">-A</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system <span class="nb">exec </span>ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium-dbg config <span class="nt">--all</span> | <span class="nb">grep </span>EnableL2Announcements
<span class="c"># =&gt; EnableL2Announcements             : true</span>

<span class="nv">$ </span>cilium config view | <span class="nb">grep </span>enable-l2
<span class="c"># =&gt; enable-l2-announcements                           true</span>
<span class="c">#    enable-l2-neigh-discovery                         false</span>

<span class="c"># 정책 설정 : arp 광고하게 될 service 와 node 지정(controlplane 제외) -&gt; 설정 직후 arping 확인!</span>
<span class="c">## 제약사항 : L2 ARP 모드에서 LB IPPool 은 같은 네트워크 대역에서만 유효. -&gt; k8s-w0 을 제외한 이유. 포함 시 리더 노드 선정 시 동작 실패 상황 발생!</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: "cilium.io/v2alpha1"  # not v2
kind: CiliumL2AnnouncementPolicy
metadata:
  name: policy1
spec:
  serviceSelector:
    matchLabels:
      app: webpod
  nodeSelector:
    matchExpressions:
      - key: kubernetes.io/hostname
        operator: NotIn
        values:
          - k8s-w0
  interfaces:
  - ^eth[1-9]+
  externalIPs: true
  loadBalancerIPs: true
</span><span class="no">EOF
</span><span class="c"># =&gt; ciliuml2announcementpolicy.cilium.io/policy1 created</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 정책 설정 후 부터 arping이 성공합니다.&lt;/span&gt;</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system get lease
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system get lease | <span class="nb">grep</span> <span class="s2">"cilium-l2announce"</span>
<span class="c"># =&gt; NAME                                   HOLDER                                                                      AGE</span>
<span class="c">#    cilium-l2announce-default-webpod       k8s-w1                                                                      2m56s</span>
<span class="c">#    ...</span>

<span class="c"># 현재 리더 역할 노드 확인</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system get lease/cilium-l2announce-default-webpod <span class="nt">-o</span> yaml | yq
<span class="c"># =&gt; ...</span>
<span class="c">#    spec:</span>
<span class="c">#      acquireTime: "2025-08-09T12:01:16.067503Z"</span>
<span class="c">#      holderIdentity: k8s-w1</span>
<span class="c">#      leaseDurationSeconds: 15</span>
<span class="c">#      leaseTransitions: 0</span>
<span class="c">#      renewTime: "2025-08-09T12:05:03.883829Z"</span>

<span class="c"># cilium 파드 이름 지정</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD0</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-ctr <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD1</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-w1  <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD2</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-w0  <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$CILIUMPOD0</span> <span class="nv">$CILIUMPOD1</span> <span class="nv">$CILIUMPOD2</span>
<span class="c"># =&gt; cilium-9dp58 cilium-tj7tw cilium-nftrl</span>

<span class="c"># 현재 해당 IP에 대한 리더가 위치한 노드의 cilium-agent 파드 내에서 정보 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nv">$CILIUMPOD0</span> <span class="nt">--</span> cilium-dbg shell <span class="nt">--</span> db/show l2-announce
<span class="c"># =&gt; IP   NetworkInterface</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nv">$CILIUMPOD1</span> <span class="nt">--</span> cilium-dbg shell <span class="nt">--</span> db/show l2-announce
<span class="c"># =&gt; IP               NetworkInterface</span>
<span class="c">#    192.168.10.211   eth1</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 리더 파드가 k8s-w1에 있기 때문에 k8s-w1의 IP와 Network Interface만 나옵니다.&lt;/span&gt;</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nv">$CILIUMPOD2</span> <span class="nt">--</span> cilium-dbg shell <span class="nt">--</span> db/show l2-announce
<span class="c"># =&gt; IP   NetworkInterface</span>

<span class="c"># 로그 확인</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system logs ds/cilium | <span class="nb">grep</span> <span class="s2">"l2"</span>

<span class="c"># router VM : LBIP로 curl 요청 확인</span>
<span class="nv">$ </span>arping <span class="nt">-i</span> eth1 <span class="nv">$LBIP</span> <span class="nt">-c</span> 1000

<span class="nv">$ </span>curl <span class="nt">--connect-timeout</span> 1 <span class="nv">$LBIP</span>
<span class="c"># =&gt; Hostname: webpod-697b545f57-b46tz</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: ::1</span>
<span class="c">#    IP: 172.20.0.131</span>
<span class="c">#    IP: fe80::48ca:7aff:fee8:da55</span>
<span class="c">#    RemoteAddr: 172.20.1.197:44454</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: 192.168.10.211</span>
<span class="c">#    User-Agent: curl/8.5.0</span>
<span class="c">#    Accept: */*</span>

<span class="c"># VIP 에 대한 mac 주소가 리더 노드의 mac 주소와 동일함을 확인</span>
<span class="nv">$ </span>arp <span class="nt">-a</span>
<span class="c"># =&gt; ? (192.168.10.211) at 08:00:27:8e:9b:f8 [ether] on eth1</span>
<span class="c">#    ? (192.168.10.101) at 08:00:27:8e:9b:f8 [ether] on eth1</span>
<span class="c">#    ? (192.168.10.100) at 08:00:27:42:b2:8c [ether] on eth1</span>
<span class="c">#    ...</span>

<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LBIP</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LBIP</span> | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod-697b545f57-24ck5</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LBIP</span> | <span class="nb">grep </span>RemoteAddr
<span class="c"># =&gt; RemoteAddr: 192.168.10.200:57078</span>

<span class="c"># 리더 노드가 아닌 다른 노드에 webpod 통신 시, SNAT 됨 : arp 동작(리더 노드)으로 인한 제약 사항</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 <span class="nv">$LBIP</span> | <span class="nb">grep </span>Hostname<span class="p">;</span> <span class="nb">sleep </span>0.1<span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 <span class="nv">$LBIP</span> | <span class="nb">grep </span>RemoteAddr<span class="p">;</span> <span class="nb">sleep </span>0.1<span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; RemoteAddr: 192.168.10.200:57284</span>
<span class="c">#    RemoteAddr: 192.168.10.200:57294   </span>
<span class="c">#    RemoteAddr: 172.20.1.197:57306   # &lt;span style="color: green;"&gt;👉 leader node인 k8s-w1이 아닌 다른 노드의 파드가 응답한 경우 SNAT으로 인해 다른 IP가 표시됨&lt;/span&gt;</span>
<span class="c">#    RemoteAddr: 172.20.1.197:57310 </span>
<span class="c">#    RemoteAddr: 192.168.10.200:57364</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<h5 id="l2-announcement-리더-노드에-주입-후-failover-확인">L2 Announcement 리더 노드에 주입 후 Failover 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 신규 터미널 (router) : 반복 호출</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 <span class="nv">$LBIP</span> | <span class="nb">grep </span>Hostname<span class="p">;</span> <span class="nb">sleep </span>0.1<span class="p">;</span> <span class="k">done</span>

<span class="c"># 현재 리더 노드 확인</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system get lease | <span class="nb">grep</span> <span class="s2">"cilium-l2announce"</span>
<span class="c"># =&gt; NAME                                   HOLDER                                                                      AGE</span>
<span class="c">#    cilium-l2announce-default-webpod       k8s-w1                                                                      19m</span>

<span class="c"># 리더 노드 강제 reboot</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w1  <span class="nb">sudo </span>reboot
<span class="c"># &lt;span style="color: green;"&gt;👉 리더 노드 재부팅시 curl이 타임아웃 되어 통신이 안 됩니다.&lt;/span&gt;</span>

<span class="c"># 신규 터미널 (router) : arp 변경(갱신) 확인</span>
<span class="nv">$ </span>arp <span class="nt">-a</span>
<span class="c"># =&gt; ? (192.168.10.211) at &lt;span style="color: green;"&gt;08:00:27:42:b2:8c&lt;/span&gt; [ether] on eth1</span>
<span class="c">#    ? (192.168.10.101) at 08:00:27:8e:9b:f8 [ether] on eth1</span>
<span class="c">#    ? (192.168.10.100) at 08:00:27:42:b2:8c [ether] on eth1</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 VIP(192.168.10.211)의 MAC 주소가 k8s-ctr의 eth1로 변경되었습니다.&lt;/span&gt;</span>

<span class="c"># 현재 리더 노드 확인</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system get lease | <span class="nb">grep</span> <span class="s2">"cilium-l2announce"</span>
<span class="c"># =&gt; cilium-l2announce-default-webpod       k8s-ctr                                                                     24m</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 예상대로 k8s-ctr 노드가 리더 노드로 승격되었습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<h3 id="service-lb-ipam-기능">Service LB-IPAM 기능</h3>

<h5 id="service-추가시-동작">Service 추가시 동작</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: netshoot-web
  labels:
    app: netshoot-web
spec:
  replicas: 3
  selector:
    matchLabels:
      app: netshoot-web
  template:
    metadata:
      labels:
        app: netshoot-web
    spec:
      terminationGracePeriodSeconds: 0
      containers:
        - name: netshoot
          image: nicolaka/netshoot
          ports:
            - containerPort: 8080
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
          command: ["sh", "-c"]
          args:
            - |
              while true; do 
                { echo -e "HTTP/1.1 200 OK</span><span class="se">\r\n</span><span class="sh">Content-Type: text/plain</span><span class="se">\r\n\r\n</span><span class="sh">OK from </span><span class="se">\$</span><span class="sh">POD_NAME"; } | nc -l -p 8080 -q 1;
              done
</span><span class="no">EOF
</span><span class="c"># =&gt; deployment.apps/netshoot-web created</span>

<span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Service
metadata:
  name: netshoot-web
  labels:
    app: netshoot-web
spec:
  type: LoadBalancer
  selector:
    app: netshoot-web
  ports:
    - name: http
      port: 80      
      targetPort: 8080
</span><span class="no">EOF
</span><span class="c"># =&gt; service/netshoot-web created</span>

<span class="c"># LB IP 확인</span>
<span class="nv">$ </span>kubectl get svc netshoot-web
<span class="c"># =&gt; NAME           TYPE           CLUSTER-IP      EXTERNAL-IP      PORT(S)        AGE</span>
<span class="c">#    netshoot-web   LoadBalancer   10.96.170.130   &lt;span style="color: green;"&gt;192.168.10.212&lt;/span&gt;   80:30240/TCP   8s</span>

<span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: "cilium.io/v2alpha1"  # not v2
kind: CiliumL2AnnouncementPolicy
metadata:
  name: policy2
spec:
  serviceSelector:
    matchLabels:
      app: netshoot-web
  nodeSelector:
    matchExpressions:
      - key: kubernetes.io/hostname
        operator: NotIn
        values:
          - k8s-w0
  interfaces:
  - ^eth[1-9]+
  externalIPs: true
  loadBalancerIPs: true
</span><span class="no">EOF
</span><span class="c"># =&gt; ciliuml2announcementpolicy.cilium.io/policy2 created</span>

<span class="c"># Service 별로 리더 노드가 다름 : 즉, 외부 인입 시 Service 별로 나름 분산(?) 처리.. </span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system get lease | <span class="nb">grep</span> <span class="s2">"cilium-l2announce"</span>
<span class="c"># =&gt; cilium-l2announce-default-netshoot-web   k8s-w1                                                                      36s</span>
<span class="c">#    cilium-l2announce-default-webpod         k8s-ctr                                                                     116m</span>

<span class="c"># 호출 확인</span>
<span class="c">## LBIP로 curl 요청 확인 : k8s 노드들에서 LB EXIP로 통신 가능!</span>
<span class="nv">$ </span>kubectl get svc netshoot-web <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.loadBalancer.ingress[0].ip}'</span>
<span class="c"># =&gt; 192.168.10.212</span>
<span class="nv">$ LB2IP</span><span class="o">=</span><span class="si">$(</span>kubectl get svc netshoot-web <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.loadBalancer.ingress[0].ip}'</span><span class="si">)</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LB2IP</span>
<span class="c"># =&gt; OK from netshoot-web-5c59d94bd4-jsh8p</span>

<span class="c">## 신규터미널 (router)</span>
<span class="nv">$ LB2IP</span><span class="o">=</span>192.168.10.212
<span class="nv">$ </span>arping <span class="nt">-i</span> eth1 <span class="nv">$LB2IP</span> <span class="nt">-c</span> 2
<span class="c"># =&gt; ARPING 192.168.10.212</span>
<span class="c">#    60 bytes from 08:00:27:8e:9b:f8 (192.168.10.212): index=0 time=452.250 usec</span>
<span class="c">#    60 bytes from 08:00:27:8e:9b:f8 (192.168.10.212): index=1 time=580.375 usec</span>
<span class="c">#    </span>
<span class="c">#    --- 192.168.10.212 statistics ---</span>
<span class="c">#    2 packets transmitted, 2 packets received,   0% unanswered (0 extra)</span>
<span class="c">#    rtt min/avg/max/std-dev = 0.452/0.516/0.580/0.064 ms</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LB2IP</span>
<span class="c"># =&gt; OK from netshoot-web-5c59d94bd4-5zb78</span>
</code></pre></div></div>

<ul>
  <li>특이하게도 Service별로 리더 노드가 다릅니다. 서비스가 여러개인 경우에는 서비스 별로 분산되는 효과가 있어서
리더 노드에 부하가 집중되는 문제가 다소 완화될 것으로 보입니다.</li>
</ul>

<h5 id="requesting-ips">Requesting IPs</h5>

<ul>
  <li>특정 Service의 External IP를 직접 설정할 수 있습니다. <a href="https://docs.cilium.io/en/stable/network/lb-ipam/#loadbalancerclass">Docs</a></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Service netshoot-web 에 EX-IP를 직접 지정 변경</span>
<span class="nv">$ </span>kubectl edit svc netshoot-web 
<span class="c"># 또는 k9s → svc → &lt;e&gt; edit</span>
<span class="nt">---</span>
<span class="c">## metadata.annotations 아래 아래 추가</span>
  annotations:
    <span class="s2">"lbipam.cilium.io/ips"</span>: <span class="s2">"192.168.10.215"</span>
<span class="nt">---</span>
<span class="c"># =&gt; service/netshoot-web edited</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get svc netshoot-web
<span class="c"># =&gt; NAME           TYPE           CLUSTER-IP      EXTERNAL-IP      PORT(S)        AGE</span>
<span class="c">#    netshoot-web   LoadBalancer   10.96.170.130   &lt;span style="color: green;"&gt;192.168.10.215&lt;/span&gt;   80:30240/TCP   9m6s</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 annotation을 통해 지정한 EXTERNAL-IP(192.168.10.215)가 설정되었습니다.&lt;/span&gt;</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get svc netshoot-web <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.loadBalancer.ingress[0].ip}'</span>
<span class="c"># =&gt; 192.168.10.215</span>
<span class="nv">$ LB2IP</span><span class="o">=</span><span class="si">$(</span>kubectl get svc netshoot-web <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.loadBalancer.ingress[0].ip}'</span><span class="si">)</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LB2IP</span>
<span class="c"># =&gt; OK from netshoot-web-5c59d94bd4-5zb78</span>
</code></pre></div></div>

<h5 id="sharing-keys">Sharing Keys</h5>

<ul>
  <li>External IP 1개를 각기 다른 Port를 통해서 사용할 수 있습니다. <a href="https://docs.cilium.io/en/stable/network/lb-ipam/#requesting-ips">Docs</a></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Service
metadata:
  name: netshoot-web2
  labels:
    app: netshoot-web
spec:
  type: LoadBalancer
  selector:
    app: netshoot-web
  ports:
    - name: http
      port: 8080      
      targetPort: 8080
</span><span class="no">EOF
</span><span class="c"># =&gt; service/netshoot-web2 created</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get svc <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>netshoot-web
<span class="c"># =&gt; NAME            TYPE           CLUSTER-IP      EXTERNAL-IP      PORT(S)          AGE</span>
<span class="c">#    netshoot-web    LoadBalancer   10.96.170.130   192.168.10.215   80:30240/TCP     12m</span>
<span class="c">#    netshoot-web2   LoadBalancer   10.96.75.231    192.168.10.212   8080:31278/TCP   14s</span>

<span class="c"># Service netshoot-web에 annotations 추가</span>
<span class="nv">$ </span>kubectl edit svc netshoot-web 
<span class="c"># 또는 k9s → svc → &lt;e&gt; edit</span>
<span class="nt">---</span> 
<span class="c">## metadata.annotations 아래 아래 추가</span>
  annotations:
    <span class="s2">"lbipam.cilium.io/ips"</span>: <span class="s2">"192.168.10.215"</span>
    <span class="s2">"lbipam.cilium.io/sharing-key"</span>: <span class="s2">"1234"</span>
<span class="nt">---</span>
<span class="c"># =&gt; service/netshoot-web edited</span>

<span class="c"># 동일하게 netshoot-web2 서비스에도 annotations 추가</span>
<span class="nv">$ </span>kubectl edit svc netshoot-web2 
<span class="c"># =&gt; service/netshoot-web2 edited</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get svc <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>netshoot-web
<span class="c"># =&gt; NAME            TYPE           CLUSTER-IP      EXTERNAL-IP      PORT(S)          AGE</span>
<span class="c">#    netshoot-web    LoadBalancer   10.96.170.130   192.168.10.215   80:30240/TCP     18m</span>
<span class="c">#    netshoot-web2   LoadBalancer   10.96.75.231    192.168.10.215   8080:31278/TCP   5m36s</span>

<span class="c"># sharing-key 사용되는 IP는 모든 같은 리더 노드 사용</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system get lease | <span class="nb">grep</span> <span class="s2">"cilium-l2announce"</span>
<span class="c"># =&gt; cilium-l2announce-default-netshoot-web    k8s-w1                                                                      17m</span>
<span class="c">#    cilium-l2announce-default-netshoot-web2   k8s-w1                                                                      5m45s</span>
<span class="c">#    cilium-l2announce-default-webpod          k8s-ctr                                                                     133m</span>

<span class="c"># 호출 확인</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LB2IP</span>
<span class="c"># =&gt; OK from netshoot-web-5c59d94bd4-5zb78</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 netshoot-web 서비스 응답&lt;/span&gt;</span>

<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LB2IP</span>:8080
<span class="c"># =&gt; OK from netshoot-web-5c59d94bd4-4fsnp</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 netshoot-web2 서비스 응답&lt;/span&gt;</span>

<span class="c"># 신규터미널 (router)</span>
<span class="nv">$ LB2IP</span><span class="o">=</span>192.168.10.215
<span class="nv">$ </span>arping <span class="nt">-i</span> eth1 <span class="nv">$LB2IP</span> <span class="nt">-c</span> 2
<span class="c"># =&gt; ARPING 192.168.10.215</span>
<span class="c">#    60 bytes from 08:00:27:8e:9b:f8 (192.168.10.215): index=0 time=1.236 msec</span>
<span class="c">#    60 bytes from 08:00:27:8e:9b:f8 (192.168.10.215): index=1 time=372.519 usec</span>
<span class="c">#    </span>
<span class="c">#    --- 192.168.10.215 statistics ---</span>
<span class="c">#    2 packets transmitted, 2 packets received,   0% unanswered (0 extra)</span>
<span class="c">#    rtt min/avg/max/std-dev = 0.373/0.804/1.236/0.432 ms</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LB2IP</span>
<span class="c"># =&gt; OK from netshoot-web-5c59d94bd4-jsh8p</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$LB2IP</span>:8080
<span class="c"># =&gt; OK from netshoot-web-5c59d94bd4-5zb78</span>
</code></pre></div></div>

<hr />

<h2 id="마치며">마치며</h2>

<p>이번 포스트에서도 노드의 파드들간 통신에 대해서 알아보았습니다.
가장 관심 있게 본 점은 Cilium의 LoadBalancer IPAM 기능을 통해서 MetalLB (L2 모드)를 대체할 수 있다는 것입니다.
MetalLB라는 추가적인 구성요소 없이 Cilium 만으로 LoadBalancer Service를 구현할 수 있다는 점이 매력적인것 같습니다. :relaxed:</p>

<p>점점 더 Cilium의 매력에 빠져드는것 같습니다. 다음 주에도 Cilium에 대해서 더 알아보도록 하겠습니다. :smile:</p>

<ul>
  <li>약어 소개
    <ul>
      <li><strong>S.IP</strong> : Source IP, 출발지(소스) IP</li>
      <li><strong>D.IP</strong> : Destination IP, 도착치(목적지) IP</li>
      <li><strong>S.Port</strong> : Source Port, 출발지(소스) 포트</li>
      <li><strong>D.Port</strong> : Destination Port, 도착지(목적지) 포트</li>
      <li><strong>NAT</strong> : Network Address Translation, 네트워크 주소 변환</li>
      <li><strong>SNAT</strong> : Source IP 를 NAT 처리, 일반적으로 출발지 IP를 변환</li>
      <li><strong>DNAT</strong> : Destination IP 를 NAT 처리, 일반적으로 목적지 IP와 목적지 포트를 변환</li>
    </ul>
  </li>
</ul>]]></content><author><name></name></author><category term="cilium" /><category term="kubernetes," /><category term="network," /><category term="linux," /><category term="cilium," /><category term="ipam," /><category term="routing," /><category term="masquerading," /><category term="coredns," /><category term="nodelocaldns" /><summary type="html"><![CDATA[이번 포스트에서는 Overlay Network인 VXLAN을 통한 파드간 통신과 Kubernetes 서비스, LB-IPAM 등을 통한 통신을 살펴보겠습니다.]]></summary></entry><entry><title type="html">[Cilium] Networking - 노드의 파드들간 통신 상세 part 1</title><link href="https://sweetlittlebird.github.io/posts/2025-08-03-Cilium-Week3/" rel="alternate" type="text/html" title="[Cilium] Networking - 노드의 파드들간 통신 상세 part 1" /><published>2025-08-03T00:10:18+09:00</published><updated>2025-08-03T00:10:18+09:00</updated><id>https://sweetlittlebird.github.io/posts/Cilium%20-%20Week3</id><content type="html" xml:base="https://sweetlittlebird.github.io/posts/2025-08-03-Cilium-Week3/"><![CDATA[<h2 id="들어가며">들어가며</h2>

<p>이번 포스트에서는 Cilium의 Networking에 대해 살펴보겠습니다. 
Cilium이 어떻게 노드에 있는 파드들 간의 통신을 처리하는지, IP 주소 할당(IPAM), 라우팅, 마스커레이딩, DNS 설정 등을 다룰 것입니다.</p>

<hr />

<h2 id="실습-환경-구성">실습 환경 구성</h2>

<ul>
  <li>이번 실습에서는 다음 그림과 같이 worker 노드를 1대 줄이고, router 노드를 추가해서 실습할 예정입니다.
<img src="/assets/2025/cilium/w3/20250803_cilium_w3_1.png" alt="img.png" class="image-center" />
    <ul>
      <li><strong>가상머신</strong> : k8s-ctr, k8s-w1, router</li>
      <li><strong>router</strong> : 사내망 10.10.0.0/16 대역 통신과 연결, k8s 에 join 되지 않은 서버, loop1/loop2 dump 인터페이스 배치</li>
      <li>Cilium CNI 가 설치된 상태로 배포됩니다.</li>
    </ul>
  </li>
</ul>

<h3 id="실습환경-배포-파일">실습환경 배포 파일</h3>

<ul>
  <li>
    <p><strong>Vagrantfile</strong> : 가상머신 정의, 부팅 시 초기 프로비저닝 설정을 포함하는 Vagrantfile입니다.</p>

    <div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Variables</span>
<span class="no">K8SV</span> <span class="o">=</span> <span class="s1">'1.33.2-1.1'</span> <span class="c1"># Kubernetes Version : apt list -a kubelet, ex) 1.32.5-1.1</span>
<span class="no">CONTAINERDV</span> <span class="o">=</span> <span class="s1">'1.7.27-1'</span> <span class="c1"># Containerd Version : apt list -a containerd.io, ex) 1.6.33-1</span>
<span class="no">CILIUMV</span> <span class="o">=</span> <span class="s1">'1.17.6'</span> <span class="c1"># Cilium CNI Version : https://github.com/cilium/cilium/tags</span>
<span class="no">N</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># max number of worker nodes</span>
  
<span class="c1"># Base Image  https://portal.cloud.hashicorp.com/vagrant/discover/bento/ubuntu-24.04</span>
<span class="no">BOX_IMAGE</span> <span class="o">=</span> <span class="s2">"bento/ubuntu-24.04"</span>
<span class="no">BOX_VERSION</span> <span class="o">=</span> <span class="s2">"202502.21.0"</span>
  
<span class="no">Vagrant</span><span class="p">.</span><span class="nf">configure</span><span class="p">(</span><span class="s2">"2"</span><span class="p">)</span> <span class="k">do</span> <span class="o">|</span><span class="n">config</span><span class="o">|</span>
<span class="c1">#-ControlPlane Node</span>
    <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">define</span> <span class="s2">"k8s-ctr"</span> <span class="k">do</span> <span class="o">|</span><span class="n">subconfig</span><span class="o">|</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="no">BOX_IMAGE</span>
        
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box_version</span> <span class="o">=</span> <span class="no">BOX_VERSION</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provider</span> <span class="s2">"virtualbox"</span> <span class="k">do</span> <span class="o">|</span><span class="n">vb</span><span class="o">|</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--groups"</span><span class="p">,</span> <span class="s2">"/Cilium-Lab"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--nicpromisc2"</span><span class="p">,</span> <span class="s2">"allow-all"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">name</span> <span class="o">=</span> <span class="s2">"k8s-ctr"</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">cpus</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">memory</span> <span class="o">=</span> <span class="mi">2560</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">linked_clone</span> <span class="o">=</span> <span class="kp">true</span>
      <span class="k">end</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">host_name</span> <span class="o">=</span> <span class="s2">"k8s-ctr"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.10.100"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="mi">60000</span><span class="p">,</span> <span class="ss">auto_correct: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">id: </span><span class="s2">"ssh"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">synced_folder</span> <span class="s2">"./"</span><span class="p">,</span> <span class="s2">"/vagrant"</span><span class="p">,</span> <span class="ss">disabled: </span><span class="kp">true</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"init_cfg.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">K8SV</span><span class="p">,</span> <span class="no">CONTAINERDV</span> <span class="p">]</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"k8s-ctr.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">N</span><span class="p">,</span> <span class="no">CILIUMV</span><span class="p">,</span> <span class="no">K8SV</span> <span class="p">]</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"route-add1.sh"</span>
    <span class="k">end</span>
  
<span class="c1">#-Worker Nodes Subnet1</span>
  <span class="p">(</span><span class="mi">1</span><span class="o">..</span><span class="no">N</span><span class="p">).</span><span class="nf">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">i</span><span class="o">|</span>
    <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">define</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span> <span class="k">do</span> <span class="o">|</span><span class="n">subconfig</span><span class="o">|</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="no">BOX_IMAGE</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box_version</span> <span class="o">=</span> <span class="no">BOX_VERSION</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provider</span> <span class="s2">"virtualbox"</span> <span class="k">do</span> <span class="o">|</span><span class="n">vb</span><span class="o">|</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--groups"</span><span class="p">,</span> <span class="s2">"/Cilium-Lab"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--nicpromisc2"</span><span class="p">,</span> <span class="s2">"allow-all"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">name</span> <span class="o">=</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">cpus</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">memory</span> <span class="o">=</span> <span class="mi">1536</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">linked_clone</span> <span class="o">=</span> <span class="kp">true</span>
      <span class="k">end</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">host_name</span> <span class="o">=</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.10.10</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="s2">"6000</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span> <span class="ss">auto_correct: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">id: </span><span class="s2">"ssh"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">synced_folder</span> <span class="s2">"./"</span><span class="p">,</span> <span class="s2">"/vagrant"</span><span class="p">,</span> <span class="ss">disabled: </span><span class="kp">true</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"init_cfg.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">K8SV</span><span class="p">,</span> <span class="no">CONTAINERDV</span><span class="p">]</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"k8s-w.sh"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"route-add1.sh"</span>
    <span class="k">end</span>
  <span class="k">end</span>
  
<span class="c1">#-Router Node</span>
    <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">define</span> <span class="s2">"router"</span> <span class="k">do</span> <span class="o">|</span><span class="n">subconfig</span><span class="o">|</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="no">BOX_IMAGE</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box_version</span> <span class="o">=</span> <span class="no">BOX_VERSION</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provider</span> <span class="s2">"virtualbox"</span> <span class="k">do</span> <span class="o">|</span><span class="n">vb</span><span class="o">|</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--groups"</span><span class="p">,</span> <span class="s2">"/Cilium-Lab"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">name</span> <span class="o">=</span> <span class="s2">"router"</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">cpus</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">memory</span> <span class="o">=</span> <span class="mi">768</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">linked_clone</span> <span class="o">=</span> <span class="kp">true</span>
      <span class="k">end</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">host_name</span> <span class="o">=</span> <span class="s2">"router"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.10.200"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="mi">60009</span><span class="p">,</span> <span class="ss">auto_correct: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">id: </span><span class="s2">"ssh"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">synced_folder</span> <span class="s2">"./"</span><span class="p">,</span> <span class="s2">"/vagrant"</span><span class="p">,</span> <span class="ss">disabled: </span><span class="kp">true</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"router.sh"</span>
    <span class="k">end</span>    
<span class="k">end</span>  
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>init_cfg.sh</strong> : args 참고하여 초기 설정을 수행하는 스크립트입니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config Start &lt;&lt;&lt;&lt;"</span>
  
<span class="nb">echo</span> <span class="s2">"[TASK 1] Setting Profile &amp; Bashrc"</span>
<span class="nb">echo</span> <span class="s1">'alias vi=vim'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s2">"sudo su -"</span> <span class="o">&gt;&gt;</span> /home/vagrant/.bashrc
<span class="nb">ln</span> <span class="nt">-sf</span> /usr/share/zoneinfo/Asia/Seoul /etc/localtime <span class="c"># Change Timezone</span>
  
<span class="nb">echo</span> <span class="s2">"[TASK 2] Disable AppArmor"</span>
systemctl stop ufw <span class="o">&amp;&amp;</span> systemctl disable ufw <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
systemctl stop apparmor <span class="o">&amp;&amp;</span> systemctl disable apparmor <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="nb">echo</span> <span class="s2">"[TASK 3] Disable and turn off SWAP"</span>
swapoff <span class="nt">-a</span> <span class="o">&amp;&amp;</span> <span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'/swap/s/^/#/'</span> /etc/fstab
  
<span class="nb">echo</span> <span class="s2">"[TASK 4] Install Packages"</span>
apt update <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
apt-get <span class="nb">install </span>apt-transport-https ca-certificates curl gpg <span class="nt">-y</span> <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="c"># Download the public signing key for the Kubernetes package repositories.</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> <span class="nt">-m</span> 755 /etc/apt/keyrings
<span class="nv">K8SMMV</span><span class="o">=</span><span class="si">$(</span><span class="nb">echo</span> <span class="nv">$1</span> | <span class="nb">sed</span> <span class="nt">-En</span> <span class="s1">'s/^([0-9]+\.[0-9]+)\..*/\1/p'</span><span class="si">)</span>
curl <span class="nt">-fsSL</span> https://pkgs.k8s.io/core:/stable:/v<span class="nv">$K8SMMV</span>/deb/Release.key | <span class="nb">sudo </span>gpg <span class="nt">--dearmor</span> <span class="nt">-o</span> /etc/apt/keyrings/kubernetes-apt-keyring.gpg
<span class="nb">echo</span> <span class="s2">"deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v</span><span class="nv">$K8SMMV</span><span class="s2">/deb/ /"</span> <span class="o">&gt;&gt;</span> /etc/apt/sources.list.d/kubernetes.list
curl <span class="nt">-fsSL</span> https://download.docker.com/linux/ubuntu/gpg <span class="nt">-o</span> /etc/apt/keyrings/docker.asc
<span class="nb">echo</span> <span class="s2">"deb [arch=</span><span class="si">$(</span>dpkg <span class="nt">--print-architecture</span><span class="si">)</span><span class="s2"> signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu </span><span class="si">$(</span><span class="nb">.</span> /etc/os-release <span class="o">&amp;&amp;</span> <span class="nb">echo</span> <span class="s2">"</span><span class="nv">$VERSION_CODENAME</span><span class="s2">"</span><span class="si">)</span><span class="s2"> stable"</span> | <span class="nb">tee</span> /etc/apt/sources.list.d/docker.list <span class="o">&gt;</span> /dev/null
  
<span class="c"># packets traversing the bridge are processed by iptables for filtering</span>
<span class="nb">echo </span>1 <span class="o">&gt;</span> /proc/sys/net/ipv4/ip_forward
<span class="nb">echo</span> <span class="s2">"net.ipv4.ip_forward = 1"</span> <span class="o">&gt;&gt;</span> /etc/sysctl.d/k8s.conf
  
<span class="c"># enable br_netfilter for iptables </span>
modprobe br_netfilter
modprobe overlay
<span class="nb">echo</span> <span class="s2">"br_netfilter"</span> <span class="o">&gt;&gt;</span> /etc/modules-load.d/k8s.conf
<span class="nb">echo</span> <span class="s2">"overlay"</span> <span class="o">&gt;&gt;</span> /etc/modules-load.d/k8s.conf
  
<span class="nb">echo</span> <span class="s2">"[TASK 5] Install Kubernetes components (kubeadm, kubelet and kubectl)"</span>
<span class="c"># Update the apt package index, install kubelet, kubeadm and kubectl, and pin their version</span>
apt update <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="c"># apt list -a kubelet ; apt list -a containerd.io</span>
apt-get <span class="nb">install</span> <span class="nt">-y</span> <span class="nv">kubelet</span><span class="o">=</span><span class="nv">$1</span> <span class="nv">kubectl</span><span class="o">=</span><span class="nv">$1</span> <span class="nv">kubeadm</span><span class="o">=</span><span class="nv">$1</span> containerd.io<span class="o">=</span><span class="nv">$2</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
apt-mark hold kubelet kubeadm kubectl <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="c"># containerd configure to default and cgroup managed by systemd</span>
containerd config default <span class="o">&gt;</span> /etc/containerd/config.toml
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'s/SystemdCgroup = false/SystemdCgroup = true/g'</span> /etc/containerd/config.toml
  
<span class="c"># avoid WARN&amp;ERRO(default endpoints) when crictl run  </span>
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; /etc/crictl.yaml
runtime-endpoint: unix:///run/containerd/containerd.sock
image-endpoint: unix:///run/containerd/containerd.sock
</span><span class="no">EOF
  
</span><span class="c"># ready to install for k8s </span>
systemctl restart containerd <span class="o">&amp;&amp;</span> systemctl <span class="nb">enable </span>containerd
systemctl <span class="nb">enable</span> <span class="nt">--now</span> kubelet
  
<span class="nb">echo</span> <span class="s2">"[TASK 6] Install Packages &amp; Helm"</span>
<span class="nb">export </span><span class="nv">DEBIAN_FRONTEND</span><span class="o">=</span>noninteractive
apt-get <span class="nb">install</span> <span class="nt">-y</span> bridge-utils sshpass net-tools conntrack ngrep tcpdump ipset arping wireguard jq yq tree bash-completion unzip kubecolor termshark <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
curl <span class="nt">-s</span> https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config End &lt;&lt;&lt;&lt;"</span>
  
</code></pre></div>    </div>
  </li>
  <li><strong>k8s-ctr.sh</strong> : kubeadm init를 통하여 kubernetes controlplane 노드를 설정하고 Cilium CNI 설치, 편리성 설정(k, kc)하는 스크립트입니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Controlplane config Start &lt;&lt;&lt;&lt;"</span>
  
<span class="nb">echo</span> <span class="s2">"[TASK 1] Initial Kubernetes"</span>
curl <span class="nt">--silent</span> <span class="nt">-o</span> /root/kubeadm-init-ctr-config.yaml https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/kubeadm-init-ctr-config.yaml
<span class="nv">K8SMMV</span><span class="o">=</span><span class="si">$(</span><span class="nb">echo</span> <span class="nv">$3</span> | <span class="nb">sed</span> <span class="nt">-En</span> <span class="s1">'s/^([0-9]+\.[0-9]+\.[0-9]+).*/\1/p'</span><span class="si">)</span>
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/K8S_VERSION_PLACEHOLDER/v</span><span class="k">${</span><span class="nv">K8SMMV</span><span class="k">}</span><span class="s2">/g"</span> /root/kubeadm-init-ctr-config.yaml
kubeadm init <span class="nt">--config</span><span class="o">=</span><span class="s2">"/root/kubeadm-init-ctr-config.yaml"</span>  <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="nb">echo</span> <span class="s2">"[TASK 2] Setting kube config file"</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> /root/.kube
<span class="nb">cp</span> <span class="nt">-i</span> /etc/kubernetes/admin.conf /root/.kube/config
<span class="nb">chown</span> <span class="si">$(</span><span class="nb">id</span> <span class="nt">-u</span><span class="si">)</span>:<span class="si">$(</span><span class="nb">id</span> <span class="nt">-g</span><span class="si">)</span> /root/.kube/config
  
<span class="nb">echo</span> <span class="s2">"[TASK 3] Source the completion"</span>
<span class="nb">echo</span> <span class="s1">'source &lt;(kubectl completion bash)'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'source &lt;(kubeadm completion bash)'</span> <span class="o">&gt;&gt;</span> /etc/profile
  
<span class="nb">echo</span> <span class="s2">"[TASK 4] Alias kubectl to k"</span>
<span class="nb">echo</span> <span class="s1">'alias k=kubectl'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'alias kc=kubecolor'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'complete -F __start_kubectl k'</span> <span class="o">&gt;&gt;</span> /etc/profile
  
<span class="nb">echo</span> <span class="s2">"[TASK 5] Install Kubectx &amp; Kubens"</span>
git clone https://github.com/ahmetb/kubectx /opt/kubectx <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">ln</span> <span class="nt">-s</span> /opt/kubectx/kubens /usr/local/bin/kubens
<span class="nb">ln</span> <span class="nt">-s</span> /opt/kubectx/kubectx /usr/local/bin/kubectx
  
<span class="nb">echo</span> <span class="s2">"[TASK 6] Install Kubeps &amp; Setting PS1"</span>
git clone https://github.com/jonmosco/kube-ps1.git /root/kube-ps1 <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="sh">"</span><span class="no">EOT</span><span class="sh">" &gt;&gt; /root/.bash_profile
source /root/kube-ps1/kube-ps1.sh
KUBE_PS1_SYMBOL_ENABLE=true
function get_cluster_short() {
  echo "</span><span class="nv">$1</span><span class="sh">" | cut -d . -f1
}
KUBE_PS1_CLUSTER_FUNCTION=get_cluster_short
KUBE_PS1_SUFFIX=') '
PS1='</span><span class="si">$(</span>kube_ps1<span class="si">)</span><span class="sh">'</span><span class="nv">$PS1</span><span class="sh">
</span><span class="no">EOT
</span>kubectl config rename-context <span class="s2">"kubernetes-admin@kubernetes"</span> <span class="s2">"HomeLab"</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="nb">echo</span> <span class="s2">"[TASK 7] Install Cilium CNI"</span>
<span class="nv">NODEIP</span><span class="o">=</span><span class="si">$(</span>ip <span class="nt">-4</span> addr show eth1 | <span class="nb">grep</span> <span class="nt">-oP</span> <span class="s1">'(?&lt;=inet\s)\d+(\.\d+){3}'</span><span class="si">)</span>
helm repo add cilium https://helm.cilium.io/ <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
helm repo update <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
helm <span class="nb">install </span>cilium cilium/cilium <span class="nt">--version</span> <span class="nv">$2</span> <span class="nt">--namespace</span> kube-system <span class="se">\</span>
<span class="nt">--set</span> <span class="nv">k8sServiceHost</span><span class="o">=</span>192.168.10.100 <span class="nt">--set</span> <span class="nv">k8sServicePort</span><span class="o">=</span>6443 <span class="se">\</span>
<span class="nt">--set</span> ipam.mode<span class="o">=</span><span class="s2">"kubernetes"</span> <span class="nt">--set</span> k8s.requireIPv4PodCIDR<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> <span class="nv">ipv4NativeRoutingCIDR</span><span class="o">=</span>10.244.0.0/16 <span class="se">\</span>
<span class="nt">--set</span> <span class="nv">routingMode</span><span class="o">=</span>native <span class="nt">--set</span> <span class="nv">autoDirectNodeRoutes</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> endpointRoutes.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> <span class="nv">kubeProxyReplacement</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> bpf.masquerade<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> <span class="nv">installNoConntrackIptablesRules</span><span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> endpointHealthChecking.enabled<span class="o">=</span><span class="nb">false</span> <span class="nt">--set</span> <span class="nv">healthChecking</span><span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
<span class="nt">--set</span> hubble.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> hubble.relay.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> hubble.ui.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> hubble.ui.service.type<span class="o">=</span>NodePort <span class="nt">--set</span> hubble.ui.service.nodePort<span class="o">=</span>30003 <span class="se">\</span>
<span class="nt">--set</span> prometheus.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> operator.prometheus.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> hubble.metrics.enableOpenMetrics<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> hubble.metrics.enabled<span class="o">=</span><span class="s2">"{dns,drop,tcp,flow,port-distribution,icmp,httpV2:exemplars=true;labelsContext=source_ip</span><span class="se">\,</span><span class="s2">source_namespace</span><span class="se">\,</span><span class="s2">source_workload</span><span class="se">\,</span><span class="s2">destination_ip</span><span class="se">\,</span><span class="s2">destination_namespace</span><span class="se">\,</span><span class="s2">destination_workload</span><span class="se">\,</span><span class="s2">traffic_direction}"</span> <span class="se">\</span>
<span class="nt">--set</span> operator.replicas<span class="o">=</span>1 <span class="nt">--set</span> debug.enabled<span class="o">=</span><span class="nb">true</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="c">#--set ipam.mode="cluster-pool" --set ipam.operator.clusterPoolIPv4PodCIDRList={"172.20.0.0/16"} --set ipv4NativeRoutingCIDR=172.20.0.0/16 \</span>
  
<span class="nb">echo</span> <span class="s2">"[TASK 8] Install Cilium / Hubble CLI"</span>
<span class="nv">CILIUM_CLI_VERSION</span><span class="o">=</span><span class="si">$(</span>curl <span class="nt">-s</span> https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt<span class="si">)</span>
<span class="nv">CLI_ARCH</span><span class="o">=</span>amd64
<span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span><span class="si">)</span><span class="s2">"</span> <span class="o">=</span> <span class="s2">"aarch64"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then </span><span class="nv">CLI_ARCH</span><span class="o">=</span>arm64<span class="p">;</span> <span class="k">fi
</span>curl <span class="nt">-L</span> <span class="nt">--fail</span> <span class="nt">--remote-name-all</span> https://github.com/cilium/cilium-cli/releases/download/<span class="k">${</span><span class="nv">CILIUM_CLI_VERSION</span><span class="k">}</span>/cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">tar </span>xzvfC cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz /usr/local/bin
<span class="nb">rm </span>cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz
  
<span class="nv">HUBBLE_VERSION</span><span class="o">=</span><span class="si">$(</span>curl <span class="nt">-s</span> https://raw.githubusercontent.com/cilium/hubble/master/stable.txt<span class="si">)</span>
<span class="nv">HUBBLE_ARCH</span><span class="o">=</span>amd64
<span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span><span class="si">)</span><span class="s2">"</span> <span class="o">=</span> <span class="s2">"aarch64"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then </span><span class="nv">HUBBLE_ARCH</span><span class="o">=</span>arm64<span class="p">;</span> <span class="k">fi
</span>curl <span class="nt">-L</span> <span class="nt">--fail</span> <span class="nt">--remote-name-all</span> https://github.com/cilium/hubble/releases/download/<span class="nv">$HUBBLE_VERSION</span>/hubble-linux-<span class="k">${</span><span class="nv">HUBBLE_ARCH</span><span class="k">}</span>.tar.gz <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">tar </span>xzvfC hubble-linux-<span class="k">${</span><span class="nv">HUBBLE_ARCH</span><span class="k">}</span>.tar.gz /usr/local/bin
<span class="nb">rm </span>hubble-linux-<span class="k">${</span><span class="nv">HUBBLE_ARCH</span><span class="k">}</span>.tar.gz
  
<span class="nb">echo</span> <span class="s2">"[TASK 9] Remove node taint"</span>
kubectl taint nodes k8s-ctr node-role.kubernetes.io/control-plane-
  
<span class="nb">echo</span> <span class="s2">"[TASK 10] local DNS with hosts file"</span>
<span class="nb">echo</span> <span class="s2">"192.168.10.100 k8s-ctr"</span> <span class="o">&gt;&gt;</span> /etc/hosts
<span class="k">for</span> <span class="o">((</span> <span class="nv">i</span><span class="o">=</span>1<span class="p">;</span> i&lt;<span class="o">=</span><span class="nv">$1</span><span class="p">;</span> i++  <span class="o">))</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"192.168.10.10</span><span class="nv">$i</span><span class="s2"> k8s-w</span><span class="nv">$i</span><span class="s2">"</span> <span class="o">&gt;&gt;</span> /etc/hosts<span class="p">;</span> <span class="k">done
  
</span><span class="nb">echo</span> <span class="s2">"[TASK 11] Install Prometheus &amp; Grafana"</span>
kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/kubernetes/addons/prometheus/monitoring-example.yaml <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
kubectl patch svc <span class="nt">-n</span> cilium-monitoring prometheus <span class="nt">-p</span> <span class="s1">'{"spec": {"type": "NodePort", "ports": [{"port": 9090, "targetPort": 9090, "nodePort": 30001}]}}'</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
kubectl patch svc <span class="nt">-n</span> cilium-monitoring grafana <span class="nt">-p</span> <span class="s1">'{"spec": {"type": "NodePort", "ports": [{"port": 3000, "targetPort": 3000, "nodePort": 30002}]}}'</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="nb">echo</span> <span class="s2">"[TASK 12] Dynamically provisioning persistent local storage with Kubernetes"</span>
kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.31/deploy/local-path-storage.yaml <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
kubectl patch storageclass local-path <span class="nt">-p</span> <span class="s1">'{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Controlplane Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div>    </div>

    <ul>
      <li>이번 실습에서는 <code class="language-plaintext highlighter-rouge">--set endpointHealthChecking.enabled=false</code> 과 <code class="language-plaintext highlighter-rouge">--set healthChecking=false</code> 옵션을 통해 endpoint health check를 완전히 해제합니다.</li>
      <li>참고로 해당 health check 기능은 비교적 소규모의 클러스터(3~10노드)에만 활성화 하기를 권장하고 있습니다. 대규모의 클러스터에서는 방화벽 정책이나 하이퍼바이저 설정으로 인해 패킷 손실이 발생할 수 있기 때문입니다. - <a href="https://docs.cilium.io/en/stable/operations/performance/scalability/report/">Docs</a></li>
      <li>
        <p><strong>kubeadm-init-ctr-config.yaml</strong></p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  apiVersion: kubeadm.k8s.io/v1beta4
  kind: <span class="k">**</span>InitConfiguration<span class="k">**</span>
  bootstrapTokens:
  - token: <span class="s2">"123456.1234567890123456"</span>
    ttl: <span class="s2">"0s"</span>
    usages:
    - signing
    - authentication
  localAPIEndpoint:
    advertiseAddress: <span class="s2">"192.168.10.100"</span>
  nodeRegistration:
    <span class="k">**</span>kubeletExtraArgs:
      - name: node-ip
        value: <span class="s2">"192.168.10.100"</span><span class="k">**</span>
    criSocket: <span class="s2">"unix:///run/containerd/containerd.sock"</span>
  <span class="nt">---</span>
  apiVersion: kubeadm.k8s.io/v1beta4
  kind: <span class="k">**</span>ClusterConfiguration<span class="k">**</span>
  kubernetesVersion: <span class="s2">"**K8S_VERSION_PLACEHOLDER**"</span>
  networking:
    podSubnet: <span class="s2">"10.244.0.0/16"</span>
    serviceSubnet: <span class="s2">"10.96.0.0/16"</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li><strong>k8s-w.sh</strong> : kubernetes worker 노드 설정, kubeadm join, Cilium CNI 설치 등을 수행하는  스크립트입니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Node config Start &lt;&lt;&lt;&lt;"</span>
  
<span class="nb">echo</span> <span class="s2">"[TASK 1] K8S Controlplane Join"</span>
curl <span class="nt">--silent</span> <span class="nt">-o</span> /root/kubeadm-join-worker-config.yaml https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/2w/kubeadm-join-worker-config.yaml
<span class="nv">NODEIP</span><span class="o">=</span><span class="si">$(</span>ip <span class="nt">-4</span> addr show eth1 | <span class="nb">grep</span> <span class="nt">-oP</span> <span class="s1">'(?&lt;=inet\s)\d+(\.\d+){3}'</span><span class="si">)</span>
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/NODE_IP_PLACEHOLDER/</span><span class="k">${</span><span class="nv">NODEIP</span><span class="k">}</span><span class="s2">/g"</span> /root/kubeadm-join-worker-config.yaml
kubeadm <span class="nb">join</span> <span class="nt">--config</span><span class="o">=</span><span class="s2">"/root/kubeadm-join-worker-config.yaml"</span> <span class="o">&gt;</span> /dev/null 2&gt;&amp;1
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Node config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div>    </div>
    <ul>
      <li>
        <p><strong>kubeadm-join-worker-config.yaml</strong></p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apiVersion: kubeadm.k8s.io/v1beta4
kind: JoinConfiguration
discovery:
  bootstrapToken:
    token: <span class="s2">"123456.1234567890123456"</span>
    apiServerEndpoint: <span class="s2">"192.168.10.100:6443"</span>
    unsafeSkipCAVerification: <span class="nb">true
</span>nodeRegistration:
  criSocket: <span class="s2">"unix:///run/containerd/containerd.sock"</span>
  kubeletExtraArgs:
    - name: node-ip
      value: <span class="s2">"NODE_IP_PLACEHOLDER"</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>route-add1.sh</strong> : k8s node 들이 사내망(?)과 통신을 위한 route 설정 스크립트입니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Route Add Config Start &lt;&lt;&lt;&lt;"</span>
  
<span class="nb">chmod </span>600 /etc/netplan/01-netcfg.yaml
<span class="nb">chmod </span>600 /etc/netplan/50-vagrant.yaml
  
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh">&gt;&gt; /etc/netplan/50-vagrant.yaml
      routes:
      - to: 10.10.0.0/16
        via: 192.168.10.200
</span><span class="no">EOT
  
</span>netplan apply
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Route Add Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>router.sh</strong> : router 역할과 추가적으로 웹서버 역할을 하는 서버의 초기 설정을 담당합니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config Start &lt;&lt;&lt;&lt;"</span>
  
<span class="nb">echo</span> <span class="s2">"[TASK 1] Setting Profile &amp; Bashrc"</span>
<span class="nb">echo</span> <span class="s1">'alias vi=vim'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s2">"sudo su -"</span> <span class="o">&gt;&gt;</span> /home/vagrant/.bashrc
<span class="nb">ln</span> <span class="nt">-sf</span> /usr/share/zoneinfo/Asia/Seoul /etc/localtime
  
<span class="nb">echo</span> <span class="s2">"[TASK 2] Disable AppArmor"</span>
systemctl stop ufw <span class="o">&amp;&amp;</span> systemctl disable ufw <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
systemctl stop apparmor <span class="o">&amp;&amp;</span> systemctl disable apparmor <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="nb">echo</span> <span class="s2">"[TASK 3] Add Kernel setting - IP Forwarding"</span>
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'s/#net.ipv4.ip_forward=1/net.ipv4.ip_forward=1/g'</span> /etc/sysctl.conf
sysctl <span class="nt">-p</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="nb">echo</span> <span class="s2">"[TASK 4] Setting Dummy Interface"</span>
modprobe dummy
ip <span class="nb">link </span>add loop1 <span class="nb">type </span>dummy
ip <span class="nb">link set </span>loop1 up
ip addr add 10.10.1.200/24 dev loop1
  
ip <span class="nb">link </span>add loop2 <span class="nb">type </span>dummy
ip <span class="nb">link set </span>loop2 up
ip addr add 10.10.2.200/24 dev loop2
  
<span class="nb">echo</span> <span class="s2">"[TASK 5] Install Packages"</span>
<span class="nb">export </span><span class="nv">DEBIAN_FRONTEND</span><span class="o">=</span>noninteractive
apt update <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
apt-get <span class="nb">install </span>net-tools jq tree ngrep tcpdump arping <span class="nt">-y</span> <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
  
<span class="nb">echo</span> <span class="s2">"[TASK 6] Install Apache"</span>
apt <span class="nb">install </span>apache2 <span class="nt">-y</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"&lt;h1&gt;Web Server : </span><span class="si">$(</span><span class="nb">hostname</span><span class="si">)</span><span class="s2">&lt;/h1&gt;"</span> <span class="o">&gt;</span> /var/www/html/index.html
  
<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div>    </div>
  </li>
</ul>

<h3 id="실습환경-배포-및-분석-툴-설치">실습환경 배포 및 분석 툴 설치</h3>

<ul>
  <li>
    <p>실습환경 배포</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>vagrant up
<span class="c"># =&gt;     ...</span>
<span class="c">#        router: [TASK 5] Install Packages</span>
<span class="c">#        router: [TASK 6] Install Apache</span>
<span class="c">#        router: &gt;&gt;&gt;&gt; Initial Config End &lt;&lt;&lt;&lt;</span>
</code></pre></div>    </div>
  </li>
  <li><code class="language-plaintext highlighter-rouge">k8s-ctr</code>, cilium 설치정보확인은 지난주의 포스트를 참고해주세요. <a href="https://sweetlittlebird.github.io/posts/2025-07-27-Cilium-Week2/#%EC%8B%A4%EC%8A%B5%ED%99%98%EA%B2%BD-%EB%B0%B0%ED%8F%AC">링크</a></li>
  <li><code class="language-plaintext highlighter-rouge">k9s</code>
    <ul>
      <li>이번 주에는 k9s라는 CLI 기반의 Kubernetes 대시보드 툴을 설치하고 살펴보겠습니다. <a href="https://github.com/derailed/k9s">github</a></li>
      <li>설치 및 실행
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># arm64 CPU 일 경우</span>
<span class="nv">$ </span>wget https://github.com/derailed/k9s/releases/latest/download/k9s_linux_arm64.deb <span class="nt">-O</span> /tmp/k9s_linux_arm64.deb
<span class="nv">$ </span>apt <span class="nb">install</span> /tmp/k9s_linux_arm64.deb
<span class="c"># =&gt; ...</span>
<span class="c">#    Preparing to unpack /tmp/k9s_linux_arm64.deb ...</span>
<span class="c">#    Unpacking k9s (0.50.9) ...</span>
<span class="c">#    Setting up k9s (0.50.9) ...</span>
    
<span class="c"># amd64 CPU 일 경우</span>
<span class="nv">$ </span>wget https://github.com/derailed/k9s/releases/latest/download/k9s_linux_amd64.deb <span class="nt">-O</span> /tmp/k9s_linux_amd64.deb
<span class="nv">$ </span>apt <span class="nb">install</span> /tmp/k9s_linux_amd64.deb
    
<span class="c"># k9s 설치 경로 확인</span>
<span class="nv">$ </span>which k9s
<span class="c"># =&gt; /usr/bin/k9s</span>
    
<span class="c"># k9s 실행</span>
<span class="nv">$ </span>k9s
</code></pre></div>        </div>
      </li>
      <li>실행 화면
<img src="/assets/2025/cilium/w3/20250803_cilium_w3_2.png" alt="img.png" />
터미널이지만 한눈에 보기 쉽게 구성되어 있습니다.</li>
      <li><code class="language-plaintext highlighter-rouge">k9s</code> 기본 사용법
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 버전 확인</span>
<span class="nv">$ </span>k9s version
<span class="c"># =&gt;  ____  __ ________</span>
<span class="c">#    |    |/  /   __   \______</span>
<span class="c">#    |       /\____    /  ___/</span>
<span class="c">#    |    \   \  /    /\___  \</span>
<span class="c">#    |____|\__ \/____//____  /</span>
<span class="c">#             \/           \/</span>
<span class="c">#    Version:    v0.50.9</span>
<span class="c">#    Commit:     ffdc7b70f044e1f26c2f6fbb93b5495e4ebdb1ad</span>
    
<span class="c"># k9s 런타임에 대한 정보</span>
<span class="nv">$ </span>k9s info
<span class="c"># =&gt; ...</span>
<span class="c">#    Version:           v0.50.9</span>
<span class="c">#    Config:            /root/.config/k9s/config.yaml</span>
<span class="c">#    Custom Views:      /root/.config/k9s/views.yaml</span>
<span class="c">#    Plugins:           /root/.config/k9s/plugins.yaml</span>
<span class="c">#    Hotkeys:           /root/.config/k9s/hotkeys.yaml</span>
<span class="c">#    Aliases:           /root/.config/k9s/aliases.yaml</span>
<span class="c">#    Skins:             /root/.config/k9s/skins</span>
<span class="c">#    Context Configs:   /root/.local/share/k9s/clusters</span>
<span class="c">#    Logs:              /root/.local/state/k9s/k9s.log</span>
<span class="c">#    Benchmarks:        /root/.local/state/k9s/benchmarks</span>
<span class="c">#    ScreenDumps:       /root/.local/state/k9s/screen-dumps</span>
    
<span class="c"># CLI의 도움말</span>
<span class="nv">$ </span>k9s <span class="nb">help</span>
    
<span class="c"># 특정 네임스페이스에서 K9s 시작</span>
<span class="nv">$ </span>k9s <span class="nt">-n</span> mycoolns
    
<span class="c"># KubeConfig에 존재하는 컨텍스트로 K9s 시작</span>
<span class="nv">$ </span>k9s <span class="nt">--context</span> coolCtx
    
<span class="c"># K9s를 읽기 전용 모드로 시작 - 클러스터 수정 명령이 비활성화됩니다.</span>
<span class="nv">$ </span>k9s <span class="nt">--readonly</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">termshark</code>
    <ul>
      <li>터미널에서 Wireshark 처럼 패킷을 볼 수 있는 툴입니다. <a href="https://github.com/gcla/termshark">github</a>, <a href="https://termshark.io/">Home</a>
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 이미 설치되어 있음</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">DEBIAN_FRONTEND</span><span class="o">=</span>noninteractive
<span class="nv">$ </span>apt-get <span class="nb">install</span> <span class="nt">-y</span> termshark
<span class="c"># =&gt; Reading package lists... Done</span>
<span class="c">#    Building dependency tree... Done</span>
<span class="c">#    Reading state information... Done</span>
<span class="c">#    termshark is already the newest version (2.4.0-1ubuntu0.24.04.3).</span>
<span class="c">#    0 upgraded, 0 newly installed, 0 to remove and 170 not upgraded.</span>
    
<span class="c"># pcap 파일 분석</span>
<span class="nv">$ </span>termshark <span class="nt">-r</span> test.pcap
    
<span class="c"># eth0 인터페이스에서 ping 패킷을 캡처합니다.</span>
<span class="nv">$ </span>termshark <span class="nt">-i</span> eth0 icmp
</code></pre></div>        </div>
      </li>
      <li>실행 화면
<img src="/assets/2025/cilium/w3/20250803_cilium_w3_3.png" alt="img.png" /></li>
    </ul>
  </li>
</ul>

<hr />

<h2 id="ipam">IPAM</h2>

<ul>
  <li>
    <p>IPAM은 <code class="language-plaintext highlighter-rouge">IP Address Management</code>의 약자로, 네트워크 엔드포인트(컨테이너 등)에 대한 IP 주소를 할당하고 관리하는 시스템입니다. <a href="https://docs.cilium.io/en/stable/network/concepts/ipam/">Docs</a></p>

    <table>
      <thead>
        <tr>
          <th><strong>Feature</strong></th>
          <th><strong>Kubernetes Host Scope</strong></th>
          <th><strong>Cluster Scope (default)</strong></th>
          <th><strong>Multi-Pool (Beta)</strong></th>
          <th><strong>CRD-backed</strong></th>
          <th><strong>AWS ENI…</strong></th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>Tunnel routing</td>
          <td>✅</td>
          <td>✅</td>
          <td>❌</td>
          <td>❌</td>
          <td>❌</td>
        </tr>
        <tr>
          <td>Direct routing</td>
          <td>✅</td>
          <td>✅</td>
          <td>✅</td>
          <td>✅</td>
          <td>✅</td>
        </tr>
        <tr>
          <td>CIDR Configuration</td>
          <td>Kubernetes</td>
          <td>Cilium</td>
          <td>Cilium</td>
          <td>External</td>
          <td>External (AWS)</td>
        </tr>
        <tr>
          <td>Multiple CIDRs per cluster</td>
          <td>❌</td>
          <td>✅</td>
          <td>✅</td>
          <td>N/A</td>
          <td>N/A</td>
        </tr>
        <tr>
          <td>Multiple CIDRs per node</td>
          <td>❌</td>
          <td>❌</td>
          <td>✅</td>
          <td>N/A</td>
          <td>N/A</td>
        </tr>
        <tr>
          <td>Dynamic CIDR/IP allocation</td>
          <td>❌</td>
          <td>❌</td>
          <td>✅</td>
          <td>✅</td>
          <td>✅</td>
        </tr>
      </tbody>
    </table>

    <blockquote>
      <p>기존 <strong>클러스터의 IPAM 모드</strong>를 변경하지 마세요.<br />
라이브 환경에서 IPAM 모드를 변경하면 기존 워크로드의 <strong>지속적인 연결 중단</strong>이 발생할 수 있습니다.<br />
IPAM 모드를 변경하는 가장 안전한 방법은 새로운 IPAM 구성으로 새로운 Kubernetes 클러스터를 설치하는 것입니다.</p>
    </blockquote>
  </li>
</ul>

<h3 id="kubernetes-host-scope">Kubernetes Host Scope</h3>

<p><a href="https://docs.cilium.io/en/stable/network/concepts/ipam/kubernetes/">Docs</a></p>

<p><img src="/assets/2025/cilium/w3/20250803_cilium_w3_4.png" alt="img.png" /></p>

<ul>
  <li>Kubernetes 호스트 범위 IPAM 모드는 <code class="language-plaintext highlighter-rouge">ipam: Kubernetes</code>로 활성화되며, 클러스터의 각 개별 노드에 주소 할당을 위임합니다.</li>
  <li>IP는 Kubernetes에 의해 각 노드에 연결된 PodCIDR 범위에서 할당됩니다. 즉, CIDR 설정의 주체는 Kubernetes입니다.</li>
  <li>이 모드에서는 Cilium 에이전트가 <code class="language-plaintext highlighter-rouge">Kubernetes v1.Node</code> 객체를 통해 PodCIDR 범위가 다음 방법 중 하나를 통해 활성화된 모든 주소 패밀리에 대해 제공될때까지 시작시 대기합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 클러스터 정보 확인</span>
<span class="nv">$ </span>kubectl cluster-info dump | <span class="nb">grep</span> <span class="nt">-m</span> 2 <span class="nt">-E</span> <span class="s2">"cluster-cidr|service-cluster-ip-range"</span>
<span class="c"># =&gt;                             "--service-cluster-ip-range=10.96.0.0/16",</span>
<span class="c">#                                "--cluster-cidr=10.244.0.0/16",</span>

<span class="c"># ipam 모드 확인</span>
<span class="nv">$ </span>cilium config view | <span class="nb">grep</span> ^ipam
<span class="c"># =&gt; ipam                                              kubernetes</span>
<span class="c">#    ipam-cilium-node-update-rate                      15s</span>

<span class="c"># 노드별 파드에 할당되는 IPAM(PodCIDR) 정보 확인</span>
<span class="c"># --allocate-node-cidrs=true 로 설정된 kube-controller-manager에서 CIDR을 자동 할당함</span>
<span class="nv">$ </span>kubectl get nodes <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{range .items[*]}{.metadata.name}{"\t"}{.spec.podCIDR}{"\n"}{end}'</span>
<span class="c"># =&gt; k8s-ctr 10.244.0.0/24</span>
<span class="c">#    k8s-w1  10.244.1.0/24</span>

<span class="nv">$ </span>kc describe pod <span class="nt">-n</span> kube-system kube-controller-manager-k8s-ctr
<span class="c"># =&gt; ....</span>
<span class="c">#    Command:</span>
<span class="c">#          kube-controller-manager</span>
<span class="c">#          --allocate-node-cidrs=true</span>
<span class="c">#          --cluster-cidr=10.244.0.0/16</span>
<span class="c">#          --service-cluster-ip-range=10.96.0.0/16</span>
<span class="c">#    ...</span>

<span class="nv">$ </span>kubectl get ciliumnode <span class="nt">-o</span> json | <span class="nb">grep </span>podCIDRs <span class="nt">-A2</span>
<span class="c"># =&gt;                     "podCIDRs": [</span>
<span class="c">#                            "10.244.0.0/24"</span>
<span class="c">#                        ],</span>
<span class="c">#    --</span>
<span class="c">#                        "podCIDRs": [</span>
<span class="c">#                            "10.244.1.0/24"</span>
<span class="c">#                        ],</span>

<span class="c"># 파드 정보 : 상태, 파드 IP 확인</span>
<span class="nv">$ </span>kubectl get ciliumendpoints.cilium.io <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE            NAME                                      SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    cilium-monitoring    grafana-5c69859d9-zgx9k                   22364               ready            10.244.0.5</span>
<span class="c">#    cilium-monitoring    prometheus-6fc896bc5d-5rbpx               15628               ready            10.244.0.143</span>
<span class="c">#    kube-system          coredns-674b8bbfcf-dhckj                  28257               ready            10.244.0.155</span>
<span class="c">#    kube-system          coredns-674b8bbfcf-n4xbw                  28257               ready            10.244.0.7</span>
<span class="c">#    kube-system          hubble-relay-5dcd46f5c-9bcxl              9702                ready            10.244.0.59</span>
<span class="c">#    kube-system          hubble-ui-76d4965bb6-rq9gv                64346               ready            10.244.0.166</span>
<span class="c">#    local-path-storage   local-path-provisioner-74f9666bc9-rrn2r   29718               ready            10.244.0.130</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 현재 모든 파드가 k8s-ctr에서 동작 중이어서 10.244.0.0/24 아이피가 할당된 것을 확인할 수 있습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<h4 id="샘플-애플리케이션-배포-및-확인">샘플 애플리케이션 배포 및 확인</h4>

<ul>
  <li>샘플 애플리케이션을 배포하고 IPAM이 올바르게 작동하는지 확인합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 샘플 애플리케이션 배포</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webpod
spec:
  replicas: 2
  selector:
    matchLabels:
      app: webpod
  template:
    metadata:
      labels:
        app: webpod
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - sample-app
            topologyKey: "kubernetes.io/hostname"
      containers:
      - name: webpod
        image: traefik/whoami
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: webpod
  labels:
    app: webpod
spec:
  selector:
    app: webpod
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
  type: ClusterIP
</span><span class="no">EOF
</span><span class="c"># =&gt; deployment.apps/webpod created</span>
<span class="c">#    service/webpod created</span>

<span class="c"># k8s-ctr 노드에 curl-pod 파드 배포</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: curl-pod
  labels:
    app: curl
spec:
  nodeName: k8s-ctr
  containers:
  - name: curl
    image: nicolaka/netshoot
    command: ["tail"]
    args: ["-f", "/dev/null"]
  terminationGracePeriodSeconds: 0
</span><span class="no">EOF
</span><span class="c"># =&gt; pod/curl-pod created</span>
</code></pre></div></div>

<ul>
  <li>배포 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 배포 확인</span>
<span class="nv">$ </span>kubectl get deploy,svc,ep webpod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                     READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES           SELECTOR</span>
<span class="c">#    deployment.apps/webpod   2/2     2            2           77s   webpod       traefik/whoami   app=webpod</span>
<span class="c">#    </span>
<span class="c">#    NAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE   SELECTOR</span>
<span class="c">#    service/webpod   ClusterIP   10.96.194.47   &lt;none&gt;        80/TCP    77s   app=webpod</span>
<span class="c">#    </span>
<span class="c">#    NAME               ENDPOINTS                       AGE</span>
<span class="c">#    endpoints/webpod   10.244.0.2:80,10.244.1.188:80   77s</span>
<span class="nv">$ </span>kubectl get endpointslices <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>webpod
<span class="c"># =&gt; NAME           ADDRESSTYPE   PORTS   ENDPOINTS                 AGE</span>
<span class="c">#    webpod-j45jt   IPv4          80      10.244.0.2,10.244.1.188   95s</span>
<span class="nv">$ </span>kubectl get ciliumendpoints <span class="c"># IP 확인</span>
<span class="c"># =&gt; NAME                      SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    curl-pod                  1072                ready            10.244.0.188</span>
<span class="c">#    webpod-697b545f57-2zpdp   24748               ready            10.244.0.2</span>
<span class="c">#    webpod-697b545f57-thl79   24748               ready            10.244.1.188</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium-dbg endpoint list

<span class="c"># 통신 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl webpod | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod-697b545f57-2zpdp</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s webpod | grep Hostname; sleep 1; done'</span>
<span class="c"># =&gt; Hostname: webpod-697b545f57-thl79</span>
<span class="c">#    Hostname: webpod-697b545f57-2zpdp</span>
<span class="c">#    Hostname: webpod-697b545f57-thl79</span>
<span class="c">#    Hostname: webpod-697b545f57-thl79</span>
<span class="c">#    Hostname: webpod-697b545f57-2zpdp</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<ul>
  <li>Hubble 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># hubble ui 웹 접속 주소 확인 : default 네임스페이스 확인</span>
<span class="nv">$ NODEIP</span><span class="o">=</span><span class="si">$(</span>ip <span class="nt">-4</span> addr show eth1 | <span class="nb">grep</span> <span class="nt">-oP</span> <span class="s1">'(?&lt;=inet\s)\d+(\.\d+){3}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"http://</span><span class="nv">$NODEIP</span><span class="s2">:30003"</span>
<span class="c"># =&gt; http://192.168.10.100:30003</span>

<span class="c"># hubble relay 포트 포워딩 실행</span>
<span class="nv">$ </span>cilium hubble port-forward&amp;
<span class="c"># =&gt; ℹ️   Hubble Relay is available at 127.0.0.1:4245</span>
<span class="nv">$ </span>hubble status
<span class="c"># =&gt; Healthcheck (via localhost:4245): Ok</span>
<span class="c">#    Current/Max Flows: 5,284/8,190 (64.52%)</span>
<span class="c">#    Flows/s: 33.82</span>
<span class="c">#    Connected Nodes: 2/2</span>

<span class="c"># flow log 모니터링</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--protocol</span> tcp <span class="nt">--to-pod</span> curl-pod
<span class="c"># =&gt; Aug  2 08:36:29.808: default/curl-pod:56772 (ID:1072) &lt;- default/webpod-697b545f57-thl79:80 (ID:24748) to-network FORWARDED (TCP Flags: ACK, FIN)</span>
<span class="c">#    Aug  2 08:36:30.530: default/curl-pod:50248 (ID:1072) &lt;- default/webpod-697b545f57-2zpdp:80 (ID:24748) to-endpoint FORWARDED (TCP Flags: SYN, ACK)</span>
<span class="c">#    Aug  2 08:36:30.533: default/curl-pod:50248 (ID:1072) &lt;- default/webpod-697b545f57-2zpdp:80 (ID:24748) to-endpoint FORWARDED (TCP Flags: ACK, PSH)</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--protocol</span> tcp <span class="nt">--from-pod</span> curl-pod
<span class="c"># =&gt; Aug  2 08:36:57.991: default/curl-pod (ID:1072) &lt;&gt; 10.96.194.47:80 (world) pre-xlate-fwd TRACED (TCP)</span>
<span class="c">#    Aug  2 08:36:57.991: default/curl-pod (ID:1072) &lt;&gt; default/webpod-697b545f57-thl79:80 (ID:24748) post-xlate-fwd TRANSLATED (TCP)</span>
<span class="c">#    Aug  2 08:36:57.991: default/curl-pod:51316 (ID:1072) -&gt; default/webpod-697b545f57-thl79:80 (ID:24748) to-network FORWARDED (TCP Flags: SYN)</span>
<span class="c">#    Aug  2 08:36:57.992: default/curl-pod:51316 (ID:1072) -&gt; default/webpod-697b545f57-thl79:80 (ID:24748) to-network FORWARDED (TCP Flags: ACK, PSH)</span>
<span class="c">#    Aug  2 08:36:57.993: default/curl-pod:51316 (ID:1072) -&gt; default/webpod-697b545f57-thl79:80 (ID:24748) to-network FORWARDED (TCP Flags: ACK)</span>
<span class="c">#    Aug  2 08:36:57.999: default/curl-pod:51316 (ID:1072) -&gt; default/webpod-697b545f57-thl79:80 (ID:24748) to-network FORWARDED (TCP Flags: ACK, FIN)</span>
<span class="c">#    Aug  2 08:36:57.999: default/curl-pod:51316 (ID:1072) -&gt; default/webpod-697b545f57-thl79:80 (ID:24748) to-network FORWARDED (TCP Flags: ACK)</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--protocol</span> tcp <span class="nt">--pod</span> curl-pod
<span class="c"># =&gt; Aug  2 08:37:22.316: default/curl-pod (ID:1072) &lt;&gt; 10.96.194.47:80 (world) pre-xlate-fwd TRACED (TCP)</span>
<span class="c">#    Aug  2 08:37:22.316: default/curl-pod (ID:1072) &lt;&gt; default/webpod-697b545f57-2zpdp:80 (ID:24748) post-xlate-fwd TRANSLATED (TCP)</span>
<span class="c">#    Aug  2 08:37:22.317: default/curl-pod:51022 (ID:1072) -&gt; default/webpod-697b545f57-2zpdp:80 (ID:24748) to-endpoint FORWARDED (TCP Flags: SYN)</span>
<span class="c">#    Aug  2 08:37:22.317: default/curl-pod:51022 (ID:1072) &lt;- default/webpod-697b545f57-2zpdp:80 (ID:24748) to-endpoint FORWARDED (TCP Flags: SYN, ACK)</span>
<span class="c">#    Aug  2 08:37:22.317: default/curl-pod:51022 (ID:1072) -&gt; default/webpod-697b545f57-2zpdp:80 (ID:24748) to-endpoint FORWARDED (TCP Flags: ACK)</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 pre-xlate-fwd, TRACED : NAT (IP 변환) 전, 추적 중인 flow&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   post-xlate-fwd, TRANSLATED : NAT 후의 흐름, NAT 변환이 일어났음&lt;/span&gt;</span>

<span class="c"># 호출 시도</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl webpod | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod-697b545f57-2zpdp</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl webpod | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod-697b545f57-thl79</span>
<span class="c"># 혹은</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s webpod | grep Hostname; sleep 1; done'</span>

<span class="c"># tcpdump 확인 : 파드 IP 확인</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> eth1 tcp port 80 <span class="nt">-nn</span>
<span class="c"># =&gt; 20:11:41.085067 IP 10.244.0.188.56954 &gt; 10.244.1.188.80: Flags [P.], seq 1:71, ack 1, win 502, options [nop,nop,TS val 2064675417 ecr 2283779636], length 70: HTTP: GET / HTTP/1.1</span>

<span class="c"># http 패킷 캡처</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> eth1 tcp port 80 <span class="nt">-w</span> /tmp/http.pcap

<span class="c"># termshark로 pcap 파일 분석</span>
<span class="nv">$ </span>termshark <span class="nt">-r</span> /tmp/http.pcap
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w3/20250803_cilium_w3_5.png" alt="img.png" class="image-center" />
<em class="image-caption">hubble UI에서 확인한 흐름 정보</em></p>

<p><img src="/assets/2025/cilium/w3/20250803_cilium_w3_6.png" alt="img_1.png" class="image-center" />
<em class="image-caption">termshark에서 확인한 패킷 정보</em></p>

<h3 id="cilium-cluster-scope">[Cilium] Cluster Scope</h3>

<p><a href="https://docs.cilium.io/en/stable/network/concepts/ipam/cluster-pool/">Docs</a>, <a href="https://docs.cilium.io/en/stable/network/kubernetes/ipam-cluster-pool/">IPAM</a></p>

<p><img src="/assets/2025/cilium/w3/20250803_cilium_w3_7.png" alt="img.png" /></p>

<ul>
  <li>각 노드에 노드별 PodCIDR 범위가 할당되며, 각 노드의 호스트 범위 할당기를 사용하여 IP를 할당합니다.</li>
  <li>이 모드는 Kubernetes Host Scope IPAM 모드와 유사하지만, Cilium이 <code class="language-plaintext highlighter-rouge">v2.CiliumNode</code>라는 리소스(CRD)를 통해 노드별 PodCIDR 범위를 관리하는 점이 다릅니다.</li>
  <li>장점은 Kubernetes가 노드별 PodCIDR 범위를 관리하지 않기 때문에, Cilium이 노드별 PodCIDR 범위를 동적으로 할당할 수 있습니다.</li>
  <li>최소 마스크 길이는 /30이며, 권장 최소 마스크 길이는 /29 이상입니다. 2개 주소는 예약되어 있습니다. (네트워크, 브로드캐스트 주소)</li>
  <li>기본 pod CIDR은 <code class="language-plaintext highlighter-rouge">10.0.0.0/8</code>입니다.</li>
</ul>

<h4 id="ipam-모드를-cluster-scope로-변경">IPAM 모드를 Cluster Scope로 변경</h4>

<blockquote>
  <p>앞서 언급한것 처럼 라이브 환경에서 IPAM 모드를 변경하지 마세요.</p>
</blockquote>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 반복 요청 해두기</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s webpod | grep Hostname; sleep 1; done'</span>

<span class="c"># Cluster Scopre 로 설정 변경</span>
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--namespace</span> kube-system <span class="nt">--reuse-values</span> <span class="se">\</span>
  <span class="nt">--set</span> ipam.mode<span class="o">=</span><span class="s2">"cluster-pool"</span> <span class="nt">--set</span> ipam.operator.clusterPoolIPv4PodCIDRList<span class="o">={</span><span class="s2">"172.20.0.0/16"</span><span class="o">}</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">ipv4NativeRoutingCIDR</span><span class="o">=</span>172.20.0.0/16

<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system rollout restart deploy/cilium-operator <span class="c"># 오퍼레이터 재시작 필요</span>
<span class="c"># =&gt; deployment.apps/cilium-operator restarted</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system rollout restart ds/cilium
<span class="c"># =&gt; daemonset.apps/cilium restarted</span>

<span class="c"># 변경 확인</span>
<span class="nv">$ </span>kubectl get nodes <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{range .items[*]}{.metadata.name}{"\t"}{.spec.podCIDR}{"\n"}{end}'</span>
<span class="c"># =&gt; k8s-ctr 10.244.0.0/24</span>
<span class="c">#    k8s-w1  10.244.1.0/24</span>
<span class="nv">$ </span>cilium config view | <span class="nb">grep</span> ^ipam
<span class="c"># =&gt; ipam                                              cluster-pool</span>
<span class="c">#    ipam-cilium-node-update-rate                      15s</span>

<span class="nv">$ </span>kubectl get ciliumnode <span class="nt">-o</span> json | <span class="nb">grep </span>podCIDRs <span class="nt">-A2</span>
<span class="c"># =&gt;                     "podCIDRs": [</span>
<span class="c">#                            "10.244.0.0/24"</span>
<span class="c">#                        ],</span>
<span class="c">#    --</span>
<span class="c">#                        "podCIDRs": [</span>
<span class="c">#                            "10.244.1.0/24"</span>
<span class="c">#                        ],</span>
<span class="nv">$ </span>kubectl get ciliumendpoints.cilium.io <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE            NAME                                      SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    cilium-monitoring    grafana-5c69859d9-zgx9k                   22364               ready            10.244.0.5</span>
<span class="c">#    cilium-monitoring    prometheus-6fc896bc5d-5rbpx               15628               ready            10.244.0.143</span>
<span class="c">#    default              curl-pod                                  1072                ready            10.244.0.188</span>
<span class="c">#    default              webpod-697b545f57-2zpdp                   24748               ready            10.244.0.2</span>
<span class="c">#    default              webpod-697b545f57-thl79                   24748               ready            10.244.1.188</span>
<span class="c">#    kube-system          coredns-674b8bbfcf-dhckj                  28257               ready            10.244.0.155</span>
<span class="c">#    kube-system          coredns-674b8bbfcf-n4xbw                  28257               ready            10.244.0.7</span>
<span class="c">#    local-path-storage   local-path-provisioner-74f9666bc9-rrn2r   29718               ready            10.244.0.130</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 IPAM 모드는 변경되었으나 podCIDR을 비롯한 IP는 아직 변경되지 않았습니다.&lt;/span&gt;</span>

<span class="c"># IPAM 모드 변경 후, 반영을 위해 Cilium 노드 리소스를 삭제하고 데몬셋을 재시작합니다.</span>
<span class="nv">$ </span>kubectl delete ciliumnode k8s-w1
<span class="c"># =&gt; ciliumnode.cilium.io "k8s-w1" deleted</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system rollout restart ds/cilium
<span class="c"># =&gt; daemonset.apps/cilium restarted</span>
<span class="nv">$ </span>kubectl get ciliumnode <span class="nt">-o</span> json | <span class="nb">grep </span>podCIDRs <span class="nt">-A2</span>
<span class="c"># =&gt;                     "podCIDRs": [</span>
<span class="c">#                            "10.244.0.0/24"</span>
<span class="c">#                        ],</span>
<span class="c">#    --</span>
<span class="c">#                        "podCIDRs": [</span>
<span class="c">#                            "172.20.0.0/24"</span>
<span class="c">#                        ],</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s-w1의 podCIDR이 변경되었습니다.&lt;/span&gt;</span>
<span class="nv">$ </span>kubectl get ciliumendpoints.cilium.io <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE            NAME                                      SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    cilium-monitoring    grafana-5c69859d9-zgx9k                   22364               ready            10.244.0.5</span>
<span class="c">#    cilium-monitoring    prometheus-6fc896bc5d-5rbpx               15628               ready            10.244.0.143</span>
<span class="c">#    default              curl-pod                                  1072                ready            10.244.0.188</span>
<span class="c">#    default              webpod-697b545f57-2zpdp                   24748               ready            10.244.0.2</span>
<span class="c">#    kube-system          coredns-674b8bbfcf-dhckj                  28257               ready            10.244.0.155</span>
<span class="c">#    kube-system          coredns-674b8bbfcf-n4xbw                  28257               ready            10.244.0.7</span>
<span class="c">#    kube-system          hubble-relay-5b48c999f9-qktv5             9702                ready            172.20.0.167</span>
<span class="c">#    kube-system          hubble-ui-655f947f96-ts4n6                64346               ready            172.20.0.122</span>
<span class="c">#    local-path-storage   local-path-provisioner-74f9666bc9-rrn2r   29718               ready            10.244.0.130</span>

<span class="c"># 마찬가지로 k8s-ctr 노드의 podCIDR도 변경합니다.</span>
<span class="nv">$ </span>kubectl delete ciliumnode k8s-ctr
<span class="c"># =&gt; ciliumnode.cilium.io "k8s-ctr" deleted</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system rollout restart ds/cilium
<span class="c"># =&gt; daemonset.apps/cilium restarted</span>
<span class="nv">$ </span>kubectl get ciliumnode <span class="nt">-o</span> json | <span class="nb">grep </span>podCIDRs <span class="nt">-A2</span>
<span class="c"># =&gt;                     "podCIDRs": [</span>
<span class="c">#                            "172.20.1.0/24"</span>
<span class="c">#                        ],</span>
<span class="c">#    --</span>
<span class="c">#                        "podCIDRs": [</span>
<span class="c">#                            "172.20.0.0/24"</span>
<span class="c">#                        ],</span>
<span class="nv">$ </span>kubectl get ciliumendpoints.cilium.io <span class="nt">-A</span> <span class="c"># 파드 IP 변경 되는가?</span>
<span class="c"># =&gt; NAMESPACE     NAME                            SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-tg9ll        28257               ready            172.20.0.56</span>
<span class="c">#    kube-system   hubble-relay-5b48c999f9-qktv5   9702                ready            172.20.0.167</span>
<span class="c">#    kube-system   hubble-ui-655f947f96-ts4n6      64346               ready            172.20.0.122</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 변경되었습니다.&lt;/span&gt;</span>

<span class="c"># 노드의 podcidr static routing 자동 변경 적용 확인</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route
<span class="c"># =&gt; ...</span>
<span class="c">#    &lt;span style="color: green;"&gt;172.20.1.113 dev lxc781feae60918&lt;/span&gt; proto kernel scope link</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w1 ip <span class="nt">-c</span> route
<span class="c"># =&gt; ...</span>
<span class="c">#    &lt;span style="color: green;"&gt;172.20.0.56 dev lxc1bf5de6d4ec4&lt;/span&gt; proto kernel scope link</span>
<span class="c">#    &lt;span style="color: green;"&gt;172.20.0.122 dev lxcb644cb2f80be&lt;/span&gt; proto kernel scope link</span>
<span class="c">#    &lt;span style="color: green;"&gt;172.20.0.167 dev lxc9c5d083a0332&lt;/span&gt; proto kernel scope link</span>

<span class="c"># 직접 rollout restart 하자! </span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-A</span> <span class="nt">-owide</span> | <span class="nb">grep </span>10.244.
<span class="c"># =&gt; cilium-monitoring    grafana-5c69859d9-zgx9k                   0/1     Running   1 (4h58m ago)   20h     10.244.0.5       k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    cilium-monitoring    prometheus-6fc896bc5d-5rbpx               1/1     Running   1 (4h58m ago)   20h     10.244.0.143     k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    default              curl-pod                                  1/1     Running   0               4h18m   10.244.0.188     k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    default              webpod-697b545f57-2zpdp                   1/1     Running   0               4h18m   10.244.0.2       k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    default              webpod-697b545f57-thl79                   1/1     Running   0               4h18m   10.244.1.188     k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    local-path-storage   local-path-provisioner-74f9666bc9-rrn2r   1/1     Running   1 (4h58m ago)   20h     10.244.0.130     k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 아직 변경되지 않은 pod들이 남아있어서 재시작하겠습니다.&lt;/span&gt;</span>

<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system rollout restart deploy/hubble-relay deploy/hubble-ui
<span class="c"># =&gt; deployment.apps/hubble-relay restarted</span>
<span class="c">#    deployment.apps/hubble-ui restarted</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> cilium-monitoring rollout restart deploy/prometheus deploy/grafana
<span class="c"># =&gt; deployment.apps/prometheus restarted</span>
<span class="c">#    deployment.apps/grafana restarted</span>
<span class="nv">$ </span>kubectl rollout restart deploy/webpod
<span class="c"># =&gt; deployment.apps/webpod restarted</span>

<span class="c">#</span>
<span class="nv">$ </span>cilium hubble port-forward&amp;
<span class="c"># =&gt; ℹ️ Hubble Relay is available at 127.0.0.1:4245</span>

<span class="c"># curl-pod는 파드만 수동으로 배포한것이라 삭제하고 다시 만들겠습니다.</span>
<span class="nv">$ </span>kubectl delete pod curl-pod
<span class="c"># =&gt; pod "curl-pod" deleted</span>
<span class="c"># k8s-ctr 노드에 curl-pod 파드 배포</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: curl-pod
  labels:
    app: curl
spec:
  nodeName: k8s-ctr
  containers:
  - name: curl
    image: nicolaka/netshoot
    command: ["tail"]
    args: ["-f", "/dev/null"]
  terminationGracePeriodSeconds: 0
</span><span class="no">EOF
</span><span class="c"># =&gt; pod/curl-pod created</span>

<span class="c"># 파드 IP 변경 확인!</span>
<span class="nv">$ </span>kubectl get ciliumendpoints.cilium.io <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE           NAME                            SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    cilium-monitoring   grafana-74f45ff4b-8s8jk         22364               ready            172.20.0.129</span>
<span class="c">#    cilium-monitoring   prometheus-5cd9888b5c-nq2jh     15628               ready            172.20.0.22</span>
<span class="c">#    default             curl-pod                        1072                ready            172.20.1.80</span>
<span class="c">#    default             webpod-bb8b9557f-7rn8t          24748               ready            172.20.0.130</span>
<span class="c">#    default             webpod-bb8b9557f-9tzvj          24748               ready            172.20.1.31</span>
<span class="c">#    kube-system         coredns-674b8bbfcf-58c7n        28257               ready            172.20.1.113</span>
<span class="c">#    kube-system         coredns-674b8bbfcf-tg9ll        28257               ready            172.20.0.56</span>
<span class="c">#    kube-system         hubble-relay-575fc84f49-m7bkm   9702                ready            172.20.0.177</span>
<span class="c">#    kube-system         hubble-ui-5b686f8966-cnqxd      64346               ready            172.20.0.244</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 모든 파드의 IP가 변경되었습니다.&lt;/span&gt;</span>

<span class="c"># 반복 요청</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s webpod | grep Hostname; sleep 1; done'</span>
</code></pre></div></div>

<ul>
  <li>이렇듯 IPAM 모드를 변경해도 이미 배포된 파드들은 IP가 변경되지 않기 때문에 운영중인 클러스터에서 IPAM 모드를 변경하는 것은 권장하지 않습니다. <br />
새로운 IPAM 모드로 새로운 클러스터를 설치하고, 기존 클러스터에서 워크로드를 이전하는 것이 가장 안전한 방법입니다.</li>
</ul>

<h3 id="cilium-cni-chaining-aws-vpc-cni-plugin">[Cilium CNI Chaining] AWS VPC CNI plugin</h3>

<p><a href="https://docs.cilium.io/en/stable/installation/cni-chaining-aws-cni/">Docs</a></p>

<p><img src="/assets/2025/cilium/w3/20250803_cilium_w3_8.png" alt="img.png" /></p>

<ul>
  <li>이번에 알아볼 것은 Cilium을 AWS VPC CNI 플러그인과 함께 사용하는 방법입니다.</li>
  <li>이 하이브리드 모드에서는 AWS VPC CNI 플러그인이 가상 네트워크 장치 설정뿐만 아니라 ENI를 통한 IP 주소 관리(IPAM)도 담당합니다.</li>
  <li>주어진 pod에 대해 초기 네트워킹이 설정된 후, Cilium CNI 플러그인은 네트워크 정책을 시행하고 로드밸런싱을 수행하며 암호화를 제공하기 위해 AWS VPC CNI 플러그인이 설정한 네트워크 장치에 eBPF 프로그램을 연결하도록 호출합니다.</li>
</ul>

<p><img src="/assets/2025/cilium/w3/20250803_cilium_w3_9.png" alt="img.png" /></p>

<ul>
  <li><strong>AWS-CNI 역할</strong> : Device plumbing, IPAM(ENI), Routing(Native-Routing 등)</li>
  <li><strong>Cilium 역할</strong> : LB, Network Policy, Encrption, Multi-Cluster, Visiblity</li>
  <li><strong>설정</strong>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>helm <span class="nb">install </span>cilium cilium/cilium <span class="nt">--version</span> 1.17.6 <span class="se">\</span>
  <span class="nt">--namespace</span> kube-system <span class="se">\</span>
  <span class="nt">--set</span> cni.chainingMode<span class="o">=</span>aws-cni <span class="se">\</span>
  <span class="nt">--set</span> cni.exclusive<span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">enableIPv4Masquerade</span><span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">routingMode</span><span class="o">=</span>native
</code></pre></div>    </div>
  </li>
  <li>AWS ENI IPAM 모드 
<a href="https://docs.cilium.io/en/stable/network/concepts/ipam/eni/">Docs</a>
<img src="/assets/2025/cilium/w3/20250803_cilium_w3_10.png" alt="img.png" /></li>
  <li>AWS ENI 할당기는 AWS 클라우드에서 수행되는 Cilium 배포에 특화되어있으며, AWS EC2 API와 통신하여 AWS Elastic Network Interface(ENI)의 IP를 기반으로 IP 를 할당합니다.</li>
  <li>이 모드는 대규모 클러스터에서의 속도 제한 문제를 해결하기 위해 단일 운영자만 EC2 서비스 API와 통신할 수 있도록 보장합니다.</li>
  <li>사전 할당 워터마크는 클러스터에서 새 pod가 예약될때 EC2 API를 호출할 필요없이 노드에서 항상 사용할 수 있도록 여러 IP 주소를 유지하는데 사용됩니다.</li>
</ul>

<hr />

<h2 id="routing">Routing</h2>

<ul>
  <li>Cilium은 Encapsulation과 Native Routing을 지원합니다. 각각에 대해 살펴 보겠습니다.</li>
</ul>

<h3 id="method-1-encapsulation-vxlan-geneve">Method 1. Encapsulation (VXLAN, GENEVE)</h3>

<p><a href="https://docs.cilium.io/en/stable/network/concepts/routing/">Docs</a></p>

<ul>
  <li>Encapsulation 모드는 특별한 인프라 요구사항이 없기 때문에 Cilium은 기본적으로 Encapsulation 모드를 사용합니다.</li>
  <li>이 모드에서는 모든 클러스터 노드가 UDP 기반의 VXLAN 또는 GENEVE를 사용하여 터널링을 통해 서로 통신합니다.</li>
  <li>Cilium 노드간의 모든 트래픽이 캡슐화 됩니다.</li>
  <li>그리고 캡슐화는 일반 노드간 연결에 의존합니다. 즉, Cilium 노드가 이미 서로 연결될 수 있다면 Encapsulation 모드를 사용할 수 있다는 이야기 입니다.</li>
  <li>기본 네트워크는 IPv4를 지원해야 하며, 다음의 UDP 포트를 방화벽에서 허용해야 합니다.
    <ul>
      <li>VXLAN (Defaut) : UDP 8472</li>
      <li>GENEVE : UDP 6081</li>
    </ul>
  </li>
  <li>장점
    <ul>
      <li><strong>단순함</strong> (Simplicity)
        <ul>
          <li>
            <ul>
              <li>클러스터 노드를 연결하는 네트워크는 PodCIDR을 인식할 필요가 없습니다.</li>
            </ul>
          </li>
          <li>클러스터 노드는 여러 라우팅 또는 링크 계층 도메인을 생성할 수 있습니다.</li>
          <li>클러스터 노드가 IP/UDP를 사용하여 서로 연결할 수 있는 한 기본 네트워크의 토폴로지는 중요하지 않습니다.</li>
        </ul>
      </li>
      <li><strong>정체성 맥락</strong> (Identity context)
        <ul>
          <li>캡슐화 프로토콜은 네트워크 패킷과 함께 메타데이터를 전송할 수 있게 해줍니다.</li>
          <li>Cilium은 소스 보안 ID와 같은 메타데이터를 전송하는 이 기능을 활용합니다.</li>
          <li>정체성 전달은 원격 노드에서 하나의 정체성 조회를 피하기 위해 설계된 최적화입니다.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>단점
    <ul>
      <li><strong>MTU Overhead</strong>
        <ul>
          <li>캡슐화 헤더가 추가됨에 의해서 페이로드에 사용할 수 있는 유효 MTU가 줄어듭니다. (VXLAN의 경우 50바이트, GENEVE의 경우 60바이트)</li>
          <li>이로 인해 특정 네트워크 연결에 대한 최대 처리량이 낮아집니다.</li>
          <li>점보 프레임(Jumbo Frame)을 사용하여 MTU를 늘려 해당 문제를 크게 완화할 수 있지만, 모든 네트워크 장치가 점보 프레임을 지원하지는 않습니다.</li>
        </ul>
      </li>
      <li><strong>Encapsulation/Decapsulation Overhead</strong>
        <ul>
          <li>캡슐화 및 디캡슐화는 CPU 오버헤드를 발생시킵니다.</li>
          <li>이 오버헤드는 일반적으로 네트워크 대역폭에 비해 작지만, 대규모 클러스터에서는 성능에 영향을 미칠 수 있습니다.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>설정방법
    <ul>
      <li><code class="language-plaintext highlighter-rouge">tunnel-protocol</code> : Encapsulation 프로토콜을 <code class="language-plaintext highlighter-rouge">vxlan</code>이나 <code class="language-plaintext highlighter-rouge">geneve</code>로 설정합니다. (기본값: vxlan)</li>
      <li><code class="language-plaintext highlighter-rouge">tunnel-port</code> : Encapsulation 프로토콜을 위한 UDP 포트를 설정합니다. vxlan의 경우 8472, geneve의 경우 6081입니다. (기본값: 8472)</li>
    </ul>
  </li>
</ul>

<h3 id="method-2-native-routing">Method 2. Native Routing</h3>

<p><a href="https://docs.cilium.io/en/stable/network/concepts/routing/#native-routing">Docs</a></p>

<p><img src="/assets/2025/cilium/w3/20250803_cilium_w3_11.png" alt="img.png" /></p>

<ul>
  <li>Native Routing 모드는 Cilium이 캡슐화 없이 Pod 간에 직접 통신할 수 있도록 합니다.</li>
  <li>캡슐화를 수행하는 대신 Cilium이 실행되는 네트워크의 라우팅 기능을 활용합니다.</li>
  <li>Native Routing 모드에서는 Cilium이 다른 로컬 엔드포인트로 주소를 지정하지 않은 모든 패킷을 Linux 커널 라우팅 하위 시스템에 위임합니다.</li>
  <li>이는 패킷이 로컬 프로세스가 패킷을 방출하는 것 처럼 라우팅 된다는것을 의미합니다.</li>
  <li>따라서 클러스터 노드를 연결하는 네트워크가 PodCIDR을 인식하고, PodCIDR를 라우팅하는 설정되어 있어야 합니다.</li>
  <li>PodCIDR 라우팅 방안 1
    <ul>
      <li>각 개별 노드는 다른 모든 노드의 모든 포드 IP를 인식하고 이를 표현하기 위해 Linux 커널 라우팅 테이블에 삽입합니다.</li>
      <li>모든 노드가 단일 L2 네트워크를 공유하는 경우 <code class="language-plaintext highlighter-rouge">auto-direct-node-routes: true</code>하여 이 문제를 해결할 수 있습니다.</li>
      <li>그렇지 않으면 <strong>BGP</strong> 데몬과 같은 추가 시스템 구성 요소를 실행하여 경로를 배포해야 합니다.</li>
    </ul>
  </li>
  <li>PodCIDR 라우팅 방안 2
    <ul>
      <li>노드 자체는 모든 포드 IP를 라우팅하는 방법을 모르지만 다른 모든 포드에 도달하는 방법을 아는 라우터가 네트워크에 존재합니다.</li>
      <li>이 시나리오에서는 Linux 노드가 이러한 라우터를 가리키는 기본 경로를 포함하도록 구성됩니다.</li>
      <li>이 모델은 클라우드 제공자 네트워크 통합에 사용됩니다. 자세한 내용은 <a href="https://docs.cilium.io/en/stable/network/concepts/routing/#google-cloud">Google Cloud</a>, <a href="https://docs.cilium.io/en/stable/network/concepts/routing/#aws-eni">AWS ENI</a> 및 Azure IPAM을 참조하세요.</li>
    </ul>
  </li>
  <li>설정방법
    <ul>
      <li><code class="language-plaintext highlighter-rouge">routing-mode: native</code>: Native Routing 모드를 활성화합니다.</li>
      <li><code class="language-plaintext highlighter-rouge">ipv4-native-routing-cidr: x.x.x.x/y</code>: Native Routing 모드에서 PodCIDR를 라우팅하는 CIDR을 설정합니다.</li>
      <li><code class="language-plaintext highlighter-rouge">auto-direct-node-routes: true</code> : 동일 L2 네트워크 공유 시, 걱 노드의 PodCIDR에 대한 Linux 커널 라우팅 테이블에 삽입합니다.</li>
    </ul>
  </li>
  <li>Native Roung 실습을 위한 Cilium Agent 단축키 지정
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># cilium 파드 이름</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD0</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-ctr <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD1</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-w1  <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$CILIUMPOD0</span> <span class="nv">$CILIUMPOD1</span> <span class="nv">$CILIUMPOD2</span>
<span class="c"># =&gt; cilium-6ggxf cilium-hb6jp</span>
  
<span class="c"># 단축키(alias) 지정</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c0</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD0</span><span class="s2"> -n kube-system -c cilium-agent -- cilium"</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c1</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD1</span><span class="s2"> -n kube-system -c cilium-agent -- cilium"</span>
</code></pre></div>    </div>
  </li>
  <li>노드간 파드 통신 상세 확인 with Native Routing</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                     READY   STATUS    RESTARTS   AGE    IP             NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    curl-pod                 1/1     Running   0          104m   172.20.1.80    k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-bb8b9557f-7rn8t   1/1     Running   0          105m   172.20.0.130   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-bb8b9557f-9tzvj   1/1     Running   0          105m   172.20.1.31    k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>

<span class="c"># Webpod1,2 파드 IP</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">WEBPODIP1</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>webpod pods <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-ctr <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].status.podIP}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">WEBPODIP2</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>webpod pods <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-w1  <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].status.podIP}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$WEBPODIP1</span> <span class="nv">$WEBPODIP2</span>
<span class="c"># =&gt; 172.20.1.31 172.20.0.130</span>

<span class="c"># curl-pod 에서 WEBPODIP2 로 ping</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> ping <span class="nv">$WEBPODIP2</span>

<span class="c"># 커널 라우팅 확인</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route
<span class="c"># =&gt; ...</span>
<span class="c">#    &lt;span style="color: green;"&gt;172.20.0.0/24 via 192.168.10.101 dev eth1 proto kernel&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 curl-pod가 있는 k8s-ctr에서는 WEBPODIP2의 172.20.0.130이 포함된 패킷을 192.168.10.101 (k8s-w1 노드 IP)로 라우팅합니다.&lt;/span&gt;</span>

<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w1 ip <span class="nt">-c</span> route
<span class="c"># =&gt; ...</span>
<span class="c">#    &lt;span style="color: green;"&gt;172.20.0.130 dev lxc9938d1653585 proto kernel scope link&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s-w1에서는 172.20.0.130의 IP를 해당 pod의 veth로 전달합니다.&lt;/span&gt;</span>

<span class="c">#</span>
<span class="nv">$ </span>cilium hubble port-forward&amp;
<span class="c"># =&gt; ℹ️   Hubble Relay is available at 127.0.0.1:424</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--pod</span> curl-pod
<span class="c"># =&gt; Aug  2 14:29:00.271: default/curl-pod (ID:1072) -&gt; default/webpod-bb8b9557f-7rn8t (ID:24748) to-network FORWARDED (ICMPv4 EchoRequest)</span>
<span class="c">#    Aug  2 14:29:00.272: default/curl-pod (ID:1072) &lt;- default/webpod-bb8b9557f-7rn8t (ID:24748) to-endpoint FORWARDED (ICMPv4 EchoReply)</span>

<span class="c">#</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> eth1 icmp
<span class="c"># =&gt; tcpdump: verbose output suppressed, use -v[v]... for full protocol decode</span>
<span class="c">#    listening on eth1, link-type EN10MB (Ethernet), snapshot length 262144 bytes</span>
<span class="c">#    23:29:18.464606 IP 172.20.1.80 &gt; 172.20.0.130: ICMP echo request, id 13, seq 815, length 64</span>
<span class="c">#    23:29:18.465333 IP 172.20.0.130 &gt; 172.20.1.80: ICMP echo reply, id 13, seq 815, length 64</span>

<span class="c">#</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> eth1 icmp <span class="nt">-w</span> /tmp/icmp.pcap
<span class="nv">$ </span>termshark <span class="nt">-r</span> /tmp/icmp.pcap
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w3/20250803_cilium_w3_14.png" alt="img.png" class="image-center" />
<em class="image-caption">termshark에서 확인한 ICMP 패킷 정보</em></p>

<p><img src="/assets/2025/cilium/w3/20250803_cilium_w3_13.png" alt="img_1.png" class="image-center" />
<em class="image-caption">Hubble UI에서 확인한 ICMP 흐름 정보</em></p>

<hr />

<h2 id="masquerading">Masquerading</h2>

<h3 id="masquerading-소개">Masquerading 소개</h3>

<p><a href="https://docs.cilium.io/en/stable/network/concepts/masquerading/">Docs</a></p>

<p><img src="/assets/2025/cilium/w3/20250803_cilium_w3_15.png" alt="img.png" /></p>

<ul>
  <li>Masquerading는 Pod가 외부 네트워크와 통신할 때 Pod의 IP 주소를 Cilium 노드의 IP 주소로 변환하는 기능입니다.</li>
  <li>Pod에서 사용되는 IPv4 주소는 일반적으로 RFC1918 개인 주소 공간에 할당되므로 외부로 라우팅 할 수 없습니다.</li>
  <li>Cilium은 이러한 Pod IP를 이미 네트워크에서 라우팅 가능한 Cilium 노드의 IP로 변환하여 외부 네트워크와 통신할 수 있도록 합니다.</li>
  <li>
    <p>만약 masquerading 기능을 사용하지 않으려면,  <code class="language-plaintext highlighter-rouge">enable-ipv4-masquerade: false</code>, <code class="language-plaintext highlighter-rouge">enable-ipv6-masquerade: false</code> 를 지정합니다</p>
  </li>
  <li>기본 동작은 로컬 노드의 IP 할당 CIDR 내에서 모든 목적지를 제외하는 것입니다.</li>
  <li>즉, Pod가 로컬 노드의 IP 할당 CIDR 내에 있는 다른 Pod와 통신할 때는 masquerading를 수행하지 않습니다.</li>
  <li>더 넓은 CIDR 범위를 제외하려면 <code class="language-plaintext highlighter-rouge">ipv4-native-routing-cidr: 10.0.0/8</code> (또는 IPv6 주소의 경우 <code class="language-plaintext highlighter-rouge">ipv6-native-routing-cidr: fd00:/100</code>) 
옵션을 사용하여 지정할 수 있습니다. 이 경우 해당 CIDR 내의 모든 목적지는 masquerade 되지 않습니다.</li>
</ul>

<h3 id="ebpf-기반-masquerading">eBPF 기반 Masquerading</h3>

<ul>
  <li><code class="language-plaintext highlighter-rouge">bpf.masquerade=true</code> 옵션을 사용하여 eBPF 기반 masquerading을 활성화할 수 있습니다.</li>
  <li>기본적으로 BPF masquerading은 BPF Host-Routing 모드도 활성화 시킵니다. 해당 모드의 장점과 한계를 확인하려면 <a href="https://docs.cilium.io/en/stable/operations/performance/tuning/#ebpf-host-routing">eBPF Host-Routing</a> 문서를 참조하세요.</li>
  <li>Masquerading은 eBPF Masquerading 프로그램을 실행하는 장치에서만 작동합니다.</li>
  <li>이는 출력 장치가 프로그램을 실행하는 경우 Pod에서 외부주소로 전송된 패킷이 Masquerading(출력장치 IPv4 주소로) 된다는 것을 의미합니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent  <span class="nt">--</span> cilium status | <span class="nb">grep </span>Masquerading
<span class="c"># =&gt; Masquerading:            BPF   [eth0, eth1]   172.20.0.0/16  [IPv4: Enabled, IPv6: Disabled]</span>
</code></pre></div>    </div>
  </li>
  <li>지정되지 않는 경우, 프로그램은 BPF NodePort 장치 감지를 사용하여 자동으로 감지됩니다.</li>
  <li>이를 수동으로 변경하려면 <code class="language-plaintext highlighter-rouge">devices</code> helm 옵션을 사용하세요.</li>
  <li>eBPF 기반 Masquerading은 TCP, UDP 및 ICMP 프로토콜을 지원합니다.</li>
  <li>기본적으로 <code class="language-plaintext highlighter-rouge">ipv4-native-routing-cidr</code> 범위를 벗어난 IP 주소를 향하는 모든 패킷을 Masquerade하지만, 다른 클러스터 노드의 Node IP로 향하는 패킷은 제외됩니다.
eBPF Masquerading이 활성화되면 pod에서 클러스터 노드의 External IP로의 트래픽도 Masquerading 되지 않습니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>cilium config view  | <span class="nb">grep </span>ipv4-native-routing-cidr
<span class="c"># =&gt; ipv4-native-routing-cidr                          172.20.0.0/16</span>
  
<span class="c"># 노드 IP로 통신 시 확인</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> eth1 icmp <span class="nt">-nn</span>
<span class="c"># =&gt; 23:58:58.175157 IP 172.20.1.80 &gt; 192.168.10.101: ICMP echo request, id 31, seq 1, length 64</span>
<span class="c">#    23:58:58.175918 IP 192.168.10.101 &gt; 172.20.1.80: ICMP echo reply, id 31, seq 1, length 64</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 Node IP로의 패킷은 Masquerading 되지 않고 Pod IP가 사용됨을 알 수 있습니다.&lt;/span&gt;</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> ping 192.168.10.101
<span class="c"># =&gt; PING 192.168.10.101 (192.168.10.101) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 192.168.10.101: icmp_seq=1 ttl=63 time=0.888 ms</span>
<span class="c">#    ...</span>
</code></pre></div>    </div>
  </li>
</ul>

<h3 id="iptables-기반-masquerading">iptables 기반 Masquerading</h3>

<ul>
  <li>이 모드는 모든 커널버전에서 작동할 수 있는 레거시 구현입니다.</li>
  <li>Cilium 네트워크 장치가 아닌 기본 네트워크 장치에서 iptables를 사용하여 masquerading을 수행합니다.</li>
  <li>masquerading이 사용되는 네트워크 장치를 제한하고 싶을 경우 <code class="language-plaintext highlighter-rouge">egress-masquerade-interfaces: eth0</code> 옵션을 사용합니다.</li>
  <li>대상 네트워크 CIDR에 따라 다른 소스 주소를 사용하는 고급 구성을 위해서는 <code class="language-plaintext highlighter-rouge">enable-masquerade-to-route-source: "true"</code>를 사용하여, 메인 network interface의 주소대신 소스 주소들을 사용할 수도 있습니다.</li>
</ul>

<h3 id="masquerading-실습">Masquerading 실습</h3>

<ul>
  <li>실습 환경 구성
<img src="/assets/2025/cilium/w3/20250803_cilium_w3_16.png" alt="img.png" />
    <ul>
      <li><strong>router</strong> : 사내망 10.10.0.0/16 대역 통신과 연결, k8s에 join 되지 않은 web 서버, loop1/loop2 dump 인터페이스를 배치</li>
    </ul>
  </li>
  <li>현재 상태 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 현재 설정 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent  <span class="nt">--</span> cilium status | <span class="nb">grep </span>Masquerading
<span class="c"># =&gt; Masquerading:            BPF   [eth0, eth1]   172.20.0.0/16  [IPv4: Enabled, IPv6: Disabled]</span>
<span class="c">#</span>
<span class="nv">$ </span>cilium config view  | <span class="nb">grep </span>ipv4-native-routing-cidr
<span class="c"># =&gt; ipv4-native-routing-cidr                          172.20.0.0/16</span>

<span class="c"># iptables 확인</span>
<span class="nv">$ </span>iptables-save | <span class="nb">grep</span> <span class="nt">-v</span> KUBE | iptables-restore
<span class="nv">$ </span>iptables-save

<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w1 <span class="s2">"sudo iptables-save | grep -v KUBE | sudo iptables-restore"</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w1 <span class="nb">sudo </span>iptables-save

<span class="c"># 통신 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nt">-s</span> webpod | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod-bb8b9557f-7rn8t</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nt">-s</span> webpod | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod-bb8b9557f-9tzvj</span>
</code></pre></div></div>

<ul>
  <li>router eth1 192.168.10.200 통신 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 터미널 2개 사용</span>
<span class="o">[</span>k8s-ctr] <span class="nv">$ </span>tcpdump <span class="nt">-i</span> eth1 icmp <span class="nt">-nn</span> <span class="c"># 혹은 hubble observe -f --pod curl-pod</span>
<span class="o">[</span>router] <span class="nv">$ </span>tcpdump <span class="nt">-i</span> eth1 icmp <span class="nt">-nn</span>

<span class="c"># router eth1 192.168.10.200 로 ping &gt;&gt; IP 확인해보자!</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> ping 192.168.10.101
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s-ctr 쪽에만 패킷이 캡쳐됨&lt;/span&gt;</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> ping 192.168.10.200
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s-ctr 및 router 모두 패킷이 캡쳐됨&lt;/span&gt;</span>

<span class="c"># k8s-ctr 패킷 캡쳐 결과</span>
<span class="c"># =&gt; 00:45:19.552476 IP 192.168.10.100 &gt; 192.168.10.200: ICMP echo request, id 73, seq 1, length 64</span>
<span class="c">#    00:45:19.553044 IP 192.168.10.200 &gt; 192.168.10.100: ICMP echo reply, id 73, seq 1, length 64</span>
<span class="c">#    ...</span>

<span class="c"># router 패킷 캡쳐 결과</span>
<span class="c"># =&gt; 00:45:19.494633 IP 192.168.10.100 &gt; 192.168.10.200: ICMP echo request, id 73, seq 1, length 64</span>
<span class="c">#    00:45:19.494758 IP 192.168.10.200 &gt; 192.168.10.100: ICMP echo reply, id 73, seq 1, length 64</span>
<span class="c">#    ...</span>

<span class="nt">---</span>
<span class="c"># 터미널 2개 사용</span>
<span class="o">[</span>k8s-ctr] <span class="nv">$ </span>tcpdump <span class="nt">-i</span> eth1 tcp port 80 <span class="nt">-nnq</span> <span class="c"># 혹은 hubble observe -f --pod curl-pod</span>
<span class="o">[</span>router] <span class="nv">$ </span>tcpdump <span class="nt">-i</span> eth1 tcp port 80 <span class="nt">-nnq</span>

<span class="c"># router eth1 192.168.10.200 로 curl &gt;&gt; IP 확인해보자!</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nt">-s</span> webpod
<span class="c"># =&gt; Hostname: webpod-bb8b9557f-9tzvj</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: ::1</span>
<span class="c">#    IP: 172.20.1.31</span>
<span class="c">#    IP: fe80::6857:8fff:fe68:c5d5</span>
<span class="c">#    RemoteAddr: 172.20.1.80:56614</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: webpod</span>
<span class="c">#    User-Agent: curl/8.14.1</span>
<span class="c">#    Accept: */*</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s-ctr 노드에 있는 webpod에 통신할때만 k8s-ctr에 캡쳐됨&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 router에는 캡쳐되지 않음&lt;/span&gt;</span>

<span class="c"># k8s-ctr 패킷 캡쳐 결과</span>
<span class="c"># =&gt; 00:58:25.714438 IP 172.20.1.80.58682 &gt; 172.20.0.130.80: tcp 70</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 IP는 Pod CIDR임&lt;/span&gt;</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nt">-s</span> webpod
<span class="c"># =&gt; Hostname: webpod-bb8b9557f-7rn8t</span>
<span class="c">#    IP: 172.20.0.130</span>
<span class="c">#    RemoteAddr: 172.20.1.80:60086</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s-1 노드에 있는 webpod에 통신할때는 패킷 캡쳐 되지않음&lt;/span&gt;</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nt">-s</span> 192.168.10.200
<span class="c"># =&gt; &lt;h1&gt;Web Server : router&lt;/h1&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s-ctr와 router 모두에 캡쳐됨&lt;/span&gt;</span>

<span class="c"># k8s-ctr 패킷 캡쳐 결과</span>
<span class="c"># =&gt; 01:01:34.458560 IP 192.168.10.100.45668 &gt; 192.168.10.200.80: tcp 78</span>
<span class="c">#    ...</span>
<span class="c"># router 패킷 캡쳐 결과</span>
<span class="c"># =&gt; 01:01:34.501812 IP 192.168.10.100.45668 &gt; 192.168.10.200.80: tcp 78</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 클러스터 바깥의 서버인 Router와는 Node IP로 통신하고 있음&lt;/span&gt;</span>
</code></pre></div></div>

<h3 id="ip-masq-agent-설정">ip-masq-agent 설정</h3>

<p><a href="https://github.com/kubernetes-sigs/ip-masq-agent">Docs</a></p>

<ul>
  <li>eBPF 기반 ip-masq-agent는 설정파일을 통해 <code class="language-plaintext highlighter-rouge">nonMasqueradeCIDRs</code>, <code class="language-plaintext highlighter-rouge">masqLinkLocal</code>, <code class="language-plaintext highlighter-rouge">masqLinkLocalIPv6</code> 옵션을 지원합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">nonMasqueradeCIDRs</code>는 masquerading을 수행하지 않을 CIDR 범위를 지정합니다.</li>
  <li>해당 설정이 없는 경우 agent는 다음의 masquerading 제외 CIDR을 사용합니다.
    <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="mi">10</span><span class="p">.</span><span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="o">/</span><span class="mi">8</span>
<span class="mi">172</span><span class="p">.</span><span class="mi">16</span><span class="p">.</span><span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="o">/</span><span class="mi">12</span>
<span class="mi">192</span><span class="p">.</span><span class="mi">168</span><span class="p">.</span><span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="o">/</span><span class="mi">16</span>
<span class="mi">100</span><span class="p">.</span><span class="mi">64</span><span class="p">.</span><span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="o">/</span><span class="mi">10</span>
<span class="mi">192</span><span class="p">.</span><span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="o">/</span><span class="mi">24</span>
<span class="mi">192</span><span class="p">.</span><span class="mi">0</span><span class="p">.</span><span class="mi">2</span><span class="p">.</span><span class="mi">0</span><span class="o">/</span><span class="mi">24</span>
<span class="mi">192</span><span class="p">.</span><span class="mi">88</span><span class="p">.</span><span class="mi">99</span><span class="p">.</span><span class="mi">0</span><span class="o">/</span><span class="mi">24</span>
<span class="mi">198</span><span class="p">.</span><span class="mi">18</span><span class="p">.</span><span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="o">/</span><span class="mi">15</span>
<span class="mi">198</span><span class="p">.</span><span class="mi">51</span><span class="p">.</span><span class="mi">100</span><span class="p">.</span><span class="mi">0</span><span class="o">/</span><span class="mi">24</span>
<span class="mi">203</span><span class="p">.</span><span class="mi">0</span><span class="p">.</span><span class="mi">113</span><span class="p">.</span><span class="mi">0</span><span class="o">/</span><span class="mi">24</span>
<span class="mi">240</span><span class="p">.</span><span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="p">.</span><span class="mi">0</span><span class="o">/</span><span class="mi">4</span>
</code></pre></div>    </div>
  </li>
  <li><code class="language-plaintext highlighter-rouge">masqLinkLocal</code>이 false이거나 지정되어있지 않으면 <code class="language-plaintext highlighter-rouge">169.254.0.0/16</code> 또한 masquerading 제외 CIDR로 사용됩니다.</li>
  <li>ipMasqAgent 설정
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 아래 설정값은 cilium 데몬셋 자동 재시작됨</span>
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--namespace</span> kube-system <span class="nt">--reuse-values</span> <span class="se">\</span>
  <span class="nt">--set</span> ipMasqAgent.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> ipMasqAgent.config.nonMasqueradeCIDRs<span class="o">=</span><span class="s1">'{10.10.1.0/24,10.10.2.0/24}'</span>
  
<span class="nv">$ </span>cilium hubble port-forward&amp;
<span class="c"># =&gt; ℹ️   Hubble Relay is available at 127.0.0.1:4245</span>
  
<span class="c"># ip-masq-agent configmap 생성 확인</span>
<span class="nv">$ </span>kubectl get cm <span class="nt">-n</span> kube-system ip-masq-agent <span class="nt">-o</span> yaml | yq
<span class="c"># =&gt; ...</span>
<span class="c">#        "config": "{\"nonMasqueradeCIDRs\":[\"10.10.1.0/24\",\"10.10.2.0/24\"]}"</span>
<span class="c">#    ...</span>
<span class="c">#        "name": "ip-masq-agent",</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>kc describe cm <span class="nt">-n</span> kube-system ip-masq-agent 
<span class="c"># =&gt; Data</span>
<span class="c">#    ====</span>
<span class="c">#    config:</span>
<span class="c">#    ----</span>
<span class="c">#    {"nonMasqueradeCIDRs":["10.10.1.0/24","10.10.2.0/24"]}</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>k9s 
  
<span class="c">#</span>
<span class="nv">$ </span>cilium config view  | <span class="nb">grep</span> <span class="nt">-i</span> ip-masq
<span class="c"># =&gt; enable-ip-masq-agent                              true</span>
  
<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system <span class="nb">exec </span>ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium-dbg bpf ipmasq list
<span class="c"># =&gt; IP PREFIX/ADDRESS</span>
<span class="c">#    10.10.1.0/24</span>
<span class="c">#    10.10.2.0/24</span>
<span class="c">#    169.254.0.0/16</span>
</code></pre></div>    </div>
  </li>
</ul>

<hr />

<h2 id="coredns-nodelocaldns">CoreDNS, NodeLocalDNS</h2>

<h3 id="coredns">CoreDNS</h3>
<p><img src="/assets/2025/cilium/w3/20250803_cilium_w3_17.png" alt="img.png" class="image-center" /></p>

<ul>
  <li>CoreDNS 소개 - <a href="https://kubernetes.io/ko/docs/tasks/administer-cluster/dns-custom-nameservers/">Docs</a> , <a href="https://coredns.io/manual/toc/">Home</a> , <a href="https://coredns.io/plugins/">Plugins</a> , <a href="https://www.youtube.com/watch?v=W3f5Ks0j2Q8">Youtube</a>
    <ul>
      <li>CoreDNS는 Kubernetes 클러스터의 DNS 서버로, 클러스터 내에서 서비스와 파드의 이름을 IP 주소로 변환하는 역할을 합니다.</li>
      <li>CoreDNS는 BIND, Knot, PowerDNS와 같은 전통적인 DNS 서버와는 다르게 
대부분의 기능을 플러그인화 하여 유연하게 확장할 수 있습니다.</li>
    </ul>
  </li>
  <li>CoreDNS 설정 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 파드의 DNS 설정 정보 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> <span class="nb">cat</span> /etc/resolv.conf
<span class="c"># =&gt; search default.svc.cluster.local svc.cluster.local cluster.local</span>
<span class="c">#    nameserver 10.96.0.10</span>
<span class="c">#    options ndots:5</span>

<span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> /var/lib/kubelet/config.yaml | <span class="nb">grep </span>cluster <span class="nt">-A1</span>
<span class="c"># =&gt; clusterDNS:</span>
<span class="c">#    - 10.96.0.10</span>
<span class="c">#    clusterDomain: cluster.local</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get svc,ep <span class="nt">-n</span> kube-system kube-dns
<span class="c"># =&gt; NAME               TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE</span>
<span class="c">#    service/kube-dns   ClusterIP   10.96.0.10   &lt;none&gt;        53/UDP,53/TCP,9153/TCP   24h</span>
<span class="c">#    </span>
<span class="c">#    NAME                 ENDPOINTS                                                   AGE</span>
<span class="c">#    endpoints/kube-dns   172.20.0.56:53,172.20.1.113:53,172.20.0.56:53 + 3 more...   24h</span>

<span class="nv">$ </span>kubectl get pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>kube-dns
<span class="c"># =&gt; NAME                       READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    coredns-674b8bbfcf-58c7n   1/1     Running   0          4h17m</span>
<span class="c">#    coredns-674b8bbfcf-tg9ll   1/1     Running   0          4h17m</span>

<span class="c">#</span>
<span class="nv">$ </span>kc describe pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>kube-dns
<span class="c"># =&gt; ...</span>
<span class="c">#     config-volume:</span>
<span class="c">#        Type:      ConfigMap (a volume populated by a ConfigMap)</span>
<span class="c">#        Name:      coredns</span>
<span class="c">#        Optional:  false</span>
<span class="c">#    ...</span>

<span class="nv">$ </span>kc describe cm <span class="nt">-n</span> kube-system coredns
<span class="c"># =&gt; ...</span>
<span class="c">#    Corefile:</span>
<span class="c">#    ----</span>
<span class="c">#    .:53 {              # 모든 도메인 요청을 53포트에서 수신</span>
<span class="c">#        errors          # DNS 응답 중 에러가 발생할 경우 로그 출력</span>
<span class="c">#        health {        # health 엔드포인트를 제공하여 상태 확인 가능</span>
<span class="c">#           lameduck 5s  # 종료 시 5초간 lameduck 모드로 트래픽을 점차 줄이며 종료</span>
<span class="c">#        }</span>
<span class="c">#        ready           # ready 엔드포인트 제공, 8181 포트의 HTTP 엔드포인트가, 모든 플러그인이 준비되었다는 신호를 보내면 200 OK 를 반환</span>
<span class="c">#        kubernetes cluster.local in-addr.arpa ip6.arpa {    # Kubernetes DNS 플러그인 설정(클러스터 내부 도메인 처리), cluster.local: 클러스터 도메인</span>
<span class="c">#           pods insecure                         # 파드 IP로 DNS 조회 허용 (보안 없음)</span>
<span class="c">#           fallthrough in-addr.arpa ip6.arpa     #  해당 도메인에서 결과 없으면 다음 플러그인으로 전달</span>
<span class="c">#           ttl 30                                #  캐시 타임 (30초)</span>
<span class="c">#        }</span>
<span class="c">#        prometheus :9153 # Prometheus metrics 수집 가능</span>
<span class="c">#        forward . /etc/resolv.conf {             # CoreDNS가 모르는 도메인은 지정된 업스트림(보통 외부 DNS)으로 전달, .: 모든 쿼리</span>
<span class="c">#           max_concurrent 1000                   # 병렬 포워딩 최대 1000개</span>
<span class="c">#        }</span>
<span class="c">#        cache 30 {                        # DNS 응답 캐시 기능, 기본 캐시 TTL 30초</span>
<span class="c">#           disable success cluster.local  # 성공 응답 캐시 안 함 (cluster.local 도메인)</span>
<span class="c">#           disable denial cluster.local   # NXDOMAIN 응답도 캐시 안 함</span>
<span class="c">#        } </span>
<span class="c">#        loop         # 간단한 전달 루프(loop)를 감지하고, 루프가 발견되면 CoreDNS 프로세스를 중단(halt).</span>
<span class="c">#        reload       # Corefile 이 변경되었을 때 자동으로 재적용, 컨피그맵 설정을 변경한 후에 변경 사항이 적용되기 위하여 약 2분정도 소요.</span>
<span class="c">#        loadbalance  # 응답에 대하여 A, AAAA, MX 레코드의 순서를 무작위로 선정하는 라운드-로빈 DNS 로드밸런서.</span>
<span class="c">#    }</span>

<span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> /etc/resolv.conf
<span class="c"># =&gt; nameserver 127.0.0.53</span>
<span class="c">#    options edns0 trust-ad</span>
<span class="c">#    search .</span>

<span class="nv">$ </span>resolvectl 
<span class="c"># =&gt; Link 2 (eth0)</span>
<span class="c">#        Current Scopes: DNS</span>
<span class="c">#             Protocols: +DefaultRoute -LLMNR -mDNS -DNSOverTLS DNSSEC=no/unsupported</span>
<span class="c">#    Current DNS Server: 10.0.2.3</span>
<span class="c">#           DNS Servers: 10.0.2.3</span>
</code></pre></div></div>

<ul>
  <li>
    <p>(참고) forward 플러그인 - <a href="https://coredns.io/plugins/forward/">Docs</a></p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 활용 1 : '.consul.local' 도메인을 관리하는 도메인 서버가 존재 시, coredns 에서 해당 도메인 서버로 질의 설정 시</span>
consul.local:53 <span class="o">{</span>
    errors
    cache 30
    forward <span class="nb">.</span> 10.150.0.1
<span class="o">}</span>
  
<span class="c"># 활용 2 : 모든 비 클러스터의 DNS 조회가 172.16.0.1 의 특정 네임서버 사용 시, /etc/resolv.conf 대신 forward 를 네임서버로 지정</span>
forward <span class="nb">.</span>  172.16.0.1
  
<span class="c"># 위 1,2 포함한 설정 예시</span>
apiVersion: v1
kind: ConfigMap
metadata:
  name: coredns
  namespace: kube-system
data:
  Corefile: |
    .:53 <span class="o">{</span>
        errors
        health
        kubernetes cluster.local <span class="k">in</span><span class="nt">-addr</span>.arpa ip6.arpa <span class="o">{</span>
           pods insecure
           fallthrough <span class="k">in</span><span class="nt">-addr</span>.arpa ip6.arpa
        <span class="o">}</span>
        prometheus :9153
        forward <span class="nb">.</span> 172.16.0.1  <span class="c"># 활용 2</span>
        cache 30
        loop
        reload
        loadbalance
    <span class="o">}</span>
    consul.local:53 <span class="o">{</span>         <span class="c"># 활용 1</span>
        errors
        cache 30
        forward <span class="nb">.</span> 10.150.0.1
    <span class="o">}</span>  
</code></pre></div>    </div>
  </li>
  <li>
    <p>파드에서 DNS 질의 확인 - <a href="https://kubernetes.io/docs/tasks/administer-cluster/dns-debugging-resolution/">Docs</a> , <a href="https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/">DNS for Services and Pods</a> , <a href="https://kubernetes.io/docs/tasks/administer-cluster/dns-horizontal-autoscaling/">Autoscale the DNS Service in a Cluster</a></p>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 모니터링1</span>
<span class="nv">$ </span>cilium hubble port-forward&amp;
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--port</span> 53
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--port</span> 53 <span class="nt">--protocol</span> UDP

<span class="c"># 모니터링2</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> any udp port 53 <span class="nt">-nn</span>

<span class="c"># 파드 IP 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                     READY   STATUS    RESTARTS   AGE     IP             NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    curl-pod                 1/1     Running   0          3h55m   172.20.1.80    k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-bb8b9557f-7rn8t   1/1     Running   0          3h55m   172.20.0.130   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-bb8b9557f-9tzvj   1/1     Running   0          3h55m   172.20.1.31    k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>

<span class="nv">$ </span>kubectl get pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>kube-dns <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                       READY   STATUS    RESTARTS   AGE     IP             NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    coredns-674b8bbfcf-58c7n   1/1     Running   0          4h29m   172.20.1.113   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    coredns-674b8bbfcf-tg9ll   1/1     Running   0          4h29m   172.20.0.56    k8s-w1    &lt;none&gt;           &lt;none&gt;</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> <span class="nb">cat</span> /etc/resolv.conf
<span class="c"># =&gt; search default.svc.cluster.local svc.cluster.local cluster.local</span>
<span class="c">#    nameserver 10.96.0.10</span>
<span class="c">#    options ndots:5</span>

<span class="c"># 실습 편리를 위해 coredns 파드를 1개로 축소</span>
<span class="nv">$ </span>kubectl scale deployment <span class="nt">-n</span> kube-system coredns <span class="nt">--replicas</span> 1
<span class="c"># =&gt; deployment.apps/coredns scaled</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>kube-dns <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                       READY   STATUS    RESTARTS   AGE     IP            NODE     NOMINATED NODE   READINESS GATES</span>
<span class="c">#    coredns-674b8bbfcf-tg9ll   1/1     Running   0          4h29m   172.20.0.56   k8s-w1   &lt;none&gt;           &lt;none&gt;</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl kube-dns.kube-system.svc:9153/metrics | <span class="nb">grep </span>coredns_cache_ | <span class="nb">grep</span> <span class="nt">-v</span> ^#
<span class="c"># =&gt; coredns_cache_entries{server="dns://:53",type="denial",view="",zones="."} 1</span>
<span class="c">#    coredns_cache_entries{server="dns://:53",type="success",view="",zones="."} 0</span>
<span class="c">#    coredns_cache_misses_total{server="dns://:53",view="",zones="."} 46</span>
<span class="c">#    coredns_cache_requests_total{server="dns://:53",view="",zones="."} 46</span>

<span class="c"># 도메인 질의</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> nslookup webpod
<span class="c"># =&gt; Server:         10.96.0.10</span>
<span class="c">#    Address:        10.96.0.10#53</span>
<span class="c">#    </span>
<span class="c">#    Name:   webpod.default.svc.cluster.local</span>
<span class="c">#    Address: 10.96.194.47</span>

<span class="c"># tcpdump로 DNS 질의 패킷 확인</span>
<span class="c"># =&gt; 01:27:05.029100 lxc9dcdf61704e7 In  IP 172.20.1.80.41316 &gt; 172.20.0.56&lt;span style="color: green;"&gt;.53&lt;/span&gt;: 62435+ &lt;span style="color: green;"&gt;A? webpod.default.svc.cluster.local.&lt;/span&gt; (50)</span>
<span class="c">#    01:27:05.029378 eth1  Out IP 172.20.1.80.41316 &gt; 172.20.0.56.53: 62435+ A? webpod.default.svc.cluster.local. (50)</span>
<span class="c">#    01:27:05.032936 eth1  In  IP 172.20.0.56.53 &gt; 172.20.1.80.41316: 62435*- &lt;span style="color: green;"&gt;1/0/0 A 10.96.194.47&lt;/span&gt; (98)</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> nslookup <span class="nt">-debug</span> webpod
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> nslookup <span class="nt">-debug</span> google.com
<span class="c"># =&gt; Server:         10.96.0.10</span>
<span class="c">#    Address:        10.96.0.10#53</span>
<span class="c">#    </span>
<span class="c">#    ------------</span>
<span class="c">#        QUESTIONS:</span>
<span class="c">#            google.com.default.svc.cluster.local, type = A, class = IN</span>
<span class="c">#        ...</span>
<span class="c">#    ------------</span>
<span class="c">#    ** server can't find google.com.default.svc.cluster.local: NXDOMAIN</span>
<span class="c">#    ;; Got recursion not available from 10.96.0.10</span>
<span class="c">#    Server:         10.96.0.10</span>
<span class="c">#    Address:        10.96.0.10#53</span>
<span class="c">#    </span>
<span class="c">#    ------------</span>
<span class="c">#        QUESTIONS:</span>
<span class="c">#            google.com.svc.cluster.local, type = A, class = IN</span>
<span class="c">#        ...</span>
<span class="c">#    ------------</span>
<span class="c">#    ** server can't find google.com.svc.cluster.local: NXDOMAIN</span>
<span class="c">#    ;; Got recursion not available from 10.96.0.10</span>
<span class="c">#    Server:         10.96.0.10</span>
<span class="c">#    Address:        10.96.0.10#53</span>
<span class="c">#    </span>
<span class="c">#    ------------</span>
<span class="c">#        QUESTIONS:</span>
<span class="c">#            google.com.cluster.local, type = A, class = IN</span>
<span class="c">#        ...</span>
<span class="c">#    ------------</span>
<span class="c">#    ** server can't find google.com.cluster.local: NXDOMAIN</span>
<span class="c">#    Server:         10.96.0.10</span>
<span class="c">#    Address:        10.96.0.10#53</span>
<span class="c">#    </span>
<span class="c">#    ------------</span>
<span class="c">#        QUESTIONS:</span>
<span class="c">#            google.com, type = A, class = IN</span>
<span class="c">#        ANSWERS:</span>
<span class="c">#        -&gt;  google.com</span>
<span class="c">#            internet address = 142.250.206.238</span>
<span class="c">#            ttl = 30</span>
<span class="c">#        AUTHORITY RECORDS:</span>
<span class="c">#        ADDITIONAL RECORDS:</span>
<span class="c">#    ------------</span>
<span class="c">#    Non-authoritative answer:</span>
<span class="c">#    Name:   google.com</span>
<span class="c">#    Address: 142.250.206.238</span>
<span class="c">#    ------------</span>
<span class="c">#        QUESTIONS:</span>
<span class="c">#            google.com, type = AAAA, class = IN</span>
<span class="c">#        ANSWERS:</span>
<span class="c">#        -&gt;  google.com</span>
<span class="c">#            has AAAA address 2404:6800:400a:804::200e</span>
<span class="c">#            ttl = 30</span>
<span class="c">#        AUTHORITY RECORDS:</span>
<span class="c">#        ADDITIONAL RECORDS:</span>
<span class="c">#    ------------</span>
<span class="c">#    Name:   google.com</span>
<span class="c">#    Address: 2404:6800:400a:804::200e</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 클러스터 외부의 도메인을 질의할때는 클러스터 내부의 search 도메인들을 먼저&lt;/span&gt; </span>
<span class="c"># &lt;span style="color: green;"&gt;확인하고, 없으면 외부 DNS 서버로 질의하여 응답을 받는 것을 알 수 있습니다.&lt;/span&gt;</span>

<span class="c"># tcpdump로 DNS 질의 패킷 확인</span>
<span class="c"># =&gt; 01:33:33.852442 lxc9dcdf61704e7 In  IP 172.20.1.80.58442 &gt; 172.20.0.56.53: 52842+ &lt;span style="color: green;"&gt;A? google.com.default.svc.cluster.local.&lt;/span&gt; (54)</span>
<span class="c">#    01:33:33.852610 eth1  Out IP 172.20.1.80.58442 &gt; 172.20.0.56.53: 52842+ A? google.com.default.svc.cluster.local. (54)</span>
<span class="c">#    01:33:33.855947 eth1  In  IP 172.20.0.56.53 &gt; 172.20.1.80.58442: 52842 NXDomain*- 0/1/0 (147)</span>
<span class="c">#    01:33:33.861141 lxc9dcdf61704e7 In  IP 172.20.1.80.36323 &gt; 172.20.0.56.53: 10644+ &lt;span style="color: green;"&gt;A? google.com.svc.cluster.local.&lt;/span&gt; (46)</span>
<span class="c">#    01:33:33.861515 eth1  Out IP 172.20.1.80.36323 &gt; 172.20.0.56.53: 10644+ A? google.com.svc.cluster.local. (46)</span>
<span class="c">#    01:33:33.862582 eth1  In  IP 172.20.0.56.53 &gt; 172.20.1.80.36323: 10644 NXDomain*- 0/1/0 (139)</span>
<span class="c">#    01:33:33.868623 lxc9dcdf61704e7 In  IP 172.20.1.80.48326 &gt; 172.20.0.56.53: 52392+ &lt;span style="color: green;"&gt;A? google.com.cluster.local.&lt;/span&gt; (42)</span>
<span class="c">#    01:33:33.868857 eth1  Out IP 172.20.1.80.48326 &gt; 172.20.0.56.53: 52392+ A? google.com.cluster.local. (42)</span>
<span class="c">#    01:33:33.870240 eth1  In  IP 172.20.0.56.53 &gt; 172.20.1.80.48326: 52392 NXDomain*- 0/1/0 (135)</span>
<span class="c">#    01:33:33.874341 lxc9dcdf61704e7 In  IP 172.20.1.80.50810 &gt; 172.20.0.56.53: 16999+ &lt;span style="color: green;"&gt;A? google.com.&lt;/span&gt; (28)</span>
<span class="c">#    01:33:33.874556 eth1  Out IP 172.20.1.80.50810 &gt; 172.20.0.56.53: 16999+ A? google.com. (28)</span>
<span class="c">#    01:33:33.928831 eth1  In  IP 172.20.0.56.53 &gt; 172.20.1.80.50810: 16999 &lt;span style="color: green;"&gt;1/0/0 A 142.250.206.238&lt;/span&gt; (54)</span>

<span class="c"># coredns 로깅, 디버깅 활성화</span>
<span class="c"># k9s → configmap → coredns 선택 → E(edit) → 아래처럼 log, debug 입력 후 빠져나오기</span>
<span class="nt">---</span>
    .:53 <span class="o">{</span>
        log
        debug
        errors
<span class="nt">---</span>

<span class="c"># 로그 모니터링 3</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system logs <span class="nt">-l</span> k8s-app<span class="o">=</span>kube-dns <span class="nt">-f</span>

<span class="c"># 도메인 질의</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> nslookup webpod
<span class="c"># =&gt; ;; Got recursion not available from 10.96.0.10</span>
<span class="c">#    Server:         10.96.0.10</span>
<span class="c">#    Address:        10.96.0.10#53</span>
<span class="c">#    </span>
<span class="c">#    Name:   webpod.default.svc.cluster.local</span>
<span class="c">#    Address: 10.96.194.47</span>
<span class="c">#    ;; Got recursion not available from 10.96.0.10</span>

<span class="c"># coredns 로그 확인</span>
<span class="c"># =&gt; [INFO] 172.20.1.80:46753 - 59201 "A IN webpod.default.svc.cluster.local. udp 50 false 512" NOERROR qr,aa,rd 98 0.000500084s</span>
<span class="c">#    [INFO] 172.20.1.80:39996 - 54949 "AAAA IN webpod.default.svc.cluster.local. udp 50 false 512" NOERROR qr,aa,rd 143 0.000554333s</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> nslookup google.com
<span class="c"># =&gt; Server:         10.96.0.10</span>
<span class="c">#    Address:        10.96.0.10#53</span>
<span class="c">#    </span>
<span class="c">#    Non-authoritative answer:</span>
<span class="c">#    Name:   google.com</span>
<span class="c">#    Address: 142.250.206.238</span>
<span class="c">#    Name:   google.com</span>
<span class="c">#    Address: 2404:6800:400a:804::200e</span>

<span class="c"># coredns 로그 확인</span>
<span class="c"># =&gt; [INFO] 172.20.1.80:43389 - 1366 "A IN google.com.default.svc.cluster.local. udp 54 false 512" NXDOMAIN qr,aa,rd 147 0.001736458s</span>
<span class="c">#    [INFO] 172.20.1.80:34460 - 17323 "A IN google.com.svc.cluster.local. udp 46 false 512" NXDOMAIN qr,aa,rd 139 0.000483917s</span>
<span class="c">#    [INFO] 172.20.1.80:40469 - 26458 "A IN google.com.cluster.local. udp 42 false 512" NXDOMAIN qr,aa,rd 135 0.000331334s</span>
<span class="c">#    [INFO] 172.20.1.80:56627 - 19160 "A IN google.com. udp 28 false 512" NOERROR qr,rd,ra 54 0.054453541s</span>
<span class="c">#    [INFO] 172.20.1.80:48324 - 36047 "AAAA IN google.com. udp 28 false 512" NOERROR qr,rd,ra 66 0.044442084s</span>

<span class="c"># CoreDNS가 prometheus 플러그인을 사용하고 있다면, 메트릭 포트(:9153)를 통해 캐시 관련 정보를 수집.</span>
<span class="c">## coredns_cache_entries 현재 캐시에 저장된 엔트리(항목) 수 : type: success 또는 denial (정상 응답 or NXDOMAIN 등)</span>
<span class="c">## coredns_cache_hits_total	캐시 조회 성공 횟수</span>
<span class="c">## coredns_cache_misses_total	캐시 미스 횟수</span>
<span class="c">## coredns_cache_requests_total	캐시 관련 요청 횟수의 총합</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl kube-dns.kube-system.svc:9153/metrics | <span class="nb">grep </span>coredns_cache_ | <span class="nb">grep</span> <span class="nt">-v</span> ^#
<span class="c"># =&gt; coredns_cache_entries{server="dns://:53",type="denial",view="",zones="."} 1</span>
<span class="c">#    coredns_cache_entries{server="dns://:53",type="success",view="",zones="."} 2</span>
<span class="c">#    coredns_cache_hits_total{server="dns://:53",type="success",view="",zones="."} 4</span>
<span class="c">#    coredns_cache_misses_total{server="dns://:53",view="",zones="."} 116</span>
<span class="c">#    coredns_cache_requests_total{server="dns://:53",view="",zones="."} 120</span>
</code></pre></div></div>

<h3 id="nodelocaldns">NodeLocalDNS</h3>

<p><a href="https://popappend.tistory.com/142">소개 블로그</a></p>

<p><img src="/assets/2025/cilium/w3/20250803_cilium_w3_18.png" alt="img.png" class="image-center" /></p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">NodeLocal DNSCache</code>는 클러스터 노드에서 DNS 캐싱 에이전트를 DaemonSet으로 실행하여 클러스터 DNS 성능을 향상시킵니다.</li>
  <li>오늘날의 아키텍처에서 ‘<code class="language-plaintext highlighter-rouge">ClusterFirst</code>’ DNS 모드의 Pods는 DNS 쿼리를 위해 kube-dns 서비스 IP에 도달합니다.</li>
  <li>이는 kube-proxy에 의해 추가된 <strong>iptables</strong> 규칙을 통해 kube-dns/CoreDNS 엔드포인트로 변환됩니다.</li>
  <li>이 새로운 아키텍처를 통해 Pods는 동일한 노드에서 실행되는 DNS 캐싱 에이전트에 도달하여 iptables DNAT 규칙과 연결 추적을 피할 수 있습니다.</li>
  <li>로컬 캐싱 에이전트는 클러스터 호스트 이름(기본적으로 “cluster.local” 접미사)의 캐시 누락에 대해 kube-dns 서비스에 쿼리합니다.</li>
  <li>현재 DNS 아키텍처에서는 로컬 kube-dns/CoreDNS 인스턴스가 없는 경우 DNS QPS가 가장 높은 포드가 다른 노드에 도달해야 할 수도 있습니다. 로컬 캐시를 사용하면 이러한 시나리오에서 지연 시간을 개선하는 데 도움이 됩니다.</li>
  <li>iptables DNAT 및 연결 추적을 건너뛰면 <a href="https://github.com/kubernetes/kubernetes/issues/56903">연결 추적 레이스</a>를 줄이고 UDP DNS 항목이 연결 추적 테이블을 채우는 것을 방지하는 데 도움이 됩니다.</li>
  <li>로컬 캐싱 에이전트에서 kube-dns 서비스로의 연결은 TCP로 업그레이드할 수 있습니다. TCP 연결 트랙 항목은 시간 초과를 해야 하는 UDP 항목과 달리 연결 종료 시 제거됩니다(기본값 <code class="language-plaintext highlighter-rouge">nf_conntrack_udp_timeout</code>은 30초)</li>
  <li>DNS 쿼리를 UDP에서 TCP로 업그레이드하면 삭제된 UDP 패킷과 DNS 타임아웃으로 인한 테일 지연 시간이 보통 최대 30초(3회 재시도 + 10초 타임아웃)까지 줄어듭니다. 노드로컬 캐시가 UDP DNS 쿼리를 듣기 때문에 애플리케이션을 변경할 필요가 없습니다.</li>
  <li>노드 수준에서 DNS 요청에 대한 메트릭 및 가시성.</li>
  <li>
    <p>네거티브 캐싱을 다시 활성화하여 kube-dns 서비스에 대한 쿼리 수를 줄일 수 있습니다.</p>
  </li>
  <li>NodeLocal DNSCache 설치 방법 - <a href="https://kubernetes.io/docs/tasks/administer-cluster/nodelocaldns/#configuration">Docs</a>
    <ul>
      <li>설치시 NodeLocal DNSCache의 로컬 Listening IP 주소는 클러스터의 기존 IP와 충돌하지 않는 모든 주소일 수 있습니다.</li>
      <li>예를들어 IPv4의 링크 로컬 범위인 <code class="language-plaintext highlighter-rouge">169.254.0.0/16</code>을 사용하거나, IPv6의 <code class="language-plaintext highlighter-rouge">fd00::/8</code> 범위를 사용하는것이 좋습니다.</li>
    </ul>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>curl <span class="nt">-LO</span> https://raw.githubusercontent.com/kubernetes/kubernetes/refs/heads/master/cluster/addons/dns/nodelocaldns/nodelocaldns.yaml

<span class="c"># 다음 값들은 적절한 값으로 대체 합니다.</span>
<span class="nv">$ kubedns</span><span class="o">=</span><span class="sb">`</span>kubectl get svc kube-dns <span class="nt">-n</span> kube-system <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.spec.clusterIP<span class="o">}</span><span class="sb">`</span> <span class="c"># coredns 의 ClusterIP</span>
<span class="c"># $ domain=&lt;cluster-domain&gt; # 보통 기본값 cluster.local 사용</span>
<span class="nv">$ domain</span><span class="o">=</span>cluster.local
<span class="c"># $ localdns=&lt;node-local-address&gt; # local listen IP address chosen for NodeLocal DNSCache</span>
<span class="nv">$ localdns</span><span class="o">=</span>169.254.20.10
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$kubedns</span> <span class="nv">$domain</span> <span class="nv">$localdns</span>
<span class="c"># =&gt; 10.96.0.10 cluster.local 169.254.1.2</span>

<span class="c"># case 1) kube-proxy가 IPTABLES 모드인 경우</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/__PILLAR__LOCAL__DNS__/</span><span class="nv">$localdns</span><span class="s2">/g; s/__PILLAR__DNS__DOMAIN__/</span><span class="nv">$domain</span><span class="s2">/g; s/__PILLAR__DNS__SERVER__/</span><span class="nv">$kubedns</span><span class="s2">/g"</span> nodelocaldns.yaml
<span class="c"># 이 모드에서는 node-local-dns 포드가 kube-dns 서비스 IP와 &lt;node-local-address&gt;를 모두 수신하므로, 포드는 IP 주소 중 하나를 사용하여 DNS 레코드를 조회할 수 있습니다.</span>

<span class="c"># case 2) kube-proxy가 IPVS 모드인 경우</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/__PILLAR__LOCAL__DNS__/</span><span class="nv">$localdns</span><span class="s2">/g; s/__PILLAR__DNS__DOMAIN__/</span><span class="nv">$domain</span><span class="s2">/g; s/,__PILLAR__DNS__SERVER__//g; s/__PILLAR__CLUSTER__DNS__/</span><span class="nv">$kubedns</span><span class="s2">/g"</span> nodelocaldns.yaml
<span class="c"># - 이 모드에서는`node-local-dns` 포드가 **&lt;node-local-address&gt;**에서만 청취합니다.</span>
<span class="c"># - IPVS 로드 밸런싱에 사용되는 인터페이스가 이미 이 주소를 사용하고 있기 때문에 `node-local-dns` 인터페이스는 kube-dns 클러스터 IP를 바인딩할 수 없습니다.</span>
<span class="c"># - `__PILLAR__UPSTREAM__SERVERS__`는 `node-local-dns` 포드에 의해 채워집니다.</span>

<span class="nv">$ </span>kubectl create <span class="nt">-f</span> nodelocaldns.yaml
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">node-local-dns</code> 포드가 활성화되면 각 클러스터 노드의 <code class="language-plaintext highlighter-rouge">kube-system</code> 네임스페이스에서 실행됩니다.</li>
  <li>이 포드는 캐시 모드에서 CoreDNS를 실행하므로 서로 다른 플러그인이 노출하는 모든 CoreDNS 메트릭을 노드 단위로 사용할 수 있습니다.</li>
  <li><code class="language-plaintext highlighter-rouge">kubectl delete -f &lt;manifest&gt;</code>를 사용하여 DaemonSet을 제거하여 비활성화할 수 있습니다. 변경한 내용을 kubetle 설정으로 되돌려야 합니다.</li>
  <li>kube-dns의 ConfigMap에 지정된 StubDomains 과 upstream servers이 node-local-dns에 의해 사용됩니다.</li>
  <li>iptables 모드일때와 ipvs 모드일때의 차이
<img src="/assets/2025/cilium/w3/20250803_cilium_w3_20.png" alt="img.png" class="image-center" />
<em class="image-caption">iptables 모드일때</em>
<img src="/assets/2025/cilium/w3/20250803_cilium_w3_21.png" alt="img_1.png" class="image-center" />
<em class="image-caption">ipvs 모드일때</em>
    <ul>
      <li>iptables 모드일 때와 ipvs 모드일 때의 차이점은, ipvs 모드에서는 Pod에서 Domain Resolve 요청을 CoreDNS Service의 ClusterIP인 10.96.0.10 IP 주소가 아니라 NodeLocal DNSCache의 CoreDNS가 설정한 Local Address IP인 169.254.25.10 IP 주소로 전송한다는 점입니다.</li>
      <li>따라서 Kubernetes Cluster가 ipvs 모드 kube-proxy를 사용하고 있다면 NodeLocal DNSCache 기법 적용 유무를 변경할 수 없습니다. ipvs 모드에서는 매번 kubelet의 Pod DNS Server 주소를 변경하고 kublet을 재시작해야 합니다. 또한 Pod들도 재시작하여 Pod가 이용하는 DNS Server의 주소가 변경되도록 해야 합니다.</li>
      <li>Kubernetes Cluster가 ipvs kube-proxy 모드를 사용하면 ipvs가 iptables의 NOTRACK Rule 을 무시하고 Loadbalancing 하기 때문입니다.</li>
    </ul>
  </li>
</ul>

<h3 id="nodelocal-dnscache-설치-및-확인">NodeLocal DNSCache 설치 및 확인</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># iptables 확인</span>
<span class="nv">$ </span>iptables-save | <span class="nb">tee </span>before.txt

<span class="c">#</span>
<span class="nv">$ </span>wget https://github.com/kubernetes/kubernetes/raw/master/cluster/addons/dns/nodelocaldns/nodelocaldns.yaml
<span class="c"># =&gt; 2025-08-03 02:19:25 (534 KB/s) - ‘nodelocaldns.yaml’ saved [5377/5377]</span>

<span class="c"># kubedns 는 coredns 서비스의 ClusterIP를 변수 지정</span>
<span class="nv">$ kubedns</span><span class="o">=</span><span class="sb">`</span>kubectl get svc kube-dns <span class="nt">-n</span> kube-system <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.spec.clusterIP<span class="o">}</span><span class="sb">`</span>
<span class="nv">$ domain</span><span class="o">=</span><span class="s1">'cluster.local'</span>    <span class="c">## default 값</span>
<span class="nv">$ localdns</span><span class="o">=</span><span class="s1">'169.254.20.10'</span>  <span class="c">## default 값</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$kubedns</span> <span class="nv">$domain</span> <span class="nv">$localdns</span>
<span class="c"># =&gt; 10.96.0.10 cluster.local 169.254.20.10</span>

<span class="c"># iptables 모드 사용 중으로 아래 명령어 수행</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/__PILLAR__LOCAL__DNS__/</span><span class="nv">$localdns</span><span class="s2">/g; s/__PILLAR__DNS__DOMAIN__/</span><span class="nv">$domain</span><span class="s2">/g; s/__PILLAR__DNS__SERVER__/</span><span class="nv">$kubedns</span><span class="s2">/g"</span> nodelocaldns.yaml

<span class="c"># nodelocaldns 설치</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> nodelocaldns.yaml
<span class="c"># =&gt; serviceaccount/node-local-dns created</span>
<span class="c">#    service/kube-dns-upstream created</span>
<span class="c">#    configmap/node-local-dns created</span>
<span class="c">#    daemonset.apps/node-local-dns created</span>
<span class="c">#    service/node-local-dns created</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>node-local-dns <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                   READY   STATUS              RESTARTS   AGE   IP               NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    node-local-dns-6gzpj   0/1     ContainerCreating   0          10s   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    node-local-dns-c2846   0/1     ContainerCreating   0          10s   192.168.10.101   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl edit cm <span class="nt">-n</span> kube-system node-local-dns <span class="c"># 'cluster.local' 과 '.:53' 에 log, debug 추가</span>
<span class="c"># =&gt; configmap/node-local-dns edited</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system rollout restart ds node-local-dns
<span class="c"># =&gt; daemonset.apps/node-local-dns restarted</span>

<span class="nv">$ </span>kubectl describe cm <span class="nt">-n</span> kube-system node-local-dns
<span class="c"># =&gt; cluster.local:53 {</span>
<span class="c">#        log</span>
<span class="c">#        debug</span>
<span class="c">#        errors</span>
<span class="c">#        cache {</span>
<span class="c">#                success 9984 30</span>
<span class="c">#                denial 9984 5</span>
<span class="c">#        }</span>
<span class="c">#        reload</span>
<span class="c">#        loop</span>
<span class="c">#        bind 169.254.20.10 10.96.0.10</span>
<span class="c">#        forward . __PILLAR__CLUSTER__DNS__ {</span>
<span class="c">#                force_tcp</span>
<span class="c">#        }</span>
<span class="c">#        prometheus :9253</span>
<span class="c">#        health 169.254.20.10:8080</span>
<span class="c">#        }</span>
<span class="c">#    ...</span>
<span class="c">#    .:53 {</span>
<span class="c">#        log</span>
<span class="c">#        debug</span>
<span class="c">#        errors</span>
<span class="c">#        cache 30</span>
<span class="c">#        reload</span>
<span class="c">#        loop</span>
<span class="c">#        bind 169.254.20.10 10.96.0.10</span>
<span class="c">#        forward . __PILLAR__UPSTREAM__SERVERS__</span>
<span class="c">#        prometheus :9253</span>
<span class="c">#        }</span>

<span class="c"># iptables 확인 : 규칙 업데이트까지 다소 시간 소요!</span>
<span class="nv">$ </span>iptables-save | <span class="nb">tee </span>after.txt
<span class="nv">$ </span>diff before.txt after.txt

<span class="c">##</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> filter <span class="nt">-S</span> | <span class="nb">grep</span> <span class="nt">-i</span> dns
<span class="c"># =&gt; -A INPUT -d 10.96.0.10/32 -p udp -m udp --dport 53 -m comment --comment "NodeLocal DNS Cache: allow DNS traffic" -j ACCEPT</span>
<span class="c">#    -A INPUT -d 10.96.0.10/32 -p tcp -m tcp --dport 53 -m comment --comment "NodeLocal DNS Cache: allow DNS traffic" -j ACCEPT</span>
<span class="c">#    -A INPUT -d 169.254.20.10/32 -p udp -m udp --dport 53 -m comment --comment "NodeLocal DNS Cache: allow DNS traffic" -j ACCEPT</span>
<span class="c">#    -A INPUT -d 169.254.20.10/32 -p tcp -m tcp --dport 53 -m comment --comment "NodeLocal DNS Cache: allow DNS traffic" -j ACCEPT</span>
<span class="c">#    -A OUTPUT -s 10.96.0.10/32 -p udp -m udp --sport 53 -m comment --comment "NodeLocal DNS Cache: allow DNS traffic" -j ACCEPT</span>
<span class="c">#    -A OUTPUT -s 10.96.0.10/32 -p tcp -m tcp --sport 53 -m comment --comment "NodeLocal DNS Cache: allow DNS traffic" -j ACCEPT</span>
<span class="c">#    -A OUTPUT -s 169.254.20.10/32 -p udp -m udp --sport 53 -m comment --comment "NodeLocal DNS Cache: allow DNS traffic" -j ACCEPT</span>
<span class="c">#    -A OUTPUT -s 169.254.20.10/32 -p tcp -m tcp --sport 53 -m comment --comment "NodeLocal DNS Cache: allow DNS traffic" -j ACCEPT</span>

<span class="c">##</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> raw <span class="nt">-S</span> | <span class="nb">grep</span> <span class="nt">-i</span> dns
<span class="c"># =&gt; -A PREROUTING -d 10.96.0.10/32 -p udp -m udp --dport 53 -m comment --comment "NodeLocal DNS Cache: skip conntrack" -j NOTRACK</span>
<span class="c">#    -A PREROUTING -d 10.96.0.10/32 -p tcp -m tcp --dport 53 -m comment --comment "NodeLocal DNS Cache: skip conntrack" -j NOTRACK</span>
<span class="c">#    -A PREROUTING -d 169.254.20.10/32 -p udp -m udp --dport 53 -m comment --comment "NodeLocal DNS Cache: skip conntrack" -j NOTRACK</span>
<span class="c">#    -A PREROUTING -d 169.254.20.10/32 -p tcp -m tcp --dport 53 -m comment --comment "NodeLocal DNS Cache: skip conntrack" -j NOTRACK</span>
<span class="c">#    -A OUTPUT -s 10.96.0.10/32 -p tcp -m tcp --sport 8080 -m comment --comment "NodeLocal DNS Cache: skip conntrack" -j NOTRACK</span>
<span class="c">#    -A OUTPUT -d 10.96.0.10/32 -p tcp -m tcp --dport 8080 -m comment --comment "NodeLocal DNS Cache: skip conntrack" -j NOTRACK</span>
<span class="c">#    ...</span>

<span class="c"># logs : </span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system logs <span class="nt">-l</span> k8s-app<span class="o">=</span>kube-dns <span class="nt">-f</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system logs <span class="nt">-l</span> k8s-app<span class="o">=</span>node-local-dns <span class="nt">-f</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> <span class="nb">cat</span> /etc/resolv.conf
<span class="c"># =&gt; search default.svc.cluster.local svc.cluster.local cluster.local</span>
<span class="c">#    nameserver 10.96.0.10</span>
<span class="c">#    options ndots:5</span>

<span class="c"># </span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> nslookup webpod
<span class="c"># kube-dns 로그 확인</span>
<span class="c"># =&gt; [INFO] 172.20.1.80:57227 - 46178 "A IN webpod.default.svc.cluster.local. udp 50 false 512" NOERROR qr,aa,rd 98 0.000729042s</span>
<span class="c">#    [INFO] 172.20.1.80:49087 - 7946 "AAAA IN webpod.default.svc.cluster.local. udp 50 false 512" NOERROR qr,aa,rd 143 0.000557625s</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> nslookup google.com
<span class="c"># kube-dns 로그 확인</span>
<span class="c"># =&gt; [INFO] 172.20.1.80:52008 - 19063 "A IN google.com.default.svc.cluster.local. udp 54 false 512" NXDOMAIN qr,aa,rd 147 0.000802417s</span>
<span class="c">#    [INFO] 172.20.1.80:53056 - 1029 "A IN google.com.svc.cluster.local. udp 46 false 512" NXDOMAIN qr,aa,rd 139 0.000377583s</span>
<span class="c">#    [INFO] 172.20.1.80:40165 - 2061 "A IN google.com.cluster.local. udp 42 false 512" NXDOMAIN qr,aa,rd 135 0.000287959s</span>
<span class="c">#    [INFO] 172.20.1.80:42852 - 42332 "A IN google.com. udp 28 false 512" NOERROR qr,aa,rd,ra 54 0.000450083s</span>
<span class="c">#    [INFO] 172.20.1.80:52047 - 947 "AAAA IN google.com. udp 28 false 512" NOERROR qr,aa,rd,ra 66 0.000662125s</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 로그가 kube-dns 쪽에만 쌓입니다.&lt;/span&gt;</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl delete pod curl-pod

<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: curl-pod
  labels:
    app: curl
spec:
  containers:
  - name: curl
    image: nicolaka/netshoot
    command: ["tail"]
    args: ["-f", "/dev/null"]
  terminationGracePeriodSeconds: 0
</span><span class="no">EOF
</span><span class="c"># =&gt; pod/curl-pod created</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> <span class="nb">cat</span> /etc/resolv.conf
<span class="c"># =&gt; search default.svc.cluster.local svc.cluster.local cluster.local</span>
<span class="c">#    nameserver 10.96.0.10</span>
<span class="c">#    options ndots:5</span>

<span class="c"># 로그 확인 시 현재 nodelocaldns 미활용! </span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system logs <span class="nt">-l</span> k8s-app<span class="o">=</span>kube-dns <span class="nt">-f</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system logs <span class="nt">-l</span> k8s-app<span class="o">=</span>node-local-dns <span class="nt">-f</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> nslookup webpod
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> nslookup google.com
</code></pre></div></div>

<ul>
  <li>위의 예제에서는 아직 NodeLocal DNSCache를 사용하지 않고 있습니다.</li>
</ul>

<h3 id="cilium-local-redirect-policy">Cilium Local Redirect Policy</h3>

<ul>
  <li><code class="language-plaintext highlighter-rouge">--set localRedirectPolicy=true</code> 해서 Local Redirect Policy를 활성화하면, Cilium은 NodeLocal DNSCache를 사용하여 DNS 요청을 처리합니다. <a href="https://docs.cilium.io/en/stable/network/kubernetes/local-redirect-policy/">Docs</a></li>
  <li>IP 주소와 Port/Protocol tuple 또는 <strong>Kubernetes Service</strong> 로 향하는 포드 <strong>트래픽</strong>을 eBPF를 사용하여 노드 내 <strong>백엔드 포드로 로컬로 리디렉션</strong>할 수 있도록 하는 Cilium의 로컬 리디렉션 정책을 구성하는 방법을 설명합니다.</li>
  <li>백엔드 포드의 네임스페이스는 정책의 네임스페이스와 일치해야 합니다.</li>
  <li>CiliumLocalRedirectPolicy는 CustomResourceDefinition으로 구성되어 있습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--namespace</span> kube-system <span class="nt">--reuse-values</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">localRedirectPolicy</span><span class="o">=</span><span class="nb">true</span>

<span class="nv">$ </span>kubectl rollout restart deploy cilium-operator <span class="nt">-n</span> kube-system
<span class="c"># =&gt; deployment.apps/cilium-operator restarted</span>
<span class="nv">$ </span>kubectl rollout restart ds cilium <span class="nt">-n</span> kube-system
<span class="c"># =&gt; daemonset.apps/cilium restarted</span>

<span class="c">#</span>
<span class="nv">$ </span>wget https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/kubernetes-local-redirect/node-local-dns.yaml

<span class="nv">$ kubedns</span><span class="o">=</span><span class="si">$(</span>kubectl get svc kube-dns <span class="nt">-n</span> kube-system <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.spec.clusterIP<span class="o">}</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/__PILLAR__DNS__SERVER__/</span><span class="nv">$kubedns</span><span class="s2">/g;"</span> node-local-dns.yaml
<span class="nv">$ </span>vi <span class="nt">-d</span> nodelocaldns.yaml node-local-dns.yaml
</code></pre></div></div>

<ul>
  <li>nodelocaldns.yaml과 node-local-dns.yaml의 diff 결과 
<img src="/assets/2025/cilium/w3/20250803_cilium_w3_22.png" alt="img.png" />
<img src="/assets/2025/cilium/w3/20250803_cilium_w3_23.png" alt="img_1.png" /></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">## before</span>
<span class="c"># args: [ "-localip", "169.254.20.10,10.96.0.10", "-conf", "/etc/Corefile", "-upstreamsvc", "kube-dns-upstream" ]</span>

<span class="c">## after</span>
<span class="c"># args: [ "-localip", "169.254.20.10,10.96.0.10", "-conf", "/etc/Corefile", "-upstreamsvc", "kube-dns-upstream", "-skipteardown=true", "-setupinterface=false", "-setupiptables=false" ]</span>


<span class="c"># 배포</span>
<span class="c"># Modify Node-local DNS cache’s deployment yaml to pass these additional arguments to node-cache: </span>
<span class="c">## -skipteardown=true, -setupinterface=false, and -setupiptables=false.</span>

<span class="c"># Modify Node-local DNS cache’s deployment yaml to put it in non-host namespace by setting hostNetwork: false for the daemonset.</span>
<span class="c"># In the Corefile, bind to 0.0.0.0 instead of the static IP.</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> node-local-dns.yaml
<span class="c"># =&gt; serviceaccount/node-local-dns configured</span>
<span class="c">#    service/kube-dns-upstream configured</span>
<span class="c">#    configmap/node-local-dns configured</span>
<span class="c">#    daemonset.apps/node-local-dns configured</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl edit cm <span class="nt">-n</span> kube-system node-local-dns <span class="c"># log, debug 추가</span>
<span class="c"># =&gt; configmap/node-local-dns edited</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system rollout restart ds node-local-dns
<span class="c"># =&gt; daemonset.apps/node-local-dns restarted</span>

<span class="nv">$ </span>kubectl describe cm <span class="nt">-n</span> kube-system node-local-dns
<span class="c"># =&gt; ...</span>
<span class="c">#    cluster.local:53 {</span>
<span class="c">#        log</span>
<span class="c">#        debug</span>
<span class="c">#        errors</span>
<span class="c">#        cache {</span>
<span class="c">#                success 9984 30</span>
<span class="c">#                denial 9984 5</span>
<span class="c">#        }</span>
<span class="c">#        reload</span>
<span class="c">#        loop</span>
<span class="c">#        bind 0.0.0.0</span>
<span class="c">#        forward . __PILLAR__CLUSTER__DNS__ {</span>
<span class="c">#                force_tcp</span>
<span class="c">#        }</span>
<span class="c">#        prometheus :9253</span>
<span class="c">#        health</span>
<span class="c">#        }</span>
<span class="c">#    ...</span>
<span class="c">#    .:53 {</span>
<span class="c">#        log</span>
<span class="c">#        debug</span>
<span class="c">#        errors</span>
<span class="c">#        cache 30</span>
<span class="c">#        reload</span>
<span class="c">#        loop</span>
<span class="c">#        bind 0.0.0.0</span>
<span class="c">#        forward . __PILLAR__UPSTREAM__SERVERS__</span>
<span class="c">#        prometheus :9253</span>
<span class="c">#        }</span>
<span class="c">#    ...</span>

<span class="c">#</span>
<span class="nv">$ </span>wget https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/kubernetes-local-redirect/node-local-dns-lrp.yaml
<span class="nv">$ </span><span class="nb">cat </span>node-local-dns-lrp.yaml
<span class="c"># =&gt; apiVersion: "cilium.io/v2"</span>
<span class="c">#    kind: CiliumLocalRedirectPolicy</span>
<span class="c">#    metadata:</span>
<span class="c">#      name: "nodelocaldns"</span>
<span class="c">#      namespace: kube-system</span>
<span class="c">#    spec:</span>
<span class="c">#      redirectFrontend:</span>
<span class="c">#        serviceMatcher:</span>
<span class="c">#          serviceName: kube-dns</span>
<span class="c">#          namespace: kube-system</span>
<span class="c">#      redirectBackend:</span>
<span class="c">#        localEndpointSelector:</span>
<span class="c">#          matchLabels:</span>
<span class="c">#            k8s-app: node-local-dns</span>
<span class="c">#        toPorts:</span>
<span class="c">#          - port: "53"</span>
<span class="c">#            name: dns</span>
<span class="c">#            protocol: UDP</span>
<span class="c">#          - port: "53"</span>
<span class="c">#            name: dns-tcp</span>
<span class="c">#            protocol: TCP</span>
        
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/kubernetes-local-redirect/node-local-dns-lrp.yaml
<span class="c"># =&gt; ciliumlocalredirectpolicy.cilium.io/nodelocaldns created</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get CiliumLocalRedirectPolicy <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE     NAME           AGE</span>
<span class="c">#    kube-system   nodelocaldns   8s</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium-dbg lrp list
<span class="c"># =&gt; LRP namespace   LRP name       FrontendType                Matching Service</span>
<span class="c">#    kube-system     nodelocaldns   clusterIP + all svc ports   kube-system/kube-dns</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium-dbg service list | <span class="nb">grep </span>LocalRedirect
<span class="c"># =&gt; 16   10.96.0.10:53/UDP       LocalRedirect   1 =&gt; 172.20.0.73:53/UDP (active)</span>
<span class="c">#    17   10.96.0.10:53/TCP       LocalRedirect   1 =&gt; 172.20.0.73:53/TCP (active)</span>

<span class="c"># logs</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system logs <span class="nt">-l</span> k8s-app<span class="o">=</span>kube-dns <span class="nt">-f</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system logs <span class="nt">-l</span> k8s-app<span class="o">=</span>node-local-dns <span class="nt">-f</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> nslookup www.google.com
<span class="c"># =&gt; Server:         10.96.0.10</span>
<span class="c">#    Address:        10.96.0.10#53</span>
<span class="c">#    </span>
<span class="c">#    Non-authoritative answer:</span>
<span class="c">#    Name:   www.google.com</span>
<span class="c">#    Address: 142.250.206.228</span>
<span class="c">#    Name:   www.google.com</span>
<span class="c">#    Address: 2404:6800:400a:804::2004</span>

<span class="c"># kube-dns 로그 확인</span>
<span class="c"># =&gt; [INFO] 172.20.1.178:55860 - 32731 "A IN www.google.com.default.svc.cluster.local. tcp 58 false 65535" NXDOMAIN qr,aa,rd 151 0.002254584s</span>
<span class="c">#    [INFO] 172.20.1.178:55860 - 50477 "A IN www.google.com.svc.cluster.local. tcp 50 false 65535" NXDOMAIN qr,aa,rd 143 0.000426625s</span>
<span class="c">#    [INFO] 172.20.1.178:55860 - 42463 "A IN www.google.com.cluster.local. tcp 46 false 65535" NXDOMAIN qr,aa,rd 139 0.000225583s</span>

<span class="c"># node-local-dns 로그 확인</span>
<span class="c"># =&gt; [INFO] 172.20.1.20:52275 - 32731 "A IN www.google.com.default.svc.cluster.local. udp 58 false 512" NXDOMAIN qr,aa,rd 151 0.009171834s</span>
<span class="c">#    [INFO] 172.20.1.20:60077 - 50477 "A IN www.google.com.svc.cluster.local. udp 50 false 512" NXDOMAIN qr,aa,rd 143 0.001657537s</span>
<span class="c">#    [INFO] 172.20.1.20:48089 - 42463 "A IN www.google.com.cluster.local. udp 46 false 512" NXDOMAIN qr,aa,rd 139 0.001401951s</span>
<span class="c">#    [INFO] 172.20.1.20:58721 - 18703 "A IN www.google.com. udp 32 false 512" NOERROR qr,rd,ra 62 0.046337824s</span>
<span class="c">#    [INFO] 172.20.1.20:42914 - 43270 "AAAA IN www.google.com. udp 32 false 512" NOERROR qr,rd,ra 74 0.042382055s</span>

<span class="c"># 한번더 dns 조회</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> nslookup www.google.com
<span class="c"># =&gt; Server:         10.96.0.10</span>
<span class="c">#    Address:        10.96.0.10#53</span>
<span class="c">#    </span>
<span class="c">#    Non-authoritative answer:</span>
<span class="c">#    Name:   www.google.com</span>
<span class="c">#    Address: 142.250.206.228</span>
<span class="c">#    Name:   www.google.com</span>
<span class="c">#    Address: 2404:6800:400a:804::2004</span>

<span class="c"># kube-dns 로그 확인</span>
<span class="c"># =&gt; (로그 없음)</span>

<span class="c"># node-local-dns 로그 확인</span>
<span class="c"># =&gt; [INFO] 172.20.1.20:52275 - 32731 "A IN www.google.com.default.svc.cluster.local. udp 58 false 512" NXDOMAIN qr,aa,rd 151 0.009171834s</span>
<span class="c">#    [INFO] 172.20.1.20:60077 - 50477 "A IN www.google.com.svc.cluster.local. udp 50 false 512" NXDOMAIN qr,aa,rd 143 0.001657537s</span>
<span class="c">#    [INFO] 172.20.1.20:48089 - 42463 "A IN www.google.com.cluster.local. udp 46 false 512" NXDOMAIN qr,aa,rd 139 0.001401951s</span>
<span class="c">#    [INFO] 172.20.1.20:58721 - 18703 "A IN www.google.com. udp 32 false 512" NOERROR qr,rd,ra 62 0.046337824s</span>
<span class="c">#    [INFO] 172.20.1.20:42914 - 43270 "AAAA IN www.google.com. udp 32 false 512" NOERROR qr,rd,ra 74 0.042382055s</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 연속 조회시 node-local-dns에 캐시가 되어서 kube-dns의 조회가 줄어듬을 확인할 수 있습니다.&lt;/span&gt;</span>

<span class="c"># nodelocaldns 에 캐시된 정보로 바로 질의 응답 확인!</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system logs <span class="nt">-l</span> k8s-app<span class="o">=</span>node-local-dns <span class="nt">-f</span>
<span class="c"># =&gt; [INFO] 172.20.1.20:52275 - 32731 "A IN www.google.com.default.svc.cluster.local. udp 58 false 512" NXDOMAIN qr,aa,rd 151 0.009171834s</span>
<span class="c">#    [INFO] 172.20.1.20:60077 - 50477 "A IN www.google.com.svc.cluster.local. udp 50 false 512" NXDOMAIN qr,aa,rd 143 0.001657537s</span>
<span class="c">#    [INFO] 172.20.1.20:48089 - 42463 "A IN www.google.com.cluster.local. udp 46 false 512" NXDOMAIN qr,aa,rd 139 0.001401951s</span>
<span class="c">#    [INFO] 172.20.1.20:58721 - 18703 "A IN www.google.com. udp 32 false 512" NOERROR qr,rd,ra 62 0.046337824s</span>
<span class="c">#    [INFO] 172.20.1.20:42914 - 43270 "AAAA IN www.google.com. udp 32 false 512" NOERROR qr,rd,ra 74 0.042382055s</span>
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w3/20250803_cilium_w3_24.png" alt="img.png" class="image-center" /></p>

<hr />

<h2 id="마치며">마치며</h2>

<p>이번 포스트에서는 노드의 파드 들간 통신과 외부와의 통신, DNS 요청을 처리하는 방법에 대해 알아보았습니다.
네트워크는 볼때마다 어려운것 같습니다. :sweat_smile: 
하지만 조금씩 이해가 되고, 익숙해지는 것 같습니다. 한걸음 한걸음 나아가고 있는것이 느껴집니다.</p>

<p>다양한 주제에 걸쳐 배웠는데, 모든 파트에서 수 많은 사람들이 조금이라도 네트워크를 효율적으로 하기위해서
애쓴 흔적들을 볼 수 있었습니다. 그런 분들이 있어서 지금 이렇게 인터넷을 사용하고 클라우드를 이용할 수 있으니
한번도 뵌적은 없지만 그분들에게 감사의 마음을 전합니다. :pray:</p>

<hr />

<h2 id="부록">부록</h2>

<h3 id="k9s-주요-단축키">K9s 주요 단축키</h3>

<table>
  <thead>
    <tr>
      <th><strong>Action</strong></th>
      <th><strong>Command</strong></th>
      <th><strong>Comment</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Show active keyboard mnemonics and help</td>
      <td><code class="language-plaintext highlighter-rouge">?</code></td>
      <td> </td>
    </tr>
    <tr>
      <td>Show all available resource alias</td>
      <td><code class="language-plaintext highlighter-rouge">ctrl-a</code></td>
      <td> </td>
    </tr>
    <tr>
      <td>To bail out of K9s</td>
      <td><code class="language-plaintext highlighter-rouge">:quit</code> <code class="language-plaintext highlighter-rouge">:q</code> <code class="language-plaintext highlighter-rouge">ctrl-c</code></td>
      <td> </td>
    </tr>
    <tr>
      <td>To go up/back to the previous view</td>
      <td><code class="language-plaintext highlighter-rouge">esc</code></td>
      <td>If you have crumbs on, this will go to the previous one</td>
    </tr>
    <tr>
      <td>View a Kubernetes resource using singular/plural or short-name</td>
      <td><code class="language-plaintext highlighter-rouge">:pod</code></td>
      <td>accepts singular, plural, short-name or alias ie pod or pods</td>
    </tr>
    <tr>
      <td>View a Kubernetes resource in a given namespace</td>
      <td><code class="language-plaintext highlighter-rouge">:pod ns-x</code></td>
      <td> </td>
    </tr>
    <tr>
      <td>View filtered pods (New v0.30.0!)</td>
      <td><code class="language-plaintext highlighter-rouge">:pod /fred</code></td>
      <td>View all pods filtered by fred</td>
    </tr>
    <tr>
      <td>View labeled pods (New v0.30.0!)</td>
      <td><code class="language-plaintext highlighter-rouge">:pod app=fred,env=dev</code></td>
      <td>View all pods with labels matching app=fred and env=dev</td>
    </tr>
    <tr>
      <td>View pods in a given context (New v0.30.0!)</td>
      <td><code class="language-plaintext highlighter-rouge">:pod @ctx1</code></td>
      <td>View all pods in context ctx1. Switches out your current k9s context!</td>
    </tr>
    <tr>
      <td>Filter out a resource view given a filter</td>
      <td><code class="language-plaintext highlighter-rouge">/filter</code></td>
      <td>Regex2 supported ie <code class="language-plaintext highlighter-rouge">fred</code></td>
    </tr>
    <tr>
      <td>Inverse regex filter</td>
      <td><code class="language-plaintext highlighter-rouge">/! filter</code></td>
      <td>Keep everything that <em>doesn’t</em> match.</td>
    </tr>
    <tr>
      <td>Filter resource view by labels</td>
      <td><code class="language-plaintext highlighter-rouge">/-l label-selector</code></td>
      <td> </td>
    </tr>
    <tr>
      <td>Fuzzy find a resource given a filter</td>
      <td><code class="language-plaintext highlighter-rouge">/-f filter</code></td>
      <td> </td>
    </tr>
    <tr>
      <td>Bails out of view/command/filter mode</td>
      <td><code class="language-plaintext highlighter-rouge">&lt;esc&gt;</code></td>
      <td> </td>
    </tr>
    <tr>
      <td>Key mapping to describe, view, edit, view logs,…</td>
      <td><code class="language-plaintext highlighter-rouge">d</code>, <code class="language-plaintext highlighter-rouge">v</code>, <code class="language-plaintext highlighter-rouge">e</code>, <code class="language-plaintext highlighter-rouge">l</code>,…</td>
      <td> </td>
    </tr>
    <tr>
      <td>To view and switch to another Kubernetes context (Pod view)</td>
      <td><code class="language-plaintext highlighter-rouge">:ctx</code></td>
      <td> </td>
    </tr>
    <tr>
      <td>To view and switch directly to another Kubernetes context (Last used view)</td>
      <td><code class="language-plaintext highlighter-rouge">:ctx context-name</code></td>
      <td> </td>
    </tr>
    <tr>
      <td>To view and switch to another Kubernetes namespace</td>
      <td><code class="language-plaintext highlighter-rouge">:ns</code></td>
      <td> </td>
    </tr>
    <tr>
      <td>To switch back to the last active command (like how “cd -“ works)</td>
      <td><code class="language-plaintext highlighter-rouge">-</code></td>
      <td>Navigation that adds breadcrumbs to the bottom are not commands</td>
    </tr>
    <tr>
      <td>To go back and forward through the command history</td>
      <td>back: <code class="language-plaintext highlighter-rouge">[</code>, forward: <code class="language-plaintext highlighter-rouge">]</code></td>
      <td>Same as above</td>
    </tr>
    <tr>
      <td>To view all saved resources</td>
      <td><code class="language-plaintext highlighter-rouge">:screendump</code> or <code class="language-plaintext highlighter-rouge">:sd</code></td>
      <td> </td>
    </tr>
    <tr>
      <td>To delete a resource (TAB and ENTER to confirm)</td>
      <td><code class="language-plaintext highlighter-rouge">ctrl-d</code></td>
      <td> </td>
    </tr>
    <tr>
      <td>To kill a resource (no confirmation dialog, equivalent to kubectl delete –now)</td>
      <td><code class="language-plaintext highlighter-rouge">ctrl-k</code></td>
      <td> </td>
    </tr>
    <tr>
      <td>Launch pulses view</td>
      <td><code class="language-plaintext highlighter-rouge">:pulses</code> or <code class="language-plaintext highlighter-rouge">:pu</code></td>
      <td> </td>
    </tr>
    <tr>
      <td>Launch XRay view</td>
      <td><code class="language-plaintext highlighter-rouge">:xray RESOURCE [NAMESPACE]</code></td>
      <td>RESOURCE can be one of po, <strong>svc</strong>, dp, rs, sts, ds, NAMESPACE is optional</td>
    </tr>
    <tr>
      <td>Launch Popeye view</td>
      <td><code class="language-plaintext highlighter-rouge">:popeye</code> or <code class="language-plaintext highlighter-rouge">:pop</code></td>
      <td>See <a href="https://github.com/derailed/k9s#popeye">popeye</a></td>
    </tr>
  </tbody>
</table>]]></content><author><name></name></author><category term="cilium" /><category term="kubernetes," /><category term="network," /><category term="linux," /><category term="cilium," /><category term="ipam," /><category term="routing," /><category term="masquerading," /><category term="coredns," /><category term="nodelocaldns" /><summary type="html"><![CDATA[Cilium의 Networking에 대해 살펴보겠습니다. Cilium이 어떻게 노드에 있는 파드들 간의 통신을 처리하는지, IP 주소 할당(IPAM), 라우팅, 마스커레이딩, DNS 설정 등을 다룰 것입니다.]]></summary></entry><entry><title type="html">[Cilium] (Observability) Hubble, Prometheus, Grafana</title><link href="https://sweetlittlebird.github.io/posts/2025-07-27-Cilium-Week2/" rel="alternate" type="text/html" title="[Cilium] (Observability) Hubble, Prometheus, Grafana" /><published>2025-07-27T00:10:18+09:00</published><updated>2025-07-27T00:10:18+09:00</updated><id>https://sweetlittlebird.github.io/posts/Cilium%20-%20Week2</id><content type="html" xml:base="https://sweetlittlebird.github.io/posts/2025-07-27-Cilium-Week2/"><![CDATA[<h2 id="들어가며">들어가며</h2>

<p>이번에는 Hubble, Prometheus, Grafana 등을 이용하여 Cilium의 관측성(Observability)에 대해 살펴보겠습니다.</p>

<hr />

<h2 id="실습-환경-구성">실습 환경 구성</h2>

<ul>
  <li>실습 환경 소개</li>
</ul>

<p>실습 환경은 지난주와 거의 유사합니다. 단, 파드 IP 대역이 <code class="language-plaintext highlighter-rouge">10.244.0.0/16</code>에서 <code class="language-plaintext highlighter-rouge">172.20.0.0/16</code>으로 변경되었습니다.</p>

<p><img src="/assets/2025/cilium/w2/20250727_cilium_w2_1.png" alt="img.png" /></p>

<ul>
  <li>배포 가상 머신은 컨트롤플레인인 k8s-ctr, 워커노드 k8s-w1, k8s-w2로 구성되어 있습니다.
    <ul>
      <li>eth0 : 10.0.2.15 (모든 노드가 동일)</li>
      <li>eth1 : 192.168.10.100~102</li>
    </ul>
  </li>
  <li>초기 프로비저닝시 <code class="language-plaintext highlighter-rouge">kubeadm init</code>과 <code class="language-plaintext highlighter-rouge">join</code> 을 실행하여 클러스터를 구성하며, <strong>이번에는 Cilium CNI가 설치된 상태로 배포됩니다</strong>.</li>
</ul>

<h3 id="실습-환경-배포-파일-작성">실습 환경 배포 파일 작성</h3>

<h4 id="vagrantfile"><strong>Vagrantfile</strong></h4>
<ul>
  <li>가상머신을 정의하고 부팅시 실행할 프로비저닝 설정을 합니다.</li>
</ul>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Variables</span>
<span class="no">K8SV</span> <span class="o">=</span> <span class="s1">'1.33.2-1.1'</span> <span class="c1"># Kubernetes Version : apt list -a kubelet , ex) 1.32.5-1.1</span>
<span class="no">CONTAINERDV</span> <span class="o">=</span> <span class="s1">'1.7.27-1'</span> <span class="c1"># Containerd Version : apt list -a containerd.io , ex) 1.6.33-1</span>
<span class="no">CILIUMV</span> <span class="o">=</span> <span class="s1">'1.17.6'</span> <span class="c1"># Cilium CNI Version : https://github.com/cilium/cilium/tags</span>
<span class="no">N</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1"># max number of worker nodes</span>

<span class="c1"># Base Image  https://portal.cloud.hashicorp.com/vagrant/discover/bento/ubuntu-24.04</span>
<span class="no">BOX_IMAGE</span> <span class="o">=</span> <span class="s2">"bento/ubuntu-24.04"</span>
<span class="no">BOX_VERSION</span> <span class="o">=</span> <span class="s2">"202502.21.0"</span>

<span class="no">Vagrant</span><span class="p">.</span><span class="nf">configure</span><span class="p">(</span><span class="s2">"2"</span><span class="p">)</span> <span class="k">do</span> <span class="o">|</span><span class="n">config</span><span class="o">|</span>
  <span class="c1">#-ControlPlane Node</span>
  <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">define</span> <span class="s2">"k8s-ctr"</span> <span class="k">do</span> <span class="o">|</span><span class="n">subconfig</span><span class="o">|</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="no">BOX_IMAGE</span>

    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box_version</span> <span class="o">=</span> <span class="no">BOX_VERSION</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provider</span> <span class="s2">"virtualbox"</span> <span class="k">do</span> <span class="o">|</span><span class="n">vb</span><span class="o">|</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--groups"</span><span class="p">,</span> <span class="s2">"/Cilium-Lab"</span><span class="p">]</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--nicpromisc2"</span><span class="p">,</span> <span class="s2">"allow-all"</span><span class="p">]</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">name</span> <span class="o">=</span> <span class="s2">"k8s-ctr"</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">cpus</span> <span class="o">=</span> <span class="mi">2</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">memory</span> <span class="o">=</span> <span class="mi">2048</span>
      <span class="n">vb</span><span class="p">.</span><span class="nf">linked_clone</span> <span class="o">=</span> <span class="kp">true</span>
    <span class="k">end</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">host_name</span> <span class="o">=</span> <span class="s2">"k8s-ctr"</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.10.100"</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="mi">60000</span><span class="p">,</span> <span class="ss">auto_correct: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">id: </span><span class="s2">"ssh"</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">synced_folder</span> <span class="s2">"./"</span><span class="p">,</span> <span class="s2">"/vagrant"</span><span class="p">,</span> <span class="ss">disabled: </span><span class="kp">true</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"init_cfg.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">K8SV</span><span class="p">,</span> <span class="no">CONTAINERDV</span> <span class="p">]</span>
    <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"k8s-ctr.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">N</span><span class="p">,</span> <span class="no">CILIUMV</span> <span class="p">]</span>
  <span class="k">end</span>

  <span class="c1">#-Worker Nodes Subnet1</span>
  <span class="p">(</span><span class="mi">1</span><span class="o">..</span><span class="no">N</span><span class="p">).</span><span class="nf">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">i</span><span class="o">|</span>
    <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">define</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span> <span class="k">do</span> <span class="o">|</span><span class="n">subconfig</span><span class="o">|</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="no">BOX_IMAGE</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box_version</span> <span class="o">=</span> <span class="no">BOX_VERSION</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provider</span> <span class="s2">"virtualbox"</span> <span class="k">do</span> <span class="o">|</span><span class="n">vb</span><span class="o">|</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--groups"</span><span class="p">,</span> <span class="s2">"/Cilium-Lab"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--nicpromisc2"</span><span class="p">,</span> <span class="s2">"allow-all"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">name</span> <span class="o">=</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">cpus</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">memory</span> <span class="o">=</span> <span class="mi">1536</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">linked_clone</span> <span class="o">=</span> <span class="kp">true</span>
      <span class="k">end</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">host_name</span> <span class="o">=</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.10.10</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="s2">"6000</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span> <span class="ss">auto_correct: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">id: </span><span class="s2">"ssh"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">synced_folder</span> <span class="s2">"./"</span><span class="p">,</span> <span class="s2">"/vagrant"</span><span class="p">,</span> <span class="ss">disabled: </span><span class="kp">true</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"init_cfg.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">K8SV</span><span class="p">,</span> <span class="no">CONTAINERDV</span><span class="p">]</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"k8s-w.sh"</span>
    <span class="k">end</span>
  <span class="k">end</span>
<span class="k">end</span>
</code></pre></div></div>

<h4 id="init_cfgsh"><strong>init_cfg.sh</strong></h4>
<ul>
  <li>프로비저닝시 vagrant가 실행할 초기 설정 스크립트입니다. arguments로 Kubernetes 버전과 Containerd 버전등을 받아서 설치합니다.</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>

<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config Start &lt;&lt;&lt;&lt;"</span>

<span class="nb">echo</span> <span class="s2">"[TASK 1] Setting Profile &amp; Bashrc"</span>
<span class="nb">echo</span> <span class="s1">'alias vi=vim'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s2">"sudo su -"</span> <span class="o">&gt;&gt;</span> /home/vagrant/.bashrc
<span class="nb">ln</span> <span class="nt">-sf</span> /usr/share/zoneinfo/Asia/Seoul /etc/localtime <span class="c"># Change Timezone</span>

<span class="nb">echo</span> <span class="s2">"[TASK 2] Disable AppArmor"</span>
systemctl stop ufw <span class="o">&amp;&amp;</span> systemctl disable ufw <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
systemctl stop apparmor <span class="o">&amp;&amp;</span> systemctl disable apparmor <span class="o">&gt;</span>/dev/null 2&gt;&amp;1

<span class="nb">echo</span> <span class="s2">"[TASK 3] Disable and turn off SWAP"</span>
swapoff <span class="nt">-a</span> <span class="o">&amp;&amp;</span> <span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'/swap/s/^/#/'</span> /etc/fstab

<span class="nb">echo</span> <span class="s2">"[TASK 4] Install Packages"</span>
apt update <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
apt-get <span class="nb">install </span>apt-transport-https ca-certificates curl gpg <span class="nt">-y</span> <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1

<span class="c"># Download the public signing key for the Kubernetes package repositories.</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> <span class="nt">-m</span> 755 /etc/apt/keyrings
<span class="nv">K8SMMV</span><span class="o">=</span><span class="si">$(</span><span class="nb">echo</span> <span class="nv">$1</span> | <span class="nb">sed</span> <span class="nt">-En</span> <span class="s1">'s/^([0-9]+\.[0-9]+)\..*/\1/p'</span><span class="si">)</span>
curl <span class="nt">-fsSL</span> https://pkgs.k8s.io/core:/stable:/v<span class="nv">$K8SMMV</span>/deb/Release.key | <span class="nb">sudo </span>gpg <span class="nt">--dearmor</span> <span class="nt">-o</span> /etc/apt/keyrings/kubernetes-apt-keyring.gpg
<span class="nb">echo</span> <span class="s2">"deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v</span><span class="nv">$K8SMMV</span><span class="s2">/deb/ /"</span> <span class="o">&gt;&gt;</span> /etc/apt/sources.list.d/kubernetes.list
curl <span class="nt">-fsSL</span> https://download.docker.com/linux/ubuntu/gpg <span class="nt">-o</span> /etc/apt/keyrings/docker.asc
<span class="nb">echo</span> <span class="s2">"deb [arch=</span><span class="si">$(</span>dpkg <span class="nt">--print-architecture</span><span class="si">)</span><span class="s2"> signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu </span><span class="si">$(</span><span class="nb">.</span> /etc/os-release <span class="o">&amp;&amp;</span> <span class="nb">echo</span> <span class="s2">"</span><span class="nv">$VERSION_CODENAME</span><span class="s2">"</span><span class="si">)</span><span class="s2"> stable"</span> | <span class="nb">tee</span> /etc/apt/sources.list.d/docker.list <span class="o">&gt;</span> /dev/null

<span class="c"># packets traversing the bridge are processed by iptables for filtering</span>
<span class="nb">echo </span>1 <span class="o">&gt;</span> /proc/sys/net/ipv4/ip_forward
<span class="nb">echo</span> <span class="s2">"net.ipv4.ip_forward = 1"</span> <span class="o">&gt;&gt;</span> /etc/sysctl.d/k8s.conf

<span class="c"># enable br_netfilter for iptables </span>
modprobe br_netfilter
modprobe overlay
<span class="nb">echo</span> <span class="s2">"br_netfilter"</span> <span class="o">&gt;&gt;</span> /etc/modules-load.d/k8s.conf
<span class="nb">echo</span> <span class="s2">"overlay"</span> <span class="o">&gt;&gt;</span> /etc/modules-load.d/k8s.conf

<span class="nb">echo</span> <span class="s2">"[TASK 5] Install Kubernetes components (kubeadm, kubelet and kubectl)"</span>
<span class="c"># Update the apt package index, install kubelet, kubeadm and kubectl, and pin their version</span>
apt update <span class="o">&gt;</span>/dev/null 2&gt;&amp;1

<span class="c"># apt list -a kubelet ; apt list -a containerd.io</span>
apt-get <span class="nb">install</span> <span class="nt">-y</span> <span class="nv">kubelet</span><span class="o">=</span><span class="nv">$1</span> <span class="nv">kubectl</span><span class="o">=</span><span class="nv">$1</span> <span class="nv">kubeadm</span><span class="o">=</span><span class="nv">$1</span> containerd.io<span class="o">=</span><span class="nv">$2</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
apt-mark hold kubelet kubeadm kubectl <span class="o">&gt;</span>/dev/null 2&gt;&amp;1

<span class="c"># containerd configure to default and cgroup managed by systemd</span>
containerd config default <span class="o">&gt;</span> /etc/containerd/config.toml
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'s/SystemdCgroup = false/SystemdCgroup = true/g'</span> /etc/containerd/config.toml

<span class="c"># avoid WARN&amp;ERRO(default endpoints) when crictl run  </span>
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; /etc/crictl.yaml
runtime-endpoint: unix:///run/containerd/containerd.sock
image-endpoint: unix:///run/containerd/containerd.sock
</span><span class="no">EOF

</span><span class="c"># ready to install for k8s </span>
systemctl restart containerd <span class="o">&amp;&amp;</span> systemctl <span class="nb">enable </span>containerd
systemctl <span class="nb">enable</span> <span class="nt">--now</span> kubelet

<span class="nb">echo</span> <span class="s2">"[TASK 6] Install Packages &amp; Helm"</span>
<span class="nb">export </span><span class="nv">DEBIAN_FRONTEND</span><span class="o">=</span>noninteractive
apt-get <span class="nb">install</span> <span class="nt">-y</span> bridge-utils sshpass net-tools conntrack ngrep tcpdump ipset arping wireguard jq tree bash-completion unzip kubecolor termshark <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
curl <span class="nt">-s</span> https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash <span class="o">&gt;</span>/dev/null 2&gt;&amp;1

<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div></div>

<h4 id="k8s-ctrsh"><strong>k8s-ctr.sh</strong></h4>
<ul>
  <li><code class="language-plaintext highlighter-rouge">kubeadm init</code>으로 컨트롤플레인을 설정하고, Cilium CNI를 설치합니다. 또한 편의를 위한 <code class="language-plaintext highlighter-rouge">k</code>, <code class="language-plaintext highlighter-rouge">kc</code> 등의 alias를 설정합니다.</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>

<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Controlplane config Start &lt;&lt;&lt;&lt;"</span>

<span class="nb">echo</span> <span class="s2">"[TASK 1] Initial Kubernetes"</span>
curl <span class="nt">--silent</span> <span class="nt">-o</span> /root/kubeadm-init-ctr-config.yaml https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/2w/kubeadm-init-ctr-config.yaml
kubeadm init <span class="nt">--config</span><span class="o">=</span><span class="s2">"/root/kubeadm-init-ctr-config.yaml"</span> <span class="nt">--skip-phases</span><span class="o">=</span>addon/kube-proxy  <span class="o">&gt;</span>/dev/null 2&gt;&amp;1


<span class="nb">echo</span> <span class="s2">"[TASK 2] Setting kube config file"</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> /root/.kube
<span class="nb">cp</span> <span class="nt">-i</span> /etc/kubernetes/admin.conf /root/.kube/config
<span class="nb">chown</span> <span class="si">$(</span><span class="nb">id</span> <span class="nt">-u</span><span class="si">)</span>:<span class="si">$(</span><span class="nb">id</span> <span class="nt">-g</span><span class="si">)</span> /root/.kube/config


<span class="nb">echo</span> <span class="s2">"[TASK 3] Source the completion"</span>
<span class="nb">echo</span> <span class="s1">'source &lt;(kubectl completion bash)'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'source &lt;(kubeadm completion bash)'</span> <span class="o">&gt;&gt;</span> /etc/profile


<span class="nb">echo</span> <span class="s2">"[TASK 4] Alias kubectl to k"</span>
<span class="nb">echo</span> <span class="s1">'alias k=kubectl'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'alias kc=kubecolor'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'complete -F __start_kubectl k'</span> <span class="o">&gt;&gt;</span> /etc/profile


<span class="nb">echo</span> <span class="s2">"[TASK 5] Install Kubectx &amp; Kubens"</span>
git clone https://github.com/ahmetb/kubectx /opt/kubectx <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">ln</span> <span class="nt">-s</span> /opt/kubectx/kubens /usr/local/bin/kubens
<span class="nb">ln</span> <span class="nt">-s</span> /opt/kubectx/kubectx /usr/local/bin/kubectx


<span class="nb">echo</span> <span class="s2">"[TASK 6] Install Kubeps &amp; Setting PS1"</span>
git clone https://github.com/jonmosco/kube-ps1.git /root/kube-ps1 <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="sh">"</span><span class="no">EOT</span><span class="sh">" &gt;&gt; /root/.bash_profile
source /root/kube-ps1/kube-ps1.sh
KUBE_PS1_SYMBOL_ENABLE=true
function get_cluster_short() {
  echo "</span><span class="nv">$1</span><span class="sh">" | cut -d . -f1
}
KUBE_PS1_CLUSTER_FUNCTION=get_cluster_short
KUBE_PS1_SUFFIX=') '
PS1='</span><span class="si">$(</span>kube_ps1<span class="si">)</span><span class="sh">'</span><span class="nv">$PS1</span><span class="sh">
</span><span class="no">EOT
</span>kubectl config rename-context <span class="s2">"kubernetes-admin@kubernetes"</span> <span class="s2">"HomeLab"</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1


<span class="nb">echo</span> <span class="s2">"[TASK 7] Install Cilium CNI"</span>
<span class="nv">NODEIP</span><span class="o">=</span><span class="si">$(</span>ip <span class="nt">-4</span> addr show eth1 | <span class="nb">grep</span> <span class="nt">-oP</span> <span class="s1">'(?&lt;=inet\s)\d+(\.\d+){3}'</span><span class="si">)</span>
helm repo add cilium https://helm.cilium.io/ <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
helm repo update <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
helm <span class="nb">install </span>cilium cilium/cilium <span class="nt">--version</span> <span class="nv">$2</span> <span class="nt">--namespace</span> kube-system <span class="se">\</span>
<span class="nt">--set</span> <span class="nv">k8sServiceHost</span><span class="o">=</span>192.168.10.100 <span class="nt">--set</span> <span class="nv">k8sServicePort</span><span class="o">=</span>6443 <span class="se">\</span>
<span class="nt">--set</span> ipam.mode<span class="o">=</span><span class="s2">"cluster-pool"</span> <span class="nt">--set</span> ipam.operator.clusterPoolIPv4PodCIDRList<span class="o">={</span><span class="s2">"172.20.0.0/16"</span><span class="o">}</span> <span class="nt">--set</span> <span class="nv">ipv4NativeRoutingCIDR</span><span class="o">=</span>172.20.0.0/16 <span class="se">\</span>
<span class="nt">--set</span> <span class="nv">routingMode</span><span class="o">=</span>native <span class="nt">--set</span> <span class="nv">autoDirectNodeRoutes</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> endpointRoutes.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> <span class="nv">kubeProxyReplacement</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> bpf.masquerade<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> <span class="nv">installNoConntrackIptablesRules</span><span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> endpointHealthChecking.enabled<span class="o">=</span><span class="nb">false</span> <span class="nt">--set</span> <span class="nv">healthChecking</span><span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
<span class="nt">--set</span> hubble.enabled<span class="o">=</span><span class="nb">false</span> <span class="nt">--set</span> operator.replicas<span class="o">=</span>1 <span class="nt">--set</span> debug.enabled<span class="o">=</span><span class="nb">true</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1


<span class="nb">echo</span> <span class="s2">"[TASK 8] Install Cilium CLI"</span>
<span class="nv">CILIUM_CLI_VERSION</span><span class="o">=</span><span class="si">$(</span>curl <span class="nt">-s</span> https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt<span class="si">)</span>
<span class="nv">CLI_ARCH</span><span class="o">=</span>amd64
<span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span><span class="si">)</span><span class="s2">"</span> <span class="o">=</span> <span class="s2">"aarch64"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then </span><span class="nv">CLI_ARCH</span><span class="o">=</span>arm64<span class="p">;</span> <span class="k">fi
</span>curl <span class="nt">-L</span> <span class="nt">--fail</span> <span class="nt">--remote-name-all</span> https://github.com/cilium/cilium-cli/releases/download/<span class="k">${</span><span class="nv">CILIUM_CLI_VERSION</span><span class="k">}</span>/cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">tar </span>xzvfC cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz /usr/local/bin
<span class="nb">rm </span>cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz


<span class="nb">echo</span> <span class="s2">"[TASK 9] local DNS with hosts file"</span>
<span class="nb">echo</span> <span class="s2">"192.168.10.100 k8s-ctr"</span> <span class="o">&gt;&gt;</span> /etc/hosts
<span class="k">for</span> <span class="o">((</span> <span class="nv">i</span><span class="o">=</span>1<span class="p">;</span> i&lt;<span class="o">=</span><span class="nv">$1</span><span class="p">;</span> i++  <span class="o">))</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"192.168.10.10</span><span class="nv">$i</span><span class="s2"> k8s-w</span><span class="nv">$i</span><span class="s2">"</span> <span class="o">&gt;&gt;</span> /etc/hosts<span class="p">;</span> <span class="k">done


</span><span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Controlplane Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div></div>

<ul>
  <li>
    <p>부가적으로 <code class="language-plaintext highlighter-rouge">kubeadm-init-ctr-config.yaml</code> 파일은 다음과 같이 작성되어 있습니다.</p>

    <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">kubeadm.k8s.io/v1beta4</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">InitConfiguration</span>
<span class="na">bootstrapTokens</span><span class="pi">:</span>
<span class="pi">-</span> <span class="na">token</span><span class="pi">:</span> <span class="s2">"</span><span class="s">123456.1234567890123456"</span>
  <span class="na">ttl</span><span class="pi">:</span> <span class="s2">"</span><span class="s">0s"</span>
  <span class="na">usages</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s">signing</span>
  <span class="pi">-</span> <span class="s">authentication</span>
<span class="na">localAPIEndpoint</span><span class="pi">:</span>
  <span class="na">advertiseAddress</span><span class="pi">:</span> <span class="s2">"</span><span class="s">192.168.10.100"</span>
<span class="na">nodeRegistration</span><span class="pi">:</span>
  <span class="na">kubeletExtraArgs</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">node-ip</span>
      <span class="na">value</span><span class="pi">:</span> <span class="s2">"</span><span class="s">192.168.10.100"</span>
  <span class="na">criSocket</span><span class="pi">:</span> <span class="s2">"</span><span class="s">unix:///run/containerd/containerd.sock"</span>
<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">kubeadm.k8s.io/v1beta4</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">ClusterConfiguration</span>
<span class="na">kubernetesVersion</span><span class="pi">:</span> <span class="s">v1.33.2</span>
<span class="na">networking</span><span class="pi">:</span>
  <span class="na">podSubnet</span><span class="pi">:</span> <span class="s2">"</span><span class="s">10.244.0.0/16"</span>
  <span class="na">serviceSubnet</span><span class="pi">:</span> <span class="s2">"</span><span class="s">10.96.0.0/16"</span>
</code></pre></div>    </div>
  </li>
</ul>

<h4 id="k8s-wsh"><strong>k8s-w.sh</strong></h4>
<ul>
  <li>워커노드에서 <code class="language-plaintext highlighter-rouge">kubeadm join</code>을 실행하여 컨트롤플레인에 조인합니다.</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>

<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Node config Start &lt;&lt;&lt;&lt;"</span>

<span class="nb">echo</span> <span class="s2">"[TASK 1] K8S Controlplane Join"</span>
curl <span class="nt">--silent</span> <span class="nt">-o</span> /root/kubeadm-join-worker-config.yaml https://raw.githubusercontent.com/gasida/vagrant-lab/refs/heads/main/cilium-study/2w/kubeadm-join-worker-config.yaml
<span class="nv">NODEIP</span><span class="o">=</span><span class="si">$(</span>ip <span class="nt">-4</span> addr show eth1 | <span class="nb">grep</span> <span class="nt">-oP</span> <span class="s1">'(?&lt;=inet\s)\d+(\.\d+){3}'</span><span class="si">)</span>
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/NODE_IP_PLACEHOLDER/</span><span class="k">${</span><span class="nv">NODEIP</span><span class="k">}</span><span class="s2">/g"</span> /root/kubeadm-join-worker-config.yaml
kubeadm <span class="nb">join</span> <span class="nt">--config</span><span class="o">=</span><span class="s2">"/root/kubeadm-join-worker-config.yaml"</span> <span class="o">&gt;</span> /dev/null 2&gt;&amp;1

<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Node config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">kubeadm-join-worker-config.yaml</code> 파일은 다음과 같이 작성되어 있습니다.
    <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">kubeadm.k8s.io/v1beta4</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">JoinConfiguration</span>
<span class="na">discovery</span><span class="pi">:</span>
  <span class="na">bootstrapToken</span><span class="pi">:</span>
    <span class="na">token</span><span class="pi">:</span> <span class="s2">"</span><span class="s">123456.1234567890123456"</span>
    <span class="na">apiServerEndpoint</span><span class="pi">:</span> <span class="s2">"</span><span class="s">192.168.10.100:6443"</span>
    <span class="na">unsafeSkipCAVerification</span><span class="pi">:</span> <span class="kc">true</span>
<span class="na">nodeRegistration</span><span class="pi">:</span>
  <span class="na">criSocket</span><span class="pi">:</span> <span class="s2">"</span><span class="s">unix:///run/containerd/containerd.sock"</span>
  <span class="na">kubeletExtraArgs</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">node-ip</span>
      <span class="na">value</span><span class="pi">:</span> <span class="s2">"</span><span class="s">NODE_IP_PLACEHOLDER"</span>
</code></pre></div>    </div>
  </li>
</ul>

<h3 id="실습환경-배포">실습환경 배포</h3>

<ul>
  <li>배포</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>vagrant up
</code></pre></div></div>

<ul>
  <li>[k8s-ctr] 접속 후 기본 정보 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># k8s-ctr 접속</span>
<span class="nv">$ </span>vagrant ssh k8s-ctr
<span class="nt">---</span>
<span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> /etc/hosts
<span class="c"># =&gt; 127.0.0.1 localhost</span>
<span class="c">#    127.0.1.1 vagrant</span>
<span class="c">#    ...</span>
<span class="c">#    127.0.2.1 k8s-ctr k8s-ctr</span>
<span class="c">#    192.168.10.100 k8s-ctr</span>
<span class="c">#    192.168.10.101 k8s-w1</span>
<span class="c">#    192.168.10.102 k8s-w2</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-w1 <span class="nb">hostname</span>
<span class="c"># =&gt; k8s-w1</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-w2 <span class="nb">hostname</span>
<span class="c"># =&gt; k8s-w2</span>

<span class="c">#</span>
<span class="nv">$ </span>ifconfig | <span class="nb">grep</span> <span class="nt">-iEA1</span> <span class="s1">'eth[0-9]:'</span>
<span class="c"># =&gt; eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span>
<span class="c">#            inet 10.0.2.15  netmask 255.255.255.0  broadcast 10.0.2.255</span>
<span class="c">#    --</span>
<span class="c">#    eth1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span>
<span class="c">#            inet 192.168.10.100  netmask 255.255.255.0  broadcast 192.168.10.255</span>

<span class="c"># 클러스터 정보 확인</span>
<span class="nv">$ </span>kubectl cluster-info
<span class="nv">$ </span>kubectl cluster-info dump | <span class="nb">grep</span> <span class="nt">-m</span> 2 <span class="nt">-E</span> <span class="s2">"cluster-cidr|service-cluster-ip-range"</span>
<span class="c"># =&gt;                             "--service-cluster-ip-range=10.96.0.0/16",</span>
<span class="c">#                                "--cluster-cidr=10.244.0.0/16",</span>
<span class="nv">$ </span>kubectl describe cm <span class="nt">-n</span> kube-system kubeadm-config
<span class="nv">$ </span>kubectl describe cm <span class="nt">-n</span> kube-system kubelet-config

<span class="c"># 노드 정보 : 상태, INTERNAL-IP 확인</span>
<span class="nv">$ </span>kubectl get node <span class="nt">-owide</span>
<span class="c"># =&gt; NAME      STATUS   ROLES           AGE   VERSION   INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION     CONTAINER-RUNTIME</span>
<span class="c">#    k8s-ctr   Ready    control-plane   14m   v1.33.2   &lt;span style="color: green;"&gt;192.168.10.100&lt;/span&gt;   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>
<span class="c">#    k8s-w1    Ready    &lt;none&gt;          11m   v1.33.2   &lt;span style="color: green;"&gt;192.168.10.101&lt;/span&gt;   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>
<span class="c">#    k8s-w2    Ready    &lt;none&gt;          10m   v1.33.2   &lt;span style="color: green;"&gt;192.168.10.102&lt;/span&gt;   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>

<span class="c"># 노드별 kubeadm-flags.env 정보 확인</span>
<span class="nv">$ </span><span class="nb">cat</span> /var/lib/kubelet/kubeadm-flags.env
<span class="c"># =&gt; KUBELET_KUBEADM_ARGS="--container-runtime-endpoint=unix:///run/containerd/containerd.sock --node-ip=192.168.10.100 --pod-infra-container-image=registry.k8s.io/pause:3.10"</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> <span class="nb">cat</span> /var/lib/kubelet/kubeadm-flags.env <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>

<span class="c"># 파드 정보 : 상태, 파드 IP 확인</span>
<span class="nv">$ </span>kubectl get nodes <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{range .items[*]}{.metadata.name}{"\t"}{.spec.podCIDR}{"\n"}{end}'</span>
<span class="c"># =&gt; k8s-ctr 10.244.0.0/24</span>
<span class="c">#    k8s-w1  10.244.1.0/24</span>
<span class="c">#    k8s-w2  10.244.2.0/24</span>
<span class="nv">$ </span>kubectl get ciliumnode <span class="nt">-o</span> json | <span class="nb">grep </span>podCIDRs <span class="nt">-A2</span>
<span class="c"># =&gt;                     "podCIDRs": [ "172.20.0.0/24" ],</span>
<span class="c">#    --</span>
<span class="c">#                        "podCIDRs": [ "172.20.1.0/24" ],</span>
<span class="c">#    --</span>
<span class="c">#                        "podCIDRs": [ "172.20.2.0/24" ],</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-A</span> <span class="nt">-owide</span>
<span class="c"># =&gt; NAMESPACE     NAME                               READY   STATUS    RESTARTS   AGE   IP               NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-2rgdx&lt;/span&gt;                       1/1     Running   0          15m   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-envoy-q97fq&lt;/span&gt;                 1/1     Running   0          12m   192.168.10.102   k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-envoy-xzxd6&lt;/span&gt;                 1/1     Running   0          13m   192.168.10.101   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-envoy-zzzw5&lt;/span&gt;                 1/1     Running   0          15m   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-fdqhq&lt;/span&gt;                       1/1     Running   0          12m   192.168.10.102   k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-kv67c&lt;/span&gt;                       1/1     Running   0          13m   192.168.10.101   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-operator-5bc66f5b9b-xps5x&lt;/span&gt;   1/1     Running   0          15m   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-4h2lt           1/1     &lt;span style="color: green;"&gt;Running&lt;/span&gt;   0          15m   172.20.0.233     k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-7m82r           1/1     &lt;span style="color: green;"&gt;Running&lt;/span&gt;   0          15m   172.20.0.167     k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   etcd-k8s-ctr                       1/1     Running   0          16m   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-apiserver-k8s-ctr             1/1     Running   0          16m   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-controller-manager-k8s-ctr    1/1     Running   0          16m   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-scheduler-k8s-ctr             1/1     Running   0          16m   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 cilium CNI가 설치되어있고, CNI가 설치되었기 때문에 coredns가 Running 상태로 시작됨을 알 수 있습니다.&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 또한 kube-proxy가 설치되지 않았고, Cilium이 kube-proxy를 대체하고 있음을 알 수 있습니다.&lt;/span&gt;</span>

<span class="c"># iptables 확인</span>
<span class="nv">$ </span>iptables-save
<span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> filter <span class="nt">-S</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> mangle <span class="nt">-S</span>
</code></pre></div></div>

<ul>
  <li>[k8s-ctr] cilium 설치 정보 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># cilium 상태 확인</span>
<span class="nv">$ </span>which cilium
<span class="c"># =&gt; /usr/local/bin/cilium</span>
<span class="nv">$ </span>cilium status
<span class="c"># =&gt;     /¯¯\</span>
<span class="c">#     /¯¯\__/¯¯\    Cilium:             OK</span>
<span class="c">#     \__/¯¯\__/    Operator:           OK</span>
<span class="c">#     /¯¯\__/¯¯\    Envoy DaemonSet:    OK</span>
<span class="c">#     \__/¯¯\__/    Hubble Relay:       disabled</span>
<span class="c">#        \__/       ClusterMesh:        disabled</span>
<span class="c">#    </span>
<span class="c">#    DaemonSet              cilium                   Desired: 3, Ready: 3/3, Available: 3/3</span>
<span class="c">#    DaemonSet              cilium-envoy             Desired: 3, Ready: 3/3, Available: 3/3</span>
<span class="c">#    Deployment             cilium-operator          Desired: 1, Ready: 1/1, Available: 1/1</span>
<span class="c">#    Containers:            cilium                   Running: 3</span>
<span class="c">#                           cilium-envoy             Running: 3</span>
<span class="c">#                           cilium-operator          Running: 1</span>
<span class="c">#                           clustermesh-apiserver</span>
<span class="c">#                           hubble-relay</span>
<span class="c">#    Cluster Pods:          2/2 managed by Cilium</span>
<span class="c">#    Helm chart version:    1.17.6</span>
<span class="c">#    Image versions         cilium             quay.io/cilium/cilium:v1.17.6@sha256:544de3d4fed7acba72758413812780a4972d47c39035f2a06d6145d8644a3353: 3</span>
<span class="c">#                           cilium-envoy       quay.io/cilium/cilium-envoy:v1.33.4-1752151664-7c2edb0b44cf95f326d628b837fcdd845102ba68@sha256:318eff387835ca2717baab42a84f35a83a5f9e7d519253df87269f80b9ff0171: 3</span>
<span class="c">#                           cilium-operator    quay.io/cilium/operator-generic:v1.17.6@sha256:91ac3bf7be7bed30e90218f219d4f3062a63377689ee7246062fa0cc3839d096: 1</span>
<span class="nv">$ </span>cilium config view
<span class="nv">$ </span>kubectl get cm <span class="nt">-n</span> kube-system cilium-config <span class="nt">-o</span> json | jq

<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg config
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg status <span class="nt">--verbose</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg metrics list

<span class="c">#</span>
<span class="nv">$ </span>kubectl get ciliumendpoints <span class="nt">-A</span>

<span class="c"># monitor</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg monitor
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg monitor <span class="nt">-v</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg monitor <span class="nt">-v</span> <span class="nt">-v</span>

<span class="c">## Filter for only the events related to endpoint</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg monitor <span class="nt">--related-to</span><span class="o">=</span>&lt;<span class="nb">id</span><span class="o">&gt;</span>

<span class="c">## Show notifications only for dropped packet events</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg monitor <span class="nt">--type</span> drop

<span class="c">## Don’t dissect packet payload, display payload in hex information</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg monitor <span class="nt">-v</span> <span class="nt">-v</span> <span class="nt">--hex</span>

<span class="c">## Layer7</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg monitor <span class="nt">-v</span> <span class="nt">--type</span> l7
</code></pre></div></div>

<h3 id="cilium-agent-단축키-지정">Cilium Agent 단축키 지정</h3>

<ul>
  <li><a href="https://sweetlittlebird.github.io/posts/2025-07-20-Cilium-Week1/#%EB%A7%88%EC%B9%98%EB%A9%B0">[Cilium] 실습 환경 구성 및 Cilium 설치</a>의 Cilium CMD Cheatsheet를 참고하여 환경변수와 alias를 지정합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># cilium 파드 이름</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD0</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-ctr <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD1</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-w1  <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD2</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-w2  <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$CILIUMPOD0</span> <span class="nv">$CILIUMPOD1</span> <span class="nv">$CILIUMPOD2</span>
<span class="c"># =&gt; cilium-5kc8d cilium-w9st8 cilium-l8lm7</span>

<span class="c"># 단축키(alias) 지정</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c0</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD0</span><span class="s2"> -n kube-system -c cilium-agent -- cilium"</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c1</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD1</span><span class="s2"> -n kube-system -c cilium-agent -- cilium"</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c2</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD2</span><span class="s2"> -n kube-system -c cilium-agent -- cilium"</span>

<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c0bpf</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD0</span><span class="s2"> -n kube-system -c cilium-agent -- bpftool"</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c1bpf</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD1</span><span class="s2"> -n kube-system -c cilium-agent -- bpftool"</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c2bpf</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD2</span><span class="s2"> -n kube-system -c cilium-agent -- bpftool"</span>
</code></pre></div></div>

<h2 id="network-observability-with-hubble">Network Observability with Hubble</h2>

<h3 id="hubble-소개">Hubble 소개</h3>

<p><img src="/assets/2025/cilium/w2/20250727_cilium_w2_2.png" alt="img.png" class="image-center w-80" /></p>

<ul>
  <li><strong>Hubble</strong>은 Cilium과 eBPF를 기반으로 구축된 <strong>완전히 분산된 네트워킹 및 보안 관측 가능성 플랫폼</strong>입니다.
서비스의 통신 및 동작뿐만 아니라 네트워킹 인프라에 대한 깊은 가시성을 투명하게 제공합니다.</li>
  <li><strong>Hubble</strong>은 오버헤드를 최소화 하는 동적 접근 방식을 제공하며, 다중 클러스터(ClusterMesh) 환경에서도 노드 수준, 컨트롤러 수준 또는
클러스터 간 가시성을 제공할 수 있습니다.</li>
  <li><strong>Hubble API</strong>는 Cilium 에이전트가 실행되는 개별 노드에서 작동합니다. Hubble CLI는 로컬 유닉스 도메인 소켓을 통해 제공되는 Hubble API를 쿼리할 수 있습니다.</li>
  <li><strong>Hubble Relay</strong>를 배포하면 클러스터 메시 시나리오에서 전체 클러스터 또는 여러 클러스터에 대한 가시성을 제공합니다. 이 모드에서는
Hubble CLI를 Hubble Relay에 연결하여 모든 노드에서 수집된 이벤트를 쿼리하거나, Hubble UI를 통해 Hubble 데이터에 접근할 수 있습니다.</li>
  <li>서비스 의존성 및 통신 그래프를 시각화 할 수 있습니다.</li>
  <li>네트워크 정책 모니터링 및 알림을 제공하여 네트워크 통신 실패 등을 모니터링 하고 원인을 파악하는데 도움을 줍니다.</li>
  <li>애플리케이션 성능 모니터링을 통해 서비스 간의 지연 시간, 오류율 등을 측정하고 분석할 수 있습니다.</li>
  <li>보안 정책 모니터링을 통해 네트워크 정책 위반, 의심스러운 트래픽 등을 감지하고 대응할 수 있습니다.</li>
</ul>

<h3 id="hubble-observability-설치">Hubble Observability 설치</h3>

<ul>
  <li>관련 문서 : <a href="https://docs.cilium.io/en/stable/observability/hubble/setup/">docs</a></li>
  <li>설치 전 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>cilium status
<span class="c"># =&gt; ...</span>
<span class="c">#     \__/¯¯\__/    Hubble Relay:       disabled</span>
<span class="c">#    ...</span>
<span class="c">#    Containers:            cilium                   Running: 3</span>
<span class="c">#                           cilium-envoy             Running: 3</span>
<span class="c">#                           cilium-operator          Running: 1</span>
<span class="c">#                           clustermesh-apiserver</span>
<span class="c">#                           hubble-relay</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>cilium config view | <span class="nb">grep</span> <span class="nt">-i</span> hubble
<span class="c"># =&gt; enable-hubble                                     false</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 현재 Hubble이 설치되어 있지 않습니다.&lt;/span&gt;</span>

<span class="nv">$ </span>kubectl get cm <span class="nt">-n</span> kube-system cilium-config <span class="nt">-o</span> json | jq
<span class="c"># =&gt; ...</span>
<span class="c">#        "enable-hubble": "false",</span>
<span class="c">#</span>
<span class="nv">$ </span>kubectl get secret <span class="nt">-n</span> kube-system | <span class="nb">grep</span> <span class="nt">-iE</span> <span class="s1">'cilium-ca|hubble'</span>
<span class="c"># =&gt; (공백) </span>
<span class="nv">$ </span>ss <span class="nt">-tnlp</span> | <span class="nb">grep</span> <span class="nt">-iE</span> <span class="s1">'cilium|hubble'</span> | <span class="nb">tee </span>before.txt
<span class="c"># =&gt; LISTEN 0      4096        127.0.0.1:37303      0.0.0.0:*    users:(("cilium-agent",pid=2853,fd=42))</span>
<span class="c">#    LISTEN 0      4096        127.0.0.1:9234       0.0.0.0:*    users:(("cilium-operator",pid=2153,fd=9))</span>
<span class="c">#    LISTEN 0      4096          0.0.0.0:9964       0.0.0.0:*    users:(("cilium-envoy",pid=2224,fd=25))</span>
<span class="c">#    LISTEN 0      4096          0.0.0.0:9964       0.0.0.0:*    users:(("cilium-envoy",pid=2224,fd=24))</span>
<span class="c">#    LISTEN 0      4096        127.0.0.1:9890       0.0.0.0:*    users:(("cilium-agent",pid=2853,fd=6))</span>
<span class="c">#    LISTEN 0      4096        127.0.0.1:9891       0.0.0.0:*    users:(("cilium-operator",pid=2153,fd=6))</span>
<span class="c">#    LISTEN 0      4096        127.0.0.1:9878       0.0.0.0:*    users:(("cilium-envoy",pid=2224,fd=27))</span>
<span class="c">#    LISTEN 0      4096        127.0.0.1:9878       0.0.0.0:*    users:(("cilium-envoy",pid=2224,fd=26))</span>
<span class="c">#    LISTEN 0      4096        127.0.0.1:9879       0.0.0.0:*    users:(("cilium-agent",pid=2853,fd=51))</span>
<span class="c">#    LISTEN 0      4096                *:9963             *:*    users:(("cilium-operator",pid=2153,fd=7))</span>
</code></pre></div></div>

<ul>
  <li>Hubble 설치</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 설치방안 1 : hubble 활성화, 메트릭 설정 등등</span>
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--namespace</span> kube-system <span class="nt">--reuse-values</span> <span class="se">\</span>
  <span class="nt">--set</span> hubble.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> hubble.relay.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> hubble.ui.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> hubble.ui.service.type<span class="o">=</span>NodePort <span class="se">\</span>
  <span class="nt">--set</span> hubble.ui.service.nodePort<span class="o">=</span>31234 <span class="se">\</span>
  <span class="nt">--set</span> hubble.export.static.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> hubble.export.static.filePath<span class="o">=</span>/var/run/cilium/hubble/events.log <span class="se">\</span>
  <span class="nt">--set</span> prometheus.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> operator.prometheus.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> hubble.metrics.enableOpenMetrics<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> hubble.metrics.enabled<span class="o">=</span><span class="s2">"{dns,drop,tcp,flow,port-distribution,icmp,httpV2:exemplars=true;labelsContext=source_ip</span><span class="se">\,</span><span class="s2">source_namespace</span><span class="se">\,</span><span class="s2">source_workload</span><span class="se">\,</span><span class="s2">destination_ip</span><span class="se">\,</span><span class="s2">destination_namespace</span><span class="se">\,</span><span class="s2">destination_workload</span><span class="se">\,</span><span class="s2">traffic_direction}"</span>
<span class="c"># =&gt; Release "cilium" has been upgraded. Happy Helming!</span>
<span class="c">#    NAME: cilium</span>
<span class="c">#    LAST DEPLOYED: Thu Jul 24 23:16:48 2025</span>
<span class="c">#    NAMESPACE: kube-system</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 2</span>
<span class="c">#    TEST SUITE: None</span>
<span class="c">#    NOTES:</span>
<span class="c">#    You have successfully installed Cilium with Hubble Relay and Hubble UI.</span>
<span class="c">#    </span>
<span class="c">#    Your release version is 1.17.6.  </span>

<span class="c"># 설치방안 2 : hubble 활성화</span>
<span class="nv">$ </span>cilium hubble <span class="nb">enable</span>
<span class="nv">$ </span>cilium hubble <span class="nb">enable</span> <span class="nt">--ui</span>

<span class="c"># cilium status를 통한 hubble 설치 상태 확인</span>
<span class="nv">$ </span>cilium status
<span class="c"># =&gt; ...</span>
<span class="c">#     \__/¯¯\__/    Hubble Relay:       OK</span>
<span class="c">#    ...</span>
<span class="c">#    Deployment             hubble-relay             Desired: 1, Ready: 1/1, Available: 1/1</span>
<span class="c">#    Deployment             hubble-ui                Desired: 1, Ready: 1/1, Available: 1/1</span>
<span class="c">#    Containers:            hubble-relay             Running: 1</span>
<span class="c">#                           hubble-ui                Running: 1</span>

<span class="c"># hubble 관련 설정 정보 확인</span>
<span class="nv">$ </span>cilium config view | <span class="nb">grep</span> <span class="nt">-i</span> hubble
<span class="c"># =&gt; enable-hubble                                     true</span>
<span class="c">#    enable-hubble-open-metrics                        true</span>
<span class="c">#    hubble-disable-tls                                false</span>
<span class="c">#    hubble-export-allowlist</span>
<span class="c">#    hubble-export-denylist</span>
<span class="c">#    hubble-export-fieldmask</span>
<span class="c">#    hubble-export-file-max-backups                    5</span>
<span class="c">#    hubble-export-file-max-size-mb                    10</span>
<span class="c">#    hubble-export-file-path                           /var/run/cilium/hubble/events.log</span>
<span class="c">#    hubble-listen-address                             :4244</span>
<span class="c">#    hubble-metrics                                    dns drop tcp flow port-distribution icmp httpV2:exemplars=true;labelsContext=source_ip,source_namespace,source_workload,destination_ip,destination_namespace,destination_workload,traffic_direction</span>
<span class="c">#    hubble-metrics-server                             :9965</span>
<span class="c">#    hubble-metrics-server-enable-tls                  false</span>
<span class="c">#    hubble-socket-path                                /var/run/cilium/hubble.sock</span>
<span class="c">#    hubble-tls-cert-file                              /var/lib/cilium/tls/hubble/server.crt</span>
<span class="c">#    hubble-tls-client-ca-files                        /var/lib/cilium/tls/hubble/client-ca.crt</span>
<span class="c">#    hubble-tls-key-file                               /var/lib/cilium/tls/hubble/server.key</span>

<span class="c"># config map에서 hubble 관련 설정 정보 확인</span>
<span class="nv">$ </span>kubectl get cm <span class="nt">-n</span> kube-system cilium-config <span class="nt">-o</span> json | <span class="nb">grep</span> <span class="nt">-i</span> hubble
<span class="c"># =&gt;         "enable-hubble": "true",</span>
<span class="c">#            "enable-hubble-open-metrics": "true",</span>
<span class="c">#            "hubble-disable-tls": "false",</span>
<span class="c">#            "hubble-export-allowlist": "",</span>
<span class="c">#    ...</span>

<span class="c"># hubble 관련 secret 정보 확인</span>
<span class="nv">$ </span>kubectl get secret <span class="nt">-n</span> kube-system | <span class="nb">grep</span> <span class="nt">-iE</span> <span class="s1">'cilium-ca|hubble'</span>
<span class="c"># =&gt; cilium-ca                      Opaque                          2      4m57s</span>
<span class="c">#    hubble-relay-client-certs      kubernetes.io/tls               3      4m57s</span>
<span class="c">#    hubble-server-certs            kubernetes.io/tls               3      4m57s</span>

<span class="c"># TCP 포트 4244를 모든 cilium을 실행하는 노드에서 열어야 할 필요가 있음</span>
<span class="nv">$ </span>ss <span class="nt">-tnlp</span> | <span class="nb">grep</span> <span class="nt">-iE</span> <span class="s1">'cilium|hubble'</span> | <span class="nb">tee </span>after.txt
<span class="c"># =&gt; LISTEN 0      4096        127.0.0.1:37303      0.0.0.0:*    users:(("cilium-agent",pid=4891,fd=52))</span>
<span class="c">#    LISTEN 0      4096        127.0.0.1:9234       0.0.0.0:*    users:(("cilium-operator",pid=2153,fd=9))</span>
<span class="c">#    LISTEN 0      4096          0.0.0.0:9964       0.0.0.0:*    users:(("cilium-envoy",pid=2224,fd=25))</span>
<span class="c">#    LISTEN 0      4096          0.0.0.0:9964       0.0.0.0:*    users:(("cilium-envoy",pid=2224,fd=24))</span>
<span class="c">#    LISTEN 0      4096        127.0.0.1:9890       0.0.0.0:*    users:(("cilium-agent",pid=4891,fd=6))</span>
<span class="c">#    LISTEN 0      4096        127.0.0.1:9891       0.0.0.0:*    users:(("cilium-operator",pid=2153,fd=6))</span>
<span class="c">#    LISTEN 0      4096        127.0.0.1:9878       0.0.0.0:*    users:(("cilium-envoy",pid=2224,fd=27))</span>
<span class="c">#    LISTEN 0      4096        127.0.0.1:9878       0.0.0.0:*    users:(("cilium-envoy",pid=2224,fd=26))</span>
<span class="c">#    LISTEN 0      4096        127.0.0.1:9879       0.0.0.0:*    users:(("cilium-agent",pid=4891,fd=62))</span>
<span class="c">#    LISTEN 0      4096                *:4244             *:*    users:(("cilium-agent",pid=4891,fd=55))</span>
<span class="c">#    LISTEN 0      4096                *:9965             *:*    users:(("cilium-agent",pid=4891,fd=34))</span>
<span class="c">#    LISTEN 0      4096                *:9962             *:*    users:(("cilium-agent",pid=4891,fd=7))</span>
<span class="c">#    LISTEN 0      4096                *:9963             *:*    users:(("cilium-operator",pid=2153,fd=7))</span>

<span class="c"># Hubble 실행 전과 후의 리스닝 포트 변경확인</span>
<span class="nv">$ </span>vi <span class="nt">-d</span> before.txt after.txt
<span class="c"># =&gt;   LISTEN 0      4096        127.0.0.1:37303      0.0.0.0:|  LISTEN 0      4096        127.0.0.1:37303      0.0.0.0:</span>
<span class="c">#      LISTEN 0      4096        127.0.0.1:9234       0.0.0.0:|  LISTEN 0      4096        127.0.0.1:9234       0.0.0.0:</span>
<span class="c">#      LISTEN 0      4096          0.0.0.0:9964       0.0.0.0:|  LISTEN 0      4096          0.0.0.0:9964       0.0.0.0:</span>
<span class="c">#      LISTEN 0      4096          0.0.0.0:9964       0.0.0.0:|  LISTEN 0      4096          0.0.0.0:9964       0.0.0.0:</span>
<span class="c">#      LISTEN 0      4096        127.0.0.1:9890       0.0.0.0:|  LISTEN 0      4096        127.0.0.1:9890       0.0.0.0:</span>
<span class="c">#      LISTEN 0      4096        127.0.0.1:9891       0.0.0.0:|  LISTEN 0      4096        127.0.0.1:9891       0.0.0.0:</span>
<span class="c">#      LISTEN 0      4096        127.0.0.1:9878       0.0.0.0:|  LISTEN 0      4096        127.0.0.1:9878       0.0.0.0:</span>
<span class="c">#      LISTEN 0      4096        127.0.0.1:9878       0.0.0.0:|  LISTEN 0      4096        127.0.0.1:9878       0.0.0.0:</span>
<span class="c">#      LISTEN 0      4096        127.0.0.1:9879       0.0.0.0:|  LISTEN 0      4096        127.0.0.1:9879       0.0.0.0:</span>
<span class="c">#      -------------------------------------------------------|  &lt;span style="background-color: green; color: #fff;"&gt;LISTEN 0      4096                *:4244             *:&lt;/span&gt;</span>
<span class="c">#      -------------------------------------------------------|  &lt;span style="background-color: green; color: #fff;"&gt;LISTEN 0      4096                *:9965             *:&lt;/span&gt;</span>
<span class="c">#      -------------------------------------------------------|  &lt;span style="background-color: green; color: #fff;"&gt;LISTEN 0      4096                *:9962             *:&lt;/span&gt;</span>
<span class="c">#      LISTEN 0      4096                *:9963             *:|  LISTEN 0      4096                *:9963             *:</span>

<span class="c"># 각 노드의 4244 포트 오픈 확인</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>ss <span class="nt">-tnlp</span> |grep 4244 <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    LISTEN 0      4096               *:4244             *:*    users:(("cilium-agent",pid=3528,fd=50))</span>
<span class="c">#    &gt;&gt; node : k8s-w2 &lt;&lt;</span>
<span class="c">#    LISTEN 0      4096               *:4244             *:*    users:(("cilium-agent",pid=3268,fd=46))</span>

<span class="c"># Hubble Relay Pod 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>hubble-relay
<span class="c"># =&gt; NAME                           READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    hubble-relay-5dcd46f5c-n4zfx   1/1     Running   0          12m</span>

<span class="nv">$ </span>kc describe pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>hubble-relay
<span class="c"># =&gt; Name:             hubble-relay-5dcd46f5c-n4zfx</span>
<span class="c">#    Namespace:        kube-system</span>
<span class="c">#    Service Account:  hubble-relay</span>
<span class="c">#    Labels:           app.kubernetes.io/name=hubble-relay</span>
<span class="c">#                      app.kubernetes.io/part-of=cilium</span>
<span class="c">#                      k8s-app=hubble-relay</span>
<span class="c">#    ...</span>
<span class="c">#        Image:         quay.io/cilium/hubble-relay:v1.17.6@sha256:7d17ec10b3d37341c18ca56165b2f29a715cb8ee81311fd07088d8bf68c01e60</span>
<span class="c">#    ...</span>

<span class="nv">$ </span>kc get svc,ep <span class="nt">-n</span> kube-system hubble-relay
<span class="c"># =&gt; NAME                   TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE</span>
<span class="c">#    service/hubble-relay   ClusterIP   10.96.207.219   &lt;none&gt;        80/TCP    14m</span>
<span class="c">#    </span>
<span class="c">#    NAME                     ENDPOINTS           AGE</span>
<span class="c">#    endpoints/hubble-relay   172.20.2.214:4245   14m</span>

<span class="c"># hubble-relay 는 hubble-peer 의 서비스(ClusterIP :443)을 통해 모든 노드의 :4244에 요청 가져올 수 있음</span>
<span class="nv">$ </span>kubectl get cm <span class="nt">-n</span> kube-system
<span class="c"># =&gt; NAME                                                   DATA   AGE</span>
<span class="c">#    cilium-config                                          158    23h</span>
<span class="c">#    cilium-envoy-config                                    1      23h</span>
<span class="c">#    ...</span>
<span class="c">#    hubble-relay-config                                    1      17m</span>
<span class="c">#    hubble-ui-nginx                                        1      17m</span>

<span class="nv">$ </span>kubectl describe cm <span class="nt">-n</span> kube-system hubble-relay-config
<span class="c"># =&gt; ...</span>
<span class="c">#    cluster-name: default</span>
<span class="c">#    peer-service: "hubble-peer.kube-system.svc.cluster.local.:443"</span>
<span class="c">#    listen-address: :4245</span>
<span class="c">#    ...</span>

<span class="c"># Hubble Peer Pod 확인</span>
<span class="nv">$ </span>kubectl get svc,ep <span class="nt">-n</span> kube-system hubble-peer
<span class="c"># =&gt; NAME                  TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE</span>
<span class="c">#    service/hubble-peer   ClusterIP   10.96.12.202   &lt;none&gt;        443/TCP   21m</span>
<span class="c">#    </span>
<span class="c">#    NAME                    ENDPOINTS                                                     AGE</span>
<span class="c">#    endpoints/hubble-peer   192.168.10.100:4244,192.168.10.101:4244,192.168.10.102:4244   21m</span>

<span class="c">#</span>
<span class="nv">$ </span>kc describe pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>hubble-ui
<span class="c"># =&gt; ...</span>
<span class="c">#      frontend:</span>
<span class="c">#        Port:           8081/TCP</span>
<span class="c">#        ...</span>
<span class="c">#      backend:</span>
<span class="c">#        Port:           8090/TCP</span>
<span class="c">#        ...</span>

<span class="nv">$ </span>kc describe cm <span class="nt">-n</span> kube-system hubble-ui-nginx
<span class="c"># =&gt; ...</span>
<span class="c">#    nginx.conf:</span>
<span class="c">#    ----</span>
<span class="c">#    server {</span>
<span class="c">#        listen       8081;</span>
<span class="c">#        listen       [::]:8081;</span>
<span class="c">#        server_name  localhost;</span>
<span class="c">#        root /app;</span>
<span class="c">#        index index.html;</span>
<span class="c">#        client_max_body_size 1G;</span>
<span class="c">#    </span>
<span class="c">#        location / {</span>
<span class="c">#            proxy_set_header Host $host;</span>
<span class="c">#            proxy_set_header X-Real-IP $remote_addr;</span>
<span class="c">#    </span>
<span class="c">#            location /api {</span>
<span class="c">#                proxy_http_version 1.1;</span>
<span class="c">#                proxy_pass_request_headers on;</span>
<span class="c">#                proxy_pass http://127.0.0.1:8090;</span>
<span class="c">#            }</span>
<span class="c">#            location / {</span>
<span class="c">#                # double `/index.html` is required here</span>
<span class="c">#                try_files $uri $uri/ /index.html /index.html;</span>
<span class="c">#            }</span>
<span class="c">#    </span>
<span class="c">#            # Liveness probe</span>
<span class="c">#            location /healthz {</span>
<span class="c">#                access_log off;</span>
<span class="c">#                add_header Content-Type text/plain;</span>
<span class="c">#                return 200 'ok';</span>
<span class="c">#            }</span>
<span class="c">#        }</span>
<span class="c">#    }</span>
<span class="c">#    ...</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get svc,ep <span class="nt">-n</span> kube-system hubble-ui
<span class="c"># =&gt; NAME                TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE</span>
<span class="c">#    service/hubble-ui   NodePort   10.96.183.249   &lt;none&gt;        80:31234/TCP   26m</span>
<span class="c">#    </span>
<span class="c">#    NAME                  ENDPOINTS           AGE</span>
<span class="c">#    endpoints/hubble-ui   172.20.1.189:8081   26m</span>

<span class="c"># hubble ui 웹 접속 주소 확인</span>
<span class="nv">$ NODEIP</span><span class="o">=</span><span class="si">$(</span>ip <span class="nt">-4</span> addr show eth1 | <span class="nb">grep</span> <span class="nt">-oP</span> <span class="s1">'(?&lt;=inet\s)\d+(\.\d+){3}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"http://</span><span class="nv">$NODEIP</span><span class="s2">:31234"</span>
<span class="c"># =&gt; http://192.168.10.100:31234</span>
</code></pre></div></div>

<ul>
  <li>
    <p>Hubble ui 접속 테스트 -&gt; 접속 후 kube-system 네임스페이스 선택
<img src="/assets/2025/cilium/w2/20250727_cilium_w2_3.png" alt="img.png" class="image-center" /></p>
  </li>
  <li>
    <p>Hubble Client 설치 - <a href="https://docs.cilium.io/en/stable/observability/hubble/setup/#install-the-hubble-client">docs</a></p>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ HUBBLE_VERSION</span><span class="o">=</span><span class="si">$(</span>curl <span class="nt">-s</span> https://raw.githubusercontent.com/cilium/hubble/master/stable.txt<span class="si">)</span>
<span class="nv">$ HUBBLE_ARCH</span><span class="o">=</span>amd64
<span class="nv">$ </span><span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span><span class="si">)</span><span class="s2">"</span> <span class="o">=</span> <span class="s2">"aarch64"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then </span><span class="nv">HUBBLE_ARCH</span><span class="o">=</span>arm64<span class="p">;</span> <span class="k">fi</span>
<span class="nv">$ </span>curl <span class="nt">-L</span> <span class="nt">--fail</span> <span class="nt">--remote-name-all</span> https://github.com/cilium/hubble/releases/download/<span class="nv">$HUBBLE_VERSION</span>/hubble-linux-<span class="k">${</span><span class="nv">HUBBLE_ARCH</span><span class="k">}</span>.tar.gz<span class="o">{</span>,.sha256sum<span class="o">}</span>
<span class="nv">$ </span><span class="nb">sudo tar </span>xzvfC hubble-linux-<span class="k">${</span><span class="nv">HUBBLE_ARCH</span><span class="k">}</span>.tar.gz /usr/local/bin
<span class="c"># =&gt; hubble</span>
<span class="nv">$ </span>which hubble
<span class="c"># =&gt; /usr/local/bin/hubble</span>
<span class="nv">$ </span>hubble status
<span class="c"># =&gt; failed getting status: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing: dial tcp 127.0.0.1:4245: connect: connection refused"</span>
</code></pre></div></div>

<ul>
  <li>Hubble client를 설치했지만 기본적으로 localhost를 통해 연결을 시도하기 때문에 연결이 되지 않습니다.
포트포워딩을 통해 hubble relay를 통해 연결할 수 있도록 설정합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>cilium hubble port-forward&amp;
<span class="c"># =&gt;   Hubble Relay is available at 127.0.0.1:4245</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 4245 포트가 localhost로 포워딩 되었습니다.&lt;/span&gt;</span>

<span class="nv">$ </span>ss <span class="nt">-tnlp</span> | <span class="nb">grep </span>4245
<span class="c"># =&gt; LISTEN 0      4096        127.0.0.1:4245       0.0.0.0:*    users:(("cilium",pid=3402,fd=7))</span>

<span class="c"># Now you can validate that you can access the Hubble API via the installed CLI</span>
<span class="nv">$ </span>hubble status
<span class="c"># =&gt; Healthcheck (via localhost:4245): Ok</span>
<span class="c">#    Current/Max Flows: 12,285/12,285 (100.00%)</span>
<span class="c">#    Flows/s: 31.55</span>
<span class="c">#    Connected Nodes: 3/3</span>

<span class="c"># hubble (api) server 기본 접속 주소 확인</span>
<span class="nv">$ </span>hubble config view 
<span class="c"># =&gt; ...</span>
<span class="c">#    port-forward-port: "4245"</span>
<span class="c">#    server: localhost:4245</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<h3 id="star-wars-demo를-통한-hubbleui-체험">Star Wars Demo를 통한 Hubble/UI 체험</h3>

<p><img src="/assets/2025/cilium/w2/20250727_cilium_w2_4.png" alt="img.png" class="image-center w-80" />
<em class="image-caption">목표 배포상태</em></p>

<ul>
  <li>스타워즈에서 영감을 받은 예제이며, deathstar, xwing, tiefighter의 세가지 마이크로 서비스로 구성되어 있습니다.</li>
  <li>deathstar는 80포트에서 http 웹서비스를 실행하며, 두 개의 pod 복제본에 걸쳐 로드 밸런싱을 수행합니다.</li>
  <li>deathstar 서비스는 empire의 우주선에 착륙 서비스를 제공하여 착륙 포트 요청을 할 수 있도록 합니다.</li>
  <li>tiefighter는 일반적인 제국 우주선의 착륙 요청 클라이언트 서비스를 나타내며 xwing은 연합 우주선의 착륙 요청 클라이언트 서비스를 나타냅니다.</li>
  <li>deathstar 착륙 서비스에 대한 접근 제어를 위한 다양한 보안 정책을 테스트하기 위하여 구성되었습니다.</li>
</ul>

<h4 id="데모-애플리케이션-배포">데모 애플리케이션 배포</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/minikube/http-sw-app.yaml
<span class="c"># =&gt; service/deathstar created</span>
<span class="c">#    deployment.apps/deathstar created</span>
<span class="c">#    pod/tiefighter created</span>
<span class="c">#    pod/xwing created</span>

<span class="c"># 파드 라벨 labels 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">--show-labels</span>
<span class="c"># =&gt; NAME                        READY   STATUS    RESTARTS   AGE   LABELS</span>
<span class="c">#    deathstar-8c4c77fb7-5zqmp   1/1     Running   0          12h   app.kubernetes.io/name=deathstar,class=deathstar,org=empire,pod-template-hash=8c4c77fb7</span>
<span class="c">#    deathstar-8c4c77fb7-h2rsh   1/1     Running   0          12h   app.kubernetes.io/name=deathstar,class=deathstar,org=empire,pod-template-hash=8c4c77fb7</span>
<span class="c">#    tiefighter                  1/1     Running   0          12h   app.kubernetes.io/name=tiefighter,class=tiefighter,org=empire</span>
<span class="c">#    xwing                       1/1     Running   0          12h   app.kubernetes.io/name=xwing,class=xwing,org=alliance</span>

<span class="nv">$ </span>kubectl get deploy,svc,ep deathstar
<span class="c"># =&gt; NAME                        READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/deathstar   2/2     2            2           12h</span>
<span class="c">#    </span>
<span class="c">#    NAME                TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE</span>
<span class="c">#    service/deathstar   ClusterIP   10.96.153.126   &lt;none&gt;        80/TCP    12h</span>
<span class="c">#    </span>
<span class="c">#    NAME                  ENDPOINTS                        AGE</span>
<span class="c">#    endpoints/deathstar   172.20.1.67:80,172.20.2.251:80   12h</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get ciliumendpoints.cilium.io <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE     NAME                           SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    default       deathstar-8c4c77fb7-5zqmp      46219               ready            172.20.2.251</span>
<span class="c">#    default       deathstar-8c4c77fb7-h2rsh      46219               ready            172.20.1.67</span>
<span class="c">#    default       tiefighter                     50993               ready            172.20.2.254</span>
<span class="c">#    default       xwing                          14847               ready            172.20.2.111</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-7m82r       30923               ready            172.20.0.134</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-dnc5n       30923               ready            172.20.1.13</span>
<span class="c">#    kube-system   hubble-relay-5dcd46f5c-n4zfx   5844                ready            172.20.2.144</span>
<span class="c">#    kube-system   hubble-ui-76d4965bb6-7mcft     14841               ready            172.20.1.30</span>
<span class="nv">$ </span>kubectl get ciliumidentities.cilium.io
<span class="c"># =&gt; NAME    NAMESPACE     AGE</span>
<span class="c">#    10901   default       12h</span>
<span class="c">#    14841   kube-system   37h</span>
<span class="c">#    14847   default       12h</span>
<span class="c">#    30923   kube-system   2d13h</span>
<span class="c">#    46219   default       12h</span>
<span class="c">#    50993   default       12h</span>
<span class="c">#    5844    kube-system   37h</span>

<span class="c"># in a multi-node installation, only the ones running on the same node will be listed</span>
<span class="c"># cilium 엔드포인트 목록 확인. 명령을 실행한 노드의 엔드포인트만 확인 가능합니다.</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium endpoint list
<span class="c"># =&gt; ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])                                                  IPv6   IPv4           STATUS</span>
<span class="c">#               ENFORCEMENT        ENFORCEMENT</span>
<span class="c">#    1332       Disabled           Disabled          1          k8s:node-role.kubernetes.io/control-plane                                                          ready</span>
<span class="c">#                                                               k8s:node.kubernetes.io/exclude-from-external-load-balancers</span>
<span class="c">#                                                               reserved:host</span>
<span class="c">#    1814       Disabled           Disabled          30923      k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=kube-system          172.20.0.134   ready</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.cluster=default</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.serviceaccount=coredns</span>
<span class="c">#                                                               k8s:io.kubernetes.pod.namespace=kube-system</span>
<span class="c">#                                                               k8s:k8s-app=kube-dns</span>
<span class="nv">$ </span>c0 endpoint list
<span class="c"># =&gt; ...</span>
<span class="c">#    1814 Disabled Disabled 30923 k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=kube-system 172.20.0.134   ready</span>
<span class="nv">$ </span>c1 endpoint list
<span class="c"># =&gt; ...</span>
<span class="c">#    507  Disabled Disabled 46219 k8s:app.kubernetes.io/name=deathstar                                       172.20.1.67   ready</span>
<span class="c">#    ...</span>
<span class="c">#    966  Disabled Disabled 30923 k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=kube-system 172.20.1.13   ready</span>
<span class="c">#    ...</span>
<span class="c">#    1864 Disabled Disabled 14841 k8s:app.kubernetes.io/name=hubble-ui                                       172.20.1.30   ready</span>
<span class="nv">$ </span>c2 endpoint list
<span class="c"># =&gt; ENDPOINT POLICY (ingress) POLICY (egress) IDENTITY LABELS (source:key[=value])                                                  IPv6   IPv4           STATUS</span>
<span class="c">#             ENFORCEMENT      ENFORCEMENT</span>
<span class="c">#    309      &lt;span style="color: green;"&gt;Disabled&lt;/span&gt;         &lt;span style="color: green;"&gt;Disabled&lt;/span&gt;        14847    k8s:app.kubernetes.io/name=xwing                                                    172.20.2.111   ready</span>
<span class="c">#    721      &lt;span style="color: green;"&gt;Disabled&lt;/span&gt;         &lt;span style="color: green;"&gt;Disabled&lt;/span&gt;        50993    k8s:app.kubernetes.io/name=tiefighter                                               172.20.2.254   ready</span>
<span class="c">#    1282     &lt;span style="color: green;"&gt;Disabled&lt;/span&gt;         &lt;span style="color: green;"&gt;Disabled&lt;/span&gt;        1        reserved:host                                                                                      ready</span>
<span class="c">#    1391     &lt;span style="color: green;"&gt;Disabled&lt;/span&gt;         &lt;span style="color: green;"&gt;Disabled&lt;/span&gt;        46219    k8s:app.kubernetes.io/name=deathstar                                                172.20.2.251   ready</span>
<span class="c">#                                                       &lt;span style="color: green;"&gt;k8s:class=deathstar&lt;/span&gt;</span>
<span class="c">#                                                       k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default</span>
<span class="c">#                                                       k8s:io.cilium.k8s.policy.cluster=default</span>
<span class="c">#                                                       k8s:io.cilium.k8s.policy.serviceaccount=default</span>
<span class="c">#                                                       k8s:io.kubernetes.pod.namespace=default</span>
<span class="c">#                                                       &lt;span style="color: green;"&gt;k8s:org=empire&lt;/span&gt;</span>
<span class="c">#    3027     &lt;span style="color: green;"&gt;Disabled&lt;/span&gt;         &lt;span style="color: green;"&gt;Disabled&lt;/span&gt;        5844     k8s:app.kubernetes.io/name=hubble-relay                                             172.20.2.144   ready</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 현재 ingress/egress 에 정책(Policy) 없음을 확인 할 수 있습니다. 또한 label을 통해 다양한 정보를 확인할 수 있습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<h4 id="현재-접근상태-확인">현재 접근상태 확인</h4>

<ul>
  <li>deathstar 서비스의 관점에서는 org=empire 라벨이 있는 우주선만 착륙을 요청할 수 있습니다.</li>
  <li>아직까지는 ingress/egress 정책이 없기 때문에 제국 우주선 뿐만 아니라 연합의 우주선 착륙 요청도 허용됩니다.</li>
  <li>아래의 명령을 통해 확인해보겠습니다</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 아래 출력에서 xwing 와 tiefighter 의 IDENTITY 값을 확인합니다.</span>
<span class="nv">$ </span>c1 endpoint list | <span class="nb">grep</span> <span class="nt">-iE</span> <span class="s1">'xwing|tiefighter|deathstar'</span>
<span class="c"># =&gt; 507        Disabled           Disabled          &lt;span style="color: green;"&gt;46219&lt;/span&gt;      k8s:app.kubernetes.io/name=deathstar                                                172.20.1.67   ready</span>
<span class="nv">$ </span>c2 endpoint list | <span class="nb">grep</span> <span class="nt">-iE</span> <span class="s1">'xwing|tiefighter|deathstar'</span>
<span class="c"># =&gt; 309        Disabled           Disabled          &lt;span style="color: green;"&gt;14847&lt;/span&gt;      k8s:app.kubernetes.io/name=xwing                                                    172.20.2.111   ready</span>
<span class="c">#    721        Disabled           Disabled          &lt;span style="color: green;"&gt;50993&lt;/span&gt;      k8s:app.kubernetes.io/name=tiefighter                                               172.20.2.254   ready</span>
<span class="c">#    1391       Disabled           Disabled          &lt;span style="color: green;"&gt;46219&lt;/span&gt;      k8s:app.kubernetes.io/name=deathstar                                                172.20.2.251   ready</span>
<span class="nv">$ XWINGID</span><span class="o">=</span>14847
<span class="nv">$ TIEFIGHTERID</span><span class="o">=</span>50993
<span class="nv">$ DEATHSTARID</span><span class="o">=</span>46219

<span class="c"># 모니터링 준비 : 터미널 3개, 단축키 설정</span>
<span class="c">## 각각 monitor 확인</span>
<span class="nv">$ </span>c0 monitor <span class="nt">-v</span> <span class="nt">-v</span>
<span class="nv">$ </span>c1 monitor <span class="nt">-v</span> <span class="nt">-v</span>
<span class="nv">$ </span>c2 monitor <span class="nt">-v</span> <span class="nt">-v</span>

<span class="c"># 모니터링 준비 : 터미널 1개</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span>

<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--from-identity</span> <span class="nv">$XWINGID</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--protocol</span> udp <span class="nt">--from-identity</span> <span class="nv">$XWINGID</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--protocol</span> tcp <span class="nt">--from-identity</span> <span class="nv">$XWINGID</span>

<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--protocol</span> tcp <span class="nt">--from-identity</span> <span class="nv">$DEATHSTARID</span>

<span class="c"># 호출 시도 1</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>xwing <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPOST</span> deathstar.default.svc.cluster.local/v1/request-landing
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>kubectl <span class="nb">exec </span>xwing <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPOST</span> deathstar.default.svc.cluster.local/v1/request-landing <span class="p">;</span> <span class="nb">sleep </span>5 <span class="p">;</span> <span class="k">done</span>

<span class="c"># 호출 시도 2</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>tiefighter <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPOST</span> deathstar.default.svc.cluster.local/v1/request-landing
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>kubectl <span class="nb">exec </span>tiefighter <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPOST</span> deathstar.default.svc.cluster.local/v1/request-landing <span class="p">;</span> <span class="nb">sleep </span>5 <span class="p">;</span> <span class="k">done</span>

<span class="c">## 모니터링</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--protocol</span> tcp <span class="nt">--from-identity</span> <span class="nv">$TIEFIGHTERID</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--protocol</span> tcp <span class="nt">--from-identity</span> <span class="nv">$DEATHSTARID</span>
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w2/20250727_cilium_w2_5.png" alt="img.png" class="image-center" />
<em class="image-caption">Hubble UI에서 모니터링</em></p>

<p><img src="/assets/2025/cilium/w2/20250727_cilium_w2_6.png" alt="img.png" class="image-center" />
<em class="image-caption">hubble observe에서 모니터링</em></p>

<ul>
  <li>제국군 우주선 tiefighter 뿐만아니라 연합군 우주선 xwing의 착륙 요청도 허용되고 있는것을 확인할 수 있습니다.</li>
</ul>

<h4 id="l3l4-정책-적용">L3/L4 정책 적용</h4>

<ul>
  <li><a href="https://docs.cilium.io/en/stable/gettingstarted/demo/#apply-an-l3-l4-policy">관련문서</a></li>
  <li>L3/L4 정책을 적용하여 제국 우주선만 착륙 요청을 허용하도록 합니다.</li>
</ul>

<p><img src="/assets/2025/cilium/w2/20250727_cilium_w2_7.png" alt="img.png" class="image-center" />
<em class="image-caption">L3/L4 정책 적용 후 목표 상태</em></p>

<ul>
  <li>Cilium의 보안정책은 <strong>Endpoint의 IP주소는 중요하지 않고</strong>, Pod의 <strong>label을 사용하여 보안 정책을 정의</strong>할 수 있습니다.</li>
  <li>아래의 정책을 적용하여 제국 우주선만 착륙 요청을 허용하도록 합니다. 이렇게하면 org=empire 라벨이 있는 Pod만 착륙 요청을 허용하게 되고,
해당 라벨이 없는 파드는 deathstar 서비스에 연결조차 할 수 없습니다. 이 정책은 IP 프로토콜(네트워크 계층 3)와 TCP 프로토콜(전송 계층 4)에만 적용하는
L3/L4 네트워크 보안 정책이라고 합니다.</li>
  <li>참고 : Cilium은 <strong>상태별 연결 추적</strong>을 수행합니다. 
즉, 프론트엔드가 백엔드에 도달할 수 있으면, 동일한 TCP/UDP 연결내의 응답은 자동으로 허용된다는것을 의미합니다.</li>
</ul>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># CiliumNetworkPolicy</span>
<span class="c1">## CiliumNetworkPolicys는 "endpointSelector"를 사용하여 팟 레이블에서 정책이 적용되는 소스와 목적지를 식별합니다. </span>
<span class="c1">## 아래 정책은 TCP 포트 80에서 레이블(org=empire)이 있는 모든 팟에서 레이블(org=empire, class=deathstar)이 있는 데스스타 팟으로 전송되는 트래픽을 화이트리스트로 작성합니다.</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s2">"</span><span class="s">cilium.io/v2"</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">CiliumNetworkPolicy</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s2">"</span><span class="s">rule1"</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">description</span><span class="pi">:</span> <span class="s2">"</span><span class="s">L3-L4</span><span class="nv"> </span><span class="s">policy</span><span class="nv"> </span><span class="s">to</span><span class="nv"> </span><span class="s">restrict</span><span class="nv"> </span><span class="s">deathstar</span><span class="nv"> </span><span class="s">access</span><span class="nv"> </span><span class="s">to</span><span class="nv"> </span><span class="s">empire</span><span class="nv"> </span><span class="s">ships</span><span class="nv"> </span><span class="s">only"</span>
  <span class="na">endpointSelector</span><span class="pi">:</span>
    <span class="na">matchLabels</span><span class="pi">:</span>
      <span class="na">org</span><span class="pi">:</span> <span class="s">empire</span>
      <span class="na">class</span><span class="pi">:</span> <span class="s">deathstar</span>
  <span class="na">ingress</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">fromEndpoints</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">matchLabels</span><span class="pi">:</span>
        <span class="na">org</span><span class="pi">:</span> <span class="s">empire</span>
    <span class="na">toPorts</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">port</span><span class="pi">:</span> <span class="s2">"</span><span class="s">80"</span>
        <span class="na">protocol</span><span class="pi">:</span> <span class="s">TCP</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/minikube/sw_l3_l4_policy.yaml
<span class="c"># =&gt; ciliumnetworkpolicy.cilium.io/rule1 created</span>
<span class="nv">$ </span>kubectl get cnp
<span class="c"># =&gt; NAME    AGE   VALID</span>
<span class="c">#    rule1   8s    True</span>
<span class="nv">$ </span>kubectl get cnp <span class="nt">-o</span> json | jq
<span class="c"># =&gt; ...</span>
<span class="c">#          "spec": {</span>
<span class="c">#            "description": "L3-L4 policy to restrict deathstar access to empire ships only",</span>
<span class="c">#            "endpointSelector": {</span>
<span class="c">#              "matchLabels": {</span>
<span class="c">#                "class": "deathstar",</span>
<span class="c">#                "org": "empire"</span>
<span class="c">#              }</span>
<span class="c">#            },</span>
<span class="c">#            "ingress": [ { </span>
<span class="c">#                 "fromEndpoints": [ { "matchLabels": { "org": "empire" } } ],</span>
<span class="c">#                 "toPorts": [ { "ports": [ { "port": "80", "protocol": "TCP" } ] } ]</span>
<span class="c">#            } ]</span>
<span class="c">#          },</span>
<span class="c">#    ...</span>

<span class="c"># 모니터링</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--type</span> drop

<span class="c"># 호출 시도 1 </span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>xwing <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPOST</span> deathstar.default.svc.cluster.local/v1/request-landing <span class="nt">--connect-timeout</span> 2
<span class="c"># =&gt; command terminated with exit code 28</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 연합군의 우주선 xwing의 착륙 요청은 거부되었습니다!&lt;/span&gt;</span>

<span class="c"># &lt;span style="color: green;"&gt;👉 DROP 된 패킷 모니터링&lt;/span&gt;</span>
<span class="c"># =&gt; (⎈|HomeLab:N/A) root@k8s-ctr:~# hubble observe -f --type drop</span>
<span class="c">#    Jul 26 07:50:53.384: default/xwing:46590 (ID:14847) &lt;&gt; default/deathstar-8c4c77fb7-h2rsh:80 (ID:46219) Policy denied DROPPED (TCP Flags: SYN)</span>
<span class="c">#    Jul 26 07:50:54.407: default/xwing:46590 (ID:14847) &lt;&gt; default/deathstar-8c4c77fb7-h2rsh:80 (ID:46219) Policy denied DROPPED (TCP Flags: SYN)</span>

<span class="c"># 모니터링 </span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--protocol</span> tcp <span class="nt">--from-identity</span> <span class="nv">$DEATHSTARID</span>

<span class="c"># 호출 시도 2</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>tiefighter <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPOST</span> deathstar.default.svc.cluster.local/v1/request-landing
<span class="c"># =&gt; Ship landed</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 제국군의 우주선 tiefighter의 착륙 요청은 허용되었습니다!&lt;/span&gt;</span>

<span class="c"># &lt;span style="color: green;"&gt;👉 허용된 패킷 모니터링&lt;/span&gt;</span>
<span class="c"># =&gt; (⎈|HomeLab:N/A) root@k8s-ctr:~# hubble observe -f --protocol tcp --from-identity $DEATHSTARID</span>
<span class="c">#    Jul 26 07:52:52.016: default/tiefighter:43410 (ID:50993) &lt;- default/deathstar-8c4c77fb7-5zqmp:80 (ID:46219) to-endpoint FORWARDED (TCP Flags: SYN, ACK)</span>
<span class="c">#    Jul 26 07:52:52.016: default/deathstar-8c4c77fb7-5zqmp:80 (ID:46219) &lt;&gt; default/tiefighter (ID:50993) pre-xlate-rev TRACED (TCP)</span>
<span class="c">#    Jul 26 07:52:52.016: default/deathstar-8c4c77fb7-5zqmp:80 (ID:46219) &lt;&gt; default/tiefighter (ID:50993) pre-xlate-rev TRACED (TCP)</span>
<span class="c">#    Jul 26 07:52:52.019: default/tiefighter:43410 (ID:50993) &lt;- default/deathstar-8c4c77fb7-5zqmp:80 (ID:46219) to-endpoint FORWARDED (TCP Flags: ACK, PSH)</span>
<span class="c">#    Jul 26 07:52:52.021: default/tiefighter:43410 (ID:50993) &lt;- default/deathstar-8c4c77fb7-5zqmp:80 (ID:46219) to-endpoint FORWARDED (TCP Flags: ACK, FIN)</span>
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w2/20250727_cilium_w2_8.png" alt="img.png" /></p>

<ul>
  <li>정책을 확인해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># deathstar 에 ingress 에 policy 활성화 확인</span>
<span class="nv">$ </span>c0 endpoint list
<span class="nv">$ </span>c1 endpoint list
<span class="c"># =&gt; ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])                                                  IPv6   IPv4          STATUS</span>
<span class="c">#               ENFORCEMENT        ENFORCEMENT</span>
<span class="c">#    ...</span>
<span class="c">#    507        &lt;span style="color: green;"&gt;Enabled&lt;/span&gt;            Disabled          46219      k8s:app.kubernetes.io/name=deathstar                                                172.20.1.67   ready</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>c2 endpoint list
<span class="c"># =&gt; ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])                                                  IPv6   IPv4           STATUS</span>
<span class="c">#               ENFORCEMENT        ENFORCEMENT</span>
<span class="c">#    ...</span>
<span class="c">#    1391       &lt;span style="color: green;"&gt;Enabled&lt;/span&gt;            Disabled          46219      k8s:app.kubernetes.io/name=deathstar                                                172.20.2.251   ready</span>
<span class="c">#    ...</span>
                                                           
<span class="nv">$ </span>kc describe cnp rule1
<span class="c"># =&gt; ...</span>
<span class="c">#    Spec:</span>
<span class="c">#      Description:  L3-L4 policy to restrict deathstar access to empire ships only</span>
<span class="c">#      Endpoint Selector:</span>
<span class="c">#        Match Labels:</span>
<span class="c">#          Class:  deathstar</span>
<span class="c">#          Org:    empire</span>
<span class="c">#      Ingress:</span>
<span class="c">#        From Endpoints:</span>
<span class="c">#          Match Labels:</span>
<span class="c">#            Org:  empire</span>
<span class="c">#        To Ports:</span>
<span class="c">#          Ports:</span>
<span class="c">#            Port:      80</span>
<span class="c">#            Protocol:  TCP</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<ul>
  <li>Life of a Packet : L7 동작 처리는 cilium-envoy 데몬셋이 담당합니다. <a href="https://docs.cilium.io/en/stable/network/ebpf/lifeofapacket/">Docs</a></li>
</ul>

<p><img src="/assets/2025/cilium/w2/20250727_cilium_w2_9.png" alt="img.png" /></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>kubectl get ds <span class="nt">-n</span> kube-system
<span class="c"># =&gt; NAME           DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE</span>
<span class="c">#    cilium         3         3         3       3            3           kubernetes.io/os=linux   2d17h</span>
<span class="c">#    cilium-envoy   3         3         3       3            3           kubernetes.io/os=linux   2d17h</span>

<span class="nv">$ </span>kubectl get pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium-envoy <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                 READY   STATUS    RESTARTS        AGE     IP               NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    cilium-envoy-q97fq   1/1     Running   3 (3h59m ago)   2d16h   192.168.10.102   k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    cilium-envoy-xzxd6   1/1     Running   3 (3h59m ago)   2d16h   192.168.10.101   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    cilium-envoy-zzzw5   1/1     Running   3 (3h59m ago)   2d17h   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>

<span class="c">#</span>
<span class="nv">$ </span>kc describe ds <span class="nt">-n</span> kube-system cilium-envoy
<span class="c"># =&gt;     Mounts:</span>
<span class="c">#          /sys/fs/bpf from bpf-maps (rw)</span>
<span class="c">#          /var/run/cilium/envoy/ from envoy-config (ro)</span>
<span class="c">#          /var/run/cilium/envoy/artifacts from envoy-artifacts (ro)</span>
<span class="c">#          &lt;span style="color: green;"&gt;/var/run/cilium/envoy/sockets from envoy-sockets (rw)&lt;/span&gt;</span>
<span class="c">#    ...</span>
<span class="c">#       envoy-config:</span>
<span class="c">#        Type:      ConfigMap (a volume populated by a ConfigMap)</span>
<span class="c">#        Name:      &lt;span style="color: green;"&gt;cilium-envoy-config&lt;/span&gt;</span>
<span class="c">#        Optional:  false</span>
<span class="c">#    ...</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> ss <span class="nt">-xnp</span> | <span class="nb">grep</span> <span class="nt">-i</span> <span class="nt">-envoy</span>
<span class="c"># =&gt; u_str  ESTAB  0  0  /var/run/cilium/envoy/sockets/admin.sock  16193  *  16192</span>
<span class="c">#    u_str  ESTAB  0  0  /var/run/cilium/envoy/sockets/admin.sock  17068  *  17067</span>
<span class="c">#    u_str  ESTAB  0  0  /var/run/cilium/envoy/sockets/xds.sock    15993  *  15992  users:(("cilium-agent",pid=1,fd=106))</span>

<span class="nv">$ </span>kc describe cm <span class="nt">-n</span> kube-system cilium-envoy-config
<span class="c"># =&gt; ...</span>
<span class="c">#    Data</span>
<span class="c">#    ====</span>
<span class="c">#    bootstrap-config.json:</span>
<span class="c">#    ----</span>
<span class="c">#    {"admin":{"address":{"pipe":{"path":"/var/run/cilium/envoy/sockets/admin.sock"}}}...</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<h4 id="http-aware-l7-정책-적용-및-테스트">HTTP-aware L7 정책 적용 및 테스트</h4>

<ul>
  <li>HTTP-aware L7 정책을 적용하고 테스트해보겠습니다. <a href="https://docs.cilium.io/en/stable/gettingstarted/demo/#apply-and-test-http-aware-l7-policy">Docs</a></li>
</ul>

<p><img src="/assets/2025/cilium/w2/20250727_cilium_w2_10.png" alt="img.png" class="image-center" /></p>

<ul>
  <li>이전의 간단한 시나리오에서는 tiefighter와 xwing에게 deathstar API에 대한 전체 액세스 권한을 부여하거나, 접속 자체를 차단하는것으로 충분햇습니다.</li>
  <li>하지만 마이크로 서비스 간의 강력한 보안(즉, 최소 권한 격리를 강제하는 것)을 제공하기 위해서는 deathstar API를 호출하는 각 서비스가 운영에 필요한 HTTP 요청만 수행하도록 제한 할 수 있어야 합니다.</li>
  <li>예를 들어 deathstar 서비스가 임의의 제국 우주선이 호출해서는 안 되는 유지보수 API를 제공한다고 가정해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 모니터링 &gt;&gt; Layer3/4 에서는 애플리케이션 상태를 확인 할 수 없음!</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--protocol</span> tcp <span class="nt">--from-identity</span> <span class="nv">$DEATHSTARID</span>
<span class="c"># =&gt; Jul 26 08:29:39.157: default/tiefighter:48472 (ID:50993) &lt;- default/deathstar-8c4c77fb7-h2rsh:80 (ID:46219) to-network FORWARDED (TCP Flags: SYN, ACK)</span>
<span class="c">#    Jul 26 08:29:39.161: default/tiefighter:48472 (ID:50993) &lt;- default/deathstar-8c4c77fb7-h2rsh:80 (ID:46219) to-network FORWARDED (TCP Flags: ACK, PSH)</span>
<span class="c">#    Jul 26 08:29:39.164: default/tiefighter:48472 (ID:50993) &lt;- default/deathstar-8c4c77fb7-h2rsh:80 (ID:46219) to-network FORWARDED (TCP Flags: ACK, FIN)</span>
<span class="c">#    Jul 26 08:29:39.201: default/tiefighter:48472 (ID:50993) &lt;- default/deathstar-8c4c77fb7-h2rsh:80 (ID:46219) to-endpoint FORWARDED (TCP Flags: SYN, ACK)</span>
<span class="c">#    Jul 26 08:29:39.201: default/deathstar-8c4c77fb7-h2rsh:80 (ID:46219) &lt;&gt; default/tiefighter (ID:50993) pre-xlate-rev TRACED (TCP)</span>
<span class="c">#    Jul 26 08:29:39.201: default/deathstar-8c4c77fb7-h2rsh:80 (ID:46219) &lt;&gt; default/tiefighter (ID:50993) pre-xlate-rev TRACED (TCP)</span>
<span class="c">#    Jul 26 08:29:39.205: default/tiefighter:48472 (ID:50993) &lt;- default/deathstar-8c4c77fb7-h2rsh:80 (ID:46219) to-endpoint FORWARDED (TCP Flags: ACK, PSH)</span>
<span class="c">#    Jul 26 08:29:39.207: default/tiefighter:48472 (ID:50993) &lt;- default/deathstar-8c4c77fb7-h2rsh:80 (ID:46219) to-endpoint FORWARDED (TCP Flags: ACK, FIN)</span>

<span class="c"># 호출해서는 안 되는 일부 유지보수 API를 노출</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>tiefighter <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPUT</span> deathstar.default.svc.cluster.local/v1/exhaust-port
<span class="c"># =&gt; Panic: deathstar exploded</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 임의로 호출해서는 안되는 API가 실행되어 deathstar가 폭발했습니다!&lt;/span&gt;</span>
</code></pre></div></div>

<h5 id="cilium을-통한-l7-정책-적용">cilium을 통한 L7 정책 적용</h5>

<ul>
  <li>cilium은 HTTP 계층(L7) 정책을 적용하여 tiefighter가 사용할 수 있는 API URL을 제한할 수 있습니다. 다음은 tiefighter가 POST /v1/request-landing URL에만 액세스할 수 있도록 하는 정책입니다.</li>
</ul>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 기존 rule1 정책을 업데이트 해서 사용</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s2">"</span><span class="s">cilium.io/v2"</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">CiliumNetworkPolicy</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s2">"</span><span class="s">rule1"</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">description</span><span class="pi">:</span> <span class="s2">"</span><span class="s">L7</span><span class="nv"> </span><span class="s">policy</span><span class="nv"> </span><span class="s">to</span><span class="nv"> </span><span class="s">restrict</span><span class="nv"> </span><span class="s">access</span><span class="nv"> </span><span class="s">to</span><span class="nv"> </span><span class="s">specific</span><span class="nv"> </span><span class="s">HTTP</span><span class="nv"> </span><span class="s">call"</span>
  <span class="na">endpointSelector</span><span class="pi">:</span>
    <span class="na">matchLabels</span><span class="pi">:</span>
      <span class="na">org</span><span class="pi">:</span> <span class="s">empire</span>
      <span class="na">class</span><span class="pi">:</span> <span class="s">deathstar</span>
  <span class="na">ingress</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">fromEndpoints</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">matchLabels</span><span class="pi">:</span>
        <span class="na">org</span><span class="pi">:</span> <span class="s">empire</span>
    <span class="na">toPorts</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">port</span><span class="pi">:</span> <span class="s2">"</span><span class="s">80"</span>
        <span class="na">protocol</span><span class="pi">:</span> <span class="s">TCP</span>
      <span class="na">rules</span><span class="pi">:</span>
        <span class="na">http</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">method</span><span class="pi">:</span> <span class="s2">"</span><span class="s">POST"</span>
          <span class="na">path</span><span class="pi">:</span> <span class="s2">"</span><span class="s">/v1/request-landing"</span>
</code></pre></div></div>

<ul>
  <li>tiefigher 에는 착륙 요청만 허용하는 L7 정책 적용후 deathstar 서비스에 착륙 요청을 해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Update the existing rule to apply L7-aware policy to protect deathstar using:</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/minikube/sw_l3_l4_l7_policy.yaml
<span class="c"># =&gt; ciliumnetworkpolicy.cilium.io/rule1 configured</span>
<span class="nv">$ </span>kubectl get cnp
<span class="c"># =&gt; NAME    AGE    VALID</span>
<span class="c">#    rule1   168m   True</span>
<span class="nv">$ </span>kc describe cnp
<span class="c"># =&gt; ...</span>
<span class="c">#    Spec:</span>
<span class="c">#      Description:  L7 policy to restrict access to specific HTTP call</span>
<span class="c">#      Endpoint Selector:</span>
<span class="c">#        Match Labels:</span>
<span class="c">#          Class:  deathstar</span>
<span class="c">#          Org:    empire</span>
<span class="c">#      Ingress:</span>
<span class="c">#        From Endpoints:</span>
<span class="c">#          Match Labels:</span>
<span class="c">#            Org:  empire</span>
<span class="c">#        To Ports:</span>
<span class="c">#          Ports:</span>
<span class="c">#            Port:      80</span>
<span class="c">#            Protocol:  TCP</span>
<span class="c">#          Rules:</span>
<span class="c">#            Http:</span>
<span class="c">#              Method:  POST</span>
<span class="c">#              Path:    /v1/request-landing</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>c0 policy get

<span class="c"># 파드 이름 지정하여 모니터링</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--pod</span> deathstar <span class="nt">--protocol</span> http
Jul 20 01:28:02.184: default/tiefighter:59020 <span class="o">(</span>ID:19274<span class="o">)</span> -&gt; default/deathstar-8c4c77fb7-9klws:80 <span class="o">(</span>ID:318<span class="o">)</span> http-request FORWARDED <span class="o">(</span>HTTP/1.1 POST http://deathstar.default.svc.cluster.local/v1/request-landing<span class="o">)</span>
Jul 20 01:28:02.190: default/tiefighter:59020 <span class="o">(</span>ID:19274<span class="o">)</span> &lt;- default/deathstar-8c4c77fb7-9klws:80 <span class="o">(</span>ID:318<span class="o">)</span> http-response FORWARDED <span class="o">(</span>HTTP/1.1 200 6ms <span class="o">(</span>POST http://deathstar.default.svc.cluster.local/v1/request-landing<span class="o">))</span>

<span class="c"># 착륙 요청을 테스트해보겠습니다.</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>tiefighter <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPOST</span> deathstar.default.svc.cluster.local/v1/request-landing
<span class="c"># =&gt; Ship landed</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 당연히 API 호출에 성공합니다.&lt;/span&gt;</span>
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w2/20250727_cilium_w2_11.png" alt="img.png" /></p>

<ul>
  <li>이번에는 tiefighter가 허용되지 않은 API를 호출해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 파드 이름 지정하여 드랍된 패킷 모니터링</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--pod</span> deathstar <span class="nt">--verdict</span> DROPPED
<span class="c"># =&gt; Jul 26 10:48:17.734: default/tiefighter:40606 (ID:50993) -&gt; default/deathstar-8c4c77fb7-h2rsh:80 (ID:46219) http-request DROPPED (HTTP/1.1 PUT http://deathstar.default.svc.cluster.local/v1/exhaust-port)</span>

<span class="c"># 혹은</span>
<span class="nv">$ </span>c1 monitor <span class="nt">-v</span> <span class="nt">--type</span> l7
<span class="nv">$ </span>c2 monitor <span class="nt">-v</span> <span class="nt">--type</span> l7
<span class="c"># =&gt; &lt;- Request http from 721 ([k8s:app.kubernetes.io/name=tiefighter k8s:class=tiefighter k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default k8s:io.cilium.k8s.policy.cluster=default k8s:io.cilium.k8s.policy.serviceaccount=default k8s:io.kubernetes.pod.namespace=default k8s:org=empire]) to 1391 ([k8s:app.kubernetes.io/name=deathstar k8s:class=deathstar k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default k8s:io.cilium.k8s.policy.cluster=default k8s:io.cilium.k8s.policy.serviceaccount=default k8s:io.kubernetes.pod.namespace=default k8s:org=empire]), identity 50993-&gt;46219, verdict Denied PUT http://deathstar.default.svc.cluster.local/v1/exhaust-port =&gt; 0</span>
<span class="c">#    &lt;- Response http to 721 ([k8s:app.kubernetes.io/name=tiefighter k8s:class=tiefighter k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default k8s:io.cilium.k8s.policy.cluster=default k8s:io.cilium.k8s.policy.serviceaccount=default k8s:io.kubernetes.pod.namespace=default k8s:org=empire]) from 1391 ([k8s:app.kubernetes.io/name=deathstar k8s:class=deathstar k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default k8s:io.cilium.k8s.policy.cluster=default k8s:io.cilium.k8s.policy.serviceaccount=default k8s:io.kubernetes.pod.namespace=default k8s:org=empire]), identity 46219-&gt;50993, verdict Forwarded PUT http://deathstar.default.svc.cluster.local/v1/exhaust-port =&gt; 403</span>

<span class="c"># 앞서 deathstar를 폭파시켰던 tiefighter에게 허용되지 않은 API를 호출해보겠습니다.</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>tiefighter <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPUT</span> deathstar.default.svc.cluster.local/v1/exhaust-port
<span class="c"># =&gt; Access denied</span>
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w2/20250727_cilium_w2_12.png" alt="img.png" class="image-center" />
<em class="image-caption">L7 정책에 의해 허용되지 않은 API 호출이 거부된 모습</em></p>

<ul>
  <li>xwing으로 착륙요청을 해서 위와 차이점을 확인해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 모니터링 : 파드 이름 지정</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">--pod</span> xwing

<span class="c"># 호출 시도 : 위와 아래 실행 종료의 차이점을 이해해보자!</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>xwing <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPOST</span> deathstar.default.svc.cluster.local/v1/request-landing <span class="nt">--connect-timeout</span> 2
<span class="c"># =&gt; command terminated with exit code 28</span>

<span class="c"># (⎈|HomeLab:N/A) root@k8s-ctr:~# hubble observe -f --pod xwing</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    Jul 26 10:50:31.048: default/xwing:57832 (ID:14847) -&gt; default/deathstar-8c4c77fb7-h2rsh:80 (ID:46219) to-network FORWARDED (TCP Flags: SYN)</span>
<span class="c">#    Jul 26 10:50:31.049: default/xwing:57832 (ID:14847) &lt;&gt; default/deathstar-8c4c77fb7-h2rsh:80 (ID:46219) policy-verdict:none INGRESS DENIED (TCP Flags: SYN)</span>
<span class="c">#    Jul 26 10:50:31.049: default/xwing:57832 (ID:14847) &lt;&gt; default/deathstar-8c4c77fb7-h2rsh:80 (ID:46219) Policy denied DROPPED (TCP Flags: SYN)</span>
<span class="c">#    ...</span>
<span class="c">#    Jul 26 10:50:32.053: default/xwing:57832 (ID:14847) &lt;&gt; default/deathstar-8c4c77fb7-h2rsh:80 (ID:46219) policy-verdict:none INGRESS DENIED (TCP Flags: SYN)</span>
<span class="c">#    Jul 26 10:50:32.053: default/xwing:57832 (ID:14847) &lt;&gt; default/deathstar-8c4c77fb7-h2rsh:80 (ID:46219) Policy denied DROPPED (TCP Flags: SYN)</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 xwing의 deathstar로의 접근은 TCP (L4) 연결 자체가 차단(DROP)됨을 확인할 수 있습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w2/20250727_cilium_w2_13.png" alt="img.png" class="image-center" />
<em class="image-caption">xwing이 L7 정책 이전에 L4 정책에 의해 deathstar로의 접근이 차단된 모습</em></p>

<ul>
  <li>다음 실습을 위해 리소스를 삭제하겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 다음 실습을 위해 리소스 삭제</span>
<span class="nv">$ </span>kubectl delete <span class="nt">-f</span> https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/minikube/http-sw-app.yaml
<span class="c"># =&gt; service "deathstar" deleted</span>
<span class="c">#    deployment.apps "deathstar" deleted</span>
<span class="c">#    pod "tiefighter" deleted</span>
<span class="c">#    pod "xwing" deleted</span>
<span class="nv">$ </span>kubectl delete cnp rule1
<span class="c"># =&gt; ciliumnetworkpolicy.cilium.io "rule1" deleted</span>

<span class="c"># 삭제 확인</span>
<span class="nv">$ </span>kubectl get cnp
<span class="c"># =&gt; No resources found in default namespace.</span>
</code></pre></div></div>

<h4 id="configuring-hubble-exporter">Configuring Hubble Exporter</h4>

<ul>
  <li>흐름 로그 - <a href="https://docs.cilium.io/en/stable/observability/hubble/configuration/export/">Docs</a></li>
  <li>Hubble Exporter는 나중에 사용할 수 있도록 Hubble flows 로그를 파일에 저장하는 cilium-agent의 기능입니다.</li>
  <li>Hubble Exporter는 file rotation, size limits, filters, field masks를 지원합니다.</li>
  <li>Hubble Exporter는 다음과 같이 설정합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># &lt;span style="color: green;"&gt;👉 이미 cilium 설치할때 적용되어서 실습 과정에는 적용할 필요가 없습니다.&lt;/span&gt;</span>
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--namespace</span> kube-system <span class="nt">--reuse-values</span> <span class="se">\</span>
   <span class="nt">--set</span> hubble.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
   <span class="nt">--set</span> hubble.export.static.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
   <span class="nt">--set</span> hubble.export.static.filePath<span class="o">=</span>/var/run/cilium/hubble/events.log

<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system rollout status ds/cilium
</code></pre></div></div>

<ul>
  <li>Hubble Exporter의 설정을 확인해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get cm <span class="nt">-n</span> kube-system cilium-config <span class="nt">-o</span> json | <span class="nb">grep </span>hubble-export
<span class="nv">$ </span>cilium config view | <span class="nb">grep </span>hubble-export
<span class="c"># =&gt; hubble-export-allowlist</span>
<span class="c">#    hubble-export-denylist</span>
<span class="c">#    hubble-export-fieldmask</span>
<span class="c">#    hubble-export-file-max-backups   5     # rotate된 Hubble export 파일을 유지할 수 있는 최대 개수. (기본값: 5)</span>
<span class="c">#    hubble-export-file-max-size-mb   10    # Hubble export 파일을 rotate할 때의 크기(MB). (기본값: 10)</span>
<span class="c">#    hubble-export-file-path          /var/run/cilium/hubble/events.log   # 대상 로그 파일의 경로. (기본값: /var/run/cilium/hubble/events.log)</span>

<span class="c"># Verify that flow logs are stored in target files</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system <span class="nb">exec </span>ds/cilium <span class="nt">--</span> <span class="nb">tail</span> <span class="nt">-f</span> /var/run/cilium/hubble/events.log
<span class="c"># &lt;span style="color: green;"&gt;👉 로그가 계속 나옵니다.&lt;/span&gt;</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system <span class="nb">exec </span>ds/cilium <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'tail -f /var/run/cilium/hubble/events.log'</span> | jq
<span class="c"># &lt;span style="color: green;"&gt;👉 로그가 json 형태로 계속 나옵니다.&lt;/span&gt;</span>
</code></pre></div></div>

<h2 id="prometheus와-grafana를-통한-모니터링">Prometheus와 Grafana를 통한 모니터링</h2>

<ul>
  <li>Prometheus와 Grafana를 통해 Cilium의 모니터링을 할 수 있습니다. <a href="https://docs.cilium.io/en/stable/observability/grafana/">Docs</a></li>
  <li>널리 알려진 툴들이라 다들 아시겠지만 간략하게 소개해 보겠습니다.
    <ul>
      <li><strong>Prometheus</strong> : 오픈 소스 모니터링 시스템으로, 시계열 데이터베이스를 사용하여 메트릭을 수집하고 저장합니다. 일종의 TSDB(Time Series Database)로, 메트릭을 수집하고 쿼리할 수 있는 강력한 기능을 제공합니다.</li>
      <li><strong>Grafana</strong> : 시각화 도구로, Prometheus와 같은 데이터 소스에서 수집된 메트릭을 대시보드 형태로 시각화할 수 있습니다. 다양한 플러그인을 통해 다양한 데이터 소스를 지원합니다.</li>
    </ul>
  </li>
  <li>추천글
    <ul>
      <li>악분님 프로메테우스 오퍼레이터 소개 - <a href="https://malwareanalysis.tistory.com/566">Blog</a></li>
      <li>hanhorang님 타노스 소개 - <a href="https://hanhorang31.github.io/post/pkos2-4-monitoring/">Blog</a></li>
      <li>[AWS EC2] 프로메테우스 직접 설치 - <a href="https://prometheus.io/docs/prometheus/latest/getting_started/">Docs</a></li>
    </ul>
  </li>
</ul>

<h3 id="샘플-애플리케이션-배포-및-확인">샘플 애플리케이션 배포 및 확인</h3>

<ul>
  <li>Prometheus와 Grafana를 설치하기 전에 샘플 애플리케이션을 배포하고, Cilium의 모니터링을 확인해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 샘플 애플리케이션 배포</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webpod
spec:
  replicas: 2
  selector:
    matchLabels:
      app: webpod
  template:
    metadata:
      labels:
        app: webpod
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - sample-app
            topologyKey: "kubernetes.io/hostname"
      containers:
      - name: webpod
        image: traefik/whoami
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: webpod
  labels:
    app: webpod
spec:
  selector:
    app: webpod
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
  type: ClusterIP
</span><span class="no">EOF

</span><span class="c"># k8s-ctr 노드에 curl-pod 파드 배포</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: curl-pod
  labels:
    app: curl
spec:
  nodeName: k8s-ctr
  containers:
  - name: curl
    image: nicolaka/netshoot
    command: ["tail"]
    args: ["-f", "/dev/null"]
  terminationGracePeriodSeconds: 0
</span><span class="no">EOF
</span></code></pre></div></div>

<ul>
  <li>샘플 애플리케이션이 배포되었는지 확인해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 배포 확인</span>
<span class="nv">$ </span>kubectl get deploy,svc,ep webpod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                     READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES           SELECTOR</span>
<span class="c">#    deployment.apps/webpod   2/2     2            2           41s   webpod       traefik/whoami   app=webpod</span>
<span class="c">#    </span>
<span class="c">#    NAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE   SELECTOR</span>
<span class="c">#    service/webpod   ClusterIP   10.96.147.79   &lt;none&gt;        80/TCP    41s   app=webpod</span>
<span class="c">#    </span>
<span class="c">#    NAME               ENDPOINTS                       AGE</span>
<span class="c">#    endpoints/webpod   172.20.1.4:80,172.20.2.101:80   41s</span>
<span class="nv">$ </span>kubectl get endpointslices <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>webpod
<span class="c"># =&gt; NAME           ADDRESSTYPE   PORTS   ENDPOINTS                 AGE</span>
<span class="c">#    webpod-g9ldp   IPv4          80      172.20.1.4,172.20.2.101   49s</span>
<span class="nv">$ </span>kubectl get ciliumendpoints
<span class="c"># =&gt; NAME                      SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    curl-pod                  472                 ready            172.20.0.43</span>
<span class="c">#    webpod-697b545f57-mvz92   18655               ready            172.20.2.101</span>
<span class="c">#    webpod-697b545f57-ns4sw   18655               ready            172.20.1.4</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium-dbg endpoint list
<span class="c"># =&gt; ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])                                                  IPv6   IPv4           STATUS</span>
<span class="c">#               ENFORCEMENT        ENFORCEMENT</span>
<span class="c">#    272        Disabled           Disabled          472        k8s:app=curl                                                                        172.20.0.43    ready</span>
<span class="c">#                                                               k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.cluster=default</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.serviceaccount=default</span>
<span class="c">#                                                               k8s:io.kubernetes.pod.namespace=default</span>
<span class="c">#    1332       Disabled           Disabled          1          k8s:node-role.kubernetes.io/control-plane                                                          ready</span>
<span class="c">#                                                               k8s:node.kubernetes.io/exclude-from-external-load-balancers</span>
<span class="c">#                                                               reserved:host</span>
<span class="c">#    1814       Disabled           Disabled          30923      k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=kube-system          172.20.0.134   ready</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.cluster=default</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.serviceaccount=coredns</span>
<span class="c">#                                                               k8s:io.kubernetes.pod.namespace=kube-system</span>
<span class="c">#                                                               k8s:k8s-app=kube-dns</span>

<span class="c"># 통신 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl webpod | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod-697b545f57-mvz92</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s webpod | grep Hostname; sleep 1; done'</span>
<span class="c"># =&gt; Hostname: webpod-697b545f57-ns4sw</span>
<span class="c">#    Hostname: webpod-697b545f57-mvz92</span>
<span class="c">#    Hostname: webpod-697b545f57-mvz92</span>
<span class="c">#    Hostname: webpod-697b545f57-ns4sw</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<h3 id="prometheus-와-grafana-설치-및-설정">Prometheus 와 Grafana 설치 및 설정</h3>

<ul>
  <li>이번 예제는 Prometheus와 Grafana를 한번에 설치하는 예제를 따라하며 진행해보겠습니다. <a href="https://www.youtube.com/watch?v=DdWksYq5Pv4">Youtube 영상</a>
    <ul>
      <li>배포 파일에 Grafana에는 Cilium Dashboard가 포함되어 있습니다.</li>
      <li>이번 예제 배포파일에는 Prometheus와 Grafana가 Cilium과 Hubble의 메트릭을 자동으로 수집하고 시각화할 수 있도록 설정되어 있습니다.</li>
    </ul>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/cilium/cilium/1.17.6/examples/kubernetes/addons/prometheus/monitoring-example.yaml
<span class="c"># =&gt; namespace/cilium-monitoring created</span>
<span class="c">#    serviceaccount/prometheus-k8s created</span>
<span class="c">#    configmap/grafana-config created</span>
<span class="c">#    configmap/grafana-cilium-dashboard created</span>
<span class="c">#    configmap/grafana-cilium-operator-dashboard created</span>
<span class="c">#    configmap/grafana-hubble-dashboard created</span>
<span class="c">#    configmap/grafana-hubble-l7-http-metrics-by-workload created</span>
<span class="c">#    configmap/prometheus created</span>
<span class="c">#    clusterrole.rbac.authorization.k8s.io/prometheus created</span>
<span class="c">#    clusterrolebinding.rbac.authorization.k8s.io/prometheus created</span>
<span class="c">#    service/grafana created</span>
<span class="c">#    service/prometheus created</span>
<span class="c">#    deployment.apps/grafana created</span>
<span class="c">#    deployment.apps/prometheus created</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get deploy,pod,svc,ep <span class="nt">-n</span> cilium-monitoring
<span class="c"># =&gt; NAME                         READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/grafana      0/1     1            0           14s</span>
<span class="c">#    deployment.apps/prometheus   1/1     1            1           14s</span>
<span class="c">#    </span>
<span class="c">#    NAME                              READY   STATUS              RESTARTS   AGE</span>
<span class="c">#    pod/grafana-5c69859d9-7cpvl       0/1     ContainerCreating   0          14s</span>
<span class="c">#    pod/prometheus-6fc896bc5d-9xfll   1/1     Running             0          14s</span>
<span class="c">#    </span>
<span class="c">#    NAME                 TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE</span>
<span class="c">#    service/grafana      ClusterIP   10.96.10.188   &lt;none&gt;        3000/TCP   14s</span>
<span class="c">#    service/prometheus   ClusterIP   10.96.218.78   &lt;none&gt;        9090/TCP   14s</span>
<span class="c">#    </span>
<span class="c">#    NAME                   ENDPOINTS           AGE</span>
<span class="c">#    endpoints/grafana      &lt;none&gt;              14s</span>
<span class="c">#    endpoints/prometheus   172.20.2.115:9090   14s</span>
<span class="nv">$ </span>kubectl get cm <span class="nt">-n</span> cilium-monitoring
<span class="c"># =&gt; NAME                                         DATA   AGE</span>
<span class="c">#    grafana-cilium-dashboard                     1      23s</span>
<span class="c">#    grafana-cilium-operator-dashboard            1      23s</span>
<span class="c">#    grafana-config                               3      24s</span>
<span class="c">#    grafana-hubble-dashboard                     1      23s</span>
<span class="c">#    grafana-hubble-l7-http-metrics-by-workload   1      23s</span>
<span class="c">#    kube-root-ca.crt                             1      24s</span>
<span class="c">#    prometheus                                   1      23s</span>

<span class="c"># 프로메테우스 서버 설정</span>
<span class="nv">$ </span>kc describe cm <span class="nt">-n</span> cilium-monitoring prometheus

<span class="c"># 그라파나 서버 설정</span>
<span class="nv">$ </span>kc describe cm <span class="nt">-n</span> cilium-monitoring grafana-config

<span class="c"># 그파라나 대시보드들 주입을 위한 설정 확인</span>
<span class="nv">$ </span>kc describe cm <span class="nt">-n</span> cilium-monitoring grafana-cilium-dashboard
<span class="nv">$ </span>kc describe cm <span class="nt">-n</span> cilium-monitoring grafana-hubble-dashboard
<span class="c"># &lt;span style="color: green;"&gt;👉 설정 내용이 길어서 캡쳐는 생략하겠습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<h3 id="cilium과-hubble-메트릭-켜기">Cilium과 Hubble 메트릭 켜기</h3>

<ul>
  <li>이번 예제에는 Cilium과 Hubble의 메트릭을 Prometheus와 Grafana가 수집할 수 있도록 설정되어 있습니다.</li>
  <li>하지만 기본적으로 Cilium, Hubble, Cilium Operator의 메트릭은 비활성화되어 있습니다.</li>
  <li>따라서 Prometheus와 Grafana가 Cilium과 Hubble의 메트릭을 수집할 수 있도록 설정을 변경해야 합니다. <a href="https://docs.cilium.io/en/stable/observability/grafana/#deploy-cilium-and-hubble-with-metrics-enabled">Docs</a></li>
  <li>메트릭을 활성화하면 구성요소가 실행중인 모든 노드에 각각 <code class="language-plaintext highlighter-rouge">9962</code>, <code class="language-plaintext highlighter-rouge">9965</code>, <code class="language-plaintext highlighter-rouge">9963</code> 포트가 열립니다.</li>
  <li>Cilium, Hubble, Cilium Operator은 다음 helm 값으로 서로 독립적으로 활성화 할 수 있습니다.
    <ul>
      <li><code class="language-plaintext highlighter-rouge">prometheus.enabled=true</code>: cilium-agent 메트릭 켜기.</li>
      <li><code class="language-plaintext highlighter-rouge">operator.prometheus.enabled=true</code>: cilium-operator 메트릭 켜기.</li>
      <li><code class="language-plaintext highlighter-rouge">hubble.metrics.enabled</code>: 주어진 Hubble 메트릭 목록을 켜기
        <ul>
          <li>Hubble 메트릭 실행을 위해서는 <code class="language-plaintext highlighter-rouge">hubble.enabled=true</code>으로 설정되어 있어야 합니다.</li>
          <li><a href="https://docs.cilium.io/en/stable/observability/metrics/#hubble-exported-metrics">Hubble exported metrics</a>에서 활성화 할 수 있는 Hubble 메트릭을 확인 가능합니다..</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># &lt;span style="color: green;"&gt;👉 이번 예제에서는 이미 활성화 되어있습니다.&lt;/span&gt;</span>
<span class="nv">$ </span>helm <span class="nb">install </span>cilium cilium/cilium <span class="nt">--version</span> 1.17.6 <span class="se">\</span>
   <span class="nt">--namespace</span> kube-system <span class="se">\</span>
   <span class="nt">--set</span> prometheus.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
   <span class="nt">--set</span> operator.prometheus.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
   <span class="nt">--set</span> hubble.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
   <span class="nt">--set</span> hubble.metrics.enableOpenMetrics<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
   <span class="nt">--set</span> hubble.metrics.enabled<span class="o">=</span><span class="s2">"{dns,drop,tcp,flow,port-distribution,icmp,httpV2:exemplars=true;labelsContext=source_ip</span><span class="se">\,</span><span class="s2">source_namespace</span><span class="se">\,</span><span class="s2">source_workload</span><span class="se">\,</span><span class="s2">destination_ip</span><span class="se">\,</span><span class="s2">destination_namespace</span><span class="se">\,</span><span class="s2">destination_workload</span><span class="se">\,</span><span class="s2">traffic_direction}"</span>

<span class="c"># 호스트에 포트 정보 확인</span>
<span class="nv">$ </span>ss <span class="nt">-tnlp</span> | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'9962|9963|9965'</span>
<span class="c"># =&gt; LISTEN 0      4096                *:9962             *:*    users:(("cilium-agent",pid=2870,fd=7))     # cilium 메트릭</span>
<span class="c">#    LISTEN 0      4096                *:9963             *:*    users:(("cilium-operator",pid=1917,fd=7))  # cilium-opeator 메트릭</span>
<span class="c">#    LISTEN 0      4096                *:9965             *:*    users:(("cilium-agent",pid=2870,fd=31))    # hubble 메트릭</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 9963 포트는 cilium-operator 메트릭을 위한 포트로 컨트롤 플레인 노드에서만 열리는듯 합니다.&lt;/span&gt;</span>

<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>ss <span class="nt">-tnlp</span> | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'9962|9963|9965'</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    LISTEN 0      4096               *:9965             *:*    users:(("cilium-agent",pid=2032,fd=39))     # hubble 메트릭</span>
<span class="c">#    LISTEN 0      4096               *:9962             *:*    users:(("cilium-agent",pid=2032,fd=7))      # cilium 메트릭</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w2 &lt;&lt;</span>
<span class="c">#    LISTEN 0      4096               *:9962             *:*    users:(("cilium-agent",pid=2036,fd=7))      # cilium 메트릭</span>
<span class="c">#    LISTEN 0      4096               *:9965             *:*    users:(("cilium-agent",pid=2036,fd=30))     # hubble 메트릭</span>
</code></pre></div></div>

<h3 id="prometheus와-grafana-접속해서-확인">Prometheus와 Grafana 접속해서 확인</h3>

<ul>
  <li>Prometheus와 Grafana를 호스트에서 접속하기 위해 NodePort를 사용하여 접속할 수 있도록 설정하겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>kubectl get svc <span class="nt">-n</span> cilium-monitoring
<span class="c"># =&gt; NAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE</span>
<span class="c">#    grafana      ClusterIP   10.96.10.188   &lt;none&gt;        3000/TCP   10m</span>
<span class="c">#    prometheus   ClusterIP   10.96.218.78   &lt;none&gt;        9090/TCP   10m</span>

<span class="c"># NodePort 설정</span>
<span class="nv">$ </span>kubectl patch svc <span class="nt">-n</span> cilium-monitoring prometheus <span class="nt">-p</span> <span class="s1">'{"spec": {"type": "NodePort", "ports": [{"port": 9090, "targetPort": 9090, "nodePort": 30001}]}}'</span>
<span class="c"># =&gt; service/prometheus patched</span>
<span class="nv">$ </span>kubectl patch svc <span class="nt">-n</span> cilium-monitoring grafana <span class="nt">-p</span> <span class="s1">'{"spec": {"type": "NodePort", "ports": [{"port": 3000, "targetPort": 3000, "nodePort": 30002}]}}'</span>
<span class="c"># =&gt; service/grafana patched</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get svc <span class="nt">-n</span> cilium-monitoring
<span class="c"># =&gt; NAME         TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE</span>
<span class="c">#    grafana      NodePort   10.96.10.188   &lt;none&gt;        3000:30002/TCP   11m</span>
<span class="c">#    prometheus   NodePort   10.96.218.78   &lt;none&gt;        9090:30001/TCP   11m</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 NodePort가 각각 30002, 30001로 설정되었습니다.&lt;/span&gt;</span>

<span class="c"># 접속 주소 확인</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"http://192.168.10.100:30001"</span>  <span class="c"># prometheus</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"http://192.168.10.100:30002"</span>  <span class="c"># grafana</span>
</code></pre></div></div>

<ul>
  <li>간혹 Prometheus의 접속시 서버와 브라우저간의 시간 차이가 발생할 수 있습니다.
    <ul>
      <li>이때는 모든 가상머신을 reboot후 재접속하면 해결되는듯 합니다.</li>
    </ul>
  </li>
  <li>Prometheus 접속 확인
    <ul>
      <li>설정확인
        <ul>
          <li>Status &gt; Configuration에서 Prometheus 설정을 확인할 수 있습니다.</li>
          <li>Status &gt; Service Discovery에서 kubernetes의 통한 서비스 디스커버리를 통해 수집된 대상을 확인할 수 있습니다.</li>
          <li>Status &gt; Targets에서 Cilium, Hubble, Cilium Operator의 메트릭이 수집되고 있는지 확인할 수 있습니다.</li>
        </ul>
      </li>
      <li>기본 쿼리창에서 <code class="language-plaintext highlighter-rouge">cilium_</code>, <code class="language-plaintext highlighter-rouge">cilium_operator_</code>, <code class="language-plaintext highlighter-rouge">hubble_</code>로 시작하는 메트릭을 검색해보면 Cilium, Hubble, Cilium Operator의 메트릭을 확인할 수 있습니다.
<img src="/assets/2025/cilium/w2/20250727_cilium_w2_14.png" alt="img.png" class="image-center" />
<em class="image-caption"><code class="language-plaintext highlighter-rouge">hubble_drop_total</code> 메트릭 검색 예제</em></li>
    </ul>
  </li>
  <li>Grafana 접속 확인
    <ul>
      <li>Configuration &gt; Data Sources에서 Prometheus 서비스의 도메인 주소를 확인할 수 있고, Prometheus에서 수집한 메트릭을 사용하고 있는것을 확인할 수 있습니다.
<img src="/assets/2025/cilium/w2/20250727_cilium_w2_15.png" alt="img.png" class="image-center" /></li>
      <li>Dashboard &gt; General : 미리 설정된 대시보드를 확인할 수 있습니다.
<img src="/assets/2025/cilium/w2/20250727_cilium_w2_16.png" alt="img.png" class="image-center" /></li>
    </ul>
  </li>
  <li>Cilium Metric 대시보드 및 간단 쿼리문 알아보기 : Generic, API, Cilium(BPF, kvstore, NW info, Endpoints, k8s integration)
    <ul>
      <li>Cilium Metric 대시보드는 전체적인 Cilium의 메트릭을 확인할 수 있는 대시보드입니다.</li>
      <li>map ops (average node) 패널 분석
<img src="/assets/2025/cilium/w2/20250727_cilium_w2_17.png" alt="img.png" class="image-center" />
        <ul>
          <li>위의 캡쳐에서 본바와 같이 아래와 같은 PromQL 쿼리문을 사용합니다.
            <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">topk</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="k">avg</span><span class="p">(</span><span class="n">rate</span><span class="p">(</span><span class="n">cilium_bpf_map_ops_total</span><span class="p">{</span><span class="n">k8s_app</span><span class="o">=</span><span class="nv">"cilium"</span><span class="p">,</span> <span class="n">pod</span><span class="o">=~</span><span class="nv">"$pod"</span><span class="p">}[</span><span class="mi">5</span><span class="n">m</span><span class="p">]))</span> <span class="k">by</span> <span class="p">(</span><span class="n">pod</span><span class="p">,</span> <span class="n">map_name</span><span class="p">,</span> <span class="k">operation</span><span class="p">))</span>
</code></pre></div>            </div>
          </li>
          <li>Prometheus에서 위의 쿼리를 바탕으로 쿼리를 해서 분석해 보겠습니다.
            <ul>
              <li><a href="https://docs.cilium.io/en/stable/observability/metrics/">공식문서</a>에서 확인해보면 <code class="language-plaintext highlighter-rouge">cilium_bpf_map_ops_total</code>는
수행된 eBPF Map 작업수를 나타냅니다.
                <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
cilium_bpf_map_ops_total 
<span class="c"># &lt;span style="color: green;"&gt;👉 전체 cilium_bpf_map_ops_total 조회&lt;/span&gt;</span>
cilium_bpf_map_ops_total<span class="o">{</span><span class="nv">k8s_app</span><span class="o">=</span><span class="s2">"cilium"</span><span class="o">}</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s_app이 cilium인 cilium_bpf_map_ops_total 조회&lt;/span&gt;</span>
cilium_bpf_map_ops_total<span class="o">{</span><span class="nv">k8s_app</span><span class="o">=</span><span class="s2">"cilium"</span>, <span class="nv">pod</span><span class="o">=</span><span class="s2">"cilium-4hghz"</span><span class="o">}</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s_app이 cilium이면서 pod 명이 cilium-4hghz인 cilium_bpf_map_ops_total 조회&lt;/span&gt;</span>
  
<span class="c"># 최근 5분 간의 데이터로 증가율 계산</span>
rate<span class="o">(</span>cilium_bpf_map_ops_total<span class="o">{</span><span class="nv">k8s_app</span><span class="o">=</span><span class="s2">"cilium"</span><span class="o">}[</span>5m]<span class="o">)</span> <span class="c"># Graph 확인</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s_app이 cilium인 cilium_bpf_map_ops_total 의 5분간 데이터 증가율 계산&lt;/span&gt;</span>
  
<span class="c"># 여러 시계열(metric series)의 값의 평균</span>
avg<span class="o">(</span>rate<span class="o">(</span>cilium_bpf_map_ops_total<span class="o">{</span><span class="nv">k8s_app</span><span class="o">=</span><span class="s2">"cilium"</span><span class="o">}[</span>5m]<span class="o">))</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 k8s_app이 cilium인 cilium_bpf_map_ops_total 의 5분간 데이터 증가율의 평균&lt;/span&gt;</span>
  
<span class="c"># 집계 함수(예: sum, avg, max, rate)와 함께 사용하여 어떤 레이블(label)을 기준으로 그룹화할지를 지정하는 그룹핑(grouping) </span>
avg<span class="o">(</span>rate<span class="o">(</span>cilium_bpf_map_ops_total<span class="o">{</span><span class="nv">k8s_app</span><span class="o">=</span><span class="s2">"cilium"</span><span class="o">}[</span>5m]<span class="o">))</span> by <span class="o">(</span>pod<span class="o">)</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 pod명으로 그룹핑&lt;/span&gt;</span>
avg<span class="o">(</span>rate<span class="o">(</span>cilium_bpf_map_ops_total<span class="o">{</span><span class="nv">k8s_app</span><span class="o">=</span><span class="s2">"cilium"</span><span class="o">}[</span>5m]<span class="o">))</span> by <span class="o">(</span>pod, map_name<span class="o">)</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 pod명과 map이름으로 그룹핑&lt;/span&gt;</span>
avg<span class="o">(</span>rate<span class="o">(</span>cilium_bpf_map_ops_total<span class="o">{</span><span class="nv">k8s_app</span><span class="o">=</span><span class="s2">"cilium"</span><span class="o">}[</span>5m]<span class="o">))</span> by <span class="o">(</span>pod, map_name, operation<span class="o">)</span> <span class="c"># Graph 확인</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 pod명과 map이름, map 동작으로 그룹핑&lt;/span&gt;</span>
  
<span class="c"># 시계열 중에서 가장 큰 k개를 선택</span>
topk<span class="o">(</span>5, avg<span class="o">(</span>rate<span class="o">(</span>cilium_bpf_map_ops_total<span class="o">{</span><span class="nv">k8s_app</span><span class="o">=</span><span class="s2">"cilium"</span><span class="o">}[</span>5m]<span class="o">)))</span> by <span class="o">(</span>pod, map_name, operation<span class="o">)</span>
topk<span class="o">(</span>5, avg<span class="o">(</span>rate<span class="o">(</span>cilium_bpf_map_ops_total<span class="o">{</span><span class="nv">k8s_app</span><span class="o">=</span><span class="s2">"cilium"</span>, <span class="nv">pod</span><span class="o">=</span><span class="s2">"cilium-4hghz"</span><span class="o">}[</span>5m]<span class="o">)))</span> by <span class="o">(</span>pod, map_name, operation<span class="o">)</span>
</code></pre></div>                </div>
              </li>
            </ul>
          </li>
          <li>Grafana 해당 대시보드 편집해서 Variables을 확인해보겠습니다.
            <ul>
              <li>앞선 PromQL 쿼리문에서 <code class="language-plaintext highlighter-rouge">$pod</code>는 Variables로 설정되어 있습니다. 이를 확인해보겠습니다.</li>
              <li>해당 dashboard &gt; Settings &gt; Variables에서 <code class="language-plaintext highlighter-rouge">$pod</code>를 확인할 수 있습니다.
<img src="/assets/2025/cilium/w2/20250727_cilium_w2_18.png" alt="img.png" class="image-center" /></li>
              <li><code class="language-plaintext highlighter-rouge">label_values(cilium_version, pod)</code>는 Prometheus에서 <code class="language-plaintext highlighter-rouge">cilium_version</code>으로 쿼리해서 얻어지는 label들 중 <code class="language-plaintext highlighter-rouge">pod</code>값을 취함을 의미합니다.
<img src="/assets/2025/cilium/w2/20250727_cilium_w2_19.png" alt="img.png" class="image-center" /></li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Cilium Operator 대시보드 : IPAM 관련 메트릭을 주로 확인할 수 있습니다. IPAM은 IP 주소 관리(IP Address Management)로, Cilium에서 IP 주소를 할당하고 관리하는 기능입니다.</li>
  <li>Hubble 대시보드 : General Processing, Network, Network Policy, HTTP, DNS 관련 메트릭을 확인할 수 있습니다.
    <ul>
      <li>Hubble L7 HTTP Metrics by Workload 대시보드 : HTTP 요청 및 응답에 대한 메트릭을 확인할 수 있습니다.
<img src="/assets/2025/cilium/w2/20250727_cilium_w2_20.png" alt="img.png" /></li>
    </ul>
  </li>
</ul>

<hr />

<h2 id="monitoring--metrics">Monitoring &amp; Metrics</h2>

<h3 id="cilium-metrics-설정-및-수집-방법">Cilium Metrics 설정 및 수집 방법</h3>

<p><a href="https://docs.cilium.io/en/stable/observability/metrics/#cilium-metrics">Docs</a></p>

<ul>
  <li>Cilium Metrics는 Cilium 자체의 상태, 즉 Cilium Agent, Cilium Envoy, Cilium Operator 프로세스에 대한 메트릭을 수집하고 제공합니다.</li>
  <li>Prometheus에서 수집할 수 있도록 하려면 <code class="language-plaintext highlighter-rouge">prometheus.enabled=true</code>로 설정해서 helm chart를 설치해야 합니다.</li>
  <li>Cilium Metrics는 <code class="language-plaintext highlighter-rouge">cilium_</code>라는 접두사를 가진 메트릭을 Prometheus에 제공합니다.</li>
  <li>Envoy Metrics는 <code class="language-plaintext highlighter-rouge">envoy_</code>라는 접두사를 가진 메트릭을 Prometheus에 제공하며, Cilium이 정의한 메트릭은 <code class="language-plaintext highlighter-rouge">cilium_envoy_</code>라는 접두사를 가집니다.</li>
  <li>Kubernetes에서 실행 및 수집될때 pod 이름과 namespace를 포함한 레이블을 추가합니다.</li>
  <li>설정 방법 (본 실습에서는 이미 적용되어 있습니다.)
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>helm <span class="nb">install </span>cilium cilium/cilium <span class="nt">--version</span> 1.17.6 <span class="se">\</span>
  <span class="nt">--namespace</span> kube-system <span class="se">\</span>
  <span class="nt">--set</span> prometheus.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> operator.prometheus.enabled<span class="o">=</span><span class="nb">true</span>

  <span class="c"># The ports can be configured via prometheus.port, envoy.prometheus.port, or operator.prometheus.port respectively.</span>
  <span class="nt">--set</span> prometheus.port
  <span class="nt">--set</span> envoy.prometheus.port
  <span class="nt">--set</span> operator.prometheus.port
  ...
</code></pre></div>    </div>
  </li>
  <li>Metric이 활성화되면 모든 Cilium 구성요소에는 다음과 같은 annotation이 표시됩니다. annotation은 Prometheus가 메트릭을 수집할지 여부를 알리는데 사용됩니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># cilium-agent 데몬셋 파드</span>
<span class="nv">$ </span>kubectl describe pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium | <span class="nb">grep </span>prometheus
<span class="c"># =&gt;                       prometheus.io/port: 9962</span>
<span class="c">#                          prometheus.io/scrape: true</span>
  
<span class="nv">$ </span>curl 192.168.10.100:9962/metrics
<span class="c"># =&gt; # HELP cilium_agent_api_process_time_seconds Duration of processed API calls labeled by path, method and return code.</span>
<span class="c">#    # TYPE cilium_agent_api_process_time_seconds histogram</span>
<span class="c">#    cilium_agent_api_process_time_seconds_bucket{method="DELETE",path="/v1/endpoint",return_code="404",le="0.005"} 3</span>
<span class="c">#    cilium_agent_api_process_time_seconds_bucket{method="DELETE",path="/v1/endpoint",return_code="404",le="0.01"} 3</span>
<span class="c">#    cilium_agent_api_process_time_seconds_bucket{method="DELETE",path="/v1/endpoint",return_code="404",le="0.025"} 3</span>
<span class="c">#    ...</span>
  
<span class="c"># cilium-operator 디플로이먼트 파드 </span>
<span class="nv">$ </span>kubectl describe pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> <span class="nv">name</span><span class="o">=</span>cilium-operator | <span class="nb">grep </span>prometheus
<span class="c"># =&gt; Annotations:          prometheus.io/port: 9963</span>
<span class="c">#                          prometheus.io/scrape: true</span>
  
<span class="nv">$ </span>curl 192.168.10.100:9963/metrics
<span class="c"># =&gt; # HELP certwatcher_read_certificate_errors_total Total number of certificate read errors</span>
<span class="c">#    # TYPE certwatcher_read_certificate_errors_total counter</span>
<span class="c">#    certwatcher_read_certificate_errors_total 0</span>
<span class="c">#    # HELP certwatcher_read_certificate_total Total number of certificate reads</span>
<span class="c">#    # TYPE certwatcher_read_certificate_total counter</span>
<span class="c">#    certwatcher_read_certificate_total 0</span>
<span class="c">#    ...</span>
</code></pre></div>    </div>
  </li>
  <li>Prometheus는  다음의 scrape_configs 섹션의 설정을 기반으로 자동으로 Cilium과 Envoy의 메트릭을 수집합니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kc describe cm <span class="nt">-n</span> cilium-monitoring prometheus
<span class="c"># =&gt; prometheus.yaml:</span>
<span class="c">#    ...</span>
<span class="c">#    scrape_configs:</span>
<span class="c">#      ...    </span>
<span class="c">#      # https://github.com/prometheus/prometheus/blob/master/documentation/examples/prometheus-kubernetes.yml#L156</span>
<span class="c">#      - job_name: 'kubernetes-pods'</span>
<span class="c">#        kubernetes_sd_configs:</span>
<span class="c">#          - role: pod</span>
<span class="c">#        relabel_configs:</span>
<span class="c">#          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]</span>
<span class="c">#            action: keep</span>
<span class="c">#            regex: true</span>
<span class="c">#          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]</span>
<span class="c">#            action: replace</span>
<span class="c">#            target_label: __metrics_path__</span>
<span class="c">#            regex: (.+)</span>
<span class="c">#          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]</span>
<span class="c">#            action: replace</span>
<span class="c">#            regex: (.+):(?:\d+);(\d+)</span>
<span class="c">#            replacement: ${1}:${2}</span>
<span class="c">#            target_label: __address__</span>
<span class="c">#          - action: labelmap</span>
<span class="c">#            regex: __meta_kubernetes_pod_label_(.+)</span>
<span class="c">#          - source_labels: [__meta_kubernetes_namespace]</span>
<span class="c">#            action: replace</span>
<span class="c">#            target_label: namespace</span>
<span class="c">#          - source_labels: [__meta_kubernetes_pod_name]</span>
<span class="c">#            action: replace</span>
<span class="c">#            target_label: pod</span>
<span class="c">#          - source_labels: [__meta_kubernetes_pod_container_port_number]</span>
<span class="c">#            action: keep</span>
<span class="c">#            regex: \d+</span>
<span class="c">#    ...</span>
</code></pre></div>    </div>
  </li>
</ul>

<p><img src="/assets/2025/cilium/w2/20250727_cilium_w2_21.png" alt="img.png" /></p>

<h3 id="hubble-metrics-설정-및-수집-방법">Hubble Metrics 설정 및 수집 방법</h3>

<p><a href="https://docs.cilium.io/en/stable/observability/metrics/#hubble-metrics">Docs</a></p>

<ul>
  <li>Cilium Metric은 Cilium의 상태를 모니터링 할 수 있게 해주지만, Hubble Metric은 Cilium이 관리하는 Kubernetes pod의 네트워크 동작을 연결과 보안과 관련하여 모니터링 할 수 있게 해줍니다.</li>
  <li>설정은 다음과 같습니다. (실습환경에서는 이미 적용되어 있습니다.)
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>helm <span class="nb">install </span>cilium cilium/cilium <span class="nt">--version</span> 1.17.6 <span class="se">\</span>
<span class="nt">--namespace</span> kube-system <span class="se">\</span>
<span class="nt">--set</span> prometheus.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> operator.prometheus.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> hubble.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> hubble.metrics.enableOpenMetrics<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> hubble.metrics.enabled<span class="o">=</span><span class="s2">"{dns,drop,tcp,flow,port-distribution,icmp,httpV2:exemplars=true;labelsContext=source_ip</span><span class="se">\,</span><span class="s2">source_namespace</span><span class="se">\,</span><span class="s2">source_workload</span><span class="se">\,</span><span class="s2">destination_ip</span><span class="se">\,</span><span class="s2">destination_namespace</span><span class="se">\,</span><span class="s2">destination_workload</span><span class="se">\,</span><span class="s2">traffic_direction}"</span>
<span class="nt">--set</span> hubble.metrics.port
</code></pre></div>    </div>
  </li>
  <li>L7 메트릭은 L7 가시성 활성화가 필요합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">hubble.metrics.enabled</code> 설정은 Hubble에서 수집할 메트릭을 지정합니다.
    <ul>
      <li>예를 들어, <code class="language-plaintext highlighter-rouge">hubble.metrics.enabled</code> 값을 Helm 챠트 value에 설정하면, Cilium 챠트는 <code class="language-plaintext highlighter-rouge">hubble-metrics</code>라는 헤드리스 서비스를 생성합니다.</li>
      <li>이 서비스는 <code class="language-plaintext highlighter-rouge">prometheus.io/scrape:'true'</code> annotation을 갖고 있어 Prometheus의 대상이 됩니다.</li>
    </ul>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># hubble-metrics 헤드리스 서비스 정보 확인</span>
<span class="nv">$ </span>kubectl get svc <span class="nt">-n</span> kube-system hubble-metrics
<span class="c"># =&gt; NAME             TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)    AGE</span>
<span class="c">#    hubble-metrics   ClusterIP   None         &lt;none&gt;        9965/TCP   2d</span>
<span class="nv">$ </span>kc describe svc <span class="nt">-n</span> kube-system hubble-metrics
<span class="c"># =&gt; Annotations:              meta.helm.sh/release-name: cilium</span>
<span class="c">#                              meta.helm.sh/release-namespace: kube-system</span>
<span class="c">#                              prometheus.io/port: 9965</span>
<span class="c">#                              prometheus.io/scrape: true</span>
<span class="c">#    ...</span>
<span class="c">#    Endpoints:                192.168.10.102:9965,192.168.10.100:9965,192.168.10.101:9965</span>
<span class="c">#    ...</span>

<span class="nv">$ </span>curl 192.168.10.100:9965/metrics
<span class="c"># =&gt; # HELP grpc_server_handled_total Total number of RPCs completed on the server, regardless of success or failure.</span>
<span class="c">#    # TYPE grpc_server_handled_total counter</span>
<span class="c">#    grpc_server_handled_total{grpc_code="Aborted",grpc_method="Check",grpc_service="grpc.health.v1.Health",grpc_type="unary"} 0</span>
<span class="c">#    grpc_server_handled_total{grpc_code="Aborted",grpc_method="GetAgentEvents",grpc_service="observer.Observer",grpc_type="server_stream"} 0</span>
<span class="c">#    grpc_server_handled_total{grpc_code="Aborted",grpc_method="GetDebugEvents",grpc_service="observer.Observer",grpc_type="server_stream"} 0</span>
<span class="c">#    ...</span>

<span class="c">#</span>
<span class="nv">$ </span>kc describe cm <span class="nt">-n</span> cilium-monitoring prometheus
<span class="c"># =&gt; prometheus.yaml:</span>
<span class="c">#    ...</span>
<span class="c">#    scrape_configs:</span>
<span class="c">#      # https://github.com/prometheus/prometheus/blob/master/documentation/examples/prometheus-kubernetes.yml#L79</span>
<span class="c">#      - job_name: 'kubernetes-endpoints'</span>
<span class="c">#        kubernetes_sd_configs:</span>
<span class="c">#          - role: endpoints</span>
<span class="c">#        relabel_configs:</span>
<span class="c">#          - source_labels: [__meta_kubernetes_pod_label_k8s_app]</span>
<span class="c">#            action: keep</span>
<span class="c">#            regex: cilium</span>
<span class="c">#          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]</span>
<span class="c">#            action: keep</span>
<span class="c">#            regex: true</span>
<span class="c">#          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]</span>
<span class="c">#            action: replace</span>
<span class="c">#            target_label: __scheme__</span>
<span class="c">#            regex: (https?)</span>
<span class="c">#          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]</span>
<span class="c">#            action: replace</span>
<span class="c">#            target_label: __metrics_path__</span>
<span class="c">#            regex: (.+)</span>
<span class="c">#          - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]</span>
<span class="c">#            action: replace</span>
<span class="c">#            target_label: __address__</span>
<span class="c">#            regex: (.+)(?::\d+);(\d+)</span>
<span class="c">#            replacement: $1:$2</span>
<span class="c">#          - action: labelmap</span>
<span class="c">#            regex: __meta_kubernetes_service_label_(.+)</span>
<span class="c">#          - source_labels: [__meta_kubernetes_namespace]</span>
<span class="c">#            action: replace</span>
<span class="c">#            target_label: namespace</span>
<span class="c">#          - source_labels: [__meta_kubernetes_service_name]</span>
<span class="c">#            action: replace</span>
<span class="c">#            target_label: service</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w2/20250727_cilium_w2_22.png" alt="img.png" /></p>

<h2 id="layer-7-protocol-visibility">Layer 7 Protocol Visibility</h2>

<ul>
  <li>Monitoring Datapath State는 기본적으로 L3/L4 패킷에 대한 가시성을 제공합니다.</li>
  <li>HTTP나 DNS같은 L7 프로토콜에 대한 가시성을 제공하기 위해서는 L7 프로토콜 가시성을 활성화해야 합니다.</li>
  <li>L7 트래픽에 대한 가시성을 활성화 하려면 L7 규칙을 지정하는 CiliumNetworkPolicy를 만들어야 합니다.</li>
  <li>CiliumNetworkPolicy는 L7 규칙과 일치하는 트래픽의 흐름이 Cilium에 표시되므로 최종사용자에게 노출될 수 있습니다.</li>
  <li>L7 네트워크 정책은 가시성을 가능하게 할 뿐만 아니라 pod에 들어가고 나가는 트래픽을 제어할 수 있음을 기억해야 합니다.</li>
</ul>

<h3 id="실습">실습</h3>

<ul>
  <li>다음 예제는 DNS(TCP/UDP/53) 및 HTTP(TCP/80 및 TCP/8080) 트래픽을 기본 네임스페이스 내에 표시할 수 있도록 L7 규칙을 지정합니다.</li>
  <li>하나는 DNS 규칙과 하나는 HTTP 규칙을 제공하며, 한 출력 통신을 제외하고 일치하지 않는 모든것을 삭제합니다.</li>
  <li>규칙이 L7 일치 조건이 생략되거나 와일드카드 처리되면 L4 섹션과 일치하는 모든 요청이 허용됩니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 반복 접속 해둔 상태</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s webpod | grep Hostname; sleep 1; done'</span>

<span class="c"># default 네임스페이스에 있는 Pod들의 egress(출방향) 트래픽을 제어하며, L7 HTTP 및 DNS 트래픽에 대한 가시성과 제어를 설정</span>
<span class="c">## method/path 기반 필터링은 안 하지만, HTTP 요청 정보는 Envoy를 통해 기록/관찰됨</span>
<span class="c">## cilium-envoy를 경유하게 됨 (DNS + HTTP 모두 L7 처리 대상)</span>
<span class="c">## 이 정책이 적용되면, 명시된 egress 외의 모든 egress 트래픽은 차단됩니다 (Cilium 정책은 default-deny 모델임)</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: "cilium.io/v2"
kind: CiliumNetworkPolicy
metadata:
  name: "l7-visibility"
spec:
  endpointSelector:
    matchLabels:
      "k8s:io.kubernetes.pod.namespace": default  # default 네임스페이스 안의 모든 Pod에 대해 egress 정책이 적용
  egress:
  - toPorts:
    - ports:
      - port: "53"
        protocol: ANY  # TCP, UDP 둘 다 허용
      rules:
        dns:
        - matchPattern: "*"  # 모든 도메인 조회 허용, L7 가시성 활성화
  - toEndpoints:
    - matchLabels:
        "k8s:io.kubernetes.pod.namespace": default
    toPorts:
    - ports:
      - port: "80"  # default 다른 파드의 HTTP TCP 80 요청 허용
        protocol: TCP
      - port: "8080"  # default 다른 파드의 HTTP TCP 8080 요청 허용
        protocol: TCP
      rules:
        http: [{}]  # 모든 HTTP 요청을 허용, L7 가시성 활성화
</span><span class="no">EOF

</span><span class="nv">$ </span>kubectl get cnp <span class="nt">-o</span> yaml
<span class="c"># =&gt;   kind: CiliumNetworkPolicy</span>
<span class="c">#      ...</span>
<span class="c">#      spec:</span>
<span class="c">#        egress:</span>
<span class="c">#        - toPorts:</span>
<span class="c">#          - ports:</span>
<span class="c">#            - port: "53"</span>
<span class="c">#              protocol: ANY</span>
<span class="c">#            rules:</span>
<span class="c">#              dns:</span>
<span class="c">#              - matchPattern: '*'</span>
<span class="c">#        - toEndpoints:</span>
<span class="c">#          - matchLabels:</span>
<span class="c">#              k8s:io.kubernetes.pod.namespace: default</span>
<span class="c">#          toPorts:</span>
<span class="c">#          - ports:</span>
<span class="c">#            - port: "80"</span>
<span class="c">#              protocol: TCP</span>
<span class="c">#            - port: "8080"</span>
<span class="c">#              protocol: TCP</span>
<span class="c">#            rules:</span>
<span class="c">#              http:</span>
<span class="c">#              - {}</span>
<span class="c">#        endpointSelector:</span>
<span class="c">#          matchLabels:</span>
<span class="c">#            k8s:io.kubernetes.pod.namespace: default</span>
<span class="c">#      ...</span>

<span class="c"># 호출 확인 : cilium-envoy 경유 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nt">-s</span> webpod
<span class="c"># =&gt; Hostname: webpod-697b545f57-mvz92</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: ::1</span>
<span class="c">#    IP: 172.20.2.101</span>
<span class="c">#    IP: fe80::68c6:baff:fe2c:766b</span>
<span class="c">#    &lt;span style="color: green;"&gt;RemoteAddr: 172.20.0.43:39216&lt;/span&gt; # 해당 IP는 curl-pod 의 IP로 cilium-envoy IP로 SNAT 되지 않았음!</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: webpod</span>
<span class="c">#    User-Agent: curl/8.14.1</span>
<span class="c">#    Accept: */*</span>
<span class="c">#    &lt;span style="color: green;"&gt;X-Envoy-Expected-Rq-Timeout-Ms: 3600000&lt;/span&gt;   # cilium-envoy 경유 확인</span>
<span class="c">#    &lt;span style="color: green;"&gt;X-Envoy-Internal: true&lt;/span&gt;</span>
<span class="c">#    X-Forwarded-Proto: http</span>
<span class="c">#    X-Request-Id: 913dbacf-5559-4d13-8855-afaa41979f4e</span>

<span class="c"># 가시성 확인</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">-t</span> l7 <span class="nt">-o</span> compact
<span class="c"># =&gt; Jul 26 14:58:47.953: default/curl-pod:34773 (ID:472) -&gt; kube-system/coredns-674b8bbfcf-7m82r:53 (ID:30923) dns-request proxy FORWARDED (DNS Query webpod.default.svc.cluster.local. AAAA)</span>
<span class="c">#    Jul 26 14:58:47.953: default/curl-pod:34773 (ID:472) -&gt; kube-system/coredns-674b8bbfcf-7m82r:53 (ID:30923) dns-request proxy FORWARDED (DNS Query webpod.default.svc.cluster.local. A)</span>
<span class="c">#    Jul 26 14:58:47.954: default/curl-pod:34773 (ID:472) &lt;- kube-system/coredns-674b8bbfcf-7m82r:53 (ID:30923) dns-response proxy FORWARDED (DNS Answer "10.96.147.79" TTL: 30 (Proxy webpod.default.svc.cluster.local. A))</span>
<span class="c">#    Jul 26 14:58:47.956: default/curl-pod:34773 (ID:472) &lt;- kube-system/coredns-674b8bbfcf-7m82r:53 (ID:30923) dns-response proxy FORWARDED (DNS Answer  TTL: 4294967295 (Proxy webpod.default.svc.cluster.local. AAAA))</span>
<span class="c">#    Jul 26 14:58:47.961: default/curl-pod:52022 (ID:472) -&gt; default/webpod-697b545f57-mvz92:80 (ID:18655) http-request FORWARDED (HTTP/1.1 GET http://webpod/)</span>
<span class="c">#    Jul 26 14:58:47.967: default/curl-pod:52022 (ID:472) &lt;- default/webpod-697b545f57-mvz92:80 (ID:18655) http-response FORWARDED (HTTP/1.1 200 5ms (GET http://webpod/))</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<ul>
  <li>Grafana에서 L7 HTTP Metrics by Workload 대시보드를 확인해보면, HTTP 요청 및 응답에 대한 메트릭을 확인할 수 있습니다.
<img src="/assets/2025/cilium/w2/20250727_cilium_w2_23.png" alt="img.png" class="image-center" />
    <ul>
      <li>이때 현재 label에는 destination_workload가 포함되어있지 않아서 메트릭이 나타나지 않는데 Destination Workload를 임시로 <code class="language-plaintext highlighter-rouge">.*</code> (정규표현식에서 와일드 카드)로 하거나 PromQL에서 해당 부분을 제외하거나 label에 추가하면 메트릭을 확인할 수 있습니다.</li>
    </ul>
  </li>
  <li>Prometheus에서도 <code class="language-plaintext highlighter-rouge">rate(hubble_http_requests_total[5m])</code>를 통해 확인해 보겠습니다. 
<img src="/assets/2025/cilium/w2/20250727_cilium_w2_24.png" alt="img.png" /></li>
</ul>

<h3 id="security-implications-및-실습">Security Implications 및 실습</h3>

<p><a href="https://docs.cilium.io/en/stable/observability/visibility/#security-implications">Docs</a></p>

<ul>
  <li>L7 트래픽 모니터링은 <strong>사용자 이름, 비밀번호, 쿼리 매개변수, API 키</strong> 등 잠재적으로 민감한 정보를 포함할 수 있기 때문에 보안에 주의해야 합니다.</li>
  <li>기본적으로 Hubble은 L7 트래픽의 민감 정보를 필터링하지 않습니다.</li>
  <li>간단한 실습을 해보겠습니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">-t</span> l7
<span class="c"># =&gt; Jul 26 15:50:11.494: default/curl-pod:49308 (ID:472) -&gt; default/webpod-697b545f57-mvz92:80 (ID:18655) http-request FORWARDED (HTTP/1.1 GET http://webpod/?user_id=1234)</span>
<span class="c">#    Jul 26 15:50:11.499: default/curl-pod:49308 (ID:472) &lt;- default/webpod-697b545f57-mvz92:80 (ID:18655) http-response FORWARDED (HTTP/1.1 200 5ms (GET http://webpod/?user_id=1234))</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 아래의 curl 명령으로 보낸 user_id가 그대로 보이는것을 확인할 수 있습니다.&lt;/span&gt;</span>
  
<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'curl -s webpod/?user_id=1234'</span>
  
<span class="c"># 민감정보 미출력 설정</span>
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--namespace</span> kube-system <span class="nt">--reuse-values</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">extraArgs</span><span class="o">=</span><span class="s2">"{--hubble-redact-enabled,--hubble-redact-http-urlquery}"</span>
<span class="c"># =&gt; Release "cilium" has been upgraded. Happy Helming!</span>
<span class="c">#    NAME: cilium</span>
<span class="c">#    LAST DEPLOYED: Sun Jul 27 00:51:08 2025</span>
<span class="c">#    NAMESPACE: kube-system</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 10</span>
<span class="c">#    TEST SUITE: None</span>
<span class="c">#    NOTES:</span>
<span class="c">#    You have successfully installed Cilium with Hubble Relay and Hubble UI.</span>
<span class="c">#    </span>
<span class="c">#    Your release version is 1.17.6.</span>
  
<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'curl -s webpod/?user_id=1234'</span>
  
<span class="c">#</span>
<span class="nv">$ </span>hubble observe <span class="nt">-f</span> <span class="nt">-t</span> l7
<span class="c"># =&gt; Jul 26 15:51:49.594: default/curl-pod:53276 (ID:472) -&gt; default/webpod-697b545f57-ns4sw:80 (ID:18655) http-request FORWARDED (HTTP/1.1 GET http://webpod/)</span>
<span class="c">#    Jul 26 15:51:49.601: default/curl-pod:53276 (ID:472) &lt;- default/webpod-697b545f57-ns4sw:80 (ID:18655) http-response FORWARDED (HTTP/1.1 200 9ms (GET http://webpod/))</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 민감정보가 필터링 된것을 확인할 수 있습니다.&lt;/span&gt;</span>
</code></pre></div>    </div>
  </li>
  <li>보안을 강화하기 위해 Cilium은 허블이 레이어 7 흐름에 존재하는 민감한 정보를 처리(제거나 마스킹)할 수 있도록 <code class="language-plaintext highlighter-rouge">--hubble-redact-enabled</code> 옵션을 제공합니다.
    <ul>
      <li>HTTP에서 URL 쿼리 파라메터(GET)을 필터링 하기위해 <code class="language-plaintext highlighter-rouge">--hubble-redact-http-urlquery</code>를 사용 =&gt; URL의 <code class="language-plaintext highlighter-rouge">?query=value</code> 제거
        <ul>
          <li>예시) 설정 전
            <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s2">"method"</span>: <span class="s2">"GET"</span>,
<span class="s2">"url"</span>: <span class="s2">"/user/profile?user_id=1234&amp;token=abcd1234"</span>,
<span class="s2">"status"</span>: 200
</code></pre></div>            </div>
          </li>
          <li>예시) 설정 후 : <code class="language-plaintext highlighter-rouge">--set extraArgs="{--hubble-redact-http-urlquery}”</code>
            <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s2">"method"</span>: <span class="s2">"GET"</span>,
<span class="s2">"url"</span>: <span class="s2">"/user/profile"</span>, <span class="c"># 쿼리 문자열이 제거되어 출력, 민감 정보 보호됨</span>
<span class="s2">"status"</span>: 200
</code></pre></div>            </div>
          </li>
        </ul>
      </li>
      <li>HTTP에서 사용자정보 (basic auth의 아이디 비밀번호) 등을 필터링하기위해 <code class="language-plaintext highlighter-rouge">--hubble-redact-http-userinfo</code>를 사용 =&gt; URL의 <code class="language-plaintext highlighter-rouge">user:pass@</code> 제거</li>
      <li>Kafka에서 API 키를 필터링하려면 <code class="language-plaintext highlighter-rouge">--hubble-redact-kafka-apikey</code> 사용</li>
      <li>HTTP 헤더를 필터링하기 위해서는 허용리스트(<code class="language-plaintext highlighter-rouge">--hubble-redact-http-headers-allow</code>) 또는 거부리스트 (<code class="language-plaintext highlighter-rouge">--hubble-redact-http-headers-deny</code>)를 사용</li>
    </ul>
  </li>
</ul>

<hr />

<h2 id="pwru-packet-where-are-you">pwru (Packet where are you)</h2>

<ul>
  <li>pwru는 eBPF 기반의 linux 커널 디버거입니다. <a href="https://github.com/cilium/pwru">https://github.com/cilium/pwru</a></li>
  <li>주요 특징
    <ul>
      <li>eBPF 기반 네트워크 트레이싱 툴로, 커널 패킷 경로를 실시간으로 모니터링합니다.</li>
      <li>고급 필터링 기능을 제공하여, 관심 있는 패킷만 골라서 추적할 수 있습니다</li>
      <li>네트워크 트러블슈팅, 즉 패킷 손실 및 처리 위치 파악, 다양한 커널 모듈과의 상호작용 등을 이해하는 데 유용합니다.</li>
      <li>커맨드라인에서 다양한 옵션과 PCAP 필터를 적용해서 상세 분석을 할 수 있습니다.</li>
    </ul>
  </li>
</ul>

<h3 id="pwru-설치-및-실행">pwru 설치 및 실행</h3>

<ul>
  <li><a href="https://medium.com/@Nikhil690/debugging-packet-drops-and-kernel-flows-with-pwru-fc03f3d479a4">PWRU: Debugging Packets and Kernel Flows</a>를 바탕으로 실행해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Prerequisites</span>
<span class="nv">$ </span><span class="nb">sudo </span>apt update
<span class="nv">$ </span><span class="nb">sudo </span>apt <span class="nb">install</span> <span class="nt">-y</span> clang llvm gcc make flex bison byacc yacc libpcap-dev golang

<span class="c"># Building PWRU from Source</span>
<span class="c">## Clone the PWRU GitHub repository</span>
<span class="nv">$ </span>git clone https://github.com/cilium/pwru.git
<span class="c"># =&gt; Cloning into 'pwru'...</span>
<span class="c">#    remote: Enumerating objects: 7681, done.</span>
<span class="c">#    remote: Counting objects: 100% (211/211), done.</span>
<span class="c">#    remote: Compressing objects: 100% (127/127), done.</span>
<span class="c">#    remote: Total 7681 (delta 117), reused 94 (delta 83), pack-reused 7470 (from 3)</span>
<span class="c">#    Receiving objects: 100% (7681/7681), 9.40 MiB | 18.12 MiB/s, done.</span>
<span class="c">#    Resolving deltas: 100% (4723/4723), done.</span>

<span class="c">## Navigate to the project directory</span>
<span class="nv">$ </span><span class="nb">cd </span>pwru

<span class="c">## Build the project : Compile the eBPF object files, Build the userspace Go application, Link everything together</span>
<span class="nv">$ </span>make
<span class="c"># =&gt; ...</span>
<span class="c">#    TARGET_GOARCH=&lt;span style="color: green;"&gt;amd64&lt;/span&gt; go generate</span>
<span class="c">#    Generating for &lt;span style="color: green;"&gt;amd64&lt;/span&gt;</span>
<span class="c">#    CC=cc GOARCH=&lt;span style="color: green;"&gt;amd64&lt;/span&gt; CGO_ENABLED=1 go build  \</span>
<span class="c">#            -ldflags "-w -s \</span>
<span class="c">#            -X 'github.com/cilium/pwru/internal/pwru.Version=v1.0.10-pre-110-gbd7ffd8'"</span>
<span class="c">#    # runtime/cgo</span>
<span class="c">#    &lt;span style="background-color: red; color: #fff;"&gt;cc: error: unrecognized command-line option '-m64'&lt;/span&gt;</span>
<span class="c">#    make: *** [Makefile:22: pwru] Error 1</span>
</code></pre></div></div>

<ul>
  <li>M1 Mac에서 빌드할 때는 <code class="language-plaintext highlighter-rouge">-m64</code> 옵션이 문제를 일으키는것 같습니다.</li>
</ul>

<h3 id="빌드-트러블슈팅-및-실행">빌드 트러블슈팅 및 실행</h3>

<ul>
  <li>빌드 로그를 봤을때 자꾸 amd64로 빌드하려고 하는것 같습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">uname</span> <span class="nt">-a</span>
<span class="c"># =&gt; Linux k8s-ctr 6.8.0-53-generic #55-Ubuntu SMP PREEMPT_DYNAMIC Fri Jan 17 15:02:14 UTC 2025 &lt;span style="color: green;"&gt;aarch64 aarch64 aarch64&lt;/span&gt; GNU/Linux</span>
</code></pre></div></div>

<ul>
  <li>하지만 제 환경은 aarch64으로 뭔기 빌드 설정이 잘못된것 같습니다. 빌드 스크립트를 수정하고 PR을 올리면 좋겠지만 시간이 없으므로 arm64로 강제로 빌드해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># (기존) TARGET_GOARCH=amd64 go generate</span>
<span class="nv">$ TARGET_GOARCH</span><span class="o">=</span>arm64 go generate
<span class="c"># =&gt; Generating for arm64</span>

<span class="c"># (기존) CC=cc GOARCH=amd64 CGO_ENABLED=1 go build  \</span>
<span class="c">#         -ldflags "-w -s \</span>
<span class="c">#         -X 'github.com/cilium/pwru/internal/pwru.Version=v1.0.10-pre-110-gbd7ffd8'"</span>
<span class="nv">$ CC</span><span class="o">=</span>cc <span class="nv">GOARCH</span><span class="o">=</span>arm64 <span class="nv">CGO_ENABLED</span><span class="o">=</span>1 go build  <span class="se">\</span>
        <span class="nt">-ldflags</span> <span class="s2">"-w -s </span><span class="se">\</span><span class="s2">
        -X 'github.com/cilium/pwru/internal/pwru.Version=v1.0.10-pre-110-gbd7ffd8'"</span>
<span class="c"># =&gt; # github.com/cilium/pwru</span>
<span class="c">#    /usr/bin/ld: /tmp/go-link-4205941405/000020.o: in function `_cgo_77133bf98b3a_C2func_getaddrinfo':</span>
<span class="c">#    /tmp/go-build/cgo_unix_cgo.cgo2.c:60:(.text+0x30): warning: Using 'getaddrinfo' in statically linked applications requires at runtime the shared libraries from the glibc version used for linking</span>
<span class="c">#    /usr/bin/ld: /root/pwru/internal/libpcap/../../libpcap/libpcap.a(nametoaddr.o): in function `pcap_nametoaddr':</span>
<span class="c">#    /root/pwru/libpcap/./nametoaddr.c:181:(.text+0x8): warning: Using 'gethostbyname' in statically linked applications requires at runtime the shared libraries from the glibc version used for linking</span>
<span class="c">#    /usr/bin/ld: /root/pwru/internal/libpcap/../../libpcap/libpcap.a(nametoaddr.o): in function `pcap_nametonetaddr':</span>
<span class="c">#    /root/pwru/libpcap/./nametoaddr.c:270:(.text+0x104): warning: Using 'getnetbyname_r' in statically linked applications requires at runtime the shared libraries from the glibc version used for linking</span>
<span class="c">#    /usr/bin/ld: /root/pwru/internal/libpcap/../../libpcap/libpcap.a(nametoaddr.o): in function `pcap_nametoproto':</span>
<span class="c">#    /root/pwru/libpcap/./nametoaddr.c:527:(.text+0x4cc): warning: Using 'getprotobyname_r' in statically linked applications requires at runtime the shared libraries from the glibc version used for linking</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 warning이 뜨긴 했지만 빌드가 된것 같습니다.&lt;/span&gt;</span>

<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-l</span> pwru
<span class="c"># =&gt; -rwxr-xr-x 1 root root 8561904 Jul 27 00:39 pwru</span>
</code></pre></div></div>

<ul>
  <li>빌드가 완료되면 <code class="language-plaintext highlighter-rouge">pwru</code> 실행파일이 생성됩니다. 이 파일을 실행하면 PWRU를 사용할 수 있습니다.</li>
  <li>리눅스 커널과 eBPF 서브시스템에 직접 상호작용하기 때문에 root 권한으로 실행해야 합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Running PWRU</span>
<span class="c">## Since PWRU interacts directly with kernel functions and eBPF subsystems, you need root permissions to run it:</span>
<span class="nv">$ </span><span class="nb">sudo</span> ./pwru <span class="o">[</span>options] <span class="o">[</span>pcap-filter]

<span class="c"># ICMP (ping) 패킷을 추적해보겠습니다.</span>
<span class="nv">$ </span><span class="nb">sudo</span> ./pwru <span class="nt">--output-tuple</span> icmp
<span class="c"># =&gt; 2025/07/27 00:40:49 Attaching kprobes (via kprobe)...</span>
<span class="c">#    1669 / 1669 [--------------------------------------------------------] 100.00% 1455 p/s</span>
<span class="c">#    2025/07/27 00:40:50 Attached (ignored 5)</span>
<span class="c">#    2025/07/27 00:40:50 Listening for events..  # &lt;span style="color: green;"&gt;👉 eBPF 설치하는 과정이 종료되고 이벤트를 listening 하고 있습니다.&lt;/span&gt;</span>
<span class="c">#    SKB                CPU PROCESS          NETNS      MARK/x        IFACE       PROTO  MTU   LEN   TUPLE FUNC</span>
<span class="c">#    0xffff00005f10c300 0   ~/bin/ping:42701 4026531840 0               0         0x0000 1500  84    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     ip_send_skb</span>
<span class="c">#    0xffff00005f10c300 0   ~/bin/ping:42701 4026531840 0               0         0x0000 1500  84    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     __ip_local_out</span>
<span class="c">#    0xffff00005f10c300 0   ~/bin/ping:42701 4026531840 0               0         0x0800 1500  84    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     nf_hook_slow</span>
<span class="c">#    0xffff00005f10c300 0   ~/bin/ping:42701 4026531840 c00             0         0x0800 1500  84    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     ip_output</span>
<span class="c">#    0xffff00005f10c300 0   ~/bin/ping:42701 4026531840 c00           eth0:2      0x0800 1500  84    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     nf_hook_slow</span>
<span class="c">#    0xffff00005f10c300 0   ~/bin/ping:42701 4026531840 c00           eth0:2      0x0800 1500  84    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     apparmor_ip_postroute</span>
<span class="c">#    0xffff00005f10c300 0   ~/bin/ping:42701 4026531840 c00           eth0:2      0x0800 1500  84    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     ip_finish_output</span>
<span class="c">#    0xffff00005f10c300 0   ~/bin/ping:42701 4026531840 c00           eth0:2      0x0800 1500  84    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     __ip_finish_output</span>
<span class="c">#    0xffff00005f10c300 0   ~/bin/ping:42701 4026531840 c00           eth0:2      0x0800 1500  84    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     ip_finish_output2</span>
<span class="c">#    0xffff00005f10c300 0   ~/bin/ping:42701 4026531840 c00           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     __dev_queue_xmit</span>
<span class="c">#    0xffff00005f10c300 0   ~/bin/ping:42701 4026531840 c00           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     qdisc_pkt_len_init</span>
<span class="c">#    0xffff00005f10c300 0   ~/bin/ping:42701 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     netdev_core_pick_tx</span>
<span class="c">#    0xffff00005f10c300 0   ~/bin/ping:42701 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     dev_qdisc_enqueue</span>
<span class="c">#    0xffff00005f10c300 0   ~/bin/ping:42701 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     __skb_get_hash</span>
<span class="c">#    0xffff00005f10c300 1   ~/sbin/sshd:6275 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     sch_direct_xmit</span>
<span class="c">#    0xffff00005f10c300 1   ~/sbin/sshd:6275 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     validate_xmit_skb_list</span>
<span class="c">#    0xffff00005f10c300 1   ~/sbin/sshd:6275 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     validate_xmit_skb</span>
<span class="c">#    0xffff00005f10c300 1   ~/sbin/sshd:6275 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     netif_skb_features</span>
<span class="c">#    0xffff00005f10c300 1   ~/sbin/sshd:6275 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     skb_network_protocol</span>
<span class="c">#    0xffff00005f10c300 1   ~/sbin/sshd:6275 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     validate_xmit_xfrm</span>
<span class="c">#    0xffff00005f10c300 1   ~/sbin/sshd:6275 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     dev_hard_start_xmit</span>
<span class="c">#    0xffff00005f10c300 1   ~/sbin/sshd:6275 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     skb_clone_tx_timestamp</span>
<span class="c">#    0xffff00005f10c300 1   ~/sbin/sshd:6275 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     napi_consume_skb</span>
<span class="c">#    0xffff00005f10c300 1   ~/sbin/sshd:6275 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     skb_release_head_state</span>
<span class="c">#    0xffff00005f10c300 1   ~/sbin/sshd:6275 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     sock_wfree</span>
<span class="c">#    0xffff00005f10c300 1   ~/sbin/sshd:6275 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     skb_release_data</span>
<span class="c">#    0xffff00005f10c300 1   ~/sbin/sshd:6275 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     skb_free_head</span>
<span class="c">#    0xffff00005f10c300 1   ~/sbin/sshd:6275 4026531840 300           eth0:2      0x0800 1500  98    10.0.2.15:0-&gt;8.8.8.8:0(icmp)     napi_skb_cache_put</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 0             eth0:2      0x0800 1500  84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     inet_gro_receive</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 0             eth0:2      0x0800 1500  84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     skb_defer_rx_timestamp</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 0             eth0:2      0x0800 1500  98    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     skb_ensure_writable</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 1500  84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     ip_rcv_core</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 1500  84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     nf_hook_slow</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 1500  84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     nf_ip_checksum</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 1500  84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     __skb_checksum_complete</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 1500  84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     ip_route_input_noref</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 1500  84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     ip_route_input_slow</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 1500  84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     fib_validate_source</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 1500  84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     __fib_validate_source</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 65536 84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     ip_local_deliver</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 65536 84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     nf_hook_slow</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 65536 84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     ip_local_deliver_finish</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 65536 64    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     ip_protocol_deliver_rcu</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 65536 64    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     raw_local_deliver</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 65536 64    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     raw_v4_input</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 65536 64    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     skb_clone</span>
<span class="c">#    0xffff00005f10c400 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 65536 64    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     raw_rcv</span>
<span class="c">#    0xffff00005f10c400 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 65536 64    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     skb_push</span>
<span class="c">#    0xffff00005f10c400 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 65536 84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     ipv4_pktinfo_prepare</span>
<span class="c">#    0xffff00005f10c400 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 1500  84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     sock_queue_rcv_skb_reason</span>
<span class="c">#    0xffff00005f10c400 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 1500  84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     sk_filter_trim_cap</span>
<span class="c">#    0xffff00005f10c400 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 1500  84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     security_sock_rcv_skb</span>
<span class="c">#    0xffff00005f10c400 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 1500  84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     apparmor_socket_sock_rcv_skb</span>
<span class="c">#    0xffff00005f10c400 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 1500  84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     __sock_queue_rcv_skb</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 65536 64    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     icmp_rcv</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 65536 56    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     ping_rcv</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 65536 56    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     skb_push</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 65536 64    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     kfree_skb_reason(SKB_DROP_REASON_NO_SOCKET)</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 65536 64    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     skb_release_head_state</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 1500  64    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     skb_release_data</span>
<span class="c">#    0xffff000007add600 0   &lt;empty&gt;:0        4026531840 300           eth0:2      0x0800 1500  64    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     kfree_skbmem</span>
<span class="c">#    0xffff00005f10c400 1   &lt;empty&gt;:42701    4026531840 300             0         0x0800 0     84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     __sock_recv_cmsgs</span>
<span class="c">#    0xffff00005f10c400 1   &lt;empty&gt;:42701    4026531840 300             0         0x0800 0     84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     __sock_recv_timestamp</span>
<span class="c">#    0xffff00005f10c400 1   &lt;empty&gt;:42701    4026531840 300             0         0x0800 0     84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     skb_free_datagram</span>
<span class="c">#    0xffff00005f10c400 1   &lt;empty&gt;:42701    4026531840 300             0         0x0800 0     84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     consume_skb</span>
<span class="c">#    0xffff00005f10c400 1   &lt;empty&gt;:42701    4026531840 300             0         0x0800 0     84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     skb_release_head_state</span>
<span class="c">#    0xffff00005f10c400 1   &lt;empty&gt;:42701    4026531840 300             0         0x0800 0     84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     sock_rfree</span>
<span class="c">#    0xffff00005f10c400 1   &lt;empty&gt;:42701    4026531840 300             0         0x0800 0     84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     skb_release_data</span>
<span class="c">#    0xffff00005f10c400 1   &lt;empty&gt;:42701    4026531840 300             0         0x0800 0     84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     skb_free_head</span>
<span class="c">#    0xffff00005f10c400 1   &lt;empty&gt;:42701    4026531840 300             0         0x0800 0     84    8.8.8.8:0-&gt;10.0.2.15:0(icmp)     kfree_skbmem</span>

<span class="c"># 다른 터미널에서 ping 명령어를 실행해보겠습니다.</span>
<span class="nv">$ </span>ping <span class="nt">-c</span> 1 8.8.8.8
<span class="c"># =&gt; PING 8.8.8.8 (8.8.8.8) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 8.8.8.8: icmp_seq=1 ttl=255 time=38.7 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 8.8.8.8 ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 38.740/38.740/38.740/0.000 ms</span>
</code></pre></div></div>

<ul>
  <li>ping 한번 보냈을 뿐인데 엄청난 량의 정보가 나왔습니다. 자세한 자료는 아래의 참고 자료를 참고해보시기 바랍니다.</li>
  <li>참고 자료
    <ul>
      <li><a href="https://nuguni.tistory.com/97">네트워크 패킷 추적 도구 - PWRU: Packet, Where Are You?</a></li>
      <li><a href="https://cilium.io/blog/2023/03/22/packet-where-are-you/">Going from Packet Where Aren’t You to pwru</a></li>
      <li><a href="https://medium.com/@Nikhil690/debugging-packet-drops-and-kernel-flows-with-pwru-fc03f3d479a4">PWRU: Debugging Packets and Kernel Flows</a></li>
    </ul>
  </li>
</ul>

<hr />

<h2 id="마치며">마치며</h2>

<p>이번 포스트에서는 Cilium의 관측성(Observability)을 위한 Hubble과 Prometheus/Grafana 연동, 각종 메트릭 그리고 PWRU를 설치하고 사용해보았습니다.
굉장히 많은 정보량에 압도되었습니다. 그래도 차근차근 따라가면서 실습해보니 Cilium의 관측성 기능을 이해하는데 큰 도움이 되었습니다.</p>

<p>관측성 도구들은 정말 강력하고 유용한 기능이지만 민감한 정보가 노출될 수 있기 때문에, 프로덕션 환경에서는 주의해서 사용해야 할 것 같습니다.
특히 끊임없이 새로운 기술이 나오고, 새로운 툴들이 나오고, 쉽게 설치하고 버전을 바꾸고 하는 현실에서
사소한 설정하나로 정보 유출이 발생할 수 있다는 점이 무섭기도 합니다. 
개발환경이나 내부에서 충분히 테스트하고 검증한 후에 프로덕션 환경에 적용하는 것이 중요할 것 같습니다.</p>

<p>이제 조금씩 회사 업무에도 Cilium을 적용하고 있어서 이번에 학습한 관측성 기능들을 활용해서
Cilium을 더 잘 이해하고, 문제를 해결하는데 도움이 될 것 같습니다.
이번 주도 스터디 준비해주신 모든 분들께 감사드립니다. :bow:</p>]]></content><author><name></name></author><category term="cilium" /><category term="kubernetes," /><category term="network," /><category term="linux," /><category term="cilium," /><category term="observability," /><category term="hubble," /><category term="prometheus," /><category term="grafana" /><summary type="html"><![CDATA[이번에는 Hubble, Prometheus, Grafana를 이용하여 Cilium의 Observability를 살펴보겠습니다.]]></summary></entry><entry><title type="html">[Cilium] 실습 환경 구성 및 Cilium 설치</title><link href="https://sweetlittlebird.github.io/posts/2025-07-20-Cilium-Week1/" rel="alternate" type="text/html" title="[Cilium] 실습 환경 구성 및 Cilium 설치" /><published>2025-07-20T00:10:18+09:00</published><updated>2025-07-20T00:10:18+09:00</updated><id>https://sweetlittlebird.github.io/posts/Cilium%20-%20Week1</id><content type="html" xml:base="https://sweetlittlebird.github.io/posts/2025-07-20-Cilium-Week1/"><![CDATA[<h2 id="들어가며">들어가며</h2>

<p>오랜만에 다시 스터디를 시작합니다.
이번에도 CloudNet@ 팀에서 진행하는 스터디로 고맙게도 스터디에 참여할 수 있게 되었습니다.
이번 스터디는 Cilium의 공식문서를 기반으로 실습해보는 스터디입니다.
Cilium 한가지 주제로 진행되는 만큼 깊고 진하게 학습할 수 있을것 같아 기대가 됩니다.</p>

<p>첫주차에는 실습 환경을 구성하고 Cilium을 설치하는 방법을 알아보겠습니다.</p>

<hr />

<h2 id="실습-환경-구성">실습 환경 구성</h2>

<h3 id="실습-환경-구성-준비">실습 환경 구성 준비</h3>

<p>저는 MacOS를 사용하고 있기때문에 homebrew를 이용하여 VirtualBox와 Vagrant를 설치하였습니다.</p>

<ul>
  <li>VirtualBox 설치</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install</span> <span class="nt">--cask</span> virtualbox
<span class="c"># =&gt; 🍺  virtualbox was successfully installed!</span>

<span class="nv">$ </span>VBoxManage <span class="nt">--version</span>
<span class="c"># =&gt; 7.1.10r169112</span>
</code></pre></div></div>

<ul>
  <li>Vagrant 설치</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install</span> <span class="nt">--cask</span> vagrant
<span class="c"># =&gt; 🍺  vagrant was successfully installed!</span>

<span class="nv">$ </span>vagrant version
<span class="c"># =&gt; Installed Version: 2.4.7</span>
<span class="c">#    Latest Version: 2.4.7</span>
<span class="c">#    </span>
<span class="c">#    You're running an up-to-date version of Vagrant!</span>
</code></pre></div></div>

<h3 id="실습-환경-소개">실습 환경 소개</h3>

<p>실습 환경을 도식화하면 다음과 같습니다.</p>

<p><img src="/assets/2025/cilium/w1/20250720_cilium_w1_1.png" alt="img.png" /></p>

<ul>
  <li>배포 가상 머신은 컨트롤플레인인 k8s-ctr, 워커노드 k8s-w1, k8s-w2로 구성되어 있습니다.
    <ul>
      <li>eth0 : 10.0.2.15 (모든 노드가 동일)</li>
      <li>eth1 : 192.168.10.100~102</li>
    </ul>
  </li>
  <li>초기 프로비저닝시 <code class="language-plaintext highlighter-rouge">kubeadm init</code>과 <code class="language-plaintext highlighter-rouge">join</code> 을 실행하여 클러스터를 구성하며, 초기에는 <strong>CNI가 설치되어 있지 않습니다</strong>.</li>
</ul>

<h3 id="실습-환경-배포-파일-작성">실습 환경 배포 파일 작성</h3>

<h4 id="vagrantfile"><strong>Vagrantfile</strong></h4>
<ul>
  <li>가상머신을 정의하고 부팅시 실행할 프로비저닝 설정을 합니다.</li>
</ul>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Variables</span>
<span class="no">K8SV</span> <span class="o">=</span> <span class="s1">'1.33.2-1.1'</span> <span class="c1"># Kubernetes Version : apt list -a kubelet , ex) 1.32.5-1.1</span>
<span class="no">CONTAINERDV</span> <span class="o">=</span> <span class="s1">'1.7.27-1'</span> <span class="c1"># Containerd Version : apt list -a containerd.io , ex) 1.6.33-1</span>
<span class="no">N</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1"># max number of worker nodes</span>

<span class="c1"># Base Image  https://portal.cloud.hashicorp.com/vagrant/discover/bento/ubuntu-24.04</span>
<span class="c1">## Rocky linux Image https://portal.cloud.hashicorp.com/vagrant/discover/rockylinux</span>
<span class="no">BOX_IMAGE</span> <span class="o">=</span> <span class="s2">"bento/ubuntu-24.04"</span>
<span class="no">BOX_VERSION</span> <span class="o">=</span> <span class="s2">"202502.21.0"</span>

<span class="no">Vagrant</span><span class="p">.</span><span class="nf">configure</span><span class="p">(</span><span class="s2">"2"</span><span class="p">)</span> <span class="k">do</span> <span class="o">|</span><span class="n">config</span><span class="o">|</span>
<span class="c1">#-ControlPlane Node</span>
    <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">define</span> <span class="s2">"k8s-ctr"</span> <span class="k">do</span> <span class="o">|</span><span class="n">subconfig</span><span class="o">|</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="no">BOX_IMAGE</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box_version</span> <span class="o">=</span> <span class="no">BOX_VERSION</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provider</span> <span class="s2">"virtualbox"</span> <span class="k">do</span> <span class="o">|</span><span class="n">vb</span><span class="o">|</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--groups"</span><span class="p">,</span> <span class="s2">"/Cilium-Lab"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--nicpromisc2"</span><span class="p">,</span> <span class="s2">"allow-all"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">name</span> <span class="o">=</span> <span class="s2">"k8s-ctr"</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">cpus</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">memory</span> <span class="o">=</span> <span class="mi">2048</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">linked_clone</span> <span class="o">=</span> <span class="kp">true</span>
      <span class="k">end</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">host_name</span> <span class="o">=</span> <span class="s2">"k8s-ctr"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.10.100"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="mi">60000</span><span class="p">,</span> <span class="ss">auto_correct: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">id: </span><span class="s2">"ssh"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">synced_folder</span> <span class="s2">"./"</span><span class="p">,</span> <span class="s2">"/vagrant"</span><span class="p">,</span> <span class="ss">disabled: </span><span class="kp">true</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"init_cfg.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">K8SV</span><span class="p">,</span> <span class="no">CONTAINERDV</span><span class="p">]</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"k8s-ctr.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">N</span> <span class="p">]</span>
    <span class="k">end</span>

<span class="c1">#-Worker Nodes Subnet1</span>
  <span class="p">(</span><span class="mi">1</span><span class="o">..</span><span class="no">N</span><span class="p">).</span><span class="nf">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">i</span><span class="o">|</span>
    <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">define</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span> <span class="k">do</span> <span class="o">|</span><span class="n">subconfig</span><span class="o">|</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="no">BOX_IMAGE</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box_version</span> <span class="o">=</span> <span class="no">BOX_VERSION</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provider</span> <span class="s2">"virtualbox"</span> <span class="k">do</span> <span class="o">|</span><span class="n">vb</span><span class="o">|</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--groups"</span><span class="p">,</span> <span class="s2">"/Cilium-Lab"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--nicpromisc2"</span><span class="p">,</span> <span class="s2">"allow-all"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">name</span> <span class="o">=</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">cpus</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">memory</span> <span class="o">=</span> <span class="mi">1536</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">linked_clone</span> <span class="o">=</span> <span class="kp">true</span>
      <span class="k">end</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">host_name</span> <span class="o">=</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.10.10</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="s2">"6000</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span> <span class="ss">auto_correct: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">id: </span><span class="s2">"ssh"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">synced_folder</span> <span class="s2">"./"</span><span class="p">,</span> <span class="s2">"/vagrant"</span><span class="p">,</span> <span class="ss">disabled: </span><span class="kp">true</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"init_cfg.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">K8SV</span><span class="p">,</span> <span class="no">CONTAINERDV</span><span class="p">]</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"k8s-w.sh"</span>
    <span class="k">end</span>
  <span class="k">end</span>
<span class="k">end</span>
</code></pre></div></div>

<h4 id="init_cfgsh"><strong>init_cfg.sh</strong></h4>
<ul>
  <li>프로비저닝시 vagrant가 실행할 초기 설정 스크립트입니다. arguments로 Kubernetes 버전과 Containerd 버전등을 받아서 설치합니다.</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>

<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config Start &lt;&lt;&lt;&lt;"</span>

<span class="nb">echo</span> <span class="s2">"[TASK 1] Setting Profile &amp; Change Timezone"</span>
<span class="nb">echo</span> <span class="s1">'alias vi=vim'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s2">"sudo su -"</span> <span class="o">&gt;&gt;</span> /home/vagrant/.bashrc
<span class="nb">ln</span> <span class="nt">-sf</span> /usr/share/zoneinfo/Asia/Seoul /etc/localtime

<span class="nb">echo</span> <span class="s2">"[TASK 2] Disable AppArmor"</span>
systemctl stop ufw <span class="o">&amp;&amp;</span> systemctl disable ufw <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
systemctl stop apparmor <span class="o">&amp;&amp;</span> systemctl disable apparmor <span class="o">&gt;</span>/dev/null 2&gt;&amp;1

<span class="nb">echo</span> <span class="s2">"[TASK 3] Disable and turn off SWAP"</span>
swapoff <span class="nt">-a</span> <span class="o">&amp;&amp;</span> <span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'/swap/s/^/#/'</span> /etc/fstab

<span class="nb">echo</span> <span class="s2">"[TASK 4] Install Packages"</span>
apt update <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
apt-get <span class="nb">install </span>apt-transport-https ca-certificates curl gpg <span class="nt">-y</span> <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1

<span class="c"># Download the public signing key for the Kubernetes package repositories.</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> <span class="nt">-m</span> 755 /etc/apt/keyrings
<span class="nv">K8SMMV</span><span class="o">=</span><span class="si">$(</span><span class="nb">echo</span> <span class="nv">$1</span> | <span class="nb">sed</span> <span class="nt">-En</span> <span class="s1">'s/^([0-9]+\.[0-9]+)\..*/\1/p'</span><span class="si">)</span>
curl <span class="nt">-fsSL</span> https://pkgs.k8s.io/core:/stable:/v<span class="nv">$K8SMMV</span>/deb/Release.key | <span class="nb">sudo </span>gpg <span class="nt">--dearmor</span> <span class="nt">-o</span> /etc/apt/keyrings/kubernetes-apt-keyring.gpg
<span class="nb">echo</span> <span class="s2">"deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v</span><span class="nv">$K8SMMV</span><span class="s2">/deb/ /"</span> <span class="o">&gt;&gt;</span> /etc/apt/sources.list.d/kubernetes.list
curl <span class="nt">-fsSL</span> https://download.docker.com/linux/ubuntu/gpg <span class="nt">-o</span> /etc/apt/keyrings/docker.asc
<span class="nb">echo</span> <span class="s2">"deb [arch=</span><span class="si">$(</span>dpkg <span class="nt">--print-architecture</span><span class="si">)</span><span class="s2"> signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu </span><span class="si">$(</span><span class="nb">.</span> /etc/os-release <span class="o">&amp;&amp;</span> <span class="nb">echo</span> <span class="s2">"</span><span class="nv">$VERSION_CODENAME</span><span class="s2">"</span><span class="si">)</span><span class="s2"> stable"</span> | <span class="nb">tee</span> /etc/apt/sources.list.d/docker.list <span class="o">&gt;</span> /dev/null

<span class="c"># packets traversing the bridge are processed by iptables for filtering</span>
<span class="nb">echo </span>1 <span class="o">&gt;</span> /proc/sys/net/ipv4/ip_forward
<span class="nb">echo</span> <span class="s2">"net.ipv4.ip_forward = 1"</span> <span class="o">&gt;&gt;</span> /etc/sysctl.d/k8s.conf

<span class="c"># enable br_netfilter for iptables </span>
modprobe br_netfilter
modprobe overlay
<span class="nb">echo</span> <span class="s2">"br_netfilter"</span> <span class="o">&gt;&gt;</span> /etc/modules-load.d/k8s.conf
<span class="nb">echo</span> <span class="s2">"overlay"</span> <span class="o">&gt;&gt;</span> /etc/modules-load.d/k8s.conf

<span class="nb">echo</span> <span class="s2">"[TASK 5] Install Kubernetes components (kubeadm, kubelet and kubectl)"</span>
<span class="c"># Update the apt package index, install kubelet, kubeadm and kubectl, and pin their version</span>
apt update <span class="o">&gt;</span>/dev/null 2&gt;&amp;1

<span class="c"># apt list -a kubelet ; apt list -a containerd.io</span>
apt-get <span class="nb">install</span> <span class="nt">-y</span> <span class="nv">kubelet</span><span class="o">=</span><span class="nv">$1</span> <span class="nv">kubectl</span><span class="o">=</span><span class="nv">$1</span> <span class="nv">kubeadm</span><span class="o">=</span><span class="nv">$1</span> containerd.io<span class="o">=</span><span class="nv">$2</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
apt-mark hold kubelet kubeadm kubectl <span class="o">&gt;</span>/dev/null 2&gt;&amp;1

<span class="c"># containerd configure to default and cgroup managed by systemd</span>
containerd config default <span class="o">&gt;</span> /etc/containerd/config.toml
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'s/SystemdCgroup = false/SystemdCgroup = true/g'</span> /etc/containerd/config.toml

<span class="c"># avoid WARN&amp;ERRO(default endpoints) when crictl run  </span>
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; /etc/crictl.yaml
runtime-endpoint: unix:///run/containerd/containerd.sock
image-endpoint: unix:///run/containerd/containerd.sock
</span><span class="no">EOF

</span><span class="c"># ready to install for k8s </span>
systemctl restart containerd <span class="o">&amp;&amp;</span> systemctl <span class="nb">enable </span>containerd
systemctl <span class="nb">enable</span> <span class="nt">--now</span> kubelet

<span class="nb">echo</span> <span class="s2">"[TASK 6] Install Packages &amp; Helm"</span>
apt-get <span class="nb">install</span> <span class="nt">-y</span> bridge-utils sshpass net-tools conntrack ngrep tcpdump ipset arping wireguard jq tree bash-completion unzip kubecolor <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
curl <span class="nt">-s</span> https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash <span class="o">&gt;</span>/dev/null 2&gt;&amp;1

<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div></div>

<h4 id="k8s-ctrsh"><strong>k8s-ctr.sh</strong></h4>
<ul>
  <li><code class="language-plaintext highlighter-rouge">kubeadm init</code>으로 컨트롤플레인을 설정하고, 편의를 위한 <code class="language-plaintext highlighter-rouge">k</code>, <code class="language-plaintext highlighter-rouge">kc</code> 등의 alias를 설정합니다.</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>

<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Controlplane config Start &lt;&lt;&lt;&lt;"</span>

<span class="nb">echo</span> <span class="s2">"[TASK 1] Initial Kubernetes"</span>
kubeadm init <span class="nt">--token</span> 123456.1234567890123456 <span class="nt">--token-ttl</span> 0 <span class="nt">--pod-network-cidr</span><span class="o">=</span>10.244.0.0/16 <span class="nt">--service-cidr</span><span class="o">=</span>10.96.0.0/16 <span class="nt">--apiserver-advertise-address</span><span class="o">=</span>192.168.10.100 <span class="nt">--cri-socket</span><span class="o">=</span>unix:///run/containerd/containerd.sock <span class="o">&gt;</span>/dev/null 2&gt;&amp;1


<span class="nb">echo</span> <span class="s2">"[TASK 2] Setting kube config file"</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> /root/.kube
<span class="nb">cp</span> <span class="nt">-i</span> /etc/kubernetes/admin.conf /root/.kube/config
<span class="nb">chown</span> <span class="si">$(</span><span class="nb">id</span> <span class="nt">-u</span><span class="si">)</span>:<span class="si">$(</span><span class="nb">id</span> <span class="nt">-g</span><span class="si">)</span> /root/.kube/config


<span class="nb">echo</span> <span class="s2">"[TASK 3] Source the completion"</span>
<span class="nb">echo</span> <span class="s1">'source &lt;(kubectl completion bash)'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'source &lt;(kubeadm completion bash)'</span> <span class="o">&gt;&gt;</span> /etc/profile


<span class="nb">echo</span> <span class="s2">"[TASK 4] Alias kubectl to k"</span>
<span class="nb">echo</span> <span class="s1">'alias k=kubectl'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'alias kc=kubecolor'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'complete -F __start_kubectl k'</span> <span class="o">&gt;&gt;</span> /etc/profile


<span class="nb">echo</span> <span class="s2">"[TASK 5] Install Kubectx &amp; Kubens"</span>
git clone https://github.com/ahmetb/kubectx /opt/kubectx <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">ln</span> <span class="nt">-s</span> /opt/kubectx/kubens /usr/local/bin/kubens
<span class="nb">ln</span> <span class="nt">-s</span> /opt/kubectx/kubectx /usr/local/bin/kubectx


<span class="nb">echo</span> <span class="s2">"[TASK 6] Install Kubeps &amp; Setting PS1"</span>
git clone https://github.com/jonmosco/kube-ps1.git /root/kube-ps1 <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="sh">"</span><span class="no">EOT</span><span class="sh">" &gt;&gt; /root/.bash_profile
source /root/kube-ps1/kube-ps1.sh
KUBE_PS1_SYMBOL_ENABLE=true
function get_cluster_short() {
  echo "</span><span class="nv">$1</span><span class="sh">" | cut -d . -f1
}
KUBE_PS1_CLUSTER_FUNCTION=get_cluster_short
KUBE_PS1_SUFFIX=') '
PS1='</span><span class="si">$(</span>kube_ps1<span class="si">)</span><span class="sh">'</span><span class="nv">$PS1</span><span class="sh">
</span><span class="no">EOT
</span>kubectl config rename-context <span class="s2">"kubernetes-admin@kubernetes"</span> <span class="s2">"HomeLab"</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1


<span class="nb">echo</span> <span class="s2">"[TASK 6] Install Kubeps &amp; Setting PS1"</span>
<span class="nb">echo</span> <span class="s2">"192.168.10.100 k8s-ctr"</span> <span class="o">&gt;&gt;</span> /etc/hosts
<span class="k">for</span> <span class="o">((</span> <span class="nv">i</span><span class="o">=</span>1<span class="p">;</span> i&lt;<span class="o">=</span><span class="nv">$1</span><span class="p">;</span> i++  <span class="o">))</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"192.168.10.10</span><span class="nv">$i</span><span class="s2"> k8s-w</span><span class="nv">$i</span><span class="s2">"</span> <span class="o">&gt;&gt;</span> /etc/hosts<span class="p">;</span> <span class="k">done


</span><span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Controlplane Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div></div>

<h4 id="k8s-wsh"><strong>k8s-w.sh</strong></h4>
<ul>
  <li>워커노드에서 <code class="language-plaintext highlighter-rouge">kubeadm join</code>을 실행하여 컨트롤플레인에 조인합니다.</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>

<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Node config Start &lt;&lt;&lt;&lt;"</span>

<span class="nb">echo</span> <span class="s2">"[TASK 1] K8S Controlplane Join"</span> 
kubeadm <span class="nb">join</span> <span class="nt">--token</span> 123456.1234567890123456 <span class="nt">--discovery-token-unsafe-skip-ca-verification</span> 192.168.10.100:6443  <span class="o">&gt;</span>/dev/null 2&gt;&amp;1

<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Node config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div></div>

<h3 id="실습-환경-배포">실습 환경 배포</h3>

<ul>
  <li>실습 환경 배포를 위한 파일이 준비되었으니 <code class="language-plaintext highlighter-rouge">vagrant up</code> 명령을 이용하여 가상 머신을 배포하겠습니다.</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>vagrant up
<span class="c"># =&gt; Bringing machine 'k8s-ctr' up with 'virtualbox' provider...</span>
<span class="c">#    Bringing machine 'k8s-w1' up with 'virtualbox' provider...</span>
<span class="c">#    Bringing machine 'k8s-w2' up with 'virtualbox' provider...</span>
<span class="c">#    ==&gt; k8s-ctr: Box 'bento/ubuntu-24.04' could not be found. Attempting to find and install...</span>
<span class="c">#        k8s-ctr: Box Provider: virtualbox</span>
<span class="c">#        k8s-ctr: Box Version: 202502.21.0</span>
<span class="c">#    ==&gt; k8s-ctr: Loading metadata for box 'bento/ubuntu-24.04'</span>
<span class="c">#        k8s-ctr: URL: https://vagrantcloud.com/api/v2/vagrant/bento/ubuntu-24.04</span>
<span class="c">#    ==&gt; k8s-ctr: Adding box 'bento/ubuntu-24.04' (v202502.21.0) for provider: virtualbox (arm64)</span>
<span class="c">#        k8s-ctr: Downloading: https://vagrantcloud.com/bento/boxes/ubuntu-24.04/versions/202502.21.0/providers/virtualbox/arm64/vagrant.box</span>
<span class="c">#    ==&gt; k8s-ctr: Successfully added box 'bento/ubuntu-24.04' (v202502.21.0) for 'virtualbox (arm64)'!</span>
<span class="c">#    ==&gt; k8s-ctr: Preparing master VM for linked clones...</span>
<span class="c">#    ...</span>
<span class="c">#        k8s-w2: &gt;&gt;&gt;&gt; K8S Node config End &lt;&lt;&lt;&lt;</span>
</code></pre></div></div>

<ul>
  <li>배포 후 각 노드에 ssh로 접속하여 ip를 확인해 보겠습니다.</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>ctr w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> vagrant ssh k8s-<span class="nv">$i</span> <span class="nt">-c</span> <span class="s1">'ip -c -4 addr show dev eth0'</span><span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span> <span class="c">#</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-ctr &lt;&lt;</span>
<span class="c">#    2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span>
<span class="c">#        altname enp0s8</span>
<span class="c">#        inet 10.0.2.15/24 metric 100 brd 10.0.2.255 scope global dynamic eth0</span>
<span class="c">#           valid_lft 85500sec preferred_lft 85500sec</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span>
<span class="c">#        altname enp0s8</span>
<span class="c">#        inet 10.0.2.15/24 metric 100 brd 10.0.2.255 scope global dynamic eth0</span>
<span class="c">#           valid_lft 85707sec preferred_lft 85707sec</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w2 &lt;&lt;</span>
<span class="c">#    2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span>
<span class="c">#        altname enp0s8</span>
<span class="c">#        inet 10.0.2.15/24 metric 100 brd 10.0.2.255 scope global dynamic eth0</span>
<span class="c">#           valid_lft 85781sec preferred_lft 85781sec</span>
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">k8s-ctr</code> 노드에 접속하여 기본 정보를 확인해 보겠습니다.</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>vagrant ssh k8s-ctr
<span class="nt">---</span>
<span class="c"># =&gt; Welcome to Ubuntu 24.04.2 LTS (GNU/Linux 6.8.0-53-generic aarch64)</span>
<span class="c">#    ...</span>
<span class="c">#    (⎈|HomeLab:N/A) root@k8s-ctr:~#</span>
<span class="nv">$ </span><span class="nb">whoami</span>
<span class="c"># =&gt; root</span>
<span class="nv">$ </span><span class="nb">pwd</span>
<span class="c"># =&gt; /root</span>
<span class="nv">$ </span>hostnamectl
<span class="c"># =&gt;  Static hostname: k8s-ctr</span>
<span class="c">#           Icon name: computer-vm</span>
<span class="c">#             Chassis: vm</span>
<span class="c">#          Machine ID: 3d6bd65db7dd43d392b2d5229abb5654</span>
<span class="c">#             Boot ID: 2d9ede04fd294425988e58c588dd201c</span>
<span class="c">#      Virtualization: qemu</span>
<span class="c">#    Operating System: Ubuntu 24.04.2 LTS</span>
<span class="c">#              Kernel: Linux 6.8.0-53-generic</span>
<span class="c">#        Architecture: arm64</span>
<span class="nv">$ </span>htop

<span class="nv">$ </span><span class="nb">cat</span> /etc/hosts
<span class="c"># =&gt; 127.0.0.1 localhost</span>
<span class="c">#    127.0.1.1 vagrant</span>
<span class="c">#    ...</span>
<span class="c">#    127.0.2.1 k8s-ctr k8s-ctr</span>
<span class="c">#    192.168.10.100 k8s-ctr</span>
<span class="c">#    192.168.10.101 k8s-w1</span>
<span class="c">#    192.168.10.102 k8s-w2</span>
<span class="nv">$ </span>ping <span class="nt">-c</span> 1 k8s-w1
<span class="c"># =&gt; PING k8s-w1 (192.168.10.101) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from k8s-w1 (192.168.10.101): icmp_seq=1 ttl=64 time=0.795 ms</span>
<span class="c">#    </span>
<span class="c">#    --- k8s-w1 ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 0.795/0.795/0.795/0.000 ms</span>
<span class="nv">$ </span>ping <span class="nt">-c</span> 1 k8s-w2
<span class="c"># =&gt; PING k8s-w2 (192.168.10.102) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from k8s-w2 (192.168.10.102): icmp_seq=1 ttl=64 time=1.20 ms</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-w1 <span class="nb">hostname</span>
<span class="c"># =&gt; k8s-w1</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-w2 <span class="nb">hostname</span>
<span class="c"># =&gt; k8s-w2</span>

<span class="c"># vagrant ssh 로 접속 시 tcp 연결 정보 : NAT Mode 10.0.2.2(GateWay)</span>
<span class="nv">$ </span>ss <span class="nt">-tnp</span> |grep sshd
<span class="c"># =&gt; ESTAB 0      0           [::ffff:10.0.2.15]:22          [::ffff:10.0.2.2]:63578 users:((&amp;quot;sshd&amp;quot;,pid=5141,fd=4),(&amp;quot;sshd&amp;quot;,pid=5094,fd=4))</span>

<span class="c"># nic 정보</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> addr
<span class="c"># =&gt; 1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span>
<span class="c">#       ...</span>
<span class="c">#    2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span>
<span class="c">#        link/ether 08:00:27:71:19:d8 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        altname enp0s8</span>
<span class="c">#        inet 10.0.2.15/24 metric 100 brd 10.0.2.255 scope global dynamic eth0</span>
<span class="c">#           valid_lft 82445sec preferred_lft 82445sec</span>
<span class="c">#    3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span>
<span class="c">#        link/ether 08:00:27:da:24:93 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        altname enp0s9</span>
<span class="c">#        inet 192.168.10.100/24 brd 192.168.10.255 scope global eth1</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>

<span class="c"># default 라우팅 정보 </span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.100</span>

<span class="c"># dns 서버 정보 : NAT Mode 10.0.2.3</span>
<span class="nv">$ </span>resolvectl
<span class="c"># =&gt; Global</span>
<span class="c">#             Protocols: -LLMNR -mDNS -DNSOverTLS DNSSEC=no/unsupported</span>
<span class="c">#      resolv.conf mode: stub</span>
<span class="c">#    </span>
<span class="c">#    Link 2 (eth0)</span>
<span class="c">#        Current Scopes: DNS</span>
<span class="c">#             Protocols: +DefaultRoute -LLMNR -mDNS -DNSOverTLS DNSSEC=no/unsupported</span>
<span class="c">#    Current DNS Server: 10.0.2.3</span>
<span class="c">#           DNS Servers: 10.0.2.3</span>
<span class="c">#    </span>
<span class="c">#    Link 3 (eth1)</span>
<span class="c">#        Current Scopes: none</span>
<span class="c">#             Protocols: -DefaultRoute -LLMNR -mDNS -DNSOverTLS DNSSEC=no/unsupported</span>
<span class="nv">$ </span><span class="nb">exit</span>
<span class="nt">---</span>
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">k8s-ctr</code> k8s 정보 확인</li>
</ul>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 클러스터 정보 확인</span>
<span class="nv">$ </span>kubectl cluster-info
<span class="c"># =&gt; Kubernetes control plane is running at https://192.168.10.100:6443</span>
<span class="c">#    CoreDNS is running at https://192.168.10.100:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</span>
<span class="c">#    </span>
<span class="c">#    To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.</span>

<span class="c"># 노드 정보 : 상태, INTERNAL-IP 확인</span>
<span class="nv">$ </span>kubectl get node <span class="nt">-owide</span>
<span class="c"># =&gt; NAME      STATUS     ROLES           AGE   VERSION   INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION     CONTAINER-RUNTIME</span>
<span class="c">#    k8s-ctr   NotReady   control-plane   2d    v1.33.2   192.168.10.100   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>
<span class="c">#    k8s-w1    NotReady   &lt;none&gt;          2d    v1.33.2   10.0.2.15        &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>
<span class="c">#    k8s-w2    NotReady   &lt;none&gt;          2d    v1.33.2   10.0.2.15        &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>

<span class="c"># 파드 정보 : 상태, 파드 IP 확인 - kube-proxy 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-A</span> <span class="nt">-owide</span>
<span class="c"># =&gt; NAMESPACE     NAME                              READY   STATUS    RESTARTS      AGE   IP               NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-79mbb          0/1     Pending   0             2d    &lt;none&gt;           &lt;none&gt;    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-rtx95          0/1     Pending   0             2d    &lt;none&gt;           &lt;none&gt;    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   etcd-k8s-ctr                      1/1     Running   1 (12m ago)   2d    192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-apiserver-k8s-ctr            1/1     Running   1 (12m ago)   2d    192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-controller-manager-k8s-ctr   1/1     Running   1 (12m ago)   2d    192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-proxy-hdffr                  1/1     Running   1 (11m ago)   2d    10.0.2.15        k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-proxy-r96sz                  1/1     Running   1 (12m ago)   2d    192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-proxy-swgmb                  1/1     Running   1 (11m ago)   2d    10.0.2.15        k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-scheduler-k8s-ctr            1/1     Running   1 (12m ago)   2d    192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>

<span class="c"># 단축어 확인(kc = kubecolor) &amp; coredns 파드 상태 확인</span>
<span class="nv">$ </span>k  describe pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>kube-dns
<span class="c"># =&gt; Name:                 coredns-674b8bbfcf-79mbb</span>
<span class="c">#    Namespace:            kube-system</span>
<span class="c">#    Priority:             2000000000</span>
<span class="c">#    Priority Class Name:  system-cluster-critical</span>
<span class="c">#    Service Account:      coredns</span>
<span class="c">#    Node:                 &lt;none&gt;</span>
<span class="c">#    Labels:               k8s-app=kube-dns</span>
<span class="c">#                          pod-template-hash=674b8bbfcf</span>
<span class="c">#    Annotations:          &lt;none&gt;</span>
<span class="c">#    Status:               Pending</span>
<span class="c">#    IP:</span>
<span class="c">#    IPs:                  &lt;none&gt;</span>
<span class="c">#    Controlled By:        ReplicaSet/coredns-674b8bbfcf</span>
<span class="c">#    Containers:</span>
<span class="c">#      coredns:</span>
<span class="c">#        Image:       registry.k8s.io/coredns/coredns:v1.12.0</span>
<span class="c">#        Ports:       53/UDP, 53/TCP, 9153/TCP</span>
<span class="c">#        Host Ports:  0/UDP, 0/TCP, 0/TCP</span>
<span class="c">#        Args:</span>
<span class="c">#          -conf</span>
<span class="c">#          /etc/coredns/Corefile</span>
<span class="c">#        Limits:</span>
<span class="c">#          memory:  170Mi</span>
<span class="c">#        Requests:</span>
<span class="c">#          cpu:        100m</span>
<span class="c">#          memory:     70Mi</span>
<span class="c">#        Liveness:     http-get http://:8080/health delay=60s timeout=5s period=10s #success=1 #failure=5</span>
<span class="c">#        Readiness:    http-get http://:8181/ready delay=0s timeout=1s period=10s #success=1 #failure=3</span>
<span class="c">#        Environment:  &lt;none&gt;</span>
<span class="c">#        Mounts:</span>
<span class="c">#          /etc/coredns from config-volume (ro)</span>
<span class="c">#          /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-vrqlj (ro)</span>
<span class="c">#    Conditions:</span>
<span class="c">#      Type           Status</span>
<span class="c">#      PodScheduled   False</span>
<span class="c">#    Volumes:</span>
<span class="c">#      config-volume:</span>
<span class="c">#        Type:      ConfigMap (a volume populated by a ConfigMap)</span>
<span class="c">#        Name:      coredns</span>
<span class="c">#        Optional:  false</span>
<span class="c">#      kube-api-access-vrqlj:</span>
<span class="c">#        Type:                    Projected (a volume that contains injected data from multiple sources)</span>
<span class="c">#        TokenExpirationSeconds:  3607</span>
<span class="c">#        ConfigMapName:           kube-root-ca.crt</span>
<span class="c">#        Optional:                false</span>
<span class="c">#        DownwardAPI:             true</span>
<span class="c">#    QoS Class:                   Burstable</span>
<span class="c">#    Node-Selectors:              kubernetes.io/os=linux</span>
<span class="c">#    Tolerations:                 CriticalAddonsOnly op=Exists</span>
<span class="c">#                                 node-role.kubernetes.io/control-plane:NoSchedule</span>
<span class="c">#                                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s</span>
<span class="c">#                                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s</span>
<span class="c">#    Events:</span>
<span class="c">#      Type     Reason            Age                  From               Message</span>
<span class="c">#      ----     ------            ----                 ----               -------</span>
<span class="c">#      Warning  FailedScheduling  7m18s (x2 over 12m)  default-scheduler  0/3 nodes are available: 3 node(s) had untolerated taint {node.kubernetes.io/not-ready: }. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.</span>
<span class="c">#      Warning  FailedScheduling  47h(x12 over 2d)    default-scheduler  0/3 nodes are available: 3 node(s) had untolerated taint {node.kubernetes.io/not-ready: }. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>kc describe pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>kube-dns
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">k8s-ctr</code> INTERNAL-IP 변경 설정</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> /var/lib/kubelet/kubeadm-flags.env
<span class="c"># =&gt; KUBELET_KUBEADM_ARGS="--container-runtime-endpoint=unix:///run/containerd/containerd.sock --pod-infra-container-image=registry.k8s.io/pause:3.10"</span>

<span class="c"># INTERNAL-IP 변경 설정</span>
<span class="nv">$ NODEIP</span><span class="o">=</span><span class="si">$(</span>ip <span class="nt">-4</span> addr show eth1 | <span class="nb">grep</span> <span class="nt">-oP</span> <span class="s1">'(?&lt;=inet\s)\d+(\.\d+){3}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/^</span><span class="se">\(</span><span class="s2">KUBELET_KUBEADM_ARGS=</span><span class="se">\"\)</span><span class="s2">/</span><span class="se">\1</span><span class="s2">--node-ip=</span><span class="k">${</span><span class="nv">NODEIP</span><span class="k">}</span><span class="s2"> /"</span> /var/lib/kubelet/kubeadm-flags.env
<span class="nv">$ </span>systemctl daemon-reexec <span class="o">&amp;&amp;</span> systemctl restart kubelet

<span class="nv">$ </span><span class="nb">cat</span> /var/lib/kubelet/kubeadm-flags.env
<span class="c"># =&gt; KUBELET_KUBEADM_ARGS="--node-ip=192.168.10.100 --container-runtime-endpoint=unix:///run/containerd/containerd.sock --pod-infra-container-image=registry.k8s.io/pause:3.10"</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get node <span class="nt">-owide</span>
<span class="c"># =&gt; NAME      STATUS     ROLES           AGE   VERSION   INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION     CONTAINER-RUNTIME</span>
<span class="c">#    k8s-ctr   NotReady   control-plane   2d    v1.33.2   192.168.10.100   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>
<span class="c">#    k8s-w1    NotReady   &lt;none&gt;          2d    v1.33.2   10.0.2.15        &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>
<span class="c">#    k8s-w2    NotReady   &lt;none&gt;          2d    v1.33.2   10.0.2.15        &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">k8s-w1</code>, <code class="language-plaintext highlighter-rouge">k8s-w2</code> 에도 위와 동일한 방법으로 INTERNAL-IP를 192.168.10.x로 변경합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">k8s-w1/w2</code> 설정 완료 후 INTERNAL-IP 확인</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl get node <span class="nt">-owide</span>
<span class="c"># =&gt; NAME      STATUS     ROLES           AGE   VERSION   INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION     CONTAINER-RUNTIME</span>
<span class="c">#    k8s-ctr   NotReady   control-plane   2d    v1.33.2   192.168.10.100   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>
<span class="c">#    k8s-w1    NotReady   &lt;none&gt;          2d    v1.33.2   192.168.10.101   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>
<span class="c">#    k8s-w2    NotReady   &lt;none&gt;          2d    v1.33.2   192.168.10.102   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>

<span class="nv">$ </span>kubectl get pod <span class="nt">-A</span> <span class="nt">-owide</span>
<span class="c"># =&gt; NAMESPACE     NAME                              READY   STATUS    RESTARTS      AGE   IP               NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-79mbb          0/1     Pending   0             2d    &lt;none&gt;           &lt;none&gt;    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-rtx95          0/1     Pending   0             2d    &lt;none&gt;           &lt;none&gt;    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   etcd-k8s-ctr                      1/1     Running   1 (27m ago)   2d    192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-apiserver-k8s-ctr            1/1     Running   1 (27m ago)   2d    192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-controller-manager-k8s-ctr   1/1     Running   1 (27m ago)   2d    192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-proxy-hdffr                  1/1     Running   1 (26m ago)   2d    192.168.10.101   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-proxy-r96sz                  1/1     Running   1 (27m ago)   2d    192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-proxy-swgmb                  1/1     Running   1 (26m ago)   2d    192.168.10.102   k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-scheduler-k8s-ctr            1/1     Running   1 (27m ago)   2d    192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
</code></pre></div></div>

<ul>
  <li><code class="language-plaintext highlighter-rouge">k8s-ctr</code> static pod의 IP 변경 설정</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>tree /etc/kubernetes/manifests
<span class="c"># =&gt; /etc/kubernetes/manifests</span>
<span class="c">#    ├── etcd.yaml</span>
<span class="c">#    ├── kube-apiserver.yaml</span>
<span class="c">#    ├── kube-controller-manager.yaml</span>
<span class="c">#    └── kube-scheduler.yaml</span>

<span class="c"># etcd 정보 확인</span>
<span class="nv">$ </span><span class="nb">cat</span> /etc/kubernetes/manifests/etcd.yaml
<span class="c"># =&gt;   ...</span>
<span class="c">#      volumes:</span>
<span class="c">#      - hostPath:</span>
<span class="c">#          path: /etc/kubernetes/pki/etcd</span>
<span class="c">#          type: DirectoryOrCreate</span>
<span class="c">#        name: etcd-certs</span>
<span class="c">#      - hostPath:</span>
<span class="c">#          path: /var/lib/etcd</span>
<span class="c">#          type: DirectoryOrCreate</span>
<span class="c">#        name: etcd-data</span>
<span class="c">#      ...</span>

<span class="nv">$ </span>tree /var/lib/etcd/
<span class="c"># =&gt; /var/lib/etcd/</span>
<span class="c">#    └── member</span>
<span class="c">#        ├── snap</span>
<span class="c">#        │   ├── 0000000000000003-0000000000002711.snap</span>
<span class="c">#        │   └── db</span>
<span class="c">#        └── wal</span>
<span class="c">#            ├── 0000000000000000-0000000000000000.wal</span>
<span class="c">#            └── 0.tmp</span>

<span class="c"># k8s-ctr 재부팅</span>
<span class="nv">$ </span>reboot
</code></pre></div></div>

<hr />

<h2 id="flannel-cni">Flannel CNI</h2>

<h3 id="flannel-소개">Flannel 소개</h3>

<ul>
  <li>Flannel은 쿠버네티스의 네트워크 요구사항을 충족하는 가장 간단하고 사용하기 쉬운 오버레이 네트워크 플러그인입니다.</li>
  <li>Flannel은 가상 네트워크를 생성하여 파드 간 통신을 가능하게 하며, VXLAN, UDP, Host-GW 등 다양한 백엔드를 지원합니다. 이 중에서는 VXLAN 사용이 가장 권장됩니다.</li>
  <li>VXLAN(Virtual eXtensible Local Area Network)은 물리적인 네트워크 환경 위에 논리적인 가상 네트워크를 구성하는 기술로, UDP 8472 포트를 통해 노드 간 터널링 방식으로 통신합니다.</li>
</ul>

<p><img src="/assets/2025/cilium/w1/20250720_cilium_w1_2.png" alt="img.png" class="image-center" />
<em class="image-caption">Flannel 구조 (출처: 추가예정)</em></p>

<ul>
  <li>위 그림처럼 파드의 eth0 네트워크 인터페이스는 호스트 네임스페이스의 veth 인터페이스와 연결되고, veth는 cni0와 연결됩니다.</li>
  <li>같은 노드 내에서는 cni0 브릿지를 통해 파드 간 통신이 이루어지며, 다른 노드와의 통신은 VXLAN을 통해 처리됩니다.</li>
  <li>VXLAN 경로에서는 cni0 브릿지를 거쳐 flannel.1 인터페이스로 패킷이 전달되고, flannel.1은 호스트의 eth0을 통해 다른 노드로 전송합니다. 이때 <strong>flannel.1은 VTEP(Vxlan Tunnel End Point)</strong> 역할을 하며, 패킷을 캡슐화하여 대상 노드의 IP로 전송하고, 도착한 노드에서는 캡슐을 해제해 해당 파드로 전달합니다.</li>
  <li>각 노드는 파드에 할당할 수 있는 IP 네트워크 대역을 가지고 있으며, flannel을 통해 ETCD나 Kubernetes API에 전달된 정보를 바탕으로 모든 노드는 자신의 라우팅 테이블을 업데이트합니다. 이를 통해 서로 다른 노드의 파드끼리도 내부 IP 주소로 통신할 수 있습니다.</li>
</ul>

<h3 id="flannel-설치-및-확인">Flannel 설치 및 확인</h3>

<ul>
  <li>설치 전 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># IP 주소 범위 확인</span>
<span class="nv">$ </span>kubectl cluster-info dump | <span class="nb">grep</span> <span class="nt">-m</span> 2 <span class="nt">-E</span> <span class="s2">"cluster-cidr|service-cluster-ip-range"</span>
<span class="c"># =&gt;                             "--service-cluster-ip-range=10.96.0.0/16",</span>
<span class="c">#                                "--cluster-cidr=10.244.0.0/16",</span>

<span class="c"># coredns 파드 상태 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>kube-dns <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                       READY   STATUS    RESTARTS   AGE     IP       NODE     NOMINATED NODE   READINESS GATES</span>
<span class="c">#    coredns-674b8bbfcf-79mbb   0/1     &lt;span style="color: green;"&gt;Pending&lt;/span&gt;   0          2d14h   &lt;none&gt;   &lt;none&gt;   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    coredns-674b8bbfcf-rtx95   0/1     &lt;span style="color: green;"&gt;Pending&lt;/span&gt;   0          2d14h   &lt;none&gt;   &lt;none&gt;   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    &lt;span style="color: green;"&gt;👉 CNI가 설치되지 않아서 Pending 상태입니다&lt;/span&gt;</span>

<span class="c">#</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> <span class="nb">link</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 08:00:27:71:19:d8 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 08:00:27:da:24:93 brd ff:ff:ff:ff:ff:ff</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.100</span>
<span class="nv">$ </span>brctl show
<span class="c"># =&gt; &lt;span style="color: green;"&gt;없음&lt;/span&gt;</span>

<span class="nv">$ </span>ip <span class="nt">-c</span> addr
<span class="c"># =&gt; ...</span>
<span class="c">#    2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span>
<span class="c">#        link/ether 08:00:27:71:19:d8 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet 10.0.2.15/24 metric 100 brd 10.0.2.255 scope global dynamic eth0</span>
<span class="c">#           valid_lft 85957sec preferred_lft 85957sec</span>
<span class="c">#    3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span>
<span class="c">#        link/ether 08:00:27:da:24:93 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet 192.168.10.100/24 brd 192.168.10.255 scope global eth1</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="nv">$ </span>ifconfig | <span class="nb">grep</span> <span class="nt">-iEA1</span> <span class="s1">'eth[0-9]:'</span>
<span class="c"># =&gt; eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span>
<span class="c">#            inet 10.0.2.15  netmask 255.255.255.0  broadcast 10.0.2.255</span>
<span class="c">#    --</span>
<span class="c">#    eth1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span>
<span class="c">#            inet 192.168.10.100  netmask 255.255.255.0  broadcast 192.168.10.255</span>

<span class="c">#</span>
<span class="nv">$ </span>iptables-save
<span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> filter <span class="nt">-S</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> mangle <span class="nt">-S</span>

<span class="c"># flannel 설치 후 비교를 위해 설치 전의 iptables 설정을 저장합니다.</span>
<span class="nv">$ </span>iptables-save <span class="o">&gt;</span> iptables-before-flannel.txt

<span class="c">#</span>
<span class="nv">$ </span>tree /etc/cni/net.d/
<span class="c"># =&gt; /etc/cni/net.d/</span>
<span class="c">#    </span>
<span class="c">#    0 directories, 0 files</span>
</code></pre></div></div>

<ul>
  <li>Flannel 설치</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># helm에 의한 namespace 생성 오류 방지를 위해 kube-flannel 네임스페이스를 수동으로 생성합니다.</span>
<span class="nv">$ </span>kubectl create ns kube-flannel
<span class="c"># =&gt; namespace/kube-flannel created</span>
<span class="nv">$ </span>kubectl label <span class="nt">--overwrite</span> ns kube-flannel pod-security.kubernetes.io/enforce<span class="o">=</span>privileged
<span class="c"># =&gt; namespace/kube-flannel labeled</span>

<span class="nv">$ </span>helm repo add flannel https://flannel-io.github.io/flannel/
<span class="c"># =&gt; "flannel" has been added to your repositories</span>
<span class="nv">$ </span>helm repo list
<span class="c"># =&gt; NAME    URL</span>
<span class="c">#    flannel https://flannel-io.github.io/flannel/</span>

<span class="nv">$ </span>helm search repo flannel
<span class="c"># =&gt; NAME            CHART VERSION   APP VERSION     DESCRIPTION</span>
<span class="c">#    flannel/flannel v0.27.1         v0.27.1         Install Flannel Network Plugin.</span>
<span class="nv">$ </span>helm show values flannel/flannel
<span class="c"># =&gt; ...</span>
<span class="c">#    podCidr: "10.244.0.0/16"</span>
<span class="c">#    ...</span>
<span class="c">#      cniBinDir: "/opt/cni/bin"</span>
<span class="c">#      cniConfDir: "/etc/cni/net.d"</span>
<span class="c">#      skipCNIConfigInstallation: false</span>
<span class="c">#      enableNFTables: false</span>
<span class="c">#      args:</span>
<span class="c">#      - "--ip-masq"</span>
<span class="c">#      - "--kube-subnet-mgr"</span>
<span class="c">#      backend: "vxlan"</span>
<span class="c">#    ...</span>

<span class="c"># k8s 관련 트래픽 통신 동작하는 nic 지정</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> &gt; flannel-values.yaml
podCidr: "10.244.0.0/16"

flannel:
  args:
  - "--ip-masq"
  - "--kube-subnet-mgr"
  - "--iface=eth1"  
</span><span class="no">EOF

</span><span class="c"># helm 설치</span>
<span class="nv">$ </span>helm <span class="nb">install </span>flannel <span class="nt">--namespace</span> kube-flannel flannel/flannel <span class="nt">-f</span> flannel-values.yaml
<span class="c"># =&gt; NAME: flannel</span>
<span class="c">#    LAST DEPLOYED: Mon Jan 19 13:52:04 2025</span>
<span class="c">#    NAMESPACE: kube-flannel</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 1</span>
<span class="c">#    TEST SUITE: None</span>
<span class="nv">$ </span>helm list <span class="nt">-A</span>
<span class="c"># =&gt; NAME    NAMESPACE       REVISION        UPDATED                                 STATUS          CHART           APP VERSION</span>
<span class="c">#    flannel kube-flannel    1               2025-01-19 13:52:04.427781204 +0900 KST deployed        flannel-v0.27.1 v0.27.1</span>

<span class="c"># 확인 : install-cni-plugin, install-cni</span>
<span class="nv">$ </span>kc describe pod <span class="nt">-n</span> kube-flannel <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>flannel
<span class="c"># =&gt; Name:                 kube-flannel-ds-5fm6l</span>
<span class="c">#    Namespace:            kube-flannel</span>
<span class="c">#    Priority:             2000001000</span>
<span class="c">#    Priority Class Name:  system-node-critical</span>
<span class="c">#    Service Account:      flannel</span>
<span class="c">#    Node:                 &lt;span style="color: green;"&gt;k8s-w1/192.168.10.101&lt;/span&gt;</span>
<span class="c">#    Start Time:           Sat, 19 Jul 2025 13:52:06 +0900</span>
<span class="c">#    Labels:               app=flannel</span>
<span class="c">#                          controller-revision-hash=66c5c78475</span>
<span class="c">#                          pod-template-generation=1</span>
<span class="c">#                          tier=node</span>
<span class="c">#    Annotations:          &lt;none&gt;</span>
<span class="c">#    Status:               Running</span>
<span class="c">#    IP:                   192.168.10.101</span>
<span class="c">#    IPs:</span>
<span class="c">#      IP:           192.168.10.101</span>
<span class="c">#    Controlled By:  DaemonSet/kube-flannel-ds</span>
<span class="c">#    Init Containers:</span>
<span class="c">#      install-cni-plugin:</span>
<span class="c">#      ...</span>
<span class="c">#      install-cni:</span>
<span class="c">#      ....</span>
<span class="c">#    Containers:</span>
<span class="c">#      kube-flannel:</span>
<span class="c">#        Container ID:  containerd://c6a1e24ae6193491289908c4b10a8ce6f9a36e000114aaf61dc60da43bdc50ca</span>
<span class="c">#        Image:         ghcr.io/flannel-io/flannel:v0.27.1</span>
<span class="c">#        Image ID:      ghcr.io/flannel-io/flannel@sha256:0c95c822b690f83dc827189d691015f92ab7e249e238876b56442b580c492d85</span>
<span class="c">#        Port:          &lt;none&gt;</span>
<span class="c">#        Host Port:     &lt;none&gt;</span>
<span class="c">#    ...</span>
<span class="c">#    Name:                 kube-flannel-ds-dstmv</span>
<span class="c">#    Namespace:            kube-flannel</span>
<span class="c">#    Priority:             2000001000</span>
<span class="c">#    Priority Class Name:  system-node-critical</span>
<span class="c">#    Service Account:      flannel</span>
<span class="c">#    Node:                 &lt;span style="color: green;"&gt;k8s-w2/192.168.10.102&lt;/span&gt;</span>
<span class="c">#    Start Time:           Sat, 19 Jul 2025 13:52:05 +0900</span>
<span class="c">#    ...</span>
<span class="c">#    IP:                   192.168.10.102</span>
<span class="c">#    ...</span>
<span class="c">#    Name:                 kube-flannel-ds-lsf7h</span>
<span class="c">#    Namespace:            kube-flannel</span>
<span class="c">#    Priority:             2000001000</span>
<span class="c">#    Priority Class Name:  system-node-critical</span>
<span class="c">#    Service Account:      flannel</span>
<span class="c">#    Node:                 &lt;span style="color: green;"&gt;k8s-ctr/192.168.10.100&lt;/span&gt;</span>
<span class="c">#    Start Time:           Sat, 19 Jul 2025 13:52:04 +0900</span>
<span class="c">#    Labels:               app=flannel</span>
<span class="c">#                          controller-revision-hash=66c5c78475</span>
<span class="c">#                          pod-template-generation=1</span>
<span class="c">#                          tier=node</span>
<span class="c">#    Annotations:          &lt;none&gt;</span>
<span class="c">#    Status:               Running</span>
<span class="c">#    IP:                   192.168.10.100</span>
<span class="c">#    ...</span>

<span class="nv">$ </span>tree /opt/cni/bin/ <span class="c"># flannel</span>
<span class="c"># =&gt; /opt/cni/bin/</span>
<span class="c">#    ├── bandwidth</span>
<span class="c">#    ├── bridge</span>
<span class="c">#    ├── dhcp</span>
<span class="c">#    ├── dummy</span>
<span class="c">#    ├── firewall</span>
<span class="c">#    ├── flannel</span>
<span class="c">#    ├── host-device</span>
<span class="c">#    ├── host-local</span>
<span class="c">#    ├── ipvlan</span>
<span class="c">#    ├── LICENSE</span>
<span class="c">#    ├── loopback</span>
<span class="c">#    ├── macvlan</span>
<span class="c">#    ├── portmap</span>
<span class="c">#    ├── ptp</span>
<span class="c">#    ├── README.md</span>
<span class="c">#    ├── sbr</span>
<span class="c">#    ├── static</span>
<span class="c">#    ├── tap</span>
<span class="c">#    ├── tuning</span>
<span class="c">#    ├── vlan</span>
<span class="c">#    └── vrf</span>
<span class="c">#    </span>
<span class="c">#    1 directory, 21 files</span>
<span class="nv">$ </span>tree /etc/cni/net.d/
<span class="c"># =&gt; /etc/cni/net.d/</span>
<span class="c">#    └── 10-flannel.conflist</span>
<span class="c">#    </span>
<span class="c">#    1 directory, 1 file</span>
<span class="nv">$ </span><span class="nb">cat</span> /etc/cni/net.d/10-flannel.conflist | jq
<span class="c"># =&gt; {</span>
<span class="c">#      "name": "cbr0",</span>
<span class="c">#      "cniVersion": "0.3.1",</span>
<span class="c">#      "plugins": [</span>
<span class="c">#        {</span>
<span class="c">#          "type": "flannel",</span>
<span class="c">#          "delegate": {</span>
<span class="c">#            "hairpinMode": true,</span>
<span class="c">#            "isDefaultGateway": true</span>
<span class="c">#          }</span>
<span class="c">#        },</span>
<span class="c">#        {</span>
<span class="c">#          "type": "portmap",</span>
<span class="c">#          "capabilities": {</span>
<span class="c">#            "portMappings": true</span>
<span class="c">#          }</span>
<span class="c">#        }</span>
<span class="c">#      ]</span>
<span class="c">#    }</span>
<span class="nv">$ </span>kc describe cm <span class="nt">-n</span> kube-flannel kube-flannel-cfg
<span class="c"># =&gt; ...</span>
<span class="c">#    net-conf.json:</span>
<span class="c">#    ----</span>
<span class="c">#    {</span>
<span class="c">#      "Network": "10.244.0.0/16",</span>
<span class="c">#      "Backend": {</span>
<span class="c">#        "Type": "vxlan"</span>
<span class="c">#      }</span>
<span class="c">#    }</span>

<span class="c"># 설치 전과 비교해보겠습니다.</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> <span class="nb">link</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 08:00:27:71:19:d8 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 08:00:27:da:24:93 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    &lt;span style="color: green;"&gt;4: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default&lt;/span&gt;</span>
<span class="c">#    &lt;span style="color: green;"&gt;    link/ether aa:3f:e5:cd:ae:92 brd ff:ff:ff:ff:ff:ff&lt;/span&gt;</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route | <span class="nb">grep </span>10.244.
<span class="c"># =&gt; 10.244.1.0/24 via 10.244.1.0 dev flannel.1 onlink</span>
<span class="c">#    10.244.2.0/24 via 10.244.2.0 dev flannel.1 onlink</span>

<span class="nv">$ </span>ping <span class="nt">-c</span> 1 10.244.1.0
<span class="c"># =&gt; PING 10.244.1.0 (10.244.1.0) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 10.244.1.0: icmp_seq=1 ttl=64 time=1.31 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 10.244.1.0 ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 1.314/1.314/1.314/0.000 ms</span>
<span class="nv">$ </span>ping <span class="nt">-c</span> 1 10.244.2.0
<span class="c"># =&gt; PING 10.244.2.0 (10.244.2.0) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 10.244.2.0: icmp_seq=1 ttl=64 time=1.31 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 10.244.2.0 ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 1.312/1.312/1.312/0.000 ms</span>

<span class="nv">$ </span>brctl show
<span class="nv">$ </span>iptables-save
<span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> filter <span class="nt">-S</span>
<span class="nv">$ </span>iptables-save <span class="o">&gt;</span> iptables-after-flannel.txt
<span class="c"># 설치 전과 후의 iptables 설정을 비교합니다.</span>
<span class="nv">$ </span>diff <span class="nt">-u</span> iptables-before-flannel.txt iptables-after-flannel.txt

<span class="c"># k8s-w1, k8s-w2 정보 확인</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> <span class="nb">link</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> route <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> brctl show <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
</code></pre></div></div>

<h3 id="샘플-애플리케이션-배포-및-확인">샘플 애플리케이션 배포 및 확인</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 샘플 애플리케이션 배포</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webpod
spec:
  replicas: 2
  selector:
    matchLabels:
      app: webpod
  template:
    metadata:
      labels:
        app: webpod
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - sample-app
            topologyKey: "kubernetes.io/hostname"
      containers:
      - name: webpod
        image: traefik/whoami
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: webpod
  labels:
    app: webpod
spec:
  selector:
    app: webpod
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
  type: ClusterIP
</span><span class="no">EOF
</span><span class="c"># =&gt; deployment.apps/webpod created</span>
<span class="c">#    service/webpod created</span>

<span class="c"># k8s-ctr 노드에 curl-pod 파드 배포</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: curl-pod
  labels:
    app: curl
spec:
  nodeName: k8s-ctr
  containers:
    - name: curl
      image: alpine/curl
      command: ["sleep", "36000"]
</span><span class="no">EOF
</span><span class="c"># =&gt; pod/curl-pod created</span>

<span class="c"># 컨트롤플레인 노드(k8s-ctr)에서 파드 확인</span>
<span class="nv">$ </span>crictl ps
<span class="c"># =&gt; CONTAINER     IMAGE         CREATED        STATE   NAME                    ATTEMPT POD ID        POD                               NAMESPACE</span>
<span class="c">#    ba7ddc59fa138 1fb7da88b3320 1 second ago   Running curl                    0       a87775d3d7098 &lt;span style="color: green;"&gt;curl-pod&lt;/span&gt;                          default</span>
<span class="c">#    2c095a0d795b7 83a2e3e54aa1e 19 minutes ago Running kube-flannel            0       49d7f057d7491 kube-flannel-ds-lsf7h             kube-flannel</span>
<span class="c">#    13ff95772dd16 738e99dbd7325 35 minutes ago Running kube-proxy              3       0ce95a5226767 kube-proxy-r96sz                  kube-system</span>
<span class="c">#    625a7ec089f93 c03972dff86ba 35 minutes ago Running kube-scheduler          3       7691ca47ac391 kube-scheduler-k8s-ctr            kube-system</span>
<span class="c">#    3b02267780926 ef439b94d49d4 35 minutes ago Running kube-controller-manager 3       232075758b77f kube-controller-manager-k8s-ctr   kube-system</span>
<span class="c">#    f956731d12744 31747a36ce712 35 minutes ago Running etcd                    3       7ac2514bac9cb etcd-k8s-ctr                      kube-system</span>
<span class="c">#    9f50506b3ca66 c0425f3fe3fbf 35 minutes ago Running kube-apiserver          3       d5246dd2d31b9 kube-apiserver-k8s-ctr            kube-system</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 curl-pod는 nodeName: 을 통해 컨트롤플레인 노드(k8s-ctr)에 배포되었습니다.&lt;/span&gt;</span>

<span class="c"># 워커 노드(k8s-w1, k8s-w2)에서 파드 확인</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>crictl ps <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; CONTAINER     IMAGE         CREATED        STATE   NAME                    ATTEMPT POD ID        POD                       NAMESPACE</span>
<span class="c">#    c934a221a4fec ab541801c8cc5 57 seconds ago Running webpod                  0       7323e0f4eced8 &lt;span style="color: green;"&gt;webpod-697b545f57-7j5vt&lt;/span&gt;   default</span>
<span class="c">#    c6a1e24ae6193 83a2e3e54aa1e 20 minutes ago Running kube-flannel            0       3a86bc505126a kube-flannel-ds-5fm6l     kube-flannel</span>
<span class="c">#    b55a66b5cd0a6 738e99dbd7325 35 minutes ago Running kube-proxy              2       8bc7a54488b35 kube-proxy-hdffr          kube-system</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w2 &lt;&lt;</span>
<span class="c">#    CONTAINER     IMAGE         CREATED        STATE   NAME                    ATTEMPT POD ID              POD                        NAMESPACE</span>
<span class="c">#    54658fa9cfc29 ab541801c8cc5 58 seconds ago Running webpod                  0       8dec7a5a7aed1 &lt;span style="color: green;"&gt;webpod-697b545f57-sdv4l&lt;/span&gt;    default</span>
<span class="c">#    9b2a414ee1acc f72407be9e08c 19 minutes ago Running coredns                 0       23071bf7a21e4 coredns-674b8bbfcf-rtx95   kube-system</span>
<span class="c">#    e1c86c4fa20fe f72407be9e08c 20 minutes ago Running coredns                 0       757397c6bcd8f coredns-674b8bbfcf-79mbb   kube-system</span>
<span class="c">#    eeac62c8beba7 83a2e3e54aa1e 20 minutes ago Running kube-flannel            0       1b4ba4f721424 kube-flannel-ds-dstmv      kube-flannel</span>
<span class="c">#    0a6112c11e948 738e99dbd7325 35 minutes ago Running kube-proxy              2       f9f19975aed04 kube-proxy-swgmb           kube-system</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 webpod는 별도로 nodeName: 을 지정하지 않았기 때문에 워커 노드(k8s-w1, k8s-w2)에 배포되었습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<ul>
  <li>확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 배포 확인</span>
<span class="nv">$ </span>kubectl get deploy,svc,ep webpod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                     READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES           SELECTOR</span>
<span class="c">#    deployment.apps/webpod   2/2     2            2           18m   webpod       traefik/whoami   app=webpod</span>
<span class="c">#    </span>
<span class="c">#    NAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE   SELECTOR</span>
<span class="c">#    service/webpod   ClusterIP   10.96.62.184   &lt;none&gt;        80/TCP    18m   app=webpod</span>
<span class="c">#    </span>
<span class="c">#    NAME               ENDPOINTS                     AGE</span>
<span class="c">#    endpoints/webpod   10.244.1.2:80,10.244.2.4:80   18m</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl api-resources | <span class="nb">grep</span> <span class="nt">-i</span> endpoint
<span class="c"># =&gt; endpoints                           ep           v1                                true         Endpoints</span>
<span class="c">#    endpointslices                                   discovery.k8s.io/v1               true         EndpointSlice</span>

<span class="nv">$ </span>kubectl get endpointslices <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>webpod
<span class="c"># =&gt; NAME           ADDRESSTYPE   PORTS   ENDPOINTS               AGE</span>
<span class="c">#    webpod-9pfs7   IPv4          80      10.244.2.4,10.244.1.2   18m</span>

<span class="c"># 배포 전과 비교해보겠습니다.</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> <span class="nb">link</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 08:00:27:71:19:d8 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 08:00:27:da:24:93 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    4: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default</span>
<span class="c">#        link/ether aa:3f:e5:cd:ae:92 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    5: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether b2:e2:a2:aa:4e:5c brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    &lt;span style="color: green;"&gt;6: veth0911be7c@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default qlen 1000&lt;/span&gt;</span>
<span class="c">#    &lt;span style="color: green;"&gt;    link/ether 6a:8b:92:5e:74:b3 brd ff:ff:ff:ff:ff:ff link-netns cni-15400ffe-d5f7-c6c2-78d9-dbbbc2f08db7&lt;/span&gt;</span>
<span class="nv">$ </span>brctl show
<span class="c"># =&gt; bridge name     bridge id               STP enabled     interfaces</span>
<span class="c">#    cni0            8000.b2e2a2aa4e5c       no              veth0911be7c</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 veth 인터페이스를 통해 파드와 연결된 cni0 브릿지가 생성되었습니다.&lt;/span&gt;</span>
<span class="nv">$ </span>iptables-save
<span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span>
<span class="nv">$ </span>iptables-save <span class="o">&gt;</span> iptables-after-deployment.txt
<span class="nv">$ </span>diff iptables-after-flannel.txt iptables-after-deployment.txt
<span class="c"># =&gt; ...</span>
<span class="c">#    62a63,64</span>
<span class="c">#    &gt; :KUBE-SEP-PQBQBGZJJ5FKN3TB - [0:0]</span>
<span class="c">#    &gt; :KUBE-SEP-R5LRHDMUTGTM635J - [0:0]</span>
<span class="c">#    66a69</span>
<span class="c">#    &gt; :KUBE-SVC-CNZCPOCNCNOROALA - [0:0]</span>
<span class="c">#    92a96,99</span>
<span class="c">#    &gt; -A KUBE-SEP-PQBQBGZJJ5FKN3TB -s 10.244.1.2/32 -m comment --comment "default/webpod" -j KUBE-MARK-MASQ</span>
<span class="c">#    &gt; -A KUBE-SEP-PQBQBGZJJ5FKN3TB -p tcp -m comment --comment "default/webpod" -m tcp -j DNAT --to-destination 10.244.1.2:80</span>
<span class="c">#    &gt; -A KUBE-SEP-R5LRHDMUTGTM635J -s 10.244.2.4/32 -m comment --comment "default/webpod" -j KUBE-MARK-MASQ</span>
<span class="c">#    &gt; -A KUBE-SEP-R5LRHDMUTGTM635J -p tcp -m comment --comment "default/webpod" -m tcp -j DNAT --to-destination 10.244.2.4:80</span>
<span class="c">#    98a106</span>
<span class="c">#    &gt; -A KUBE-SERVICES -d 10.96.62.184/32 -p tcp -m comment --comment "default/webpod cluster IP" -m tcp --dport 80 -j KUBE-SVC-CNZCPOCNCNOROALA</span>
<span class="c">#    103a112,114</span>
<span class="c">#    &gt; -A KUBE-SVC-CNZCPOCNCNOROALA ! -s 10.244.0.0/16 -d 10.96.62.184/32 -p tcp -m comment --comment "default/webpod cluster IP" -m tcp --dport 80 -j KUBE-MARK-MASQ</span>
<span class="c">#    &gt; -A KUBE-SVC-CNZCPOCNCNOROALA -m comment --comment "default/webpod -&gt; 10.244.1.2:80" -m statistic --mode random --probability 0.50000000000 -j KUBE-SEP-PQBQBGZJJ5FKN3TB</span>
<span class="c">#    &gt; -A KUBE-SVC-CNZCPOCNCNOROALA -m comment --comment "default/webpod -&gt; 10.244.2.4:80" -j KUBE-SEP-R5LRHDMUTGTM635J</span>
<span class="c">#    ...</span>

<span class="c"># k8s-w1, k8s-w2 정보 확인</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> <span class="nb">link</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    ...</span>
<span class="c">#    5: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 56:8b:b8:09:e1:a0 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    6: veth52205e86@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether ba:b1:d5:a8:5e:c6 brd ff:ff:ff:ff:ff:ff link-netns cni-42b4483c-e253-de82-a5c3-2cbf657cc6ed</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w2 &lt;&lt;</span>
<span class="c">#    ...</span>
<span class="c">#    5: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether b6:aa:16:04:b0:58 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    6: veth605dad7b@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 36:5a:70:ff:de:e9 brd ff:ff:ff:ff:ff:ff link-netns cni-e020c420-373a-900d-bf44-34fbe4622f7e</span>
<span class="c">#    7: veth002efe84@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether be:86:35:e2:1a:5d brd ff:ff:ff:ff:ff:ff link-netns cni-af271963-86ee-26b6-35b9-39173672cd1a</span>
<span class="c">#    8: veth1dce6530@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether fa:d9:af:04:69:e2 brd ff:ff:ff:ff:ff:ff link-netns cni-ca1eedc6-43ff-e346-318d-ba345e0ba532</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> route <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> brctl show <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
</code></pre></div></div>

<ul>
  <li>통신 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>webpod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                      READY   STATUS    RESTARTS   AGE   IP           NODE     NOMINATED NODE   READINESS GATES</span>
<span class="c">#    webpod-697b545f57-7j5vt   1/1     Running   0          24m   10.244.1.2   k8s-w1   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-697b545f57-sdv4l   1/1     Running   0          24m   10.244.2.4   k8s-w2   &lt;none&gt;           &lt;none&gt;</span>
<span class="nv">$ POD1IP</span><span class="o">=</span>10.244.1.2
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nv">$POD1IP</span>
<span class="c"># =&gt; Hostname: webpod-697b545f57-7j5vt</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: ::1</span>
<span class="c">#    IP: 10.244.1.2</span>
<span class="c">#    IP: fe80::dc28:1fff:fe46:abd0</span>
<span class="c">#    RemoteAddr: 10.244.0.2:46774</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: 10.244.1.2</span>
<span class="c">#    User-Agent: curl/8.14.1</span>
<span class="c">#    Accept: */*</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get svc,ep webpod
<span class="c"># =&gt; NAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE</span>
<span class="c">#    service/webpod   ClusterIP   10.96.62.184   &lt;none&gt;        80/TCP    25m</span>
<span class="c">#    </span>
<span class="c">#    NAME               ENDPOINTS                     AGE</span>
<span class="c">#    endpoints/webpod   10.244.1.2:80,10.244.2.4:80   25m</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl webpod
<span class="c"># =&gt; Hostname: webpod-697b545f57-7j5vt</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: ::1</span>
<span class="c">#    IP: 10.244.1.2</span>
<span class="c">#    IP: fe80::dc28:1fff:fe46:abd0</span>
<span class="c">#    RemoteAddr: 10.244.0.2:55684</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: webpod</span>
<span class="c">#    User-Agent: curl/8.14.1</span>
<span class="c">#    Accept: */*</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl webpod | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod-697b545f57-7j5vt</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s webpod | grep Hostname; sleep 1; done'</span>
<span class="c"># =&gt; Hostname: webpod-697b545f57-7j5vt</span>
<span class="c">#    Hostname: webpod-697b545f57-sdv4l</span>
<span class="c">#    Hostname: webpod-697b545f57-7j5vt</span>
<span class="c">#    ...</span>

<span class="c"># Service 동작 처리에 iptables 규칙 활용 확인 &gt;&gt; Service 가 100개 , 1000개 , 10000개 증가 되면???</span>
<span class="nv">$ </span>kubectl get svc webpod <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.spec.clusterIP}"</span>
<span class="c"># =&gt; 10.96.62.184</span>
<span class="nv">$ SVCIP</span><span class="o">=</span><span class="si">$(</span>kubectl get svc webpod <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.spec.clusterIP}"</span><span class="si">)</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span> | <span class="nb">grep</span> <span class="nv">$SVCIP</span>
<span class="c"># =&gt; -A KUBE-SERVICES -d 10.96.62.184/32 -p tcp -m comment --comment "default/webpod cluster IP" -m tcp --dport 80 -j KUBE-SVC-CNZCPOCNCNOROALA</span>
<span class="c">#    -A KUBE-SVC-CNZCPOCNCNOROALA ! -s 10.244.0.0/16 -d 10.96.62.184/32 -p tcp -m comment --comment "default/webpod cluster IP" -m tcp --dport 80 -j KUBE-MARK-MASQ</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span> | <span class="nb">grep</span> <span class="nv">$SVCIP</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    -A KUBE-SERVICES -d 10.96.62.184/32 -p tcp -m comment --comment "default/webpod cluster IP" -m tcp --dport 80 -j KUBE-SVC-CNZCPOCNCNOROALA</span>
<span class="c">#    -A KUBE-SVC-CNZCPOCNCNOROALA ! -s 10.244.0.0/16 -d 10.96.62.184/32 -p tcp -m comment --comment "default/webpod cluster IP" -m tcp --dport 80 -j KUBE-MARK-MASQ</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w2 &lt;&lt;</span>
<span class="c">#    -A KUBE-SERVICES -d 10.96.62.184/32 -p tcp -m comment --comment "default/webpod cluster IP" -m tcp --dport 80 -j KUBE-SVC-CNZCPOCNCNOROALA</span>
<span class="c">#    -A KUBE-SVC-CNZCPOCNCNOROALA ! -s 10.244.0.0/16 -d 10.96.62.184/32 -p tcp -m comment --comment "default/webpod cluster IP" -m tcp --dport 80 -j KUBE-MARK-MASQ</span>
</code></pre></div></div>

<ul>
  <li>대규모 환경에서 iptables 단점
    <ul>
      <li>kube-proxy에 의해 생성되는 iptables 규칙이 많아질수록 성능 저하가 발생할 수 있습니다.</li>
      <li>특히, 많은 수의 서비스가 있는 경우 iptables 규칙이 급격히 증가하여 성능에 영향을 미칠 수 있습니다.</li>
      <li>테스트 클러스터에서 3800개 노드의 19000개 파드를 배포한 결과, iptables 규칙이 24,000개 이상 생성되었습니다.</li>
      <li>이로 인한 성능 저하는 다음과 같습니다.
        <ul>
          <li>통신 연결시 1.2ms의 지연이 발생했습니다.</li>
          <li>클러스터의 iptables 규칙 갱신이 5분 이상 소요되었습니다.</li>
          <li>53%의 CPU 오버헤드가 발생했습니다.</li>
        </ul>
      </li>
      <li>이러한 문제로 인해 iptables를 사용하지 않고 eBPF을 사용하는 cilium 과 같은 CNI 플러그인이 대안으로 인기를 얻고 있습니다.</li>
    </ul>
  </li>
</ul>

<h2 id="cilium-cni">Cilium CNI</h2>

<h3 id="cilium-cni-소개">Cilium CNI 소개</h3>

<ul>
  <li><strong>Cilium</strong>은 기존의 복잡한 네트워크 스택을 <strong>eBPF</strong>를 통해 <strong>간소화</strong>하고, <strong>빠르게 처리</strong>할 수 있도록 하는 CNI 플러그인입니다.</li>
  <li>iptables 기반의 kube-proxy를 대체하여, 앞서 살펴본 기존의 Iptables 기반의 CNI 플러그인 들의 단점을 대부분 해결할 수 있습니다.</li>
</ul>

<p><img src="/assets/2024/kans-3th/w8/20241026_kans_w8_5.png" alt="img.png" class="image-center w-80" />
<em class="image-caption"><a href="https://isovalent.com/blog/post/migrating-from-metallb-to-cilium/">https://isovalent.com/blog/post/migrating-from-metallb-to-cilium/</a></em></p>

<ul>
  <li>Cilium eBPF는 추가적인 코드 수정이나 설정 변경없이, 리눅스 커널에서 동작하는 Bytecode를 자유롭게 프로그래밍하여 커널에 로딩시켜 동작이 가능합니다. <a href="https://www.youtube.com/watch?v=qsnR-s4XuGo&amp;t=1059s">링크</a>
<img src="/assets/2025/cilium/w1/20250720_cilium_w1_19.png" alt="img.png" /></li>
  <li>또한 eBPF는 모든 패킷을 가로채기 위해서 수신 NIC의 ingress TC(<a href="https://netbeez.net/blog/how-to-use-the-linux-traffic-control/">Traffic Control</a>) hooks를 사용할 수 있습니다.
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_6.png" alt="img.png" class="image-center w-60" />
<em class="image-caption">NIC의 TC Hooks에 eBPF 프로그램이 attach 된 예</em></li>
  <li>Cilium은 터널모드(VXLAN, GENEVE), 네이티브 라우팅 모드의 2가지 네트워크 모드를 제공합니다. <a href="https://docs.cilium.io/en/stable/network/concepts/routing/">Docs</a>
    <ul>
      <li><strong>터널모드</strong> : Cilium이 VXLAN(UDP 8472), GENEVE(UDP 6081) 인터페이스를 만들어서 이들을 통해 트래픽을 전달합니다. Encapsulation 모드라고도 합니다.</li>
      <li><strong>네이티브 라우팅 모드</strong> : Cilium가 패킷 전달을 위해 구성을 변경하지 않고, 외부에서 제공되는 패킷 전달 방법(클라우드 또는 BGP 라우팅등)을 사용합니다. Direct Routing 모드라고도 합니다.
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_7.png" alt="img.png" class="image-center w-80" />
<img src="/assets/2025/cilium/w1/20250720_cilium_w1_16.png" alt="img.png" /></li>
    </ul>
  </li>
  <li>2021년 10월 Cilium은 CNCF에 채택되었습니다. <a href="https://cilium.io/blog/2021/10/13/cilium-joins-cncf/">링크</a></li>
  <li>Googke GKE dataplane과 AWS EKS Anywhere에서 기본 CNI로 Cilium을 사용하고 있습니다. <a href="https://isovalent.com/blog/post/2021-09-aws-eks-anywhere-chooses-cilium/">링크</a></li>
  <li>Cilium은 Kube-Proxy를 100% 대체 가능합니다.
    <ul>
      <li>iptables를 거의 사용하지 않고도 동작하며, 이를 통해 성능을 향상시킬 수 있습니다.</li>
      <li>하지만 istio, FHRP, VRRP 등과 같이 iptables 기능을 활용하는 동작들은 이슈가 발생할 수 있으며, 차츰 해결해 나가고 있습니다.</li>
      <li>동작 소개 1 - <a href="https://www.youtube.com/watch?v=yKPNmhckJHY">Youtube</a></li>
      <li>동작 소개 2 : ByteDance 사례 - <a href="https://www.youtube.com/watch?v=cKPW67D7X10">Youtube</a>, <a href="https://kccncchn2025.sched.com/event/1x5hK/simplifying-the-networking-and-security-stack-with-cilium-hubble-and-tetragon-liyi-huang-isovalent-at-cisco-kaixi-fan-bytedance">CNCF</a></li>
    </ul>
  </li>
  <li>구성요소 - <a href="https://ssup2.github.io/blog-software/docs/theory-analysis/kubernetes-cilium-plugin/">링크</a>
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_8.png" alt="img.png" class="image-center w-80" />
<em class="image-caption">Cilium 아키텍쳐 - <a href="https://github.com/cilium/cilium">출처</a></em>
    <ul>
      <li>Cilium <strong>Operator</strong> : K8S 클러스터에 대한 한 번씩 처리해야 하는 작업을 관리합니다.</li>
      <li>Cilium <strong>Agent</strong> : 데몬셋으로 실행, K8S API 설정으로 부터 ‘네트워크 설정, 네트워크 정책, 서비스 부하분산, 모니터링’ 등을 수행하며, eBPF 프로그램을 관리합니다.</li>
      <li>Cilium <strong>Client</strong> (CLI) : Cilium 커멘드툴로 eBPF maps 에 직접 접속하여 상태를 확인할 수 있습니다.</li>
      <li><strong>Hubble</strong> : 네트워크와 보안 모니터링 플랫폼 역할을 하여, Server, Relay, Client, Graphical UI 로 구성되어 있습니다.</li>
      <li><strong>Data Store</strong> : Cilium Agent 간의 상태를 저장하고 전파하는 데이터 저장소, 2가지 종류 중 선택(K8S CRDs, Key-Value Store)할 수 있습니다.
<img src="/assets/2025/cilium/w1/20250720_cilium_w1_17.png" alt="img.png" />
<img src="/assets/2025/cilium/w1/20250720_cilium_w1_18.png" alt="img_1.png" /></li>
    </ul>
  </li>
</ul>

<h3 id="cilium-cni-설치">Cilium CNI 설치</h3>

<h4 id="cilium-시스템-요구-사항-확인---공식-문서">Cilium 시스템 요구 사항 확인 - <a href="https://docs.cilium.io/en/stable/operations/system_requirements/">공식 문서</a></h4>

<ul>
  <li>AMD64 또는 AArch64 CPU 아키텍처를 사용하는 호스트</li>
  <li><a href="https://docs.cilium.io/en/stable/operations/system_requirements/#linux-kernel">Linux 커널</a> 5.4 이상 또는 동등 버전(예: RHEL 8.6의 경우 4.18)
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">arch</span>
<span class="c"># =&gt; aarch64</span>
      
<span class="nv">$ </span><span class="nb">uname</span> <span class="nt">-r</span>
<span class="c"># =&gt; 6.8.0-53-generic</span>
</code></pre></div>    </div>
  </li>
  <li>커널 구성 옵션 활성화
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># [커널 구성 옵션] 기본 요구 사항 </span>
<span class="nv">$ </span><span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'CONFIG_BPF|CONFIG_BPF_SYSCALL|CONFIG_NET_CLS_BPF|CONFIG_BPF_JIT|CONFIG_NET_CLS_ACT|CONFIG_NET_SCH_INGRESS|CONFIG_CRYPTO_SHA1|CONFIG_CRYPTO_USER_API_HASH|CONFIG_CGROUPS|CONFIG_CGROUP_BPF|CONFIG_PERF_EVENTS|CONFIG_SCHEDSTATS'</span> /boot/config-<span class="si">$(</span><span class="nb">uname</span> <span class="nt">-r</span><span class="si">)</span>
<span class="c"># =&gt; CONFIG_BPF=y</span>
<span class="c">#    CONFIG_BPF_SYSCALL=y</span>
<span class="c">#    CONFIG_BPF_JIT=y</span>
<span class="c">#    CONFIG_BPF_JIT_ALWAYS_ON=y</span>
<span class="c">#    CONFIG_BPF_JIT_DEFAULT_ON=y</span>
<span class="c">#    CONFIG_BPF_UNPRIV_DEFAULT_OFF=y</span>
<span class="c">#    # CONFIG_BPF_PRELOAD is not set</span>
<span class="c">#    CONFIG_BPF_LSM=y</span>
<span class="c">#    CONFIG_CGROUPS=y</span>
<span class="c">#    CONFIG_CGROUP_BPF=y</span>
<span class="c">#    CONFIG_PERF_EVENTS=y</span>
<span class="c">#    CONFIG_NET_SCH_INGRESS=m</span>
<span class="c">#    CONFIG_NET_CLS_BPF=m</span>
<span class="c">#    CONFIG_NET_CLS_ACT=y</span>
<span class="c">#    CONFIG_BPF_STREAM_PARSER=y</span>
<span class="c">#    CONFIG_CRYPTO_SHA1=y</span>
<span class="c">#    CONFIG_CRYPTO_USER_API_HASH=m</span>
<span class="c">#    CONFIG_CRYPTO_SHA1_ARM64_CE=m</span>
<span class="c">#    CONFIG_SCHEDSTATS=y</span>
<span class="c">#    CONFIG_BPF_EVENTS=y</span>
<span class="c">#    CONFIG_BPF_KPROBE_OVERRIDE=y</span>
    
<span class="c"># [커널 구성 옵션] Requirements for Tunneling and Routing</span>
<span class="nv">$ </span><span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'CONFIG_VXLAN=y|CONFIG_VXLAN=m|CONFIG_GENEVE=y|CONFIG_GENEVE=m|CONFIG_FIB_RULES=y'</span> /boot/config-<span class="si">$(</span><span class="nb">uname</span> <span class="nt">-r</span><span class="si">)</span>
<span class="nv">$ CONFIG_FIB_RULES</span><span class="o">=</span>y <span class="c"># 커널에 내장됨</span>
<span class="nv">$ CONFIG_VXLAN</span><span class="o">=</span>m <span class="c"># 모듈로 컴파일됨 → 커널에 로드해서 사용</span>
<span class="nv">$ CONFIG_GENEVE</span><span class="o">=</span>m <span class="c"># 모듈로 컴파일됨 → 커널에 로드해서 사용</span>
    
<span class="c">## (참고) 커널 로드</span>
<span class="nv">$ </span>lsmod | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'vxlan|geneve'</span>
<span class="c"># =&gt; vxlan                 147456  0</span>
<span class="c">#    ip6_udp_tunnel         16384  1 vxlan</span>
<span class="c">#    udp_tunnel             36864  1 vxlan</span>
<span class="nv">$ </span>modprobe geneve
<span class="nv">$ </span>lsmod | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'vxlan|geneve'</span>
<span class="c"># =&gt; geneve                 45056  0</span>
<span class="c">#    vxlan                 147456  0</span>
<span class="c">#    ip6_udp_tunnel         16384  2 geneve,vxlan</span>
<span class="c">#    udp_tunnel             36864  2 geneve,vxlan</span>
    
<span class="c"># [커널 구성 옵션] Requirements for L7 and FQDN Policies</span>
<span class="nv">$ </span><span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'CONFIG_NETFILTER_XT_TARGET_TPROXY|CONFIG_NETFILTER_XT_TARGET_MARK|CONFIG_NETFILTER_XT_TARGET_CT|CONFIG_NETFILTER_XT_MATCH_MARK|CONFIG_NETFILTER_XT_MATCH_SOCKET'</span> /boot/config-<span class="si">$(</span><span class="nb">uname</span> <span class="nt">-r</span><span class="si">)</span>
<span class="c"># =&gt; CONFIG_NETFILTER_XT_TARGET_CT=m</span>
<span class="c">#    CONFIG_NETFILTER_XT_TARGET_MARK=m</span>
<span class="c">#    CONFIG_NETFILTER_XT_TARGET_TPROXY=m</span>
<span class="c">#    CONFIG_NETFILTER_XT_MATCH_MARK=m</span>
<span class="c">#    CONFIG_NETFILTER_XT_MATCH_SOCKET=m</span>
    
<span class="c"># [커널 구성 옵션] Requirements for Netkit Device Mode</span>
<span class="nv">$ </span><span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'CONFIG_NETKIT=y|CONFIG_NETKIT=m'</span> /boot/config-<span class="si">$(</span><span class="nb">uname</span> <span class="nt">-r</span><span class="si">)</span>
<span class="c"># =&gt; CONFIG_NETKIT=y</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>고급 기능 동작을 위한 최소 커널 버전 - <a href="https://docs.cilium.io/en/stable/operations/system_requirements/#required-kernel-versions-for-advanced-features">Docs</a></p>

    <table>
      <thead>
        <tr>
          <th><strong>Cilium Feature</strong></th>
          <th><strong>Minimum Kernel Version</strong></th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><a href="https://docs.cilium.io/en/stable/security/network/encryption-wireguard/#encryption-wg">WireGuard Transparent Encryption</a></td>
          <td>&gt;= 5.6</td>
        </tr>
        <tr>
          <td>Full support for <a href="https://docs.cilium.io/en/stable/network/kubernetes/kubeproxy-free/#session-affinity">Session Affinity</a></td>
          <td>&gt;= 5.7</td>
        </tr>
        <tr>
          <td>BPF-based proxy redirection</td>
          <td>&gt;= 5.7</td>
        </tr>
        <tr>
          <td>Socket-level LB bypass in pod netns</td>
          <td>&gt;= 5.7</td>
        </tr>
        <tr>
          <td>L3 devices</td>
          <td>&gt;= 5.8</td>
        </tr>
        <tr>
          <td><strong>BPF-based host routing</strong></td>
          <td><strong>&gt;= 5.10</strong></td>
        </tr>
        <tr>
          <td><a href="https://docs.cilium.io/en/stable/network/multicast/#enable-multicast">Multicast Support in Cilium (Beta)</a> (AMD64)</td>
          <td>&gt;= 5.10</td>
        </tr>
        <tr>
          <td>IPv6 BIG TCP support</td>
          <td>&gt;= 5.19</td>
        </tr>
        <tr>
          <td><a href="https://docs.cilium.io/en/stable/network/multicast/#enable-multicast">Multicast Support in Cilium (Beta)</a> (AArch64)</td>
          <td>&gt;= 6.0</td>
        </tr>
        <tr>
          <td><strong>IPv4 BIG TCP support</strong></td>
          <td><strong>&gt;= 6.3</strong></td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>Cilium 동작(Node 간)을 위한 방화벽 규칙 : 해당 포트 인/아웃 허용 필요 - <a href="https://docs.cilium.io/en/stable/operations/system_requirements/#firewall-rules">Docs</a></li>
  <li><strong>Mounted eBPF filesystem</strong> : 일부 배포판 마운트되어 있음, 혹은 Cilium 설치 시 마운트 시도 - <a href="https://docs.cilium.io/en/stable/operations/system_requirements/#mounted-ebpf-filesystem">Docs</a>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># eBPF 파일 시스템 마운트 확인</span>
<span class="nv">$ </span>mount | <span class="nb">grep</span> /sys/fs/bpf
<span class="c"># =&gt; bpf on /sys/fs/bpf type bpf (rw,nosuid,nodev,noexec,relatime,mode=700)</span>
</code></pre></div>    </div>
  </li>
  <li><strong>Privileges</strong> : Cilium 동작을 위해서 관리자 수준 권한 필요 - <a href="https://docs.cilium.io/en/stable/operations/system_requirements/#privileges">Docs</a>
    <ul>
      <li>cilium은 네트워킹 작업과 보안 정책을 구현하는 eBPF 프로그램 설치를 위해 리눅스 커널과 상호작용합니다. 
이 작업은 관리자 권한이 필요하며, cilium은 이를 위해 <code class="language-plaintext highlighter-rouge">CAP_SYS_ADMIN</code> 권한을 사용합니다. 또한 해당 권한은 cilium-agent 컨테이너에 부여되어야 합니다.</li>
      <li>가장 편리한 방법은 cilium-agent를 <code class="language-plaintext highlighter-rouge">root</code> 사용자나 privileged 모드로 실행하는 것입니다.</li>
      <li>cilium은 또한 호스트 네트워킹 네임스페이스에 대한 접근을 필요로 합니다. 따라서 cilium 파드는 호스트 네트워킹 네임스페이스에 직접 사용할 수 있도록 설정되어야 합니다.</li>
    </ul>
  </li>
</ul>

<h4 id="kube-proxy-제거">kube-proxy 제거</h4>

<ul>
  <li>기존 Flannel CNI를 제거합니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>helm uninstall <span class="nt">-n</span> kube-flannel flannel
<span class="c"># =&gt; release "flannel" uninstalled</span>
<span class="nv">$ </span>helm list <span class="nt">-A</span>
<span class="c"># =&gt; NAME    NAMESPACE       REVISION        UPDATED STATUS  CHART   APP VERSION</span>
  
<span class="c">#</span>
<span class="nv">$ </span>kubectl get all <span class="nt">-n</span> kube-flannel
<span class="nv">$ </span><span class="o">=&gt;</span> No resources found <span class="k">in </span>kube-flannel namespace.
<span class="nv">$ </span>kubectl delete ns kube-flannel
<span class="c"># =&gt; namespace "kube-flannel" deleted</span>
  
<span class="nv">$ </span>kubectl get pod <span class="nt">-A</span> <span class="nt">-owide</span>
</code></pre></div>    </div>
  </li>
  <li>k8s-ctr, k8s-w1, k8s-w2 모든 노드에서 아래 실행하여 flannel 관련된 인터페이스를 제거합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 제거 전 확인</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> <span class="nb">link</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    4: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default</span>
<span class="c">#        link/ether aa:3f:e5:cd:ae:92 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    5: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 1e:a9:44:a0:00:e1 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    6: veth322e34b5@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 8e:ea:40:c5:46:a7 brd ff:ff:ff:ff:ff:ff link-netns cni-62beabc5-97a9-e6cf-7f8f-bd4de413d33c</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> <span class="nb">link</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    ...</span>
<span class="c">#    4: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default</span>
<span class="c">#        link/ether c2:b2:62:af:c2:93 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    5: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 06:8a:4c:62:12:de brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    6: vethd8fb7cb1@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether e2:3f:03:c3:be:a2 brd ff:ff:ff:ff:ff:ff link-netns cni-81f15ae4-4a35-bce7-f755-657f3b8e39ea</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w2 &lt;&lt;</span>
<span class="c">#    ...</span>
<span class="c">#    4: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default</span>
<span class="c">#        link/ether 02:dd:56:d3:f6:3f brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    5: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 06:57:05:39:42:57 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    6: veth390f8e9e@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 5a:23:ff:ba:28:90 brd ff:ff:ff:ff:ff:ff link-netns cni-a27cec88-43c0-acf5-0bc5-f64e945bded3</span>
<span class="c">#    7: veth357a49b9@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether b6:6c:69:43:29:a6 brd ff:ff:ff:ff:ff:ff link-netns cni-36af9b39-bcb8-ad52-beb5-4b67475b404f</span>
<span class="c">#    8: vethf9bb5584@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 4a:7c:ab:42:e7:ca brd ff:ff:ff:ff:ff:ff link-netns cni-29e132ee-4860-b74c-c4f5-d5d27b341b83</span>

<span class="nv">$ </span>brctl show
<span class="c"># =&gt; bridge name     bridge id               STP enabled     interfaces</span>
<span class="c">#    cni0            8000.1ea944a000e1       no              veth322e34b5</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> brctl show <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    bridge name     bridge id               STP enabled     interfaces</span>
<span class="c">#    cni0            8000.068a4c6212de       no              vethd8fb7cb1</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w2 &lt;&lt;</span>
<span class="c">#    bridge name     bridge id               STP enabled     interfaces</span>
<span class="c">#    cni0            8000.065705394257       no              veth357a49b9</span>
<span class="c">#                                                            veth390f8e9e</span>
<span class="c">#                                                            vethf9bb5584</span>

<span class="nv">$ </span>ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.244.0.0/24 dev cni0 proto kernel scope link src 10.244.0.1</span>
<span class="c">#    10.244.1.0/24 via 10.244.1.0 dev flannel.1 onlink</span>
<span class="c">#    10.244.2.0/24 via 10.244.2.0 dev flannel.1 onlink</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.100</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> route <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.244.0.0/24 via 10.244.0.0 dev flannel.1 onlink</span>
<span class="c">#    10.244.1.0/24 dev cni0 proto kernel scope link src 10.244.1.1</span>
<span class="c">#    10.244.2.0/24 via 10.244.2.0 dev flannel.1 onlink</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.101</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w2 &lt;&lt;</span>
<span class="c">#    default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.244.0.0/24 via 10.244.0.0 dev flannel.1 onlink</span>
<span class="c">#    10.244.1.0/24 via 10.244.1.0 dev flannel.1 onlink</span>
<span class="c">#    10.244.2.0/24 dev cni0 proto kernel scope link src 10.244.2.1</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.102</span>

<span class="c"># vnic 제거</span>
<span class="nv">$ </span>ip <span class="nb">link </span>del flannel.1
<span class="nv">$ </span>ip <span class="nb">link </span>del cni0

<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>ip <span class="nb">link </span>del flannel.1 <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>ip <span class="nb">link </span>del cni0 <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>

<span class="c"># 제거 확인</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> <span class="nb">link</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    6: veth322e34b5@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 8e:ea:40:c5:46:a7 brd ff:ff:ff:ff:ff:ff link-netns cni-62beabc5-97a9-e6cf-7f8f-bd4de413d33c</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 flannel.1과 cni0가 삭제되었습니다.&lt;/span&gt;</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> <span class="nb">link</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>

<span class="nv">$ </span>brctl show
<span class="c"># =&gt; &lt;span style="color: green;"&gt;없음&lt;/span&gt;</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> brctl show <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    &gt;&gt; node : k8s-w2 &lt;&lt;</span>

<span class="nv">$ </span>ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.100</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> route <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.101</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w2 &lt;&lt;</span>
<span class="c">#    default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.102</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 flannel.1과 cni0가 삭제되어, 관련 라우팅 정보가 삭제되었습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<ul>
  <li>기존 kube-proxy를 제거합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system delete ds kube-proxy
<span class="c"># =&gt; daemonset.apps "kube-proxy" deleted</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system delete cm kube-proxy
<span class="c"># =&gt; configmap "kube-proxy" deleted</span>

<span class="c"># 배포된 파드의 IP는 남겨져 있습니다.</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-A</span> <span class="nt">-owide</span>
<span class="c"># =&gt; NAMESPACE     NAME                              READY   STATUS             RESTARTS         AGE     IP               NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    default       curl-pod                          1/1     Running            1 (143m ago)     3h1m    10.244.0.3       k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    default       webpod-697b545f57-7j5vt           1/1     Running            1 (142m ago)     3h2m    10.244.1.3       k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    default       webpod-697b545f57-sdv4l           1/1     Running            1 (142m ago)     3h2m    10.244.2.7       k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-79mbb          0/1     CrashLoopBackOff   27 (4m ago)      2d17h   10.244.2.5       k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-rtx95          0/1     CrashLoopBackOff   27 (4m26s ago)   2d17h   10.244.2.6       k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   etcd-k8s-ctr                      1/1     Running            4 (143m ago)     2d17h   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-apiserver-k8s-ctr            1/1     Running            4 (143m ago)     2d17h   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-controller-manager-k8s-ctr   1/1     Running            4 (143m ago)     2d17h   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-scheduler-k8s-ctr            1/1     Running            4 (143m ago)     2d17h   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl webpod
<span class="c"># =&gt; curl: (6) Could not resolve host: webpod</span>
<span class="c">#    command terminated with exit code 6</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 kube-proxy와 CNI의 삭제로 coredns가 동작하지 않아서 webpod 서비스에 접근할 수 없습니다.&lt;/span&gt;</span>

<span class="c">#</span>
<span class="nv">$ </span>iptables-save

<span class="c"># Run on each node with root permissions:</span>
<span class="nv">$ </span>iptables-save | <span class="nb">grep</span> <span class="nt">-v</span> KUBE | <span class="nb">grep</span> <span class="nt">-v</span> FLANNEL | iptables-restore
<span class="nv">$ </span>iptables-save

<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w1 <span class="s2">"sudo iptables-save | grep -v KUBE | grep -v FLANNEL | sudo iptables-restore"</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w1 <span class="nb">sudo </span>iptables-save

<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w2 <span class="s2">"sudo iptables-save | grep -v KUBE | grep -v FLANNEL | sudo iptables-restore"</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w2 <span class="nb">sudo </span>iptables-save

<span class="c">#</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                      READY   STATUS    RESTARTS       AGE     IP           NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    curl-pod                  1/1     Running   1 (155m ago)   3h14m   10.244.0.3   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-697b545f57-7j5vt   1/1     Running   1 (155m ago)   3h14m   10.244.1.3   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-697b545f57-sdv4l   1/1     Running   1 (155m ago)   3h14m   10.244.2.7   k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
</code></pre></div></div>

<ul>
  <li>노드별 파드에 할당되는 IPAM(PodCIDR) 정보를 확인해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#--allocate-node-cidrs=true 로 설정된 kube-controller-manager에서 CIDR을 자동 할당함</span>
<span class="nv">$ </span>kubectl get nodes <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{range .items[*]}{.metadata.name}{"\t"}{.spec.podCIDR}{"\n"}{end}'</span>
<span class="c"># =&gt; k8s-ctr 10.244.0.0/24</span>
<span class="c">#    k8s-w1  10.244.1.0/24</span>
<span class="c">#    k8s-w2  10.244.2.0/24</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                      READY   STATUS    RESTARTS       AGE     IP           NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    curl-pod                  1/1     Running   1 (157m ago)   3h15m   10.244.0.3   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-697b545f57-7j5vt   1/1     Running   1 (156m ago)   3h16m   10.244.1.3   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-697b545f57-sdv4l   1/1     Running   1 (156m ago)   3h16m   10.244.2.7   k8s-w2    &lt;none&gt;           &lt;none&gt;</span>

<span class="c">#</span>
<span class="nv">$ </span>kc describe pod <span class="nt">-n</span> kube-system kube-controller-manager-k8s-ctr
<span class="c"># =&gt; ...</span>
<span class="c">#       Command:</span>
<span class="c">#          kube-controller-manager</span>
<span class="c">#          --allocate-node-cidrs=true</span>
<span class="c">#          --cluster-cidr=10.244.0.0/16</span>
<span class="c">#          --service-cluster-ip-range=10.96.0.0/16</span>
<span class="c">#    ... </span>
</code></pre></div></div>

<h4 id="cilium-cni-설치-with-helm">Cilium CNI 설치 with Helm</h4>

<ul>
  <li>관련 문서 : <a href="https://docs.cilium.io/en/stable/helm-reference/">Helm</a>, <a href="https://docs.cilium.io/en/stable/network/concepts/masquerading/">Masquering</a>, <a href="https://docs.cilium.io/en/stable/network/concepts/ipam/cluster-pool/">ClusterScope</a>, <a href="https://docs.cilium.io/en/stable/network/concepts/routing/">Routing</a></li>
  <li>Cilium 1.17.5 Helm Chart - <a href="https://artifacthub.io/packages/helm/cilium/cilium/1.17.5">ArtifactHub</a>를 사용하여 설치합니다.
<img src="/assets/2025/cilium/w1/20250720_cilium_w1_3.png" alt="img.png" /></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Cilium 설치 with Helm</span>
<span class="nv">$ </span>helm repo add cilium https://helm.cilium.io/
<span class="c"># =&gt; "cilium" has been added to your repositories</span>

<span class="c"># 모든 NIC 지정 + bpf.masq=true + NoIptablesRules</span>
<span class="nv">$ </span>helm <span class="nb">install </span>cilium cilium/cilium <span class="nt">--version</span> 1.17.5 <span class="nt">--namespace</span> kube-system <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">k8sServiceHost</span><span class="o">=</span>192.168.10.100 <span class="nt">--set</span> <span class="nv">k8sServicePort</span><span class="o">=</span>6443 <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">kubeProxyReplacement</span><span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">routingMode</span><span class="o">=</span>native <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">autoDirectNodeRoutes</span><span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> ipam.mode<span class="o">=</span><span class="s2">"cluster-pool"</span> <span class="se">\</span>
  <span class="nt">--set</span> ipam.operator.clusterPoolIPv4PodCIDRList<span class="o">={</span><span class="s2">"172.20.0.0/16"</span><span class="o">}</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">ipv4NativeRoutingCIDR</span><span class="o">=</span>172.20.0.0/16 <span class="se">\</span>
  <span class="nt">--set</span> endpointRoutes.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">installNoConntrackIptablesRules</span><span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> bpf.masquerade<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> ipv6.enabled<span class="o">=</span><span class="nb">false</span>
<span class="c"># =&gt; NAME: cilium</span>
<span class="c">#    LAST DEPLOYED: Sat Jul 19 17:34:05 2025</span>
<span class="c">#    NAMESPACE: kube-system</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 1</span>
<span class="c">#    TEST SUITE: None</span>
<span class="c">#    NOTES:</span>
<span class="c">#    You have successfully installed Cilium with Hubble.</span>
<span class="c">#    </span>
<span class="c">#    Your release version is 1.17.5.</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>helm get values cilium <span class="nt">-n</span> kube-system
<span class="c"># =&gt; USER-SUPPLIED VALUES:</span>
<span class="c">#    autoDirectNodeRoutes: true</span>
<span class="c">#    bpf:</span>
<span class="c">#      masquerade: true</span>
<span class="c">#    endpointRoutes:</span>
<span class="c">#      enabled: true</span>
<span class="c">#    installNoConntrackIptablesRules: true</span>
<span class="c">#    ipam:</span>
<span class="c">#      mode: cluster-pool</span>
<span class="c">#      operator:</span>
<span class="c">#        clusterPoolIPv4PodCIDRList:</span>
<span class="c">#        - 172.20.0.0/16</span>
<span class="c">#    ipv4NativeRoutingCIDR: 172.20.0.0/16</span>
<span class="c">#    ipv6:</span>
<span class="c">#      enabled: false</span>
<span class="c">#    k8sServiceHost: 192.168.10.100</span>
<span class="c">#    k8sServicePort: 6443</span>
<span class="c">#    kubeProxyReplacement: true</span>
<span class="c">#    routingMode: native</span>
<span class="nv">$ </span>helm list <span class="nt">-A</span>
<span class="c"># =&gt; NAME    NAMESPACE       REVISION        UPDATED                                 STATUS          CHART           APP VERSION</span>
<span class="c">#    cilium  kube-system     1               2025-07-19 17:34:05.700270399 +0900 KST deployed        cilium-1.17.5   1.17.5</span>
<span class="nv">$ </span>kubectl get crd
<span class="c"># =&gt; No resources found</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> kubectl get pod <span class="nt">-A</span>
<span class="c"># =&gt; Every 2.0s: kubectl get pod -A                                                                                                                 k8s-ctr: Sat Jul 19 17:36:42 2025</span>
<span class="c">#    </span>
<span class="c">#    NAMESPACE     NAME                               READY   STATUS    RESTARTS       AGE</span>
<span class="c">#    default       curl-pod                           1/1     Running   1 (166m ago)   3h24m</span>
<span class="c">#    default       webpod-697b545f57-7j5vt            1/1     Running   1 (165m ago)   3h25m</span>
<span class="c">#    default       webpod-697b545f57-sdv4l            1/1     Running   1 (165m ago)   3h25m</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-envoy-b2mn9&lt;/span&gt;                 1/1     Running   0              2m36s</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-envoy-dgdmn&lt;/span&gt;                 1/1     Running   0              2m36s</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-envoy-pjn95&lt;/span&gt;                 1/1     Running   0              2m36s</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-fl689&lt;/span&gt;                       1/1     Running   0              2m36s</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-mqnkn&lt;/span&gt;                       1/1     Running   0              2m36s</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-operator-865bc7f457-hpwvh&lt;/span&gt;   1/1     Running   0              2m36s</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-operator-865bc7f457-v5k84&lt;/span&gt;   1/1     Running   0              2m36s</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-zz9k4&lt;/span&gt;                       1/1     Running   0              2m36s</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-7q52c           1/1     &lt;span style="color: green;"&gt;Running&lt;/span&gt;   0              52s</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-bvsfb           1/1     &lt;span style="color: green;"&gt;Running&lt;/span&gt;   0              66s</span>
<span class="c">#    kube-system   etcd-k8s-ctr                       1/1     Running   4 (166m ago)   2d18h</span>
<span class="c">#    kube-system   kube-apiserver-k8s-ctr             1/1     Running   4 (166m ago)   2d18h</span>
<span class="c">#    kube-system   kube-controller-manager-k8s-ctr    1/1     Running   4 (166m ago)   2d18h</span>
<span class="c">#    kube-system   kube-scheduler-k8s-ctr             1/1     Running   4 (166m ago)   2d18h</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 cilium 관련된 파드가 배포되었고 coredns 파드도 정상적으로 동작합니다.&lt;/span&gt;</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium-dbg status <span class="nt">--verbose</span>
<span class="c"># =&gt; KubeProxyReplacement:   True   [eth0    10.0.2.15 fd17:625c:f037:2:a00:27ff:fe71:19d8 fe80::a00:27ff:fe71:19d8, eth1   192.168.10.102 fe80::a00:27ff:fe79:58ac (Direct Routing)]</span>
<span class="c">#    ...</span>
<span class="c">#    Routing:                Network: Native   Host: BPF</span>
<span class="c">#    ...</span>
<span class="c">#    Masquerading:           BPF   [eth0, eth1]   172.20.0.0/16 [IPv4: Enabled, IPv6: Disabled]</span>
<span class="c">#    ...</span>

<span class="c"># 노드에 iptables 확인</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span>
<span class="c"># =&gt; -P PREROUTING ACCEPT</span>
<span class="c">#    -P INPUT ACCEPT</span>
<span class="c">#    -P OUTPUT ACCEPT</span>
<span class="c">#    -P POSTROUTING ACCEPT</span>
<span class="c">#    -N CILIUM_OUTPUT_nat</span>
<span class="c">#    -N CILIUM_POST_nat</span>
<span class="c">#    -N CILIUM_PRE_nat</span>
<span class="c">#    -N KUBE-KUBELET-CANARY</span>
<span class="c">#    -A PREROUTING -m comment --comment "cilium-feeder: CILIUM_PRE_nat" -j CILIUM_PRE_nat</span>
<span class="c">#    -A OUTPUT -m comment --comment "cilium-feeder: CILIUM_OUTPUT_nat" -j CILIUM_OUTPUT_nat</span>
<span class="c">#    -A POSTROUTING -m comment --comment "cilium-feeder: CILIUM_POST_nat" -j CILIUM_POST_nat</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>

<span class="nv">$ </span>iptables-save
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>iptables-save <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span> 
</code></pre></div></div>

<ul>
  <li>PodCIDR IPAM 확인해보겠습니다. - <a href="https://docs.cilium.io/en/stable/network/concepts/ipam/cluster-pool/">ClusterScope</a></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>kubectl get nodes <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{range .items[*]}{.metadata.name}{"\t"}{.spec.podCIDR}{"\n"}{end}'</span>
<span class="c"># =&gt; k8s-ctr 10.244.0.0/24</span>
<span class="c">#    k8s-w1  10.244.1.0/24</span>
<span class="c">#    k8s-w2  10.244.2.0/24</span>

<span class="c"># 파드 IP 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                      READY   STATUS    RESTARTS       AGE     IP           NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    curl-pod                  1/1     Running   1 (172m ago)   3h30m   10.244.0.3   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-697b545f57-7j5vt   1/1     Running   1 (171m ago)   3h30m   10.244.1.3   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-697b545f57-sdv4l   1/1     Running   1 (171m ago)   3h30m   10.244.2.7   k8s-w2    &lt;none&gt;           &lt;none&gt;</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get ciliumnodes
<span class="c"># =&gt; NAME      CILIUMINTERNALIP   INTERNALIP       AGE</span>
<span class="c">#    k8s-ctr   172.20.2.68        192.168.10.100   6m11s</span>
<span class="c">#    k8s-w1    172.20.1.88        192.168.10.101   6m50s</span>
<span class="c">#    k8s-w2    172.20.0.235       192.168.10.102   7m8s</span>
<span class="nv">$ </span>kubectl get ciliumnodes <span class="nt">-o</span> json | <span class="nb">grep </span>podCIDRs <span class="nt">-A2</span>
<span class="c"># =&gt;                     "podCIDRs": [</span>
<span class="c">#                            "172.20.2.0/24"</span>
<span class="c">#                        ],</span>
<span class="c">#    --</span>
<span class="c">#                        "podCIDRs": [</span>
<span class="c">#                            "172.20.1.0/24"</span>
<span class="c">#                        ],</span>
<span class="c">#    --</span>
<span class="c">#                        "podCIDRs": [</span>
<span class="c">#                            "172.20.0.0/24"</span>
<span class="c">#                        ],</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl rollout restart deployment webpod
<span class="c"># =&gt; deployment.apps/webpod restarted</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                      READY   STATUS    RESTARTS       AGE     IP             NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    curl-pod                  1/1     Running   1 (172m ago)   3h31m   10.244.0.3     k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-86f878c468-448pc   1/1     Running   0              11s     172.20.0.202   k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-86f878c468-ttbs2   1/1     Running   0              15s     172.20.1.123   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>

<span class="c"># k8s-ctr 노드에 curl-pod 파드 배포</span>
<span class="nv">$ </span>kubectl delete pod curl-pod <span class="nt">--grace-period</span><span class="o">=</span>0
<span class="c"># =&gt; pod "curl-pod" deleted</span>

<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: curl-pod
  labels:
    app: curl
spec:
  nodeName: k8s-ctr
  containers:
  - name: curl
    image: nicolaka/netshoot
    command: ["tail"]
    args: ["-f", "/dev/null"]
  terminationGracePeriodSeconds: 0
</span><span class="no">EOF
</span><span class="c"># =&gt; pod/curl-pod created</span>

<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                      READY   STATUS    RESTARTS   AGE   IP             NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    curl-pod                  1/1     Running   0          33s   172.20.2.15    k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-86f878c468-448pc   1/1     Running   0          66s   172.20.0.202   k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-86f878c468-ttbs2   1/1     Running   0          70s   172.20.1.123   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="nv">$ </span>kubectl get ciliumendpoints
<span class="c"># =&gt; NAME                      SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    curl-pod                  5180                ready            172.20.2.15</span>
<span class="c">#    webpod-86f878c468-448pc   34270               ready            172.20.0.202</span>
<span class="c">#    webpod-86f878c468-ttbs2   34270               ready            172.20.1.123</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium-dbg endpoint list
<span class="c"># =&gt; ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])                                                  IPv6   IPv4           STATUS</span>
<span class="c">#               ENFORCEMENT        ENFORCEMENT</span>
<span class="c">#    60         Disabled           Disabled          20407      k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=kube-system          172.20.0.167   ready</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.cluster=default</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.serviceaccount=coredns</span>
<span class="c">#                                                               k8s:io.kubernetes.pod.namespace=kube-system</span>
<span class="c">#                                                               k8s:k8s-app=kube-dns</span>
<span class="c">#    71         Disabled           Disabled          4          reserved:health                                                                     172.20.0.114   ready</span>
<span class="c">#    1368       Disabled           Disabled          20407      k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=kube-system          172.20.0.92    ready</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.cluster=default</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.serviceaccount=coredns</span>
<span class="c">#                                                               k8s:io.kubernetes.pod.namespace=kube-system</span>
<span class="c">#                                                               k8s:k8s-app=kube-dns</span>
<span class="c">#    2533       Disabled           Disabled          1          reserved:host                                                                                      ready</span>
<span class="c">#    2605       Disabled           Disabled          34270      k8s:app=webpod                                                                      172.20.0.202   ready</span>
<span class="c">#                                                               k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.cluster=default</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.serviceaccount=default</span>
<span class="c">#                                                               k8s:io.kubernetes.pod.namespace=default</span>

<span class="c"># 통신 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl webpod | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod-86f878c468-448pc</span>

</code></pre></div></div>

<h3 id="cilium-설치-확인">Cilium 설치 확인</h3>

<ul>
  <li>cilium cli를 설치하여 Cilium 상태를 확인해 보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># cilium cli 설치</span>
<span class="nv">$ CILIUM_CLI_VERSION</span><span class="o">=</span><span class="si">$(</span>curl <span class="nt">-s</span> https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt<span class="si">)</span>
<span class="nv">$ CLI_ARCH</span><span class="o">=</span>amd64
<span class="nv">$ </span><span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span><span class="si">)</span><span class="s2">"</span> <span class="o">=</span> <span class="s2">"aarch64"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then </span><span class="nv">CLI_ARCH</span><span class="o">=</span>arm64<span class="p">;</span> <span class="k">fi</span>
<span class="nv">$ </span>curl <span class="nt">-L</span> <span class="nt">--fail</span> <span class="nt">--remote-name-all</span> https://github.com/cilium/cilium-cli/releases/download/<span class="k">${</span><span class="nv">CILIUM_CLI_VERSION</span><span class="k">}</span>/cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nv">$ </span><span class="nb">tar </span>xzvfC cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz /usr/local/bin
<span class="c"># =&gt; cilium</span>
<span class="nv">$ </span><span class="nb">rm </span>cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz

<span class="c"># cilium 상태 확인</span>
<span class="nv">$ </span>which cilium
<span class="c"># =&gt; /usr/local/bin/cilium</span>
<span class="nv">$ </span>cilium status
<span class="c"># =&gt;     /¯¯\</span>
<span class="c">#     /¯¯\__/¯¯\    Cilium:             OK</span>
<span class="c">#     \__/¯¯\__/    Operator:           OK</span>
<span class="c">#     /¯¯\__/¯¯\    Envoy DaemonSet:    OK</span>
<span class="c">#     \__/¯¯\__/    Hubble Relay:       disabled</span>
<span class="c">#        \__/       ClusterMesh:        disabled</span>
<span class="c">#    </span>
<span class="c">#    DaemonSet              cilium                   Desired: 3, Ready: 3/3, Available: 3/3</span>
<span class="c">#    DaemonSet              cilium-envoy             Desired: 3, Ready: 3/3, Available: 3/3</span>
<span class="c">#    Deployment             cilium-operator          Desired: 2, Ready: 2/2, Available: 2/2</span>
<span class="c">#    Containers:            cilium                   Running: 3</span>
<span class="c">#                           cilium-envoy             Running: 3</span>
<span class="c">#                           cilium-operator          Running: 2</span>
<span class="c">#                           clustermesh-apiserver</span>
<span class="c">#                           hubble-relay</span>
<span class="c">#    Cluster Pods:          5/5 managed by Cilium</span>
<span class="c">#    Helm chart version:    1.17.5</span>
<span class="c">#    Image versions         cilium             quay.io/cilium/cilium:v1.17.5@sha256:baf8541723ee0b72d6c489c741c81a6fdc5228940d66cb76ef5ea2ce3c639ea6: 3</span>
<span class="c">#                           cilium-envoy       quay.io/cilium/cilium-envoy:v1.32.6-1749271279-0864395884b263913eac200ee2048fd985f8e626@sha256:9f69e290a7ea3d4edf9192acd81694089af048ae0d8a67fb63bd62dc1d72203e: 3</span>
<span class="c">#                           cilium-operator    quay.io/cilium/operator-generic:v1.17.5@sha256:f954c97eeb1b47ed67d08cc8fb4108fb829f869373cbb3e698a7f8ef1085b09e: 2</span>
<span class="nv">$ </span>cilium config view
<span class="c"># =&gt; ...</span>
<span class="c">#    cluster-pool-ipv4-cidr                            172.20.0.0/16</span>
<span class="c">#    default-lb-service-ipam                           lbipam</span>
<span class="c">#    ipam                                              cluster-pool</span>
<span class="c">#    ipam-cilium-node-update-rate                      15s</span>
<span class="c">#    iptables-random-fully                             false</span>
<span class="c">#    ipv4-native-routing-cidr                          172.20.0.0/16</span>
<span class="c">#    kube-proxy-replacement                            true</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>kubectl get cm <span class="nt">-n</span> kube-system cilium-config <span class="nt">-o</span> json | jq

<span class="c">#</span>
<span class="nv">$ </span>cilium config <span class="nb">set </span>debug <span class="nb">true</span> <span class="o">&amp;&amp;</span> watch kubectl get pod <span class="nt">-A</span>
<span class="c"># =&gt; ✨ Patching ConfigMap cilium-config with debug=true...</span>
<span class="c">#    ♻️  Restarted Cilium pods</span>
<span class="nv">$ </span>cilium config view | <span class="nb">grep</span> <span class="nt">-i</span> debug
<span class="c"># =&gt; debug                                             true</span>
<span class="c">#    debug-verbose</span>

<span class="c"># cilium daemon = cilium-dbg</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg config
<span class="c"># =&gt; ##### Read-write configurations #####</span>
<span class="c">#    ConntrackAccounting               : Disabled</span>
<span class="c">#    ConntrackLocal                    : Disabled</span>
<span class="c">#    Debug                             : Disabled</span>
<span class="c">#    DebugLB                           : Disabled</span>
<span class="c">#    DebugPolicy                       : Enabled</span>
<span class="c">#    DropNotification                  : Enabled</span>
<span class="c">#    MonitorAggregationLevel           : Medium</span>
<span class="c">#    PolicyAccounting                  : Enabled</span>
<span class="c">#    PolicyAuditMode                   : Disabled</span>
<span class="c">#    PolicyTracing                     : Disabled</span>
<span class="c">#    PolicyVerdictNotification         : Enabled</span>
<span class="c">#    SourceIPVerification              : Enabled</span>
<span class="c">#    TraceNotification                 : Enabled</span>
<span class="c">#    MonitorNumPages                   : 64</span>
<span class="c">#    PolicyEnforcement                 : default</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg status <span class="nt">--verbose</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    KubeProxyReplacement:   True   [eth0    10.0.2.15 fd17:625c:f037:2:a00:27ff:fe71:19d8 fe80::a00:27ff:fe71:19d8, eth1   192.168.10.102 fe80::a00:27ff:fe79:58ac (Direct Routing)]</span>
<span class="c">#    Routing:                Network: Native   Host: BPF</span>
<span class="c">#    Attach Mode:            TCX</span>
<span class="c">#    Device Mode:            veth</span>
<span class="c">#    ...</span>
<span class="c">#    KubeProxyReplacement Details:</span>
<span class="c">#      Status:                 True</span>
<span class="c">#      Socket LB:              Enabled</span>
<span class="c">#      Socket LB Tracing:      Enabled</span>
<span class="c">#      Socket LB Coverage:     Full</span>
<span class="c">#      Devices:                eth0    10.0.2.15 fd17:625c:f037:2:a00:27ff:fe71:19d8 fe80::a00:27ff:fe71:19d8, eth1   192.168.10.102 fe80::a00:27ff:fe79:58ac (Direct Routing)</span>
<span class="c">#      Mode:                   SNAT</span>
<span class="c">#      Backend Selection:      Random</span>
<span class="c">#      Session Affinity:       Enabled</span>
<span class="c">#      Graceful Termination:   Enabled</span>
<span class="c">#      NAT46/64 Support:       Disabled</span>
<span class="c">#      XDP Acceleration:       Disabled</span>
<span class="c">#      Services:</span>
<span class="c">#      - ClusterIP:      Enabled</span>
<span class="c">#      - NodePort:       Enabled (Range: 30000-32767)</span>
<span class="c">#      - LoadBalancer:   Enabled</span>
<span class="c">#      - externalIPs:    Enabled</span>
<span class="c">#      - HostPort:       Enabled</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<ul>
  <li>cilium_host, cilium_net, cilium_health 등의 네트워크 기본 정보를 확인해보겠습니다.</li>
</ul>

<p><img src="/assets/2025/cilium/w1/20250720_cilium_w1_4.png" alt="img.png" class="image-center" />
<img src="/assets/2025/cilium/w1/20250720_cilium_w1_5.png" alt="img_1.png" class="image-center w-50" />
<a href="https://arthurchiao.art/blog/ctrip-network-arch-evolution/" class="image-caption">출처 : https://arthurchiao.art/blog/ctrip-network-arch-evolution/</a></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> addr
<span class="c"># =&gt; ...</span>
<span class="c">#    7: cilium_net@cilium_host: &lt;BROADCAST,MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span>
<span class="c">#        link/ether 4e:28:ea:3e:83:e0 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet6 fe80::4c28:eaff:fe3e:83e0/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    8: cilium_host@cilium_net: &lt;BROADCAST,MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span>
<span class="c">#        link/ether 22:ad:62:34:21:8e brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet 172.20.2.68/32 scope global cilium_host</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#        inet6 fe80::20ad:62ff:fe34:218e/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    12: lxcc4a3ffff7931@if11: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span>
<span class="c">#        link/ether 76:62:d3:8d:58:1f brd ff:ff:ff:ff:ff:ff link-netns cni-ca74ac02-08e1-9092-74ad-f60026576c19</span>
<span class="c">#        inet6 fe80::7462:d3ff:fe8d:581f/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    14: lxc_health@if13: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span>
<span class="c">#        link/ether ca:67:c2:a6:88:89 brd ff:ff:ff:ff:ff:ff link-netnsid 2</span>
<span class="c">#        inet6 fe80::c867:c2ff:fea6:8889/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> addr <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>

<span class="c">#</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> addr show cilium_net
<span class="c"># =&gt; 7: cilium_net@cilium_host: &lt;BROADCAST,MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span>
<span class="c">#        link/ether 4e:28:ea:3e:83:e0 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet6 fe80::4c28:eaff:fe3e:83e0/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> addr show cilium_host
<span class="c"># =&gt; 8: cilium_host@cilium_net: &lt;BROADCAST,MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span>
<span class="c">#        link/ether 22:ad:62:34:21:8e brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet 172.20.2.68/32 scope global cilium_host</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#        inet6 fe80::20ad:62ff:fe34:218e/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> addr show cilium_net  <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> addr show cilium_host <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>

<span class="c"># lxc_health 인터페이스는 veth 로 cilium(NET NS 0, 호스트와 다름)과 veth pair 이다 - 링크</span>
<span class="c"># cilium 인터페이스에 파드 IP가 할당되어 있으며, cilium-health-responder 로 동작한다</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> addr show lxc_health
<span class="c"># =&gt; 14: lxc_health@if13: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span>
<span class="c">#        link/ether ca:67:c2:a6:88:89 brd ff:ff:ff:ff:ff:ff link-netnsid 2</span>
<span class="c">#        inet6 fe80::c867:c2ff:fea6:8889/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> addr show lxc_health  <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>

<span class="c"># IP 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium-dbg status <span class="nt">--verbose</span>
<span class="c"># =&gt; ....</span>
<span class="c">#    Name              IP              Node   Endpoints</span>
<span class="c">#      k8s-w2 (localhost):</span>
<span class="c">#        Host connectivity to 192.168.10.102:   &lt;span style="color: green;"&gt;# &lt;-- NodeIP&lt;/span&gt;</span>
<span class="c">#          ICMP to stack:   OK, RTT=440.958µs</span>
<span class="c">#          HTTP to agent:   OK, RTT=539.708µs</span>
<span class="c">#        Endpoint connectivity to 172.20.0.114: &lt;span style="color: green;"&gt;# &lt;-- HealthIP&lt;/span&gt;</span>
<span class="c">#          ICMP to stack:   OK, RTT=189µs</span>
<span class="c">#          HTTP to agent:   OK, RTT=502µs</span>
<span class="c">#      k8s-ctr:</span>
<span class="c">#        Host connectivity to 192.168.10.100:   &lt;span style="color: green;"&gt;# &lt;-- NodeIP&lt;/span&gt;</span>
<span class="c">#          ICMP to stack:   OK, RTT=1.011167ms</span>
<span class="c">#          HTTP to agent:   OK, RTT=1.071083ms</span>
<span class="c">#        Endpoint connectivity to 172.20.2.223: &lt;span style="color: green;"&gt;# &lt;-- HealthIP&lt;/span&gt;</span>
<span class="c">#          ICMP to stack:   OK, RTT=1.027125ms</span>
<span class="c">#          HTTP to agent:   OK, RTT=7.677708ms</span>
<span class="c">#      k8s-w1:</span>
<span class="c">#        Host connectivity to 192.168.10.101:   &lt;span style="color: green;"&gt;# &lt;-- NodeIP&lt;/span&gt;</span>
<span class="c">#          ICMP to stack:   OK, RTT=888.417µs</span>
<span class="c">#          HTTP to agent:   OK, RTT=1.167333ms</span>
<span class="c">#        Endpoint connectivity to 172.20.1.229: &lt;span style="color: green;"&gt;# &lt;-- HealthIP&lt;/span&gt;</span>
<span class="c">#          ICMP to stack:   OK, RTT=1.806167ms</span>
<span class="c">#          HTTP to agent:   OK, RTT=1.903ms</span>
<span class="c">#    ....</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium-dbg endpoint list | <span class="nb">grep </span>health
<span class="c"># =&gt; 2955  Disabled  Disabled  4  reserved:health  172.20.0.114  ready                                                             172.20.1.40    ready </span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium-dbg status <span class="nt">--all-addresses</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    Allocated addresses:</span>
<span class="c">#      172.20.0.114 (health)</span>
<span class="c">#      172.20.0.167 (kube-system/coredns-674b8bbfcf-bvsfb [restored])</span>
<span class="c">#      172.20.0.202 (default/webpod-86f878c468-448pc [restored])</span>
<span class="c">#      172.20.0.235 (router)</span>
<span class="c">#      172.20.0.92 (kube-system/coredns-674b8bbfcf-7q52c [restored])</span>
<span class="c">#    ...</span>

<span class="c"># Check health info in CT/NAT tables : ICMP records in Conntrack (CT) table and NAT table</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium bpf ct list global | <span class="nb">grep </span>ICMP |head <span class="nt">-n4</span>
<span class="c"># =&gt; ICMP IN 192.168.10.101:19430 -&gt; 172.20.0.114:0 expires=11874 Packets=0 Bytes=0 RxFlagsSeen=0x00 LastRxReport=11814 TxFlagsSeen=0x00 LastTxReport=11814 Flags=0x0000 [ ] RevNAT=0 SourceSecurityID=6 IfIndex=0 BackendID=0</span>
<span class="c">#    ICMP IN 192.168.10.101:0 -&gt; 172.20.0.114:0 related expires=11874 Packets=0 Bytes=0 RxFlagsSeen=0x00 LastRxReport=11814 TxFlagsSeen=0x00 LastTxReport=0 Flags=0x0000 [ ] RevNAT=0 SourceSecurityID=6 IfIndex=0 BackendID=0</span>
<span class="c">#    ICMP IN 192.168.10.101:2374 -&gt; 172.20.0.114:0 expires=11535 Packets=0 Bytes=0 RxFlagsSeen=0x00 LastRxReport=11475 TxFlagsSeen=0x00 LastTxReport=11475 Flags=0x0000 [ ] RevNAT=0 SourceSecurityID=6 IfIndex=0 BackendID=0</span>
<span class="c">#    ICMP IN 192.168.10.101:47855 -&gt; 172.20.0.114:0 expires=11415 Packets=0 Bytes=0 RxFlagsSeen=0x00 LastRxReport=11355 TxFlagsSeen=0x00 LastTxReport=11355 Flags=0x0000 [ ] RevNAT=0 SourceSecurityID=6 IfIndex=0 BackendID=0</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium bpf nat list | <span class="nb">grep </span>ICMP |head <span class="nt">-n4</span>
<span class="c"># =&gt; ICMP OUT 192.168.10.102:35430 -&gt; 172.20.1.229:0 XLATE_SRC 192.168.10.102:35430 Created=164sec ago NeedsCT=1</span>
<span class="c">#    ICMP IN 172.20.2.223:0 -&gt; 192.168.10.102:47029 XLATE_DST 192.168.10.102:47029 Created=464sec ago NeedsCT=1</span>
<span class="c">#    ICMP IN 172.20.2.223:0 -&gt; 192.168.10.102:52326 XLATE_DST 192.168.10.102:52326 Created=54sec ago NeedsCT=1</span>
<span class="c">#    ICMP OUT 192.168.10.102:47029 -&gt; 172.20.2.223:0 XLATE_SRC 192.168.10.102:47029 Created=464sec ago NeedsCT=1</span>
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w1/20250720_cilium_w1_6.png" alt="img.png" class="image-center" />
<em class="image-caption"><a href="https://arthurchiao.art/blog/cilium-code-health-probe">node 및 endpoint health check 절차</a></em></p>

<ul>
  <li>routing 정보 확인해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Native-Routing + autoDirectNodeRoutes=true</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route | <span class="nb">grep </span>172.20 | <span class="nb">grep </span>eth1
<span class="c"># =&gt; 172.20.0.0/24 via 192.168.10.102 dev eth1 proto kernel</span>
<span class="c">#    172.20.1.0/24 via 192.168.10.101 dev eth1 proto kernel</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> route | <span class="nb">grep </span>172.20 | <span class="nb">grep </span>eth1 <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>

<span class="c"># hostNetwork 를 사용하지 않는 파드의 경우 endpointRoutes.enabled=true 설정으로 lxcY 인터페이스 생성됨</span>
<span class="nv">$ </span>kubectl get ciliumendpoints <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE     NAME                       SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    default       curl-pod                   5180                ready            172.20.2.15</span>
<span class="c">#    default       webpod-86f878c468-448pc    34270               ready            172.20.0.202</span>
<span class="c">#    default       webpod-86f878c468-ttbs2    34270               ready            172.20.1.123</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-7q52c   20407               ready            172.20.0.92</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-bvsfb   20407               ready            172.20.0.167</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route | <span class="nb">grep </span>lxc
<span class="c"># =&gt; 172.20.2.15 dev lxcc4a3ffff7931 proto kernel scope link</span>
<span class="c">#    172.20.2.223 dev lxc_health proto kernel scope link</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> route | <span class="nb">grep </span>lxc <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
</code></pre></div></div>

<ul>
  <li>보다 상세한 내용은 <a href="https://docs.cilium.io/en/stable/network/kubernetes/kubeproxy-free/">공식문서</a>를 참고하세요.</li>
</ul>

<hr />

<h2 id="통신-확인">통신 확인</h2>

<h3 id="노드간-파드---파드-통신">노드간 ‘파드 -&gt; 파드’ 통신</h3>

<ul>
  <li><a href="https://docs.cilium.io/en/stable/network/ebpf/lifeofapacket/">참고</a> <a href="https://velog.io/@_gyullbb/Cilium">추천 글</a></li>
</ul>

<p><img src="/assets/2025/cilium/w1/20250720_cilium_w1_7.png" alt="img.png" class="image-center" />
<em class="image-caption">파드에서 빠져나갈 때</em></p>

<p><img src="/assets/2025/cilium/w1/20250720_cilium_w1_8.png" alt="img_1.png" class="image-center" />
<em class="image-caption">파드로 들어올 때</em></p>

<ul>
  <li>cilium 정보 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 먼저 아래의 cheatsheet을 참고하여 c0, c0bpf 등의 단축키(alias)를 지정한 후에 진행합니다.</span>

<span class="c"># 엔드포인트 정보 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                      READY   STATUS    RESTARTS   AGE     IP             NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    curl-pod                  1/1     Running   0          3h40m   172.20.2.15    k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-86f878c468-448pc   1/1     Running   0          3h41m   &lt;span style="color: green;"&gt;172.20.0.202&lt;/span&gt;   k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-86f878c468-ttbs2   1/1     Running   0          3h41m   172.20.1.123   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="nv">$ </span>kubectl get svc,ep webpod
<span class="c"># =&gt; NAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE</span>
<span class="c">#    service/webpod   ClusterIP   10.96.62.184   &lt;none&gt;        80/TCP    7h12m</span>
<span class="c">#    </span>
<span class="c">#    NAME               ENDPOINTS                         AGE</span>
<span class="c">#    endpoints/webpod   172.20.0.202:80,172.20.1.123:80   7h12m</span>

<span class="c"># 첫번째 webpod의 IP 주소를 WEBPOD1IP 변수에 저장합니다.</span>
<span class="nv">$ WEBPOD1IP</span><span class="o">=</span>172.20.0.202

<span class="c"># BPF maps : 목적지 파드와 통신 시 어느곳으로 보내야 될지 확인할 수 있다</span>
<span class="nv">$ </span>c0 map get cilium_ipcache
<span class="nv">$ </span>c0 map get cilium_ipcache | <span class="nb">grep</span> <span class="nv">$WEBPOD1IP</span>
<span class="c"># =&gt; 172.20.0.202/32     identity=34270 encryptkey=0 tunnelendpoint=192.168.10.102 flags=&lt;none&gt;   sync</span>

<span class="c"># curl-pod 의 LXC 변수 지정</span>
<span class="c"># $ LXC=&lt;k8s-ctr의 가장 나중에 lxc 이름(lxc_health 제외)&gt;</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route | <span class="nb">grep </span>lxc
<span class="c"># =&gt; 172.20.2.15 dev &lt;span style="color: green;"&gt;lxcc4a3ffff7931&lt;/span&gt; proto kernel scope link</span>
<span class="c">#    172.20.2.223 dev lxc_health proto kernel scope link</span>
<span class="nv">$ LXC</span><span class="o">=</span>lxcc4a3ffff7931

<span class="c"># Node’s eBPF programs</span>
<span class="c">## list of eBPF programs</span>
<span class="nv">$ </span>c0bpf net show
<span class="nv">$ </span>c0bpf net show | <span class="nb">grep</span> <span class="nv">$LXC</span> 
<span class="c"># =&gt; lxcc4a3ffff7931(12) tcx/ingress cil_from_container prog_id 1212 link_id 22</span>
<span class="c">#    lxcc4a3ffff7931(12) tcx/egress cil_to_container prog_id 1214 link_id 23 </span>

<span class="c">## Use bpftool prog show id to view additional information about a program, including a list of attached eBPF maps:</span>
<span class="c"># $ c0bpf prog show id &lt;출력된 prog id 입력&gt;</span>
<span class="nv">$ </span>c0bpf prog show <span class="nb">id </span>1214
<span class="c"># =&gt; 1214: sched_cls  name cil_to_container  tag 0b3125767ba1861c  gpl</span>
<span class="c">#            loaded_at 2025-07-19T08:50:37+0000  uid 0</span>
<span class="c">#            xlated 1448B  jited 1144B  memlock 4096B  map_ids 219,41,218</span>
<span class="c">#            btf_id 468</span>

<span class="nv">$ </span>c0bpf map list
<span class="c"># =&gt; ...</span>
<span class="c">#    41: percpu_hash  name cilium_metrics  flags 0x1</span>
<span class="c">#            key 8B  value 16B  max_entries 1024  memlock 19024B</span>
<span class="c">#    ...</span>
<span class="c">#    227: array  name .rodata.config  flags 0x480</span>
<span class="c">#            key 4B  value 52B  max_entries 1  memlock 8192B</span>
<span class="c">#            btf_id 496  frozen</span>
<span class="c">#    228: prog_array  name cilium_calls_ne  flags 0x0</span>
<span class="c">#            key 4B  value 4B  max_entries 50  memlock 720B</span>
<span class="c">#            owner_prog_type sched_cls  owner jited</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<ul>
  <li>다른 노드 간 ‘파드 -&gt; 파드’ 통신을 확인해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># vagrant ssh k8s-w1 , # vagrant ssh k8s-w2 각각 터미널 접속 후 아래 실행</span>
<span class="nv">$ </span>ngrep <span class="nt">-tW</span> byline <span class="nt">-d</span> eth1 <span class="s1">''</span> <span class="s1">'tcp port 80'</span>

<span class="c"># [k8s-ctr] curl-pod 에서 curl 요청 시도</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nv">$WEBPOD1IP</span>
<span class="c"># 각각 터미널에서 출력 확인 : 파드의 소스 IP와 목적지 IP가 다른 노드의 서버 NIC에서 확인! : Native-Routung </span>
<span class="c"># =&gt; ####</span>
<span class="c">#    T 2025/07/19 21:36:42.198609 172.20.2.15:46708 -&gt; 172.20.0.202:80 [AP] #4</span>
<span class="c">#    GET / HTTP/1.1.</span>
<span class="c">#    ...</span>
<span class="c">#    ##</span>
<span class="c">#    T 2025/07/19 21:36:42.200368 172.20.0.202:80 -&gt; 172.20.2.15:46708 [AP] #6</span>
<span class="c">#    HTTP/1.1 200 OK.</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w1/20250720_cilium_w1_9.png" alt="img.png" class="image-center" /></p>

<h3 id="노드간-파드---서비스-통신">노드간 ‘파드 -&gt; 서비스’ 통신</h3>

<ul>
  <li>참고 : <a href="https://velog.io/@haruband/K8SCilium-Socket-Based-LoadBalancing-%EA%B8%B0%EB%B2%95">[K8S/Cilium] Socket-Based LoadBalancing 기법</a></li>
</ul>

<p><img src="/assets/2025/cilium/w1/20250720_cilium_w1_10.png" alt="img.png" class="image-center" />
<em class="image-caption">네트워크기반 로드밸런싱 vs 소켓기반 로드밸런싱 비교</em></p>

<ul>
  <li>Pod1 안에서 동작하는 앱이 <strong>connect() 시스템콜</strong>을 이용하여 소켓을 연결할 때 목적지 주소가 서비스 주소(10.10.8.55)이면 소켓의 목적지 주소를 바로 백엔드 주소(10.0.0.31)로 설정합니다.</li>
  <li>이후 앱에서 해당 소켓을 통해 보내는 모든 패킷의 목적지 주소는 이미 백엔드 주소(10.0.0.31)로 설정되어 있기 때문에 중간에 <strong>DNAT 변환 및 역변환 과정이 필요없어집니다.</strong></li>
  <li><strong>Destination NAT</strong> 변환은 시스템 콜 레벨에서 발생하며, 패킷이 커널에 의해 생성되기도 전에 수행됩니다.</li>
  <li><strong>Socket operations</strong> : <strong>BPF socket operations program</strong> 은 <strong>root cgroup 에 연결</strong>되며 TCP <strong>event</strong>(ESTABLISHED) 에서 실행됩니다.</li>
  <li>
    <p><strong>Socket send/recv</strong> : Socket send/recv hook 은 <strong>TCP</strong> socket 의 모든 <strong>송수신</strong> 작업에서 실행되며, <strong>hook</strong> 에서 <strong>검사/삭제/리다이렉션</strong>을 할 수 있습니다.
<img src="/assets/2025/cilium/w1/20250720_cilium_w1_11.png" alt="img.png" class="image-center" />
<em class="image-caption">https://cilium.io/blog/2020/11/10/ebpf-future-of-networking/</em></p>
  </li>
  <li>파드 네임스페이스에서 Socket-Based LoadBalancing 기법을 그림으로 정리해보면 아래와 같습니다.</li>
</ul>

<p><img src="/assets/2025/cilium/w1/20250720_cilium_w1_12.png" alt="img.png" class="image-center" />
<em class="image-caption">출처 : <a href="https://velog.io/@haruband/K8SCilium-Socket-Based-LoadBalancing-%EA%B8%B0%EB%B2%95">[K8S/Cilium] Socket-Based LoadBalancing 기법</a></em></p>

<ul>
  <li>그림상의 좌측은 네트워크 기반 로드밸런싱 기법을 사용한 경우이고, 우측은 소켓 기반 로드밸런싱 기법을 사용한 경우입니다.</li>
  <li>
    <p>소켓 기반 로드밸런싱 기법은 네트워크 기반 로드밸런싱 기법과 비교하여 DNAT 변환 및 역변환 과정이 필요 없기 때문에 성능이 향상됩니다.</p>
  </li>
  <li>connect() 와 sendto() 소켓 함수에 연결된 프로그램(connect4, sendmsg4)에서는 소켓의 목적지 주소를 백엔드 주소와 포트로 변환하고, cilium_lb4_backends 맵에 백엔드 주소와 포트를 등록해놓습니다.</li>
  <li>
    <p>이후 recvmsg() 소켓 함수에 연결된 프로그램(recvmsg4)에서는 cilium_lb4_reverse_nat 맵을 이용해서 목적지 주소와 포트를 다시 서비스 주소와 포트로 변환합니다.
<img src="/assets/2025/cilium/w1/20250720_cilium_w1_14.png" alt="img.png" class="image-center" />
<em class="image-caption">https://k8s.networkop.co.uk/services/clusterip/dataplane/ebpf/</em></p>
  </li>
  <li>실습 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># curl 호출</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl webpod

<span class="c"># 신규 터미널 : 파드에서 SVC(ClusterIP) 접속 시 tcpdump 로 확인 : ClusterIP가 소켓 레벨에서 이미 Endpoint 로 변경되었음을 확인!</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>curl-pod <span class="nt">--</span> tcpdump <span class="nt">-enni</span> any <span class="nt">-q</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    14:09:05.318403 eth0  Out ifindex 11 d6:ab:bb:21:3a:93 172.20.2.15.40982 &gt; 172.20.1.123.80: tcp 0</span>
<span class="c">#    14:09:05.319286 eth0  In  ifindex 11 76:62:d3:8d:58:1f 172.20.1.123.80 &gt; 172.20.2.15.40982: tcp 0</span>
<span class="c">#    ...</span>

<span class="c"># Socket-Based LoadBalancing 관련 설정들 확인</span>
<span class="nv">$ </span>c0 status <span class="nt">--verbose</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    KubeProxyReplacement Details:</span>
<span class="c">#      Status:                 True</span>
<span class="c">#      Socket LB:              Enabled</span>
<span class="c">#      Socket LB Tracing:      Enabled</span>
<span class="c">#      Socket LB Coverage:     Full</span>
<span class="c">#      Devices:                eth0    10.0.2.15 fd17:625c:f037:2:a00:27ff:fe71:19d8 fe80::a00:27ff:fe71:19d8, eth1   192.168.10.100 fe80::a00:27ff:feda:2493 (Direct Routing)</span>
<span class="c">#      Mode:                   SNAT</span>
<span class="c">#      Backend Selection:      Random</span>
<span class="c">#      Session Affinity:       Enabled</span>
<span class="c">#      Graceful Termination:   Enabled</span>
<span class="c">#      NAT46/64 Support:       Disabled</span>
<span class="c">#      XDP Acceleration:       Disabled</span>
<span class="c">#      Services:</span>
<span class="c">#      - ClusterIP:      Enabled</span>
<span class="c">#      - NodePort:       Enabled (Range: 30000-32767)</span>
<span class="c">#      - LoadBalancer:   Enabled</span>
  
<span class="c"># syscall 호출 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>curl-pod <span class="nt">--</span> strace <span class="nt">-c</span> curl <span class="nt">-s</span> webpod
<span class="c"># =&gt; ...</span>
<span class="c">#    % time     seconds  usecs/call     calls    errors syscall</span>
<span class="c">#    ------ ----------- ----------- --------- --------- ----------------</span>
<span class="c">#     &lt;span style="color: green;"&gt;19.00    0.001003         334         3         1 connect&lt;/span&gt;</span>
<span class="c">#     15.97    0.000843         281         3           sendto</span>
<span class="c">#     15.82    0.000835          23        35           munmap</span>
<span class="c">#     10.59    0.000559          93         6         3 recvfrom</span>
<span class="c">#     10.33    0.000545           8        63           mmap</span>
<span class="c">#      7.58    0.000400           8        47        30 openat</span>
<span class="c">#      4.32    0.000228          10        22           close</span>
<span class="c">#      3.87    0.000204          20        10           lseek</span>
<span class="c">#      2.94    0.000155           6        24           fcntl</span>
<span class="c">#      2.56    0.000135           4        28           rt_sigaction</span>
<span class="c">#      1.46    0.000077           8         9           ppoll</span>
<span class="c">#      1.23    0.000065          16         4           socket</span>
<span class="c">#      0.72    0.000038          12         3         3 ioctl</span>
<span class="c">#      0.68    0.000036          36         1           newfstatat</span>
<span class="c">#      0.63    0.000033           2        14           mprotect</span>
<span class="c">#      &lt;span style="color: green;"&gt;0.63    0.000033           1        27           read&lt;/span&gt;</span>
<span class="c">#      0.55    0.000029           9         3           readv</span>
<span class="c">#      0.21    0.000011           0        12           fstat</span>
<span class="c">#      0.21    0.000011           0        14           rt_sigprocmask</span>
<span class="c">#      0.17    0.000009           9         1           writev</span>
<span class="c">#      0.15    0.000008           1         5           setsockopt</span>
<span class="c">#      &lt;span style="color: green;"&gt;0.15    0.000008           1         5           getsockname&lt;/span&gt;</span>
<span class="c">#      0.09    0.000005           5         1           eventfd2</span>
<span class="c">#      0.06    0.000003           0         4           brk</span>
<span class="c">#      0.04    0.000002           2         1           getrandom</span>
<span class="c">#      &lt;span style="color: green;"&gt;0.04    0.000002           2         1           getsockopt&lt;/span&gt;</span>
<span class="c">#      0.02    0.000001           1         1           getgid</span>
<span class="c">#      0.00    0.000000           0         1           set_tid_address</span>
<span class="c">#      0.00    0.000000           0         1           getuid</span>
<span class="c">#      0.00    0.000000           0         2           geteuid</span>
<span class="c">#      0.00    0.000000           0         1           getegid</span>
<span class="c">#      0.00    0.000000           0         1           execve</span>
<span class="c">#    ------ ----------- ----------- --------- --------- ----------------</span>
<span class="c">#    100.00    0.005278          14       353        37 total</span>

<span class="c"># 상세 출력</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>curl-pod <span class="nt">--</span> strace <span class="nt">-s</span> 65535 <span class="nt">-f</span> <span class="nt">-tt</span> curl <span class="nt">-s</span> webpod

<span class="c"># 특정 이벤트 필터링 : -e</span>
<span class="c">## connect 로 출력되는 10.96.62.184 는 webpod Service 의 ClusterIP입니다.</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>curl-pod <span class="nt">--</span> strace <span class="nt">-e</span> <span class="nv">trace</span><span class="o">=</span>connect     curl <span class="nt">-s</span> webpod
<span class="c"># =&gt; connect(5, {sa_family=AF_INET, sin_port=htons(80), sin_addr=inet_addr("10.96.62.184")}, 16) = 0</span>
<span class="c">#    connect(4, {sa_family=AF_INET, sin_port=htons(80), sin_addr=inet_addr("10.96.62.184")}, 16) = -1 EINPROGRESS (Operation in progress)</span>
<span class="c">#    ...</span>

<span class="c">## connect 로 출력되는 172.20.2.15 는 curl-pod 의 파드 IP입니다. -&gt; 목적지 webpod 파드 IP가 아닙니다.</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>curl-pod <span class="nt">--</span> strace <span class="nt">-e</span> <span class="nv">trace</span><span class="o">=</span>getsockname curl <span class="nt">-s</span> webpod
<span class="c"># =&gt; getsockname(4, {sa_family=AF_INET, sin_port=htons(52951), sin_addr=inet_addr("172.20.2.15")}, [128 =&gt; 16]) = 0</span>
<span class="c">#    getsockname(5, {sa_family=AF_INET, sin_port=htons(42089), sin_addr=inet_addr("172.20.2.15")}, [16]) = 0</span>
<span class="c">#    getsockname(4, {sa_family=AF_INET, sin_port=htons(60934), sin_addr=inet_addr("172.20.2.15")}, [128 =&gt; 16]) = 0</span>
<span class="c">#    getsockname(4, {sa_family=AF_INET, sin_port=htons(60934), sin_addr=inet_addr("172.20.2.15")}, [128 =&gt; 16]) = 0</span>
<span class="c">#    getsockname(4, {sa_family=AF_INET, sin_port=htons(60934), sin_addr=inet_addr("172.20.2.15")}, [128 =&gt; 16]) = 0</span>

<span class="nv">$ </span>kubectl <span class="nb">exec </span>curl-pod <span class="nt">--</span> strace <span class="nt">-e</span> <span class="nv">trace</span><span class="o">=</span>getsockopt curl <span class="nt">-s</span> webpod
<span class="c"># =&gt; getsockopt(4, SOL_SOCKET, SO_ERROR, [0], [4]) = 0 # 소켓 연결 성공</span>
</code></pre></div></div>

<ul>
  <li>strace를 통해 위와 같이 IP 변환에 대해 알아보려 했지만 
실제로는 소켓 레벨에서 이미 변환이 완료되어 있기 때문에 strace로는 확인할 수 없습니다.</li>
  <li>이는 eBPF를 통해 시스템 콜을 줄여 성능을 향상시키는 Cilium의 특징 중 하나입니다.</li>
  <li>ℹ️ 참고로  strace는 시스템 콜을 추적하는 도구로 다음과 같은 기능들로 사용할 수 있습니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 중단점 트레이싱 : -ttt(첫 열에 기준시간으로부터 흐른 시간 표시) , -T(마지막 필드 time에 시스템 콜에 걸린 시간을 표시) , -p PID(프로세스 ID가 PID 인 프로세스를 트레이싱)</span>
<span class="nv">$ </span>strace <span class="nt">-ttt</span> <span class="nt">-T</span> <span class="nt">-p</span> 1884
  
<span class="c"># 시스템 콜별 통계</span>
<span class="nv">$ </span>strace <span class="nt">-c</span> <span class="nt">-p</span> 1884
  
<span class="c"># 프로그램 실행시 시스템 콜 추적</span>
<span class="nv">$ </span>strace <span class="nb">ls</span>
  
<span class="c"># 옵션 사용해보기 : -s(출력 string 결과 최댓값 지정), -tt(첫 열에 기준시간으로부터 흐른 시간 표시, ms단위), -f(멀티 스레드,멀티 프로레스의 자식 프로세스의 시스템 콜 추적)</span>
<span class="nv">$ </span>strace <span class="nt">-s</span> 65535 <span class="nt">-f</span> <span class="nt">-T</span> <span class="nt">-tt</span> <span class="nt">-o</span> &lt;파일명&gt; <span class="nt">-p</span> &lt;pid&gt;
  
<span class="c"># hostname 명령 분석하기 : -o &lt;파일명&gt; 출력 결과를 파일로 떨구기</span>
<span class="nv">$ </span>strace <span class="nt">-s</span> 65535 <span class="nt">-f</span> <span class="nt">-T</span> <span class="nt">-tt</span> <span class="nt">-o</span> hostname_f_trace <span class="nb">hostname</span> <span class="nt">-f</span>
  
<span class="c"># 특정 이벤트 : -e</span>
<span class="nv">$ </span>strace <span class="nt">-e</span> <span class="nv">trace</span><span class="o">=</span>connect curl ipinfo.io
</code></pre></div>    </div>
  </li>
</ul>

<h3 id="cilium-사용시-주의사항">Cilium 사용시 주의사항</h3>

<ul>
  <li>소켓 기반 로드밸런싱 이용시 Istio(EnvoyProxy)와 같은 사이드카 우회문제가 있을 수 있습니다. <a href="https://velog.io/@haruband/K8S-Cilium-Socket-based-LoadBalancing-%EC%97%90-%EC%9D%98%ED%95%9C-Istio-Envoy-%EC%9A%B0%ED%9A%8C-%EB%AC%B8%EC%A0%9C-%EB%B6%84%EC%84%9D">링크</a>
<img src="/assets/2025/cilium/w1/20250720_cilium_w1_15.png" alt="img.png" />
    <ul>
      <li>앞서 확인한것 처럼 서비스의 IP가 이미 백엔드 IP로 변환되었기 때문에, 서비스 IP기반으로 동작하는 모든 필터가 우회되는 현상입니다.</li>
      <li>해결 방안은 파드 네임스페이스에서는 소켓 기반 로드밸런싱을 사용하지 않는 것입니다. 즉, 호스트 네임스페이스만 사용하게 설정하는 것입니다
        <ul>
          <li>HTTP의 경우 Envoy의 HTTP 필터가 HTTP 패킷의 host 헤더를 필터링하여 패킷의 목적지 주소를 서비스 IP에서 백엔드 IP로 변환을 잘 합니다.</li>
          <li>하지만, HTTP가 아닌 일반 TCP 서비스 (예) Telnet 등)은 위 환경에서 문제가 발생합니다.</li>
        </ul>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 설정</span>
<span class="nv">$ VERSION</span><span class="o">=</span>1.17.5
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--version</span> <span class="nv">$VERSION</span> <span class="nt">--namespace</span> kube-system <span class="nt">--reuse-values</span> <span class="se">\</span>
  <span class="nt">--set</span> socketLB.hostNamespaceOnly<span class="o">=</span><span class="nb">true</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system rollout restart ds/cilium
<span class="c"># =&gt; daemonset.apps/cilium restarted</span>
  
<span class="nv">$ </span>cilium config view | <span class="nb">grep </span>bpf-lb-sock-hostns-only
<span class="c"># =&gt; bpf-lb-sock-hostns-only                           true</span>
  
<span class="c"># 확인</span>
<span class="c"># 지속적으로 접속 트래픽 발생</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>kubectl <span class="nb">exec </span>curl-pod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nv">$SVCIP</span> | <span class="nb">grep </span>Hostname<span class="p">;</span><span class="nb">echo</span> <span class="s2">"-----"</span><span class="p">;</span><span class="nb">sleep </span>1<span class="p">;</span><span class="k">done</span>
<span class="c"># =&gt; Hostname: webpod-86f878c468-448pc</span>
<span class="c">#    -----</span>
<span class="c">#    Hostname: webpod-86f878c468-ttbs2</span>
<span class="c">#    -----</span>
<span class="c">#    Hostname: webpod-86f878c468-ttbs2</span>
<span class="c">#    ...</span>
  
<span class="c"># 파드에서 SVC(ClusterIP) 접속 시 tcpdump 로 확인 &gt;&gt; 파드 내부 캡쳐인데, SVC(10.96.62.184) 트래픽이 보인다!</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>curl-pod <span class="nt">--</span> tcpdump <span class="nt">-enni</span> any <span class="nt">-q</span>
<span class="c"># =&gt; 14:38:41.369005 eth0  Out ifindex 11 d6:ab:bb:21:3a:93 172.20.2.15.52976 &gt; &lt;span style="color: green;"&gt;10.96.62.184.80&lt;/span&gt;: tcp 0</span>
<span class="c">#    14:38:41.369050 eth0  Out ifindex 11 d6:ab:bb:21:3a:93 172.20.2.15.52976 &gt; &lt;span style="color: green;"&gt;10.96.62.184.80&lt;/span&gt;: tcp 76</span>
<span class="c">#    14:38:41.369767 eth0  In  ifindex 11 76:62:d3:8d:58:1f &lt;span style="color: green;"&gt;10.96.62.184.80&lt;/span&gt; &gt; 172.20.2.15.52976: tcp 0</span>
<span class="c">#    14:38:41.370802 eth0  In  ifindex 11 76:62:d3:8d:58:1f &lt;span style="color: green;"&gt;10.96.62.184.80&lt;/span&gt; &gt; 172.20.2.15.52976: tcp 327</span>
<span class="c">#    ...	</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li>Service ClusterIP로 NFS나 SMB 같은 프로토콜을 사용하면 문제가 발생할 수 있습니다. (Longhorn, Portworx, Robin 등) - <a href="https://docs.cilium.io/en/stable/network/kubernetes/kubeproxy-free/#limitations">Docs</a>, <a href="https://github.com/cilium/cilium/issues/21541">Issue</a>
    <ul>
      <li>Cilium의 eBPF를 통한 kube-proxy 대체 기능은 socket기반 로드밸런싱을 사용하기 때문에, 앞서 살펴본것 처럼 서비스 IP가 백엔드 IP로 변환되어 사용됩니다.</li>
      <li>NFS나 SMB 프로토콜은 서비스 IP를 사용하여 통신하기 때문에, socket기반 로드밸런싱을 사용하면 문제가 발생할 수 있습니다.
이 문제는 Longhorn, Portworx, Robin 등과 같은 스토리지 시스템에서 발생할 수 있으며, <code class="language-plaintext highlighter-rouge">ReadWriteMany</code> 모드를 사용하는 다른 스토리지 시스템에서도 발생할 수 있습니다.</li>
      <li>이를 해결하기 위해서는 다음의 패치들이 커널에 포함되어있어야 합니다.
        <ul>
          <li><code class="language-plaintext highlighter-rouge">0bdf399342c5 ("net: Avoid address overwrite in kernel_connect")</code></li>
          <li><code class="language-plaintext highlighter-rouge">86a7e0b69bd5 ("net: prevent rewrite of msg_name in sock_sendmsg()")</code></li>
          <li><code class="language-plaintext highlighter-rouge">01b2885d9415 ("net: Save and restore msg_namelen in sock_sendmsg")</code></li>
          <li><code class="language-plaintext highlighter-rouge">cedc019b9f26 ("smb: use kernel_connect() and kernel_bind()")</code> (SMB only)</li>
        </ul>
      </li>
      <li>위의 패치들은 많은 안정화 커널버전에 백포트 되었으며, 아래의 배포판 중 해당 버전 이상에서는 해결되었습니다.
        <ul>
          <li><strong>Ubuntu</strong>: <code class="language-plaintext highlighter-rouge">5.4.0-187-generic</code>, <code class="language-plaintext highlighter-rouge">5.15.0-113-generic</code>, <code class="language-plaintext highlighter-rouge">6.5.0-41-generic</code> or newer.</li>
          <li><strong>RHEL 8</strong>: <code class="language-plaintext highlighter-rouge">4.18.0-553.8.1.el8_10.x86_64</code> or newer (RHEL 8.10+).</li>
          <li><strong>RHEL 9</strong>: <code class="language-plaintext highlighter-rouge">kernel-5.14.0-427.31.1.el9_4</code> or newer (RHEL 9.4+).</li>
        </ul>
      </li>
      <li>보다 자세한 사항은 <a href="https://github.com/cilium/cilium/issues/21541">Github Issue 21541</a>를 확인하세요.</li>
    </ul>
  </li>
  <li>Cilium은 kubernetes의 중추적인 역할을 하는 kube-proxy를 대체하기 때문에, Linux Network Stack을 사용하는 애플리케이션 등을
적용시 꼭 사전 검증이 필요합니다.</li>
</ul>

<hr />

<h2 id="마치며">마치며</h2>

<p>이번 주에는 가장 기본적인 CNI인 Flannel과 가장 고도화된 CNI 중의 하나인 Cilium을 살펴보았습니다.
한번에 두가지를 비교해 보면서 Cilium의 특징과 장점을 확인하는 시간이었습니다.
또한 Cilium이 기능적으로 혁신적이고 최근 기술인 만큼 아직 엣지 케이스가 많이 남아있다는 것도 알 수 있었습니다.</p>

<p>줌 영상 스터디로 한번 설명을 듣고, 정리된 실습자료를 따라하는데 시간이 쭉쭉 가고, 이해가 잘 안 가는 부분이 많은데, 
스터디를 준비해주시는 CloudNet@ 팀 분들이 얼마나 정성과 시간을 쏟았을지 감사한 마음이 듭니다.</p>

<p>마지막으로 실습환경을 삭제하며 마치겠습니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>vagrant destroy <span class="nt">-f</span> <span class="o">&amp;&amp;</span> <span class="nb">rm</span> <span class="nt">-rf</span> .vagrant
</code></pre></div></div>

<hr />

<ul>
  <li>💁 참고 : Cilium CMD Cheatsheet
    <ul>
      <li>Cheatsheet - <a href="https://docs.cilium.io/en/stable/cheatsheet/">Docs</a></li>
      <li>CMD References - <a href="https://docs.cilium.io/en/stable/cmdref/">Docs</a></li>
    </ul>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># cilium 파드 이름</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD0</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-ctr <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD1</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-w1  <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD2</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-w2  <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$CILIUMPOD0</span> <span class="nv">$CILIUMPOD1</span> <span class="nv">$CILIUMPOD2</span>
  
<span class="c"># 단축키(alias) 지정</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c0</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD0</span><span class="s2"> -n kube-system -c cilium-agent -- cilium"</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c1</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD1</span><span class="s2"> -n kube-system -c cilium-agent -- cilium"</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c2</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD2</span><span class="s2"> -n kube-system -c cilium-agent -- cilium"</span>
  
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c0bpf</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD0</span><span class="s2"> -n kube-system -c cilium-agent -- bpftool"</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c1bpf</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD1</span><span class="s2"> -n kube-system -c cilium-agent -- bpftool"</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c2bpf</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD2</span><span class="s2"> -n kube-system -c cilium-agent -- bpftool"</span>
  
<span class="c"># endpoint</span>
<span class="nv">$ </span>c0 endpoint list
<span class="nv">$ </span>c0 endpoint list <span class="nt">-o</span> json
<span class="nv">$ </span>c1 endpoint list
<span class="nv">$ </span>c2 endpoint list
  
<span class="nv">$ </span>c1 endpoint get &lt;<span class="nb">id</span><span class="o">&gt;</span>
<span class="nv">$ </span>c1 endpoint log &lt;<span class="nb">id</span><span class="o">&gt;</span>
  
<span class="c">## Enable debugging output on the cilium-dbg monitor for this endpoint</span>
<span class="nv">$ </span>c1 endpoint config &lt;<span class="nb">id</span><span class="o">&gt;</span> <span class="nv">Debug</span><span class="o">=</span><span class="nb">true</span>
  
<span class="c"># monitor</span>
<span class="nv">$ </span>c1 monitor
<span class="nv">$ </span>c1 monitor <span class="nt">-v</span>
<span class="nv">$ </span>c1 monitor <span class="nt">-v</span> <span class="nt">-v</span>
  
<span class="c">## Filter for only the events related to endpoint</span>
<span class="nv">$ </span>c1 monitor <span class="nt">--related-to</span><span class="o">=</span>&lt;<span class="nb">id</span><span class="o">&gt;</span>
  
<span class="c">## Show notifications only for dropped packet events</span>
<span class="nv">$ </span>c1 monitor <span class="nt">--type</span> drop
  
<span class="c">## Don’t dissect packet payload, display payload in hex information</span>
<span class="nv">$ </span>c1 monitor <span class="nt">-v</span> <span class="nt">-v</span> <span class="nt">--hex</span>
  
<span class="c">## Layer7</span>
<span class="nv">$ </span>c1 monitor <span class="nt">-v</span> <span class="nt">--type</span> l7
  
<span class="c"># Manage IP addresses and associated information - IP List</span>
<span class="nv">$ </span>c0 ip list
  
<span class="c"># IDENTITY :  1(host), 2(world), 4(health), 6(remote), 파드마다 개별 ID</span>
<span class="nv">$ </span>c0 ip list <span class="nt">-n</span>
  
<span class="c"># Retrieve information about an identity</span>
<span class="nv">$ </span>c0 identity list
  
<span class="c"># 엔드포인트 기준 ID</span>
<span class="nv">$ </span>c0 identity list <span class="nt">--endpoints</span>
  
<span class="c"># 엔드포인트 설정 확인 및 변경</span>
<span class="nv">$ </span>c0 endpoint config &lt;엔트포인트ID&gt;
  
<span class="c"># 엔드포인트 상세 정보 확인</span>
<span class="nv">$ </span>c0 endpoint get &lt;엔트포인트ID&gt;
  
<span class="c"># 엔드포인트 로그 확인</span>
<span class="nv">$ </span>c0 endpoint log &lt;엔트포인트ID&gt;
  
<span class="c"># Show bpf filesystem mount details</span>
<span class="nv">$ </span>c0 bpf fs show
  
<span class="c"># bfp 마운트 폴더 확인</span>
<span class="nv">$ </span>tree /sys/fs/bpf
  
<span class="c"># Get list of loadbalancer services</span>
<span class="nv">$ </span>c0 service list
<span class="nv">$ </span>c1 service list
<span class="nv">$ </span>c2 service list
  
<span class="c">## Or you can get the loadbalancer information using bpf list</span>
<span class="nv">$ </span>c0 bpf lb list
<span class="nv">$ </span>c1 bpf lb list
<span class="nv">$ </span>c2 bpf lb list
  
<span class="c">## List reverse NAT entries</span>
<span class="nv">$ </span>c1 bpf lb list <span class="nt">--revnat</span>
<span class="nv">$ </span>c2 bpf lb list <span class="nt">--revnat</span>
  
<span class="c"># List connection tracking entries</span>
<span class="nv">$ </span>c0 bpf ct list global
<span class="nv">$ </span>c1 bpf ct list global
<span class="nv">$ </span>c2 bpf ct list global
  
<span class="c"># Flush connection tracking entries</span>
<span class="nv">$ </span>c0 bpf ct flush
<span class="nv">$ </span>c1 bpf ct flush
<span class="nv">$ </span>c2 bpf ct flush
  
<span class="c"># List all NAT mapping entries</span>
<span class="nv">$ </span>c0 bpf nat list
<span class="nv">$ </span>c1 bpf nat list
<span class="nv">$ </span>c2 bpf nat list
  
<span class="c"># Flush all NAT mapping entries</span>
<span class="nv">$ </span>c0 bpf nat flush
<span class="nv">$ </span>c1 bpf nat flush
<span class="nv">$ </span>c2 bpf nat flush
  
<span class="c"># Manage the IPCache mappings for IP/CIDR &lt;-&gt; Identity</span>
<span class="nv">$ </span>c0 bpf ipcache list# Display cgroup metadata maintained by Cilium
<span class="nv">$ </span>c0 cgroups list
<span class="nv">$ </span>c1 cgroups list
<span class="nv">$ </span>c2 cgroups list
  
<span class="c"># List all open BPF maps</span>
<span class="nv">$ </span>c0 map list
<span class="nv">$ </span>c1 map list <span class="nt">--verbose</span>
<span class="nv">$ </span>c2 map list <span class="nt">--verbose</span>
  
<span class="nv">$ </span>c1 map events cilium_lb4_services_v2
<span class="nv">$ </span>c1 map events cilium_lb4_reverse_nat
<span class="nv">$ </span>c1 map events cilium_lxc
<span class="nv">$ </span>c1 map events cilium_ipcache
  
<span class="c"># List all metrics</span>
<span class="nv">$ </span>c1 metrics list
  
<span class="c"># List contents of a policy BPF map : Dump all policy maps</span>
<span class="nv">$ </span>c0 bpf policy get <span class="nt">--all</span>
<span class="nv">$ </span>c1 bpf policy get <span class="nt">--all</span> <span class="nt">-n</span>
<span class="nv">$ </span>c2 bpf policy get <span class="nt">--all</span> <span class="nt">-n</span>
  
<span class="c"># Dump StateDB contents as JSON</span>
<span class="nv">$ </span>c0 statedb dump
  
<span class="c">#</span>
<span class="nv">$ </span>c0 shell <span class="nt">--</span> db/show devices
<span class="nv">$ </span>c1 shell <span class="nt">--</span> db/show devices
<span class="nv">$ </span>c2 shell <span class="nt">--</span> db/show devices 
</code></pre></div>    </div>
  </li>
</ul>]]></content><author><name></name></author><category term="cilium" /><category term="kubernetes," /><category term="network," /><category term="linux," /><category term="cilium" /><summary type="html"><![CDATA[Cilium CNI를 실습하기 위한 환경을 구성하고 Cilium을 설치하는 방법을 알아봅니다.]]></summary></entry><entry><title type="html">MacOS 업데이트 후 Magnet이 자동 시작이 안 될 때 해결 방법</title><link href="https://sweetlittlebird.github.io/posts/2025-06-28-MacOS-%EC%97%85%EB%8D%B0%EC%9D%B4%ED%8A%B8-%ED%9B%84-Magnet%EC%9D%B4-%EC%9E%90%EB%8F%99-%EC%8B%9C%EC%9E%91%EC%9D%B4-%EC%95%88-%EB%90%A0-%EB%95%8C-%ED%95%B4%EA%B2%B0-%EB%B0%A9%EB%B2%95/" rel="alternate" type="text/html" title="MacOS 업데이트 후 Magnet이 자동 시작이 안 될 때 해결 방법" /><published>2025-06-28T10:00:00+09:00</published><updated>2025-06-28T10:00:00+09:00</updated><id>https://sweetlittlebird.github.io/posts/MacOS%20%EC%97%85%EB%8D%B0%EC%9D%B4%ED%8A%B8%20%ED%9B%84%20Magnet%EC%9D%B4%20%EC%9E%90%EB%8F%99%20%EC%8B%9C%EC%9E%91%EC%9D%B4%20%EC%95%88%20%EB%90%A0%20%EB%95%8C%20%ED%95%B4%EA%B2%B0%20%EB%B0%A9%EB%B2%95</id><content type="html" xml:base="https://sweetlittlebird.github.io/posts/2025-06-28-MacOS-%EC%97%85%EB%8D%B0%EC%9D%B4%ED%8A%B8-%ED%9B%84-Magnet%EC%9D%B4-%EC%9E%90%EB%8F%99-%EC%8B%9C%EC%9E%91%EC%9D%B4-%EC%95%88-%EB%90%A0-%EB%95%8C-%ED%95%B4%EA%B2%B0-%EB%B0%A9%EB%B2%95/"><![CDATA[<h2 id="들어가며">들어가며</h2>

<p><img src="/assets/2025/2025-06-28/img.png" alt="img.png" class="w-20 image-center" /></p>

<p>Magnet은 MacOS에서 창 관리를 도와주는 유용한 앱입니다. 
유료 앱이고 Mac App Store에서 구매해야 하지만, 그만한 가치를 제공합니다.
무료로 사용할 수 있는 <a href="https://rectangleapp.com/">Rectangle</a>과 같은 대안도 있지만, 
무상 업데이트를 계속 해주고 있고 Mac App Store에서 구매할 수 있기 때문에 믿을 수 있어서
계속 사용하고 있습니다.</p>

<p>하지만 MacOS 업데이트 후 Magnet이 자동으로 시작되지 않는 문제가 발생할 수 있습니다. 이 글에서는 이 문제를 해결하는 방법을 알아보겠습니다.</p>

<h2 id="문제-발생">문제 발생</h2>

<p>MacOS Ventura에서 Sequoia로 업데이트한 후 Magnet이 기능은 정상적으로 동작하지만,
자동으로 시작되지 않는 문제가 발생했습니다.
시스템 설정에서 
<code class="language-plaintext highlighter-rouge">시스템 설정 &gt; 일반 &gt; 로그인 항목</code>에 Magnet이 등록되어있지 않고 
<code class="language-plaintext highlighter-rouge">시스템 설정 &gt; 일반 &gt; 로그인 항목 &gt; + 버튼</code>을 눌러서 Magnet을 추가해도 추가되지 않았습니다.</p>

<p>수동으로 켜면 되지만 매번 수동으로 켜는 것은 번거롭기 때문에
문제 해결 방법을 찾아보았습니다.</p>

<h2 id="해결-방법">해결 방법</h2>

<p><a href="https://www.reddit.com/r/MacOS/comments/101s7d3/magnet_app_does_not_start_on_boot/">레딧 글</a>에서 해결방법을 찾아서
여기에 남겨 봅니다.</p>

<ol>
  <li>접근성 권한 재설정
    <ul>
      <li>Magnet 종료 → <code class="language-plaintext highlighter-rouge">시스템 설정 &gt; 개인정보 보호 및 보안 &gt; 접근성</code>에서 Magnet 비활성화 및 제거</li>
    </ul>
  </li>
  <li>앱 및 설정 파일 완전 삭제
    <ul>
      <li>Magnet 앱을 응용 프로그램 폴더에서 삭제.</li>
      <li>~/Library/Preferences 폴더에서 com.crowdcafe.windowmagnet.plist 파일 삭제.</li>
      <li>휴지통 비우기 및 Mac 재시동.</li>
    </ul>
  </li>
  <li>앱 재설치 및 권한 재부여
    <ul>
      <li>App Store에서 Magnet 최신 버전 다운로드 및 설치.</li>
      <li>Magnet 실행 후 접근성 권한 요청 시, 반드시 허용.</li>
      <li>Magnet 환경설정에서 ‘로그인 시 자동 실행(Launch at Login)’ 옵션 활성화.</li>
    </ul>
  </li>
  <li>문제 지속 시
    <ul>
      <li>위 과정을 반복해도 문제가 계속된다면, Magnet 개발사에 버그 리포트 제출</li>
    </ul>
  </li>
</ol>

<h2 id="마치며">마치며</h2>

<p>이 방법으로 Magnet이 자동으로 시작되지 않는 문제를 해결할 수 있었습니다.
블로그 글을 쓰다보니 해결하는 방법보다 부가적인 내용을 더 많이 작성한 것 같습니다.
이게 맞나 싶긴한데 반년동안 방치했던 블로그를 다시 시작하는 의미로
작성해봅니다. 다음번에는 더 유익한 글로 찾아뵙기를 기원해봅니다. :pray:</p>

<p>ps. 업데이트 후 Magnet에 설정기능이 굉장히 강력해진것을 발견했습니다.
무상으로 이렇게 좋은 기능을 제공해주다니 개발사에 감사할 따름입니다.</p>

<p><img src="/assets/2025/2025-06-28/20250628_magnet.png" alt="img.png" class="w-80 image-center" /></p>]]></content><author><name></name></author><category term="macos," /><category term="troubleshooting" /><category term="macos," /><category term="magnet," /><category term="troubleshooting" /><summary type="html"><![CDATA[Magnet은 MacOS에서 창 관리를 도와주는 유용한 앱입니다. MacOS 업데이트 후 Magnet이 자동으로 시작되지 않는 문제를 해결하는 방법을 알아봅니다.]]></summary></entry><entry><title type="html">[CI/CD] Jenkins CI/ArgoCD + K8S</title><link href="https://sweetlittlebird.github.io/posts/2024-12-22-CICD-Lite-Week3/" rel="alternate" type="text/html" title="[CI/CD] Jenkins CI/ArgoCD + K8S" /><published>2024-12-22T00:01:18+09:00</published><updated>2024-12-22T00:01:18+09:00</updated><id>https://sweetlittlebird.github.io/posts/CICD%20Lite%20-%20Week3</id><content type="html" xml:base="https://sweetlittlebird.github.io/posts/2024-12-22-CICD-Lite-Week3/"><![CDATA[<h2 id="들어가며">들어가며</h2>

<p>이번 주에는 ArgoCD와 Jenkins를 사용하여 Kubernetes로의 배포를 하는 CI/CD를 구성해보겠습니다.</p>

<h2 id="jenkins-ciargocd--k8s">Jenkins CI/ArgoCD + K8S</h2>

<h3 id="실습환경-구성">실습환경 구성</h3>

<ul>
  <li>이번에는 개발 PC에 Jenkins와 Gogs를 설치하고, Kind를 사용하여 Kubernetes 클러스터를 구성하고 ArgoCD를 설치하여 CI/CD를 구성해보겠습니다.</li>
</ul>

<h4 id="jenkins-gogs-설치">Jenkins, Gogs 설치</h4>

<ul>
  <li>Jenkins의 경우 1주차에서 설치하였지만 다시 한번 되짚어 보겠습니다.</li>
  <li>또한 이번에는 Gitlab 클라우드 서비스 대신, 자체 PC에 Gogs를 설치하여 사용해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 작업 디렉토리 생성 후 이동</span>
<span class="nv">$ </span><span class="nb">mkdir </span>cicd-labs
<span class="nv">$ </span><span class="nb">cd </span>cicd-labs

<span class="c"># </span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh"> &gt; docker-compose.yaml
services:

  jenkins:
    container_name: jenkins
    image: jenkins/jenkins
    restart: unless-stopped
    networks:
      - cicd-network
    ports:
      - "8080:8080"
      - "50000:50000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - jenkins_home:/var/jenkins_home

  gogs:
    container_name: gogs
    image: gogs/gogs
    restart: unless-stopped
    networks:
      - cicd-network
    ports:
      - "10022:22"
      - "3000:3000"
    volumes:
      - gogs-data:/data

volumes:
  jenkins_home:
  gogs-data:

networks:
  cicd-network:
    driver: bridge
</span><span class="no">EOT


</span><span class="c"># 배포</span>
<span class="nv">$ </span>docker compose up <span class="nt">-d</span>
<span class="c"># =&gt; [+] Running 2/2</span>
<span class="c">#     ⠿ Container jenkins  Started  0.5s</span>
<span class="c">#     ⠿ Container gogs     Started  0.5s</span>
<span class="nv">$ </span>docker compose ps
<span class="c"># =&gt; NAME                COMMAND                  SERVICE             STATUS              PORTS</span>
<span class="c">#    gogs                &amp;quot;/app/gogs/docker/st…&amp;quot;   gogs                running (healthy)   0.0.0.0:10022-&amp;gt;22/tcp, 0.0.0.0:3000-&amp;gt;3000/tcp</span>
<span class="c">#    jenkins             &amp;quot;/usr/bin/tini -- /u…&amp;quot;   jenkins             running             0.0.0.0:8080-&amp;gt;8080/tcp, 0.0.0.0:50000-&amp;gt;50000/tcp</span>

<span class="c"># 기본 정보 확인</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>gogs jenkins <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; container : </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker compose <span class="nb">exec</span> <span class="nv">$i</span> sh <span class="nt">-c</span> <span class="s2">"whoami &amp;&amp; pwd"</span><span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; container : gogs &amp;lt;&amp;lt;</span>
<span class="c">#    root</span>
<span class="c">#    /app/gogs</span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; container : jenkins &amp;lt;&amp;lt;</span>
<span class="c">#    jenkins</span>
<span class="c">#    /</span>

<span class="c"># 도커를 이용하여 각 컨테이너로 접속</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins bash
<span class="nv">$ </span><span class="nb">exit</span>

<span class="nv">$ </span>docker compose <span class="nb">exec </span>gogs bash
<span class="nv">$ </span><span class="nb">exit</span>
</code></pre></div></div>

<h4 id="jenkins-컨테이너-초기설정">Jenkins 컨테이너 초기설정</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Jenkins 초기 암호 확인</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins <span class="nb">cat</span> /var/jenkins_home/secrets/initialAdminPassword
<span class="c"># =&gt; 3da38dccc7d14d1a8bee4b02c4e09da8</span>

<span class="c"># Jenkins 웹 접속 주소 확인 : 계정 / 암호 입력 &gt;&gt; **admin / qwe123**</span>
<span class="nv">$ </span>open <span class="s2">"http://127.0.0.1:8080"</span> <span class="c"># macOS</span>

<span class="c"># (참고) 로그 확인 : 플러그인 설치 과정 확인</span>
<span class="nv">$ </span>docker compose logs jenkins <span class="nt">-f</span>

<span class="c"># IP 확인 (MacOS 기준)</span>
<span class="nv">$ </span>ifconfig | <span class="nb">grep</span> <span class="s2">"inet "</span> | <span class="nb">grep</span> <span class="nt">-v</span> 127.0.0
<span class="c"># =&gt; inet &lt;span style="color: red;"&gt;10.0.4.3&lt;/span&gt; netmask 0xffffff00 broadcast 10.0.4.255</span>
<span class="c"># 또는</span>
<span class="nv">$ </span>ipconfig getifaddr en0
<span class="c"># =&gt; &lt;span style="color: red;"&gt;10.0.4.3&lt;/span&gt;</span>
</code></pre></div></div>

<ul>
  <li>Jenkins URL 설정</li>
</ul>

<p>앞서 확인한 IP 주소를 이용하여 Jenkins URL을 설정합니다.</p>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_1.png" alt="img.png" /></p>

<ul>
  <li>1주차때와 마찬가지로 Docker-out-of-Docker를 사용하겠습니다. 자세한 내용은 <a href="https://sweetlittlebird.github.io/posts/2024-12-08-CICD-Lite-Week1/#jenkins-%EC%86%8C%EA%B0%9C">1주차 내용</a>을 참고하세요.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Jenkins 컨테이너 내부에 도커 실행 파일 설치</span>
<span class="nv">$ </span>docker compose <span class="nb">exec</span> <span class="nt">--privileged</span> <span class="nt">-u</span> root jenkins bash
<span class="nt">-----------------------------------------------------</span>
<span class="nv">$ </span><span class="nb">id</span>

<span class="nv">$ </span>curl <span class="nt">-fsSL</span> https://download.docker.com/linux/debian/gpg <span class="nt">-o</span> /etc/apt/keyrings/docker.asc
<span class="c"># =&gt; uid=0(root) gid=0(root) groups=0(root)</span>
<span class="nv">$ </span><span class="nb">chmod </span>a+r /etc/apt/keyrings/docker.asc
<span class="nv">$ </span><span class="nb">echo</span> <span class="se">\</span>
  <span class="s2">"deb [arch=</span><span class="si">$(</span>dpkg <span class="nt">--print-architecture</span><span class="si">)</span><span class="s2"> signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/debian </span><span class="se">\</span><span class="s2">
  </span><span class="si">$(</span><span class="nb">.</span> /etc/os-release <span class="o">&amp;&amp;</span> <span class="nb">echo</span> <span class="s2">"</span><span class="nv">$VERSION_CODENAME</span><span class="s2">"</span><span class="si">)</span><span class="s2"> stable"</span> | <span class="se">\</span>
  <span class="nb">tee</span> /etc/apt/sources.list.d/docker.list <span class="o">&gt;</span> /dev/null
<span class="nv">$ </span>apt-get update <span class="o">&amp;&amp;</span> apt <span class="nb">install </span>docker-ce-cli curl tree jq yq <span class="nt">-y</span>

<span class="nv">$ </span>docker info
<span class="c"># =&gt; Client: Docker Engine - Community</span>
<span class="c">#     Version:    27.4.1</span>
<span class="c">#     Context:    default</span>
<span class="c">#     Debug Mode: false</span>
<span class="c">#     Plugins:</span>
<span class="c">#      buildx: Docker Buildx (Docker Inc.)</span>
<span class="c">#        Version:  v0.19.3</span>
<span class="c">#        Path:     /usr/libexec/docker/cli-plugins/docker-buildx</span>
<span class="c">#      compose: Docker Compose (Docker Inc.)</span>
<span class="c">#        Version:  v2.32.1</span>
<span class="c">#        Path:     /usr/libexec/docker/cli-plugins/docker-compose</span>
<span class="c">#    </span>
<span class="c">#    Server:</span>
<span class="c">#     Containers: 29</span>
<span class="c">#      Running: 2</span>
<span class="c">#      Paused: 0</span>
<span class="c">#      Stopped: 27</span>
<span class="c">#     Images: 42</span>
<span class="c">#     Server Version: 20.10.12</span>
<span class="c">#     Storage Driver: overlay2</span>
<span class="c">#      Backing Filesystem: extfs</span>
<span class="c">#      Supports d_type: true</span>
<span class="c">#      Native Overlay Diff: true</span>
<span class="c">#      userxattr: false</span>
<span class="c">#     Logging Driver: json-file</span>
<span class="c">#     Cgroup Driver: cgroupfs</span>
<span class="c">#     Cgroup Version: 2</span>
<span class="c">#     ...</span>
<span class="c">#     Insecure Registries:</span>
<span class="c">#      hubproxy.docker.internal:5000</span>
<span class="c">#      127.0.0.0/8</span>
<span class="c">#     Live Restore Enabled: false</span>
<span class="nv">$ </span>docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE             COMMAND                  CREATED        STATUS                    PORTS                                              NAMES</span>
<span class="c">#    110494b9ca48   gogs/gogs         &amp;quot;/app/gogs/docker/st…&amp;quot;   14 hours ago   Up 37 minutes (healthy)   0.0.0.0:3000-&amp;gt;3000/tcp, 0.0.0.0:10022-&amp;gt;22/tcp      gogs</span>
<span class="c">#    8b7c591c828d   jenkins/jenkins   &amp;quot;/usr/bin/tini -- /u…&amp;quot;   14 hours ago   Up 37 minutes             0.0.0.0:8080-&amp;gt;8080/tcp, 0.0.0.0:50000-&amp;gt;50000/tcp   jenkins</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 DooD이기 때문에 호스트에서 동작중인 컨테이너가 보입니다.&lt;/span&gt;</span>
<span class="nv">$ </span>which docker
<span class="c"># =&gt; /usr/bin/docker</span>

<span class="c"># Jenkins 컨테이너 내부에서 root가 아닌 jenkins 유저도 docker를 실행할 수 있도록 권한을 부여</span>
<span class="nv">$ </span>groupadd <span class="nt">-g</span> 2000 <span class="nt">-f</span> docker  <span class="c"># macOS(Container)</span>
<span class="c"># $ groupadd -g 1001 -f docker  # Windows WSL2(Container) &gt;&gt; cat /etc/group 에서 docker 그룹ID를 지정</span>

<span class="nv">$ </span><span class="nb">chgrp </span>docker /var/run/docker.sock
<span class="nv">$ </span><span class="nb">chmod </span>g+w /var/run/docker.sock
<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-l</span> /var/run/docker.sock
<span class="c"># =&gt; srwxrwxr-x 1 root docker 0 Oct 01 06:03 /var/run/docker.sock</span>
<span class="nv">$ </span>usermod <span class="nt">-aG</span> docker jenkins
<span class="nv">$ </span><span class="nb">cat</span> /etc/group | <span class="nb">grep </span>docker
<span class="c"># =&gt; docker:x:2000:jenkins</span>

<span class="nb">exit</span>
<span class="nt">--------------------------------------------</span>

<span class="c"># jenkins item 실행 시 docker 명령 실행 권한 에러 발생 : Jenkins 컨테이너 재기동으로 위 설정 내용을 Jenkins app 에도 적용 필요</span>
<span class="nv">$ </span>docker compose restart jenkins
<span class="c"># =&gt; [+] Running 1/1</span>
<span class="c">#     ⠿ Container jenkins  Started    0.9s</span>
<span class="c"># $ sudo docker compose restart jenkins  # Windows 경우 이후부터 sudo 붙여서 실행하자</span>

<span class="c"># jenkins user로 docker 명령 실행 확인</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins <span class="nb">id</span>
<span class="c"># =&gt; uid=1000(jenkins) gid=1000(jenkins) groups=1000(jenkins),2000(docker)</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins docker info
<span class="c"># =&gt; Client: Docker Engine - Community</span>
<span class="c">#     Version:    27.4.1</span>
<span class="c">#     ...</span>
<span class="c">#    </span>
<span class="c">#    Server:</span>
<span class="c">#     Containers: 29</span>
<span class="c">#      Running: 2</span>
<span class="c">#      Paused: 0</span>
<span class="c">#      Stopped: 27</span>
<span class="c">#     Images: 42</span>
<span class="c">#     Server Version: 20.10.12</span>
<span class="c">#     ...</span>
<span class="c">#     Live Restore Enabled: false</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE             COMMAND                  CREATED        STATUS                    PORTS                                              NAMES</span>
<span class="c">#    110494b9ca48   gogs/gogs         &amp;quot;/app/gogs/docker/st…&amp;quot;   14 hours ago   Up 41 minutes (healthy)   0.0.0.0:3000-&amp;gt;3000/tcp, 0.0.0.0:10022-&amp;gt;22/tcp      gogs</span>
<span class="c">#    8b7c591c828d   jenkins/jenkins   &amp;quot;/usr/bin/tini -- /u…&amp;quot;   14 hours ago   Up 57 seconds             0.0.0.0:8080-&amp;gt;8080/tcp, 0.0.0.0:50000-&amp;gt;50000/tcp   jenkins</span>
</code></pre></div></div>

<ul>
  <li>OS 재부팅시에 jenkins 컨테이너에서 docker 실행이 실패하는 경우가 있는데, 그럴 경우 아래와 같이 docker 그룹을 다시 지정합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 소켓 파일의 권한 확인</span>
<span class="nv">$ </span>docker compose <span class="nb">exec</span> <span class="nt">--privileged</span> <span class="nt">-u</span> root jenkins <span class="nb">ls</span> <span class="nt">-l</span> /var/run/docker.sock
<span class="c"># =&gt; srwxr-xr-x 1 root root 0 Oct 01 05:22 /var/run/docker.sock</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 그룹이 root로 복구되어있습니다. docker 그룹으로 다시 변경해야 합니다.&lt;/span&gt;</span>

<span class="c"># 소켓 파일에 docker 그룹을 다시 지정</span>
<span class="nv">$ </span>docker compose <span class="nb">exec</span> <span class="nt">--privileged</span> <span class="nt">-u</span> root jenkins <span class="nb">chgrp </span>docker /var/run/docker.sock

<span class="c"># 소켓 파일에 docker 그룹 쓰기권한 다시 지정</span>
<span class="nv">$ </span>docker compose <span class="nb">exec</span> <span class="nt">--privileged</span> <span class="nt">-u</span> root jenkins <span class="nb">chmod </span>g+w /var/run/docker.sock

<span class="c"># 확인</span>
<span class="nv">$ </span>docker compose <span class="nb">exec</span> <span class="nt">--privileged</span> <span class="nt">-u</span> root jenkins <span class="nb">ls</span> <span class="nt">-l</span> /var/run/docker.sock
<span class="c"># =&gt; srwxrwxr-x 1 root docker 0 Oct 01 05:22 /var/run/docker.sock</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins docker info
</code></pre></div></div>

<h4 id="gogs-초기-설정">Gogs 초기 설정</h4>

<ul>
  <li>초기설정을 위해 웹 접속을 합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 초기 설정 웹 접속</span>
<span class="nv">$ </span>open <span class="s2">"http://127.0.0.1:3000/install"</span> <span class="c"># macOS</span>
<span class="c"># 웹 브라우저에서 http://127.0.0.1:3000/install 접속 # Windows</span>
</code></pre></div></div>

<ul>
  <li>다음과 같이 설정값을 변경합니다.
    <ul>
      <li>Database Type : SQLite3</li>
      <li>Application URL : <code class="language-plaintext highlighter-rouge">http://&lt;앞에서 확인한 IP&gt;:3000/</code></li>
      <li>Default Branch : main</li>
      <li>관리자 계정 설정 클릭 : username : devops, password : qwe123, email입력
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_2.png" alt="img.png" /></li>
    </ul>
  </li>
  <li>Install Gogs 버튼 클릭 =&gt; 관리자 계정으로 로그인</li>
</ul>

<h5 id="access-token-발행">Access Token 발행</h5>

<ul>
  <li>로그인 후 Your Settings &gt; Applications &gt; Generate New Token 클릭 &gt; Token Name(devops) &gt; Generate Token 클릭하여 토큰을 발행합니다.</li>
  <li>발행된 토큰(<code class="language-plaintext highlighter-rouge">a85f33b7fd28ac1ed83c3233fc4ca3a67c04c296</code>)을 복사하여 안전한 곳에 기록해둡니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_3.png" alt="img.png" /></p>

<h5 id="repository-생성">Repository 생성</h5>

<ul>
  <li>우측상단의 <code class="language-plaintext highlighter-rouge">+</code> 버튼을 클릭하여 나오는 메뉴에서 New Repository를 클릭해서 새로운 Repository를 다음과 같이 2개 생성합니다.</li>
  <li><strong>개발팀용</strong>
    <ul>
      <li>Repository Name : <strong>dev-app</strong></li>
      <li>Visibility : (<strong>Check</strong>) This repository is <strong>Private</strong></li>
      <li>.gitignore : <strong>Python</strong></li>
      <li>Readme : Default → (Check) initialize this repository with selected files and template</li>
    </ul>

    <p>⇒ Create Repository 클릭 =&gt; Repo 주소 확인 (<code class="language-plaintext highlighter-rouge">http://10.0.4.3:3000/devops/dev-apps.git</code>)</p>
  </li>
  <li><strong>데브옵스팀용</strong>
    <ul>
      <li>Repository Name : <strong>ops-deploy</strong></li>
      <li>Visibility : (<strong>체크</strong>) This repository is <strong>Private</strong></li>
      <li>Readme : Default → (체크) initialize this repository with selected files and template</li>
    </ul>

    <p>⇒ Create Repository 클릭 =&gt; Repo 주소 확인 (<code class="language-plaintext highlighter-rouge">http://10.0.4.3:3000/devops/ops-deploy.git</code>)</p>
  </li>
</ul>

<h5 id="gogs-실습을-위해-호스트-pc의-git-설정">Gogs 실습을 위해 호스트 PC의 git 설정</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># (옵션) GIT 인증 정보 초기화</span>
<span class="nv">$ </span>git credential-cache <span class="nb">exit</span>

<span class="c">#</span>
<span class="c"># $ git clone &lt;각자 Gogs dev-app repo 주소&gt;</span>
<span class="nv">$ </span>git clone http://10.0.4.3:3000/devops/dev-app.git
<span class="c"># =&gt; Cloning into 'dev-app'...</span>
<span class="c">#    Username for 'http://10.0.4.3:3000': devops</span>
<span class="c">#    Password for 'http://a@10.0.4.3:3000': # &lt;span style="color: green;"&gt;앞서 발급받은 access key 입력&lt;/span&gt;</span>

<span class="c">#    remote: Enumerating objects: 4, done.</span>
<span class="c">#    remote: Counting objects: 100% (4/4), done.</span>
<span class="c">#    remote: Compressing objects: 100% (3/3), done.</span>
<span class="c">#    remote: Total 4 (delta 0), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    Unpacking objects: 100% (4/4), 705 bytes | 352.00 KiB/s, done.</span>

<span class="c">#</span>
<span class="nv">$ </span><span class="nb">cd </span>dev-app

<span class="c">#</span>
<span class="nv">$ </span>git config user.name <span class="s2">"devops"</span>
<span class="nv">$ </span>git config user.email <span class="s2">"a@a.com"</span>
<span class="nv">$ </span>git config init.defaultBranch main
<span class="nv">$ </span>git config credential.helper store

<span class="c">#</span>
<span class="nv">$ </span>git branch
<span class="c"># =&gt; * main</span>
<span class="nv">$ </span>git remote <span class="nt">-v</span>
<span class="c"># =&gt; origin  http://10.0.4.3:3000/devops/dev-app.git (fetch)</span>
<span class="c">#    origin  http://10.0.4.3:3000/devops/dev-app.git (push)</span>

<span class="c"># server.py 파일 작성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> server.py <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
from http.server import ThreadingHTTPServer, BaseHTTPRequestHandler
from datetime import datetime
import socket

class RequestHandler(BaseHTTPRequestHandler):
    def do_GET(self):
        self.send_response(200)
        self.send_header('Content-type', 'text/plain')
        self.end_headers()
        
        now = datetime.now()
        hostname = socket.gethostname()
        response_string = now.strftime("The time is %-I:%M:%S %p, VERSION 0.0.1</span><span class="se">\n</span><span class="sh">")
        response_string += f"Server hostname: {hostname}</span><span class="se">\n</span><span class="sh">"
        self.wfile.write(bytes(response_string, "utf-8")) 

def startServer():
    try:
        server = ThreadingHTTPServer(('', 80), RequestHandler)
        print("Listening on " + ":".join(map(str, server.server_address)))
        server.serve_forever()
    except KeyboardInterrupt:
        server.shutdown()

if __name__ == "__main__":
    startServer()
</span><span class="no">EOF

</span><span class="c"># Dockerfile 생성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Dockerfile <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
FROM python:3.12
ENV PYTHONUNBUFFERED 1
COPY . /app
WORKDIR /app 
CMD python3 server.py
</span><span class="no">EOF

</span><span class="c"># VERSION 파일 생성</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"0.0.1"</span> <span class="o">&gt;</span> VERSION

<span class="c">#</span>
<span class="nv">$ </span>git status
<span class="c"># =&gt; On branch main</span>
<span class="c">#    Your branch is up to date with 'origin/main'.</span>
<span class="c">#    </span>
<span class="c">#    Untracked files:</span>
<span class="c">#      (use &amp;quot;git add &amp;lt;file&amp;gt;...&amp;quot; to include in what will be committed)</span>
<span class="c">#            Dockerfile</span>
<span class="c">#            VERSION</span>
<span class="c">#            server.py</span>
<span class="c">#    </span>
<span class="c">#    nothing added to commit but untracked files present (use &amp;quot;git add&amp;quot; to track)</span>
<span class="nv">$ </span>git add <span class="nb">.</span>
<span class="nv">$ </span>git commit <span class="nt">-m</span> <span class="s2">"Add dev-app"</span>
<span class="c"># =&gt; [main 3531233] Add dev-app</span>
<span class="c">#     3 files changed, 32 insertions(+)</span>
<span class="c">#     create mode 100644 Dockerfile</span>
<span class="c">#     create mode 100644 VERSION</span>
<span class="c">#     create mode 100644 server.py</span>
<span class="nv">$ </span>git push <span class="nt">-u</span> origin main
<span class="c"># =&gt; Enumerating objects: 6, done.</span>
<span class="c">#    Counting objects: 100% (6/6), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (4/4), done.</span>
<span class="c">#    Writing objects: 100% (5/5), 900 bytes | 900.00 KiB/s, done.</span>
<span class="c">#    Total 5 (delta 0), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To http://10.0.4.3:3000/devops/dev-app.git</span>
<span class="c">#       5c906c3..3531233  main -&amp;gt; main</span>
<span class="c">#    branch 'main' set up to track 'origin/main'.</span>
</code></pre></div></div>

<ul>
  <li>Gogs Repo에서 확인
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_4.png" alt="img.png" /></li>
</ul>

<h4 id="도커-허브--설정">도커 허브  설정</h4>

<ul>
  <li>도커 허브에 로그인하여 dev-app이라는 Repository를 생성합니다. 도커허브 소개와 Repository 생성은 <a href="https://sweetlittlebird.github.io/posts/2024-12-08-CICD-Lite-Week1/#docker-hub-%EC%86%8C%EA%B0%9C">1주차 내용</a>을 참고하세요.</li>
  <li>배포를 편하게 하기위해 Token도 발급하여 사용해보겠습니다.
    <ol>
      <li>계정 &gt; Account Settings &gt; Security 클릭
  <img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_5.png" alt="img.png" class="image-center" /></li>
      <li>New Access Token 클릭
        <ul>
          <li>Token Name : devops</li>
          <li>Expireation date : 만료일을 적절히 선택합니다.</li>
          <li>권한은 Read, Write, Delete를 선택합니다.</li>
          <li>Create 클릭하여 토큰을 생성하고, 발급된 토큰을 복사하여 안전한 곳에 저장합니다.
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_6.png" alt="img.png" class="image-center" />
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_7.png" alt="img_1.png" class="image-center" /></li>
          <li>발급된 토큰 : <code class="language-plaintext highlighter-rouge">dckr_****</code></li>
        </ul>
      </li>
    </ol>
  </li>
</ul>

<hr />

<h3 id="jenkins-ci--k8s-kind">Jenkins CI + K8S (Kind)</h3>

<h4 id="kind-소개-및-설치">Kind 소개 및 설치</h4>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_8.png" alt="img.png" class="w-20 image-center" /></p>

<ul>
  <li>Kind는 Kubernetes in Docker의 줄임말로, 로컬 환경에서 쉽게 Kubernetes 클러스터를 구성할 수 있도록 도와주는 도구입니다.</li>
  <li>이름처럼 Docker를 이용하여 Kubernetes 클러스터를 구성하며, Docker를 이용하기 때문에 다양한 환경에서 쉽게 사용할 수 있습니다.</li>
  <li>Kind는 HA를 포함한 멀티노드를 지원하지만, 테스트와 실험적인 목적으로만 사용하기를 추천합니다.</li>
  <li>Kind는 클러스터를 구성하기 위해 kubeadm을 사용합니다.</li>
  <li><a href="https://sweetlittlebird.github.io/posts/2024-09-07-KANS-Study-Week2/#kind-%EC%86%8C%EA%B0%9C-%EB%B0%8F-%EC%84%A4%EC%B9%98">Kind 소개 및 설치</a>, <a href="https://kind.sigs.k8s.io/docs/user/quick-start/">Kind 공식문서</a></li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_9.png" alt="img.png" class="image-center" />
<em class="image-caption">Kind 구성도</em></p>

<h5 id="kind-및-툴-설치">Kind 및 툴 설치</h5>

<ul>
  <li>필수 툴 설치</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Install Kind</span>
<span class="nv">$ </span>brew <span class="nb">install </span>kind
<span class="nv">$ </span>kind <span class="nt">--version</span>
<span class="c"># =&gt; kind version 0.26.0</span>

<span class="c"># Install kubectl</span>
<span class="nv">$ </span>brew <span class="nb">install </span>kubernetes-cli
<span class="nv">$ </span>kubectl version <span class="nt">--client</span><span class="o">=</span><span class="nb">true</span>
<span class="c"># =&gt; Client Version: v1.31.0</span>
<span class="c">#    Kustomize Version: v5.4.2</span>
<span class="c">#    Kubecolor Version: v0.4.0</span>

<span class="c">## kubectl -&gt; k 단축키 설정</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"alias kubectl=kubecolor"</span> <span class="o">&gt;&gt;</span> ~/.zshrc

<span class="c"># Install Helm</span>
<span class="nv">$ </span>brew <span class="nb">install </span>helm
<span class="nv">$ </span>helm version
<span class="c"># =&gt; version.BuildInfo{Version:&amp;quot;v3.15.4&amp;quot;, GitCommit:&amp;quot;fa9efb07d9d8debbb4306d72af76a383895aa8c4&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;, GoVersion:&amp;quot;go1.22.6&amp;quot;}</span>
</code></pre></div></div>

<ul>
  <li>(권장) 유용한 툴 설치</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 툴 설치</span>
<span class="nv">$ </span>brew <span class="nb">install </span>krew
<span class="nv">$ </span>brew <span class="nb">install </span>kube-ps1
<span class="nv">$ </span>brew <span class="nb">install </span>kubectx

<span class="c"># kubectl 출력 시 하이라이트 처리</span>
<span class="nv">$ </span>brew <span class="nb">install </span>kubecolor
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"alias kubectl=kubecolor"</span> <span class="o">&gt;&gt;</span> ~/.zshrc
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"compdef kubecolor=kubectl"</span> <span class="o">&gt;&gt;</span> ~/.zshrc

<span class="c"># krew 플러그인 설치</span>
<span class="nv">$ </span>kubectl krew <span class="nb">install </span>neat stren
</code></pre></div></div>

<h5 id="kind-기본-사용---클러스터-배포-및-확인">Kind 기본 사용 - 클러스터 배포 및 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 클러스터 배포 전 확인</span>
<span class="nv">$ </span>docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE             COMMAND                  CREATED        STATUS                 PORTS                                              NAMES</span>
<span class="c">#    110494b9ca48   gogs/gogs         &amp;quot;/app/gogs/docker/st…&amp;quot;   19 hours ago   Up 5 hours (healthy)   0.0.0.0:3000-&amp;gt;3000/tcp, 0.0.0.0:10022-&amp;gt;22/tcp      gogs</span>
<span class="c">#    8b7c591c828d   jenkins/jenkins   &amp;quot;/usr/bin/tini -- /u…&amp;quot;   19 hours ago   Up 4 hours             0.0.0.0:8080-&amp;gt;8080/tcp, 0.0.0.0:50000-&amp;gt;50000/tcp   jenkins</span>

<span class="c"># Create a cluster with kind</span>
<span class="nv">$ </span>kind create cluster
<span class="c"># =&gt; Creating cluster &amp;quot;kind&amp;quot; ...</span>
<span class="c">#     ✓ Ensuring node image (kindest/node:v1.32.0) 🖼</span>
<span class="c">#     ✓ Preparing nodes 📦</span>
<span class="c">#     ✓ Writing configuration 📜</span>
<span class="c">#     ✓ Starting control-plane 🕹️</span>
<span class="c">#     ✓ Installing CNI 🔌</span>
<span class="c">#     ✓ Installing StorageClass 💾</span>
<span class="c">#    Set kubectl context to &amp;quot;kind-kind&amp;quot;</span>
<span class="c">#    You can now use your cluster with:</span>
<span class="c">#    </span>
<span class="c">#    kubectl cluster-info --context kind-kind</span>
<span class="c">#    </span>
<span class="c">#    Not sure what to do next? 😅  Check out https://kind.sigs.k8s.io/docs/user/quick-start/</span>

<span class="c"># 클러스터 배포 확인</span>
<span class="nv">$ </span>kind get clusters
<span class="c"># =&gt; kind</span>
<span class="nv">$ </span>kind get nodes
<span class="c"># =&gt; kind-control-plane</span>
<span class="nv">$ </span>kubectl cluster-info
<span class="c"># =&gt; Kubernetes control plane is running at https://127.0.0.1:64234</span>
<span class="c">#    CoreDNS is running at https://127.0.0.1:64234/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</span>
<span class="c">#    </span>
<span class="c">#    To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.</span>

<span class="c"># 노드 정보 확인</span>
<span class="nv">$ </span>kubectl get node <span class="nt">-o</span> wide
<span class="c"># =&gt; NAME                 STATUS   ROLES           AGE   VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE                         KERNEL-VERSION     CONTAINER-RUNTIME</span>
<span class="c">#    kind-control-plane   Ready    control-plane   63s   v1.32.0   172.20.0.2    &amp;lt;none&amp;gt;        Debian GNU/Linux 12 (bookworm)   5.10.76-linuxkit   containerd://1.7.24</span>

<span class="c"># 파드 정보 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE            NAME                                         READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    kube-system          coredns-668d6bf9bc-8pqmk                     1/1     Running   0          67s</span>
<span class="c">#    kube-system          coredns-668d6bf9bc-9ngw2                     1/1     Running   0          67s</span>
<span class="c">#    kube-system          etcd-kind-control-plane                      1/1     Running   0          74s</span>
<span class="c">#    kube-system          kindnet-zlwz2                                1/1     Running   0          67s</span>
<span class="c">#    kube-system          kube-apiserver-kind-control-plane            1/1     Running   0          74s</span>
<span class="c">#    kube-system          kube-controller-manager-kind-control-plane   1/1     Running   0          74s</span>
<span class="c">#    kube-system          kube-proxy-nbp2t                             1/1     Running   0          67s</span>
<span class="c">#    kube-system          kube-scheduler-kind-control-plane            1/1     Running   0          74s</span>
<span class="c">#    local-path-storage   local-path-provisioner-58cc7856b6-wl6z8      1/1     Running   0          67s</span>
<span class="nv">$ </span>kubectl get componentstatuses
<span class="c"># =&gt; NAME                 STATUS    MESSAGE   ERROR</span>
<span class="c">#    controller-manager   Healthy   ok</span>
<span class="c">#    scheduler            Healthy   ok</span>
<span class="c">#    etcd-0               Healthy   ok</span>

<span class="c"># 컨트롤플레인 (컨테이너) 노드 1대가 실행</span>
<span class="nv">$ </span>docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE                  COMMAND                  CREATED              STATUS                 PORTS                                              NAMES</span>
<span class="c">#    3d4063180754   kindest/node:v1.32.0   &amp;quot;/usr/local/bin/entr…&amp;quot;   About a minute ago   Up About a minute      127.0.0.1:64234-&amp;gt;6443/tcp                          kind-control-plane</span>
<span class="c">#    110494b9ca48   gogs/gogs              &amp;quot;/app/gogs/docker/st…&amp;quot;   19 hours ago         Up 5 hours (healthy)   0.0.0.0:3000-&amp;gt;3000/tcp, 0.0.0.0:10022-&amp;gt;22/tcp      gogs</span>
<span class="c">#    8b7c591c828d   jenkins/jenkins        &amp;quot;/usr/bin/tini -- /u…&amp;quot;   19 hours ago         Up 4 hours             0.0.0.0:8080-&amp;gt;8080/tcp, 0.0.0.0:50000-&amp;gt;50000/tcp   jenkins</span>
<span class="nv">$ </span>docker images
<span class="c"># =&gt; REPOSITORY                                                                   TAG           IMAGE ID       CREATED         SIZE</span>
<span class="c">#    kindest/node                                                                 &amp;lt;none&amp;gt;        b5a8f8764a3e   7 days ago      1.05GB</span>

<span class="c"># kube config 파일 확인</span>
<span class="nv">$ </span><span class="nb">cat</span> ~/.kube/config
<span class="c"># 혹은</span>
<span class="c"># $ cat $KUBECONFIG # KUBECONFIG 변수 지정 사용 시</span>

<span class="c"># nginx 파드 배포 및 확인 : 컨트롤플레인 노드인데 파드가 배포 될까요?</span>
<span class="nv">$ </span>kubectl run nginx <span class="nt">--image</span><span class="o">=</span>nginx:alpine
<span class="c"># =&gt; pod/nginx created</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME    READY   STATUS    RESTARTS   AGE   IP           NODE                 NOMINATED NODE   READINESS GATES</span>
<span class="c">#    nginx   1/1     Running   0          10s   10.244.0.5   kind-control-plane   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>

<span class="c"># 노드에 Taints 정보 확인</span>
<span class="nv">$ </span>kubectl describe node | <span class="nb">grep </span>Taints
<span class="c"># =&gt; Taints:             &amp;lt;none&amp;gt;</span>

<span class="c"># 클러스터 삭제</span>
<span class="nv">$ </span>kind delete cluster
<span class="c"># =&gt; Deleting cluster &amp;quot;kind&amp;quot; ...</span>
<span class="c">#    Deleted nodes: [&amp;quot;kind-control-plane&amp;quot;]</span>

<span class="c"># kube config 삭제 확인</span>
<span class="nv">$ </span><span class="nb">cat</span> ~/.kube/config
<span class="c"># 혹은</span>
<span class="c"># $ cat $KUBECONFIG # KUBECONFIG 변수 지정 사용 시</span>
</code></pre></div></div>

<h4 id="kind로-kubernetes-클러스터-배포---3노드">Kind로 Kubernetes 클러스터 배포 - 3노드</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 클러스터 배포 전 확인</span>
<span class="nv">$ </span>docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE             COMMAND                  CREATED        STATUS                 PORTS                                              NAMES</span>
<span class="c">#    110494b9ca48   gogs/gogs         &amp;quot;/app/gogs/docker/st…&amp;quot;   19 hours ago   Up 5 hours (healthy)   0.0.0.0:3000-&amp;gt;3000/tcp, 0.0.0.0:10022-&amp;gt;22/tcp      gogs</span>
<span class="c">#    8b7c591c828d   jenkins/jenkins   &amp;quot;/usr/bin/tini -- /u…&amp;quot;   19 hours ago   Up 4 hours             0.0.0.0:8080-&amp;gt;8080/tcp, 0.0.0.0:50000-&amp;gt;50000/tcp   jenkins</span>

<span class="c"># 방안1 : 환경변수 지정</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">KUBECONFIG</span><span class="o">=</span><span class="nv">$PWD</span>/kubeconfig

<span class="c"># Create a cluster with kind</span>
<span class="c"># $ MyIP=&lt;각자 자신의 PC IP&gt;</span>
<span class="nv">$ MyIP</span><span class="o">=</span>10.0.4.3

<span class="nv">$ </span><span class="nb">cd</span> ..
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> kind-3node.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
networking:
  apiServerAddress: "</span><span class="nv">$MyIP</span><span class="sh">"
nodes:
- role: control-plane
  extraPortMappings:
  - containerPort: 30000
    hostPort: 30000
  - containerPort: 30001
    hostPort: 30001
  - containerPort: 30002
    hostPort: 30002
  - containerPort: 30003
    hostPort: 30003
- role: worker
- role: worker
</span><span class="no">EOF
</span><span class="nv">$ </span>kind create cluster <span class="nt">--config</span> kind-3node.yaml <span class="nt">--name</span> myk8s <span class="nt">--image</span> kindest/node:v1.30.6
<span class="c"># =&gt; Creating cluster &amp;quot;myk8s&amp;quot; ...</span>
<span class="c">#     ✓ Ensuring node image (kindest/node:v1.30.6) 🖼</span>
<span class="c">#     ✓ Preparing nodes 📦 📦 📦</span>
<span class="c">#     ✓ Writing configuration 📜</span>
<span class="c">#     ✓ Starting control-plane 🕹️</span>
<span class="c">#     ✓ Installing CNI 🔌</span>
<span class="c">#     ✓ Installing StorageClass 💾</span>
<span class="c">#     ✓ Joining worker nodes 🚜</span>
<span class="c">#    Set kubectl context to &amp;quot;kind-myk8s&amp;quot;</span>
<span class="c">#    You can now use your cluster with:</span>
<span class="c">#    </span>
<span class="c">#    kubectl cluster-info --context kind-myk8s</span>
<span class="c">#    </span>
<span class="c">#    Thanks for using kind! 😊</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kind get nodes <span class="nt">--name</span> myk8s
<span class="c"># =&gt; myk8s-control-plane</span>
<span class="c">#    myk8s-worker</span>
<span class="c">#    myk8s-worker2</span>
<span class="nv">$ </span>kubens default
<span class="c"># =&gt; Context &amp;quot;kind-myk8s&amp;quot; modified.</span>
<span class="c">#    Active namespace is &amp;quot;default&amp;quot;.</span>

<span class="c"># kind 는 별도 도커 네트워크 생성 후 사용 : 기본값 172.18.0.0/16</span>
<span class="nv">$ </span>docker network <span class="nb">ls</span>
<span class="c"># =&gt; NETWORK ID     NAME                     DRIVER    SCOPE</span>
<span class="c">#    8204a0851463   host                     host      local</span>
<span class="c">#    3bbcc6aa8f38   kind                     bridge    local</span>
<span class="nv">$ </span>docker inspect kind | jq
<span class="c"># =&gt; [</span>
<span class="c">#      {</span>
<span class="c">#        &amp;quot;Name&amp;quot;: &amp;quot;kind&amp;quot;,</span>
<span class="c">#        &amp;quot;Id&amp;quot;: &amp;quot;3bbcc6aa8f388f86f02478f41de1e4dd917e5812b6cf6257972e4af0bedf5021&amp;quot;,</span>
<span class="c">#        &amp;quot;Created&amp;quot;: &amp;quot;2024-10-01T11:37:09.195259833Z&amp;quot;,</span>
<span class="c">#        &amp;quot;Scope&amp;quot;: &amp;quot;local&amp;quot;,</span>
<span class="c">#        &amp;quot;Driver&amp;quot;: &amp;quot;bridge&amp;quot;,</span>
<span class="c">#        &amp;quot;EnableIPv6&amp;quot;: true,</span>
<span class="c">#        &amp;quot;IPAM&amp;quot;: {</span>
<span class="c">#          &amp;quot;Driver&amp;quot;: &amp;quot;default&amp;quot;,</span>
<span class="c">#          &amp;quot;Options&amp;quot;: {},</span>
<span class="c">#          &amp;quot;Config&amp;quot;: [</span>
<span class="c">#            {</span>
<span class="c">#              &amp;quot;Subnet&amp;quot;: &amp;quot;172.20.0.0/16&amp;quot;,</span>
<span class="c">#              &amp;quot;Gateway&amp;quot;: &amp;quot;172.20.0.1&amp;quot;</span>
<span class="c">#            }</span>
<span class="c">#          ]</span>
<span class="c">#        },</span>
<span class="c">#        &amp;quot;Internal&amp;quot;: false,</span>
<span class="c">#        &amp;quot;Attachable&amp;quot;: false,</span>
<span class="c">#        &amp;quot;Ingress&amp;quot;: false,</span>
<span class="c">#        &amp;quot;ConfigFrom&amp;quot;: {</span>
<span class="c">#          &amp;quot;Network&amp;quot;: &amp;quot;&amp;quot;</span>
<span class="c">#        },</span>
<span class="c">#        &amp;quot;ConfigOnly&amp;quot;: false,</span>
<span class="c">#        &amp;quot;Containers&amp;quot;: {</span>
<span class="c">#          &amp;quot;35739bf3542771236d47fd4dcb27da13814184a3de57c7203904f66ecbab4710&amp;quot;: {</span>
<span class="c">#            &amp;quot;Name&amp;quot;: &amp;quot;myk8s-worker&amp;quot;,</span>
<span class="c">#            &amp;quot;EndpointID&amp;quot;: &amp;quot;5de8e9e48e611f2c4cb908649f5dcdf63c82d624b85f85a6573ced7cbd454554&amp;quot;,</span>
<span class="c">#            &amp;quot;MacAddress&amp;quot;: &amp;quot;02:42:ac:14:00:03&amp;quot;,</span>
<span class="c">#            &amp;quot;IPv4Address&amp;quot;: &amp;quot;172.20.0.3/16&amp;quot;,</span>
<span class="c">#          },</span>
<span class="c">#          &amp;quot;48023a25d056141b00747f14ff52da2b46c46c0d0edbeb714dedd1f3c71360e4&amp;quot;: {</span>
<span class="c">#            &amp;quot;Name&amp;quot;: &amp;quot;myk8s-control-plane&amp;quot;,</span>
<span class="c">#            &amp;quot;EndpointID&amp;quot;: &amp;quot;9d51136474882d6ca7a4aabe7291e26527f44c3b88c7191b654506fdf1d65c84&amp;quot;,</span>
<span class="c">#            &amp;quot;MacAddress&amp;quot;: &amp;quot;02:42:ac:14:00:04&amp;quot;,</span>
<span class="c">#            &amp;quot;IPv4Address&amp;quot;: &amp;quot;172.20.0.4/16&amp;quot;,</span>
<span class="c">#          },</span>
<span class="c">#          &amp;quot;fefdfb00a2228f646119483a24503e1dc8bd74292e462fc9fa2ef3446004b4af&amp;quot;: {</span>
<span class="c">#            &amp;quot;Name&amp;quot;: &amp;quot;myk8s-worker2&amp;quot;,</span>
<span class="c">#            &amp;quot;EndpointID&amp;quot;: &amp;quot;c669ce7940abb8722b7ac41cc533c260838d31881c915a49147829e9d28a746c&amp;quot;,</span>
<span class="c">#            &amp;quot;MacAddress&amp;quot;: &amp;quot;02:42:ac:14:00:02&amp;quot;,</span>
<span class="c">#            &amp;quot;IPv4Address&amp;quot;: &amp;quot;172.20.0.2/16&amp;quot;,</span>
<span class="c">#          }</span>
<span class="c">#        },</span>
<span class="c">#        &amp;quot;Options&amp;quot;: {</span>
<span class="c">#          &amp;quot;com.docker.network.bridge.enable_ip_masquerade&amp;quot;: &amp;quot;true&amp;quot;,</span>
<span class="c">#          &amp;quot;com.docker.network.driver.mtu&amp;quot;: &amp;quot;1500&amp;quot;</span>
<span class="c">#        },</span>
<span class="c">#        &amp;quot;Labels&amp;quot;: {}</span>
<span class="c">#      }</span>
<span class="c">#    ]</span>

<span class="c"># k8s api 주소 확인 : 어떻게 로컬에서 접속이 되는 걸까?</span>
<span class="nv">$ </span>kubectl cluster-info
<span class="c"># =&gt; Kubernetes control plane is running at https://10.0.4.3:51235</span>
<span class="c">#    CoreDNS is running at https://10.0.4.3:51235/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</span>
<span class="c">#    </span>
<span class="c">#    To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 docker가 10.0.4.3:51235 접속시 kind 컨테이너의 6443 포트로 포워딩 해주고&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   ~/.kube/config 에서 10.0.4.3:51235를 apiserver 주소로 지정하고 있기 때문에 접속이 가능합니다.&lt;/span&gt;</span>

<span class="c"># 노드 정보 확인 : CRI 는 containerd 사용</span>
<span class="nv">$ </span>kubectl get node <span class="nt">-o</span> wide
<span class="c"># =&gt; NAME                  STATUS   ROLES           AGE     VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE                         KERNEL-VERSION     CONTAINER-RUNTIME</span>
<span class="c">#    myk8s-control-plane   Ready    control-plane   3m8s    v1.30.6   172.20.0.4    &amp;lt;none&amp;gt;        Debian GNU/Linux 12 (bookworm)   5.10.76-linuxkit   containerd://1.7.18</span>
<span class="c">#    myk8s-worker          Ready    &amp;lt;none&amp;gt;          2m48s   v1.30.6   172.20.0.3    &amp;lt;none&amp;gt;        Debian GNU/Linux 12 (bookworm)   5.10.76-linuxkit   containerd://1.7.18</span>
<span class="c">#    myk8s-worker2         Ready    &amp;lt;none&amp;gt;          2m48s   v1.30.6   172.20.0.2    &amp;lt;none&amp;gt;        Debian GNU/Linux 12 (bookworm)   5.10.76-linuxkit   containerd://1.7.18</span>

<span class="c"># 파드 정보 확인 : CNI 는 kindnet 사용</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-A</span> <span class="nt">-o</span> wide
<span class="c"># =&gt; NAMESPACE            NAME                                          READY   STATUS    RESTARTS   AGE     IP           NODE                  NOMINATED NODE   READINESS GATES</span>
<span class="c">#    kube-system          coredns-55cb58b774-m7h2c                      1/1     Running   0          3m7s    10.244.0.2   myk8s-control-plane   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          coredns-55cb58b774-z88v5                      1/1     Running   0          3m7s    10.244.0.3   myk8s-control-plane   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          etcd-myk8s-control-plane                      1/1     Running   0          3m22s   172.20.0.4   myk8s-control-plane   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          kindnet-mp6mj                                 1/1     Running   0          3m7s    172.20.0.4   myk8s-control-plane   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          kindnet-q2k9w                                 1/1     Running   0          3m4s    172.20.0.2   myk8s-worker2         &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          kindnet-t99c4                                 1/1     Running   0          3m4s    172.20.0.3   myk8s-worker          &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          kube-apiserver-myk8s-control-plane            1/1     Running   0          3m21s   172.20.0.4   myk8s-control-plane   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          kube-controller-manager-myk8s-control-plane   1/1     Running   0          3m21s   172.20.0.4   myk8s-control-plane   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          kube-proxy-f85sx                              1/1     Running   0          3m7s    172.20.0.4   myk8s-control-plane   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          kube-proxy-ltckc                              1/1     Running   0          3m4s    172.20.0.2   myk8s-worker2         &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          kube-proxy-njr42                              1/1     Running   0          3m4s    172.20.0.3   myk8s-worker          &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          kube-scheduler-myk8s-control-plane            1/1     Running   0          3m21s   172.20.0.4   myk8s-control-plane   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    local-path-storage   local-path-provisioner-7d4d9bdcc5-jhl5h       1/1     Running   0          3m7s    10.244.0.4   myk8s-control-plane   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>

<span class="c"># 쿠버네티스 네임스페이스 확인 &gt;&gt; 도커 컨테이너에서 배운 네임스페이스와 다릅니다!</span>
<span class="nv">$ </span>kubectl get namespaces
<span class="c"># =&gt; NAME                 STATUS   AGE</span>
<span class="c">#    default              Active   3m42s</span>
<span class="c">#    kube-node-lease      Active   3m42s</span>
<span class="c">#    kube-public          Active   3m42s</span>
<span class="c">#    kube-system          Active   3m42s</span>
<span class="c">#    local-path-storage   Active   3m35s</span>

<span class="c"># 컨트롤플레인/워커 노드(컨테이너) 확인 : 도커 컨테이너 이름은 myk8s-control-plane , myk8s-worker/worker-2 임을 확인</span>
<span class="nv">$ </span>docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE                  COMMAND                  CREATED         STATUS                 PORTS                                                            NAMES</span>
<span class="c">#    35739bf35427   kindest/node:v1.30.6   &amp;quot;/usr/local/bin/entr…&amp;quot;   4 minutes ago   Up 4 minutes                                                                            myk8s-worker</span>
<span class="c">#    48023a25d056   kindest/node:v1.30.6   &amp;quot;/usr/local/bin/entr…&amp;quot;   4 minutes ago   Up 4 minutes           0.0.0.0:30000-30003-&amp;gt;30000-30003/tcp, 10.0.4.3:51235-&amp;gt;6443/tcp   myk8s-control-plane</span>
<span class="c">#    fefdfb00a222   kindest/node:v1.30.6   &amp;quot;/usr/local/bin/entr…&amp;quot;   4 minutes ago   Up 4 minutes                                                                            myk8s-worker2</span>
<span class="nv">$ </span>docker images

<span class="c"># 디버그용 내용 출력에 ~/.kube/config 권한 인증 로드</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-v6</span>
<span class="c"># =&gt; I1221 20:19:47.265879   56969 loader.go:395] Config loaded from file:  /Users/anonym/Documents/GitHub/cicd-lite/w3/1/dev-app/kubeconfig</span>
<span class="c">#    I1221 20:19:47.354543   56969 round_trippers.go:553] GET https://10.0.4.3:51235/api/v1/namespaces/default/pods?limit=500 200 OK in 79 milliseconds</span>
<span class="c">#    No resources found in default namespace.</span>

<span class="c"># kube config 파일 확인</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="nv">$KUBECONFIG</span>
<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-l</span> <span class="nv">$KUBECONFIG</span>
<span class="c"># =&gt; .rw------- anonym staff 5.5 KB Sat Oct 01 20:16:21 2024  /Users/user/Documents/GitHub/cicd-lite/w3/1/dev-app/kubeconfig</span>
</code></pre></div></div>

<h5 id="kube-ops-view-설치">kube-ops-view 설치</h5>

<ul>
  <li>kube-ops-view는 쿠버네티스 클러스터의 상태를 시각적으로 보여주는 대시보드입니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># kube-ops-view</span>
<span class="c"># helm show values geek-cookbook/kube-ops-view</span>
<span class="nv">$ </span>helm repo add geek-cookbook https://geek-cookbook.github.io/charts/
<span class="nv">$ </span>helm <span class="nb">install </span>kube-ops-view geek-cookbook/kube-ops-view <span class="nt">--version</span> 1.2.2 <span class="nt">--set</span> service.main.type<span class="o">=</span>NodePort,service.main.ports.http.nodePort<span class="o">=</span>30001 <span class="nt">--set</span> env.TZ<span class="o">=</span><span class="s2">"Asia/Seoul"</span> <span class="nt">--namespace</span> kube-system

<span class="c"># 설치 확인</span>
<span class="nv">$ </span>kubectl get deploy,pod,svc,ep <span class="nt">-n</span> kube-system <span class="nt">-l</span> app.kubernetes.io/instance<span class="o">=</span>kube-ops-view
<span class="c"># =&gt; NAME                            READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/kube-ops-view   1/1     1            1           25s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                 READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/kube-ops-view-796947d6dc-6b6xx   1/1     Running   0          25s</span>
<span class="c">#    </span>
<span class="c">#    NAME                    TYPE       CLUSTER-IP    EXTERNAL-IP   PORT(S)          AGE</span>
<span class="c">#    service/kube-ops-view   NodePort   10.96.18.59   &amp;lt;none&amp;gt;        8080:30001/TCP   25s</span>
<span class="c">#    </span>
<span class="c">#    NAME                      ENDPOINTS         AGE</span>
<span class="c">#    endpoints/kube-ops-view   10.244.1.2:8080   25s</span>

<span class="c"># kube-ops-view 접속 URL 확인 (1.5 , 2 배율)</span>
<span class="nv">$ </span>open <span class="s2">"http://127.0.0.1:30001/#scale=1.5"</span>
<span class="nv">$ </span>open <span class="s2">"http://127.0.0.1:30001/#scale=2"</span>
</code></pre></div></div>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_10.png" alt="img.png" class="w-80 image-center" /></p>

<h5 id="클러스터-삭제">클러스터 삭제</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 클러스터 삭제</span>
<span class="nv">$ </span>kind delete cluster <span class="nt">--name</span> myk8s
<span class="c"># =&gt; Deleting cluster &amp;quot;myk8s&amp;quot; ...</span>
<span class="c">#    Deleted nodes: [&amp;quot;myk8s-worker&amp;quot; &amp;quot;myk8s-control-plane&amp;quot; &amp;quot;myk8s-worker2&amp;quot;]</span>
<span class="nv">$ </span>docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE             COMMAND                  CREATED        STATUS                 PORTS                                              NAMES</span>
<span class="c">#    110494b9ca48   gogs/gogs         &amp;quot;/app/gogs/docker/st…&amp;quot;   19 hours ago   Up 6 hours (healthy)   0.0.0.0:3000-&amp;gt;3000/tcp, 0.0.0.0:10022-&amp;gt;22/tcp      gogs</span>
<span class="c">#    8b7c591c828d   jenkins/jenkins   &amp;quot;/usr/bin/tini -- /u…&amp;quot;   19 hours ago   Up 5 hours             0.0.0.0:8080-&amp;gt;8080/tcp, 0.0.0.0:50000-&amp;gt;50000/tcp   jenkins</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="nv">$KUBECONFIG</span>
<span class="nv">$ </span><span class="nb">unset </span>KUBECONFIG
</code></pre></div></div>

<h4 id="jenkins-설정--plugin-설치-자격증명-설정">Jenkins 설정 : Plugin 설치, 자격증명 설정</h4>

<ul>
  <li>Jenkins Plugin 설치 : Dashboard &gt; Manage Jenkins &gt; Plugins &gt; Available plugins 탭에서 설치
    <ul>
      <li><strong>Pipeline Stage View</strong> - <a href="https://plugins.jenkins.io/pipeline-stage-view/">Docs</a></li>
      <li><strong>Docker Pipeline</strong> : building, testing, and using Docker images from Jenkins Pipeline - <a href="https://plugins.jenkins.io/docker-workflow/">Docs</a></li>
      <li><strong>Gogs</strong> : Webhook Plugin - <a href="https://plugins.jenkins.io/gogs-webhook/">Docs</a>
        <ul>
          <li>예시 : <code class="language-plaintext highlighter-rouge">http(s)://&lt;&lt; jenkins-server &gt;&gt;/gogs-webhook/?job=&lt;&lt;jobname&gt;&gt;</code></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>자격증명 설정 : Dashboard &gt; Manage Jenkins &gt; Credentials &gt; Global &gt; Add Credentials 에서 추가
    <ol>
      <li>Gogs Repo 자격증명 설정 : <strong>gogs-crd</strong>
        <ul>
          <li>Kind : Username with password</li>
          <li>Username : <code class="language-plaintext highlighter-rouge">devops</code></li>
          <li>Password : <code class="language-plaintext highlighter-rouge">&lt;Gogs 토큰&gt;</code></li>
          <li>ID : <code class="language-plaintext highlighter-rouge">gogs-crd</code></li>
        </ul>
      </li>
      <li>도커 허브 자격증명 설정 : <strong>dockerhub-crd</strong>
        <ul>
          <li>Kind : Username with password</li>
          <li>Username : <code class="language-plaintext highlighter-rouge">&lt;도커 계정명&gt;</code></li>
          <li>Password : <code class="language-plaintext highlighter-rouge">&lt;도커 계정 암호 혹은 토큰&gt;</code></li>
          <li>ID : <code class="language-plaintext highlighter-rouge">dockerhub-crd</code></li>
        </ul>
      </li>
      <li>k8s(kind) 자격증명 설정 : <strong>k8s-crd</strong>
        <ul>
          <li>Kind : <code class="language-plaintext highlighter-rouge">Secret file</code></li>
          <li>File : <code class="language-plaintext highlighter-rouge">&lt;kubeconfig 파일 업로드&gt;</code></li>
          <li>ID : <code class="language-plaintext highlighter-rouge">k8s-crd</code></li>
        </ul>
      </li>
    </ol>
  </li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_11.png" alt="img.png" class="image-center" />
<em class="image-caption">Jenkins 자격증명 설정 결과</em></p>

<h5 id="jenkins-item-생성-pipeline">Jenkins item 생성 (Pipeline)</h5>

<ul>
  <li>간단한 Pipeline 스크립트를 작성하여 gogs와 도커허브의 자격증명이 잘 연동됨을 확인해보겠습니다.</li>
  <li>아래의 Pipeline 스크립트를 <code class="language-plaintext highlighter-rouge">pipeline-ci</code>라는 이름으로 생성합니다.</li>
</ul>

<div class="language-gradle highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pipeline</span> <span class="o">{</span>
    <span class="n">agent</span> <span class="n">any</span>
    <span class="n">environment</span> <span class="o">{</span>
        <span class="n">DOCKER_IMAGE</span> <span class="o">=</span> <span class="s1">'&lt;자신의 도커 허브 계정&gt;/dev-app'</span> <span class="c1">// Docker 이미지 이름</span>
    <span class="o">}</span>
    <span class="n">stages</span> <span class="o">{</span>
        <span class="n">stage</span><span class="o">(</span><span class="s1">'Checkout'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                 <span class="n">git</span> <span class="nl">branch:</span> <span class="s1">'main'</span><span class="o">,</span>
                 <span class="nl">url:</span> <span class="s1">'http://&lt;PC의 IP&gt;:3000/devops/dev-app.git'</span><span class="o">,</span>  <span class="c1">// Git에서 코드 체크아웃</span>
                 <span class="nl">credentialsId:</span> <span class="s1">'gogs-crd'</span>  <span class="c1">// Credentials ID</span>
            <span class="o">}</span>
        <span class="o">}</span>
        <span class="n">stage</span><span class="o">(</span><span class="s1">'Read VERSION'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">script</span> <span class="o">{</span>
                    <span class="c1">// VERSION 파일 읽기</span>
                    <span class="kt">def</span> <span class="n">version</span> <span class="o">=</span> <span class="n">readFile</span><span class="o">(</span><span class="s1">'VERSION'</span><span class="o">).</span><span class="na">trim</span><span class="o">()</span>
                    <span class="n">echo</span> <span class="s2">"Version found: ${version}"</span>
                    <span class="c1">// 환경 변수 설정</span>
                    <span class="n">env</span><span class="o">.</span><span class="na">DOCKER_TAG</span> <span class="o">=</span> <span class="n">version</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
        <span class="n">stage</span><span class="o">(</span><span class="s1">'Docker Build and Push'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">script</span> <span class="o">{</span>
                    <span class="n">docker</span><span class="o">.</span><span class="na">withRegistry</span><span class="o">(</span><span class="s1">'https://index.docker.io/v1/'</span><span class="o">,</span> <span class="s1">'dockerhub-crd'</span><span class="o">)</span> <span class="o">{</span>
                        <span class="c1">// DOCKER_TAG 사용</span>
                        <span class="kt">def</span> <span class="n">appImage</span> <span class="o">=</span> <span class="n">docker</span><span class="o">.</span><span class="na">build</span><span class="o">(</span><span class="s2">"${DOCKER_IMAGE}:${DOCKER_TAG}"</span><span class="o">)</span>
                        <span class="n">appImage</span><span class="o">.</span><span class="na">push</span><span class="o">()</span>
                        <span class="n">appImage</span><span class="o">.</span><span class="na">push</span><span class="o">(</span><span class="s2">"latest"</span><span class="o">)</span>
                    <span class="o">}</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
    <span class="n">post</span> <span class="o">{</span>
        <span class="n">success</span> <span class="o">{</span>
            <span class="n">echo</span> <span class="s2">"Docker image ${DOCKER_IMAGE}:${DOCKER_TAG} has been built and pushed successfully!"</span>
        <span class="o">}</span>
        <span class="n">failure</span> <span class="o">{</span>
            <span class="n">echo</span> <span class="s2">"Pipeline failed. Please check the logs."</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<ul>
  <li>지금 빌드 =&gt; 콘솔 Output 확인
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_12.png" alt="img.png" class="image-center" /></li>
  <li>도커 허브 확인
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_13.png" alt="img.png" class="image-center" />
    <ul>
      <li>자격증명들이 잘 연동되어, 파이프라인에서 지정한것 처럼 버전명의 태그(0.0.1)과 latest 태그가 잘 생성되었습니다!</li>
    </ul>
  </li>
</ul>

<h4 id="kubernetes-클러스터에-응용프로그램-배포하기">Kubernetes 클러스터에 응용프로그램 배포하기</h4>

<ul>
  <li>Jenkins Pipeline을 통해 Kubernetes 클러스터에 응용프로그램을 배포해보겠습니다.</li>
  <li>먼저 Kubernetes 클러스터에 배포할때 사용하는 deployment에 대해 알아보겠습니다.</li>
</ul>

<h5 id="deployment-소개">Deployment 소개</h5>

<script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
<div class="mermaid">
  graph TD
      subgraph Deployment
          subgraph ReplicaSet
              direction TB
              subgraph Pod[Pod]
                  direction LR
                  Container1(Container)
                  Container2(Container)
              end
              subgraph Pod2[Pod]
                  direction LR
                  Container3(Container)
                  Container4(Container)
              end
              subgraph Pod3[Pod]
                  direction LR
                  Container5(Container)
              end
          end
      end
  classDef Pod fill:#fff,stroke:#ccc,stroke-width:2px;
  classDef ReplicaSet fill:#fff,stroke:#ccc,stroke-width:2px;
  classDef Deployment fill:#fff,stroke:#ccc,stroke-width:2px;
  class Pod,Pod2,Pod3 Pod;
  class Deployment Deployment;
  </div>
<p><em class="image-caption">Kubernetes 배포 구조</em></p>

<ul>
  <li>Kubernetes를 배포하는 최소단위는 <strong>Pod</strong>이며, <strong>하나 이상의 컨테이너로 구성</strong>됩니다.</li>
  <li>Pod는 <strong>ReplicaSet</strong>에 의해 관리되며, ReplicaSet은 <strong>Pod의 수를 유지하도록 관리</strong>합니다.</li>
  <li>
    <p><strong>Deployment</strong>는 <strong>ReplicaSet을 관리하며, Pod의 배포 및 업데이트를 관리</strong>합니다.</p>
  </li>
  <li>Kubernetes는 manifest라는 yaml 파일을 통해 리소스를 정의하고, 선언형 방식으로 원하는 상태를 선언시 해당 상태를 충족시키기 위해 클러스터를 조정합니다.</li>
  <li>아래는 kubernetes의 manifest의 구조입니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apiVersion: ...   <span class="c"># &lt;span style="color: green;"&gt;👉 리소스를 만드는데 사용할 Kubernetes API 버전&lt;/span&gt;</span>
kind: ...         <span class="c"># &lt;span style="color: green;"&gt;👉 만들고자 하는 리소스의 종류&lt;/span&gt;</span>
metadata:
    ...           <span class="c"># &lt;span style="color: green;"&gt;👉 리소스를 식별하는 고유 데이터와 상태와 관련없는 메타데이터&lt;/span&gt;</span>
spec:
    ...           <span class="c"># &lt;span style="color: green;"&gt;👉 리소스의 원하는 상태를 정의&lt;/span&gt;</span>
</code></pre></div>    </div>
  </li>
</ul>

<h5 id="deployment-배포-실습">Deployment 배포 실습</h5>

<ul>
  <li>
    <p>앞서 작성한 Jenkins Pipeline을 통해 빌드된 도커 이미지를 Kubernetes 클러스터에 응용프로그램을 배포해보겠습니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 디플로이먼트 오브젝트 배포 : 리플리카(파드 2개), 컨테이너 이미지 &gt;&gt; 아래 도커 계정 부분만 변경해서 배포해보자</span>
<span class="c">#$ DHUSER=&lt;도커 허브 계정명&gt;</span>
<span class="nv">$ DHUSER</span><span class="o">=</span>sweetlittlebird
  
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: timeserver
spec:
  replicas: 2
  selector:
    matchLabels:
      pod: timeserver-pod
  template:
    metadata:
      labels:
        pod: timeserver-pod
    spec:
      containers:
      - name: timeserver-container
        image: docker.io/</span><span class="nv">$DHUSER</span><span class="sh">/dev-app:0.0.1
</span><span class="no">EOF
</span><span class="c"># =&gt; deployment.apps/timeserver created</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> kubectl get deploy,pod <span class="nt">-o</span> wide
  
<span class="c"># 배포 상태 확인 : kube-ops-view 웹 확인</span>
<span class="nv">$ </span>kubectl get deploy,pod <span class="nt">-o</span> wide
<span class="c"># =&gt; NAME                         READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS             IMAGES                                    SELECTOR</span>
<span class="c">#    deployment.apps/timeserver   0/2     2            0           45s   timeserver-container   docker.io/sweetlittlebird/dev-app:0.0.1   pod=timeserver-pod</span>
<span class="c">#    </span>
<span class="c">#    NAME                              READY   STATUS             RESTARTS   AGE   IP           NODE            NOMINATED NODE   READINESS GATES</span>
<span class="c">#    pod/timeserver-5b5ff6d859-s282p   0/1     &lt;span style="color: red;"&gt;ImagePullBackOff&lt;/span&gt;   0          45s   10.244.2.2   myk8s-worker2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    pod/timeserver-5b5ff6d859-v7gs7   0/1     &lt;span style="color: red;"&gt;ImagePullBackOff&lt;/span&gt;   0          45s   10.244.1.2   myk8s-worker    &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 배포상태가 ImagePullBackOff로 배포가 되지 않았습니다.&lt;/span&gt;</span>
  
<span class="nv">$ </span>kubectl describe pod
<span class="c"># =&gt; Name:             timeserver-5b5ff6d859-s282p</span>
<span class="c">#    ...</span>
<span class="c">#    Events:</span>
<span class="c">#      Type     Reason     Age                    From               Message</span>
<span class="c">#      ----     ------     ----                   ----               -------</span>
<span class="c">#      Normal   Scheduled  5m38s                  default-scheduler  Successfully assigned default/timeserver-5b5ff6d859-s282p to myk8s-worker2</span>
<span class="c">#      Normal   Pulling    4m4s (x4 over 5m37s)   kubelet            Pulling image &amp;quot;docker.io/sweetlittlebird/dev-app:0.0.1&amp;quot;</span>
<span class="c">#      Warning  Failed     4m3s (x4 over 5m35s)   kubelet            Failed to pull image &amp;quot;docker.io/sweetlittlebird/dev-app:0.0.1&amp;quot;: failed to pull and unpack image &amp;quot;docker.io/sweetlittlebird/dev-app:0.0.1&amp;quot;: failed to resolve reference &amp;quot;docker.io/sweetlittlebird/dev-app:0.0.1&amp;quot;: pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed</span>
<span class="c">#      Warning  Failed     4m3s (x4 over 5m35s)   kubelet            Error: ErrImagePull</span>
<span class="c">#      Warning  Failed     3m48s (x6 over 5m35s)  kubelet            Error: ImagePullBackOff</span>
<span class="c">#      Normal   BackOff    22s (x20 over 5m35s)   kubelet            Back-off pulling image &amp;quot;docker.io/sweetlittlebird/dev-app:0.0.1&amp;quot;```</span>
</code></pre></div>    </div>
  </li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_14.png" alt="img.png" class="image-center" />
<em class="image-caption">Kube-Ops-View를 통해 살펴본 Kubernetes 클러스터에 timeserver 배포 실패</em></p>

<ul>
  <li>위와 같이 Image pull error가 나면서 배포가 실패했습니다.</li>
  <li><code class="language-plaintext highlighter-rouge">kubectl describe pod</code>를 통해 확인한 결과, <code class="language-plaintext highlighter-rouge">pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed</code>와 같은 메시지가 나타나고
이는 Kubernetes 클러스터에서 도커 이미지를 pull할 때 도커 허브에 인증 토큰이 되어있지 않아서 발생한 문제를 의미합니다.</li>
  <li>도커 허브의 인증토큰을 등록하고 다시 시도해보겠습니다.</li>
</ul>

<h4 id="k8s에-docker-hub-인증토큰-등록-후-다시-배포">K8S에 Docker Hub 인증토큰 등록 후 다시 배포</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># k8s secret : 도커 자격증명 설정</span>
 
<span class="nv">$ </span>kubectl get secret <span class="nt">-A</span>  <span class="c"># 기존 시크릿 확인</span>
<span class="c"># =&gt; NAMESPACE     NAME                                  TYPE                            DATA   AGE</span>
<span class="c">#    kube-system   bootstrap-token-abcdef                bootstrap.kubernetes.io/token   6      164m</span>
<span class="c">#    kube-system   sh.helm.release.v1.kube-ops-view.v1   helm.sh/release.v1              1      25m</span>

<span class="c">#$ DHUSER=&lt;도커 허브 계정&gt;</span>
<span class="c">#$ DHPASS=&lt;도커 허브 암호 혹은 토큰&gt;</span>

<span class="nv">$ DHUSER</span><span class="o">=</span>sweetlittlebird
<span class="nv">$ DHPASS</span><span class="o">=</span>dckr_<span class="k">****</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$DHUSER</span> <span class="nv">$DHPASS</span>
<span class="c"># =&gt; sweetlittlebird dckr_****</span>

<span class="c"># 도커 허브 시크릿 생성</span>
<span class="nv">$ </span>kubectl create secret docker-registry dockerhub-secret <span class="se">\</span>
  <span class="nt">--docker-server</span><span class="o">=</span>https://index.docker.io/v1/ <span class="se">\</span>
  <span class="nt">--docker-username</span><span class="o">=</span><span class="nv">$DHUSER</span> <span class="se">\</span>
  <span class="nt">--docker-password</span><span class="o">=</span><span class="nv">$DHPASS</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get secret
<span class="c"># =&gt; NAME               TYPE                             DATA   AGE</span>
<span class="c">#    dockerhub-secret   kubernetes.io/dockerconfigjson   1      8s</span>
<span class="nv">$ </span>kubectl describe secret
<span class="c"># =&gt; Name:         dockerhub-secret</span>
<span class="c">#    Namespace:    default</span>
<span class="c">#    Labels:       &amp;lt;none&amp;gt;</span>
<span class="c">#    Annotations:  &amp;lt;none&amp;gt;</span>
<span class="c">#    </span>
<span class="c">#    Type:  kubernetes.io/dockerconfigjson</span>
<span class="c">#    </span>
<span class="c">#    Data</span>
<span class="c">#    ====</span>
<span class="c">#    .dockerconfigjson:  205 bytes</span>
<span class="nv">$ </span>kubectl get secrets <span class="nt">-o</span> yaml | kubectl neat  <span class="c"># base64 인코딩 확인</span>
<span class="c"># =&gt; apiVersion: v1</span>
<span class="c">#    items:</span>
<span class="c">#    - apiVersion: v1</span>
<span class="c">#      data:</span>
<span class="c">#        .dockerconfigjson: eyJhdXRocyI6eyJodHRwczovL2luZGV4LmRvY2tlci5pby92MS8iOnsidXNlcm5hbWUiOiJzZWNyZXRsaXR0bGViaXJkIiwicGFzc3dvcmQiOiJkY2tyX3BhdF9QdWNpVTRIMFBPZVpYWGNvV1VNd1ozTVpZVEUiLCJhdXRoIjoiYzJWamNtVjBiR2wwZEd4bFltbHlaRHBrWTJ0eVgzQmhkRjlRZFdOcFZUUklNRkJQWlZwWVdHTnZWMVZOZDFvelRWcFpWRVU9In19fQ==</span>
<span class="c">#      kind: Secret</span>
<span class="c">#      metadata:</span>
<span class="c">#        name: dockerhub-secret</span>
<span class="c">#        namespace: default</span>
<span class="c">#      type: kubernetes.io/dockerconfigjson</span>
<span class="c">#    kind: List</span>
<span class="c">#    metadata: {}</span>

<span class="nv">$ SECRET</span><span class="o">=</span><span class="nv">eyJhdXRocyI6eyJodHRwczovL2luZGV4LmRvY2tlci5pby92MS8iOnsidXNlcm5hbWUiOiJzZWNyZXRsaXR0bGViaXJkIiwicGFzc3dvcmQiOiJkY2tyX3BhdF9QdWNpVTRIMFBPZVpYWGNvV1VNd1ozTVpZVEUiLCJhdXRoIjoiYzJWamNtVjBiR2wwZEd4bFltbHlaRHBrWTJ0eVgzQmhkRjlRZFdOcFZUUklNRkJQWlZwWVdHTnZWMVZOZDFvelRWcFpWRVU9In19fQ</span><span class="o">==</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"</span><span class="nv">$SECRET</span><span class="s2">"</span> | <span class="nb">base64</span> <span class="nt">-d</span> <span class="p">;</span> <span class="nb">echo</span>
<span class="c"># =&gt; {&amp;quot;auths&amp;quot;:{&amp;quot;https://index.docker.io/v1/&amp;quot;:{&amp;quot;username&amp;quot;:&amp;quot;sweetlittlebird&amp;quot;,&amp;quot;password&amp;quot;:&amp;quot;dckr_****&amp;quot;,&amp;quot;auth&amp;quot;:&amp;quot;c2VjcmV0bGl0dGxlYmlyZDpkY2tyX3BhdF9QdWNpVTRIMFBPZVpYWGNvV1VNd1ozTVpZVEU=&amp;quot;}}}</span>

<span class="c"># 도커허브 인증 토큰이 등록되었으니 다시 배포해보겠습니다.</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: timeserver
spec:
  replicas: 2
  selector:
    matchLabels:
      pod: timeserver-pod
  template:
    metadata:
      labels:
        pod: timeserver-pod
    spec:
      containers:
      - name: timeserver-container
        image: docker.io/</span><span class="nv">$DHUSER</span><span class="sh">/dev-app:0.0.1
      imagePullSecrets:
      - name: dockerhub-secret
</span><span class="no">EOF
</span><span class="nv">$ </span>watch <span class="nt">-d</span> kubectl get deploy,pod <span class="nt">-o</span> wide

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get deploy,pod
<span class="c"># =&gt; NAME                         READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/timeserver   2/2     2            2           39s</span>
<span class="c">#    </span>
<span class="c">#    NAME                              READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/timeserver-549cc9bc89-k6n6g   1/1     Running   0          39s</span>
<span class="c">#    pod/timeserver-549cc9bc89-kdmgx   1/1     Running   0          39s</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 배포가 잘 되었습니다!&lt;/span&gt;</span>

<span class="c"># 접속을 위한 curl 파드 생성</span>
<span class="nv">$ </span>kubectl run curl-pod <span class="nt">--image</span><span class="o">=</span>curlimages/curl:latest <span class="nt">--command</span> <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s2">"while true; do sleep 3600; done"</span>
<span class="c"># =&gt; pod/curl-pod created</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                          READY   STATUS    RESTARTS   AGE    IP           NODE            NOMINATED NODE   READINESS GATES</span>
<span class="c">#    curl-pod                      1/1     Running   0          22s    10.244.2.6   myk8s-worker2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    timeserver-549cc9bc89-k6n6g   1/1     Running   0          103s   10.244.2.5   myk8s-worker2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    timeserver-549cc9bc89-kdmgx   1/1     Running   0          103s   10.244.1.6   myk8s-worker    &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>

<span class="c"># timeserver 파드 IP 1개 확인 후 접속 확인</span>
<span class="c">#$ PODIP1=&lt;timeserver-Y 파드 IP&gt;</span>
<span class="nv">$ PODIP1</span><span class="o">=</span>10.244.2.5

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nv">$PODIP1</span>
<span class="c"># =&gt; The time is 2:51:54 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-k6n6g</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nv">$PODIP1</span>
<span class="c"># =&gt; The time is 2:52:03 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-k6n6g</span>

<span class="c"># 로그 확인</span>
<span class="nv">$ </span>kubectl logs deploy/timeserver
<span class="nv">$ </span>kubectl logs deploy/timeserver <span class="nt">-f</span>
<span class="nv">$ </span>kubectl stern deploy/timeserver
<span class="nv">$ </span>kubectl stern <span class="nt">-l</span> <span class="nv">pod</span><span class="o">=</span>timeserver-pod
</code></pre></div></div>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_15.png" alt="img.png" class="image-center" /></p>

<ul>
  <li>kube-ops-view를 통해서도 배포가 잘 되었음을 확인할 수 있습니다.</li>
  <li>파드 1개 삭제 후 동작을 확인해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="c">#$ POD1NAME=&lt;파드 1개 이름&gt;</span>
<span class="nv">$ POD1NAME</span><span class="o">=</span>timeserver-549cc9bc89-k6n6g

<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                          READY   STATUS    RESTARTS   AGE    IP           NODE            NOMINATED NODE   READINESS GATES</span>
<span class="c">#    curl-pod                      1/1     Running   0          22s    10.244.2.6   myk8s-worker2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    timeserver-549cc9bc89-k6n6g   1/1     Running   0          103s   10.244.2.5   myk8s-worker2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    timeserver-549cc9bc89-kdmgx   1/1     Running   0          103s   10.244.1.6   myk8s-worker    &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="nv">$ </span>kubectl delete pod <span class="nv">$POD1NAME</span> <span class="o">&amp;&amp;</span> kubectl get pod <span class="nt">-w</span>
<span class="c"># =&gt; pod &amp;quot;timeserver-549cc9bc89-k6n6g&amp;quot; deleted              # &lt;span style="color: green;"&gt;👉 분명히 timeserver 파드 1개를 삭제하였는데&lt;/span&gt;</span>
<span class="c">#    NAME                          READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    curl-pod                      1/1     Running   0          115s</span>
<span class="c">#    timeserver-549cc9bc89-kdmgx   1/1     Running   0          7m20s</span>
<span class="c">#    timeserver-549cc9bc89-pvm5k   1/1     Running   0          31s   # &lt;span style="color: green;"&gt;👉 다시 새로운 파드가 생성되었습니다.&lt;/span&gt;</span>

<span class="c"># 셀프 힐링 , 파드 IP 변경 -&gt; 고정 진입점(고정 IP/도메인네임) 필요 =&gt; Service</span>
<span class="nv">$ </span>kubectl get deploy,rs,pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                         READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS             IMAGES                                    SELECTOR</span>
<span class="c">#    deployment.apps/timeserver   2/2     2            2           10m   timeserver-container   docker.io/sweetlittlebird/dev-app:0.0.1   pod=timeserver-pod</span>
<span class="c">#    </span>
<span class="c">#    NAME                                    DESIRED   CURRENT   READY   AGE   CONTAINERS             IMAGES                                    SELECTOR</span>
<span class="c">#    replicaset.apps/timeserver-549cc9bc89   2         2         2       10m   timeserver-container   docker.io/sweetlittlebird/dev-app:0.0.1   pod=timeserver-pod,pod-template-hash=549cc9bc89</span>
<span class="c">#    </span>
<span class="c">#    NAME                              READY   STATUS    RESTARTS   AGE     IP           NODE            NOMINATED NODE   READINESS GATES</span>
<span class="c">#    pod/curl-pod                      1/1     Running   0          4m56s   10.244.2.7   myk8s-worker2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    pod/timeserver-549cc9bc89-kdmgx   1/1     Running   0          10m     10.244.1.6   myk8s-worker    &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    pod/timeserver-549cc9bc89-pvm5k   1/1     Running   0          3m32s   10.244.2.8   myk8s-worker2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
</code></pre></div></div>

<ul>
  <li>위와 같이 파드가 삭제되면 ReplicaSet에 의해 새로운 파드가 생성되는 것을 확인할 수 있습니다.</li>
  <li>이때 IP가 변경되어 새로운 파드가 생성되는데, 이렇게 되면 매번 파드가 생성될때 마다 IP가 변경되어 서비스를 제공하기 어렵습니다.</li>
  <li>이를 해결하기 위해 <strong>Service</strong>를 사용합니다.</li>
</ul>

<h5 id="service-소개">Service 소개</h5>

<ul>
  <li><strong>Service</strong>는 Pod의 집합에 대한 고정된 진입점을 제공합니다. 앞서 살펴본것과 같이 Pod는 생성/삭제되면 IP가 변경되는데, 이를 Service를 통해 고정된 IP로 접근할 수 있습니다.</li>
  <li>Deployment를 통해 Pod가 여러 개 생성되면, Service는 이들을 하나의 집합으로 묶어서 부하분산(Load Balancing)을 제공합니다.</li>
  <li>Service는 Deployment를 대상으로 하지않고, Pod를 대상으로 합니다. Pod의 Label Selector를 통해 Service는 Pod를 선택합니다. 
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_16.png" alt="img.png" class="image-center" />
<em class="image-caption">Service와 Deployment, Pod manifest의 관계</em></li>
  <li>Service는 다음과 같은 종류가 있습니다.
    <ul>
      <li><strong>ClusterIP</strong> : 클러스터 내부에서만 접근 가능합니다.</li>
      <li><strong>NodePort</strong> : 클러스터 내부에서는 물론 외부에서 접근 가능합니다. 이때 파드가 동작하는 노드 IP의 지정된 포트로 접근 가능합니다.</li>
      <li><strong>LoadBalancer</strong> : 클라우드 제공자의 로드밸런서를 사용하여 외부에서 접근 가능합니다.</li>
    </ul>
  </li>
</ul>

<h5 id="service-배포-실습">Service 배포 실습</h5>

<ul>
  <li>간단한 서비스를 배포해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 서비스 생성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Service
metadata:
  name: timeserver
spec:
  selector:
    pod: timeserver-pod
  ports:
  - port: 80
    targetPort: 80
    protocol: TCP
    nodePort: 30000
  type: NodePort
</span><span class="no">EOF
</span><span class="c"># =&gt; service/timeserver created</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get service,ep timeserver <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                 TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE   SELECTOR</span>
<span class="c">#    service/timeserver   NodePort   10.96.204.127   &amp;lt;none&amp;gt;        80:30000/TCP   13s   pod=timeserver-pod</span>
<span class="c">#    </span>
<span class="c">#    NAME                   ENDPOINTS                     AGE</span>
<span class="c">#    endpoints/timeserver   10.244.1.6:80,10.244.2.8:80   13s</span>

<span class="c"># Service(ClusterIP)로 접속 확인 : 도메인네임 방식</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl timeserver
<span class="c"># =&gt; The time is 3:29:30 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl timeserver.default.svc.cluster.local
<span class="c"># =&gt; The time is 3:29:33 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-pvm5k</span>

<span class="c"># Service(ClusterIP)로 접속 확인 : 클러스터 IP 방식</span>
<span class="nv">$ </span>kubectl get svc timeserver <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.spec.clusterIP<span class="o">}</span>
<span class="c"># =&gt; 10.96.204.127</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="si">$(</span>kubectl get svc timeserver <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.spec.clusterIP<span class="o">}</span><span class="si">)</span>
<span class="c"># =&gt; The time is 3:29:40 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-pvm5k</span>

<span class="c"># Service(NodePort)로 접속 확인 "노드IP:NodePort"</span>
<span class="nv">$ </span>curl http://127.0.0.1:30000
<span class="c"># =&gt; The time is 3:32:43 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-&lt;span style="color: red;"&gt;kdmgx&lt;/span&gt;</span>
<span class="nv">$ </span>curl http://127.0.0.1:30000
<span class="c"># =&gt; The time is 3:32:59 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-&lt;span style="color: red;"&gt;pvm5k&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 서비스가 2개의 Pod 사이를 Load balancing 하는것을 확인 할 수 있습니다.&lt;/span&gt;</span>

<span class="c"># 반복 접속 해두기 : 부하분산 확인</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 http://127.0.0.1:30000 | <span class="nb">grep </span>name <span class="p">;</span> <span class="nb">sleep </span>1 <span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; Server hostname: timeserver-549cc9bc89-kdmgx</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-kdmgx</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#    ...</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span>  <span class="k">do </span>curl <span class="nt">-s</span> http://127.0.0.1:30000 | <span class="nb">grep </span>name<span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;   54 Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#      46 Server hostname: timeserver-549cc9bc89-kdmgx</span>

<span class="c"># 파드 복제복 증가 : service endpoint 대상에 자동 추가</span>
<span class="nv">$ </span>kubectl scale deployment timeserver <span class="nt">--replicas</span> 4
<span class="c"># =&gt; deployment.apps/timeserver scaled</span>
<span class="nv">$ </span>kubectl get service,ep timeserver <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                 TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE   SELECTOR</span>
<span class="c">#    service/timeserver   NodePort   10.96.204.127   &amp;lt;none&amp;gt;        80:30000/TCP   37m   pod=timeserver-pod</span>
<span class="c">#    </span>
<span class="c">#    NAME                   ENDPOINTS                                               AGE</span>
<span class="c">#    endpoints/timeserver   10.244.1.6:80,10.244.1.7:80,10.244.2.8:80 + 1 more...   37m</span>

<span class="c"># 반복 접속 해두기 : 부하분산 확인</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 http://127.0.0.1:30000 | <span class="nb">grep </span>name <span class="p">;</span> <span class="nb">sleep </span>1 <span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-h9q6p</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-h9q6p</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-xlbck</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-kdmgx</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-xlbck</span>
<span class="c">#    ...</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span>  <span class="k">do </span>curl <span class="nt">-s</span> http://127.0.0.1:30000 | <span class="nb">grep </span>name<span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;   29 Server hostname: timeserver-549cc9bc89-xlbck</span>
<span class="c">#      27 Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#      22 Server hostname: timeserver-549cc9bc89-kdmgx</span>
<span class="c">#      22 Server hostname: timeserver-549cc9bc89-h9q6p</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 파드 수 만큼 자동으로 로드밸런싱 되는것을 확인 할 수 있습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<h5 id="앱-업데이트-후-재배포">앱 업데이트 후 재배포</h5>

<ul>
  <li>샘플 앱의 server.py와 VERSION 파일을 업데이트하고, Jenkins Pipeline을 통해 새로운 버전을 배포해보겠습니다.</li>
  <li>먼저 샘플 앱의 업데이트를 진행합니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 업데이트</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s1">'s/0.0.1/0.0.2/g'</span> server.py
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"0.0.2"</span> <span class="o">&gt;</span> VERSION
<span class="nv">$ </span>git add <span class="nb">.</span>
<span class="nv">$ </span>git commit <span class="nt">-m</span> <span class="s2">"Update to 0.0.2"</span>
<span class="c"># =&gt; main c17ce89] Update to 0.0.2</span>
<span class="c">#     2 files changed, 2 insertions(+), 2 deletions(-)</span>
<span class="nv">$ </span>git push origin main
<span class="c"># =&gt; Enumerating objects: 7, done.</span>
<span class="c">#    Counting objects: 100% (7/7), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (3/3), done.</span>
<span class="c">#    Writing objects: 100% (4/4), 332 bytes | 332.00 KiB/s, done.</span>
<span class="c">#    Total 4 (delta 2), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To http://10.0.4.3:3000/devops/dev-app.git</span>
<span class="c">#       3531233..c17ce89  main -&amp;gt; main</span>
</code></pre></div>    </div>
  </li>
  <li>Jenkins에서 Build Now를 클릭하여 통해 새로운 버전을 docker hub에 업로드 합니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_17.png" alt="img.png" /></p>

<ul>
  <li>새로운 버전이 docker hub에 업로드 되었으니, Kubernetes 클러스터에 배포해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 파드 복제복 증가</span>
<span class="nv">$ </span>kubectl scale deployment timeserver <span class="nt">--replicas</span> 4
<span class="c"># =&gt; deployment.apps/timeserver scaled</span>
<span class="nv">$ </span>kubectl get service,ep timeserver <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                 TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE   SELECTOR</span>
<span class="c">#    service/timeserver   NodePort   10.96.204.127   &amp;lt;none&amp;gt;        80:30000/TCP   45m   pod=timeserver-pod</span>
<span class="c">#    </span>
<span class="c">#    NAME                   ENDPOINTS                                               AGE</span>
<span class="c">#    endpoints/timeserver   10.244.1.6:80,10.244.1.7:80,10.244.2.8:80 + 1 more...   45m</span>

<span class="c"># 반복 접속 해두기 : 부하분산 확인</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 http://127.0.0.1:30000 | <span class="nb">grep </span>name <span class="p">;</span> <span class="nb">sleep </span>1 <span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; Server hostname: timeserver-549cc9bc89-kdmgx</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-h9q6p</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-kdmgx</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-xlbck</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#    ...</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span>  <span class="k">do </span>curl <span class="nt">-s</span> http://127.0.0.1:30000 | <span class="nb">grep </span>name<span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;   32 Server hostname: timeserver-549cc9bc89-xlbck</span>
<span class="c">#      27 Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#      25 Server hostname: timeserver-549cc9bc89-kdmgx</span>
<span class="c">#      16 Server hostname: timeserver-549cc9bc89-h9q6p</span>

<span class="c"># 업데이트를 배포하기 위해서 kubectl set image를 통해 컨테이너 이미지를 변경합니다.</span>
<span class="c"># $ kubectl set image deployment timeserver timeserver-container=$DHUSER/dev-app:0.0.Y &amp;&amp; watch -d "kubectl get deploy,ep timeserver; echo; kubectl get rs,pod"</span>
<span class="nv">$ </span>kubectl <span class="nb">set </span>image deployment timeserver timeserver-container<span class="o">=</span><span class="nv">$DHUSER</span>/dev-app:0.0.2 <span class="o">&amp;&amp;</span> watch <span class="nt">-d</span> <span class="s2">"kubectl get deploy,ep timeserver; echo; kubectl get rs,pod"</span>
<span class="c"># =&gt; Every 2.0s: kubectl get deploy,ep timeserver; echo; kubectl get rs,pod                                                                 Balthazar.local: Sun Oct 01 01:17:30 2024</span>
<span class="c">#    ...</span>
<span class="c">#    </span>
<span class="c">#    NAME                              READY   STATUS        RESTARTS   AGE</span>
<span class="c">#    pod/timeserver-549cc9bc89-h9q6p   1/1     Terminating   0          11m</span>
<span class="c">#    pod/timeserver-549cc9bc89-kdmgx   1/1     Terminating   0          88m</span>
<span class="c">#    pod/timeserver-549cc9bc89-pvm5k   1/1     Terminating   0          81m</span>
<span class="c">#    pod/timeserver-549cc9bc89-xlbck   1/1     Terminating   0          11m</span>
<span class="c">#    pod/timeserver-6f476fdbf-f8hw5    1/1     Running       0          9s</span>
<span class="c">#    pod/timeserver-6f476fdbf-k5fsn    1/1     Running       0          9s</span>
<span class="c">#    pod/timeserver-6f476fdbf-qq465    1/1     Running       0          4s</span>
<span class="c">#    pod/timeserver-6f476fdbf-tvrl5    1/1     Running       0          3s</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 기존 버전의 파드가 종료되고 새로운 파드가 replica 수 만큼 생성 되는 것을 확인 할 수 있습니다.&lt;/span&gt;</span>

<span class="c"># 롤링업데이트를 확인하기 위해 별도의 터미널에서 다음의 명령을 입력합니다.</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 http://127.0.0.1:30000<span class="p">;</span> <span class="nb">sleep </span>1 <span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    The time is 4:17:24 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#    The time is 4:17:25 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-xlbck</span>
<span class="c">#    The time is 4:17:26 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-xlbck</span>
<span class="c">#    The time is 4:17:27 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#    The time is 4:17:28 PM, VERSION 0.0.2</span>
<span class="c">#    Server hostname: timeserver-6f476fdbf-k5fsn</span>
<span class="c">#    The time is 4:17:29 PM, VERSION 0.0.2</span>
<span class="c">#    Server hostname: timeserver-6f476fdbf-qq465</span>
<span class="c">#    The time is 4:17:30 PM, VERSION 0.0.2</span>
<span class="c">#    Server hostname: timeserver-6f476fdbf-tvrl5</span>
<span class="c">#    The time is 4:17:31 PM, VERSION 0.0.2</span>
<span class="c">#    Server hostname: timeserver-6f476fdbf-f8hw5</span>
<span class="c">#    The time is 4:17:32 PM, VERSION 0.0.2</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 롤링업데이트를 통해 서비스 중단 없이 배포가 잘 됨을 확인 할 수 있습니다.&lt;/span&gt;</span>


<span class="c"># 롤링 업데이트 확인</span>
<span class="nv">$ </span>kubectl get deploy,rs,pod,svc,ep <span class="nt">-owide</span>

<span class="c"># kubectl get deploy $DEPLOYMENT_NAME</span>
<span class="nv">$ </span>kubectl get deploy timeserver
<span class="c"># =&gt; NAME         READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    timeserver   4/4     4            4           90m</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 READY는 전체 replica 중 몇 개의 파드가 서비스가 가능한지 알려줍니다.&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;    UP-TO-DATE는 몇 개의 파드가 현재의 버전(상태)인지 알려줍니다.&lt;/span&gt;</span>

<span class="nv">$ </span>kubectl get pods <span class="nt">-l</span> <span class="nv">pod</span><span class="o">=</span>timeserver-pod
<span class="c"># =&gt; NAME                         READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    timeserver-6f476fdbf-f8hw5   1/1     Running   0          3m3s</span>
<span class="c">#    timeserver-6f476fdbf-k5fsn   1/1     Running   0          3m3s</span>
<span class="c">#    timeserver-6f476fdbf-qq465   1/1     Running   0          2m58s</span>
<span class="c">#    timeserver-6f476fdbf-tvrl5   1/1     Running   0          2m57s</span>
</code></pre></div></div>

<h4 id="gogs-webhook을-통해-jenkins-pipeline-자동화">Gogs Webhook을 통해 Jenkins Pipeline 자동화</h4>

<ul>
  <li>Jenkins Pipeline을 통해 새로운 버전을 배포하는 과정을 자동화하기 위해 Gogs Webhook을 설정해보겠습니다.</li>
  <li>git push를 통해 새로운 버전을 업로드하면, Gogs Webhook을 통해 Jenkins Pipeline이 자동으로 실행되어 새로운 버전의 도커 이미지가 docker hub에 업로드되도록 합니다.</li>
</ul>

<h5 id="gogs-설정-수정-및-webhook-설정">Gogs 설정 수정 및 Webhook 설정</h5>

<ul>
  <li>
    <p>먼저 gogs 컨테이너의 app.ini 파일을 수정하여 jenkins가 gogs에 접근할 수 있도록 설정합니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># app.ini 파일 수정</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>gogs vi /data/gogs/conf/app.ini
</code></pre></div>    </div>

    <div class="language-ini highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># app.ini
</span><span class="err">...</span>
<span class="nn">[security]</span>
<span class="py">INSTALL_LOCK</span> <span class="p">=</span> <span class="s">true</span>
<span class="py">SECRET_KEY</span>   <span class="p">=</span> <span class="s">atxaUPQcbAEwpIu</span>
<span class="py">LOCAL_NETWORK_ALLOWLIST</span> <span class="p">=</span> <span class="s">10.0.4.3 # 각자 자신의 PC IP</span>
<span class="err">...</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>Gogs 컨테이너를 재기동합니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker compose restart gogs
</code></pre></div>    </div>
  </li>
  <li>
    <p>Gogs 에서 Webhook을 설정합니다.</p>
    <ol>
      <li>Repository를 선택후 우측의 Settings &gt; Webhooks &gt; Add a new webhook에서 Gogs를 선택합니다.
  <img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_18.png" alt="img.png" /></li>
      <li>Payload URL : <code class="language-plaintext highlighter-rouge">http://&lt;Jenkins의 IP = PC의 IP&gt;:8080/gogs-webhook/?job=SCM-Pipeline/</code></li>
      <li>Content Type : <code class="language-plaintext highlighter-rouge">application/json</code></li>
      <li>Secret : <code class="language-plaintext highlighter-rouge">qwe123</code></li>
      <li>When should this webhook be triggered? : Just the push event</li>
      <li>Active : 체크</li>
      <li>Add Webhook을 클릭하여 웹훅을 저장합니다.</li>
    </ol>
  </li>
</ul>

<h5 id="jenkins에서-gogs-webhook을-통한-pipeline-생성">Jenkins에서 Gogs Webhook을 통한 Pipeline 생성</h5>

<ul>
  <li>이번에는 Jenkins에서 앞서 생성한 Gogs Webhook을 통해 새로운 버전을 배포하는 Pipeline을 생성해보겠습니다.</li>
  <li>Dashboard &gt; New Item 을 선택합니다.
    <ul>
      <li>item name : SCM-Pipeline</li>
      <li>item type : Pipeline</li>
      <li>OK를 클릭합니다.</li>
    </ul>
  </li>
  <li>Pipeline 설정을 다음과 같이 설정합니다.
    <ul>
      <li>GitHub project : <code class="language-plaintext highlighter-rouge">http://&lt;PC의 IP&gt;:3000/&lt;Gogs 계정명&gt;/dev-app.git</code></li>
      <li>Use Gogs secret : <code class="language-plaintext highlighter-rouge">qwe123</code></li>
      <li>Build Triggers : Build when a change is pushed to Gogs 체크</li>
      <li>Pipeline script from SCM
        <ul>
          <li>SCM : Git
            <ul>
              <li>Repo URL : <code class="language-plaintext highlighter-rouge">http://&lt;PC의 IP&gt;:3000/&lt;Gogs 계정명&gt;/dev-app.git</code></li>
              <li>Credentials : <code class="language-plaintext highlighter-rouge">devops/*</code></li>
              <li>Branch : <code class="language-plaintext highlighter-rouge">*/main</code></li>
            </ul>
          </li>
          <li>Script Path : <code class="language-plaintext highlighter-rouge">Jenkinsfile</code> 
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_19.png" alt="img.png" /></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h5 id="jenkinsfile-작성-후-git-push">Jenkinsfile 작성 후 Git Push</h5>

<ul>
  <li>Jenkinsfile을 작성합니다.</li>
</ul>

<div class="language-groovy highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pipeline</span> <span class="o">{</span>
    <span class="n">agent</span> <span class="n">any</span>
    <span class="n">environment</span> <span class="o">{</span>
        <span class="n">DOCKER_IMAGE</span> <span class="o">=</span> <span class="s1">'&lt;자신의 도커 허브 계정&gt;/dev-app'</span> <span class="c1">// Docker 이미지 이름</span>
    <span class="o">}</span>
    <span class="n">stages</span> <span class="o">{</span>
        <span class="n">stage</span><span class="o">(</span><span class="s1">'Checkout'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                 <span class="n">git</span> <span class="nl">branch:</span> <span class="s1">'main'</span><span class="o">,</span>
                 <span class="nl">url:</span> <span class="s1">'http://&lt;PC의 IP&gt;:3000/devops/dev-app.git'</span><span class="o">,</span>  <span class="c1">// Git에서 코드 체크아웃</span>
                 <span class="nl">credentialsId:</span> <span class="s1">'gogs-crd'</span>  <span class="c1">// Credentials ID</span>
            <span class="o">}</span>
        <span class="o">}</span>
        <span class="n">stage</span><span class="o">(</span><span class="s1">'Read VERSION'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">script</span> <span class="o">{</span>
                    <span class="c1">// VERSION 파일 읽기</span>
                    <span class="kt">def</span> <span class="n">version</span> <span class="o">=</span> <span class="n">readFile</span><span class="o">(</span><span class="s1">'VERSION'</span><span class="o">).</span><span class="na">trim</span><span class="o">()</span>
                    <span class="n">echo</span> <span class="s2">"Version found: ${version}"</span>
                    <span class="c1">// 환경 변수 설정</span>
                    <span class="n">env</span><span class="o">.</span><span class="na">DOCKER_TAG</span> <span class="o">=</span> <span class="n">version</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
        <span class="n">stage</span><span class="o">(</span><span class="s1">'Docker Build and Push'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">script</span> <span class="o">{</span>
                    <span class="n">docker</span><span class="o">.</span><span class="na">withRegistry</span><span class="o">(</span><span class="s1">'https://index.docker.io/v1/'</span><span class="o">,</span> <span class="s1">'dockerhub-crd'</span><span class="o">)</span> <span class="o">{</span>
                        <span class="c1">// DOCKER_TAG 사용</span>
                        <span class="kt">def</span> <span class="n">appImage</span> <span class="o">=</span> <span class="n">docker</span><span class="o">.</span><span class="na">build</span><span class="o">(</span><span class="s2">"${DOCKER_IMAGE}:${DOCKER_TAG}"</span><span class="o">)</span>
                        <span class="n">appImage</span><span class="o">.</span><span class="na">push</span><span class="o">()</span>
                        <span class="n">appImage</span><span class="o">.</span><span class="na">push</span><span class="o">(</span><span class="s2">"latest"</span><span class="o">)</span>
                    <span class="o">}</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
    <span class="n">post</span> <span class="o">{</span>
        <span class="n">success</span> <span class="o">{</span>
            <span class="n">echo</span> <span class="s2">"Docker image ${DOCKER_IMAGE}:${DOCKER_TAG} has been built and pushed successfully!"</span>
        <span class="o">}</span>
        <span class="n">failure</span> <span class="o">{</span>
            <span class="n">echo</span> <span class="s2">"Pipeline failed. Please check the logs."</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<ul>
  <li>VERSION 파일과 server.py 파일을 0.0.2 =&gt; 0.0.3으로 수정합니다.</li>
  <li>작성된 파일 push</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"VERSION </span><span class="si">$(</span><span class="nb">cat </span>VERSION<span class="si">)</span><span class="s2"> Changed"</span> <span class="o">&amp;&amp;</span> git push <span class="nt">-u</span> origin main
</code></pre></div></div>

<ul>
  <li>Push와 거의 동시에 Jenkins에서 Build가 시작되고 성공적으로 빌드가 되었습니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_20.png" alt="img.png" /></p>

<ul>
  <li>Docker hub에도 0.0.3 버전이 업로드 잘 되었습니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_21.png" alt="img.png" /></p>

<ul>
  <li>Gogs에서 Repository &gt; Settings &gt; Webhooks &gt; 웹훅 클릭하면 웹훅 전달 로그를 확인할 수 있습니다.
Gogs =&gt; Jenkins의 방향으로 Webhook이 전달되었음을 확인할 수 있습니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_22.png" alt="img.png" /></p>

<ul>
  <li>마지막으로 Kubernetes 클러스터에서 새로운 버전을 배포하겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl <span class="nb">set </span>image deployment timeserver timeserver-container<span class="o">=</span><span class="nv">$DHUSER</span>/dev-app:0.0.3 <span class="o">&amp;&amp;</span> watch <span class="nt">-d</span> <span class="s2">"kubectl get deploy,ep timeserver; echo; kubectl get rs,pod"</span>
</code></pre></div></div>

<hr />

<h3 id="jenkins-cicd--k8s-kind">Jenkins CI/CD + K8S (Kind)</h3>

<ul>
  <li>이번에는 Jenkins에서 바로 Kubernetes 클러스터에 배포할 수 있도록 하는 실습을 진행해보겠습니다.</li>
  <li>Jenkins 컨테이너 내부에 필요한 툴(kubectl, helm)을 설치 하겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Install kubectl, helm</span>
<span class="nv">$ </span>docker compose <span class="nb">exec</span> <span class="nt">--privileged</span> <span class="nt">-u</span> root jenkins bash
<span class="nt">--------------------------------------------</span>
<span class="c">#curl -LO "https://dl.k8s.io/release/v1.31.0/bin/linux/amd64/kubectl" </span>
<span class="nv">$ </span>curl <span class="nt">-LO</span> <span class="s2">"https://dl.k8s.io/release/</span><span class="si">$(</span>curl <span class="nt">-L</span> <span class="nt">-s</span> https://dl.k8s.io/release/stable.txt<span class="si">)</span><span class="s2">/bin/linux/arm64/kubectl"</span>  <span class="c"># macOS</span>
<span class="c"># $ curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"  # WindowOS</span>

<span class="nv">$ </span><span class="nb">install</span> <span class="nt">-o</span> root <span class="nt">-g</span> root <span class="nt">-m</span> 0755 kubectl /usr/local/bin/kubectl
<span class="nv">$ </span>kubectl version <span class="nt">--client</span><span class="o">=</span><span class="nb">true</span>
<span class="c"># =&gt; Client Version: v1.32.0</span>
<span class="c">#    Kustomize Version: v5.5.0</span>

<span class="c">#</span>
<span class="nv">$ </span>curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
<span class="nv">$ </span>helm version
<span class="c"># =&gt; version.BuildInfo{Version:&amp;quot;v3.16.4&amp;quot;, GitCommit:&amp;quot;7877b45b63f95635153b29a42c0c2f4273ec45ca&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;, GoVersion:&amp;quot;go1.22.7&amp;quot;}</span>

<span class="nv">$ </span><span class="nb">exit</span>
<span class="nt">--------------------------------------------</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins kubectl version <span class="nt">--client</span><span class="o">=</span><span class="nb">true</span>
<span class="c"># =&gt; Client Version: v1.32.0</span>
<span class="c">#    Kustomize Version: v5.5.0</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins helm version
<span class="c"># =&gt; version.BuildInfo{Version:&amp;quot;v3.16.4&amp;quot;, GitCommit:&amp;quot;7877b45b63f95635153b29a42c0c2f4273ec45ca&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;, GoVersion:&amp;quot;go1.22.7&amp;quot;}</span>
</code></pre></div></div>

<ul>
  <li>Jenkins Item 생성(Pipeline) : item name(k8s-cmd)</li>
</ul>

<div class="language-gradle highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pipeline</span> <span class="o">{</span>
    <span class="n">agent</span> <span class="n">any</span>
    <span class="n">environment</span> <span class="o">{</span>
        <span class="n">KUBECONFIG</span> <span class="o">=</span> <span class="n">credentials</span><span class="o">(</span><span class="s1">'k8s-crd'</span><span class="o">)</span>
    <span class="o">}</span>
    <span class="n">stages</span> <span class="o">{</span>
        <span class="n">stage</span><span class="o">(</span><span class="s1">'List Pods'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">sh</span> <span class="s1">'''
                # Fetch and display Pods
                kubectl get pods -A --kubeconfig "$KUBECONFIG"
                '''</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_23.png" alt="img.png" /></p>

<h5 id="jenkins를-이용한-blue-green-배포-실습">Jenkins를 이용한 blue-green 배포 실습</h5>

<ul>
  <li>디플로이먼트 / 서비스 yaml 파일 작성 - http-echo 및 코드 push</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># </span>
<span class="nv">$ </span><span class="nb">cd </span>dev-app

<span class="c">#</span>
<span class="nv">$ </span><span class="nb">mkdir </span>deploy

<span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> deploy/echo-server-blue.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: apps/v1
kind: Deployment
metadata:
  name: echo-server-blue
spec:
  replicas: 2
  selector:
    matchLabels:
      app: echo-server
      version: blue
  template:
    metadata:
      labels:
        app: echo-server
        version: blue
    spec:
      containers:
      - name: echo-server
        image: hashicorp/http-echo
        args:
        - "-text=Hello from Blue"
        ports:
        - containerPort: 5678
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> deploy/echo-server-service.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: v1
kind: Service
metadata:
  name: echo-server-service
spec:
  selector:
    app: echo-server
    version: blue
  ports:
  - protocol: TCP
    port: 80
    targetPort: 5678
    nodePort: 30000
  type: NodePort
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> deploy/echo-server-green.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: apps/v1
kind: Deployment
metadata:
  name: echo-server-green
spec:
  replicas: 2
  selector:
    matchLabels:
      app: echo-server
      version: green
  template:
    metadata:
      labels:
        app: echo-server
        version: green
    spec:
      containers:
      - name: echo-server
        image: hashicorp/http-echo
        args:
        - "-text=Hello from Green"
        ports:
        - containerPort: 5678
</span><span class="no">EOF

</span><span class="c">#</span>
<span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"Add echo server yaml"</span> <span class="o">&amp;&amp;</span> git push <span class="nt">-u</span> origin main
<span class="c"># =&gt; main 76adc73] Add echo server yaml</span>
<span class="c">#     3 files changed, 60 insertions(+)</span>
<span class="c">#     create mode 100644 deploy/echo-server-blue.yaml</span>
<span class="c">#     create mode 100644 deploy/echo-server-green.yaml</span>
<span class="c">#     create mode 100644 deploy/echo-server-service.yaml</span>
<span class="c">#    Enumerating objects: 7, done.</span>
<span class="c">#    Counting objects: 100% (7/7), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (6/6), done.</span>
<span class="c">#    Writing objects: 100% (6/6), 789 bytes | 789.00 KiB/s, done.</span>
<span class="c">#    Total 6 (delta 2), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To http://10.0.4.3:3000/devops/dev-app.git</span>
<span class="c">#       60f336b..76adc73  main -&amp;gt; main</span>
<span class="c">#    branch 'main' set up to track 'origin/main'.</span>
</code></pre></div></div>

<ul>
  <li>Jenkins에서 Pipeline을 작성하여 배포해 보겠습니다.</li>
  <li>먼저, 이전 실습에서 배포한 deployment와 service를 삭제합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl delete deploy,svc timeserver
<span class="c"># =&gt; deployment.apps &amp;quot;timeserver&amp;quot; deleted</span>
<span class="c">#    service &amp;quot;timeserver&amp;quot; deleted</span>
</code></pre></div></div>

<ul>
  <li>반복접속을 미리 실행해둡니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 별도의 터미널에서 실행</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 http://127.0.0.1:30000 <span class="p">;</span> <span class="nb">echo</span> <span class="p">;</span> <span class="nb">sleep </span>1  <span class="p">;</span> kubectl get deploy <span class="nt">-owide</span> <span class="p">;</span> <span class="nb">echo</span> <span class="p">;</span> kubectl get svc,ep echo-server-service <span class="nt">-owide</span> <span class="p">;</span> <span class="nb">echo</span> <span class="s2">"------------"</span> <span class="p">;</span> <span class="k">done</span>
<span class="c"># 혹은 </span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 http://127.0.0.1:30000 <span class="p">;</span> <span class="nb">date</span> <span class="p">;</span> <span class="nb">echo</span> <span class="s2">"------------"</span> <span class="p">;</span> <span class="nb">sleep </span>1 <span class="p">;</span> <span class="k">done</span>
</code></pre></div></div>

<ul>
  <li>Jenkins에서 Pipeline 생성 : item name(k8s-bluegreen)</li>
</ul>

<div class="language-gradle highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pipeline</span> <span class="o">{</span>
    <span class="n">agent</span> <span class="n">any</span>

    <span class="n">environment</span> <span class="o">{</span>
        <span class="n">KUBECONFIG</span> <span class="o">=</span> <span class="n">credentials</span><span class="o">(</span><span class="s1">'k8s-crd'</span><span class="o">)</span>
    <span class="o">}</span>

    <span class="n">stages</span> <span class="o">{</span>
        <span class="n">stage</span><span class="o">(</span><span class="s1">'Checkout'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                 <span class="n">git</span> <span class="nl">branch:</span> <span class="s1">'main'</span><span class="o">,</span>
                 <span class="nl">url:</span> <span class="s1">'http://&lt;PC의 IP&gt;:3000/devops/dev-app.git'</span><span class="o">,</span>  <span class="c1">// Git에서 코드 체크아웃</span>
                 <span class="nl">credentialsId:</span> <span class="s1">'gogs-crd'</span>  <span class="c1">// Credentials ID</span>
            <span class="o">}</span>
        <span class="o">}</span>

        <span class="n">stage</span><span class="o">(</span><span class="s1">'container image build'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">echo</span> <span class="s2">"container image build"</span>
            <span class="o">}</span>
        <span class="o">}</span>

        <span class="n">stage</span><span class="o">(</span><span class="s1">'container image upload'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">echo</span> <span class="s2">"container image upload"</span>
            <span class="o">}</span>
        <span class="o">}</span>

        <span class="n">stage</span><span class="o">(</span><span class="s1">'k8s deployment blue version'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">sh</span> <span class="s2">"kubectl apply -f ./deploy/echo-server-blue.yaml --kubeconfig $KUBECONFIG"</span>
                <span class="n">sh</span> <span class="s2">"kubectl apply -f ./deploy/echo-server-service.yaml --kubeconfig $KUBECONFIG"</span>
            <span class="o">}</span>
        <span class="o">}</span>

        <span class="n">stage</span><span class="o">(</span><span class="s1">'approve green version'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">input</span> <span class="nl">message:</span> <span class="s1">'approve green version'</span><span class="o">,</span> <span class="nl">ok:</span> <span class="s2">"Yes"</span>
            <span class="o">}</span>
        <span class="o">}</span>

        <span class="n">stage</span><span class="o">(</span><span class="s1">'k8s deployment green version'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
	        	<span class="n">sh</span> <span class="s2">"kubectl apply -f ./deploy/echo-server-green.yaml --kubeconfig $KUBECONFIG"</span>
            <span class="o">}</span>
        <span class="o">}</span>

        <span class="n">stage</span><span class="o">(</span><span class="s1">'approve version switching'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">script</span> <span class="o">{</span>
                    <span class="n">returnValue</span> <span class="o">=</span> <span class="n">input</span> <span class="nl">message:</span> <span class="s1">'Green switching?'</span><span class="o">,</span> <span class="nl">ok:</span> <span class="s2">"Yes"</span><span class="o">,</span> <span class="nl">parameters:</span> <span class="o">[</span><span class="n">booleanParam</span><span class="o">(</span><span class="nl">defaultValue:</span> <span class="kc">true</span><span class="o">,</span> <span class="nl">name:</span> <span class="s1">'IS_SWITCHED'</span><span class="o">)]</span>
                    <span class="k">if</span> <span class="o">(</span><span class="n">returnValue</span><span class="o">)</span> <span class="o">{</span>
                        <span class="n">sh</span> <span class="s2">"kubectl patch svc echo-server-service -p '{\"spec\": {\"selector\": {\"version\": \"green\"}}}' --kubeconfig $KUBECONFIG"</span>
                    <span class="o">}</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>

        <span class="n">stage</span><span class="o">(</span><span class="s1">'Blue Rollback'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">script</span> <span class="o">{</span>
                    <span class="n">returnValue</span> <span class="o">=</span> <span class="n">input</span> <span class="nl">message:</span> <span class="s1">'Blue Rollback?'</span><span class="o">,</span> <span class="nl">parameters:</span> <span class="o">[</span><span class="n">choice</span><span class="o">(</span><span class="nl">choices:</span> <span class="o">[</span><span class="s1">'done'</span><span class="o">,</span> <span class="s1">'rollback'</span><span class="o">],</span> <span class="nl">name:</span> <span class="s1">'IS_ROLLBACk'</span><span class="o">)]</span>
                    <span class="k">if</span> <span class="o">(</span><span class="n">returnValue</span> <span class="o">==</span> <span class="s2">"done"</span><span class="o">)</span> <span class="o">{</span>
                        <span class="n">sh</span> <span class="s2">"kubectl delete -f ./deploy/echo-server-blue.yaml --kubeconfig $KUBECONFIG"</span>
                    <span class="o">}</span>
                    <span class="k">if</span> <span class="o">(</span><span class="n">returnValue</span> <span class="o">==</span> <span class="s2">"rollback"</span><span class="o">)</span> <span class="o">{</span>
                        <span class="n">sh</span> <span class="s2">"kubectl patch svc echo-server-service -p '{\"spec\": {\"selector\": {\"version\": \"blue\"}}}' --kubeconfig $KUBECONFIG"</span>
                    <span class="o">}</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<ul>
  <li>Build Now로 배포 후 동작을 확인합니다.
    <ul>
      <li>blue 버전이 배포된 다음 green 버전을 배포할지 승인 여부를 묻습니다.
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_24.png" alt="img.png" /></li>
      <li>승인하면 green 버전이 배포됩니다. 하지만 아직 트래픽은 Blue로만 흐릅니다.
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl get deploy <span class="nt">-owide</span> <span class="p">;</span> <span class="nb">echo</span> <span class="p">;</span> kubectl get svc,ep echo-server-service <span class="nt">-owide</span>
<span class="c"># =&gt; Hello from Blue</span>
<span class="c">#    </span>
<span class="c">#    NAME                READY   UP-TO-DATE   AVAILABLE   AGE     CONTAINERS    IMAGES                SELECTOR</span>
<span class="c">#    echo-server-blue    2/2     2            2           3m46s   echo-server   hashicorp/http-echo   app=echo-server,version=blue</span>
<span class="c">#    echo-server-green   2/2     2            2           31s     echo-server   hashicorp/http-echo   app=echo-server,version=green</span>
<span class="c">#    </span>
<span class="c">#    NAME                          TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE     SELECTOR</span>
<span class="c">#    service/echo-server-service   NodePort   10.96.40.148   &amp;lt;none&amp;gt;        80:30000/TCP   3m45s   app=echo-server,version=blue</span>
<span class="c">#    </span>
<span class="c">#    NAME                            ENDPOINTS                         AGE</span>
<span class="c">#    endpoints/echo-server-service   10.244.1.8:5678,10.244.2.8:5678   3m45s</span>
</code></pre></div>        </div>
      </li>
      <li>green으로 배포할지 승인하면 마침내 green으로 트래픽이 전달 됩니다. 
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_25.png" alt="img.png" />
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl get deploy <span class="nt">-owide</span> <span class="p">;</span> <span class="nb">echo</span> <span class="p">;</span> kubectl get svc,ep echo-server-service <span class="nt">-owide</span>
<span class="c"># =&gt; Hello from Green</span>
<span class="c">#    </span>
<span class="c">#    NAME                READY   UP-TO-DATE   AVAILABLE   AGE     CONTAINERS    IMAGES                SELECTOR</span>
<span class="c">#    echo-server-blue    2/2     2            2           6m14s   echo-server   hashicorp/http-echo   app=echo-server,version=blue</span>
<span class="c">#    echo-server-green   2/2     2            2           2m59s   echo-server   hashicorp/http-echo   app=echo-server,version=green</span>
<span class="c">#    </span>
<span class="c">#    NAME                          TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE     SELECTOR</span>
<span class="c">#    service/echo-server-service   NodePort   10.96.40.148   &amp;lt;none&amp;gt;        80:30000/TCP   6m13s   app=echo-server,version=green</span>
<span class="c">#    </span>
<span class="c">#    NAME                            ENDPOINTS                         AGE</span>
<span class="c">#    endpoints/echo-server-service   10.244.1.9:5678,10.244.2.9:5678   6m13s</span>
</code></pre></div>        </div>
      </li>
      <li>마지막으로 blue를 롤백할지 물으며, 승인하면 blue가 삭제 됩니다.
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># =&gt; Hello from Green</span>
<span class="c">#    </span>
<span class="c">#    NAME                READY   UP-TO-DATE   AVAILABLE   AGE     CONTAINERS    IMAGES                SELECTOR</span>
<span class="c">#    echo-server-green   2/2     2            2           4m55s   echo-server   hashicorp/http-echo   app=echo-server,version=green</span>
<span class="c">#    </span>
<span class="c">#    NAME                          TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE    SELECTOR</span>
<span class="c">#    service/echo-server-service   NodePort   10.96.40.148   &amp;lt;none&amp;gt;        80:30000/TCP   8m9s   app=echo-server,version=green</span>
<span class="c">#    </span>
<span class="c">#    NAME                            ENDPOINTS                         AGE</span>
<span class="c">#    endpoints/echo-server-service   10.244.1.9:5678,10.244.2.9:5678   8m9s</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li>실습 완료 후 삭제</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl delete deploy echo-server-blue echo-server-green
<span class="nv">$ </span>kubectl delete svc echo-server-service
</code></pre></div></div>

<h3 id="jenkins-ci--argocd--k8s-kind">Jenkins CI + ArgoCD + K8S (Kind)</h3>

<h4 id="argocd-소개">ArgoCD 소개</h4>

<ul>
  <li>ArgoCD는 GitOps를 지원하는 CD 도구로, Kubernetes 클러스터에 배포된 애플리케이션의 상태를 지속적으로 모니터링하고,
Git 저장소에 정의된 상태와 실제 상태가 일치하지 않을 경우 자동으로 동기화하여 애플리케이션을 원하는 상태로 유지하는 툴입니다.</li>
  <li>ArgoCD의 아키텍쳐
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_26.png" alt="img.png" /></li>
  <li>ArgoCD는 배포된 애플리케이션의 상태인 Kubernetes manifest를 다음의 방식들로 정의할 수 있습니다.
    <ul>
      <li><a href="https://kustomize.io/">Kustomize</a> 애플리케이션</li>
      <li><a href="https://helm.sh/">helm</a> chart</li>
      <li><a href="https://jsonnet.org/">jsonnet</a> 파일</li>
      <li>yaml/json manifest 파일이 있는 디렉터리</li>
      <li>기타 config management plugin에서 정의한 파일</li>
    </ul>
  </li>
  <li>자세한 사항은 <a href="https://argoproj.github.io/">공식 홈페이지</a>나 <a href="https://malwareanalysis.tistory.com/tag/ArgoCD">악분님 ArgoCD 정리 블로그</a>를 참고해주세요.</li>
</ul>

<h4 id="argocd-설치-및-기본설정">ArgoCD 설치 및 기본설정</h4>

<ul>
  <li>ArgoCD를 설치하고 기본 설정을 진행해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 네임스페이스 생성 및 파라미터 파일 작성</span>
<span class="nv">$ </span>kubectl create ns argocd
<span class="c"># =&gt; namespace/argocd created</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; argocd-values.yaml
dex:
  enabled: false

server:
  service:
    type: NodePort
    nodePortHttps: 30002
</span><span class="no">EOF

</span><span class="c"># 설치</span>
<span class="nv">$ </span>helm repo add argo https://argoproj.github.io/argo-helm
<span class="c"># =&gt; &amp;quot;argo&amp;quot; has been added to your repositories</span>
<span class="nv">$ </span>helm <span class="nb">install </span>argocd argo/argo-cd <span class="nt">--version</span> 7.7.10 <span class="nt">-f</span> argocd-values.yaml <span class="nt">--namespace</span> argocd
<span class="c"># =&gt; NAME: argocd</span>
<span class="c">#    LAST DEPLOYED: Sun Oct 01 16:53:42 2024</span>
<span class="c">#    NAMESPACE: argocd</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 1</span>
<span class="c">#    TEST SUITE: None</span>
<span class="c">#    NOTES:</span>
<span class="c">#    In order to access the server UI you have the following options:</span>
<span class="c">#    </span>
<span class="c">#    1. kubectl port-forward service/argocd-server -n argocd 8080:443</span>
<span class="c">#        and then open the browser on http://localhost:8080 and accept the certificate</span>
<span class="c">#    </span>
<span class="c">#    2. enable ingress in the values file `server.ingress.enabled` and either</span>
<span class="c">#          - Add the annotation for ssl passthrough: https://argo-cd.readthedocs.io/en/stable/operator-manual/ingress/#option-1-ssl-passthrough</span>
<span class="c">#          - Set the `configs.params.&amp;quot;server.insecure&amp;quot;` in the values file and terminate SSL at your ingress: https://argo-cd.readthedocs.io/en/stable/operator-manual/ingress/#option-2-multiple-ingress-objects-and-hosts</span>
<span class="c">#    </span>
<span class="c">#    After reaching the UI the first time you can login with username: admin and the random password generated during the installation. You can find the password by running:</span>
<span class="c">#    kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath=&amp;quot;{.data.password}&amp;quot; | base64 -d</span>
<span class="c">#    (You should delete the initial secret afterwards as suggested by the Getting Started Guide: https://argo-cd.readthedocs.io/en/stable/getting_started/#4-login-using-the-cli)</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get pod,svc,ep <span class="nt">-n</span> argocd
<span class="c"># =&gt; NAME                                                    READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/argocd-application-controller-0                     1/1     Running   0          4m55s</span>
<span class="c">#    pod/argocd-applicationset-controller-856f6bd788-zvtd2   1/1     Running   0          4m55s</span>
<span class="c">#    pod/argocd-notifications-controller-764b9d6597-z4mrx    1/1     Running   0          4m55s</span>
<span class="c">#    pod/argocd-redis-5c67786686-qwx8f                       1/1     Running   0          4m55s</span>
<span class="c">#    pod/argocd-repo-server-c9f8b6dbf-jpjcq                  1/1     Running   0          4m55s</span>
<span class="c">#    pod/argocd-server-7bff46b6bd-7n6vx                      1/1     Running   0          4m55s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                       TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE</span>
<span class="c">#    service/argocd-applicationset-controller   ClusterIP   10.96.166.245   &amp;lt;none&amp;gt;        7000/TCP                     4m55s</span>
<span class="c">#    service/argocd-redis                       ClusterIP   10.96.46.103    &amp;lt;none&amp;gt;        6379/TCP                     4m55s</span>
<span class="c">#    service/argocd-repo-server                 ClusterIP   10.96.117.132   &amp;lt;none&amp;gt;        8081/TCP                     4m55s</span>
<span class="c">#    service/argocd-server                      NodePort    10.96.75.70     &amp;lt;none&amp;gt;        80:30080/TCP,443:30002/TCP   4m55s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                         ENDPOINTS                           AGE</span>
<span class="c">#    endpoints/argocd-applicationset-controller   10.244.2.13:7000                    4m55s</span>
<span class="c">#    endpoints/argocd-redis                       10.244.2.12:6379                    4m55s</span>
<span class="c">#    endpoints/argocd-repo-server                 10.244.1.11:8081                    4m55s</span>
<span class="c">#    endpoints/argocd-server                      10.244.1.10:8080,10.244.1.10:8080   4m55s</span>
<span class="nv">$ </span>kubectl get crd | <span class="nb">grep </span>argo
<span class="c"># =&gt; applications.argoproj.io      2024-10-01T07:54:01Z</span>
<span class="c">#    applicationsets.argoproj.io   2024-10-01T07:54:01Z</span>
<span class="c">#    appprojects.argoproj.io       2024-10-01T07:54:01Z</span>

<span class="c"># 최초 접속 암호 확인</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> argocd get secret argocd-initial-admin-secret <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.data.password}"</span> | <span class="nb">base64</span> <span class="nt">-d</span> <span class="p">;</span><span class="nb">echo</span>
<span class="c"># =&gt; ZaQfvE9xrehyKxvl</span>

<span class="c"># Argo CD 웹 접속 주소 확인 : 초기 암호 입력 (admin 계정)</span>
<span class="nv">$ </span>open <span class="s2">"https://127.0.0.1:30002"</span> <span class="c"># macOS</span>
<span class="c">## Windows OS경우 직접 웹 브라우저에서 https://127.0.0.1:30002 접속</span>
</code></pre></div></div>

<ul>
  <li>Argo CD 웹 접속 확인 - 위에서 확인한 초기 비밀번호로 로그인합니다.
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_27.png" alt="img.png" class="image-center" />
<em class="image-caption">Argo CD 웹 초기 화면</em>
    <ul>
      <li>User Info &gt; Update password로 admin 계정 암호를 변경합니다. (qwe12345)</li>
    </ul>
  </li>
  <li>Settings &gt; Clusters, Projects, Accounts 등 기본정보를 확인해봅니다.</li>
  <li>실습을 위해 ops-deploy Repo를 등록해보겠습니다.
    <ul>
      <li>Settings &gt; Repositories &gt; Connect Repo 클릭
        <ul>
          <li>connection method : VIA HTTPS</li>
          <li>Type : git</li>
          <li>Project : default</li>
          <li>Repo URL : http://<PC의 IP="">:3000/devops/ops-deploy</PC의></li>
          <li>Username : devops</li>
          <li>Password : <Gogs 토큰=""></Gogs></li>
        </ul>

        <p>=&gt;  입력 후 CONNECT 클릭
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_28.png" alt="img.png" /></p>
      </li>
      <li>모든 정보가 정확하여 연결이 되면 연결상태가 Successful로 등록됩니다.</li>
    </ul>
  </li>
</ul>

<h4 id="helm-chart를-통한-배포-실습">Helm chart를 통한 배포 실습</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">mkdir </span>nginx-chart
<span class="nv">$ </span><span class="nb">cd </span>nginx-chart

<span class="nv">$ </span><span class="nb">mkdir </span>templates

<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> templates/configmap.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: v1
kind: ConfigMap
metadata:
  name: 
data:
  index.html: |
</span><span class="no">
EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> templates/deployment.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: apps/v1
kind: Deployment
metadata:
  name: 
spec:
  replicas: 
  selector:
    matchLabels:
      app: 
  template:
    metadata:
      labels:
        app: 
    spec:
      containers:
      - name: nginx
        image: :
        ports:
        - containerPort: 80
        volumeMounts:
        - name: index-html
          mountPath: /usr/share/nginx/html/index.html
          subPath: index.html
      volumes:
      - name: index-html
        configMap:
          name: 
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> templates/service.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: v1
kind: Service
metadata:
  name: 
spec:
  selector:
    app: 
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
    nodePort: 30000
  type: NodePort
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> values.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
indexHtml: |
  &lt;!DOCTYPE html&gt;
  &lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Welcome to Nginx!&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;h1&gt;Hello, Kubernetes!&lt;/h1&gt;
    &lt;p&gt;Nginx version 1.26.1&lt;/p&gt;
  &lt;/body&gt;
  &lt;/html&gt;

image:
  repository: nginx
  tag: 1.26.1

replicaCount: 1
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Chart.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: v2
name: nginx-chart
description: A Helm chart for deploying Nginx with custom index.html
type: application
version: 1.0.0
appVersion: "1.26.1"
</span><span class="no">EOF

</span><span class="c"># 이전 timeserver/service(nodeport) 삭제</span>
<span class="nv">$ </span>kubectl delete deploy,svc <span class="nt">--all</span>

<span class="c"># 직접 배포 해보기</span>
<span class="nv">$ </span>helm <span class="nb">install </span>dev-nginx <span class="nb">.</span> <span class="nt">-f</span> values.yaml
<span class="c"># =&gt; NAME: dev-nginx</span>
<span class="c">#    LAST DEPLOYED: Sun Oct 01 19:54:23 2024</span>
<span class="c">#    NAMESPACE: default</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 1</span>
<span class="c">#    TEST SUITE: None</span>
<span class="nv">$ </span>helm list
<span class="c"># =&gt; NAME       NAMESPACE REVISION  UPDATED                             STATUS    CHART             APP VERSION</span>
<span class="c">#    dev-nginx  default   1         2024-10-01 19:54:23.03644 +0900 KST deployed  nginx-chart-1.0.0 1.26.1     </span>
<span class="nv">$ </span>kubectl get deploy,svc,ep,cm dev-nginx <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                        READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES         SELECTOR</span>
<span class="c">#    deployment.apps/dev-nginx   1/1     1            1           4s    nginx        nginx:1.26.1   app=dev-nginx</span>
<span class="c">#    </span>
<span class="c">#    NAME                TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE   SELECTOR</span>
<span class="c">#    service/dev-nginx   NodePort   10.96.79.233   &amp;lt;none&amp;gt;        80:30000/TCP   4s    app=dev-nginx</span>
<span class="c">#    </span>
<span class="c">#    NAME                  ENDPOINTS        AGE</span>
<span class="c">#    endpoints/dev-nginx   10.244.1.16:80   4s</span>
<span class="c">#    </span>
<span class="c">#    NAME                  DATA   AGE</span>
<span class="c">#    configmap/dev-nginx   1      4s</span>

<span class="c">#</span>
<span class="nv">$ </span>curl http://127.0.0.1:30000
<span class="c"># =&gt; &lt;!DOCTYPE html&amp;gt;</span>
<span class="c">#    &amp;lt;html&amp;gt;</span>
<span class="c">#    &amp;lt;head&amp;gt;</span>
<span class="c">#      &amp;lt;title&amp;gt;Welcome to Nginx!&amp;lt;/title&amp;gt;</span>
<span class="c">#    &amp;lt;/head&amp;gt;</span>
<span class="c">#    &amp;lt;body&amp;gt;</span>
<span class="c">#      &amp;lt;h1&amp;gt;Hello, Kubernetes!&amp;lt;/h1&amp;gt;</span>
<span class="c">#      &amp;lt;p&amp;gt;Nginx version 1.26.1&amp;lt;/p&amp;gt;</span>
<span class="c">#    &amp;lt;/body&amp;gt;</span>
<span class="c">#    &amp;lt;/html&amp;gt;</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> http://127.0.0.1:30000 | <span class="nb">grep </span>version
<span class="c"># =&gt;   &amp;lt;p&amp;gt;Nginx version 1.26.1&amp;lt;/p&amp;gt;</span>
<span class="nv">$ </span>open http://127.0.0.1:30000

<span class="c"># value 값 변경 후 적용 해보기 : version/tag, replicaCount</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> values.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
indexHtml: |
  &lt;!DOCTYPE html&gt;
  &lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Welcome to Nginx!&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;h1&gt;Hello, Kubernetes!&lt;/h1&gt;
    &lt;p&gt;Nginx version 1.26.2&lt;/p&gt;
  &lt;/body&gt;
  &lt;/html&gt;

image:
  repository: nginx
  tag: 1.26.2

replicaCount: 2
</span><span class="no">EOF

</span><span class="c"># helm chart 업그레이드 적용</span>
<span class="nv">$ </span>helm upgrade dev-nginx <span class="nb">.</span> <span class="nt">-f</span> values.yaml
<span class="c"># =&gt; Release &amp;quot;dev-nginx&amp;quot; has been upgraded. Happy Helming!</span>
<span class="c">#    NAME: dev-nginx</span>
<span class="c">#    LAST DEPLOYED: Sun Oct 01 19:56:59 2024</span>
<span class="c">#    NAMESPACE: default</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 2</span>
<span class="c">#    TEST SUITE: None</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>helm list
<span class="c"># =&gt; NAME            NAMESPACE       REVISION        UPDATED                                 STATUS          CHART                   APP VERSION</span>
<span class="c">#    dev-nginx       default         2               2024-10-01 19:56:59.30731 +0900 KST     deployed        nginx-chart-1.0.0       1.26.1</span>
<span class="nv">$ </span>kubectl get deploy,svc,ep,cm dev-nginx <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                        READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES         SELECTOR</span>
<span class="c">#    deployment.apps/dev-nginx   &lt;span style="color: red;"&gt;2/2     2            2&lt;/span&gt;           38s   nginx        &lt;span style="color: red;"&gt;nginx:1.26.2&lt;/span&gt;   app=dev-nginx</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 Replica가 2개로 늘어나서 파드가 2개가 되었고 버전 1.26.2가 적용되었습니다.&lt;/span&gt;</span>
<span class="nv">$ </span>curl http://127.0.0.1:30000
<span class="c"># =&gt; &amp;lt;!DOCTYPE html&amp;gt;</span>
<span class="c">#    &amp;lt;html&amp;gt;</span>
<span class="c">#    &amp;lt;head&amp;gt;</span>
<span class="c">#      &amp;lt;title&amp;gt;Welcome to Nginx!&amp;lt;/title&amp;gt;</span>
<span class="c">#    &amp;lt;/head&amp;gt;</span>
<span class="c">#    &amp;lt;body&amp;gt;</span>
<span class="c">#      &amp;lt;h1&amp;gt;Hello, Kubernetes!&amp;lt;/h1&amp;gt;</span>
<span class="c">#      &amp;lt;p&amp;gt;Nginx version 1.26.2&amp;lt;/p&amp;gt;</span>
<span class="c">#    &amp;lt;/body&amp;gt;</span>
<span class="c">#    &amp;lt;/html&amp;gt;</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> http://127.0.0.1:30000 | <span class="nb">grep </span>version
<span class="c"># =&gt;   &amp;lt;p&amp;gt;Nginx version 1.26.2&amp;lt;/p&amp;gt;</span>
<span class="nv">$ </span>open http://127.0.0.1:30000

<span class="c"># 확인 후 삭제</span>
<span class="nv">$ </span>helm uninstall dev-nginx
</code></pre></div></div>

<h5 id="repoops-deploy-에-nginx-helm-chart-를-argo-cd를-통한-배포-1">Repo(ops-deploy) 에 nginx helm chart 를 Argo CD를 통한 배포 1</h5>

<ul>
  <li>git 작업</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">mkdir </span>cicd-labs
<span class="nv">$ </span><span class="nb">cd </span>cicd-labs
<span class="nv">$ </span>git clone http://10.0.4.3:3000/devops/ops-deploy.git
<span class="c"># =&gt; Cloning into 'ops-deploy'...</span>
<span class="c">#    remote: Enumerating objects: 3, done.</span>
<span class="c">#    remote: Counting objects: 100% (3/3), done.</span>
<span class="c">#    remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    Unpacking objects: 100% (3/3), 228 bytes | 114.00 KiB/s, done.</span>
<span class="nv">$ </span><span class="nb">cd </span>ops-deploy

<span class="c">#</span>
<span class="nv">$ </span>git config user.name <span class="s2">"devops"</span>
<span class="nv">$ </span>git config user.email <span class="s2">"a@a.com"</span>
<span class="nv">$ </span>git config init.defaultBranch main
<span class="nv">$ </span>git config credential.helper store

<span class="c">#</span>
<span class="nv">$ VERSION</span><span class="o">=</span>1.26.1
<span class="nv">$ </span><span class="nb">mkdir </span>nginx-chart
<span class="nv">$ </span><span class="nb">mkdir </span>nginx-chart/templates

<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> nginx-chart/VERSION <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
</span><span class="nv">$VERSION</span><span class="sh">
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> nginx-chart/templates/configmap.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: v1
kind: ConfigMap
metadata:
  name: 
data:
  index.html: |
</span><span class="no">
EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> nginx-chart/templates/deployment.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: apps/v1
kind: Deployment
metadata:
  name: 
spec:
  replicas: 
  selector:
    matchLabels:
      app: 
  template:
    metadata:
      labels:
        app: 
    spec:
      containers:
      - name: nginx
        image: :
        ports:
        - containerPort: 80
        volumeMounts:
        - name: index-html
          mountPath: /usr/share/nginx/html/index.html
          subPath: index.html
      volumes:
      - name: index-html
        configMap:
          name: 
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> nginx-chart/templates/service.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: v1
kind: Service
metadata:
  name: 
spec:
  selector:
    app: 
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
    nodePort: 30000
  type: NodePort
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> nginx-chart/values-dev.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
indexHtml: |
  &lt;!DOCTYPE html&gt;
  &lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Welcome to Nginx!&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;h1&gt;Hello, Kubernetes!&lt;/h1&gt;
    &lt;p&gt;DEV : Nginx version </span><span class="nv">$VERSION</span><span class="sh">&lt;/p&gt;
  &lt;/body&gt;
  &lt;/html&gt;

image:
  repository: nginx
  tag: </span><span class="nv">$VERSION</span><span class="sh">

replicaCount: 1
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> nginx-chart/values-prd.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
indexHtml: |
  &lt;!DOCTYPE html&gt;
  &lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Welcome to Nginx!&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;h1&gt;Hello, Kubernetes!&lt;/h1&gt;
    &lt;p&gt;PRD : Nginx version </span><span class="nv">$VERSION</span><span class="sh">&lt;/p&gt;
  &lt;/body&gt;
  &lt;/html&gt;

image:
  repository: nginx
  tag: </span><span class="nv">$VERSION</span><span class="sh">

replicaCount: 2
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> nginx-chart/Chart.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: v2
name: nginx-chart
description: A Helm chart for deploying Nginx with custom index.html
type: application
version: 1.0.0
appVersion: "</span><span class="nv">$VERSION</span><span class="sh">"
</span><span class="no">EOF

</span><span class="nv">$ </span>tree nginx-chart
<span class="c"># =&gt; nginx-chart</span>
<span class="c">#    ├── Chart.yaml</span>
<span class="c">#    ├── VERSION</span>
<span class="c">#    ├── templates</span>
<span class="c">#    │   ├── configmap.yaml</span>
<span class="c">#    │   ├── deployment.yaml</span>
<span class="c">#    │   └── service.yaml</span>
<span class="c">#    ├── values-dev.yaml</span>
<span class="c">#    └── values-prd.yaml</span>

<span class="c">#</span>
<span class="nv">$ </span>git status <span class="o">&amp;&amp;</span> git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"Add nginx helm chart"</span> <span class="o">&amp;&amp;</span> git push <span class="nt">-u</span> origin main
<span class="c"># =&gt; On branch main</span>
<span class="c">#    Your branch is up to date with 'origin/main'.</span>
<span class="c">#    </span>
<span class="c">#    Untracked files:</span>
<span class="c">#      (use &amp;quot;git add &amp;lt;file&amp;gt;...&amp;quot; to include in what will be committed)</span>
<span class="c">#            nginx-chart/</span>
<span class="c">#    </span>
<span class="c">#    nothing added to commit but untracked files present (use &amp;quot;git add&amp;quot; to track)</span>
<span class="c">#    [main 2bcfda2] Add nginx helm chart</span>
<span class="c">#     7 files changed, 88 insertions(+)</span>
<span class="c">#     create mode 100644 nginx-chart/Chart.yaml</span>
<span class="c">#     create mode 100644 nginx-chart/VERSION</span>
<span class="c">#     create mode 100644 nginx-chart/templates/configmap.yaml</span>
<span class="c">#     create mode 100644 nginx-chart/templates/deployment.yaml</span>
<span class="c">#     create mode 100644 nginx-chart/templates/service.yaml</span>
<span class="c">#     create mode 100644 nginx-chart/values-dev.yaml</span>
<span class="c">#     create mode 100644 nginx-chart/values-prd.yaml</span>
<span class="c">#    Enumerating objects: 12, done.</span>
<span class="c">#    Counting objects: 100% (12/12), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (10/10), done.</span>
<span class="c">#    Writing objects: 100% (11/11), 1.44 KiB | 1.44 MiB/s, done.</span>
<span class="c">#    Total 11 (delta 1), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To http://10.0.4.3:3000/devops/ops-deploy.git</span>
<span class="c">#       f7dc047..2bcfda2  main -&amp;gt; main</span>
<span class="c">#    branch 'main' set up to track 'origin/main'.</span>
</code></pre></div></div>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_29.png" alt="img.png" /></p>

<h5 id="argo-cd에-app-등록">Argo CD에 App 등록</h5>

<ul>
  <li>ArgoCD에서 Application &gt; New App을 클릭하여 애플리케이션을 등록합니다.
    <ul>
      <li>GENERAL
        <ul>
          <li>App Name : dev-nginx</li>
          <li>Project Name : default</li>
          <li>SYNC POLICY : Manual</li>
          <li>SYNC OPTIONS : AUTO-CREATE NAMESPACE(Check)</li>
        </ul>
      </li>
      <li>Source
        <ul>
          <li>Repo URL : <code class="language-plaintext highlighter-rouge">&lt;설정되어 있는 것 선택&gt;</code> (http://10.0.4.3:3000/devops/ops-deploy)</li>
          <li>Revision : HEAD</li>
          <li>PATH : nginx-chart</li>
        </ul>
      </li>
      <li>DESTINATION
        <ul>
          <li>Cluster URL : <code class="language-plaintext highlighter-rouge">&lt;기본값&gt;</code></li>
          <li>NAMESPACE : dev-nginx</li>
        </ul>
      </li>
      <li>HELM
        <ul>
          <li>Values files : values-dev.yaml 
=&gt; 작성 후 상단 CREATE 클릭</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_30.png" alt="img.png" class="image-center" />
<em class="image-caption">Argo CD Application 등록 직후</em></p>

<ul>
  <li>등록 직후에는 git에 등록된 manifest 파일의 내용과 현재 k8s의 상태가 다르기 때문에 <code class="language-plaintext highlighter-rouge">OutOfSync</code> 상태로 표시됩니다.</li>
  <li>dev-nginx를 클릭해서 보면 리소스의 배치와 어떤 리소스가 <code class="language-plaintext highlighter-rouge">OutOfSync</code>인지 표시가 됩니다.</li>
  <li>다음 명령을 입력해서 application의 배포상태를 확인해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>kubectl get applications <span class="nt">-n</span> argocd
<span class="c"># =&gt; NAME        SYNC STATUS   HEALTH STATUS</span>
<span class="c">#    dev-nginx   OutOfSync     Missing</span>

<span class="nv">$ </span>kubectl describe applications <span class="nt">-n</span> argocd dev-nginx
<span class="c"># =&gt; ...</span>
<span class="c">#    Events:</span>
<span class="c">#      Type    Reason           Age    From                           Message</span>
<span class="c">#      ----    ------           ----   ----                           -------</span>
<span class="c">#      Normal  ResourceCreated  7m38s  argocd-server                  admin created application</span>
<span class="c">#      Normal  ResourceUpdated  7m     argocd-application-controller  Updated sync status:  -&amp;gt; Unknown</span>
<span class="c">#      Normal  ResourceUpdated  6m58s  argocd-application-controller  Updated health status:  -&amp;gt; Healthy</span>
<span class="c">#      Normal  ResourceUpdated  3m35s  argocd-application-controller  Updated sync status: Unknown -&amp;gt; OutOfSync</span>
<span class="c">#      Normal  ResourceUpdated  3m35s  argocd-application-controller  Updated health status: Healthy -&amp;gt; Missing</span>

<span class="c"># 반복 접속 시도</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 http://127.0.0.1:30000 <span class="p">;</span> <span class="nb">date</span> <span class="p">;</span> <span class="nb">echo</span> <span class="s2">"------------"</span> <span class="p">;</span> <span class="nb">sleep </span>1 <span class="p">;</span> <span class="k">done</span>
</code></pre></div></div>

<ul>
  <li>ArgoCD에서 DIFF 버튼을 클릭하면 현재 상태와 git에 등록된 상태를 비교할 수 있습니다.
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_31.png" alt="img.png" class="image-center" />
<em class="image-caption">Argo CD Application DIFF 화면</em></li>
  <li>SYNC 버튼을 클릭하여 git의 manifest에 지정된 상태와 k8s의 상태를 동기화 해보겠습니다.
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_32.png" alt="img.png" /></li>
  <li>동기화가 완료되면 다음과 같이 노란색 화살표 아이콘 대신 녹색 체크표시가 나면서 <code class="language-plaintext highlighter-rouge">Synced</code> 상태로 변경됩니다. 
또한 동시에 Kubernetes에 NGINX가 배포가 잘 되었습니다.
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_33.png" alt="img.png" class="image-center" />
<em class="image-caption">Argo CD Application 동기화 완료</em></li>
</ul>

<h5 id="코드-수정-후-반영-확인">코드 수정 후 반영 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ VERSION</span><span class="o">=</span>1.26.2

<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> nginx-chart/VERSION <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
</span><span class="nv">$VERSION</span><span class="sh">
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> nginx-chart/values-dev.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
indexHtml: |
  &lt;!DOCTYPE html&gt;
  &lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Welcome to Nginx!&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;h1&gt;Hello, Kubernetes!&lt;/h1&gt;
    &lt;p&gt;DEV : Nginx version </span><span class="nv">$VERSION</span><span class="sh">&lt;/p&gt;
  &lt;/body&gt;
  &lt;/html&gt;

image:
  repository: nginx
  tag: </span><span class="nv">$VERSION</span><span class="sh">

replicaCount: 2
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> nginx-chart/values-prd.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
indexHtml: |
  &lt;!DOCTYPE html&gt;
  &lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Welcome to Nginx!&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;h1&gt;Hello, Kubernetes!&lt;/h1&gt;
    &lt;p&gt;PRD : Nginx version </span><span class="nv">$VERSION</span><span class="sh">&lt;/p&gt;
  &lt;/body&gt;
  &lt;/html&gt;

image:
  repository: nginx
  tag: </span><span class="nv">$VERSION</span><span class="sh">

replicaCount: 2
</span><span class="no">EOF

</span><span class="c">#</span>
<span class="nv">$ </span>git status <span class="o">&amp;&amp;</span> git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"Update nginx version </span><span class="si">$(</span><span class="nb">cat </span>nginx-chart/VERSION<span class="si">)</span><span class="s2">"</span> <span class="o">&amp;&amp;</span> git push <span class="nt">-u</span> origin main
<span class="c"># =&gt; On branch main</span>
<span class="c">#    Your branch is up to date with 'origin/main'.</span>
<span class="c">#    </span>
<span class="c">#    Changes not staged for commit:</span>
<span class="c">#      (use &amp;quot;git add &amp;lt;file&amp;gt;...&amp;quot; to update what will be committed)</span>
<span class="c">#      (use &amp;quot;git restore &amp;lt;file&amp;gt;...&amp;quot; to discard changes in working directory)</span>
<span class="c">#            modified:   nginx-chart/VERSION</span>
<span class="c">#            modified:   nginx-chart/values-dev.yaml</span>
<span class="c">#            modified:   nginx-chart/values-prd.yaml</span>
<span class="c">#    </span>
<span class="c">#    no changes added to commit (use &amp;quot;git add&amp;quot; and/or &amp;quot;git commit -a&amp;quot;)</span>
<span class="c">#    [main e1b02a2] Update nginx version 1.26.2</span>
<span class="c">#     3 files changed, 6 insertions(+), 6 deletions(-)</span>
<span class="c">#    Enumerating objects: 11, done.</span>
<span class="c">#    Counting objects: 100% (11/11), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (5/5), done.</span>
<span class="c">#    Writing objects: 100% (6/6), 589 bytes | 589.00 KiB/s, done.</span>
<span class="c">#    Total 6 (delta 2), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To http://10.0.4.3:3000/devops/ops-deploy.git</span>
<span class="c">#       2bcfda2..e1b02a2  main -&amp;gt; main</span>
<span class="c">#    branch 'main' set up to track 'origin/main'.</span>
</code></pre></div></div>

<ul>
  <li>Argo CD 웹 확인 =&gt; REFRESH 클릭
    <ul>
      <li>ArgoCD는 주기적으로 동기화 되나 바로 확인하려면 REFRESH 버튼을 클릭해야 합니다. (기본 주기는 3분)
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_34.png" alt="img.png" class="image-center" /></li>
      <li>DIFF로 확인하면 manifest 파일의 변경사항이 나타납니다.
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_35.png" alt="img.png" class="image-center" /></li>
    </ul>
  </li>
  <li>SYNC &gt; SYNCHRONIZE를 클릭하여 동기화 해보겠습니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 배포확인</span>
<span class="nv">$ </span>kubectl get all <span class="nt">-n</span> dev-nginx <span class="nt">-o</span> wide
<span class="c"># =&gt; NAME                             READY   STATUS    RESTARTS   AGE   IP           NODE            NOMINATED NODE   READINESS GATES</span>
<span class="c">#    pod/dev-nginx-5db658bd4f-nfldn   1/1     Running   0          8s    10.244.1.7   myk8s-worker    &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    pod/dev-nginx-5db658bd4f-rxmfz   1/1     Running   0          10s   10.244.2.6   myk8s-worker2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    </span>
<span class="c">#    NAME                TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE   SELECTOR</span>
<span class="c">#    service/dev-nginx   NodePort   10.96.233.99   &amp;lt;none&amp;gt;        80:30000/TCP   16m   app=dev-nginx</span>
<span class="c">#    </span>
<span class="c">#    NAME                        READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES         SELECTOR</span>
<span class="c">#    deployment.apps/dev-nginx   2/2     2            2           16m   nginx        &lt;span style="color: red;"&gt;nginx:1.26.2&lt;/span&gt;   app=dev-nginx</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 변경된 버전이 잘 배포되었습니다.&lt;/span&gt;</span>
<span class="c">#    </span>
<span class="c">#    NAME                                   DESIRED   CURRENT   READY   AGE   CONTAINERS   IMAGES         SELECTOR</span>
<span class="c">#    replicaset.apps/dev-nginx-5db658bd4f   2         2         2       11s   nginx        nginx:1.26.2   app=dev-nginx,pod-template-hash=5db658bd4f</span>
<span class="c">#    replicaset.apps/dev-nginx-77d44dfbf6   0         0         0       16m   nginx        nginx:1.26.1   app=dev-nginx,pod-template-hash=77d44dfbf6</span>
</code></pre></div>    </div>
  </li>
  <li>여기에서 replicaset은 기존 1.26.1이 남아있는데 그것은 ArgoCD가 Rollback을 지원하기 위해 기존 replicaset을 남겨서 관리하기 때문입니다.</li>
  <li>몇개의 history를 남길지는 설정에서 변경할 수 있습니다.</li>
  <li>ArgoCD웹 에서 APP 삭제하고 아래의 명령으로 삭제 진행상황을 확인합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>watch <span class="nt">-d</span> kubectl get all <span class="nt">-n</span> dev-nginx <span class="nt">-o</span> wide
</code></pre></div></div>

<h4 id="argocd-declarative-setup으로-배포-실습">ArgoCD Declarative Setup으로 배포 실습</h4>

<ul>
  <li>이번에는 ArgoCD 애플리케이션 자체를 yaml로 생성해보겠습니다.</li>
  <li>이를 통해 애플리케이션을 생성하고 배포하는 과정을 자동화할 수 있습니다.</li>
  <li>자세한 사항은 다음 공식 문서를 참고하세요. <a href="https://argo-cd.readthedocs.io/en/stable/operator-manual/declarative-setup/">ArgoCD Declarative Setup - Project, applications, ArgoCD Settings - Docs</a></li>
  <li>dev-nginx App 생성 및 Auto SYNC</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Declarative 방식으로 ArgoCD App 생성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: dev-nginx
  namespace: argocd
  finalizers:
  - resources-finalizer.argocd.argoproj.io
spec:
  project: default
  source:
    helm:
      valueFiles:
      - values-dev.yaml
    path: nginx-chart
    repoURL: http://10.0.4.3:3000/devops/ops-deploy
    targetRevision: HEAD
  syncPolicy:
    automated:
      prune: true
    syncOptions:
    - CreateNamespace=true
  destination:
    namespace: dev-nginx
    server: https://kubernetes.default.svc
</span><span class="no">EOF
</span><span class="c"># =&gt; application.argoproj.io/dev-nginx created</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get applications <span class="nt">-n</span> argocd dev-nginx
<span class="c"># =&gt; NAME        SYNC STATUS   HEALTH STATUS</span>
<span class="c">#    dev-nginx   Synced        Healthy</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 automated sync 정책이어서 배포 직후 동기화 된 상태가 됩니다.&lt;/span&gt;</span>
<span class="nv">$ </span>kubectl get applications <span class="nt">-n</span> argocd dev-nginx <span class="nt">-o</span> yaml | kubectl neat
<span class="nv">$ </span>kubectl describe applications <span class="nt">-n</span> argocd dev-nginx
<span class="c"># =&gt; ...</span>
<span class="c">#    Events:</span>
<span class="c">#      Type    Reason              Age   From                           Message</span>
<span class="c">#      ----    ------              ----  ----                           -------</span>
<span class="c">#      Normal  ResourceUpdated     80s   argocd-application-controller  Updated sync status:  -&amp;gt; Unknown</span>
<span class="c">#      Normal  ResourceUpdated     80s   argocd-application-controller  Updated health status:  -&amp;gt; Healthy</span>
<span class="c">#      Normal  OperationStarted    57s   argocd-application-controller  Initiated automated sync to 'e1b02a29e47a839ebcc93e46ee9da1f2d5320148'</span>
<span class="c">#      Normal  ResourceUpdated     57s   argocd-application-controller  Updated sync status: Unknown -&amp;gt; OutOfSync</span>
<span class="c">#      Normal  ResourceUpdated     57s   argocd-application-controller  Updated health status: Healthy -&amp;gt; Missing</span>
<span class="c">#      Normal  ResourceUpdated     57s   argocd-application-controller  Updated sync status: OutOfSync -&amp;gt; Synced</span>
<span class="c">#      Normal  ResourceUpdated     57s   argocd-application-controller  Updated health status: Missing -&amp;gt; Progressing</span>
<span class="c">#      Normal  OperationCompleted  57s   argocd-application-controller  Sync operation to e1b02a29e47a839ebcc93e46ee9da1f2d5320148 succeeded</span>
<span class="c">#      Normal  ResourceUpdated     55s   argocd-application-controller  Updated health status: Progressing -&amp;gt; Healthy</span>
<span class="nv">$ </span>kubectl get pod,svc,ep,cm <span class="nt">-n</span> dev-nginx
<span class="c"># =&gt; NAME                             READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/dev-nginx-5db658bd4f-blcr6   1/1     Running   0          74s</span>
<span class="c">#    pod/dev-nginx-5db658bd4f-k984k   1/1     Running   0          74s</span>
<span class="c">#    </span>
<span class="c">#    NAME                TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE</span>
<span class="c">#    service/dev-nginx   NodePort   10.96.176.134   &amp;lt;none&amp;gt;        80:30000/TCP   74s</span>
<span class="c">#    </span>
<span class="c">#    NAME                  ENDPOINTS                     AGE</span>
<span class="c">#    endpoints/dev-nginx   10.244.1.8:80,10.244.2.8:80   74s</span>
<span class="c">#    </span>
<span class="c">#    NAME                         DATA   AGE</span>
<span class="c">#    configmap/dev-nginx          1      74s</span>
<span class="c">#    configmap/kube-root-ca.crt   1      24m</span>

<span class="c">#</span>
<span class="nv">$ </span>curl http://127.0.0.1:30000
<span class="c"># =&gt; &amp;lt;!DOCTYPE html&amp;gt;</span>
<span class="c">#    &amp;lt;html&amp;gt;</span>
<span class="c">#    &amp;lt;head&amp;gt;</span>
<span class="c">#      &amp;lt;title&amp;gt;Welcome to Nginx!&amp;lt;/title&amp;gt;</span>
<span class="c">#    &amp;lt;/head&amp;gt;</span>
<span class="c">#    &amp;lt;body&amp;gt;</span>
<span class="c">#      &amp;lt;h1&amp;gt;Hello, Kubernetes!&amp;lt;/h1&amp;gt;</span>
<span class="c">#      &amp;lt;p&amp;gt;DEV : Nginx version 1.26.2&amp;lt;/p&amp;gt;</span>
<span class="c">#    &amp;lt;/body&amp;gt;</span>
<span class="c">#    &amp;lt;/html&amp;gt;</span>
<span class="nv">$ </span>open http://127.0.0.1:30000

<span class="c"># Argo CD App 삭제</span>
<span class="nv">$ </span>kubectl delete applications <span class="nt">-n</span> argocd dev-nginx
<span class="c"># =&gt; application.argoproj.io &amp;quot;dev-nginx&amp;quot; deleted</span>
</code></pre></div></div>

<ul>
  <li>prd-nginx App 생성 및 Auto SYNC</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: prd-nginx
  namespace: argocd
  finalizers:
  - resources-finalizer.argocd.argoproj.io
spec:
  destination:
    namespace: prd-nginx
    server: https://kubernetes.default.svc
  project: default
  source:
    helm:
      valueFiles:
      - values-prd.yaml
    path: nginx-chart
    repoURL: http://10.0.4.3:3000/devops/ops-deploy
    targetRevision: HEAD
  syncPolicy:
    automated:
      prune: true
    syncOptions:
    - CreateNamespace=true
</span><span class="no">EOF
</span><span class="c"># =&gt; application.argoproj.io/prd-nginx created</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get applications <span class="nt">-n</span> argocd prd-nginx
<span class="c"># =&gt; NAME        SYNC STATUS   HEALTH STATUS</span>
<span class="c">#    prd-nginx   Synced        Healthy</span>
<span class="nv">$ </span>kubectl describe applications <span class="nt">-n</span> argocd prd-nginx
<span class="c"># =&gt; ...</span>
<span class="c">#    Events:</span>
<span class="c">#      Type    Reason              Age   From                           Message</span>
<span class="c">#      ----    ------              ----  ----                           -------</span>
<span class="c">#      Normal  ResourceUpdated     28s   argocd-application-controller  Updated sync status:  -&amp;gt; Unknown</span>
<span class="c">#      Normal  ResourceUpdated     28s   argocd-application-controller  Updated health status:  -&amp;gt; Healthy</span>
<span class="c">#      Normal  OperationStarted    18s   argocd-application-controller  Initiated automated sync to 'e1b02a29e47a839ebcc93e46ee9da1f2d5320148'</span>
<span class="c">#      Normal  ResourceUpdated     18s   argocd-application-controller  Updated sync status: Unknown -&amp;gt; OutOfSync</span>
<span class="c">#      Normal  ResourceUpdated     18s   argocd-application-controller  Updated health status: Healthy -&amp;gt; Missing</span>
<span class="c">#      Normal  ResourceUpdated     15s   argocd-application-controller  Updated sync status: OutOfSync -&amp;gt; Synced</span>
<span class="c">#      Normal  ResourceUpdated     15s   argocd-application-controller  Updated health status: Missing -&amp;gt; Progressing</span>
<span class="c">#      Normal  OperationCompleted  15s   argocd-application-controller  Sync operation to e1b02a29e47a839ebcc93e46ee9da1f2d5320148 succeeded</span>
<span class="c">#      Normal  ResourceUpdated     13s   argocd-application-controller  Updated health status: Progressing -&amp;gt; Healthy</span>
<span class="nv">$ </span>kubectl get pod,svc,ep,cm <span class="nt">-n</span> prd-nginx
<span class="c"># =&gt; NAME                             READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/prd-nginx-645b5ffbbf-9jp6g   1/1     Running   0          45s</span>
<span class="c">#    pod/prd-nginx-645b5ffbbf-ch6q2   1/1     Running   0          45s</span>
<span class="c">#    </span>
<span class="c">#    NAME                TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE</span>
<span class="c">#    service/prd-nginx   NodePort   10.96.206.18   &amp;lt;none&amp;gt;        80:30000/TCP   45s</span>
<span class="c">#    </span>
<span class="c">#    NAME                  ENDPOINTS                     AGE</span>
<span class="c">#    endpoints/prd-nginx   10.244.1.9:80,10.244.2.9:80   45s</span>
<span class="c">#    </span>
<span class="c">#    NAME                         DATA   AGE</span>
<span class="c">#    configmap/kube-root-ca.crt   1      47s</span>
<span class="c">#    configmap/prd-nginx          1      45s</span>

<span class="c">#</span>
<span class="nv">$ </span>curl http://127.0.0.1:30000
<span class="c"># =&gt; &amp;lt;!DOCTYPE html&amp;gt;</span>
<span class="c">#    &amp;lt;html&amp;gt;</span>
<span class="c">#    &amp;lt;head&amp;gt;</span>
<span class="c">#      &amp;lt;title&amp;gt;Welcome to Nginx!&amp;lt;/title&amp;gt;</span>
<span class="c">#    &amp;lt;/head&amp;gt;</span>
<span class="c">#    &amp;lt;body&amp;gt;</span>
<span class="c">#      &amp;lt;h1&amp;gt;Hello, Kubernetes!&amp;lt;/h1&amp;gt;</span>
<span class="c">#      &amp;lt;p&amp;gt;PRD : Nginx version 1.26.2&amp;lt;/p&amp;gt;</span>
<span class="c">#    &amp;lt;/body&amp;gt;</span>
<span class="c">#    &amp;lt;/html&amp;gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 PRD nginx가 잘 배포되었습니다.&lt;/span&gt;</span>
<span class="nv">$ </span>open http://127.0.0.1:30000

<span class="c"># Argo CD App 삭제</span>
<span class="nv">$ </span>kubectl delete applications <span class="nt">-n</span> argocd prd-nginx
<span class="c"># =&gt; application.argoproj.io &amp;quot;prd-nginx&amp;quot; deleted</span>
</code></pre></div></div>

<h4 id="argocd를-이용한-full-cicd-구성">ArgoCD를 이용한 Full CI/CD 구성</h4>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_36.png" alt="img.png" /></p>

<ul>
  <li>최종적으로 위와 같이 CI/CD 파이프라인을 구성해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">cd </span>ops-deploy
<span class="nv">$ </span><span class="nb">mkdir </span>dev-app

<span class="c"># 도커 계정 정보</span>
<span class="c">#$ DHUSER=&lt;도커 허브 계정&gt;</span>
<span class="nv">$ DHUSER</span><span class="o">=</span>sweetlittlebird

<span class="c"># 버전 정보 </span>
<span class="nv">$ VERSION</span><span class="o">=</span>0.0.1

<span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> dev-app/VERSION <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
</span><span class="nv">$VERSION</span><span class="sh">
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> dev-app/timeserver.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: apps/v1
kind: Deployment
metadata:
  name: timeserver
spec:
  replicas: 2
  selector:
    matchLabels:
      pod: timeserver-pod
  template:
    metadata:
      labels:
        pod: timeserver-pod
    spec:
      containers:
      - name: timeserver-container
        image: docker.io/</span><span class="nv">$DHUSER</span><span class="sh">/dev-app:</span><span class="nv">$VERSION</span><span class="sh">
      imagePullSecrets:
      - name: dockerhub-secret
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> dev-app/service.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: v1
kind: Service
metadata:
  name: timeserver
spec:
  selector:
    pod: timeserver-pod
  ports:
  - port: 80
    targetPort: 80
    protocol: TCP
    nodePort: 30000
  type: NodePort
</span><span class="no">EOF

</span><span class="c">#</span>
<span class="nv">$ </span>git status <span class="o">&amp;&amp;</span> git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"Add dev-app deployment yaml"</span> <span class="o">&amp;&amp;</span> git push <span class="nt">-u</span> origin main
</code></pre></div></div>

<ul>
  <li>ArgoCD에 app 생성</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: timeserver
  namespace: argocd
  finalizers:
  - resources-finalizer.argocd.argoproj.io
spec:
  project: default
  source:
    path: dev-app
    repoURL: http://10.0.4.3:3000/devops/ops-deploy
    targetRevision: HEAD
  syncPolicy:
    automated:
      prune: true
    syncOptions:
    - CreateNamespace=true
  destination:
    namespace: default
    server: https://kubernetes.default.svc
</span><span class="no">EOF
</span><span class="c"># =&gt; application.argoproj.io/timeserver created</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get applications <span class="nt">-n</span> argocd timeserver
<span class="c"># =&gt; NAME         SYNC STATUS   HEALTH STATUS</span>
<span class="c">#    timeserver   Synced        Healthy</span>
<span class="nv">$ </span>kubectl get applications <span class="nt">-n</span> argocd timeserver <span class="nt">-o</span> yaml | kubectl neat
<span class="nv">$ </span>kubectl describe applications <span class="nt">-n</span> argocd timeserver
<span class="c"># =&gt; ...</span>
<span class="c">#    Events:</span>
<span class="c">#      Type    Reason              Age   From                           Message</span>
<span class="c">#      ----    ------              ----  ----                           -------</span>
<span class="c">#      Normal  OperationStarted    23s   argocd-application-controller  Initiated automated sync to 'd64cb772abc1646bd74abbd47b688eeb6d59d65a'</span>
<span class="c">#      Normal  ResourceUpdated     23s   argocd-application-controller  Updated sync status:  -&amp;gt; OutOfSync</span>
<span class="c">#      Normal  ResourceUpdated     23s   argocd-application-controller  Updated health status:  -&amp;gt; Missing</span>
<span class="c">#      Normal  ResourceUpdated     23s   argocd-application-controller  Updated sync status: OutOfSync -&amp;gt; Synced</span>
<span class="c">#      Normal  OperationCompleted  23s   argocd-application-controller  Sync operation to d64cb772abc1646bd74abbd47b688eeb6d59d65a succeeded</span>
<span class="c">#      Normal  ResourceUpdated     23s   argocd-application-controller  Updated health status: Missing -&amp;gt; Progressing</span>
<span class="c">#      Normal  ResourceUpdated     21s   argocd-application-controller  Updated health status: Progressing -&amp;gt; Healthy</span>
<span class="nv">$ </span>kubectl get deploy,rs,pod
<span class="c"># =&gt; NAME                         READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/timeserver   2/2     2            2           42s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                    DESIRED   CURRENT   READY   AGE</span>
<span class="c">#    replicaset.apps/timeserver-549cc9bc89   2         2         2       42s</span>
<span class="c">#    </span>
<span class="c">#    NAME                              READY   STATUS    RESTARTS      AGE</span>
<span class="c">#    pod/curl-pod                      1/1     Running   2 (51m ago)   21h</span>
<span class="c">#    pod/timeserver-549cc9bc89-5bsfm   1/1     Running   0             42s</span>
<span class="c">#    pod/timeserver-549cc9bc89-rwcsz   1/1     Running   0             42s</span>
<span class="nv">$ </span>kubectl get svc,ep timeserver
<span class="c"># =&gt; NAME                 TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE</span>
<span class="c">#    service/timeserver   NodePort   10.96.45.219   &amp;lt;none&amp;gt;        80:30000/TCP   50s</span>
<span class="c">#    </span>
<span class="c">#    NAME                   ENDPOINTS                       AGE</span>
<span class="c">#    endpoints/timeserver   10.244.1.10:80,10.244.2.10:80   50s</span>

<span class="c">#</span>
<span class="nv">$ </span>curl http://127.0.0.1:30000
<span class="c"># =&gt; The time is 12:16:57 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-5bsfm</span>
<span class="nv">$ </span>open http://127.0.0.1:30000
</code></pre></div></div>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_37.png" alt="img.png" /></p>

<h5 id="dev-app-repo-코드-작업">dev-app Repo 코드 작업</h5>

<ul>
  <li>dev-app Repo에 VERSION 업데이트 시 =&gt; ops-deploy Repo 에 dev-app 에 파일에 버전 정보 업데이트 작업 추가
    <ol>
      <li>기존 버전 정보는 VERSION 파일 내에 정보를 가져와서 변수 지정 : <code class="language-plaintext highlighter-rouge">OLDVER=$(cat dev-app/VERSION)</code></li>
      <li>신규 버전 정보는 environment 도커 태그 정보를 가져와서 변수 지정 : <code class="language-plaintext highlighter-rouge">NEWVER=$(echo ${DOCKER_TAG})</code></li>
      <li>이후 sed 로 ops-deploy Repo 에 dev-app/VERSION, timeserver.yaml 2개 파일에 ‘기존 버전’ → ‘신규 버전’으로 값 변경</li>
      <li>이후 ops-deploy Repo 에 git push ⇒ Argo CD app 가 최대 3분 사이에 변경 확인 후 AutoSync 로 신규 버전 업데이트 진행</li>
    </ol>
  </li>
  <li>아래는 dev-app 에 위치한 Jenkinsfile로 젠킨스에 SCM-Pipeline (SCM:git) 으로 사용되고 있는 파일을 수정해서 실습에 사용하겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Jenkinsfile</span>
pipeline <span class="o">{</span>
    agent any
    environment <span class="o">{</span>
        DOCKER_IMAGE <span class="o">=</span> <span class="s1">'sweetlittlebird/dev-app'</span> // Docker 이미지 이름
        GOGSCRD <span class="o">=</span> credentials<span class="o">(</span><span class="s1">'gogs-crd'</span><span class="o">)</span>
    <span class="o">}</span>
    stages <span class="o">{</span>
        stage<span class="o">(</span><span class="s1">'dev-app Checkout'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                 git branch: <span class="s1">'main'</span>,
                 url: <span class="s1">'http://10.0.4.3:3000/devops/dev-app.git'</span>,  // Git에서 코드 체크아웃
                 credentialsId: <span class="s1">'gogs-crd'</span>  // Credentials ID
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'Read VERSION'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                script <span class="o">{</span>
                    // VERSION 파일 읽기
                    def version <span class="o">=</span> readFile<span class="o">(</span><span class="s1">'VERSION'</span><span class="o">)</span>.trim<span class="o">()</span>
                    <span class="nb">echo</span> <span class="s2">"Version found: </span><span class="k">${</span><span class="nv">version</span><span class="k">}</span><span class="s2">"</span>
                    // 환경 변수 설정
                    env.DOCKER_TAG <span class="o">=</span> version
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'Docker Build and Push'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                script <span class="o">{</span>
                    docker.withRegistry<span class="o">(</span><span class="s1">'https://index.docker.io/v1/'</span>, <span class="s1">'dockerhub-crd'</span><span class="o">)</span> <span class="o">{</span>
                        // DOCKER_TAG 사용
                        def appImage <span class="o">=</span> docker.build<span class="o">(</span><span class="s2">"</span><span class="k">${</span><span class="nv">DOCKER_IMAGE</span><span class="k">}</span><span class="s2">:</span><span class="k">${</span><span class="nv">DOCKER_TAG</span><span class="k">}</span><span class="s2">"</span><span class="o">)</span>
                        appImage.push<span class="o">()</span>
                        appImage.push<span class="o">(</span><span class="s2">"latest"</span><span class="o">)</span>
                    <span class="o">}</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'ops-deploy Checkout'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                 git branch: <span class="s1">'main'</span>,
                 url: <span class="s1">'http://10.0.4.3:3000/devops/ops-deploy.git'</span>,  // Git에서 코드 체크아웃
                 credentialsId: <span class="s1">'gogs-crd'</span>  // Credentials ID
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'ops-deploy version update push'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                sh <span class="s1">'''
                OLDVER=$(cat dev-app/VERSION)
                NEWVER=$(echo ${DOCKER_TAG})
                sed -i -e "s/$OLDVER/$NEWVER/" dev-app/timeserver.yaml
                sed -i -e "s/$OLDVER/$NEWVER/" dev-app/VERSION
                git add ./dev-app
                git config user.name "devops"
                git config user.email "a@a.com"
                git commit -m "version update ${DOCKER_TAG}"
                git push http://${GOGSCRD_USR}:${GOGSCRD_PSW}@10.0.4.3:3000/devops/ops-deploy.git
                '''</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
    post <span class="o">{</span>
        success <span class="o">{</span>
            <span class="nb">echo</span> <span class="s2">"Docker image </span><span class="k">${</span><span class="nv">DOCKER_IMAGE</span><span class="k">}</span><span class="s2">:</span><span class="k">${</span><span class="nv">DOCKER_TAG</span><span class="k">}</span><span class="s2"> has been built and pushed successfully!"</span>
        <span class="o">}</span>
        failure <span class="o">{</span>
            <span class="nb">echo</span> <span class="s2">"Pipeline failed. Please check the logs."</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<ul>
  <li>아래는 dev-app (Repo) 에서 VERSION과 server.py 수정 후 git push를 진행합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># VERSION 파일 수정 : 0.0.4</span>
<span class="c"># server.py 파일 수정 : 0.0.4</span>

<span class="c"># git push : VERSION, server.py, Jenkinsfile</span>
git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"VERSION </span><span class="si">$(</span><span class="nb">cat </span>VERSION<span class="si">)</span><span class="s2"> Changed"</span> <span class="o">&amp;&amp;</span> git push <span class="nt">-u</span> origin main
</code></pre></div></div>
<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_38.png" alt="img.png" /></p>

<ul>
  <li>ArgoCD 웹에서 동작을 확인해보겠습니다.</li>
  <li>Jenkins Pipeline이 실행되면서 dev-app Repo의 버전 정보가 변경되고, ops-deploy Repo의 dev-app/VERSION 파일과 timeserver.yaml 파일이 
변경되어 ArgoCD가 변경사항을 감지하고 자동으로 배포를 진행합니다.</li>
  <li>REFRESH 버튼을 클릭하거나 ArgoCD WebHook 설정시 즉시 반영이 가능합니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_39.png" alt="img.png" /></p>

<ul>
  <li>dev-app Repo에서 몇번 더 버전을 업데이트 해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># VERSION 파일 수정 : 0.0.5</span>
<span class="c"># server.py 파일 수정 : 0.0.5</span>

<span class="c"># git push : VERSION, server.py, Jenkinsfile</span>
<span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"VERSION </span><span class="si">$(</span><span class="nb">cat </span>VERSION<span class="si">)</span><span class="s2"> Changed"</span> <span class="o">&amp;&amp;</span> git push <span class="nt">-u</span> origin main
<span class="c"># =&gt; [main 881d051] VERSION 0.0.5 Changed</span>
<span class="c">#     2 files changed, 2 insertions(+), 2 deletions(-)</span>
<span class="c">#    Enumerating objects: 7, done.</span>
<span class="c">#    Counting objects: 100% (7/7), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (3/3), done.</span>
<span class="c">#    Writing objects: 100% (4/4), 329 bytes | 329.00 KiB/s, done.</span>
<span class="c">#    Total 4 (delta 2), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To http://10.0.4.3:3000/devops/dev-app.git</span>
<span class="c">#       1d4cec2..881d051  main -&amp;gt; main</span>
<span class="c">#    branch 'main' set up to track 'origin/main'.</span>

<span class="c"># 배포 결과 확인</span>
<span class="nv">$ </span>curl http://127.0.0.1:30000
<span class="c"># =&gt; The time is 12:34:14 PM, VERSION 0.0.5</span>
<span class="c">#    Server hostname: timeserver-7546694df7-wds9r</span>
</code></pre></div></div>

<ul>
  <li>CI/CD가 잘 동작하여 최신버전이 배포됨을 확인 할 수 있습니다.</li>
</ul>

<hr />

<h3 id="argo-rollout--k8skind">Argo Rollout + K8S(Kind)</h3>

<ul>
  <li>Argo는 ArgoCD 뿐만 아니라 다양한 프로젝트를 제공하고 있으며, 그중의 하나가 Argo Rollout입니다.</li>
  <li>Argo Rollout은 Kubernetes의 Deployment, StatefulSet, DaemonSet, Job, CronJob 등의 리소스를 대체하여 롤아웃을 관리하는 컨트롤러입니다.</li>
  <li>다음과 같은 기능을 제공합니다. <a href="https://argoproj.github.io/argo-rollouts/concepts/">문서</a>
    <ul>
      <li>Blue-Green 업데이트 전략
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_40.png" alt="img.png" class="image-center" /></li>
      <li>Canary 업데이트 전략
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_41.png" alt="img_1.png" class="image-center" /></li>
      <li>세밀하고 가중치가 부여된 트래픽 전환</li>
      <li>자동화된 롤백 및 프로모션</li>
      <li>수동 판단</li>
      <li>사용자 정의 가능한 메트릭 쿼리 및 비즈니스 KPI 분석</li>
      <li>인그레스 컨트롤러 통합: NGINX, ALB, Apache APISIX</li>
      <li>서비스 메쉬 통합: Istio, Linkerd, SMI</li>
      <li>여러 제공자의 동시 사용: SMI + NGINX, Istio + ALB 등</li>
      <li>메트릭 제공자 통합: Prometheus, Wavefront, Kayenta, Web, Kubernetes Jobs, Datadog, New Relic, Graphite, InfluxDB</li>
    </ul>
  </li>
</ul>

<h5 id="argo-rollout-설치-및-실습">Argo Rollout 설치 및 실습</h5>

<ul>
  <li>Argo Rollout을 설치해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 네임스페이스 생성 및 파라미터 파일 작성</span>
<span class="nv">$ </span>kubectl create ns argo-rollouts
<span class="c"># =&gt; namespace/argo-rollouts created</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh"> &gt; argorollouts-values.yaml
dashboard:
  enabled: true
  service:
    type: NodePort
    nodePort: 30003
</span><span class="no">EOT

</span><span class="c"># 설치</span>
<span class="nv">$ </span>helm <span class="nb">install </span>argo-rollouts argo/argo-rollouts <span class="nt">--version</span> 2.35.1 <span class="nt">-f</span> argorollouts-values.yaml <span class="nt">--namespace</span> argo-rollouts
<span class="c"># =&gt; NAME: argo-rollouts</span>
<span class="c">#    LAST DEPLOYED: Sun Oct 01 23:05:23 2024</span>
<span class="c">#    NAMESPACE: argo-rollouts</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 1</span>
<span class="c">#    TEST SUITE: None</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get all <span class="nt">-n</span> argo-rollouts
<span class="c"># =&gt; NAME                                           READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/argo-rollouts-86469b5878-j6p5k             1/1     Running   0          42s</span>
<span class="c">#    pod/argo-rollouts-86469b5878-vlr6z             1/1     Running   0          43s</span>
<span class="c">#    pod/argo-rollouts-dashboard-7c88d965fc-l6lml   1/1     Running   0          43s</span>
<span class="c">#    </span>
<span class="c">#    NAME                              TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span>
<span class="c">#    service/argo-rollouts-dashboard   NodePort   10.96.195.148   &amp;lt;none&amp;gt;        3100:30003/TCP   43s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                      READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/argo-rollouts             2/2     2            2           43s</span>
<span class="c">#    deployment.apps/argo-rollouts-dashboard   1/1     1            1           43s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                                 DESIRED   CURRENT   READY   AGE</span>
<span class="c">#    replicaset.apps/argo-rollouts-86469b5878             2         2         2       43s</span>
<span class="c">#    replicaset.apps/argo-rollouts-dashboard-7c88d965fc   1         1         1       43s</span>
<span class="nv">$ </span>kubectl get crds
<span class="c"># =&gt; NAME                                   CREATED AT</span>
<span class="c">#    analysisruns.argoproj.io               2024-10-01T14:05:24Z</span>
<span class="c">#    analysistemplates.argoproj.io          2024-10-01T14:05:24Z</span>
<span class="c">#    applications.argoproj.io               2024-10-01T07:54:01Z</span>
<span class="c">#    applicationsets.argoproj.io            2024-10-01T07:54:01Z</span>
<span class="c">#    appprojects.argoproj.io                2024-10-01T07:54:01Z</span>
<span class="c">#    clusteranalysistemplates.argoproj.io   2024-10-01T14:05:24Z</span>
<span class="c">#    experiments.argoproj.io                2024-10-01T14:05:24Z</span>
<span class="c">#    rollouts.argoproj.io                   2024-10-01T14:05:24Z</span>

<span class="c"># Argo rollouts 대시보드 접속 주소 확인</span>
<span class="nv">$ </span>open <span class="s2">"http://127.0.0.1:30003"</span>
</code></pre></div></div>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_42.png" alt="img.png" /></p>

<ul>
  <li>Argo Rollout을 이용해서 배포를 진행해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Run the following command to deploy the initial Rollout and Service:</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/basic/rollout.yaml
<span class="c"># =&gt; rollout.argoproj.io/rollouts-demo created</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/basic/service.yaml
<span class="c"># =&gt; service/rollouts-demo created</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get rollout
<span class="c"># =&gt; NAME            DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    rollouts-demo   5         5         5            5           16s</span>
<span class="nv">$ </span>kubectl describe rollout
<span class="c"># =&gt; ...</span>
<span class="c">#    Events:</span>
<span class="c">#      Type    Reason                  Age   From                 Message</span>
<span class="c">#      ----    ------                  ----  ----                 -------</span>
<span class="c">#      Normal  RolloutAddedToInformer  25s   rollouts-controller  Rollout resource added to informer: default/rollouts-demo</span>
<span class="c">#      Normal  RolloutNotCompleted     25s   rollouts-controller  Rollout not completed, started update to revision 1 (687d76d795)</span>
<span class="c">#      Normal  RolloutUpdated          25s   rollouts-controller  Rollout updated to revision 1</span>
<span class="c">#      Normal  NewReplicaSetCreated    25s   rollouts-controller  Created ReplicaSet rollouts-demo-687d76d795 (revision 1)</span>
<span class="c">#      Normal  ScalingReplicaSet       25s   rollouts-controller  Scaled up ReplicaSet rollouts-demo-687d76d795 (revision 1) from 0 to 5</span>
<span class="c">#      Normal  RolloutCompleted        25s   rollouts-controller  Rollout completed update to revision 1 (687d76d795): Initial deploy</span>

<span class="nv">$ </span>kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>rollouts-demo
<span class="c"># =&gt; NAME                             READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    rollouts-demo-687d76d795-7pbl9   1/1     Running   0          46s</span>
<span class="c">#    rollouts-demo-687d76d795-bnl2c   1/1     Running   0          46s</span>
<span class="c">#    rollouts-demo-687d76d795-ggzsq   1/1     Running   0          46s</span>
<span class="c">#    rollouts-demo-687d76d795-vtnlj   1/1     Running   0          46s</span>
<span class="c">#    rollouts-demo-687d76d795-xmk2x   1/1     Running   0          46s</span>
<span class="nv">$ </span>kubectl get svc,ep rollouts-demo
<span class="c"># =&gt; NAME                    TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE</span>
<span class="c">#    service/rollouts-demo   ClusterIP   10.96.237.173   &amp;lt;none&amp;gt;        80/TCP    47s</span>
<span class="c">#    </span>
<span class="c">#    NAME                      ENDPOINTS                                                        AGE</span>
<span class="c">#    endpoints/rollouts-demo   10.244.1.14:8080,10.244.1.15:8080,10.244.1.16:8080 + 2 more...   47s</span>
<span class="nv">$ </span>kubectl get rollouts rollouts-demo <span class="nt">-o</span> yaml | kubectl neat
<span class="c"># =&gt; ...</span>
<span class="c">#    spec:</span>
<span class="c">#      replicas: 5</span>
<span class="c">#      revisionHistoryLimit: 2</span>
<span class="c">#      selector:</span>
<span class="c">#        matchLabels:</span>
<span class="c">#          app: rollouts-demo</span>
<span class="c">#      strategy:</span>
<span class="c">#        canary:</span>
<span class="c">#          steps:</span>
<span class="c">#          - setWeight: 20</span>
<span class="c">#          - setWeight: 40</span>
<span class="c">#          - pause:</span>
<span class="c">#              duration: 10</span>
<span class="c">#          - setWeight: 60</span>
<span class="c">#          - pause:</span>
<span class="c">#              duration: 10</span>
<span class="c">#          - setWeight: 80</span>
<span class="c">#          - pause:</span>
<span class="c">#              duration: 10</span>
<span class="c">#      ...</span>
</code></pre></div></div>

<ul>
  <li>
    <p>우측상단의 NAMESPACE를 default로 변경하고 rollout-demo를 클릭하면 다음의 rollout 화면이 나타납니다.
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_43.png" alt="img.png" /></p>
  </li>
  <li>
    <p>rollouts-demo:blue를 rollouts-demo:yellow로 변경해서 배포해보겠습니다.</p>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl edit rollouts rollouts-demo
...
     - image: argoproj/rollouts-demo:yellow
...
<span class="c"># =&gt; rollout.argoproj.io/rollouts-demo edited</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 위와 같이 rollouts-demo/blue를 rollouts-demo/yellow로 변경합니다.&lt;/span&gt;</span>

<span class="c"># 파드 label 정보 확인</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>rollouts-demo <span class="nt">-owide</span> <span class="nt">--show-labels</span>
</code></pre></div></div>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_44.png" alt="img.png" /></p>

<ul>
  <li>위와같이 yellow가 20% 만큼 canary 배포되고 정자 상태에 있습니다.</li>
  <li>Promote 버튼을 클릭하여 보겠습니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_45.png" alt="img.png" /></p>

<ul>
  <li>정해진 rollout rule에 따라 10초씩 대기 후 20%씩 canary 배포 비율을 높여서 최종적으로 전체가 yellow로 배포됩니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_46.png" alt="img.png" /></p>

<h2 id="마치며">마치며</h2>

<p>이번주에는 생각보다 실습량이 많아서 시간이 많이 걸렸습니다. 
하지만, K8S에 CI/CD 배포하는것과 ArgoCD와 Argo Rollout을 이용한 CI/CD 파이프라인 구성을 경험해볼 수 있어서 좋았습니다.
특히 ArgoCD와 Argo Rollout은 웹 UI는 조금 날것 느낌이 났지만,
기능이나 컨셉 자체는 좋은것 같고, 
선언적인 방식이나 CLI를 통해서 자동화할 수 있으니 다양하게 활용할 수 있을것 같습니다.</p>

<p>스터디 컨셉이 CI/CD 맛보기여서 가벼운 마음으로 시작했는데
실제 스터디는 가볍지 않았던것 같습니다.<br />
이 맛에 스터디합니다. 
:sweat_smile: 맛보기가 이 정도이니 본편은 얼마나 깊고 넓을지 기대가 됩니다.</p>

<p>연말에 어수선한 가운데 다들 스터디 참여하신 분들 모두 고생 많으셨고, 
진행해주신 가시다님께 감사드립니다.</p>

<p>긴 글 읽어주셔서 감사합니다. 
한 해 마무리 잘 하시고, 건강한 모습으로 내년에 또 뵙기를 기원합니다. :bow::bowing_woman:</p>]]></content><author><name></name></author><category term="kans" /><category term="cicd," /><category term="jenkins," /><category term="git," /><category term="linux" /><summary type="html"><![CDATA[이번 주에는 ArgoCD와 Jenkins를 사용하여 Kubernetes로의 배포를 하는 CI/CD를 구성해보겠습니다.]]></summary></entry><entry><title type="html">[CI/CD] GitHub Actions CI/CD</title><link href="https://sweetlittlebird.github.io/posts/2024-12-14-CICD-Lite-Week2/" rel="alternate" type="text/html" title="[CI/CD] GitHub Actions CI/CD" /><published>2024-12-14T23:01:18+09:00</published><updated>2024-12-14T23:01:18+09:00</updated><id>https://sweetlittlebird.github.io/posts/CICD%20Lite%20-%20Week2</id><content type="html" xml:base="https://sweetlittlebird.github.io/posts/2024-12-14-CICD-Lite-Week2/"><![CDATA[<h2 id="들어가며">들어가며</h2>

<p>이번 주에는 GitHub Actions를 이용한 CI/CD에 대해 알아보겠습니다.</p>

<h2 id="github-actions-cicd">GitHub Actions CI/CD</h2>

<h3 id="github-actions란">GitHub Actions란?</h3>

<ul>
  <li><a href="https://docs.github.com/ko/actions">공식문서</a> -
<a href="https://docs.github.com/ko/actions/about-github-actions/understanding-github-actions">개요</a> -
<a href="https://docs.github.com/ko/billing/managing-billing-for-your-products/managing-billing-for-github-actions">요금</a> -
<a href="https://blog.outsider.ne.kr/1744">GitHub Actions의 다양한 기능 활용하기</a></li>
  <li>GitHub Actions는 GitHub에서 호스팅되는 <strong>지속적 통합(CI) 및 지속적 배포(CD)</strong> 서비스입니다.</li>
  <li>푸시나 풀 리퀘스트와 같은 이벤트에 반응하여 <strong>사용자 지정된 워크플로</strong>를 실행할 수 있습니다. 이를 통해 CI/CD를 GitHub Actions로 구현할 수 있습니다.</li>
  <li>GitHub Actions는 <strong>GitHub Marketplace</strong>에서 기존에 작성된 워크플로를 가져와 사용할 수 있습니다. Slack 알림, AWS 배포 등 다양한 워크플로가 있습니다.</li>
  <li>GitHub Actions는 <strong>YAML</strong> 파일을 사용하여 워크플로를 정의합니다. 워크플로는 <strong>job</strong>으로 구성되며, 각 job은 <strong>step</strong>으로 구성됩니다.
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_1.png" alt="img.png" /></li>
  <li>
    <p>GitHub Actions의 요금은 아래와 같으며 500MB 스토리지와 매월 2000분을 무료로 사용할 수 있습니다.</p>

    <table>
      <thead>
        <tr>
          <th>계획</th>
          <th>스토리지</th>
          <th>분(월)</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>GitHub Free</td>
          <td>500 MB</td>
          <td>2,000</td>
        </tr>
        <tr>
          <td>GitHub Pro</td>
          <td>1GB</td>
          <td>3,000</td>
        </tr>
        <tr>
          <td>조직용 GitHub Free</td>
          <td>500 MB</td>
          <td>2,000</td>
        </tr>
        <tr>
          <td>GitHub Team</td>
          <td>2GB</td>
          <td>3,000</td>
        </tr>
        <tr>
          <td>GitHub Enterprise Cloud</td>
          <td>50GB</td>
          <td>50,000</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<h3 id="첫-github-actions-워크플로-만들기">첫 GitHub Actions 워크플로 만들기</h3>

<ul>
  <li>GitHub Actions는 repository 내의 <code class="language-plaintext highlighter-rouge">.github/workflows</code> 디렉터리에 저장된 워크플로우 정의 파일을 읽어서 실행합니다.</li>
  <li>간단한 GitHub Repository를 만들고 그 안에 워크플로우를 만들어서 테스트 해보겠습니다.
    <ol>
      <li>새로운 Repository 만들기 <a href="https://www.github.com/new">링크</a>
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_2.png" alt="img.png" /></li>
      <li>git clone으로 repository를 로컬로 가져옵니다.
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>git clone https://github.com/sweetlittlebird/2024-cicd-w2-1.git
<span class="nv">$ </span><span class="nb">cd </span>2024-cicd-w2-1
</code></pre></div>        </div>
      </li>
      <li><code class="language-plaintext highlighter-rouge">.github/workflows</code> 디렉터리를 만들고 그 안에 <code class="language-plaintext highlighter-rouge">main.yml</code> 파일을 만듭니다. (파일명은 자유롭게 지정 가능합니다.)
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">mkdir</span> <span class="nt">-p</span> .github/workflows
<span class="nv">$ </span><span class="nb">touch</span> .github/workflows/main.yml
</code></pre></div>        </div>
      </li>
      <li><code class="language-plaintext highlighter-rouge">main.yml</code> 파일에 워크플로우 작성합니다.
        <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># .github/workflows/main.yml</span>
<span class="na">name</span><span class="pi">:</span> <span class="s">Hello World</span>                 <span class="c1"># Github 웹 사이드바 이름</span>
<span class="na">on</span><span class="pi">:</span>
  <span class="na">workflow_dispatch</span><span class="pi">:</span>              <span class="c1"># 수동으로 실행할 수 있는 워크플로우</span>
  <span class="na">push</span><span class="pi">:</span>                           <span class="c1"># push 이벤트 발생 시 실행</span>
     
<span class="na">jobs</span><span class="pi">:</span>
  <span class="na">build</span><span class="pi">:</span>                          <span class="c1"># Jobs 이름</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>        <span class="c1"># 실행 환경</span>
    <span class="na">steps</span><span class="pi">:</span>                        <span class="c1"># Job 내부의 Step 들 </span>
      <span class="pi">-</span> <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/checkout@v3</span> <span class="c1"># actions/checkout 레포지토리의 v3 버전의 워크플로우 사용</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Hello World</span>         <span class="c1"># Step 이름</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">echo "Hello World"</span>     
</code></pre></div>        </div>
      </li>
      <li>GitHub에 push하여 워크플로우를 실행합니다.
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>git add <span class="nb">.</span>
<span class="nv">$ </span>git commit <span class="nt">-m</span> <span class="s2">"GitHub Actions 추가"</span>
<span class="nv">$ </span>git push origin main
</code></pre></div>        </div>
      </li>
      <li>GitHub Repository에서 Actions 탭을 클릭하여 워크플로우를 확인합니다. <a href="https://github.com/sweetlittlebird/2024-cicd-w2-1/actions">링크</a>
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_3.png" alt="img.png" />
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_4.png" alt="img.png" /></li>
    </ol>
  </li>
  <li>워크플로우가 잘 실행되어서 <code class="language-plaintext highlighter-rouge">Hello World</code>가 잘 출력되었습니다.</li>
</ul>

<h4 id="워크플로우를-수동으로-트리거-하기">워크플로우를 수동으로 트리거 하기</h4>

<ul>
  <li>앞서 작성한 워크플로우 처럼 on: workflow_dispatch를 사용하면 워크플로우를 수동으로 실행할 수 있습니다.</li>
  <li>GitHub Repository에서 Actions 탭을 클릭하고 <code class="language-plaintext highlighter-rouge">Run workflow</code> 버튼을 클릭하여 워크플로우를 수동으로 실행할 수 있습니다.
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_5.png" alt="img.png" /></li>
</ul>

<h3 id="직접-개발-후-실행">직접 개발 후 실행</h3>

<ul>
  <li>이번에는 가상머신을 만들고 그 안에서 간단한 웹 서버를 만들어서 GitHub Actions로 배포해보겠습니다.</li>
  <li>가상머신은 Vagrant를 사용하여 만들어 보겠습니다.
    <div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Vagrantfile</span>
<span class="no">Vagrant</span><span class="p">.</span><span class="nf">configure</span><span class="p">(</span><span class="s2">"2"</span><span class="p">)</span> <span class="k">do</span> <span class="o">|</span><span class="n">config</span><span class="o">|</span>
  <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="s2">"ubuntu/jammy64"</span>
  <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="mi">20022</span>
  <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">80</span><span class="p">,</span> <span class="ss">host: </span><span class="mi">20080</span>
  <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">inline: </span><span class="o">&lt;&lt;-</span><span class="no">SHELL</span><span class="sh">
    sudo apt-get update
    sudo apt install -y tree 
</span><span class="no">  SHELL</span>
<span class="k">end</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>위와 같이 Vagrantfile을 작성하고 <code class="language-plaintext highlighter-rouge">vagrant up</code>으로 가상머신을 만들어 줍니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>vagrant up
  
<span class="nv">$ </span>vargrant ssh 
<span class="c"># --------</span>
  
<span class="nv">$ </span>python3 <span class="nt">-V</span>
<span class="c"># =&gt; Python 3.10.12</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> server.py <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
from http.server import ThreadingHTTPServer, BaseHTTPRequestHandler
from datetime import datetime
  
class RequestHandler(BaseHTTPRequestHandler):
    def do_GET(self):
        self.send_response(200)
        self.send_header('Content-type', 'text/plain')
        self.end_headers()
        now = datetime.now()
        response_string = now.strftime("The time is %-I:%M:%S %p, CloudNeta Study.</span><span class="se">\n</span><span class="sh">")
        self.wfile.write(bytes(response_string, "utf-8")) 
  
def startServer():
    try:
        server = ThreadingHTTPServer(('', 80), RequestHandler)
        print("Listening on " + ":".join(map(str, server.server_address)))
        server.serve_forever()
    except KeyboardInterrupt:
        server.shutdown()
  
if __name__== "__main__":
    startServer()
</span><span class="no">EOF
  
</span><span class="nv">$ </span><span class="nb">sudo </span>python3 server.py
  
<span class="c"># 아래 확인 후</span>
<span class="c"># CTRL+C 로 실행 취소</span>
  
<span class="c"># (신규터미널) 서버1 SSH 접속</span>
<span class="nv">$ </span>curl localhost
<span class="c"># =&gt; The time is 2:50:56 PM, CloudNeta Study.</span>
<span class="nv">$ </span><span class="nb">sudo </span>ss <span class="nt">-tnlp</span>
<span class="c"># =&gt; State  Recv-Q Send-Q Local Address:Port Peer Address:PortProcess</span>
<span class="c">#    LISTEN 0      5            0.0.0.0:80        0.0.0.0:*    users:((&amp;quot;python3&amp;quot;,pid=2299,fd=3))</span>
<span class="c">#    LISTEN 0      128          0.0.0.0:22        0.0.0.0:*    users:((&amp;quot;sshd&amp;quot;,pid=1030,fd=3))</span>
  
<span class="c"># --------</span>
</code></pre></div>    </div>
  </li>
  <li>Git 작업
    <ul>
      <li>토큰 발급해두기 : scope (repo, workflow) 필요합니다. 
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_6.png" alt="img.png" /></li>
      <li>Private Repo 신규 생성
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_7.png" alt="img.png" /></li>
      <li>가상머신에서 Git 작업
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ GITUSER</span><span class="o">=</span><span class="s2">"sweetlittlebird"</span>
<span class="nv">$ </span>git config <span class="nt">--global</span> user.name <span class="nv">$GITUSER</span>
<span class="nv">$ </span>git config <span class="nt">--global</span> user.email <span class="s2">"sweetlittlebird@sweetlittlebird.com"</span>
<span class="nv">$ </span>git clone https://github.com/<span class="nv">$GITUSER</span>/2024-cicd-w2-2.git
<span class="c"># =&gt; Cloning into '2024-cicd-w2-2'...</span>
<span class="c">#    Username for 'https://github.com': git</span>
<span class="c">#    Password for 'https://git@github.com':</span>
<span class="c">#    remote: Enumerating objects: 3, done.</span>
<span class="c">#    remote: Counting objects: 100% (3/3), done.</span>
<span class="c">#    remote: Compressing objects: 100% (2/2), done.</span>
<span class="c">#    remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)</span>
<span class="c">#    Receiving objects: 100% (3/3), done.</span>
<span class="nv">$ </span><span class="nb">cp </span>server.py 2024-cicd-w2-2/
<span class="nv">$ </span><span class="nb">cd </span>2024-cicd-w2-2
    
<span class="nv">$ </span>git status
<span class="c"># =&gt; On branch main</span>
<span class="c">#    Your branch is up to date with 'origin/main'.</span>
<span class="c">#    </span>
<span class="c">#    Untracked files:</span>
<span class="c">#      (use &amp;quot;git add &amp;lt;file&amp;gt;...&amp;quot; to include in what will be committed)</span>
<span class="c">#            server.py</span>
<span class="c">#    </span>
<span class="c">#    nothing added to commit but untracked files present (use &amp;quot;git add&amp;quot; to track)</span>
<span class="nv">$ </span>git add <span class="nb">.</span>
<span class="nv">$ </span>git commit <span class="nt">-m</span> <span class="s2">"Initial commit"</span>
<span class="c"># =&gt; [main 30500ca] Initial commit</span>
<span class="c">#     1 file changed, 22 insertions(+)</span>
<span class="c">#     create mode 100644 server.py</span>
<span class="nv">$ </span>git push origin main 
<span class="c"># =&gt; Username for 'https://github.com': git</span>
<span class="c">#    Password for 'https://git@github.com': *** # &lt;span style="color: green;"&gt;👉 ghp로 시작하는 발급해둔 토큰을 사용합니다.&lt;/span&gt; </span>
<span class="c">#    Enumerating objects: 4, done.</span>
<span class="c">#    Counting objects: 100% (4/4), done.</span>
<span class="c">#    Delta compression using up to 2 threads</span>
<span class="c">#    Compressing objects: 100% (3/3), done.</span>
<span class="c">#    Writing objects: 100% (3/3), 665 bytes | 332.00 KiB/s, done.</span>
<span class="c">#    Total 3 (delta 0), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To https://github.com/sweetlittlebird/2024-cicd-w2-2.git</span>
<span class="c">#       ceaed76..30500ca  main -&amp;gt; main</span>
</code></pre></div>        </div>
        <p><img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_8.png" alt="img.png" /></p>
      </li>
    </ul>
  </li>
  <li>서버 실행
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">nohup sudo </span>python3 server.py <span class="o">&gt;</span> server.log 2&gt;&amp;1 &amp;
<span class="nv">$ </span><span class="nb">cat </span>server.log
<span class="c"># =&gt; nohup: ignoring input</span>
<span class="nv">$ </span>curl localhost
<span class="c"># =&gt; The time is 3:13:00 PM, CloudNeta Study.</span>
<span class="nv">$ </span><span class="nb">cat </span>server.log
<span class="c"># =&gt; nohup: ignoring input</span>
<span class="c">#    127.0.0.1 - - [14/Dec/2024 15:13:00] &amp;quot;GET / HTTP/1.1&amp;quot; 200 -</span>
  
<span class="c">#</span>
<span class="nv">$ </span><span class="nb">grep </span>log .gitignore
<span class="c"># =&gt; # Installer logs</span>
<span class="c">#    pip-log.txt</span>
<span class="c">#    *.log          # &lt;span style="color: green;"&gt;👉 로그 파일은 git에서 무시하도록 되어있습니다.&lt;/span&gt;</span>
  
<span class="c">#</span>
<span class="nv">$ </span>git add <span class="nb">.</span>
<span class="nv">$ </span>git commit <span class="nt">-m</span> <span class="s2">"add log file"</span>
<span class="c"># =&gt; nothing to commit, working tree clean  &lt;span style="color: green;"&gt;👉 로그 파일은 git에서 무시하도록 되어있어서 git add . 의 영향을 받지 않습니다.&lt;/span&gt;</span>
<span class="nv">$ </span>git status
<span class="c"># =&gt; nothing to commit, working tree clean</span>
</code></pre></div>    </div>
  </li>
  <li>코드 수정 후 재실행
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/CloudNeta/CICD/g"</span> server.py
  
<span class="c"># 프로세스 종료</span>
<span class="nv">$ </span><span class="nb">sudo </span>ss <span class="nt">-tnlp</span>
<span class="c"># =&gt; State  Recv-Q Send-Q Local Address:Port Peer Address:PortProcess</span>
<span class="c">#    LISTEN 0      128          0.0.0.0:22        0.0.0.0:*    users:(("sshd",pid=883,fd=3))</span>
<span class="c">#    LISTEN 0      5            0.0.0.0:80        0.0.0.0:*    users:((&amp;quot;python3&amp;quot;,pid=2287,fd=3))</span>
<span class="nv">$ </span><span class="nb">sudo </span>fuser <span class="nt">-k</span> <span class="nt">-n</span> tcp 80                 <span class="c"># &lt;span style="color: green;"&gt;👉 80번 포트를 사용하는 프로세스를 종료합니다.&lt;/span&gt;</span>
<span class="c"># =&gt; 80/tcp:               2287</span>
<span class="c">#    [1]+  Killed                  nohup sudo python3 server.py &amp;gt; server.log 2&amp;gt;&amp;amp;1  (wd: ~)</span>
<span class="c">#    (wd now: ~/2024-cicd-w2-2)</span>
<span class="nv">$ </span><span class="nb">sudo </span>ss <span class="nt">-tnlp</span>
<span class="c"># =&gt; State  Recv-Q Send-Q Local Address:Port Peer Address:PortProcess</span>
<span class="c">#    LISTEN 0      128          0.0.0.0:22        0.0.0.0:*    users:(("sshd",pid=883,fd=3))</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 80 포트를 사용하던 python3가 종료되어서 없어졌습니다.&lt;/span&gt;</span>
  
<span class="c"># 재실행</span>
<span class="nv">$ </span><span class="nb">nohup sudo </span>python3 server.py <span class="o">&gt;</span> server.log 2&gt;&amp;1 &amp;
<span class="nv">$ </span>curl localhost
<span class="c"># =&gt; The time is 3:24:23 PM, CICD Study.  # &lt;span style="color: green;"&gt;👉 수정사항이 반영되었습니다.&lt;/span&gt;</span>
</code></pre></div>    </div>
  </li>
  <li>코드 push
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 매번 사용자 인증을 요구하지 않도록 인증 정보를 저장하도록 설정하겠습니다.</span>
<span class="nv">$ </span>git config <span class="nt">--global</span> credential.helper store
  
<span class="c">#</span>
<span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"version update"</span> <span class="o">&amp;&amp;</span> git push origin main
<span class="c"># =&gt; [main 11f7a3d] version update</span>
<span class="c">#     1 file changed, 1 insertion(+), 1 deletion(-)</span>
<span class="c">#    Username for 'https://github.com': git</span>
<span class="c">#    Password for 'https://git@github.com':</span>
<span class="c">#    Enumerating objects: 5, done.</span>
<span class="c">#    Counting objects: 100% (5/5), done.</span>
<span class="c">#    Delta compression using up to 2 threads</span>
<span class="c">#    Compressing objects: 100% (3/3), done.</span>
<span class="c">#    Writing objects: 100% (3/3), 312 bytes | 156.00 KiB/s, done.</span>
<span class="c">#    Total 3 (delta 1), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    remote: Resolving deltas: 100% (1/1), completed with 1 local object.</span>
<span class="c">#    To https://github.com/sweetlittlebird/2024-cicd-w2-2.git</span>
<span class="c">#       30500ca..11f7a3d  main -&amp;gt; main</span>
  
<span class="nv">$ </span>git push origin main
<span class="c"># =&gt; Everything up-to-date</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 인증정보가 저장되어서 별도의 인증과정 없이 사용할 수 있습니다.&lt;/span&gt;</span>
</code></pre></div>    </div>
  </li>
</ul>

<h3 id="github-actions로-배포하기">GitHub Actions로 배포하기</h3>

<ul>
  <li>개인 PC에서 작업 후 Github에 push하면 GitHub Actions를 통해 VM에 배포가 되도록 CI/CD를 구성해보겠습니다.</li>
</ul>

<h5 id="ssh-키-생성">SSH 키 생성</h5>

<ul>
  <li>먼저 가상머신에 ssh 접속을 위해 ssh key를 생성하고 GitHub에 등록합니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cd</span> ~/.ssh
<span class="nv">$ </span>ssh-keygen <span class="nt">-t</span> ed25519
<span class="c"># =&gt; Enter file in which to save the key (/home/vagrant/.ssh/id_ed25519):</span>
<span class="c">#    Enter passphrase (empty for no passphrase): # &lt;span style="color: green;"&gt;👉 비밀번호 없이 엔터만 입력합니다.&lt;/span&gt;</span>
<span class="c">#    Enter same passphrase again:                # &lt;span style="color: green;"&gt;👉 엔터만 입력합니다.&lt;/span&gt;</span>
  
<span class="c"># 생성된 공개키를 로그인 허용 키 목록에 추가합니다</span>
<span class="nv">$ </span><span class="nb">cat </span>id_ed25519.pub  <span class="o">&gt;&gt;</span> authorized_keys     
<span class="nv">$ </span><span class="nb">cat </span>id_ed25519   <span class="c"># &lt;span style="color: green;"&gt;👉 개인키를 복사합니다. 복사한 키는 github secret에 추가할 것입니다.&lt;/span&gt;</span>
</code></pre></div>    </div>
  </li>
</ul>

<h5 id="github에-ssh-키와-가상머신-외부-ip-등록">GitHub에 SSH 키와 가상머신 외부 IP 등록</h5>

<ul>
  <li>GitHub의 Repository에서 <code class="language-plaintext highlighter-rouge">Settings</code> -&gt; <code class="language-plaintext highlighter-rouge">Secrets and variables</code> -&gt; <code class="language-plaintext highlighter-rouge">Actions</code> -&gt; <code class="language-plaintext highlighter-rouge">New repository secret</code>를 클릭하여 아래와 같이 추가합니다.
    <ul>
      <li><code class="language-plaintext highlighter-rouge">SSH_PRIVATE_KEY</code> : 앞에서 복사한 개인키를 추가합니다. 
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_9.png" alt="img.png" /></li>
      <li><code class="language-plaintext highlighter-rouge">EC2_PIP</code> : 가상머신의 외부 IP를 추가합니다. (인터넷에서 접속가능한 IP여야 합니다.)
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_10.png" alt="img.png" /></li>
    </ul>
  </li>
</ul>

<h5 id="내-pc에서-코드-작업">내 PC에서 코드 작업</h5>

<ul>
  <li>
    <p>내 PC에서 작업을 합니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>git clone https://github.com/sweetlittlebird/2024-cicd-w2-2.git
<span class="c"># =&gt; Cloning into '2024-cicd-w2-2'...</span>
<span class="c">#    remote: Enumerating objects: 9, done.</span>
<span class="c">#    remote: Counting objects: 100% (9/9), done.</span>
<span class="c">#    remote: Compressing objects: 100% (7/7), done.</span>
<span class="c">#    remote: Total 9 (delta 1), reused 6 (delta 1), pack-reused 0 (from 0)</span>
<span class="c">#    Receiving objects: 100% (9/9), done.</span>
<span class="c">#    Resolving deltas: 100% (1/1), done.</span>
<span class="nv">$ </span><span class="nb">cd </span>2024-cicd-w2-2
  
<span class="c"># 워크플로우 파일 생성</span>
<span class="nv">$ </span><span class="nb">mkdir</span> <span class="nt">-p</span> .github/workflows/
<span class="nv">$ </span><span class="nb">touch</span> .github/workflows/deploy.yaml
  
<span class="c"># 소스 수정</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s2">"s/CICD/CICD 2w/g"</span> server.py
</code></pre></div>    </div>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">.github/workflows/deploy.yaml</code> 파일을 작성합니다.</p>

    <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># .github/workflows/deploy.yaml</span>
<span class="na">name</span><span class="pi">:</span> <span class="s">CICD1</span>
<span class="na">on</span><span class="pi">:</span>
  <span class="na">workflow_dispatch</span><span class="pi">:</span>
  <span class="na">push</span><span class="pi">:</span>
    <span class="na">branches</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">main</span>
  
<span class="na">jobs</span><span class="pi">:</span>
  <span class="na">deploy</span><span class="pi">:</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Configure the SSH Private Key Secret</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">mkdir -p ~/.ssh/</span>
          <span class="s">echo "${{ secrets.SSH_PRIVATE_KEY }}" &gt; ~/.ssh/id_rsa</span>
          <span class="s">chmod 600 ~/.ssh/id_rsa</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Set Strict Host Key Checking</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">echo "StrictHostKeyChecking=no" &gt; ~/.ssh/config</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Git Pull</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">export MY_HOST="${{ secrets.EC2_PIP }}"</span>
          <span class="s">ssh vagrant@$MY_HOST &lt;&lt; EOF</span>
            <span class="s">cd /home/vagrant/2024-cicd-w2-2 || exit 1</span>
            <span class="s">git pull origin main || exit 1</span>
          <span class="s">EOF</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Run service</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">export MY_HOST="${{ secrets.EC2_PIP }}"</span>
          <span class="s">ssh vagrant@$MY_HOST sudo fuser -k -n tcp 80 || true</span>
          <span class="s">ssh vagrant@$MY_HOST "nohup sudo -E python3 /home/vagrant/2024-cicd-w2-2/server.py &gt; /home/vagrant/2024-cicd-w2-2/server.log 2&gt;&amp;1 &amp;"</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>코드를 push합니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"add workflow"</span> <span class="o">&amp;&amp;</span> git push origin main
</code></pre></div>    </div>
  </li>
  <li>GitHub Actions를 확인해보겠습니다.
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_11.png" alt="img.png" /></li>
  <li>가상머신에서 확인해보겠습니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>vagrant ssh
  
<span class="c">#-------</span>
<span class="nv">$ </span><span class="nb">cd </span>2024-cicd-w2-2/
<span class="nv">$ </span><span class="nb">grep</span> <span class="nt">-i</span> cicd server.py
<span class="c"># =&gt;         response_string = now.strftime(&amp;quot;The time is %-I:%M:%S %p, CICD 2w Study.\n&amp;quot;)</span>
<span class="nv">$ </span><span class="nb">sudo </span>ps <span class="nt">-ef</span> |grep server.py
<span class="c"># =&gt; root        2620       1  0 15:57 ?        00:00:00 sudo -E python3 /home/vagrant/2024-cicd-w2-2/server.py</span>
<span class="c">#    root        2621    2620  0 15:57 ?        00:00:00 python3 /home/vagrant/2024-cicd-w2-2/server.py</span>
<span class="nv">$ </span><span class="nb">tail</span> /home/vagrant/2024-cicd-w2-2/server.log
<span class="c"># =&gt; nohup: ignoring input</span>
<span class="c">#------- </span>
</code></pre></div>    </div>
  </li>
  <li>변경사항을 브라우저로 확인해보겠습니다.
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_12.png" alt="img.png" />
    <ul>
      <li>변경사항이 잘 반영되어서 CICD <code class="language-plaintext highlighter-rouge">2w</code>로 변경되었습니다.</li>
    </ul>
  </li>
</ul>

<h5 id="코드-수정-후-동작-확인">코드 수정 후 동작 확인</h5>

<ul>
  <li>개인 PC에서 코드와 워크플로우를 수정하고 GitHub에 push하여 배포가 잘 되는지 확인해보겠습니다.
    <ul>
      <li>코드 수정
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s2">"s/CICD 2w/CICD1 End/g"</span> server.py
</code></pre></div>        </div>
      </li>
      <li>
        <p>워크플로우 수정</p>

        <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># .github/workflows/deploy.yaml</span>
<span class="na">name</span><span class="pi">:</span> <span class="s">CICD1 End</span>
<span class="na">on</span><span class="pi">:</span>
  <span class="na">workflow_dispatch</span><span class="pi">:</span>
  <span class="na">push</span><span class="pi">:</span>
    <span class="na">branches</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">main</span>
    
<span class="na">jobs</span><span class="pi">:</span>
  <span class="na">deployfinal</span><span class="pi">:</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Configure the SSH Private Key Secret</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">mkdir -p ~/.ssh/</span>
          <span class="s">echo "${{ secrets.SSH_PRIVATE_KEY }}" &gt; ~/.ssh/id_rsa</span>
          <span class="s">chmod 600 ~/.ssh/id_rsa</span>
    
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Set Strict Host Key Checking</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">echo "StrictHostKeyChecking=no" &gt; ~/.ssh/config</span>
    
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Git Pull</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">export MY_HOST="${{ secrets.EC2_PIP }}"</span>
          <span class="s">ssh vagrant@$MY_HOST &lt;&lt; EOF</span>
            <span class="s">cd /home/vagrant/2024-cicd-w2-2 || exit 1</span>
            <span class="s">git pull origin main || exit 1</span>
          <span class="s">EOF</span>
    
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Run service</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">export MY_HOST="${{ secrets.EC2_PIP }}"</span>
          <span class="s">ssh vagrant@$MY_HOST sudo fuser -k -n tcp 80 || true</span>
          <span class="s">ssh vagrant@$MY_HOST "nohup sudo -E python3 /home/vagrant/2024-cicd-w2-2/server.py &gt; /home/vagrant/2024-cicd-w2-2/server.log 2&gt;&amp;1 &amp;"</span>
</code></pre></div>        </div>
      </li>
      <li>코드 push
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"edit workflow"</span> <span class="o">&amp;&amp;</span> git push origin main
    
<span class="c"># [가상머신]</span>
<span class="nv">$ </span><span class="nb">grep</span> <span class="nt">-i</span> cicd server.py
<span class="c"># =&gt;         response_string = now.strftime(&amp;quot;The time is %-I:%M:%S %p, CICD1 End Study.</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 변경된 소스가 서버에 반영되었습니다.&lt;/span&gt;</span>
    
<span class="nv">$ </span><span class="nb">sudo </span>ps <span class="nt">-ef</span> |grep server.py
<span class="c"># =&gt; root        3011       1  0 16:17 ?        00:00:00 sudo -E python3 /home/vagrant/2024-cicd-w2-2/server.py</span>
<span class="c">#    root        3012    3011  0 16:17 ?        00:00:00 python3 /home/vagrant/2024-cicd-w2-2/server.py</span>
<span class="c">#    vagrant     3035    2255  0 16:18 pts/0    00:00:00 grep --color=auto server.py</span>
<span class="nv">$ </span><span class="nb">tail</span> /home/vagrant/2024-cicd-w2-2/server.log
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li>변경사항을 브라우저로 확인해보겠습니다.
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_13.png" alt="img.png" />
    <ul>
      <li>변경사항이 잘 반영되어서 CICD1 End로 변경되었습니다.</li>
    </ul>
  </li>
</ul>

<h3 id="github-actions의-marketplace-활용하기">GitHub Actions의 Marketplace 활용하기</h3>

<ul>
  <li>이번에는 GitHub Actions의 Marketplace에서 다른 액션을 가져와서 사용해보겠습니다.</li>
  <li>Marketplace는 <a href="https://github.com/marketplace">https://github.com/marketplace</a>로 접속할 수 있습니다.</li>
  <li>이번 실습에서 사용할 액션은 ssh와 scp 입니다.</li>
</ul>

<h4 id="ssh-for-github-actions">SSH for GitHub Actions</h4>
<ul>
  <li>관련 주소 : <a href="https://github.com/appleboy/ssh-action">Github</a>, <a href="https://github.com/marketplace/actions/ssh-remote-commands">marketplace</a></li>
  <li>SSH for GitHub Actions는 원격 서버에 SSH로 접속하여 명령을 실행할 수 있습니다.</li>
  <li>앞의 실습처럼 쉘 명령으로 ssh 접속이 가능하지만 이 액션을 사용하면 더 간편하게 사용할 수 있습니다.</li>
  <li>사용 예
    <ol>
      <li>
        <p>아이디/비밀번호로 원격 서버에 접속하여 <code class="language-plaintext highlighter-rouge">whoami</code> 명령을 실행합니다.</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>name: remote ssh <span class="nb">command
</span>on: <span class="o">[</span>push]
<span class="nb">jobs</span>:
  build:
    name: Build
    runs-on: ubuntu-latest
    steps:
      - name: executing remote ssh commands using password
        uses: appleboy/ssh-action@v1.2.0
        with:
          host: <span class="k">${</span><span class="p">{ secrets.HOST </span><span class="k">}</span><span class="o">}</span>
          username: linuxserver.io
          password: <span class="k">${</span><span class="p">{ secrets.PASSWORD </span><span class="k">}</span><span class="o">}</span>
          port: <span class="k">${</span><span class="p">{ secrets.PORT </span><span class="k">}</span><span class="o">}</span>
          script: <span class="nb">whoami</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p>비밀번호 대신 private key를 사용하여 로그인 합니다.</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Using private key</span>
- name: executing remote ssh commands using ssh key
  uses: appleboy/ssh-action@v1.2.0
  with:
    host: <span class="k">${</span><span class="p">{ secrets.HOST </span><span class="k">}</span><span class="o">}</span>
    username: <span class="k">${</span><span class="p">{ secrets.USERNAME </span><span class="k">}</span><span class="o">}</span>
    key: <span class="k">${</span><span class="p">{ secrets.KEY </span><span class="k">}</span><span class="o">}</span>
    port: <span class="k">${</span><span class="p">{ secrets.PORT </span><span class="k">}</span><span class="o">}</span>
    script: <span class="nb">whoami</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p>여러 명령을 실행할 수 있습니다.</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Multiple Commands</span>
- name: multiple <span class="nb">command
  </span>uses: appleboy/ssh-action@v1.2.0
  with:
    host: <span class="k">${</span><span class="p">{ secrets.HOST </span><span class="k">}</span><span class="o">}</span>
    username: <span class="k">${</span><span class="p">{ secrets.USERNAME </span><span class="k">}</span><span class="o">}</span>
    key: <span class="k">${</span><span class="p">{ secrets.KEY </span><span class="k">}</span><span class="o">}</span>
    port: <span class="k">${</span><span class="p">{ secrets.PORT </span><span class="k">}</span><span class="o">}</span>
    script: |
      <span class="nb">whoami
      ls</span> <span class="nt">-al</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p>환경 변수를 쉘에 전달할 수 있습니다.</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Pass environment variable to shell script</span>
- name: pass environment
  uses: appleboy/ssh-action@v1.2.0
  <span class="nb">env</span>:
    FOO: <span class="s2">"BAR"</span>
    BAR: <span class="s2">"FOO"</span>
    SHA: <span class="k">${</span><span class="p">{ github.sha </span><span class="k">}</span><span class="o">}</span>
  with:
    host: <span class="k">${</span><span class="p">{ secrets.HOST </span><span class="k">}</span><span class="o">}</span>
    username: <span class="k">${</span><span class="p">{ secrets.USERNAME </span><span class="k">}</span><span class="o">}</span>
    key: <span class="k">${</span><span class="p">{ secrets.KEY </span><span class="k">}</span><span class="o">}</span>
    port: <span class="k">${</span><span class="p">{ secrets.PORT </span><span class="k">}</span><span class="o">}</span>
    envs: FOO,BAR,SHA
    script: |
      <span class="nb">echo</span> <span class="s2">"I am </span><span class="nv">$FOO</span><span class="s2">"</span>
      <span class="nb">echo</span> <span class="s2">"I am </span><span class="nv">$BAR</span><span class="s2">"</span>
      <span class="nb">echo</span> <span class="s2">"sha: </span><span class="nv">$SHA</span><span class="s2">"</span>
</code></pre></div>        </div>
      </li>
    </ol>
  </li>
  <li>
    <p>워크플로우 설정 후 테스트</p>

    <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># .github/workflows/ssh-deploy.yaml</span>
<span class="na">name</span><span class="pi">:</span> <span class="s">CICD2</span>
<span class="na">on</span><span class="pi">:</span>
  <span class="na">workflow_dispatch</span><span class="pi">:</span>
  <span class="na">push</span><span class="pi">:</span>
    <span class="na">branches</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">main</span>
  
<span class="na">jobs</span><span class="pi">:</span>
  <span class="na">ssh-deploy</span><span class="pi">:</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Github Repository Checkout</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/checkout@v4</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">executing remote ssh commands</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">appleboy/ssh-action@v1.2.0</span>
        <span class="na">env</span><span class="pi">:</span>
          <span class="na">AWS_KEYS</span><span class="pi">:</span> <span class="pi">|</span>
            <span class="s">ACCESSKEY : asdf1234end</span>
            <span class="s">SECRETKEY : qwer1234end</span>
        <span class="na">with</span><span class="pi">:</span>
          <span class="na">host</span><span class="pi">:</span> <span class="s">${{ secrets.EC2_PIP }}</span>
          <span class="na">port</span><span class="pi">:</span> <span class="m">22</span>
          <span class="na">username</span><span class="pi">:</span> <span class="s">vagrant</span>
          <span class="na">key</span><span class="pi">:</span> <span class="s">${{ secrets.SSH_PRIVATE_KEY }}</span>
          <span class="na">envs</span><span class="pi">:</span> <span class="s">AWS_KEYS</span>
          <span class="na">script_stop</span><span class="pi">:</span> <span class="kc">true</span>
          <span class="na">script</span><span class="pi">:</span> <span class="pi">|</span>
            <span class="s">cd /home/vagrant/2024-cicd-w2-2</span>
            <span class="s">echo "$AWS_KEYS" &gt; .env</span>
</code></pre></div>    </div>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"add ssh action test"</span> <span class="o">&amp;&amp;</span> git push origin main
</code></pre></div>    </div>
  </li>
  <li>
    <p>가상머신에서 확인</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-al</span> ~/2024-cicd-w2-2/
<span class="c"># =&gt; total 32</span>
<span class="c">#    drwxrwxr-x 4 vagrant vagrant 4096 Oct 01 16:46 .</span>
<span class="c">#    drwxr-x--- 5 vagrant vagrant 4096 Oct 01 16:46 ..</span>
<span class="c">#    -rw-rw-r-- 1 vagrant vagrant   49 Oct 01 16:46 .env  # &lt;span style="color: green;"&gt;👉 .env파일이 생성되었습니다.&lt;/span&gt;  </span>
<span class="c">#    drwxrwxr-x 8 vagrant vagrant 4096 Oct 01 16:46 .git</span>
<span class="c">#    drwxrwxr-x 3 vagrant vagrant 4096 Oct 01 15:57 .github</span>
<span class="c">#    -rw-rw-r-- 1 vagrant vagrant 3139 Oct 01 15:11 .gitignore</span>
<span class="c">#    -rw-rw-r-- 1 vagrant vagrant    0 Oct 01 16:46 server.log</span>
<span class="c">#    -rw-rw-r-- 1 vagrant vagrant  761 Oct 01 16:17 server.py</span>
<span class="c">#    -rw-rw-r-- 1 vagrant vagrant  759 Oct 01 16:17 server.py-e</span>
<span class="nv">$ </span><span class="nb">cat</span> ~/2024-cicd-w2-2/.env
<span class="c"># =&gt; ACCESSKEY : asdf1234end</span>
<span class="c">#    SECRETKEY : qwer1234end</span>
</code></pre></div>    </div>
  </li>
  <li>GitHub에서 .env가 있는지 확인해보겠습니다.
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_14.png" alt="img.png" />
.env 파일이 Git에는 없습니다! 하지만 가상머신 서버에 .env 파일이 있었던 것은 SSH for GitHub Actions를 통해 전달된 것입니다.</li>
</ul>

<h4 id="scp-for-github-actions">SCP for GitHub Actions</h4>

<ul>
  <li>관련 주소 : <a href="https://github.com/appleboy/scp-action">Github</a>, <a href="https://github.com/marketplace/actions/scp-files">marketplace</a></li>
  <li>SCP for GitHub Actions는 원격 서버로 파일을 전송해주는 액션입니다.</li>
  <li>실습을 통해 기능을 알아보겠습니다.</li>
  <li>server.py 수정하기
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s2">"s/CICD1 End Study/SCP Test/g"</span> server.py
</code></pre></div>    </div>
  </li>
  <li>
    <p>워크플로우 파일 수정하기</p>

    <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># .github/workflows/scp-ssh-deploy.yaml</span>
<span class="na">name</span><span class="pi">:</span> <span class="s">CICD2</span>
<span class="na">on</span><span class="pi">:</span>
  <span class="na">workflow_dispatch</span><span class="pi">:</span>
  <span class="na">push</span><span class="pi">:</span>
    <span class="na">branches</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">main</span>
  
<span class="na">jobs</span><span class="pi">:</span>
  <span class="na">scp-ssh-deploy</span><span class="pi">:</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Github Repository Checkout</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/checkout@v4</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">executing remote ssh commands</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">appleboy/ssh-action@v1.2.0</span>
        <span class="na">env</span><span class="pi">:</span>
          <span class="na">AWS_KEYS</span><span class="pi">:</span> <span class="s">${{ secrets.MYKEYS }}</span>
        <span class="na">with</span><span class="pi">:</span>
          <span class="na">host</span><span class="pi">:</span> <span class="s">${{ secrets.EC2_PIP }}</span>
          <span class="na">username</span><span class="pi">:</span> <span class="s">vagrant</span>
          <span class="na">port</span><span class="pi">:</span> <span class="m">22</span>
          <span class="na">key</span><span class="pi">:</span> <span class="s">${{ secrets.SSH_PRIVATE_KEY }}</span>
          <span class="na">envs</span><span class="pi">:</span> <span class="s">AWS_KEYS</span>
          <span class="na">script_stop</span><span class="pi">:</span> <span class="kc">true</span>
          <span class="na">script</span><span class="pi">:</span> <span class="pi">|</span>
             <span class="s">cd /home/vagrant/2024-cicd-w2-2</span>
             <span class="s">echo "$AWS_KEYS" &gt; .env</span>
             <span class="s">sudo fuser -k -n tcp 80 || true</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">copy file via scp</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">appleboy/scp-action@v0.1.7</span>
        <span class="na">with</span><span class="pi">:</span>
          <span class="na">host</span><span class="pi">:</span> <span class="s">${{ secrets.EC2_PIP }}</span>
          <span class="na">username</span><span class="pi">:</span> <span class="s">vagrant</span>
          <span class="na">port</span><span class="pi">:</span> <span class="m">22</span>
          <span class="na">key</span><span class="pi">:</span> <span class="s">${{ secrets.SSH_PRIVATE_KEY }}</span>
          <span class="na">source</span><span class="pi">:</span> <span class="s">server.py</span>
          <span class="na">target</span><span class="pi">:</span> <span class="s">/home/vagrant/2024-cicd-w2-2</span>
</code></pre></div>    </div>
  </li>
  <li>코드 push하기
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"using scp ssh action"</span> <span class="o">&amp;&amp;</span> git push origin main
</code></pre></div>    </div>
  </li>
  <li>가상서버에서 확인
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 서버 1</span>
<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-al</span> ~/2024-cicd-w2-2/
<span class="c"># =&gt; total 28</span>
<span class="c">#    drwxrwxr-x 4 vagrant vagrant 4096 Dec 14 17:04 .</span>
<span class="c">#    drwxr-x--- 5 vagrant vagrant 4096 Dec 14 17:04 ..</span>
<span class="c">#    -rw-rw-r-- 1 vagrant vagrant    1 Dec 14 17:03 .env</span>
<span class="c">#    drwxrwxr-x 8 vagrant vagrant 4096 Dec 14 17:02 .git</span>
<span class="c">#    drwxrwxr-x 3 vagrant vagrant 4096 Dec 14 15:57 .github</span>
<span class="c">#    -rw-rw-r-- 1 vagrant vagrant 3139 Dec 14 15:11 .gitignore</span>
<span class="c">#    -rw-rw-r-- 1 vagrant vagrant    0 Dec 14 17:02 server.log</span>
<span class="c">#    -rw-r--r-- 1 vagrant vagrant  754 Dec 14 17:03 server.py</span>
<span class="nv">$ </span><span class="nb">cat</span> ~/2024-cicd-w2-2/server.py | <span class="nb">grep </span>SCP
<span class="c"># =&gt;         response_string = now.strftime(&amp;quot;The time is %-I:%M:%S %p, SCP Test.\n&amp;quot;)  </span>
<span class="c"># &lt;span style="color: green;"&gt;👉 변경사항이 잘 반영되었습니다.&lt;/span&gt;</span>
</code></pre></div>    </div>
  </li>
</ul>

<h4 id="최종-실습">최종 실습</h4>

<ul>
  <li>앞서 쉘 명령으로 진행했던 작업을 GitHub Actions의 Marketplace에서 가져온 ssh, scp 액션을 사용하여 진행해보겠습니다.</li>
  <li>내 PC에서 소스 수정하기
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s2">"s/SCP Test/CICD2 End 🥳/g"</span> server.py
</code></pre></div>    </div>
  </li>
  <li>
    <p>워크플로우 수정하기</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># .github/workflows/deploy.yaml</span>
name: CICD2
on:
  workflow_dispatch:
  push:
    branches:
      - main
  
<span class="nb">jobs</span>:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Github Repository Checkout
        uses: actions/checkout@v4
  
      - name: copy file via ssh
        uses: appleboy/scp-action@v0.1.7
        with:
          host: <span class="k">${</span><span class="p">{ secrets.EC2_PIP </span><span class="k">}</span><span class="o">}</span>
          username: vagrant
          port: 22  
          key: <span class="k">${</span><span class="p">{ secrets.SSH_PRIVATE_KEY </span><span class="k">}</span><span class="o">}</span>
          <span class="nb">source</span>: server.py
          target: /home/vagrant
  
      - name: executing remote ssh commands 
        uses: appleboy/ssh-action@v1.2.0
        <span class="nb">env</span>:
          AWS_KEYS: <span class="k">${</span><span class="p">{ secrets.MYKEYS </span><span class="k">}</span><span class="o">}</span>
        with:
          host: <span class="k">${</span><span class="p">{ secrets.EC2_PIP </span><span class="k">}</span><span class="o">}</span>
          username: vagrant
          port: 22
          key: <span class="k">${</span><span class="p">{ secrets.SSH_PRIVATE_KEY </span><span class="k">}</span><span class="o">}</span>
          envs: AWS_KEYS
          script_stop: <span class="nb">true
          </span>script: |
             <span class="nb">cd</span> /home/vagrant/2024-cicd-w2-2
             <span class="nb">echo</span> <span class="s2">"</span><span class="nv">$AWS_KEYS</span><span class="s2">"</span> <span class="o">&gt;</span> .env
             <span class="nb">sudo </span>fuser <span class="nt">-k</span> <span class="nt">-n</span> tcp 80 <span class="o">||</span> <span class="nb">true
             rm </span>server.py
             <span class="nb">cp</span> /home/vagrant/server.py ./
             <span class="nb">nohup sudo</span> <span class="nt">-E</span> python3 /home/vagrant/2024-cicd-w2-2/server.py <span class="o">&gt;</span> /home/vagrant/2024-cicd-w2-2/server.log 2&gt;&amp;1 &amp;
             <span class="nb">echo</span> <span class="s2">"test"</span> <span class="o">&gt;&gt;</span> /home/vagrant/text.txt
</code></pre></div>    </div>
  </li>
  <li>코드 push하기
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"Deploy CICD2 Final"</span> <span class="o">&amp;&amp;</span> git push origin main
</code></pre></div>    </div>
  </li>
  <li>웹으로 접속해서 확인해보겠습니다.
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_15.png" alt="img.png" />
    <ul>
      <li>변경사항이 잘 반영되어서 CICD2 End 🥳로 변경되었습니다.</li>
    </ul>
  </li>
</ul>

<h3 id="github-actions-with-ansible">GitHub Actions with Ansible</h3>

<ul>
  <li>이번에는 GitHub Actions를 사용하여 Ansible을 실행해보겠습니다.</li>
  <li>상세한 Ansible 사용법은 <a href="https://docs.ansible.com/ansible/latest/index.html">Ansible 공식문서</a>를 참고하시고, 이번 실습에서는
간단하게 Ansible을 이용해서 Ping 테스트를 해보겠습니다. (여기에서의 ping은 ansible이 해당 호스트와 통신이 가능한지 확인하는 것이고 일반적인 ping과는 다릅니다.)</li>
  <li>
    <p>워크플로우 작성</p>

    <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># .github/workflows/ansible-deploy.yaml</span>
<span class="na">name</span><span class="pi">:</span> <span class="s">Run Ansible</span>
<span class="na">on</span><span class="pi">:</span>
  <span class="na">workflow_dispatch</span><span class="pi">:</span>
  <span class="na">push</span><span class="pi">:</span>
    <span class="na">branches</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">main</span>
  
<span class="na">jobs</span><span class="pi">:</span>
  <span class="na">run-playbooks</span><span class="pi">:</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Github Repository Checkout</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/checkout@v4</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Setup Python </span><span class="m">3</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/setup-python@v5</span>
        <span class="na">with</span><span class="pi">:</span>
          <span class="na">python-version</span><span class="pi">:</span> <span class="s2">"</span><span class="s">3.8"</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Upgrade Pip &amp; Install Ansible</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">python -m pip install --upgrade pip</span>
          <span class="s">python -m pip install ansible</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Implement the Private SSH Key</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">mkdir -p ~/.ssh/</span>
          <span class="s">echo "$" &gt; ~/.ssh/id_rsa</span>
          <span class="s">chmod 600 ~/.ssh/id_rsa</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Ansible Inventory File for Remote host</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">mkdir -p ./devops/ansible/</span>
          <span class="s">export INVENTORY_FILE=./devops/ansible/inventory.ini</span>
          <span class="s">echo "[my_host_group]" &gt; $INVENTORY_FILE</span>
          <span class="s">echo "$" &gt;&gt; $INVENTORY_FILE</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Ansible Default Configuration File</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">mkdir -p ./devops/ansible/</span>
          <span class="s">cat &lt;&lt;EOF &gt; ./devops/ansible/ansible.cfg</span>
          <span class="s">[defaults]</span>
          <span class="s">ansible_python_interpreter = '/usr/bin/python3'</span>
          <span class="s">ansible_ssh_private_key_file = ~/.ssh/id_rsa</span>
          <span class="s">remote_user = vagrant</span>
          <span class="s">inventory = ./inventory.ini</span>
          <span class="s">host_key_checking = False</span>
          <span class="s">EOF</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Ping Ansible Hosts</span>
        <span class="na">working-directory</span><span class="pi">:</span> <span class="s">./devops/ansible/</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">ansible all -m ping</span>
  
      <span class="c1"># - name: Run Ansible Playbooks</span>
      <span class="c1">#   working-directory: ./devops/ansible/</span>
      <span class="c1">#   run: |</span>
      <span class="c1">#     ansible-playbook install-nginx.yaml</span>
  
      <span class="c1"># - name: Deploy Python via Ansible</span>
      <span class="c1">#   working-directory: ./devops/ansible/</span>
      <span class="c1">#   run: |</span>
      <span class="c1">#     ansible-playbook deploy-python.yaml</span>
</code></pre></div>    </div>
  </li>
  <li>워크플로우 push 하기
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"Deploy Ansible Test"</span> <span class="o">&amp;&amp;</span> git push origin main
</code></pre></div>    </div>
  </li>
  <li>GitHub Actions에서 ping 결과를 확인해보겠습니다.
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_16.png" alt="img.png" />
    <ul>
      <li>정상적으로 ping이 가서 “pong”이라는 응답이 돌아왔습니다.</li>
    </ul>
  </li>
</ul>

<h2 id="마치며">마치며</h2>

<p>지금까지 GitHub Actions의 기본적인 사용하고, Marketplace에서 제공하는 액션 사용해보고, Ansible까지 맛보기로 사용해보았습니다.</p>

<p>GitHub Actions는 일부 제약이 있지만 무료로 편리하게 사용할 수 있고
Marketplace를 통해 다양한 추가기능을 손쉽게 사용할 수 있어서 매력적입니다.</p>

<p>하지만 매번 가상환경을 프로비저닝하고, 필요한 패키지를 설치하는 등의 작업이
시간이 의외로 많이 들어서, 실제 동작 시간이 예상보다 오래 걸릴 수 있다는 점이 있습니다.
또한 Jenkins나 다른 CI/CD 도구들은 실패한 상태의 쉘에 직접 로그인해서 트러블 슈팅을 할 수 있지만,
Github Actions는 그렇게 할 수 없는 점도 아쉽습니다.</p>

<p>그래도 GitHub를 사용하면서 저렴한 가격으로 간단하게 CI/CD를 구성할 수 있다는 점은 매력적인것 같습니다.</p>

<p>추운 날씨에도 애써주신 모든 분들 고생 많으셨습니다. 감사합니다! :bow:</p>]]></content><author><name></name></author><category term="kans" /><category term="cicd," /><category term="jenkins," /><category term="git," /><category term="linux" /><summary type="html"><![CDATA[이번 주에는 GitHub Actions를 이용한 CI/CD에 대해 알아보겠습니다.]]></summary></entry><entry><title type="html">[CI/CD] Jenkins CI/CD + Docker</title><link href="https://sweetlittlebird.github.io/posts/2024-12-08-CICD-Lite-Week1/" rel="alternate" type="text/html" title="[CI/CD] Jenkins CI/CD + Docker" /><published>2024-12-08T00:50:18+09:00</published><updated>2024-12-08T00:50:18+09:00</updated><id>https://sweetlittlebird.github.io/posts/CICD%20Lite%20-%20Week1</id><content type="html" xml:base="https://sweetlittlebird.github.io/posts/2024-12-08-CICD-Lite-Week1/"><![CDATA[<h2 id="들어가며">들어가며</h2>

<p>스터디 시간이 다시 돌아왔습니다. ^^ 이번 스터디는 3주차의 다소 짧은 스터디로 CI/CD에 관련해서 진행됩니다.
즐거운 연말 다시 한번 과제로 달려보겠습니다. :laughing:</p>

<p>이번 주에는 Jenkins와 Git, Docker를 이용하여 CI/CD 파이프라인을 구축해보겠습니다.</p>

<h2 id="jenkins-cicd--docker">Jenkins CI/CD + Docker</h2>

<h3 id="cicd란">CI/CD란?</h3>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_1.png" alt="img.png" class="image-center" />
<em class="image-caption">CI/CD 파이프라인 (출처:<a href="https://blog.devgenius.io/what-is-ci-cd-concept-375cb226cf3d">Dev Genius</a>)</em></p>

<ul>
  <li>CI/CD는 Continuous Integration(지속적 통합)과 Continuous Deployment(지속적 배포)의 약자로 소프트웨어 개발의 계획단계에서 부터 배포/운영까지 전 과정에 걸쳐
자동화된 프로세스를 통해 소프트웨어를 빠르게, 안정적으로 배포할 수 있도록 하는 방법론입니다.</li>
  <li>CI와 CD로 나눠서 살펴보겠습니다.
    <ul>
      <li>CI : 여러 개발자들이 작성한 코드를 하나로 통합하는 코드의 통합을 지속적으로 진행하는 것을 의미합니다.
        <ul>
          <li>CI의 단계 : 계획 -&gt; 코딩 -&gt; 빌드 -&gt; 테스트 -&gt; 패키징</li>
        </ul>
      </li>
      <li>CD : CI를 통해 빌드된 결과물을 배포하고 운영하고, 모니터링을 통해 개선할 점을 파악하는 과정을 지속적으로 진행하는 것을 의미합니다.
        <ul>
          <li>CD의 단계 : 배포 -&gt; 운영 -&gt; 모니터링 -&gt; 피드백</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>CI/CD는 위의 그림과 같이 다양한 툴들로 구성이 되며 이번주에는 Jenkins와 Git, Docker를 이용하여 CI/CD 파이프라인을 구축해보겠습니다.</li>
</ul>

<h3 id="컨테이너를-이용한-어플리케이션-개발">컨테이너를 이용한 어플리케이션 개발</h3>

<p>CI/CD 파이프라인을 구축하기 위해 Docker를 이용하여 어플리케이션을 컨테이너화하겠습니다.</p>

<h4 id="ruby로-특정-문자열-출력하는-간단한-어플리케이션-만들기">ruby로 특정 문자열 출력하는 간단한 어플리케이션 만들기</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nv">$ </span><span class="nb">mkdir </span>1.1 <span class="o">&amp;&amp;</span> <span class="nb">cd </span>1.1
  <span class="nv">$ </span><span class="nb">echo</span> <span class="s1">'puts "Hello Docker!"'</span> <span class="o">&gt;</span> hello.rb
  
  <span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Dockerfile <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
  FROM ruby:3.3
  COPY hello.rb /app/
  WORKDIR /app
  CMD ["ruby", "hello.rb"]
</span><span class="no">  EOF
  
</span>  <span class="c"># 이미지 빌드</span>
  <span class="nv">$ </span>docker build <span class="nt">-t</span> hello <span class="nb">.</span>
  <span class="c"># =&gt; [+] Building 36.6s (9/9) FINISHED</span>
  <span class="nv">$ </span>docker image <span class="nb">ls</span> <span class="nt">-f</span> <span class="nv">reference</span><span class="o">=</span>hello
  <span class="c"># =&gt; REPOSITORY   TAG       IMAGE ID       CREATED          SIZE</span>
  <span class="c">#    hello        latest    d0c55f1ebe18   35 seconds ago   1GB</span>
  
  <span class="c"># 실행</span>
  <span class="nv">$ </span>docker run hello
  <span class="c"># =&gt; Hello Docker!</span>
</code></pre></div></div>

<ul>
  <li>
    <p>코드 수정</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 코드 수정</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"puts 'Hello CloudNet@'"</span> <span class="o">&gt;</span> hello.rb
  
<span class="c"># 컨테이너 이미지 빌드</span>
<span class="nv">$ </span>docker build <span class="nb">.</span> <span class="nt">-t</span> hello:1
<span class="nv">$ </span>docker image <span class="nb">ls</span> <span class="nt">-f</span> <span class="nv">reference</span><span class="o">=</span>hello
<span class="c"># =&gt; REPOSITORY   TAG       IMAGE ID       CREATED         SIZE</span>
<span class="c">#    hello        1         7fe4f428d492   3 seconds ago   1GB</span>
<span class="c">#    hello        latest    d0c55f1ebe18   3 minutes ago   1GB  </span>
<span class="c"># &lt;span style="color: green;"&gt;👉 Latest 태그는 IMAGE ID를 통해 아직 이전의 이미지를 갖고 있는 것을 확인할 수 있습니다.&lt;/span&gt;</span>
  
<span class="c"># 1번 태그에 추가적으로 latest 태그를 붙여보겠습니다.</span>
<span class="nv">$ </span>docker tag hello:1 hello:latest
<span class="nv">$ </span>docker image <span class="nb">ls</span> <span class="nt">-f</span> <span class="nv">reference</span><span class="o">=</span>hello
<span class="c"># =&gt; REPOSITORY   TAG       IMAGE ID       CREATED          SIZE</span>
<span class="c">#    hello        1         7fe4f428d492   36 seconds ago   1GB</span>
<span class="c">#    hello        latest    7fe4f428d492   36 seconds ago   1GB</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 Latest 태그도 동일한 IMAGE ID를 갖게되었습니다.&lt;/span&gt;</span>
  
<span class="c"># 컨테이너 실행</span>
<span class="nv">$ </span>docker run <span class="nt">--rm</span> hello:1
<span class="c"># =&gt; Hello CloudNet@</span>
<span class="nv">$ </span>docker run <span class="nt">--rm</span> hello
<span class="c"># =&gt; Hello CloudNet@</span>
</code></pre></div>    </div>
  </li>
</ul>

<h4 id="compiling-code-in-docker">Compiling code in Docker</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c"># 코드 작성</span>
  <span class="nv">$ </span><span class="nb">mkdir </span>1.2 <span class="o">&amp;&amp;</span> <span class="nb">cd </span>1.2
  
  <span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Hello.java <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
  class Hello {
      public static void main(String[] args) {
          System.out.println("Hello Docker");
      }
  }
</span><span class="no">  EOF
  
</span>  <span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Dockerfile <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
  FROM openjdk
  COPY . /app
  WORKDIR /app
  RUN javac Hello.java    # 컴파일
  CMD java Hello
</span><span class="no">  EOF
  
</span>  <span class="c"># 컨테이너 이미지 빌드</span>
  <span class="nv">$ </span>docker pull openjdk
  <span class="nv">$ </span>docker build <span class="nb">.</span> <span class="nt">-t</span> hello:2 <span class="nt">-t</span> hello:latest
  <span class="c"># =&gt; [+] Building 0.8s (9/9) FINISHED</span>
  <span class="nv">$ </span>docker image <span class="nb">ls</span> <span class="nt">-f</span> <span class="nv">reference</span><span class="o">=</span>hello
  <span class="c"># =&gt; REPOSITORY   TAG       IMAGE ID       CREATED          SIZE</span>
  <span class="c">#    hello        2         ba37ddf45c26   10 seconds ago   487MB</span>
  <span class="c">#    hello        latest    ba37ddf45c26   10 seconds ago   487MB</span>
  <span class="c">#    hello        1         7fe4f428d492   9 minutes ago    1GB</span>
  
  <span class="c"># 컨테이너 실행</span>
  <span class="nv">$ </span>docker run <span class="nt">--rm</span> hello:2
  <span class="c"># =&gt; Hello Docker</span>
  <span class="nv">$ </span>docker run <span class="nt">--rm</span> hello
  <span class="c"># =&gt; Hello Docker</span>
  
  <span class="c"># 컨테이너 이미지 내부에 파일 목록을 보면 어떤가요? 꼭 필요한 파일만 있는가요? 보안적으로 어떨까요?</span>
  <span class="nv">$ </span>docker run <span class="nt">--rm</span> hello <span class="nb">ls</span> <span class="nt">-l</span>
  <span class="c"># =&gt; -rw-r--r-- 1 root root  89 Dec  5 15:04 Dockerfile</span>
  <span class="c">#    -rw-r--r-- 1 root root 416 Dec  5 15:05 Hello.class</span>
  <span class="c">#    -rw-r--r-- 1 root root 111 Dec  5 15:04 Hello.java</span>
  <span class="c"># &lt;span style="color: green;"&gt;👉 꼭 필요한 파일 외에도 Dockerfile, *.java 파일, java 컴파일러 등이 있습니다.&lt;/span&gt;</span>
  <span class="c"># &lt;span style="color: green;"&gt;   이 파일들은 정보 유출이나 공격 대상이 될 수 있기 때문에 컨테이너 이미지에 없어야 합니다.&lt;/span&gt;</span>
  
  <span class="c"># RUN 컴파일 시 소스코드와 java 컴파일러(javac)가 포함되어 있음. 실제 애플리케이션 실행에 필요 없음. </span>
  <span class="nv">$ </span>docker run <span class="nt">--rm</span> hello javac <span class="nt">--help</span>
  <span class="c"># =&gt; Usage: javac &amp;lt;options&amp;gt; &amp;lt;source files&amp;gt;</span>
  <span class="c">#    where possible options include:</span>
  <span class="c">#      @&amp;lt;filename&amp;gt;                  Read options and filenames from file</span>
  <span class="c">#    ...</span>
</code></pre></div></div>

<h4 id="멀티-스테이지-빌드">멀티 스테이지 빌드</h4>
<ul>
  <li>멀티 스테이지 빌드는 빌드를 여러 단계로 나누어서 진행하는 방법입니다.</li>
  <li>각 단계마다 필요한 환경을 구성하여 빌드를 진행하고, 최종적으로 필요한 파일만을 추출하여 불필요한 파일들이 제외된
가볍고 안전한 이미지를 생성할 수 있습니다.
  <img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_2.png" alt="img.png" class="image-center" />
  <em class="image-caption">멀티 스테이지 빌드 동작</em></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c"># 코드 작성</span>
  <span class="nv">$ </span><span class="nb">mkdir </span>1.3 <span class="o">&amp;&amp;</span> <span class="nb">cd </span>1.3
  
  <span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Hello.java <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
  class Hello {
      public static void main(String[] args) {
          System.out.println("Hello Multistage container build");
      }
  }
</span><span class="no">  EOF
  
</span>  <span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Dockerfile <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
  FROM openjdk:11 AS buildstage
  COPY . /app
  WORKDIR /app
  RUN javac Hello.java
  
  FROM openjdk:11-jre-slim
  COPY --from=buildstage /app/Hello.class /app/
  WORKDIR /app
  CMD java Hello
</span><span class="no">  EOF
  
</span>  <span class="c"># 컨테이너 이미지 빌드 : 용량 비교 해보자!</span>
  <span class="nv">$ </span>docker build <span class="nb">.</span> <span class="nt">-t</span> hello:3 <span class="nt">-t</span> hello:latest
  <span class="nv">$ </span>docker image <span class="nb">ls</span> <span class="nt">-f</span> <span class="nv">reference</span><span class="o">=</span>hello
  <span class="c"># =&gt; REPOSITORY   TAG       IMAGE ID       CREATED          SIZE</span>
  <span class="c">#    hello        3         4a058414ac44   11 seconds ago   216MB</span>
  <span class="c">#    hello        latest    4a058414ac44   11 seconds ago   216MB</span>
  <span class="c">#    hello        2         ba37ddf45c26   24 minutes ago   487MB</span>
  <span class="c">#    ...</span>
  <span class="c"># &lt;span style="color: green;"&gt;👉 Compiler가 없는 가벼운 jre 이미지를 사용하여 컨테이너 이미지 크기도 줄어든 것을 확인할 수 있습니다.&lt;/span&gt;</span>
  
  <span class="c"># 컨테이너 실행</span>
  <span class="nv">$ </span>docker run <span class="nt">--rm</span> hello:3
  <span class="c"># =&gt; Hello Multistage container build</span>
  <span class="nv">$ </span>docker run <span class="nt">--rm</span> hello
  <span class="c"># =&gt; Hello Multistage container build</span>
  
  <span class="c"># 컨테이너 이미지 내부에 파일 목록을 보면 어떤가요?</span>
  <span class="nv">$ </span>docker run <span class="nt">--rm</span> hello <span class="nb">ls</span> <span class="nt">-l</span>
  <span class="c"># =&gt; total 4</span>
  <span class="c">#    -rw-r--r-- 1 root root 436 Dec  5 15:26 Hello.class</span>
  <span class="nv">$ </span>docker run <span class="nt">--rm</span> hello javac <span class="nt">--help</span>
  <span class="c"># =&gt; docker: Error response from daemon: OCI runtime create failed: container_linux.go:380: starting container process caused: exec: &amp;quot;javac&amp;quot;: executable file not found in $PATH: unknown.</span>
  <span class="c"># &lt;span style="color: green;"&gt;👉 javac가 없어서 이전보다 안전한것을 알 수 있습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<h4 id="jib로-자바-컨테이너-빌드">Jib로 자바 컨테이너 빌드</h4>
<p><a href="https://cloud.google.com/java/getting-started/jib?hl=ko">문서</a>, 
  <a href="https://colevelup.tistory.com/53">관련 블로그1</a>,
  <a href="https://jh-labs.tistory.com/509">관련 블로그2</a></p>
<ul>
  <li>Jib는 Google에서 만든 오픈소스 도구로, Java 어플리케이션을 컨테이너 이미지로 빌드하는 도구입니다.</li>
  <li>Jib는 docker 없이 컨테이너 이미지를 빌드할 수 있으며, 빌드 속도가 빠르고, 이미지 크기가 작아서 배포가 용이합니다.</li>
  <li>Maven 또는 Gradle 플러그인으로 사용할 수 있습니다.</li>
  <li>기존의 Docker 이미지 빌드 흐름은 다음과 같습니다.
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_3.png" alt="img.png" /></li>
  <li>Jib는 다음과 같이 빌드 흐름이 간소화됩니다.
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_4.png" alt="img.png" />
    <ul>
      <li>빌드와 동시에 이미지가 만들어지고 저장소에 푸시까지 가능합니다.</li>
      <li>Jenkins 등의 CI 서버에 Docker가 없어도 컨테이너 이미지를 빌드할 수 있습니다.</li>
      <li>이미지 레이어 캐싱을 통해 빌드 속도가 빠릅니다.</li>
      <li>이미지 크기가 작아서 배포가 용이합니다.</li>
    </ul>
  </li>
</ul>

<h4 id="어플리케이션-서버-컨테이너화-하기">어플리케이션 서버 컨테이너화 하기</h4>

<ul>
  <li>데모를 위해 HTTP 웹 어플리케이션을 컨테이너화 해보겠습니다.</li>
  <li>다음은 ruby 언어로 작성한 기본적인 웹서버로, 현재 날짜와 시간을 표시합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">mkdir </span>1.4 <span class="o">&amp;&amp;</span> <span class="nb">cd </span>1.4

<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> app.rb <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
require 'sinatra'

get '/' do
  "Hello, World! The time is #{Time.now}"
end
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Dockerfile <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
FROM ruby:3.3
RUN gem install sinatra rackup puma
COPY app.rb /app/
WORKDIR /app
CMD ["ruby", "app.rb", "-o", "0.0.0.0"]
</span><span class="no">EOF

</span><span class="c"># 컨테이너 이미지 빌드</span>

<span class="nv">$ </span>docker build <span class="nb">.</span> <span class="nt">-t</span> timeserver:1 <span class="o">&amp;&amp;</span> docker tag timeserver:1 timeserver:latest
<span class="nv">$ </span>docker image <span class="nb">ls</span> <span class="nt">-f</span> <span class="nv">reference</span><span class="o">=</span>timeserver
<span class="c"># =&gt; REPOSITORY   TAG       IMAGE ID       CREATED          SIZE</span>
<span class="c">#    timeserver   1         6393669e5e68   12 seconds ago   1GB</span>
<span class="c">#    timeserver   latest    6393669e5e68   12 seconds ago   1GB</span>

<span class="c"># 컨테이너 실행</span>
<span class="nv">$ </span>docker run <span class="nt">-d</span> <span class="nt">-p</span> 8080:4567 <span class="nt">--name</span><span class="o">=</span>timeserver timeserver

<span class="c"># 컨테이너 접속 및 로그 확인</span>
<span class="nv">$ </span>curl http://localhost:8080
<span class="c"># =&gt; Hello, World! The time is 2024-10-01 15:28:18 +0000</span>
<span class="nv">$ </span>docker logs timeserver
<span class="c"># =&gt; Puma starting in single mode...</span>
<span class="c">#    * Puma version: 6.5.0 (&amp;quot;Sky's Version&amp;quot;)</span>
<span class="c">#    == Sinatra (v4.1.1) has taken the stage on 4567 for development with backup from Puma</span>
<span class="c">#    * Ruby version: ruby 3.3.6 (2024-10-01 revision 75015d4c1f) [aarch64-linux]</span>
<span class="c">#    *  Min threads: 0</span>
<span class="c">#    *  Max threads: 5</span>
<span class="c">#    *  Environment: development</span>
<span class="c">#    *          PID: 1</span>
<span class="c">#    * Listening on http://0.0.0.0:4567</span>
<span class="c">#    Use Ctrl-C to stop</span>
<span class="c">#    172.17.0.1 - - [01/Oct/2024:15:28:07 +0000] &amp;quot;GET / HTTP/1.1&amp;quot; 200 51 0.0048</span>

<span class="c"># 컨테이너 이미지 내부에 파일 확인</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> timeserver <span class="nb">ls</span> <span class="nt">-l</span>
<span class="c"># =&gt; total 4</span>
<span class="c">#    -rw-r--r-- 1 root root 76 Dec  6 15:20 app.rb</span>
</code></pre></div></div>

<ul>
  <li>도커 컨테이너 내부의 소스코드를 수정해서 반영되는지 확인해보겠습니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_5.png" alt="20241205_cicd_lite_w1_5.png" class="image-center" />
<em class="image-caption">vscode에 docker 확장 설치</em></p>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_6.png" alt="20241205_cicd_lite_w1_6.png" class="image-center" />
<em class="image-caption">timeserver 컨테이너 내부의 app.rb 파일 수정</em></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 컨테이너 이미지 내부에 app.rb 파일 수정 후 반영 확인 : VSCODE 경우 docker 확장프로그램 활용</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> timeserver <span class="nb">cat </span>app.rb
<span class="c"># =&gt; require 'sinatra'</span>
<span class="c">#    </span>
<span class="c">#    get '/' do</span>
<span class="c">#      &amp;quot;Hello, World! 😀 The time is #{Time.now}&amp;quot;</span>
<span class="c">#    end</span>

<span class="c"># 컨테이너 접속 후 확인 </span>
<span class="nv">$ </span>curl http://localhost:8080
<span class="c"># =&gt; Hello, World! The time is 2024-10-01 15:45:09 +0000%</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 수정 사항이 반영되지 않았습니다!&lt;/span&gt;</span>

<span class="c"># 컨테이너 삭제</span>
<span class="nv">$ </span>docker <span class="nb">rm</span> <span class="nt">-f</span> timeserver
</code></pre></div></div>

<ul>
  <li>어플리케이션 수정해서 테스트</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s1">'s#World!#World! 😀 Hello CloudNeta Study!#'</span> app.rb
<span class="nv">$ </span><span class="nb">cat </span>app.rb
<span class="c"># =&gt; require 'sinatra'</span>
<span class="c">#    </span>
<span class="c">#    get '/' do</span>
<span class="c">#      &amp;quot;Hello, World! 😀 Hello CloudNeta Study! The time is #{Time.now}&amp;quot;</span>
<span class="c">#    end</span>

<span class="c"># 컨테이너 이미지 빌드</span>
<span class="nv">$ </span>docker build <span class="nb">.</span> <span class="nt">-t</span> timeserver:2 <span class="nt">-t</span> timeserver:latest
<span class="nv">$ </span>docker image <span class="nb">ls</span> <span class="nt">-f</span> <span class="nv">reference</span><span class="o">=</span>timeserver
<span class="c"># =&gt; REPOSITORY   TAG       IMAGE ID       CREATED          SIZE</span>
<span class="c">#    timeserver   2         80f230757e3c   2 seconds ago    1.01GB</span>
<span class="c">#    timeserver   latest    80f230757e3c   2 seconds ago    1.01GB</span>
<span class="c">#    timeserver   1         c7055ab70155   27 minutes ago   1.01GB</span>

<span class="c"># 컨테이너 실행</span>
<span class="nv">$ </span>docker run <span class="nt">-d</span> <span class="nt">-p</span> 8080:4567 <span class="nt">--name</span><span class="o">=</span>timeserver timeserver
<span class="c"># =&gt; 278108d26b3998c8281add75b631d59a9d44abd4eb3e4f173b0b156d66e5da75</span>

<span class="c"># 컨테이너 접속 및 로그 확인</span>
<span class="nv">$ </span>curl http://localhost:8080
<span class="c"># =&gt; Hello, World! 😀 Hello CloudNeta Study! The time is 2024-10-01 15:55:19 +0000</span>

<span class="c"># 컨테이너 삭제</span>
<span class="nv">$ </span>docker <span class="nb">rm</span> <span class="nt">-f</span> timeserver
</code></pre></div></div>

<h4 id="로컬-개발을-위한-방안">로컬 개발을 위한 방안</h4>

<ul>
  <li>소스를 수정할 때마다 위와 같이 컨테이너 이미지를 빌드하고 실행하는 것은 번거롭습니다.</li>
  <li>이를 편리하게 하기 위해서 로컬 폴더와 컨테이너의 앱 소스를 매핑하고, 코드 내용을 동적으로 반영해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">mkdir </span>1.5 <span class="o">&amp;&amp;</span> <span class="nb">cd </span>1.5

<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> app.rb <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
require 'sinatra/base'

class App &lt; Sinatra::Base
  get '/' do
    "Hello, World! The time is #{Time.now}"
  end
end
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> config.ru <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
require 'rack/unreloader'
require 'sinatra'
Unreloader = Rack::Unreloader.new{App}
Unreloader.require './app.rb'

run Unreloader
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Dockerfile <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
FROM ruby:3.3
RUN gem install sinatra rackup puma </span><span class="se">\</span><span class="sh">
    rack-unreloader # 소스코드 변경시 자동으로 반영하기위한 툴
COPY app.rb config.ru /app/
WORKDIR /app
CMD ["rackup", "--host", "0.0.0.0"]
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> docker-compose.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
services:
  frontend:
    build: .
    command: rackup --host 0.0.0.0
    volumes:
      - type: bind
        source: .
        target: /app
    ports:
      - "8080:9292"
</span><span class="no">EOF

</span><span class="c"># 도커 컴포즈로 컨테이너 빌드</span>
<span class="nv">$ </span>docker compose build 
<span class="c"># 도커 컴포즈로 컨테이너 실행 </span>
<span class="nv">$ </span>docker compose up <span class="nt">-d</span>
<span class="c"># =&gt; [+] Running 1/1</span>
<span class="c">#     ⠿ Container 15-frontend-1  Started 0.4s</span>

<span class="c"># 컴포즈로 실행 시 이미지와 컨테이너 네이밍 규칙을 알아보자!</span>
<span class="nv">$ </span>docker compose ps
<span class="c"># =&gt; NAME                COMMAND                  SERVICE             STATUS              PORTS</span>
<span class="c">#    15-frontend-1       &amp;quot;rackup --host 0.0.0…&amp;quot;   frontend            running             0.0.0.0:8080-&amp;gt;9292/tcp</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 컴포즈로 실행시 현재 디렉터리 이름에서 특수문자를 제외한 것에 컨테이너 이름에 "-1"를 붙이는듯 합니다.&lt;/span&gt;</span>

<span class="nv">$ </span>docker compose images
<span class="c"># =&gt; Container           Repository          Tag                 Image Id            Size</span>
<span class="c">#    15-frontend-1       15_frontend         latest              4aa2b680f319        1.01GB</span>

<span class="c">#</span>
<span class="nv">$ </span>curl http://localhost:8080
<span class="c"># =&gt; Hello, World! The time is 2024-10-01 05:55:18 +0000!!!!!%</span>
<span class="nv">$ </span>docker compose logs
<span class="c"># =&gt; 15-frontend-1  | Puma starting in single mode...</span>
<span class="c">#    15-frontend-1  | * Puma version: 6.5.0 (&amp;quot;Sky's Version&amp;quot;)</span>
<span class="c">#    15-frontend-1  | * Ruby version: ruby 3.3.6 (2024-10-01 revision 75015d4c1f) [aarch64-linux]</span>
<span class="c">#    15-frontend-1  | *  Min threads: 0</span>
<span class="c">#    15-frontend-1  | *  Max threads: 5</span>
<span class="c">#    15-frontend-1  | *  Environment: development</span>
<span class="c">#    15-frontend-1  | *          PID: 1</span>
<span class="c">#    15-frontend-1  | * Listening on http://0.0.0.0:9292</span>
<span class="c">#    15-frontend-1  | Use Ctrl-C to stop</span>
<span class="c">#    15-frontend-1  | 172.23.0.1 - - [01/Oct/2024:03:58:23 +0000] &amp;quot;GET / HTTP/1.1&amp;quot; 200 51 0.0153</span>
</code></pre></div></div>

<ul>
  <li>소스코드 수정 후 반영 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat </span>app.rb
<span class="c"># =&gt; require 'sinatra/base'</span>
<span class="c">#    </span>
<span class="c">#    class App &amp;lt; Sinatra::Base</span>
<span class="c">#      get '/' do</span>
<span class="c">#        &amp;quot;Hello, World! The time is #{Time.now}&amp;quot;</span>
<span class="c">#      end</span>
<span class="c">#    end</span>

<span class="c"># 소스코드 수정</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s1">'s#World!#World! 😀 Hello CloudNeta Study!#'</span> app.rb
<span class="nv">$ </span><span class="nb">cat </span>app.rb
<span class="c"># =&gt; require 'sinatra/base'</span>
<span class="c">#    </span>
<span class="c">#    class App &amp;lt; Sinatra::Base</span>
<span class="c">#      get '/' do</span>
<span class="c">#        &amp;quot;Hello, World! 😀 Hello CloudNeta Study! The time is #{Time.now}!!!!!&amp;quot;</span>
<span class="c">#      end</span>
<span class="c">#    end</span>

<span class="nv">$ </span>curl http://localhost:8080
<span class="c"># =&gt; Hello, World! 😀 Hello CloudNeta Study! The time is 2024-10-01 05:57:05 +0000!!!!!</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 변경사항이 잘 반영되었습니다. :)&lt;/span&gt;</span>

<span class="c"># 컨테이너 중지 및 삭제</span>
<span class="nv">$ </span>docker compose down
</code></pre></div></div>

<h3 id="cicd-실습환경-구성">CI/CD 실습환경 구성</h3>

<ul>
  <li>Jenkins와 Gitlab을 이용하여 CI/CD 파이프라인을 구축해보겠습니다.</li>
  <li>Jenkins는 Docker에 설치해서 사용하고 Gitlab은 <a href="https://www.gitlab.com">gitlab.com</a>를 사용하겠습니다.</li>
</ul>

<h4 id="jenkins-소개">Jenkins 소개</h4>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_7.png" alt="img.png" class="image-center" /></p>
<ul>
  <li>Jenkins는 오픈소스 CI/CD 도구로, 빌드, 테스트, 배포 등의 작업을 자동화할 수 있습니다.</li>
  <li>Jenkins는 CI/CD라는 용어가 있기 전부터 사용되던 도구로, CI/CD에 국한되지 않고 다양한 작업을 자동화할 수 있습니다.</li>
  <li>주요 기능은 다음과 같습니다.
    <ol>
      <li><strong>확장성</strong> : 다양한 플러그인 생태계를 가지고 있어 기능을 확장할 수 있습니다. Git, Docker, Kubernetes 등 다양한 도구 및 플랫폼과 통합할 수 있습니다.</li>
      <li><strong>분산 빌드</strong> : 분산 빌드를 지원하여 여러 머신에서 작업을 실행할 수 있습니다. 이를 통해 부하를 분산시키고 빌드 속도를 높일 수 있습니다.</li>
      <li><strong>자동화된 테스트</strong> : 테스트 실행을 자동화하여 코드 품질에 대한 즉각적인 피드백을 제공합니다. 다양한 테스트 프레임워크 및 도구를 지원합니다.</li>
      <li><strong>코드 파이프라인</strong> : Jenkinsfile을 사용하여 빌드, 테스트, 배포 파이프라인을 코드로 정의할 수 있습니다. 이를 통해 버전 관리와 협업이 용이합니다.</li>
      <li><strong>지속적 통합 및 지속적 배포 (CI/CD)</strong> : 코드 변경 사항을 통합하고, 애플리케이션을 빌드하고, 테스트를 실행하고, 배포하는 과정을 자동화합니다. 이를 통해 일관되고 신뢰할 수 있는 배포 프로세스를 보장합니다.</li>
    </ol>
  </li>
  <li>흔히 사용되는 CI/CD 워크플로우는 다음과 같습니다.
    <ol>
      <li><strong>최신 코드 가져오기</strong> : 개발을 위해 중앙 코드 리포지터리에서 로컬 시스템으로 애플리케이션의 최신 코드를 가져</li>
      <li><strong>단위 테스트 구현과 실행</strong> : 코드 작성 전 단위 테스트 케이스를 먼저 작성</li>
      <li><strong>코드 개발</strong> : 실패한 테스트 케이스를 성공으로 바꾸면서 코드 개발</li>
      <li><strong>단위 테스트 케이스 재실행</strong> : 단위 테스트 케이스 실행 시 통과(성공!)</li>
      <li><strong>코드 푸시와 병합</strong> : 개발 소스 코드를 중앙 리포지터리로 푸시하고, 코드 병합</li>
      <li><strong>코드 병합 후 컴파일</strong> : 변경 함수 코드가 병함되면 전체 애플리케이션이 컴파일된다</li>
      <li><strong>병합된 코드에서 테스트 실행</strong> : 개별 테스트뿐만 아니라 전체 통합 테스트를 실행하여 문제 없는지 확인</li>
      <li><strong>아티팩트 배포</strong> : 애플리케이션을 빌드하고, 애플리케이션 서버의 프로덕션 환경에 배포</li>
      <li><strong>배포 애플리케이션의 E-E 테스트 실행</strong> : 셀레늄 Selenium과 같은 User Interface 자동화 도구를 통해 애플리케이션의 전체 워크플로가 정상 동작하는지 확인하는 종단간 End-to-End 테스트를 실행.</li>
    </ol>
  </li>
  <li>이러한 워크플로우를 코드 커밋/푸시와 같은 이벤트가 발생할 때 자동으로 실행되도록 설정할 수 있습니다.</li>
</ul>

<h5 id="jenkins-컨테이너에서-호스트에-도커-데몬-사용-설정">Jenkins 컨테이너에서 호스트에 도커 데몬 사용 설정</h5>

<ul>
  <li>컨테이너에서 도커를 사용하기 위해서는 DinD(Docker in Docker)를 사용하여 컨테이너 안에서 도커를 실행하거나
DooD(Docker outside of Docker)를 사용하여 호스트의 도커 데몬을 사용할 수 있습니다.</li>
  <li>이번에는 Docker outside of Docker를 사용하여 호스트의 도커 데몬을 사용하겠습니다.
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_8.png" alt="img.png" class="image-center" />
<em class="image-caption">DinD와 DooD 구조 비교</em></li>
</ul>

<h4 id="jenkins-컨테이너-실행-및-설정">Jenkins 컨테이너 실행 및 설정</h4>

<ul>
  <li>먼저 Jenkins 컨테이너를 실행하겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 작업 디렉토리 생성 후 이동</span>
<span class="nv">$ </span><span class="nb">mkdir </span>cicd-labs <span class="o">&amp;&amp;</span> <span class="nb">cd </span>cicd-labs

<span class="c"># </span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh"> &gt; docker-compose.yaml
services:
  jenkins:
    container_name: jenkins
    image: jenkins/jenkins
    restart: unless-stopped
    networks:
      - cicd-network
    ports:
      - "8080:8080"
      - "50000:50000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - jenkins_home:/var/jenkins_home
volumes:
  jenkins_home:
networks:
  cicd-network:
    driver: bridge
</span><span class="no">EOT

</span><span class="c"># 배포</span>
<span class="nv">$ </span>docker compose up <span class="nt">-d</span>
<span class="c"># =&gt; [+] Running 13/13</span>
<span class="c">#     ⠿ jenkins Pulled                                                                                                                                                      13.7s</span>
<span class="c">#    [+] Running 3/3</span>
<span class="c">#     ⠿ Network cicd-labs_cicd-network   Created                                                                                                                             0.0s</span>
<span class="c">#     ⠿ Volume &amp;quot;cicd-labs_jenkins_home&amp;quot;  Created                                                                                                                             0.0s</span>
<span class="c">#     ⠿ Container jenkins                Started</span>
<span class="nv">$ </span>docker compose ps
<span class="c"># =&gt; NAME                COMMAND                  SERVICE             STATUS              PORTS</span>
<span class="c">#    jenkins             &amp;quot;/usr/bin/tini -- /u…&amp;quot;   jenkins             running             0.0.0.0:8080-&amp;gt;8080/tcp, 0.0.0.0:50000-&amp;gt;50000/tcp</span>

<span class="c"># 기본 정보 확인</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>jenkins <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; container : </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker compose <span class="nb">exec</span> <span class="nv">$i</span> sh <span class="nt">-c</span> <span class="s2">"whoami &amp;&amp; pwd"</span><span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; container : jenkins &amp;lt;&amp;lt;</span>
<span class="c">#    jenkins</span>
<span class="c">#    /</span>

<span class="c"># 도커를 이용하여 컨테이너로 접속</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins bash
<span class="nv">$ </span><span class="nb">exit</span>
</code></pre></div></div>

<ul>
  <li>Jenkins 초기 설정을 진행하겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 초기 비밀번호 확인</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins <span class="nb">cat</span> /var/jenkins_home/secrets/initialAdminPassword
<span class="c"># =&gt; dcc757c8c4f14fc09795ed0440baf157</span>

<span class="c"># 브라우저에서 접속하여 초기 비밀번호 입력후 설정 진행 : 계정 / 암호 입력 &gt;&gt; admin / qwe123</span>
<span class="nv">$ </span>open http://localhost:8080
</code></pre></div></div>

<ul>
  <li>jenkins 컨테이너에서 호스트의 도커 데몬을 사용하기 위해 설정을 진행하겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># jenkins 컨테이너에서 호스트의 도커 데몬을 사용하기 위한 설정</span>
<span class="nv">$ </span>docker compose <span class="nb">exec</span> <span class="nt">--privileged</span> <span class="nt">-u</span> root jenkins bash
<span class="nt">-----------------------------------------------------</span>
<span class="nv">$ </span><span class="nb">id</span>
<span class="c"># =&gt; uid=0(root) gid=0(root) groups=0(root)</span>

<span class="nv">$ </span>curl <span class="nt">-fsSL</span> https://download.docker.com/linux/debian/gpg <span class="nt">-o</span> /etc/apt/keyrings/docker.asc
<span class="nv">$ </span><span class="nb">chmod </span>a+r /etc/apt/keyrings/docker.asc
<span class="nv">$ </span><span class="nb">echo</span> <span class="se">\</span>
  <span class="s2">"deb [arch=</span><span class="si">$(</span>dpkg <span class="nt">--print-architecture</span><span class="si">)</span><span class="s2"> signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/debian </span><span class="se">\</span><span class="s2">
  </span><span class="si">$(</span><span class="nb">.</span> /etc/os-release <span class="o">&amp;&amp;</span> <span class="nb">echo</span> <span class="s2">"</span><span class="nv">$VERSION_CODENAME</span><span class="s2">"</span><span class="si">)</span><span class="s2"> stable"</span> | <span class="se">\</span>
  <span class="nb">tee</span> /etc/apt/sources.list.d/docker.list <span class="o">&gt;</span> /dev/null
<span class="nv">$ </span>apt-get update <span class="o">&amp;&amp;</span> apt <span class="nb">install </span>docker-ce-cli curl tree jq <span class="nt">-y</span>

<span class="nv">$ </span>docker info
<span class="c"># =&gt; Client: Docker Engine - Community</span>
<span class="c">#     Version:    27.3.1</span>
<span class="c">#     Context:    default</span>
<span class="c">#     Debug Mode: false</span>
<span class="c">#     Plugins:</span>
<span class="c">#      buildx: Docker Buildx (Docker Inc.)</span>
<span class="c">#        Version:  v0.17.1</span>
<span class="c">#        Path:     /usr/libexec/docker/cli-plugins/docker-buildx</span>
<span class="c">#      compose: Docker Compose (Docker Inc.)</span>
<span class="c">#        Version:  v2.29.7</span>
<span class="c">#        Path:     /usr/libexec/docker/cli-plugins/docker-compose</span>
<span class="c">#    </span>
<span class="c">#    Server:</span>
<span class="c">#     Containers: 27</span>
<span class="c">#      Running: 3</span>
<span class="c">#      Paused: 0</span>
<span class="c">#      Stopped: 24</span>
<span class="c">#     Images: 37</span>
<span class="c">#     Server Version: 20.10.12</span>
<span class="c">#     Storage Driver: overlay2</span>
<span class="c">#      Backing Filesystem: extfs</span>
<span class="c">#      Supports d_type: true</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE                  COMMAND                  CREATED          STATUS          PORTS                                              NAMES</span>
<span class="c">#    06409fe2219f   jenkins/jenkins        &amp;quot;/usr/bin/tini -- /u…&amp;quot;   25 minutes ago   Up 25 minutes   0.0.0.0:8080-&amp;gt;8080/tcp, 0.0.0.0:50000-&amp;gt;50000/tcp   jenkins</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 Docker-out-of-Docker 이기 때문에 호스트 도커 데몬에서 운영되는 컨테이너를 볼 수 있습니다!&lt;/span&gt;</span>
<span class="nv">$ </span>which docker
<span class="c"># =&gt; /usr/bin/docker</span>

<span class="c"># Jenkins 컨테이너 내부에서 root가 아닌 jenkins 유저도 docker를 실행할 수 있도록 권한을 부여</span>
<span class="nv">$ </span>groupadd <span class="nt">-g</span> 2000 <span class="nt">-f</span> docker
<span class="nv">$ </span><span class="nb">chgrp </span>docker /var/run/docker.sock
<span class="nv">$ </span><span class="nb">chmod </span>770 /var/run/docker.sock
<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-l</span> /var/run/docker.sock
<span class="c"># =&gt; srwxr-xr-x 1 root docker 0 Dec  7 03:12 /var/run/docker.sock</span>
<span class="nv">$ </span>usermod <span class="nt">-aG</span> docker jenkins
<span class="nv">$ </span><span class="nb">cat</span> /etc/group | <span class="nb">grep </span>docker
<span class="c"># =&gt; docker:x:2000:jenkins</span>

<span class="nv">$ </span><span class="nb">exit</span>
<span class="nt">--------------------------------------------</span>

<span class="c"># jenkins item 실행 시 docker 명령 실행 권한 에러 발생 : Jenkins 컨테이너 재기동으로 위 설정 내용을 Jenkins app 에도 적용 필요</span>
<span class="nv">$ </span>docker compose restart jenkins
<span class="c"># $ sudo docker compose restart jenkins  # Windows 경우 이후부터 sudo 붙여서 실행</span>

<span class="c"># jenkins user로 docker 명령 실행 확인</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins <span class="nb">id</span>
<span class="c"># =&gt; uid=1000(jenkins) gid=1000(jenkins) groups=1000(jenkins),2000(docker)</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins docker info
<span class="c"># =&gt; Client: Docker Engine - Community</span>
<span class="c">#     Version:    27.3.1</span>
<span class="c">#     Context:    default</span>
<span class="c">#     ...</span>
<span class="c">#    </span>
<span class="c">#    Server:</span>
<span class="c">#     Containers: 27</span>
<span class="c">#      Running: 3</span>
<span class="c">#      Paused: 0</span>
<span class="c">#      Stopped: 24</span>
<span class="c">#     Images: 37</span>
<span class="c">#     Server Version: 20.10.12</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE                  COMMAND                  CREATED          STATUS         PORTS                                              NAMES</span>
<span class="c">#    06409fe2219f   jenkins/jenkins        &amp;quot;/usr/bin/tini -- /u…&amp;quot;   30 minutes ago   Up 2 minutes   0.0.0.0:8080-&amp;gt;8080/tcp, 0.0.0.0:50000-&amp;gt;50000/tcp   jenkins</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<h4 id="gitlab-소개">Gitlab 소개</h4>

<ul>
  <li>Gitlab은 Github와 유사한 Git 기반의 코드 저장소 서비스로, 코드 저장소, 이슈 트래커, CI/CD 파이프라인, 코드 검토 등의 기능을 제공합니다.
<a href="https://www.gitlab.com">Gitlab.com</a></li>
  <li>이번 실습에서는 코드 저장소 기능만 사용하고 Jenkins의 CI/CD 파이프라인을 사용하겠습니다.</li>
  <li>주요 기능
    <ul>
      <li><strong>소스 코드 관리</strong> : GitLab은 Git 기반의 소스 코드 저장소를 제공하여 버전 관리를 쉽게 할 수 있습니다.</li>
      <li><strong>CI/CD 파이프라인</strong> : GitLab은 CI/CD 파이프라인을 통해 코드의 빌드, 테스트, 배포를 자동화할 수 있습니다.</li>
      <li><strong>이슈 트래킹</strong> : 프로젝트의 버그, 기능 요청 등을 관리할 수 있는 이슈 트래킹 시스템을 제공합니다.</li>
      <li><strong>코드 리뷰</strong> : 병합 요청(Merge Request)을 통해 코드 리뷰를 쉽게 진행할 수 있습니다.</li>
      <li><strong>위키</strong> : 프로젝트 관련 문서를 작성하고 관리할 수 있는 위키 기능을 제공합니다.</li>
      <li><strong>프로젝트 관리</strong> : 마일스톤, 보드, 라벨 등을 통해 프로젝트를 체계적으로 관리할 수 있습니다.</li>
      <li><strong>통합 및 확장성</strong> : 다양한 외부 도구와의 통합 및 확장을 지원하여 유연한 개발 환경을 구축할 수 있습니다.</li>
      <li><strong>셀프 호스트 가능</strong> : GitLab은 오픈소스로 제공되어 무료로 자체 서버에 설치하여 사용할 수 있습니다. (일부 기능 차이가 있음)</li>
    </ul>
  </li>
</ul>

<h4 id="gitlab-프로젝트-생성-및-설정">Gitlab 프로젝트 생성 및 설정</h4>

<ul>
  <li>
    <p>Gitlab.com에서 새로운 프로젝트를 생성하겠습니다.
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_9.png" alt="img.png" class="image-center" />
<em class="image-caption">Gitlab 프로젝트 생성</em></p>
  </li>
  <li>
    <p>프로젝트 생성시 프로젝트 이름과 가시성을 설정하고 생성합니다.</p>
    <ul>
      <li><strong>프로젝트 이름</strong> : 2024-cicd-lite-w1</li>
      <li><strong>가시성</strong> : Private</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_10.png" alt="img_1.png" class="image-center" />
<em class="image-caption">Jenkins와 연동을 위해 토큰 발급</em></p>

<ul>
  <li>프로젝트 생성 후 프로젝트 설정에서 CI/CD 파이프라인을 위한 토큰을 발급받습니다.</li>
  <li>프로필 아이콘 클릭 &gt; Preferences &gt; Access Tokens &gt; Add new token을 클릭하여 토큰을 발급받습니다.
    <ul>
      <li><strong>토큰 이름</strong> : jenkins</li>
      <li><strong>권한</strong> : read_repository, write_repository</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_11.png" alt="img_2.png" class="image-center" />
<em class="image-caption">토큰 발급 완료</em></p>

<ul>
  <li>토큰이 완료되면 복사할 수 있습니다. 이후에는 다시 확인할 수 없으므로 잘 기록해두어야 합니다.</li>
</ul>

<h5 id="gitlab에서-소스-받기">Gitlab에서 소스 받기</h5>

<ul>
  <li>소스를 받기 위해 git 주소를 복사합니다.
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_12.png" alt="img.png" class="image-center" />
<em class="image-caption">Gitlab 프로젝트 주소 복사</em></li>
  <li>프로젝트 페이지에 접속 후 Code 버튼을 클릭하고 클립보드 아이콘을 클릭하여 주소를 복사할 수 있습니다.</li>
  <li>복사한 주소로 소스를 받아서 필요한 파일들을 생성해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># &lt;span style="color: green;"&gt;👉 아이디와 비밀번호를 물으면 토큰이름과 발급받은 토큰을 입력하시면 됩니다.&lt;/span&gt;</span>
<span class="nv">$ </span>git clone https://gitlab.com/littlebird/2024-cicd-lite-w1.git
<span class="c"># =&gt; Cloning into '2024-cicd-lite-w1'...</span>
<span class="c">#    Username for 'https://gitlab.com': jenkins</span>
<span class="c">#    Password for 'https://jenkins@gitlab.com': glpat-ABCD1234</span>
<span class="c">#    remote: Enumerating objects: 3, done.</span>
<span class="c">#    remote: Counting objects: 100% (3/3), done.</span>
<span class="c">#    remote: Compressing objects: 100% (2/2), done.</span>
<span class="c">#    remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)</span>
<span class="c">#    Receiving objects: 100% (3/3), done.</span>
<span class="nv">$ </span><span class="nb">cd </span>2024-cicd-lite-w1/

<span class="c"># 소스코드 작성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> app.rb <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
require 'sinatra'

get '/' do
  "Hello, World! The time is #{Time.now}"
end
</span><span class="no">EOF

</span><span class="c"># Dockerfile 작성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Dockerfile <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
FROM ruby:3.3
RUN gem install sinatra rackup puma
COPY app.rb /app/
WORKDIR /app
CMD ["ruby", "app.rb", "-o", "0.0.0.0"]
</span><span class="no">EOF

</span><span class="c"># VERSION 파일 생성</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"0.0.1"</span> <span class="o">&gt;</span> VERSION

<span class="c">#</span>
<span class="nv">$ </span>git add <span class="nb">.</span>
<span class="nv">$ </span>git commit <span class="nt">-m</span> <span class="s2">"Initial commit"</span>
<span class="c"># =&gt; [main 569ce3c] Initial commit</span>
<span class="c">#     3 files changed, 11 insertions(+)</span>
<span class="c">#     create mode 100644 Dockerfile</span>
<span class="c">#     create mode 100644 VERSION</span>
<span class="c">#     create mode 100644 app.rb</span>
<span class="nv">$ </span>git push <span class="nt">-u</span> origin main
<span class="c"># =&gt; Enumerating objects: 6, done.</span>
<span class="c">#    Counting objects: 100% (6/6), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (4/4), done.</span>
<span class="c">#    Writing objects: 100% (5/5), 536 bytes | 536.00 KiB/s, done.</span>
<span class="c">#    Total 5 (delta 0), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To https://gitlab.com/littlebird/2024-cicd-lite-w1.git</span>
<span class="c">#       fe2fb73..569ce3c  main -&amp;gt; main</span>
<span class="c">#    branch 'main' set up to track 'origin/main'.</span>
</code></pre></div></div>

<ul>
  <li>Gitlab 리파지토리에서 확인해보겠습니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_13.png" alt="img.png" /></p>

<ul>
  <li>Gitlab 프로젝트에 소스가 정상적으로 업로드 되었습니다.</li>
</ul>

<h4 id="docker-hub-소개">Docker Hub 소개</h4>

<ul>
  <li><a href="https://hub.docker.com">도커허브(Docker Hub)</a>는 도커 이미지를 저장하고 공유할 수 있는 클라우드 서비스입니다.</li>
  <li>여러 사용자가 자신이 만든 도커 이미지를 서로 자유롭게 공유할 수 있습니다.</li>
  <li>유의 사항
    <ul>
      <li>Docker Hub는 무료로 누구나 업로드 할 수 있기 때문에, 공식(Official) 라벨이 없는 이미지는 보안에 취약할 수 있고, 사용법을 알 수 없거나, 제대로 작동하지 않을 수 있습니다.</li>
      <li>도커 악성 이미지를 통한 취약점 공격 기사 모음
        <ul>
          <li>도커도 이제 공격 통로! 악성 이미지 늘어나고 있다 - <a href="https://www.boannews.com/media/view.asp?idx=93080&amp;page=1&amp;kind=1">링크</a></li>
          <li>도커 환경 공격하는 해커들, 전략을 또 변경했다 - <a href="https://www.boannews.com/media/view.asp?idx=89841&amp;page=1&amp;kind=1">링크</a></li>
          <li>암호화폐 채굴 공격자들, 잘못 설정된 도커 집중 공략 - <a href="https://www.boannews.com/media/view.asp?idx=87427&amp;page=1&amp;kind=1">링크</a></li>
          <li>리눅스 노리던 봇넷 멀웨어 둘, 최근 들어 도커 서버도 노리기 시작 - <a href="https://www.boannews.com/media/view.asp?idx=89205&amp;page=1&amp;kind=1">링크</a></li>
          <li>도커 호스트 감염시켜가며 암호화폐 채굴하는 웜 발견 - <a href="https://www.boannews.com/media/view.asp?idx=83854&amp;page=1&amp;kind=1">링크</a>  *</li>
        </ul>
      </li>
      <li>사용자당 1개의 Private Repository만 무료로 사용할 수 있습니다.</li>
    </ul>
  </li>
  <li>주요 기능
    <ul>
      <li><strong>도커 이미지 저장소</strong> : 도커 이미지를 저장하고 공유할 수 있습니다.</li>
      <li><strong>자동 빌드</strong> : Github, Gitlab과 연동하여 코드가 업데이트 될 때마다 자동으로 이미지를 빌드할 수 있습니다.</li>
      <li><strong>웹훅</strong> : 타 서비스와 연동하여 이벤트가 발생할 때마다 특정 URL로 요청을 보낼 수 있습니다.</li>
      <li><strong>Docker Hub CLI 도구</strong> : 도커 이미지를 커맨드라인으로 관리할 수 있는 도구를 제공합니다.</li>
    </ul>
  </li>
</ul>

<h4 id="docker-hub에-dev-app-private-repo-생성">Docker Hub에 dev-app (private) repo 생성</h4>

<ul>
  <li>Docker Hub에 dev-app이라는 private 리포지토리를 생성하겠습니다.</li>
  <li>Docker Hub에 로그인 후 Repositories &gt; Create Repository를 클릭하여 리포지토리를 생성합니다.
    <ul>
      <li><strong>Repository Name</strong> : dev-app</li>
      <li><strong>Visibility</strong> : Private</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_14.png" alt="img.png" /></p>

<h3 id="jenkins-기본-사용">Jenkins 기본 사용</h3>

<ul>
  <li>Jenkins를 사용하여 CI/CD 파이프라인을 구축해보겠습니다.</li>
  <li>작업 소개
    <ol>
      <li><strong>Trigger</strong> : 작업을 수행하는 시점을 지정합니다.
        <ul>
          <li>작업 수행 태스크 task가 언제 시작될지를 지시할 수 있습니다.</li>
        </ul>
      </li>
      <li><strong>Built step</strong> : 작업을 구성하는 단계별 태스크를 지정합니다.
        <ul>
          <li>특정 목표를 수행하기 위한 태스크를 단계별 step로 구성할 수 있습니다.</li>
          <li>이것을 젠킨스에서는 빌드 스텝 build step이라고 부릅니다.</li>
        </ul>
      </li>
      <li><strong>Post-build action</strong> : 태스크가 완료 후 수행할 명령을 지정합니다.
        <ul>
          <li>예를 들어 작업의 결과(성공 or 실패)를 사용자에게 알려주는 후속 동작이나, 자바 코드를 컴파일한 후 생성된 클래스 파일을 특정 위치로 복사 등의 작업을 수행할 수 있습니다.
     - (참고) 젠킨스의 <strong>빌드</strong> : 젠킨스 작업의 특정 실행 버전
       - 사용자는 젠킨스 작업을 여러번 실행할 수 있는데, 실행될 때마다 <strong>고유 빌드 번호</strong>가 부여됩니다.
       - 작업 실행 중에 생성된 <strong>아티팩트</strong>, <strong>콘솔 로드</strong> 등 특정 실행 버전과 관련된 모든 세부 정보가 해당 빌드 번호로 저장됩니다.</li>
        </ul>
      </li>
    </ol>
  </li>
  <li>첫번째 작업 생성
    <ul>
      <li>name : first</li>
      <li>item type : freestyle project</li>
      <li>Build Steps : Execute shell
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">echo</span> <span class="s2">"docker check"</span> | <span class="nb">tee </span>test.txt
docker ps
</code></pre></div>        </div>
        <p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_15.png" alt="img.png" class="image-center" />
<em class="image-caption">Jenkins 첫번째 작업 생성</em></p>
      </li>
    </ul>
  </li>
  <li>
    <p>“Build Now”(지금 실행) 메뉴를 클릭하여 작업을 실행합니다.
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_16.png" alt="img.png" class="image-center" />
<em class="image-caption">빌드 결과 (Console Output)</em></p>
  </li>
  <li>작업 공간 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins <span class="nb">ls</span> /var/jenkins_home/workspace
<span class="c"># =&gt; first</span>

<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins <span class="nb">ls</span> /var/jenkins_home/workspace/first
<span class="c"># =&gt; test.txt</span>

<span class="c"># 작업 결과 확인</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins <span class="nb">cat</span> /var/jenkins_home/workspace/first/test.txt
<span class="c"># =&gt; docker check</span>
</code></pre></div></div>

<h4 id="jenkins-플러그인-설치">Jenkins 플러그인 설치</h4>

<ul>
  <li>Jenkins 플러그인을 설치하여 더 다양한 기능을 사용할 수 있습니다.</li>
  <li>Dashboard &gt; Manage Jenkins 메뉴를 클릭하고, 플러그인 관리를 클릭합니다.</li>
  <li>Available plugins 를 클릭하여 다양한 플러그인을 설치할 수 있습니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_17.png" alt="img.png" class="image-center" />
<em class="image-caption">Jenkins 플러그인 설치 화면</em></p>

<ul>
  <li>다음의 plugin 을 설치합니다.
    <ul>
      <li><strong>Pipeline Stage View</strong> : 파이프라인 스테이지를 시각적으로 보여주는 플러그인 <a href="https://plugins.jenkins.io/pipeline-stage-view/">링크</a></li>
      <li><strong>Docker Pipeline</strong> : 파이프라인에서 도커를 사용할 수 있도록 지원하는 플러그인 <a href="https://plugins.jenkins.io/docker-workflow/">링크</a></li>
      <li><strong>Gitlab</strong> : Gitlab과 Jenkins를 연동할 수 있도록 지원하는 플러그인 <a href="https://plugins.jenkins.io/gitlab-plugin/">링크</a></li>
    </ul>
  </li>
  <li>Dashboard &gt; Manage Jenkins &gt; Credentials &gt; System &gt; Global credentials (unrestricted) &gt; Add Credentials 를 클릭하여 자격증명을 추가합니다.
    <ul>
      <li>Docker hub 크레덴셜
        <ul>
          <li>Kind : Username with password</li>
          <li>Username : <code class="language-plaintext highlighter-rouge">&lt;docker hub 계정&gt;</code></li>
          <li>Password : <code class="language-plaintext highlighter-rouge">&lt;docker hub 비밀번호 혹은 토큰&gt;</code></li>
          <li>ID : <code class="language-plaintext highlighter-rouge">dockerhub-credentials</code> =&gt; 자격증명 이름으로 pipeline에서 사용됩니다.</li>
        </ul>
      </li>
      <li>Gitlab 저장소 크레덴셜
        <ul>
          <li>Kind : Username with password</li>
          <li>Username : <code class="language-plaintext highlighter-rouge">&lt;gitlab 토큰 이름&gt;</code></li>
          <li>Password : <code class="language-plaintext highlighter-rouge">&lt;gitlab 토큰&gt;</code></li>
          <li>ID : <code class="language-plaintext highlighter-rouge">gitlab-credentials</code> =&gt; 자격증명 이름으로 pipeline에서 사용됩니다.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="파이프라인">파이프라인</h4>

<ul>
  <li>pipeline은 CI/CD 파이프라인을 코드로 정의하는 플러그인 스크립트입니다. <a href="https://www.jenkins.io/doc/book/pipeline/">docs</a></li>
</ul>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_18.png" alt="img.png" /></p>

<ul>
  <li>파이프라인의 <strong>장점</strong>
    <ul>
      <li><strong>코드</strong> : 애플리케이션 CI/CD 프로세스를 코드 형식으로 작성할 수 있고, 해당 코드를 중앙 리포지터리에 저장하여 팀원과 공유 및 작업 가능합니다.</li>
      <li><strong>내구성</strong> : 젠킨스 서비스가 의도적으로 또는 우발적으로 재시작되더라도 문제없이 유지됩니다.</li>
      <li><strong>일시 중지 가능</strong> : 파이프라인을 실행하는 도중 사람의 승인이나 입력을 기다리기 위해 중단하거나 기다리는 것이 가능합니다.</li>
      <li><strong>다양성</strong> : 분기나 반복, 병렬 처리와 같은 다양한 CI/CD 요구 사항을 지원합니다.</li>
    </ul>
  </li>
  <li>파이프라인 용어
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_19.png" alt="img.png" class="image-center" />
    <ul>
      <li><strong>Pipeline(파이프라인)</strong> : 전체 빌드 프로세스를 정의하는 코드</li>
      <li><strong>Node(노드) = Agent</strong> : 파이프라인을 실행하는 시스템</li>
      <li><strong>Stages</strong> : 순차 작업 명세인 stage 들의 묶음</li>
      <li><strong>Stage</strong> : 특정 단계에서 수행되는 작업들의 정의</li>
      <li><strong>Steps</strong> : 파이프라인의 특정 단계에서 수행되는 단일 작업을 의미.</li>
      <li><strong>Post</strong> : 빌드 후 조치, 일반적으로 stages 작업이 끝난 후 추가적인 steps/step</li>
      <li><strong>Directive</strong> - <a href="https://www.jenkins.io/doc/book/pipeline/syntax/#declarative-directives">Docs</a>
        <ul>
          <li><strong>Environment</strong> (key=value) : 파이프라인 내부에서 사용할 환경변수</li>
          <li><strong>Parameters</strong> : 입력 받아야할 변수를 정의 - Type(string, text, choice, password …)</li>
          <li><strong>Triggers</strong> : 파이프라인을 실행하는 조건 설정</li>
          <li><strong>Input</strong> : 파이프라인 실행 중 사용자 입력을 받을 수 있도록 설정</li>
          <li><strong>When</strong> : stage 를 실행 할 조건 설정</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>파이프라인 구성 형태 3가지
    <ol>
      <li><strong>Pipeline Script</strong> : 일반적인 방식으로 Jenkins 파이프라인을 생성하여 Shell Script 형태로 작성 <a href="https://www.jenkins.io/doc/book/pipeline/getting-started/#through-the-classic-ui">링크</a></li>
      <li><strong>Pipeline Script from SCM</strong> : Jenkinsfile을 git 등의 SCM(Source Code Management)에 저장하고, 빌드 시작 시 해당 파일을 읽어 파이프라인을 실행 <a href="https://www.jenkins.io/doc/book/pipeline/getting-started/#defining-a-pipeline-in-scm">링크</a></li>
      <li><strong>Blue Ocean 기반</strong> : Blue Ocean 플러그인을 설치하여 UI로 파이프라인을 구성하면 Jenkinsfile이 자동으로 생성됨 <a href="https://www.jenkins.io/doc/book/pipeline/getting-started/#through-blue-ocean">링크</a></li>
    </ol>
  </li>
  <li>파이프라인 구문 형태 2가지
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_20.png" alt="img.png" class="image-center w-80" />
<em class="image-caption">파이프라인 구문 형태별 구조</em>
    <ol>
      <li><strong>Declarative Pipeline</strong> : 간결하고 가독성이 좋으며, 최근 문법이고, 권장하는 방법. step은 필수로 사용
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pipeline <span class="o">{</span>
   agent any     <span class="c"># Execute this Pipeline or any of its stages, on any available agent.</span>
   stages <span class="o">{</span>
     stage<span class="o">(</span><span class="s1">'Build'</span><span class="o">)</span> <span class="o">{</span>   <span class="c"># Defines the "Build" stage.</span>
         steps <span class="o">{</span>
             //         <span class="c"># Perform some steps related to the "Build" stage.</span>
         <span class="o">}</span>
     <span class="o">}</span>
     stage<span class="o">(</span><span class="s1">'Test'</span><span class="o">)</span> <span class="o">{</span> 
         steps <span class="o">{</span>
             // 
         <span class="o">}</span>
     <span class="o">}</span>
     stage<span class="o">(</span><span class="s1">'Deploy'</span><span class="o">)</span> <span class="o">{</span> 
         steps <span class="o">{</span>
             // 
         <span class="o">}</span>
     <span class="o">}</span>
   <span class="o">}</span>
<span class="o">}</span>
</code></pre></div>        </div>
      </li>
      <li><strong>Scripted Pipeline</strong> : 커스텀이 용이하나 복잡도가 높고, step은 필수가 아님
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>node <span class="o">{</span>             <span class="c"># Execute this Pipeline or any of its stages, on any available agent.</span>
  stage<span class="o">(</span><span class="s1">'Build'</span><span class="o">)</span> <span class="o">{</span> <span class="c"># Defines the "Build" stage. stage blocks are optional in Scripted Pipeline syntax. However, implementing stage blocks in a Scripted Pipeline provides clearer visualization of each stage's subset of tasks/steps in the Jenkins UI.</span>
   //              <span class="c"># Perform some steps related to the "Build" stage.</span>
  <span class="o">}</span>
  stage<span class="o">(</span><span class="s1">'Test'</span><span class="o">)</span> <span class="o">{</span> 
   // 
  <span class="o">}</span>
  stage<span class="o">(</span><span class="s1">'Deploy'</span><span class="o">)</span> <span class="o">{</span> 
   // 
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div>        </div>
      </li>
    </ol>
  </li>
</ul>

<h5 id="jenkins-pipeline-실습">Jenkins Pipeline 실습</h5>

<ul>
  <li>New Item &gt; Pipeline 으로 파이프라인을 생성합니다.
    <ul>
      <li><strong>Name</strong> : First-Pipeline</li>
      <li><strong>Definition</strong> : Pipeline script</li>
      <li><strong>Script</strong> : 아래의 파이프라인 스크립트를 입력합니다.</li>
    </ul>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pipeline <span class="o">{</span>
    agent any

    stages <span class="o">{</span>
        stage<span class="o">(</span><span class="s1">'Hello'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                <span class="nb">echo</span> <span class="s1">'Hello World'</span>
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'Deploy'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                <span class="nb">echo</span> <span class="s2">"Deployed successfully!"</span><span class="p">;</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<ul>
  <li>
    <p>Save 하여 저장후 “Build Now”를 클릭하여 파이프라인을 실행합니다.
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_21.png" alt="img.png" class="image-center" />
<em class="image-caption">파이프라인 실행 결과</em></p>
  </li>
  <li>
    <p>아래 처럼 수정 후 확인: 환경변수 사용, 문자열 보간 → Console Output 확인</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pipeline <span class="o">{</span>
    agent any
    environment <span class="o">{</span> 
        CC <span class="o">=</span> <span class="s1">'clang'</span>
    <span class="o">}</span>
      
    stages <span class="o">{</span>
        stage<span class="o">(</span><span class="s1">'Example'</span><span class="o">)</span> <span class="o">{</span>
            environment <span class="o">{</span> 
                AN_ACCESS_KEY <span class="o">=</span> <span class="s1">'abcdefg'</span>
            <span class="o">}</span>
            steps <span class="o">{</span>
                <span class="nb">echo</span> <span class="s2">"</span><span class="k">${</span><span class="nv">CC</span><span class="k">}</span><span class="s2">"</span><span class="p">;</span>
                sh <span class="s1">'echo ${AN_ACCESS_KEY}'</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div>    </div>

    <p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_22.png" alt="img.png" class="image-center" />
<em class="image-caption">Console Output</em></p>
  </li>
  <li>
    <p>아래 처럼 수정 후 확인: 파이프라인 빌드 시작(트리거) → Console Output 확인</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pipeline <span class="o">{</span>
    agent any
    triggers <span class="o">{</span>
        cron<span class="o">(</span><span class="s1">'H */4 * * 1-5'</span><span class="o">)</span>
    <span class="o">}</span>
    stages <span class="o">{</span>
        stage<span class="o">(</span><span class="s1">'Example'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                <span class="nb">echo</span> <span class="s1">'Hello World'</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div>    </div>

    <p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_23.png" alt="img.png" class="image-center" />
<em class="image-caption">Console Output</em></p>
  </li>
  <li>
    <p>아래 처럼 수정 후 확인: 파라미터와 함께 빌드 → Console Output 확인 ⇒ 다시 한번 더 빌드 클릭 (변수 입력 칸 확인)</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pipeline <span class="o">{</span>
    agent any
    parameters <span class="o">{</span>
        string<span class="o">(</span>name: <span class="s1">'PERSON'</span>, defaultValue: <span class="s1">'Mr Jenkins'</span>, description: <span class="s1">'Who should I say hello to?'</span><span class="o">)</span>
        text<span class="o">(</span>name: <span class="s1">'BIOGRAPHY'</span>, defaultValue: <span class="s1">''</span>, description: <span class="s1">'Enter some information about the person'</span><span class="o">)</span>
        booleanParam<span class="o">(</span>name: <span class="s1">'TOGGLE'</span>, defaultValue: <span class="nb">true</span>, description: <span class="s1">'Toggle this value'</span><span class="o">)</span>
        choice<span class="o">(</span>name: <span class="s1">'CHOICE'</span>, choices: <span class="o">[</span><span class="s1">'One'</span>, <span class="s1">'Two'</span>, <span class="s1">'Three'</span><span class="o">]</span>, description: <span class="s1">'Pick something'</span><span class="o">)</span>
        password<span class="o">(</span>name: <span class="s1">'PASSWORD'</span>, defaultValue: <span class="s1">'SECRET'</span>, description: <span class="s1">'Enter a password'</span><span class="o">)</span>
    <span class="o">}</span>
    stages <span class="o">{</span>
        stage<span class="o">(</span><span class="s1">'Example'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                <span class="nb">echo</span> <span class="s2">"Hello </span><span class="k">${</span><span class="nv">params</span><span class="p">.PERSON</span><span class="k">}</span><span class="s2">"</span>
                <span class="nb">echo</span> <span class="s2">"Biography: </span><span class="k">${</span><span class="nv">params</span><span class="p">.BIOGRAPHY</span><span class="k">}</span><span class="s2">"</span>
                <span class="nb">echo</span> <span class="s2">"Toggle: </span><span class="k">${</span><span class="nv">params</span><span class="p">.TOGGLE</span><span class="k">}</span><span class="s2">"</span>
                <span class="nb">echo</span> <span class="s2">"Choice: </span><span class="k">${</span><span class="nv">params</span><span class="p">.CHOICE</span><span class="k">}</span><span class="s2">"</span>
                <span class="nb">echo</span> <span class="s2">"Password: </span><span class="k">${</span><span class="nv">params</span><span class="p">.PASSWORD</span><span class="k">}</span><span class="s2">"</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>파이프라인 스크립트를 수정하고 저장 후 “Build with Parameters”를 클릭하여 파라미터를 입력하고 빌드를 실행하면
아래와 같이 지정된 파라미터로 빌드를 실행할 수 있습니다.</p>
  </li>
</ul>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_24.png" alt="img.png" class="image-center" />
<em class="image-caption">Build with Parameters 화면</em></p>

<ul>
  <li>
    <p>아래처럼 post (빌드 후 조치) 블록을 추가하여 빌드 후 조치를 설정할 수 있습니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pipeline <span class="o">{</span>
    agent any
    stages <span class="o">{</span>
        stage<span class="o">(</span><span class="s1">'Compile'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                <span class="nb">echo</span> <span class="s2">"Compiled successfully!"</span><span class="p">;</span>
            <span class="o">}</span>
        <span class="o">}</span>
  
        stage<span class="o">(</span><span class="s1">'JUnit'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                <span class="nb">echo</span> <span class="s2">"JUnit passed successfully!"</span><span class="p">;</span>
            <span class="o">}</span>
        <span class="o">}</span>
  
        stage<span class="o">(</span><span class="s1">'Code Analysis'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                <span class="nb">echo</span> <span class="s2">"Code Analysis completed successfully!"</span><span class="p">;</span>
            <span class="o">}</span>
        <span class="o">}</span>
  
        stage<span class="o">(</span><span class="s1">'Deploy'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                <span class="nb">echo</span> <span class="s2">"Deployed successfully!"</span><span class="p">;</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
    post <span class="o">{</span> 
        always <span class="o">{</span> 
            <span class="nb">echo</span> <span class="s1">'I will always say Hello again!'</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div>    </div>

    <p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_25.png" alt="img.png" class="image-center w-80" />
<em class="image-caption">step 별 메시지와 post 메시지</em></p>

    <ul>
      <li>post에는 always 외에도 다음과 같은 옵션을 사용할 수 있습니다.
        <ul>
          <li><strong>always</strong> : 항상 실행</li>
          <li><strong>changed</strong> : 성공 또는 실패가 변경되었을 때 실행</li>
          <li><strong>success</strong> : 성공했을 때 실행</li>
          <li><strong>failure</strong> : 실패했을 때 실행</li>
          <li><strong>unstable</strong> : 불안정한 상태일 때 실행</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>Pipeline Syntax -&gt; Snippet Generator 를 사용하여 파이프라인 스크립트를 생성할 수 있습니다.
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_26.png" alt="img.png" class="image-center w-80" /></p>
  </li>
</ul>

<h5 id="gitlab과-jenkins-pipeline-연동-실습">Gitlab과 Jenkins pipeline 연동 실습</h5>

<ul>
  <li>Gitlab에서 소스를 받아 빌드 후 Docker Hub에 이미지를 업로드하는 파이프라인을 구성해보겠습니다.</li>
  <li>Pipeline script</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pipeline <span class="o">{</span>
    agent any
    environment <span class="o">{</span>
        DOCKER_IMAGE <span class="o">=</span> <span class="s1">'sweetlittlebird/dev-app'</span> // Docker 이미지 이름
    <span class="o">}</span>
    stages <span class="o">{</span>
        stage<span class="o">(</span><span class="s1">'Checkout'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                 git branch: <span class="s1">'main'</span>,
                 url: <span class="s1">'https://gitlab.com/littlebird/2024-cicd-lite-w1.git'</span>,  // Git에서 코드 체크아웃
                 credentialsId: <span class="s1">'gitlab-credentials'</span>  // Credentials ID
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'Read VERSION'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                script <span class="o">{</span>
                    // VERSION 파일 읽기
                    def version <span class="o">=</span> readFile<span class="o">(</span><span class="s1">'VERSION'</span><span class="o">)</span>.trim<span class="o">()</span>
                    <span class="nb">echo</span> <span class="s2">"Version found: </span><span class="k">${</span><span class="nv">version</span><span class="k">}</span><span class="s2">"</span>
                    // 환경 변수 설정
                    env.DOCKER_TAG <span class="o">=</span> version
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'Docker Build and Push'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                script <span class="o">{</span>
                    docker.withRegistry<span class="o">(</span><span class="s1">'https://index.docker.io/v1/'</span>, <span class="s1">'dockerhub-credentials'</span><span class="o">)</span> <span class="o">{</span>
                        // DOCKER_TAG 사용
                        def appImage <span class="o">=</span> docker.build<span class="o">(</span><span class="s2">"</span><span class="k">${</span><span class="nv">DOCKER_IMAGE</span><span class="k">}</span><span class="s2">:</span><span class="k">${</span><span class="nv">DOCKER_TAG</span><span class="k">}</span><span class="s2">"</span><span class="o">)</span>
                        appImage.push<span class="o">()</span>
                    <span class="o">}</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
    post <span class="o">{</span>
        success <span class="o">{</span>
            <span class="nb">echo</span> <span class="s2">"Docker image </span><span class="k">${</span><span class="nv">DOCKER_IMAGE</span><span class="k">}</span><span class="s2">:</span><span class="k">${</span><span class="nv">DOCKER_TAG</span><span class="k">}</span><span class="s2"> has been built and pushed successfully!"</span>
        <span class="o">}</span>
        failure <span class="o">{</span>
            <span class="nb">echo</span> <span class="s2">"Pipeline failed. Please check the logs."</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<ul>
  <li>
    <p>Build Now -&gt; Console Output 확인</p>

    <p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_27.png" alt="img.png" class="image-center w-80" /></p>
  </li>
  <li>
    <p>Docker Hub에서 이미지 확인</p>

    <p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_28.png" alt="img.png" class="image-center" /></p>
  </li>
</ul>

<h4 id="도커-기반-어플리케이션의-cicd-구성">도커 기반 어플리케이션의 CI/CD 구성</h4>

<ul>
  <li>Jenkins와 Gitlab을 사용하여 다음 그림과 같은 형태의 도커 기반 어플리케이션의 CI/CD 파이프라인을 구성해보겠습니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_29.png" alt="img.png" class="image-center w-80" />
<em class="image-caption">목표 CI/CD 파이프라인</em></p>

<h5 id="gitlab에서-jenkins-연동-설정">Gitlab에서 Jenkins 연동 설정</h5>

<ul>
  <li>gitlab 프로젝트 페이지 &gt; Settings &gt; Integrations &gt; Jenkins 연결후 아래의 정보를 입력 합니다.
    <ul>
      <li><strong>Enable integration</strong> : Active 체크</li>
      <li><strong>Trigger</strong> : Push, Merge request 체크</li>
      <li><strong>URL</strong> : <code class="language-plaintext highlighter-rouge">http://&lt;Jenkins접속주소&gt;:&lt;Jenkins포트&gt;</code></li>
      <li><strong>Project name</strong> : <code class="language-plaintext highlighter-rouge">SCM-Pipeline</code> (Jenkins 프로젝트 이름)</li>
      <li><strong>Username</strong> : <code class="language-plaintext highlighter-rouge">&lt;Jenkins 아이디&gt;</code></li>
      <li><strong>Password</strong> : <code class="language-plaintext highlighter-rouge">&lt;Jenkins 비밀번호&gt;</code></li>
    </ul>

    <p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_30.png" alt="img.png" class="image-center" /></p>
  </li>
</ul>

<h5 id="jenkins에서-gitlab-연동-설정">Jenkins에서 Gitlab 연동 설정</h5>

<ul>
  <li>Jenkins Item 생성
    <ul>
      <li>Dashboard &gt; New Item &gt; Pipeline (item name : <code class="language-plaintext highlighter-rouge">SCM-Pipeline</code>)</li>
    </ul>
  </li>
  <li>Build Triggers 설정
    <ul>
      <li>Configuration &gt; Build Triggers
        <ul>
          <li><strong>Build when a change is pushed to GitLab</strong> 체크</li>
          <li><strong>Push Events</strong> 체크</li>
          <li><strong>Accepted Merge Request Events</strong> 체크
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_31.png" alt="img.png" /></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>Jenkins 파일 생성 후 push</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Jenkinsfile <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
pipeline {
    agent any
    environment {
        DOCKER_IMAGE = 'sweetlittlebird/dev-app' // Docker 이미지 이름
    }
    stages {
        stage('Checkout') {
            steps {
                 git branch: 'main',
                 url: 'https://gitlab.com/littlebird/2024-cicd-lite-w1.git',  // Git에서 코드 체크아웃
                 credentialsId: 'gitlab-credentials'  // Credentials ID
            }
        }
        stage('Read VERSION') {
            steps {
                script {
                    // VERSION 파일 읽기
                    def version = readFile('VERSION').trim()
                    echo "Version found: </span><span class="se">\$</span><span class="sh">{version}"
                    // 환경 변수 설정
                    env.DOCKER_TAG = version
                }
            }
        }
        stage('Docker Build and Push') {
            steps {
                script {
                    docker.withRegistry('https://index.docker.io/v1/', 'dockerhub-credentials') {
                        // DOCKER_TAG 사용
                        def appImage = docker.build("</span><span class="se">\$</span><span class="sh">{DOCKER_IMAGE}:</span><span class="se">\$</span><span class="sh">{DOCKER_TAG}")
                        appImage.push()
                    }
                }
            }
        }
    }
    post {
        success {
            echo "Docker image </span><span class="se">\$</span><span class="sh">{DOCKER_IMAGE}:</span><span class="se">\$</span><span class="sh">{DOCKER_TAG} has been built and pushed successfully!"
        }
        failure {
            echo "Pipeline failed. Please check the logs."
        }
    }
}
</span><span class="no">EOF
  
</span><span class="c"># 버전 업데이트</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; VERSION
0.0.2
</span><span class="no">EOF
  
</span><span class="nv">$ </span>git add <span class="nb">.</span>
<span class="nv">$ </span>git commit <span class="nt">-m</span> <span class="s2">"Add Jenkinsfile"</span>
<span class="c"># =&gt; [main e5671f2] Add Jenkinsfile</span>
<span class="c">#     1 file changed, 45 insertions(+)</span>
<span class="c">#     create mode 100644 Jenkinsfile</span>
<span class="nv">$ </span>git push <span class="nt">-u</span> origin main
<span class="c"># =&gt; Enumerating objects: 4, done.</span>
<span class="c">#    Counting objects: 100% (4/4), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (3/3), done.</span>
<span class="c">#    Writing objects: 100% (3/3), 859 bytes | 859.00 KiB/s, done.</span>
<span class="c">#    Total 3 (delta 1), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To https://gitlab.com/littlebird/2024-cicd-lite-w1.git</span>
<span class="c">#       41a6efc..e5671f2  main -&amp;gt; main</span>
<span class="c">#    branch 'main' set up to track 'origin/main'.</span>
</code></pre></div>    </div>
  </li>
  <li>Jenkins 트리거 빌드 확인
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_32.png" alt="img.png" />
    <ul>
      <li>git push에 의해 자동으로 빌드가 잘 되었습니다.</li>
    </ul>
  </li>
  <li>Docker 저장소 확인
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_33.png" alt="img.png" />
    <ul>
      <li>Docker Hub에 수정된 0.0.2 버전의 이미지가 업로드 되었습니다.</li>
    </ul>
  </li>
  <li>
    <p>Gitlab Webhook 기록 확인
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_34.png" alt="img.png" class="image-center" /></p>
  </li>
  <li>
    <p>app.rb 소스와 VERSION 변경 후 Jenkins 트리거 작업 한번 더 확인</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># app.rb 수정</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s1">'s/Hello, World!/Hello, Jenkins! 😀/'</span> app.rb
  
<span class="c"># VERSION 수정</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"0.0.3"</span> <span class="o">&gt;</span> VERSION
  
<span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"Update app.rb and VERSION </span><span class="si">$(</span><span class="nb">cat </span>VERSION<span class="si">)</span><span class="s2">"</span> <span class="o">&amp;&amp;</span> git push <span class="nt">-u</span> origin main
<span class="c"># =&gt; [main a100e97] Update app.rb and VERSION 0.0.3</span>
<span class="c">#     3 files changed, 7 insertions(+), 2 deletions(-)</span>
<span class="c">#     create mode 100644 app.rb-e</span>
<span class="c">#    Enumerating objects: 7, done.</span>
<span class="c">#    Counting objects: 100% (7/7), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (3/3), done.</span>
<span class="c">#    Writing objects: 100% (4/4), 509 bytes | 509.00 KiB/s, done.</span>
<span class="c">#    Total 4 (delta 0), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To https://gitlab.com/littlebird/2024-cicd-lite-w1.git</span>
<span class="c">#       1bd4fcb..a100e97  main -&amp;gt; main</span>
<span class="c">#    branch 'main' set up to track 'origin/main'.</span>
</code></pre></div>    </div>

    <p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_35.png" alt="img.png" /></p>
    <ul>
      <li>빌드가 잘 되고 Docker Hub에 이미지가 업로드 되었습니다.</li>
    </ul>
  </li>
</ul>

<h5 id="jenkins-빌드-후-컨테이너-실행">Jenkins 빌드 후 컨테이너 실행</h5>

<ul>
  <li>Jenkins pipline 빌드 후 Docker 컨테이너를 실행하는 파이프라인을 구성해보겠습니다.</li>
  <li>
    <p>Jenkinsfile 수정</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pipeline <span class="o">{</span>
    agent any
    environment <span class="o">{</span>
        DOCKER_IMAGE <span class="o">=</span> <span class="s1">'sweetlittlebird/dev-app'</span> // Docker 이미지 이름
        CONTAINER_NAME <span class="o">=</span> <span class="s1">'dev-app'</span>  // Docker 컨테이너 이름
    <span class="o">}</span>
    stages <span class="o">{</span>
        stage<span class="o">(</span><span class="s1">'Checkout'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                git branch: <span class="s1">'main'</span>,
                url: <span class="s1">'https://gitlab.com/littlebird/2024-cicd-lite-w1.git'</span>,  // Git에서 코드 체크아웃
                credentialsId: <span class="s1">'gitlab-credentials'</span>  // Credentials ID
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'Read VERSION'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                script <span class="o">{</span>
                    // VERSION 파일 읽기
                    def version <span class="o">=</span> readFile<span class="o">(</span><span class="s1">'VERSION'</span><span class="o">)</span>.trim<span class="o">()</span>
                    <span class="nb">echo</span> <span class="s2">"Version found: </span><span class="k">${</span><span class="nv">version</span><span class="k">}</span><span class="s2">"</span>
                    // 환경 변수 설정
                    env.DOCKER_TAG <span class="o">=</span> version
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'Docker Build and Push'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                script <span class="o">{</span>
                    docker.withRegistry<span class="o">(</span><span class="s1">'https://index.docker.io/v1/'</span>, <span class="s1">'dockerhub-credentials'</span><span class="o">)</span> <span class="o">{</span>
                        // DOCKER_TAG 사용
                        def appImage <span class="o">=</span> docker.build<span class="o">(</span><span class="s2">"</span><span class="k">${</span><span class="nv">DOCKER_IMAGE</span><span class="k">}</span><span class="s2">:</span><span class="k">${</span><span class="nv">DOCKER_TAG</span><span class="k">}</span><span class="s2">"</span><span class="o">)</span>
                        appImage.push<span class="o">()</span>
                    <span class="o">}</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'Check, Stop and Run Docker Container'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                script <span class="o">{</span>
                    // 실행 중인 컨테이너 확인
                    def isRunning <span class="o">=</span> sh<span class="o">(</span>
                        script: <span class="s2">"docker ps -q -f name=</span><span class="k">${</span><span class="nv">CONTAINER_NAME</span><span class="k">}</span><span class="s2">"</span>,
                        returnStdout: <span class="nb">true</span>
                    <span class="o">)</span>.trim<span class="o">()</span>
                      
                    <span class="k">if</span> <span class="o">(</span>isRunning<span class="o">)</span> <span class="o">{</span>
                        <span class="nb">echo</span> <span class="s2">"Container '</span><span class="k">${</span><span class="nv">CONTAINER_NAME</span><span class="k">}</span><span class="s2">' is already running. Stopping it..."</span>
                        // 실행 중인 컨테이너 중지
                        sh <span class="s2">"docker stop </span><span class="k">${</span><span class="nv">CONTAINER_NAME</span><span class="k">}</span><span class="s2">"</span>
                        // 컨테이너 제거
                        sh <span class="s2">"docker rm </span><span class="k">${</span><span class="nv">CONTAINER_NAME</span><span class="k">}</span><span class="s2">"</span>
                        <span class="nb">echo</span> <span class="s2">"Container '</span><span class="k">${</span><span class="nv">CONTAINER_NAME</span><span class="k">}</span><span class="s2">' stopped and removed."</span>
                    <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
                        <span class="nb">echo</span> <span class="s2">"Container '</span><span class="k">${</span><span class="nv">CONTAINER_NAME</span><span class="k">}</span><span class="s2">' is not running."</span>
                    <span class="o">}</span>
                      
                    // 5초 대기
                    <span class="nb">echo</span> <span class="s2">"Waiting for 5 seconds before starting the new container..."</span>
                    <span class="nb">sleep</span><span class="o">(</span>5<span class="o">)</span>
                      
                    // 신규 컨테이너 실행
                    <span class="nb">echo</span> <span class="s2">"Starting a new container '</span><span class="k">${</span><span class="nv">CONTAINER_NAME</span><span class="k">}</span><span class="s2">'..."</span>
                    sh <span class="s2">"""
                    docker run -d --name </span><span class="k">${</span><span class="nv">CONTAINER_NAME</span><span class="k">}</span><span class="s2"> -p 4000:4567 </span><span class="k">${</span><span class="nv">DOCKER_IMAGE</span><span class="k">}</span><span class="s2">:</span><span class="k">${</span><span class="nv">DOCKER_TAG</span><span class="k">}</span><span class="s2">
                    """</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>        
    <span class="o">}</span>
    post <span class="o">{</span>
        success <span class="o">{</span>
            <span class="nb">echo</span> <span class="s2">"Docker image </span><span class="k">${</span><span class="nv">DOCKER_IMAGE</span><span class="k">}</span><span class="s2">:</span><span class="k">${</span><span class="nv">DOCKER_TAG</span><span class="k">}</span><span class="s2"> has been built and pushed successfully!"</span>
        <span class="o">}</span>
        failure <span class="o">{</span>
            <span class="nb">echo</span> <span class="s2">"Pipeline failed. Please check the logs."</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>git commit 후 push</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">echo </span>0.0.4 <span class="o">&gt;</span> VERSION
  
<span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"Update Jenkinsfile </span><span class="si">$(</span><span class="nb">cat </span>VERSION<span class="si">)</span><span class="s2">"</span> <span class="o">&amp;&amp;</span> git push <span class="nt">-u</span> origin main
<span class="c"># =&gt; [main 25e5c95] Update Jenkinsfile 0.0.4</span>
<span class="c">#     2 files changed, 2 insertions(+), 1 deletion(-)</span>
<span class="c">#    Enumerating objects: 7, done.</span>
<span class="c">#    Counting objects: 100% (7/7), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (3/3), done.</span>
<span class="c">#    Writing objects: 100% (4/4), 385 bytes | 385.00 KiB/s, done.</span>
<span class="c">#    Total 4 (delta 2), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To https://gitlab.com/littlebird/2024-cicd-lite-w1.git</span>
<span class="c">#       26c809d..25e5c95  main -&amp;gt; main</span>
<span class="c">#    branch 'main' set up to track 'origin/main'.</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>생성된 컨테이너 접속 확인</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker image <span class="nb">ls</span>
<span class="c"># =&gt; REPOSITORY                                                                   TAG           IMAGE ID       CREATED             SIZE</span>
<span class="c">#    sweetlittlebird/dev-app                                                      0.0.4         2f5f42fa7dd6   9 minutes ago       1.01GB</span>
<span class="c">#    ... </span>
<span class="nv">$ </span>docker ps <span class="nt">--filter</span> <span class="nv">name</span><span class="o">=</span>dev-app
<span class="c"># =&gt; CONTAINER ID   IMAGE                           COMMAND                  CREATED         STATUS         PORTS                  NAMES</span>
<span class="c">#    e5d4760ea725   sweetlittlebird/dev-app:0.0.4   &amp;quot;ruby app.rb -o 0.0.…&amp;quot;   2 minutes ago   Up 2 minutes   0.0.0.0:4000-&amp;gt;80/tcp   dev-app</span>
<span class="nv">$ </span>curl http://localhost:4000
<span class="c"># =&gt; Hello, Jenkins! 😀 The time is 2024-10-01 15:49:44 +0000!!</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>app.rb와 VERSION 수정 후 push 후 컨테이너 접속 후 반영 확인</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># app.rb 수정</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s1">'s/Hello, Jenkins! 😀/Hello, Jenkins again!!! 😎/'</span> app.rb
  
<span class="c"># VERSION 수정</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"0.0.5"</span> <span class="o">&gt;</span> VERSION
  
<span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"Update app.rb and VERSION </span><span class="si">$(</span><span class="nb">cat </span>VERSION<span class="si">)</span><span class="s2">"</span> <span class="o">&amp;&amp;</span> git push <span class="nt">-u</span> origin main
<span class="c"># =&gt; [main 70eaa32] Update app.rb and VERSION 0.0.5</span>
<span class="c">#     3 files changed, 3 insertions(+), 3 deletions(-)</span>
<span class="c">#    Enumerating objects: 7, done.</span>
<span class="c">#    Counting objects: 100% (7/7), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (3/3), done.</span>
<span class="c">#    Writing objects: 100% (4/4), 519 bytes | 519.00 KiB/s, done.</span>
<span class="c">#    Total 4 (delta 0), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To https://gitlab.com/littlebird/2024-cicd-lite-w1.git</span>
<span class="c">#       cc87e97..70eaa32  main -&amp;gt; main</span>
<span class="c">#    branch 'main' set up to track 'origin/main'.</span>
  
<span class="c"># 호스트 PC에서 반복 접속 실행 : 서비스 중단 시간 체크!</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 http://127.0.0.1:4000 <span class="p">;</span> <span class="nb">date</span><span class="p">;</span> <span class="nb">sleep </span>1 <span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; Hello, Jenkins again!!! 😎 The time is 2024-10-01 15:52:25 +0000!!Sun Oct  1 00:52:25 KST 2024</span>
<span class="c">#    Hello, Jenkins again!!! 😎 The time is 2024-10-01 15:52:26 +0000!!Sun Oct  1 00:52:26 KST 2024</span>
<span class="c">#    Sun Oct  1 00:52:27 KST 2024</span>
<span class="c">#    Sun Oct  1 00:52:28 KST 2024</span>
<span class="c">#    Sun Oct  1 00:52:29 KST 2024</span>
<span class="c">#    Sun Oct  1 00:52:30 KST 2024</span>
<span class="c">#    Sun Oct  1 00:52:31 KST 2024</span>
<span class="c">#    Sun Oct  1 00:52:32 KST 2024</span>
<span class="c">#    Hello, Jenkins again!!! 😎 The time is 2024-10-01 15:52:33 +0000!!Sun Oct  1 00:52:33 KST 2024</span>
<span class="c">#    Hello, Jenkins again!!! 😎 The time is 2024-10-01 15:52:34 +0000!!Sun Oct  1 00:52:34 KST 2024</span>
<span class="c">#    Hello, Jenkins again!!! 😎 The time is 2024-10-01 15:52:35 +0000!!Sun Oct  1 00:52:35 KST 2024</span>
</code></pre></div>    </div>
  </li>
  <li>수정사항이 적용은 잘 되었지만 6~7초 가량 서비스가 중단되는 것을 확인할 수 있습니다. 이는 컨테이너 중지 및 재시작 시간이 소요되기 때문입니다.</li>
  <li>이러한 문제를 해결하기 위해 docker swarm이나 kubernetes 등의 컨테이너 오케스트레이션 툴을 사용하여 서비스 중단 없이 배포할 수 있습니다.
이 부분은 다음에 다루도록 하겠습니다.</li>
</ul>

<h2 id="마치며">마치며</h2>

<p>이번 시간에는 Jenkins, Gitlab 등을 사용하여 CI/CD 파이프라인을 구성하는 방법을 알아보았습니다.
다양하게 테스트해보고 싶었는데 생각보다 정리하는데 시간이 많이 소요되어 다양한 예제를 다루지 못한 점이 아쉽습니다.</p>

<p>Jenkins는 예전에 써보고 Teamcity나 Github action을 주로 사용해왔는데, 
다시 사용해보니 Jenkins도 Jenkinsfile과 Pipeline도 지원하고 예전에 비해서 훨씬 좋아진 것 같습니다.
이번 스터디를 통해 Jenkins를 재발견한것 같습니다.
준비해주신 Gasida 님께 감사드립니다.</p>]]></content><author><name></name></author><category term="kans" /><category term="cicd," /><category term="jenkins," /><category term="git," /><category term="linux" /><summary type="html"><![CDATA[Jenkins와 Git, Docker를 이용하여 CI/CD 파이프라인을 구축해보겠습니다.]]></summary></entry><entry><title type="html">[KANS 3기] AWS EKS : VPC CNI</title><link href="https://sweetlittlebird.github.io/posts/2024-11-03-KANS-Study-Week9/" rel="alternate" type="text/html" title="[KANS 3기] AWS EKS : VPC CNI" /><published>2024-11-03T00:00:18+09:00</published><updated>2024-11-03T00:00:18+09:00</updated><id>https://sweetlittlebird.github.io/posts/KANS%20Study%20-%20Week9</id><content type="html" xml:base="https://sweetlittlebird.github.io/posts/2024-11-03-KANS-Study-Week9/"><![CDATA[<h2 id="들어가며">들어가며</h2>

<p>안녕하세요. 이번 주에는 AWS EKS의 VPC CNI에 대해 알아보겠습니다.
KANS 3기 9주차 스터디를 시작하겠습니다.</p>

<hr />

<h2 id="aws-eks--vpc-cni">AWS EKS : VPC CNI</h2>

<h3 id="aws-vpc-cni-소개">AWS VPC CNI 소개</h3>

<ul>
  <li>AWS VPC CNI는 AWS에서 제공하는 CNI(Container Network Interface) 플러그인으로, AWS VPC(Virtual Private Cloud)의 네트워크를 사용하여 파드 간 통신을 지원하는 CNI 플러그인입니다.</li>
  <li>AWS VPC CNI의 특징
    <ul>
      <li>가장 큰 특징은 파드의 IP 네트워크 대역과 노드(인스턴스)의 IP 네트워크 대역이 같아서 직접 통신이 가능하다는 것입니다. - 
<a href="https://github.com/aws/amazon-vpc-cni-k8s">Github</a>, <a href="https://github.com/aws/amazon-vpc-cni-k8s/blob/master/docs/cni-proposal.md">Proposal</a></li>
      <li>또한 VPC와 통합되어 VPC Flow logs나 VPC 라우팅 정책, 보안 그룹(Security Group) 등을 활용할 수 있습니다.</li>
      <li>아래에서 설명할 Warm Pool을 통해 노드의 IP 주소를 재사용하여 파드의 생성과 삭제를 빠르게 할 수 있습니다.</li>
    </ul>
  </li>
  <li>Amazon VPC CNI는 크게 두가지 구성요소로  이루어집니다.
    <ul>
      <li>CNI 바이너리 : 파드간 통신을 활성화 하도록 파드 네트워크를 설정합니다. CNI 바이너리는 노드의 루트 파일 시스템에서 실행되며,
새로운 파드가 추가되거나, 기존 파드가 제거 될때 kubelet에 의해 호출됩니다.</li>
      <li>ipamd : IP 주소를 할당하고 관리하는 데몬으로 다음을 담당 합니다.
        <ul>
          <li>노드에서 ENI(<code class="language-plaintext highlighter-rouge">Elastic Network Interface</code> - EC2에서 사용하는 일종의 가상 랜카드) 관리</li>
          <li>사용가능한 IP 주소들의 웜풀 유지</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>인스턴스가 생성되면 EC2는 기본 서브넷과 연결된 기본 ENI를 생성하고 연결합니다.
호스트 네트워크 모드에서 실행되는 포드는 노드 기본 ENI에 할당된 기본 IP 주소를 
사용하며 호스트와 동일한 네트워크 네임스페이스를 공유합니다.</li>
</ul>

<blockquote>
  <p><strong>웜풀(warm pool)</strong>은
  노드가 프로비저닝 될 때 미리 할당된 IP 주소들의 집합입니다. 
  이것은 노드가 프로비저닝 될 때마다 새로운 IP 주소를 할당하는 것을 방지하고, 노드가 삭제되어도 IP 주소를 재사용할 수 있도록 하여
  조금 더 빠른 파드의 생성과 삭제를 가능하게 합니다.</p>
</blockquote>

<ul>
  <li>EC2 인스턴스별 최대 사용가능한 ENI 갯수는 인스턴스 타입에 따라 다르며, 
인스턴스 타입별 ENI 갯수는 <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html#network-cards">여기</a>에서 확인할 수 있습니다. 
이 ENI 갯수에 따라 할당 가능한 IP 주소의 갯수가 결정되며, 이에 따라 파드의 갯수가 제한될 수 있습니다.</li>
  <li>
    <p>각 ENI는 할당할 수 있는 IP수가 제한되어 있으며, 이 수는 EC2 인스턴스 타입에 따라 다릅니다.
인스턴스 타입별 ENI 당 IP 할당 수는 <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AvailableIpPerENI.html">여기</a>에서 확인할 수 있습니다.
ENI 당 할당할 수 있는 IP 를 slot 이라고 하며, 이 slot은 VPC CNI를 통해 파드에 할당됩니다.</p>

    <p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_1.png" alt="img.png" class="image-center" />
<em class="image-caption">파드에 IP를 할당하기 위한 절차</em></p>
  </li>
</ul>

<h4 id="calico-cni와의-차이점">Calico CNI와의 차이점</h4>

<ul>
  <li>노드와 파드의 네트워크 대역을 동일하게 설정함으로써 NAT(Network Address Translation)을 사용하지 않아도 되기 때문에
성능이 향상되고 지연이 최소화 됩니다.</li>
</ul>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_2.png" alt="img.png" class="image-center w-80" /></p>

<ul>
  <li>파드간 통신시 Calico CNI 등의 일반적인 CNI는 오버레이(VXLAN, IP-in-IP)를 사용하여 통신하지만,
AWS VPC CNI는 VPC의 네트워크를 사용하여 직접 통신합니다.</li>
</ul>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_3.png" alt="img_1.png" class="image-center w-90" /></p>

<h4 id="ipv4-prefix-위임-delegation">IPv4 Prefix 위임 (Delegation)</h4>

<ul>
  <li>앞서 알아 본것 처럼 각 파드는 노드의 ENI에 할당된 IP 주소를 사용하고, ENI당 IP (slot) 수와 ENI 갯수는
인스턴스별로 제한이 있고, 이 값이 큰 편이 아닙니다. 이를 해결하기위해 IPv4 Prefix 위임이 도입되었습니다.</li>
  <li>IPv4 Prefix는 ENI 별로 IP를 할당하지 않고, /28의 접두사 길이 CIDR 블록을 노드에 할당하여 파드에 할당할 IP 주소를 관리합니다.
이렇게 하면 각 슬랏당 16개의 IP주소를 할당할 수 있어서 다음과 같은 갯수의 최대 IP 또는 파드를 사용할 수 있습니다.</li>
  <li>최대 사용가능한 IP 수 계산 : 
<code class="language-plaintext highlighter-rouge">사용가능한 파드 IP 수 = (최대 네트워크 인터페이스(ENI) 갯수 * (네트워크 인터페이스 당 slot 수 - 1) * 16)</code>
    <ul>
      <li>단, 실제로는 인스턴스 유형별로 권장되는 최대 갯수로 선정됩니다.</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_4.png" alt="img.png" class="image-center" /></p>

<ul>
  <li>참고 링크 : <a href="https://trans.yonghochoi.com/translations/aws_vpc_cni_increase_pods_per_node_limits.ko">Amazon VPC CNI 플러그인으로 노드당 파드수 제한 늘리기</a></li>
</ul>

<hr />

<h3 id="실습-준비">실습 준비</h3>

<h4 id="구성-환경">구성 환경</h4>

<ul>
  <li>사전 준비물 : AWS 계정, SSH 키 페어, IAM 계정 생성 후 키</li>
  <li>전체 구성도 : VPC 1개(퍼블릭 서브넷 3개, 프라이빗 서브넷 3개), EKS 클러스터(Control Plane), 관리형 노드 그룹(EC2 3대), Add-on
<img src="/assets/2024/kans-3th/w9/20241102_kans_w9_28.png" alt="img.png" class="image-center" />
    <ul>
      <li>CloudFormation 스택 실행 시 <strong>파라미터</strong>를 기입하면, 해당 정보가 반영되어 배포됩니다.</li>
      <li>실습 환경을 위한 <strong>VPC</strong> 1개가 생성되고, <strong>퍼블릭</strong> 서브넷 3개와 <strong>프라이빗</strong> 서브넷 3개가 생성됩니다.</li>
      <li>CloudFormation 에 EC2의 <strong>UserData</strong> 부분(<strong>Script</strong> 실행)으로 Amazon EKS <strong>설치(with OIDC, Endpoint Public)</strong>를 진행합니다.</li>
      <li><strong>관리형 노드 그룹</strong>(워커 노드)는 AZ1~AZ3를 사용하여, 기본 <strong>3</strong>대로 구성됩니다</li>
      <li><strong>Add-on</strong> 같이 설치 됨 : 최신 버전 - kube-proxy, coredns, aws vpc cni - <a href="https://docs.aws.amazon.com/eks/latest/userguide/eks-add-ons.html">링크</a></li>
      <li><strong>노드</strong>에 <strong>EC2 IAM Profile</strong> 권한 추가 : external-dns-access, full-ecr-access, alb-ingress-access, awsLoadBalancerController</li>
    </ul>
  </li>
</ul>

<h4 id="배포-및-테스트">배포 및 테스트</h4>

<ul>
  <li>배포
    <ul>
      <li>aws cli를 설치하고, aws configure로 자격증명을 설정 후 아래의 명령을 실행합니다.</li>
      <li>다음의 파라미터가 있고, :point_right: 표시가 있는 부분은 필수로 설정해주어야 합니다.
        <ul>
          <li><strong>Deploy EC2</strong>
            <ol>
              <li>:point_right: <strong>KeyName</strong> : 작업용 bastion ec2에 SSH 접속을 위한 <strong>SSH 키페어</strong> 선택 <em>← 미리 SSH 키 생성 해두자!</em></li>
              <li>:point_right: <strong>MyIamUserAccessKeyID</strong> : <strong>관리자</strong> 수준의 권한을 가진 IAM User의 액세스 키ID 입력</li>
              <li>:point_right: <strong>MyIamUserSecretAccessKey</strong> : <strong>관리자</strong> 수준의 권한을 가진 IAM User의 <strong>시크릿 키ID</strong> 입력 <strong>← 노출되지 않게 보안 주의</strong></li>
              <li>:point_right: <strong>SgIngressSshCidr</strong> : 작업용 bastion ec2에 <strong>SSH 접속 가능한 IP</strong> 입력 (<strong>집 공인IP</strong>/32 입력), 보안그룹 인바운드 규칙에 반영됨</li>
              <li>MyInstanceType: 작업용 bastion EC2 인스턴스의 타입 (기본 <strong>t3.medium</strong>) ⇒ 변경 가능</li>
              <li>LatestAmiId : 작업용 bastion EC2에 사용할 AMI는 아마존리눅스2 최신 버전 사용</li>
            </ol>
          </li>
          <li><strong>EKS Config</strong>
            <ol>
              <li><strong>ClusterBaseName</strong> : EKS <strong>클러스터 이름</strong>이며, <strong>myeks</strong> 기본값 사용을 권장 → 이유: 실습 리소스 태그명과 실습 커멘드에서 사용</li>
              <li><strong>KubernetesVersion</strong> : EKS 호환, 쿠버네티스 버전 (기본 v1.30, 실습은 <strong>1.30</strong> 버전 사용)</li>
              <li><strong>WorkerNodeInstanceType</strong>: 워커 노드 EC2 인스턴스의 타입 (기본 <strong>t3.medium</strong>) ⇒ 변경 가능</li>
              <li><strong>WorkerNodeCount</strong> : 워커노드의 갯수를 입력 (기본 3대) ⇒ 변경 가능</li>
              <li><strong>WorkerNodeVolumesize</strong> : 워커노드의 EBS 볼륨 크기 (기본 80GiB) ⇒ 변경 가능</li>
            </ol>
          </li>
          <li><strong>Region AZ</strong> : 리전과 가용영역을 지정, 기본값 그대로 사용</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># YAML 파일 다운로드</span>
<span class="nv">$ </span>curl <span class="nt">-O</span> https://s3.ap-northeast-2.amazonaws.com/cloudformation.cloudneta.net/kans/eks-oneclick.yaml

<span class="c"># CloudFormation 스택 배포</span>
<span class="c"># aws cloudformation deploy --template-file eks-oneclick.yaml --stack-name myeks --parameter-overrides KeyName=&lt;My SSH Keyname&gt; SgIngressSshCidr=&lt;My Home Public IP Address&gt;/32 MyIamUserAccessKeyID=&lt;IAM User의 액세스키&gt; MyIamUserSecretAccessKey=&lt;IAM User의 시크릿 키&gt; ClusterBaseName='&lt;eks 이름&gt;' --region ap-northeast-2</span>
<span class="c"># 예시) aws cloudformation deploy --template-file eks-oneclick.yaml --stack-name myeks --parameter-overrides KeyName=aws-ec2 SgIngressSshCidr=$(curl -s ipinfo.io/ip)/32  MyIamUserAccessKeyID=AKIA5... MyIamUserSecretAccessKey='CVNa2...' ClusterBaseName=myeks --region ap-northeast-2</span>

<span class="c">## Tip. 워커노드 인스턴스 타입 변경 : WorkerNodeInstanceType=t3.xlarge</span>
<span class="c"># 예시) aws cloudformation deploy --template-file eks-oneclick.yaml --stack-name myeks --parameter-overrides KeyName=aws-ec2 SgIngressSshCidr=$(curl -s ipinfo.io/ip)/32  MyIamUserAccessKeyID=AKIA5... MyIamUserSecretAccessKey='CVNa2...' ClusterBaseName=myeks --region ap-northeast-2 WorkerNodeInstanceType=t3.xlarge </span>

<span class="nv">$ </span>aws cloudformation deploy <span class="nt">--template-file</span> eks-oneclick.yaml <span class="nt">--stack-name</span> myeks <span class="se">\</span>
  <span class="nt">--parameter-overrides</span> <span class="nv">KeyName</span><span class="o">=</span>aws-ec2 <span class="se">\</span>
  <span class="nv">SgIngressSshCidr</span><span class="o">=</span><span class="si">$(</span>curl <span class="nt">-s</span> ipinfo.io/ip<span class="si">)</span>/32 <span class="se">\</span>
  <span class="nv">MyIamUserAccessKeyID</span><span class="o">=</span>AKIA5... <span class="se">\</span>
  <span class="nv">MyIamUserSecretAccessKey</span><span class="o">=</span><span class="s1">'CVNa2...'</span> <span class="se">\ </span> 
  <span class="nv">ClusterBaseName</span><span class="o">=</span>myeks <span class="se">\ </span>
  <span class="nt">--region</span> ap-northeast-2
<span class="c"># =&gt; Waiting for changeset to be created..</span>
<span class="c">#    Waiting for stack create/update to complete</span>
<span class="c">#    Successfully created/updated stack - myeks</span>

<span class="c"># CloudFormation 스택 배포 완료 후 작업용 EC2 IP 출력</span>
<span class="nv">$ </span>aws cloudformation describe-stacks <span class="nt">--stack-name</span> myeks <span class="nt">--query</span> <span class="s1">'Stacks[*].Outputs[0].OutputValue'</span> <span class="nt">--output</span> text
<span class="c"># =&gt; 3.35.140.75</span>

<span class="c"># 작업용 EC2 SSH 접속</span>
<span class="nv">$ </span>ssh <span class="nt">-i</span> ~/.ssh/aws-ec2-key.cer ec2-user@<span class="si">$(</span>aws cloudformation describe-stacks <span class="nt">--stack-name</span> myeks <span class="nt">--query</span> <span class="s1">'Stacks[*].Outputs[0].OutputValue'</span> <span class="nt">--output</span> text<span class="si">)</span>
<span class="c"># =&gt;    ,     #_</span>
<span class="c">#       ~\_  ####_        Amazon Linux 2</span>
<span class="c">#      ~~  \_#####\</span>
<span class="c">#      ~~     \###|       AL2 End of Life is 2025-06-30.</span>
<span class="c">#      ~~       \#/ ___</span>
<span class="c">#       ~~       V~' '-&amp;gt;</span>
<span class="c">#        ~~~         /    A newer version of Amazon Linux is available!</span>
<span class="c">#          ~~._.   _/</span>
<span class="c">#             _/ _/       Amazon Linux 2023, GA and supported until 2028-03-15.</span>
<span class="c">#           _/m/'           https://aws.amazon.com/linux/amazon-linux-2023/</span>
<span class="c">#    </span>
<span class="c">#    10 package(s) needed for security, out of 13 available</span>
<span class="c">#    Run &amp;quot;sudo yum update&amp;quot; to apply all updates.</span>
<span class="c">#    [root@myeks-bastion ~]#</span>
</code></pre></div></div>

<ul>
  <li>작업용 EC2에 SSH 키 파일 사용하여 SSH 접속 후 확인해보겠습니다.</li>
  <li>쿠버네티스 정상 설치 확인은 스택 생성 시작 후 20분 후 접속하는 것이 좋습니다.</li>
  <li>접속 후 기본 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># SSH 접속</span>
<span class="nv">$ </span>ssh <span class="nt">-i</span> ~/.ssh/aws-ec2-key.cer ec2-user@<span class="si">$(</span>aws cloudformation describe-stacks <span class="nt">--stack-name</span> myeks <span class="nt">--query</span> <span class="s1">'Stacks[*].Outputs[0].OutputValue'</span> <span class="nt">--output</span> text<span class="si">)</span>

<span class="c"># cloud-init 실행 과정 로그 확인</span>
<span class="nv">$ </span><span class="nb">tail</span> <span class="nt">-f</span> /var/log/cloud-init-output.log
<span class="c"># =&gt;  ...</span>
<span class="c">#     69  dnsmasq                  available    [ =stable ]</span>
<span class="c">#     70  unbound1.17              available    [ =stable ]</span>
<span class="c">#     72  collectd-python3         available    [ =stable ]</span>
<span class="c">#    † Note on end-of-support. Use 'info' subcommand.</span>
<span class="c">#    Created symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /usr/lib/systemd/system/docker.service.</span>
<span class="c">#    cloudinit End!</span>
<span class="c">#    Cloud-init v. 19.3-46.amzn2.0.2 finished at Sat, 01 Nov 2024 07:27:24 +0000. Datasource DataSourceEc2.  Up 84.79 seconds</span>

<span class="c"># cloud-init 정상 완료 후 eksctl 실행 과정 로그 확인</span>
<span class="nv">$ </span><span class="nb">tail</span> <span class="nt">-f</span> /root/create-eks.log
<span class="c"># =&gt; ...</span>
<span class="c">#    2024-10-01 16:26:46 [ℹ]  deploying stack &amp;quot;eksctl-myeks-cluster&amp;quot;</span>
<span class="c">#    2024-10-01 16:27:16 [ℹ]  waiting for CloudFormation stack &amp;quot;eksctl-myeks-cluster&amp;quot;</span>
<span class="c">#    ...</span>
<span class="c">#    2024-10-01 16:40:31 [✔]  EKS cluster &amp;quot;myeks&amp;quot; in &amp;quot;ap-northeast-2&amp;quot; region is ready</span>

<span class="c"># default 네임스페이스 적용</span>
<span class="nv">$ </span>kubectl ns default
<span class="c"># =&gt; Context &amp;quot;anonym@myeks.ap-northeast-2.eksctl.io&amp;quot; modified.</span>
<span class="c">#    Active namespace is &amp;quot;default&amp;quot;.</span>

<span class="c"># 설치 확인</span>
<span class="nv">$ </span>kubectl cluster-info
<span class="c"># =&gt; Kubernetes control plane is running at https://CF0FD5E1EEB937DD6FF881B7EBADDFD4.yl4.ap-northeast-2.eks.amazonaws.com</span>
<span class="c">#    CoreDNS is running at https://CF0FD5E1EEB937DD6FF881B7EBADDFD4.yl4.ap-northeast-2.eks.amazonaws.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</span>
<span class="nv">$ </span>eksctl get cluster
<span class="c"># =&gt; NAME REGION    EKSCTL CREATED</span>
<span class="c">#    myeks  ap-northeast-2  True</span>
<span class="nv">$ </span>eksctl get nodegroup <span class="nt">--cluster</span> <span class="nv">$CLUSTER_NAME</span>
<span class="c"># =&gt; CLUSTER  NODEGROUP STATUS  CREATED               MIN SIZE  MAX SIZE  DESIRED CAPACITY  INSTANCE TYPE  IMAGE ID    ASG NAME                                      TYPE</span>
<span class="c">#    myeks    ng1       ACTIVE  2024-10-01T07:37:58Z  3         3         3                 t3.medium      AL2_x86_64  eks-ng1-4ec975e7-9584-1403-37c4-fc55cc2ec860  managed</span>

<span class="c"># 환경변수 정보 확인</span>
<span class="nv">$ </span><span class="nb">export</span> | egrep <span class="s1">'ACCOUNT|AWS_|CLUSTER|KUBERNETES|VPC|Subnet'</span>
<span class="nv">$ </span><span class="nb">export</span> | egrep <span class="s1">'ACCOUNT|AWS_|CLUSTER|KUBERNETES|VPC|Subnet'</span> | egrep <span class="nt">-v</span> <span class="s1">'SECRET|KEY'</span>
<span class="c"># =&gt; declare -x ACCOUNT_ID=&amp;quot;123456789012&amp;quot;</span>
<span class="c">#    declare -x AWS_DEFAULT_REGION=&amp;quot;ap-northeast-2&amp;quot;</span>
<span class="c">#    declare -x AWS_PAGER=&amp;quot;&amp;quot;</span>
<span class="c">#    declare -x AWS_REGION=&amp;quot;ap-northeast-2&amp;quot;</span>
<span class="c">#    declare -x CLUSTER_NAME=&amp;quot;myeks&amp;quot;</span>
<span class="c">#    declare -x KUBERNETES_VERSION=&amp;quot;1.30&amp;quot;</span>
<span class="c">#    declare -x PrivateSubnet1=&amp;quot;subnet-02550e25cd3a9d814&amp;quot;</span>
<span class="c">#    declare -x PrivateSubnet2=&amp;quot;subnet-0c2adfcc3d586e58d&amp;quot;</span>
<span class="c">#    declare -x PrivateSubnet3=&amp;quot;subnet-04dd8e21b159de4cb&amp;quot;</span>
<span class="c">#    declare -x PubSubnet1=&amp;quot;subnet-0a06ed52d587bd707&amp;quot;</span>
<span class="c">#    declare -x PubSubnet2=&amp;quot;subnet-00b4dacf7eef35d33&amp;quot;</span>
<span class="c">#    declare -x PubSubnet3=&amp;quot;subnet-03c911c48452b41b2&amp;quot;</span>
<span class="c">#    declare -x VPCID=&amp;quot;vpc-0837921f515624150&amp;quot;</span>

<span class="c"># 인증 정보 확인</span>
<span class="nv">$ </span><span class="nb">cat</span> /root/.kube/config
<span class="nv">$ </span>kubectl config view
<span class="nv">$ </span>kubectl ctx
<span class="c"># =&gt; anonym@myeks.ap-northeast-2.eksctl.io</span>

<span class="c"># 노드 정보 확인</span>
<span class="nv">$ </span>kubectl get node <span class="nt">--label-columns</span><span class="o">=</span>node.kubernetes.io/instance-type,eks.amazonaws.com/capacityType,topology.kubernetes.io/zone
<span class="c"># =&gt; NAME                                               STATUS   ROLES    AGE     VERSION               INSTANCE-TYPE   CAPACITYTYPE   ZONE</span>
<span class="c">#    ip-192-168-1-186.ap-northeast-2.compute.internal   Ready    &amp;lt;none&amp;gt;   7m26s   v1.30.4-eks-a737599   t3.medium       ON_DEMAND      ap-northeast-2a</span>
<span class="c">#    ip-192-168-2-92.ap-northeast-2.compute.internal    Ready    &amp;lt;none&amp;gt;   7m22s   v1.30.4-eks-a737599   t3.medium       ON_DEMAND      ap-northeast-2b</span>
<span class="c">#    ip-192-168-3-235.ap-northeast-2.compute.internal   Ready    &amp;lt;none&amp;gt;   7m22s   v1.30.4-eks-a737599   t3.medium       ON_DEMAND      ap-northeast-2c</span>
<span class="nv">$ </span>eksctl get iamidentitymapping <span class="nt">--cluster</span> myeks
<span class="c"># =&gt; ARN                      USERNAME        GROUPS          ACCOUNT</span>
<span class="c">#    arn:aws:iam::123456789012:role/eksctl-myeks-nodegroup-ng1-NodeInstanceRole-kPdCWLD1sAsU  system:node: system:bootstrappers,system:nodes</span>

<span class="c"># krew 플러그인 확인</span>
<span class="nv">$ </span>kubectl krew list
<span class="c"># =&gt; PLUGIN   VERSION</span>
<span class="c">#    ctx      v0.9.5</span>
<span class="c">#    get-all  v1.3.8</span>
<span class="c">#    krew     v0.4.4</span>
<span class="c">#    neat     v2.0.4</span>
<span class="c">#    ns       v0.9.5</span>
<span class="c">#    stern    v1.31.0</span>

<span class="c"># 모든 네임스페이스에서 모든 리소스 확인</span>
<span class="nv">$ </span>kubectl get-all
</code></pre></div></div>

<ul>
  <li>노드 접속 확인 및 SSH 접속</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 노드 IP 확인 및 PrivateIP 변수 지정</span>
<span class="nv">$ </span>aws ec2 describe-instances <span class="nt">--query</span> <span class="s2">"Reservations[*].Instances[*].{PublicIPAdd:PublicIpAddress,PrivateIPAdd:PrivateIpAddress,InstanceName:Tags[?Key=='Name']|[0].Value,Status:State.Name}"</span> <span class="nt">--filters</span> <span class="nv">Name</span><span class="o">=</span>instance-state-name,Values<span class="o">=</span>running <span class="nt">--output</span> table
<span class="c"># =&gt; ------------------------------------------------------------------</span>
<span class="c">#    |                        DescribeInstances                       |</span>
<span class="c">#    +----------------+-----------------+------------------+----------+</span>
<span class="c">#    |  InstanceName  |  PrivateIPAdd   |   PublicIPAdd    | Status   |</span>
<span class="c">#    +----------------+-----------------+------------------+----------+</span>
<span class="c">#    |  myeks-ng1-Node|  192.168.2.92   |  43.203.143.233  |  running |</span>
<span class="c">#    |  myeks-ng1-Node|  192.168.3.235  |  15.164.95.12    |  running |</span>
<span class="c">#    |  myeks-bastion |  192.168.1.100  |  3.35.140.75     |  running |</span>
<span class="c">#    |  myeks-ng1-Node|  192.168.1.186  |  3.38.183.82     |  running |</span>
<span class="c">#    +----------------+-----------------+------------------+----------+</span>
<span class="nv">$ N1</span><span class="o">=</span><span class="si">$(</span>kubectl get node <span class="nt">--label-columns</span><span class="o">=</span>topology.kubernetes.io/zone <span class="nt">--selector</span><span class="o">=</span>topology.kubernetes.io/zone<span class="o">=</span>ap-northeast-2a <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.items[0].status.addresses[0].address<span class="o">}</span><span class="si">)</span>
<span class="nv">$ N2</span><span class="o">=</span><span class="si">$(</span>kubectl get node <span class="nt">--label-columns</span><span class="o">=</span>topology.kubernetes.io/zone <span class="nt">--selector</span><span class="o">=</span>topology.kubernetes.io/zone<span class="o">=</span>ap-northeast-2b <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.items[0].status.addresses[0].address<span class="o">}</span><span class="si">)</span>
<span class="nv">$ N3</span><span class="o">=</span><span class="si">$(</span>kubectl get node <span class="nt">--label-columns</span><span class="o">=</span>topology.kubernetes.io/zone <span class="nt">--selector</span><span class="o">=</span>topology.kubernetes.io/zone<span class="o">=</span>ap-northeast-2c <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.items[0].status.addresses[0].address<span class="o">}</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"export N1=</span><span class="nv">$N1</span><span class="s2">"</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"export N2=</span><span class="nv">$N2</span><span class="s2">"</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"export N3=</span><span class="nv">$N3</span><span class="s2">"</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$N1</span>, <span class="nv">$N2</span>, <span class="nv">$N3</span>
<span class="c"># =&gt; 192.168.1.186, 192.168.2.92, 192.168.3.235</span>

<span class="c"># 보안그룹 ID와 보안그룹 이름(Name아님을 주의!) 확인</span>
<span class="nv">$ </span>aws ec2 describe-security-groups <span class="nt">--query</span> <span class="s1">'SecurityGroups[*].[GroupId, GroupName]'</span> <span class="nt">--output</span> text
<span class="c"># =&gt; sg-07b8900660cb85dff default</span>
<span class="c">#    sg-0ece66fedd1fb4abe myeks-EKSEC2SG-1GNaTdbIbBNG</span>
<span class="c">#    sg-07663468a536ba88b eksctl-myeks-cluster-ControlPlaneSecurityGroup-S7dWa32uw1S7</span>
<span class="c">#    sg-0edc706b941f0aef7 eksctl-myeks-cluster-ClusterSharedNodeSecurityGroup-sO3DEJP4xewT</span>
<span class="c">#    sg-02c614a038ec1f7e7 eks-cluster-sg-myeks-104368993</span>
<span class="c">#    sg-036e220bf3d8aaf20 eksctl-myeks-nodegroup-ng1-remoteAccess</span>
<span class="c">#    sg-035e2b98b5ac89231 default</span>

<span class="c"># 노드 보안그룹 ID 확인</span>
<span class="nv">$ </span>aws ec2 describe-security-groups <span class="nt">--filters</span> <span class="nv">Name</span><span class="o">=</span>group-name,Values<span class="o">=</span><span class="k">*</span>ng1<span class="k">*</span> <span class="nt">--query</span> <span class="s2">"SecurityGroups[*].[GroupId]"</span> <span class="nt">--output</span> text
<span class="c"># =&gt; sg-036e220bf3d8aaf20</span>
<span class="nv">$ NGSGID</span><span class="o">=</span><span class="si">$(</span>aws ec2 describe-security-groups <span class="nt">--filters</span> <span class="nv">Name</span><span class="o">=</span>group-name,Values<span class="o">=</span><span class="k">*</span>ng1<span class="k">*</span> <span class="nt">--query</span> <span class="s2">"SecurityGroups[*].[GroupId]"</span> <span class="nt">--output</span> text<span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$NGSGID</span>
<span class="c"># =&gt; sg-036e220bf3d8aaf20</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"export NGSGID=</span><span class="nv">$NGSGID</span><span class="s2">"</span> <span class="o">&gt;&gt;</span> /etc/profile

<span class="c"># 노드 보안그룹에 eksctl-host 에서 노드(파드)에 접속 가능하게 룰(Rule) 추가 설정</span>
<span class="nv">$ </span>aws ec2 authorize-security-group-ingress <span class="nt">--group-id</span> <span class="nv">$NGSGID</span> <span class="nt">--protocol</span> <span class="s1">'-1'</span> <span class="nt">--cidr</span> 192.168.1.100/32

<span class="c"># eksctl-host 에서 노드의IP나 coredns 파드IP로 ping 테스트</span>
<span class="nv">$ </span>ping <span class="nt">-c</span> 1 <span class="nv">$N1</span>
<span class="c"># =&gt; PING 192.168.1.186 (192.168.1.186) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 192.168.1.186: icmp_seq=1 ttl=255 time=0.492 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 192.168.1.186 ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 0.492/0.492/0.492/0.000 ms</span>
<span class="nv">$ </span>ping <span class="nt">-c</span> 1 <span class="nv">$N2</span>
<span class="nv">$ </span>ping <span class="nt">-c</span> 1 <span class="nv">$N3</span>

<span class="c"># 워커 노드 SSH 접속 : '-i ~/.ssh/id_rsa' 생략 가능</span>
<span class="nv">$ </span><span class="k">for </span>node <span class="k">in</span> <span class="nv">$N1</span> <span class="nv">$N2</span> <span class="nv">$N3</span><span class="p">;</span> <span class="k">do </span>ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no ec2-user@<span class="nv">$node</span> <span class="nb">hostname</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span>ssh ec2-user@<span class="nv">$N1</span>
<span class="nv">$ </span><span class="nb">exit</span>
<span class="nv">$ </span>ssh ec2-user@<span class="nv">$N2</span>
<span class="nv">$ </span><span class="nb">exit</span>
<span class="nv">$ </span>ssh ec2-user@<span class="nv">$N3</span>
<span class="nv">$ </span><span class="nb">exit</span>
</code></pre></div></div>

<ul>
  <li>Add-on 정보확인 : 최신 버전 - kube-proxy, coredns, aws vpc cni - 링크 mgmt</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 모든 파드의 컨테이너 이미지 정보 확인</span>
<span class="nv">$ </span>kubectl get pods <span class="nt">--all-namespaces</span> <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.items[*].spec.containers[*].image}"</span> | <span class="nb">tr</span> <span class="nt">-s</span> <span class="s1">'[[:space:]]'</span> <span class="s1">'\n'</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span>
<span class="c"># =&gt;       3 602401143452.dkr.ecr.ap-northeast-2.amazonaws.com/amazon/aws-network-policy-agent:v1.1.4-eksbuild.1</span>
<span class="c">#          3 602401143452.dkr.ecr.ap-northeast-2.amazonaws.com/amazon-k8s-cni:v1.18.6-eksbuild.1</span>
<span class="c">#          2 602401143452.dkr.ecr.ap-northeast-2.amazonaws.com/eks/coredns:v1.11.3-eksbuild.2</span>
<span class="c">#          3 602401143452.dkr.ecr.ap-northeast-2.amazonaws.com/eks/kube-proxy:v1.30.5-minimal-eksbuild.2</span>
<span class="c"># 위 버전은 Add-on 으로 최신 버전 설치</span>
<span class="nv">$ </span>kubectl get pods <span class="nt">-A</span>
<span class="nv">$ </span>kubectl get pods <span class="nt">--all-namespaces</span> <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.items[*].spec.containers[*].image}"</span> | <span class="nb">tr</span> <span class="nt">-s</span> <span class="s1">'[[:space:]]'</span> <span class="s1">'\n'</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span>
<span class="c"># =&gt;       3 602401143452.dkr.ecr.ap-northeast-2.amazonaws.com/amazon/aws-network-policy-agent:v1.1.4-eksbuild.1</span>
<span class="c">#          3 602401143452.dkr.ecr.ap-northeast-2.amazonaws.com/amazon-k8s-cni:v1.18.6-eksbuild.1</span>
<span class="c">#          2 602401143452.dkr.ecr.ap-northeast-2.amazonaws.com/eks/coredns:v1.11.3-eksbuild.2</span>
<span class="c">#          3 602401143452.dkr.ecr.ap-northeast-2.amazonaws.com/eks/kube-proxy:v1.30.5-minimal-eksbuild.2</span>

<span class="c"># eksctl 설치/업데이트 addon 확인</span>
<span class="nv">$ </span>eksctl get addon <span class="nt">--cluster</span> <span class="nv">$CLUSTER_NAME</span>
<span class="c"># =&gt; NAME        VERSION             STATUS  ISSUES      IAMROLE                                                                       UPDATE                AVAILABLE  CONFIGURATION  VALUES  POD      IDENTITY  ASSOCIATION  ROLES</span>
<span class="c">#    coredns     v1.11.3-eksbuild.2  ACTIVE  0</span>
<span class="c">#    kube-proxy  v1.30.5-eksbuild.2  ACTIVE  0</span>
<span class="c">#    vpc-cni     v1.18.6-eksbuild.1  ACTIVE  0           arn:aws:iam::123456789012:role/eksctl-myeks-addon-vpc-cni-Role1-QUy8qUBqFjcx  enableNetworkPolicy:  &amp;quot;true&amp;quot;</span>

<span class="c"># (참고) eks 설치 yaml 중 addon 내용</span>
<span class="nv">$ </span><span class="nb">tail</span> <span class="nt">-n11</span> myeks.yaml
<span class="c"># =&gt; addons:</span>
<span class="c">#      - name: vpc-cni # no version is specified so it deploys the default version</span>
<span class="c">#        version: latest # auto discovers the latest available</span>
<span class="c">#        attachPolicyARNs:</span>
<span class="c">#          - arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy</span>
<span class="c">#        configurationValues: |-</span>
<span class="c">#          enableNetworkPolicy: &amp;quot;true&amp;quot;</span>
<span class="c">#      - name: kube-proxy</span>
<span class="c">#        version: latest</span>
<span class="c">#      - name: coredns</span>
<span class="c">#        version: latest</span>
</code></pre></div></div>

<hr />

<h3 id="노드에서-기본-네트워크-정보-확인">노드에서 기본 네트워크 정보 확인</h3>

<h4 id="워커-노드-기본-네트워크-구성">워커 노드 기본 네트워크 구성</h4>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_5.png" alt="img.png" class="image-center w-60" /></p>

<ul>
  <li>네트워크 네임스페이스는 호스트(Root)와 파드별(Per Pod)로 구분됩니다.</li>
  <li>특정한 파드 (kube-proxy, aws-node)는 호스트의 IP를 그대로 사용합니다. =&gt; 파드의 Host Network 옵션 - <a href="https://xn--vj5b11biyw.kr/306">참고</a></li>
  <li>t3.medium 의 경우 ENI 마다 최대 6개의 IP를 가질 수 있습니다. (ENI 당 5개의 보조 IP)</li>
  <li>ENI0, ENI1 으로 2개의 ENI는 자신의 IP 이외에 추가적으로 5개의 보조 프라이빗 IP를 가질 수 있습니다.</li>
  <li>coredns 파드는 veth으로 호스트에는 eniY@ifN 인터페이스와 파드에 eth0과 연결되어 있습니다.</li>
</ul>

<h4 id="실습-보조-ipv4-주소를-파드가-사용하는지-확인">[실습] 보조 IPv4 주소를 파드가 사용하는지 확인</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># coredns 파드 IP 정보 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>kube-dns <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                       READY   STATUS    RESTARTS   AGE   IP             NODE                                               NOMINATED NODE   READINESS GATES</span>
<span class="c">#    coredns-699d8c5988-bvxtz   1/1     Running   0          18m   192.168.1.30   ip-192-168-1-186.ap-northeast-2.compute.internal   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    coredns-699d8c5988-vt68k   1/1     Running   0          18m   192.168.3.82   ip-192-168-3-235.ap-northeast-2.compute.internal   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>

<span class="c"># 노드의 라우팅 정보 확인 &gt;&gt; EC2 네트워크 정보의 '보조 프라이빗 IPv4 주소'와 비교해보자</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="nv">$N1</span> <span class="nv">$N2</span> <span class="nv">$N3</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> ssh ec2-user@<span class="nv">$i</span> <span class="nb">sudo </span>ip <span class="nt">-c</span> route<span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; node 192.168.1.186 &amp;lt;&amp;lt;</span>
<span class="c">#    default via 192.168.1.1 dev eth0</span>
<span class="c">#    169.254.169.254 dev eth0</span>
<span class="c">#    192.168.1.0/24 dev eth0 proto kernel scope link src 192.168.1.186</span>
<span class="c">#    192.168.1.30 dev eni319ad74733c scope link</span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; node 192.168.2.92 &amp;lt;&amp;lt;</span>
<span class="c">#    default via 192.168.2.1 dev eth0</span>
<span class="c">#    169.254.169.254 dev eth0</span>
<span class="c">#    192.168.2.0/24 dev eth0 proto kernel scope link src 192.168.2.92</span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; node 192.168.3.235 &amp;lt;&amp;lt;</span>
<span class="c">#    default via 192.168.3.1 dev eth0</span>
<span class="c">#    169.254.169.254 dev eth0</span>
<span class="c">#    192.168.3.0/24 dev eth0 proto kernel scope link src 192.168.3.235</span>
<span class="c">#    192.168.3.82 dev enid438418b082 scope link</span>

<span class="c"># &lt;span style="color: green;"&gt;👉 노드의 IP와 파드의 IP가 같은 대역임을 확인 할 수 있습니다.&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;    예를 들어서 노드 IP가 192.168.1.186인 경우 파드는 192.168.1.30으로&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;    동일한 IP 대역으로, 보조 IPv4가 사용됨을 확인 할 수 있습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<h4 id="실습-테스트용-파드-생성---nicolakanetshoot">[실습] 테스트용 파드 생성 - <a href="https://github.com/nicolaka/netshoot">nicolaka/netshoot</a></h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># [터미널1~3] 노드 모니터링</span>
<span class="nv">$ </span>ssh ec2-user@<span class="nv">$N1</span>
<span class="c"># =&gt; [ec2-user@ip-192-168-1-186 ~]$</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> <span class="s2">"ip link | egrep 'eth|eni' ;echo;echo "</span><span class="o">[</span>ROUTE TABLE]<span class="s2">"; route -n | grep eni"</span>
<span class="c"># =&gt; 2: eth0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc</span>
<span class="c">#     mq state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 02:35:26:fe:f6:2f brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    3: eni319ad74733c@if3: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt;</span>
<span class="c">#    mtu 9001 qdisc noqueue state UP mode DEFAULT group defaul</span>
<span class="c">#    t</span>
<span class="c">#        link/ether 16:69:60:63:cf:f7 brd ff:ff:ff:ff:ff:ff li</span>
<span class="c">#    nk-netns cni-a953612e-ef39-78ca-660c-2a1ecde16b39</span>
<span class="c">#    4: eth1: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc</span>
<span class="c">#     mq state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 02:86:42:43:71:d1 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    </span>
<span class="c">#    [ROUTE TABLE]</span>
<span class="c">#    192.168.1.30    0.0.0.0         255.255.255.255 UH    0</span>
<span class="c">#        0        0 eni319ad74733c</span>

<span class="nv">$ </span>ssh ec2-user@<span class="nv">$N2</span>
<span class="c"># =&gt; [ec2-user@ip-192-168-2-92 ~]$</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> <span class="s2">"ip link | egrep 'eth|eni' ;echo;echo "</span><span class="o">[</span>ROUTE TABLE]<span class="s2">"; route -n | grep eni"</span>
<span class="c"># =&gt; 2: eth0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc</span>
<span class="c">#     mq state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 06:bc:36:ed:7c:d3 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    </span>
<span class="c">#    [ROUTE TABLE]</span>

<span class="nv">$ </span>ssh ec2-user@<span class="nv">$N3</span>
<span class="c"># =&gt; [ec2-user@ip-192-168-3-235 ~]$</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> <span class="s2">"ip link | egrep 'eth|eni' ;echo;echo "</span><span class="o">[</span>ROUTE TABLE]<span class="s2">"; route -n | grep eni"</span>
<span class="c"># =&gt; 2: eth0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc</span>
<span class="c">#     mq state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 0a:3e:a1:00:00:05 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    3: enid438418b082@if3: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt;</span>
<span class="c">#    mtu 9001 qdisc noqueue state UP mode DEFAULT group defaul</span>
<span class="c">#    t</span>
<span class="c">#        link/ether 02:50:3a:92:0e:1b brd ff:ff:ff:ff:ff:ff li</span>
<span class="c">#    nk-netns cni-23569158-d846-4981-4105-ec08005e9b95</span>
<span class="c">#    4: eth1: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc</span>
<span class="c">#     mq state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 0a:e8:ac:41:8c:ab brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    </span>
<span class="c">#    [ROUTE TABLE]</span>
<span class="c">#    192.168.3.82    0.0.0.0         255.255.255.255 UH    0</span>
<span class="c">#        0        0 enid438418b082</span>

<span class="c"># 테스트용 파드 netshoot-pod 생성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: netshoot-pod
spec:
  replicas: 3
  selector:
    matchLabels:
      app: netshoot-pod
  template:
    metadata:
      labels:
        app: netshoot-pod
    spec:
      containers:
      - name: netshoot-pod
        image: nicolaka/netshoot
        command: ["tail"]
        args: ["-f", "/dev/null"]
      terminationGracePeriodSeconds: 0
</span><span class="no">EOF
</span><span class="c"># =&gt; deployment.apps/netshoot-pod created</span>

<span class="c"># 파드 이름 변수 지정</span>
<span class="nv">$ PODNAME1</span><span class="o">=</span><span class="si">$(</span>kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>netshoot-pod <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.items[0].metadata.name<span class="o">}</span><span class="si">)</span>
<span class="nv">$ PODNAME2</span><span class="o">=</span><span class="si">$(</span>kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>netshoot-pod <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.items[1].metadata.name<span class="o">}</span><span class="si">)</span>
<span class="nv">$ PODNAME3</span><span class="o">=</span><span class="si">$(</span>kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>netshoot-pod <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.items[2].metadata.name<span class="o">}</span><span class="si">)</span>

<span class="c"># 파드 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-o</span> wide
<span class="c"># =&gt; NAME                            READY   STATUS    RESTARTS   AGE   IP              NODE                                               NOMINATED NODE   READINESS GATES</span>
<span class="c">#    netshoot-pod-74b7555dc7-6qsvf   1/1     Running   0          29s   192.168.1.112   ip-192-168-1-186.ap-northeast-2.compute.internal   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    netshoot-pod-74b7555dc7-x6lxb   1/1     Running   0          29s   192.168.2.172   ip-192-168-2-92.ap-northeast-2.compute.internal    &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    netshoot-pod-74b7555dc7-x7r96   1/1     Running   0          29s   192.168.3.246   ip-192-168-3-235.ap-northeast-2.compute.internal   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-o</span><span class="o">=</span>custom-columns<span class="o">=</span>NAME:.metadata.name,IP:.status.podIP
<span class="c"># =&gt; NAME                            IP</span>
<span class="c">#    netshoot-pod-74b7555dc7-6qsvf   192.168.1.112</span>
<span class="c">#    netshoot-pod-74b7555dc7-x6lxb   192.168.2.172</span>
<span class="c">#    netshoot-pod-74b7555dc7-x7r96   192.168.3.246</span>

<span class="c"># 노드에 라우팅 정보 확인</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="nv">$N1</span> <span class="nv">$N2</span> <span class="nv">$N3</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> ssh ec2-user@<span class="nv">$i</span> <span class="nb">sudo </span>ip <span class="nt">-c</span> route<span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt; node 192.168.1.186 &amp;lt;&amp;lt;</span>
<span class="c">#    default via 192.168.1.1 dev eth0</span>
<span class="c">#    169.254.169.254 dev eth0</span>
<span class="c">#    192.168.1.0/24 dev eth0 proto kernel scope link src 192.168.1.186</span>
<span class="c">#    192.168.1.30 dev eni319ad74733c scope link</span>
<span class="c">#    192.168.1.112 dev eni7ecb7efa346 scope link  # &lt;span style="color: green;"&gt;👉 추가된 신규 파드의 IPv4 보조 IP&lt;/span&gt;</span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; node 192.168.2.92 &amp;lt;&amp;lt;</span>
<span class="c">#    default via 192.168.2.1 dev eth0</span>
<span class="c">#    169.254.169.254 dev eth0</span>
<span class="c">#    192.168.2.0/24 dev eth0 proto kernel scope link src 192.168.2.92</span>
<span class="c">#    192.168.2.172 dev enif06a5cbfaaa scope link  # &lt;span style="color: green;"&gt;👉 추가된 신규 파드의 IPv4 보조 IP&lt;/span&gt;</span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; node 192.168.3.235 &amp;lt;&amp;lt;</span>
<span class="c">#    default via 192.168.3.1 dev eth0</span>
<span class="c">#    169.254.169.254 dev eth0</span>
<span class="c">#    192.168.3.0/24 dev eth0 proto kernel scope link src 192.168.3.235</span>
<span class="c">#    192.168.3.82 dev enid438418b082 scope link</span>
<span class="c">#    192.168.3.246 dev eniea7f0ec96dd scope link  # &lt;span style="color: green;"&gt;👉 추가된 신규 파드의 IPv4 보조 IP&lt;/span&gt;</span>
</code></pre></div></div>

<ul>
  <li>파드가 생성되면, 워커 노드에 eniY@ifN 추가되고 라우팅 테이블에도 정보가 추가된것을 확인 할 수 있습니다.</li>
  <li>테스트용 파드 eniY 정보 확인 - 워커 노드 EC2</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 노드3에서 네트워크 인터페이스 정보 확인</span>
<span class="nv">$ </span>ssh ec2-user@<span class="nv">$N3</span>
<span class="nt">----------------</span>
<span class="nv">$ </span>ip <span class="nt">-br</span> <span class="nt">-c</span> addr show
<span class="c"># =&gt; lo               UNKNOWN        127.0.0.1/8 ::1/128</span>
<span class="c">#    eth0             UP             192.168.3.235/24 fe80::83e:a1ff:fe00:5/64</span>
<span class="c">#    enid438418b082@if3 UP             fe80::50:3aff:fe92:e1b/64</span>
<span class="c">#    eth1             UP             192.168.3.236/24 fe80::8e8:acff:fe41:8cab/64</span>
<span class="c">#    eniea7f0ec96dd@if3 UP             fe80::8cd8:57ff:fee7:29c/64</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> <span class="nb">link</span>
<span class="c"># =&gt; 1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span>
<span class="c">#    2: eth0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc mq state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 0a:3e:a1:00:00:05 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    3: enid438418b082@if3: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc noqueue state UP mode DEFAULT group default</span>
<span class="c">#        link/ether 02:50:3a:92:0e:1b brd ff:ff:ff:ff:ff:ff link-netns cni-23569158-d846-4981-4105-ec08005e9b95</span>
<span class="c">#    4: eth1: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc mq state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 0a:e8:ac:41:8c:ab brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    5: eniea7f0ec96dd@if3: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc noqueue state UP mode DEFAULT group default</span>
<span class="c">#        link/ether 8e:d8:57:e7:02:9c brd ff:ff:ff:ff:ff:ff link-netns cni-508d7216-7484-4497-a023-c6236435d535</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> addr
<span class="c"># =&gt; ...</span>
<span class="c">#    2: eth0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc mq state UP group default qlen 1000</span>
<span class="c">#        link/ether 0a:3e:a1:00:00:05 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet 192.168.3.235/24 brd 192.168.3.255 scope global dynamic eth0</span>
<span class="c">#           valid_lft 2166sec preferred_lft 2166sec</span>
<span class="c">#        inet6 fe80::83e:a1ff:fe00:5/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    3: enid438418b082@if3: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc noqueue state UP group default</span>
<span class="c">#        link/ether 02:50:3a:92:0e:1b brd ff:ff:ff:ff:ff:ff link-netns cni-23569158-d846-4981-4105-ec08005e9b95</span>
<span class="c">#        inet6 fe80::50:3aff:fe92:e1b/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    4: eth1: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc mq state UP group default qlen 1000</span>
<span class="c">#        link/ether 0a:e8:ac:41:8c:ab brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet 192.168.3.236/24 brd 192.168.3.255 scope global eth1</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#        inet6 fe80::8e8:acff:fe41:8cab/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    5: eniea7f0ec96dd@if3: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc noqueue state UP group default</span>
<span class="c">#        link/ether 8e:d8:57:e7:02:9c brd ff:ff:ff:ff:ff:ff link-netns cni-508d7216-7484-4497-a023-c6236435d535</span>
<span class="c">#        inet6 fe80::8cd8:57ff:fee7:29c/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="nv">$ </span>ip route <span class="c"># 혹은 route -n</span>
<span class="c"># =&gt; default via 192.168.3.1 dev eth0</span>
<span class="c">#    169.254.169.254 dev eth0</span>
<span class="c">#    192.168.3.0/24 dev eth0 proto kernel scope link src 192.168.3.235</span>
<span class="c">#    192.168.3.82 dev enid438418b082 scope link</span>
<span class="c">#    192.168.3.246 dev eniea7f0ec96dd scope link</span>
  
<span class="c"># 마지막 생성된 네임스페이스 정보 출력 -t net(네트워크 타입)</span>
<span class="nv">$ </span><span class="nb">sudo </span>lsns <span class="nt">-o</span> PID,COMMAND <span class="nt">-t</span> net | <span class="nb">awk</span> <span class="s1">'NR&gt;2 {print $1}'</span> | <span class="nb">tail</span> <span class="nt">-n</span> 1
<span class="c"># =&gt; 9774</span>
  
<span class="c"># 마지막 생성된 네임스페이스 net PID 정보 출력 -t net(네트워크 타입)를 변수 지정</span>
<span class="nv">$ MyPID</span><span class="o">=</span><span class="si">$(</span><span class="nb">sudo </span>lsns <span class="nt">-o</span> PID,COMMAND <span class="nt">-t</span> net | <span class="nb">awk</span> <span class="s1">'NR&gt;2 {print $1}'</span> | <span class="nb">tail</span> <span class="nt">-n</span> 1<span class="si">)</span>
  
<span class="c"># PID 정보로 파드 정보 확인</span>
<span class="nv">$ </span><span class="nb">sudo </span>nsenter <span class="nt">-t</span> <span class="nv">$MyPID</span> <span class="nt">-n</span> ip <span class="nt">-c</span> addr
<span class="c"># =&gt; ...</span>
<span class="c">#    3: eth0@if5: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc noqueue state UP group default</span>
<span class="c">#        link/ether 6a:d5:4d:a7:45:7e brd ff:ff:ff:ff:ff:ff link-netnsid 0</span>
<span class="c">#        inet 192.168.3.246/32 scope global eth0</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#        inet6 fe80::68d5:4dff:fea7:457e/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="nv">$ </span><span class="nb">sudo </span>nsenter <span class="nt">-t</span> <span class="nv">$MyPID</span> <span class="nt">-n</span> ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 169.254.1.1 dev eth0</span>
<span class="c">#    169.254.1.1 dev eth0 scope link</span>
  
<span class="nv">$ </span><span class="nb">exit</span>
<span class="nt">----------------</span>
</code></pre></div></div>

<ul>
  <li>테스트용 파드 접속(exec) 후 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 테스트용 파드 접속(exec) 후 Shell 실행</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$PODNAME1</span> <span class="nt">--</span> zsh
<span class="c"># =&gt;  netshoot-pod-74b7555dc7-6qsvf  ~ </span>
  
<span class="c"># 아래부터는 pod-1 Shell 에서 실행 : 네트워크 정보 확인</span>
<span class="nt">----------------------------</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> addr
<span class="c"># =&gt; ...</span>
<span class="c">#    3: eth0@if5: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc noqueue state UP group default</span>
<span class="c">#        link/ether c6:cb:41:a0:85:57 brd ff:ff:ff:ff:ff:ff link-netnsid 0</span>
<span class="c">#        inet 192.168.1.112/32 scope global eth0</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#        inet6 fe80::c4cb:41ff:fea0:8557/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 169.254.1.1 dev eth0</span>
<span class="c">#    169.254.1.1 dev eth0 scope link</span>
<span class="nv">$ </span>route <span class="nt">-n</span>
<span class="c"># =&gt; Kernel IP routing table</span>
<span class="c">#    Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span>
<span class="c">#    0.0.0.0         169.254.1.1     0.0.0.0         UG    0      0        0 eth0</span>
<span class="c">#    169.254.1.1     0.0.0.0         255.255.255.255 UH    0      0        0 eth0</span>
<span class="c">#$ ping -c 1 &lt;pod-2 IP&gt;</span>
<span class="nv">$ </span>ping <span class="nt">-c</span> 1 192.168.2.172
<span class="c"># =&gt; PING 192.168.2.172 (192.168.2.172) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 192.168.2.172: icmp_seq=1 ttl=125 time=1.25 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 192.168.2.172 ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 1.249/1.249/1.249/0.000 ms</span>
<span class="nv">$ </span>ps
<span class="c"># =&gt; PID   USER     TIME  COMMAND</span>
<span class="c">#        1 root      0:00 tail -f /dev/null</span>
<span class="c">#      109 root      0:00 zsh</span>
<span class="c">#      186 root      0:00 ps</span>
<span class="nv">$ </span><span class="nb">cat</span> /etc/resolv.conf
<span class="c"># =&gt; search default.svc.cluster.local svc.cluster.local cluster.local ap-northeast-2.compute.internal</span>
<span class="c">#    nameserver 10.100.0.10</span>
<span class="c">#    options ndots:5</span>
<span class="nv">$ </span><span class="nb">exit</span>
<span class="nt">----------------------------</span>
  
<span class="c"># 파드2 Shell 실행</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$PODNAME2</span> <span class="nt">--</span> ip <span class="nt">-c</span> addr
<span class="c"># =&gt; ...</span>
<span class="c">#    3: eth0@if3: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc noqueue state UP group default</span>
<span class="c">#        link/ether 02:ea:11:63:f6:9f brd ff:ff:ff:ff:ff:ff link-netnsid 0</span>
<span class="c">#        inet 192.168.2.172/32 scope global eth0</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#        inet6 fe80::ea:11ff:fe63:f69f/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
  
<span class="c"># 파드3 Shell 실행</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$PODNAME3</span> <span class="nt">--</span> ip <span class="nt">-br</span> <span class="nt">-c</span> addr
<span class="c"># =&gt; lo               UNKNOWN        127.0.0.1/8 ::1/128</span>
<span class="c">#    eth0@if5         UP             192.168.3.246/32 fe80::68d5:4dff:fea7:457e/64</span>
</code></pre></div></div>

<hr />

<h3 id="노드간-파드-통신">노드간 파드 통신</h3>

<ul>
  <li><strong>파드간 통신 흐름</strong> : AWS VPC CNI의 경우 별도의 오버레이(Overlay) 통신 기술없이, VPC에서 Native하게 파드간 직접 통신이 가능합니다.</li>
</ul>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_6.png" alt="img.png" class="image-center" /></p>

<ul>
  <li>파드간 통신 과정 참고</li>
</ul>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_7.png" alt="img.png" class="image-center" />
<em class="image-caption"><a href="https://github.com/aws/amazon-vpc-cni-k8s/blob/master/docs/cni-proposal.md">https://github.com/aws/amazon-vpc-cni-k8s/blob/master/docs/cni-proposal.md</a></em></p>

<h4 id="실습-파드간-통신-테스트-및-확인--별도의-nat-동작-없이-통신-가능">[실습] 파드간 통신 테스트 및 확인 : 별도의 NAT 동작 없이 통신 가능!</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 파드 IP 변수 지정</span>
<span class="nv">$ PODIP1</span><span class="o">=</span><span class="si">$(</span>kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>netshoot-pod <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.items[0].status.podIP<span class="o">}</span><span class="si">)</span>
<span class="nv">$ PODIP2</span><span class="o">=</span><span class="si">$(</span>kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>netshoot-pod <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.items[1].status.podIP<span class="o">}</span><span class="si">)</span>
<span class="nv">$ PODIP3</span><span class="o">=</span><span class="si">$(</span>kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>netshoot-pod <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.items[2].status.podIP<span class="o">}</span><span class="si">)</span>

<span class="c"># 파드1 Shell 에서 파드2로 ping 테스트</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$PODNAME1</span> <span class="nt">--</span> ping <span class="nt">-c</span> 2 <span class="nv">$PODIP2</span>
<span class="c"># =&gt; PING 192.168.2.172 (192.168.2.172) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 192.168.2.172: icmp_seq=1 ttl=125 time=0.915 ms</span>
<span class="c">#    64 bytes from 192.168.2.172: icmp_seq=2 ttl=125 time=0.870 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 192.168.2.172 ping statistics ---</span>
<span class="c">#    2 packets transmitted, 2 received, 0% packet loss, time 1001ms</span>
<span class="c">#    rtt min/avg/max/mdev = 0.870/0.892/0.915/0.022 ms</span>

<span class="c"># 파드2 Shell 에서 파드3로 ping 테스트</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$PODNAME2</span> <span class="nt">--</span> ping <span class="nt">-c</span> 2 <span class="nv">$PODIP3</span>
<span class="c"># =&gt; PING 192.168.3.246 (192.168.3.246) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 192.168.3.246: icmp_seq=1 ttl=125 time=1.79 ms</span>
<span class="c">#    64 bytes from 192.168.3.246: icmp_seq=2 ttl=125 time=1.25 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 192.168.3.246 ping statistics ---</span>
<span class="c">#    2 packets transmitted, 2 received, 0% packet loss, time 1002ms</span>
<span class="c">#    rtt min/avg/max/mdev = 1.245/1.516/1.788/0.271 ms</span>

<span class="c"># 파드3 Shell 에서 파드1로 ping 테스트</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$PODNAME3</span> <span class="nt">--</span> ping <span class="nt">-c</span> 2 <span class="nv">$PODIP1</span>
<span class="c"># =&gt; PING 192.168.1.112 (192.168.1.112) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 192.168.1.112: icmp_seq=1 ttl=125 time=1.08 ms</span>
<span class="c">#    64 bytes from 192.168.1.112: icmp_seq=2 ttl=125 time=1.23 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 192.168.1.112 ping statistics ---</span>
<span class="c">#    2 packets transmitted, 2 received, 0% packet loss, time 1001ms</span>
<span class="c">#    rtt min/avg/max/mdev = 1.084/1.155/1.227/0.071 ms</span>

<span class="c"># 워커 노드 EC2 : TCPDUMP 확인</span>
<span class="c">## For Pod to external (outside VPC) traffic, we will program iptables to SNAT using Primary IP address on the Primary ENI.</span>
<span class="nv">$ </span><span class="nb">sudo </span>tcpdump <span class="nt">-i</span> any <span class="nt">-nn</span> icmp
<span class="c"># =&gt; 08:11:33.865634 IP 192.168.2.172 &amp;gt; 192.168.3.246: ICMP echo request, id 19, seq 1, length 64</span>
<span class="c">#    08:11:33.865684 IP 192.168.2.172 &amp;gt; 192.168.3.246: ICMP echo request, id 19, seq 1, length 64</span>
<span class="c">#    08:11:33.867117 IP 192.168.3.246 &amp;gt; 192.168.2.172: ICMP echo reply, id 19, seq 1, length 64</span>
<span class="c">#    08:11:33.867195 IP 192.168.3.246 &amp;gt; 192.168.2.172: ICMP echo reply, id 19, seq 1, length 64</span>
<span class="c">#    08:11:34.866610 IP 192.168.2.172 &amp;gt; 192.168.3.246: ICMP echo request, id 19, seq 2, length 64</span>
<span class="c">#    08:11:34.866654 IP 192.168.2.172 &amp;gt; 192.168.3.246: ICMP echo request, id 19, seq 2, length 64</span>
<span class="c">#    08:11:34.867865 IP 192.168.3.246 &amp;gt; 192.168.2.172: ICMP echo reply, id 19, seq 2, length 64</span>
<span class="c">#    08:11:34.867891 IP 192.168.3.246 &amp;gt; 192.168.2.172: ICMP echo reply, id 19, seq 2, length 64</span>
<span class="nv">$ </span><span class="nb">sudo </span>tcpdump <span class="nt">-i</span> eth1 <span class="nt">-nn</span> icmp
<span class="c"># &lt;span style="color: green;"&gt;👉 캡쳐된 패킷이 없습니다.&lt;/span&gt;</span>
<span class="nv">$ </span><span class="nb">sudo </span>tcpdump <span class="nt">-i</span> eth0 <span class="nt">-nn</span> icmp
<span class="c"># =&gt; 08:11:33.865689 IP 192.168.2.172 &amp;gt; 192.168.3.246: ICMP echo request, id 19, seq 1, length 64</span>
<span class="c">#    08:11:33.867117 IP 192.168.3.246 &amp;gt; 192.168.2.172: ICMP echo reply, id 19, seq 1, length 64</span>
<span class="c">#    08:11:34.866654 IP 192.168.2.172 &amp;gt; 192.168.3.246: ICMP echo request, id 19, seq 2, length 64</span>
<span class="c">#    08:11:34.867865 IP 192.168.3.246 &amp;gt; 192.168.2.172: ICMP echo reply, id 19, seq 2, length 64</span>
<span class="nv">$ </span><span class="nb">sudo </span>tcpdump <span class="nt">-i</span> eniYYYYYYYY <span class="nt">-nn</span> icmp
<span class="c"># =&gt; 08:11:33.865643 IP 192.168.2.172 &amp;gt; 192.168.3.246: ICMP echo request, id 19, seq 1, length 64</span>
<span class="c">#    08:11:33.867195 IP 192.168.3.246 &amp;gt; 192.168.2.172: ICMP echo reply, id 19, seq 1, length 64</span>
<span class="c">#    08:11:34.866610 IP 192.168.2.172 &amp;gt; 192.168.3.246: ICMP echo request, id 19, seq 2, length 64</span>
<span class="c">#    08:11:34.867891 IP 192.168.3.246 &amp;gt; 192.168.2.172: ICMP echo reply, id 19, seq 2, length 64</span>

<span class="c"># [워커 노드1]</span>
<span class="c"># routing policy database management 확인</span>
<span class="nv">$ </span>ip rule
<span class="c"># =&gt; 0: from all lookup local</span>
<span class="c">#    512: from all to 192.168.1.30 lookup main</span>
<span class="c">#    512: from all to 192.168.1.112 lookup main</span>
<span class="c">#    1024:  from all fwmark 0x80/0x80 lookup main</span>
<span class="c">#    32766: from all lookup main</span>
<span class="c">#    32767: from all lookup default</span>

<span class="c"># routing table management 확인</span>
<span class="nv">$ </span>ip route show table <span class="nb">local</span>
<span class="c"># =&gt; broadcast 127.0.0.0 dev lo proto kernel scope link src 127.0.0.1</span>
<span class="c">#    local 127.0.0.0/8 dev lo proto kernel scope host src 127.0.0.1</span>
<span class="c">#    local 127.0.0.1 dev lo proto kernel scope host src 127.0.0.1</span>
<span class="c">#    broadcast 127.255.255.255 dev lo proto kernel scope link src 127.0.0.1</span>
<span class="c">#    broadcast 192.168.1.0 dev eth0 proto kernel scope link src 192.168.1.186</span>
<span class="c">#    broadcast 192.168.1.0 dev eth1 proto kernel scope link src 192.168.1.9</span>
<span class="c">#    local 192.168.1.9 dev eth1 proto kernel scope host src 192.168.1.9</span>
<span class="c">#    local 192.168.1.186 dev eth0 proto kernel scope host src 192.168.1.186</span>
<span class="c">#    broadcast 192.168.1.255 dev eth0 proto kernel scope link src 192.168.1.186</span>
<span class="c">#    broadcast 192.168.1.255 dev eth1 proto kernel scope link src 192.168.1.9</span>

<span class="c"># 디폴트 네트워크 정보를 eth0 을 통해서 빠져나간다</span>
<span class="nv">$ </span>ip route show table main
<span class="c"># =&gt; default via 192.168.1.1 dev eth0</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<hr />

<h3 id="파드에서-외부-통신">파드에서 외부 통신</h3>

<ul>
  <li>파드에서 외부 통신 흐름 : iptable 에 SNAT 을 통하여 노드의 eth0 IP로 변경되어서 외부와 통신합니다.</li>
</ul>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_8.png" alt="img.png" class="image-center" />
<em class="image-caption"><a href="https://github.com/aws/amazon-vpc-cni-k8s/blob/master/docs/cni-proposal.md">https://github.com/aws/amazon-vpc-cni-k8s/blob/master/docs/cni-proposal.md</a></em></p>

<ul>
  <li>VPC CNI 의 External source network address translation (<code class="language-plaintext highlighter-rouge">SNAT</code>) 설정에 따라, 외부(인터넷) 통신 시 <strong>SNAT</strong> 하거나 혹은 <strong>SNAT 없이</strong> 통신을 할 수 있다 - <a href="https://docs.aws.amazon.com/eks/latest/userguide/external-snat.html">링크</a></li>
</ul>

<h4 id="실습-파드에서-외부-통신-테스트-및-확인"><strong>[실습] 파드에서 외부 통신</strong> 테스트 및 확인</h4>

<ul>
  <li>파드 shell 실행 후 외부로 ping 테스트 &amp; 워커 노드에서 tcpdump 및 iptables 정보 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 작업용 EC2 : pod-1 Shell 에서 외부로 ping</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$PODNAME1</span> <span class="nt">--</span> ping <span class="nt">-c</span> 1 www.google.com
<span class="c"># =&gt; PING www.google.com (172.217.25.164) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from kix06s19-in-f4.1e100.net (172.217.25.164): icmp_seq=1 ttl=104 time=39.0 ms</span>
<span class="c">#    </span>
<span class="c">#    --- www.google.com ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 38.967/38.967/38.967/0.000 ms</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$PODNAME1</span> <span class="nt">--</span> ping <span class="nt">-i</span> 0.1 www.google.com
  
<span class="c"># 워커 노드 EC2 : TCPDUMP 확인</span>
<span class="nv">$ </span><span class="nb">sudo </span>tcpdump <span class="nt">-i</span> any <span class="nt">-nn</span> icmp
<span class="nv">$ </span><span class="nb">sudo </span>tcpdump <span class="nt">-i</span> eth0 <span class="nt">-nn</span> icmp
  
<span class="c"># 작업용 EC2 : 퍼블릭IP 확인</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="nv">$N1</span> <span class="nv">$N2</span> <span class="nv">$N3</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> ssh ec2-user@<span class="nv">$i</span> curl <span class="nt">-s</span> ipinfo.io/ip<span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
  
<span class="c"># 작업용 EC2 : pod-1 Shell 에서 외부 접속 확인 - 공인IP는 어떤 주소인가?</span>
<span class="c">## The right way to check the weather - [링크](https://github.com/chubin/wttr.in)</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="nv">$PODNAME1</span> <span class="nv">$PODNAME2</span> <span class="nv">$PODNAME3</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; Pod : </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$i</span> <span class="nt">--</span> curl <span class="nt">-s</span> ipinfo.io/ip<span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$PODNAME1</span> <span class="nt">--</span> curl <span class="nt">-s</span> wttr.in/seoul
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$PODNAME1</span> <span class="nt">--</span> curl <span class="nt">-s</span> wttr.in/seoul?format<span class="o">=</span>3
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$PODNAME1</span> <span class="nt">--</span> curl <span class="nt">-s</span> wttr.in/Moon
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$PODNAME1</span> <span class="nt">--</span> curl <span class="nt">-s</span> wttr.in/:help
  
<span class="c"># 워커 노드 EC2</span>
<span class="nv">$ </span>ip rule
<span class="nv">$ </span>ip route show table main
<span class="nv">$ </span><span class="nb">sudo </span>iptables <span class="nt">-L</span> <span class="nt">-n</span> <span class="nt">-v</span> <span class="nt">-t</span> nat
<span class="nv">$ </span><span class="nb">sudo </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span>
  
<span class="c"># 파드가 외부와 통신시에는 아래 처럼 'AWS-SNAT-CHAIN-0' 룰(rule)에 의해서 SNAT 되어서 외부와 통신!</span>
<span class="c"># 참고로 뒤 IP는 eth0(ENI 첫번째)의 IP 주소입니다.</span>
<span class="c"># --random-fully 동작 - [링크1](https://ssup2.github.io/issue/Linux_TCP_SYN_Packet_Drop_SNAT_Port_Race_Condition/)  [링크2](https://ssup2.github.io/issue/Kubernetes_TCP_Connection_Delay_VXLAN_CNI_Plugin/)</span>
<span class="nv">$ </span><span class="nb">sudo </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span> | <span class="nb">grep</span> <span class="s1">'A AWS-SNAT-CHAIN'</span>
<span class="c"># =&gt; -A AWS-SNAT-CHAIN-0 -d 192.168.0.0/16 -m comment --comment &amp;quot;AWS SNAT CHAIN&amp;quot; -j RETURN</span>
<span class="c">#    -A AWS-SNAT-CHAIN-0 ! -o vlan+ -m comment --comment &amp;quot;AWS, SNAT&amp;quot; -m addrtype ! --dst-type LOCAL -j SNAT --to-source 192.168.2.92 --random-fully</span>
  
<span class="c">## 아래 'mark 0x4000/0x4000' 매칭되지 않아서 RETURN 됨!</span>
<span class="c"># =&gt; -A KUBE-POSTROUTING -m mark ! --mark 0x4000/0x4000 -j RETURN</span>
<span class="c">#    -A KUBE-POSTROUTING -j MARK --set-xmark 0x4000/0x0</span>
<span class="c">#    -A KUBE-POSTROUTING -m comment --comment &amp;quot;kubernetes service traffic requiring SNAT&amp;quot; -j MASQUERADE --random-fully</span>
<span class="c">#    ...</span>
  
<span class="c"># 카운트 확인 시 AWS-SNAT-CHAIN-0에 매칭되어, 목적지가 192.168.0.0/16 아니고 외부 빠져나갈때 SNAT 192.168.1.251(EC2 노드1 IP) 변경되어 나갑니다.</span>
<span class="nv">$ </span><span class="nb">sudo </span>iptables <span class="nt">-t</span> filter <span class="nt">--zero</span><span class="p">;</span> <span class="nb">sudo </span>iptables <span class="nt">-t</span> nat <span class="nt">--zero</span><span class="p">;</span> <span class="nb">sudo </span>iptables <span class="nt">-t</span> mangle <span class="nt">--zero</span><span class="p">;</span> <span class="nb">sudo </span>iptables <span class="nt">-t</span> raw <span class="nt">--zero</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> <span class="s1">'sudo iptables -v --numeric --table nat --list AWS-SNAT-CHAIN-0; echo ; sudo iptables -v --numeric --table nat --list KUBE-POSTROUTING; echo ; sudo iptables -v --numeric --table nat --list POSTROUTING'</span>
<span class="c"># =&gt; Chain AWS-SNAT-CHAIN-0 (1 references)</span>
<span class="c">#     pkts bytes target     prot opt in     out     source               destination</span>
<span class="c">#       12  1106 RETURN     all  --  *      *       0.0.0.0/0            192.168.0.0/16  /* AWS SNAT CHAIN */</span>
<span class="c">#       31  1924 SNAT       all  --  *      !vlan+  0.0.0.0/0            0.0.0.0/0            /* AWS, SNAT */ ADDRTYPE match dst-type !LOCAL to:192.168.2.92 random-fully</span>
<span class="c">#    </span>
<span class="c">#    Chain KUBE-POSTROUTING (1 references)</span>
<span class="c">#     pkts bytes target     prot opt in     out     source               destination</span>
<span class="c">#       53  3630 RETURN     all  --  *      *       0.0.0.0/0            0.0.0.0/0            mark match ! 0x4000/0x4000</span>
<span class="c">#        0     0 MARK       all  --  *      *       0.0.0.0/0            0.0.0.0/0            MARK xor 0x4000</span>
<span class="c">#        0     0 MASQUERADE  all  --  * * 0.0.0.0/0            0.0.0.0/0            /* kubernetes service traffic requiring SNAT */ random-fully</span>
<span class="c">#    </span>
<span class="c">#    Chain POSTROUTING (policy ACCEPT 22 packets, 1706 bytes)</span>
<span class="c">#     pkts bytes target     prot opt in     out     source               destination</span>
<span class="c">#       53  3630 KUBE-POSTROUTING  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes postrouting rules */</span>
<span class="c">#       53  3630 AWS-SNAT-CHAIN-0  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* AWS SNAT CHAIN */</span>
  
<span class="c"># conntrack 확인</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="nv">$N1</span> <span class="nv">$N2</span> <span class="nv">$N3</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> ssh ec2-user@<span class="nv">$i</span> <span class="nb">sudo </span>conntrack <span class="nt">-L</span> <span class="nt">-n</span> |grep <span class="nt">-v</span> <span class="s1">'169.254.169'</span><span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; node 192.168.1.186 &amp;lt;&amp;lt;</span>
<span class="c">#    udp      17 29 src=192.168.1.186 dst=146.56.40.151 sport=50772 dport=123 src=146.56.40.151 dst=192.168.1.186 sport=123 dport=47629 mark=128 use=1</span>
<span class="c">#    tcp      6 86395 ESTABLISHED src=192.168.1.186 dst=52.95.197.175 sport=45832 dport=443 src=52.95.197.175 dst=192.168.1.186 sport=443 dport=30346 [ASSURED] mark=128 use=1</span>
<span class="c">#    tcp      6 86395 ESTABLISHED src=192.168.1.186 dst=52.95.195.121 sport=48862 dport=443 src=52.95.195.121 dst=192.168.1.186 sport=443 dport=41664 [ASSURED] mark=128 use=1</span>
<span class="c">#    conntrack v1.4.4 (conntrack-tools): 59 flow entries have been shown.</span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; node 192.168.2.92 &amp;lt;&amp;lt;</span>
<span class="c">#    conntrack v1.4.4 (conntrack-tools): 50 flow entries have been shown.</span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; node 192.168.3.235 &amp;lt;&amp;lt;</span>
<span class="c">#    conntrack v1.4.4 (conntrack-tools): 51 flow entries have been shown.</span>
<span class="c">#    udp      17 23 src=192.168.3.235 dst=146.56.40.151 sport=51849 dport=123 src=146.56.40.151 dst=192.168.3.235 sport=123 dport=29777 mark=128 use=1</span>
</code></pre></div></div>

<ul>
  <li>다음 실습을 위해서 파드 삭제</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl delete deploy netshoot-pod
<span class="c"># =&gt; deployment.apps &amp;quot;netshoot-pod&amp;quot; deleted</span>
</code></pre></div></div>

<hr />

<h3 id="노드의-파드-생성-갯수-제한">노드의 파드 생성 갯수 제한</h3>

<h4 id="사전-준비--kube-ops-view-설치">사전 준비 : kube-ops-view 설치</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># kube-ops-view</span>
<span class="nv">$ </span>helm repo add geek-cookbook https://geek-cookbook.github.io/charts/
<span class="c"># =&gt; &amp;quot;geek-cookbook&amp;quot; has been added to your repositories</span>
<span class="nv">$ </span>helm <span class="nb">install </span>kube-ops-view geek-cookbook/kube-ops-view <span class="nt">--version</span> 1.2.2 <span class="nt">--set</span> service.main.type<span class="o">=</span>LoadBalancer <span class="nt">--set</span> env.TZ<span class="o">=</span><span class="s2">"Asia/Seoul"</span> <span class="nt">--namespace</span> kube-system
<span class="c"># =&gt; NAME: kube-ops-view</span>
<span class="c">#    LAST DEPLOYED: Sat Oct  1 17:30:33 2024</span>
<span class="c">#    NAMESPACE: kube-system</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 1</span>
<span class="c">#    TEST SUITE: None</span>
<span class="c">#    NOTES:</span>
<span class="c">#    1. Get the application URL by running these commands:</span>
<span class="c">#         NOTE: It may take a few minutes for the LoadBalancer IP to be available.</span>
<span class="c">#               You can watch the status of by running 'kubectl get svc -w kube-ops-view'</span>
<span class="c">#      export SERVICE_IP=$(kubectl get svc --namespace kube-system kube-ops-view -o jsonpath='{.status.loadBalancer.ingress[0].ip}')</span>
<span class="c">#      echo http://$SERVICE_IP:8080</span>

<span class="c"># kube-ops-view 접속 URL 확인 (1.5 배율)</span>
<span class="nv">$ </span>kubectl get svc <span class="nt">-n</span> kube-system kube-ops-view <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.status.loadBalancer.ingress[0].hostname<span class="o">}</span> | <span class="nb">awk</span> <span class="s1">'{ print "KUBE-OPS-VIEW URL = http://"$1":8080/#scale=1.5"}'</span>
<span class="c"># =&gt; KUBE-OPS-VIEW URL = http://ae19b387d6fee48239f44d3f9f121378-262130081.ap-northeast-2.elb.amazonaws.com:8080/#scale=1.5</span>
</code></pre></div></div>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_29.png" alt="img.png" class="image-center" /></p>

<ul>
  <li><strong>Secondary IPv4 addresses</strong> (기본값) : 인스턴스 유형에 최대 ENI 갯수와 할당 가능 IP 수를 조합하여 선정</li>
</ul>

<h4 id="워커-노드의-인스턴스-타입-별-파드-생성-갯수-제한">워커 노드의 인스턴스 타입 별 파드 생성 갯수 제한</h4>

<ul>
  <li><strong>인스턴스 타입</strong> 별 ENI 최대 갯수와 할당 가능한 최대 IP 갯수에 따라서 파드 배치 갯수가 결정됨</li>
  <li>단, aws-node 와 kube-proxy 파드는 호스트의 IP를 사용함으로 최대 갯수에서 제외함</li>
</ul>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_9.png" alt="img.png" class="image-center w-90" /></p>

<blockquote>
  <p>👉 최대 파드 생성 갯수 : <code class="language-plaintext highlighter-rouge">(Number of network interfaces for the instance type × (the number of IP addressess per network interface - 1)) + 2</code></p>
</blockquote>

<h4 id="워커-노드의-인스턴스-정보-확인--t3medium-사용-시">워커 노드의 인스턴스 정보 확인 : t3.medium 사용 시</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># t3 타입의 정보(필터) 확인</span>
<span class="nv">$ </span>aws ec2 describe-instance-types <span class="nt">--filters</span> <span class="nv">Name</span><span class="o">=</span>instance-type,Values<span class="o">=</span>t3.<span class="k">*</span> <span class="se">\</span>
  <span class="nt">--query</span> <span class="s2">"InstanceTypes[].{Type: InstanceType, MaxENI: NetworkInfo.MaximumNetworkInterfaces, IPv4addr: NetworkInfo.Ipv4AddressesPerInterface}"</span> <span class="se">\</span>
  <span class="nt">--output</span> table
<span class="c"># =&gt; --------------------------------------</span>
<span class="c">#    |        DescribeInstanceTypes       |</span>
<span class="c">#    +----------+----------+--------------+</span>
<span class="c">#    | IPv4addr | MaxENI   |    Type      |</span>
<span class="c">#    +----------+----------+--------------+</span>
<span class="c">#    |  12      |  3       |  t3.large    |</span>
<span class="c">#    |  6       |  3       |  t3.medium   |</span>
<span class="c">#    |  15      |  4       |  t3.2xlarge  |</span>
<span class="c">#    |  15      |  4       |  t3.xlarge   |</span>
<span class="c">#    |  2       |  2       |  t3.micro    |</span>
<span class="c">#    |  2       |  2       |  t3.nano     |</span>
<span class="c">#    |  4       |  3       |  t3.small    |</span>
<span class="c">#    +----------+----------+--------------+</span>

<span class="c"># c5 타입의 정보(필터) 확인</span>
<span class="nv">$ </span>aws ec2 describe-instance-types <span class="nt">--filters</span> <span class="nv">Name</span><span class="o">=</span>instance-type,Values<span class="o">=</span>c5<span class="k">*</span>.<span class="k">*</span> <span class="se">\</span>
  <span class="nt">--query</span> <span class="s2">"InstanceTypes[].{Type: InstanceType, MaxENI: NetworkInfo.MaximumNetworkInterfaces, IPv4addr: NetworkInfo.Ipv4AddressesPerInterface}"</span> <span class="se">\</span>
  <span class="nt">--output</span> table
<span class="c"># =&gt; ----------------------------------------</span>
<span class="c">#    |         DescribeInstanceTypes        |</span>
<span class="c">#    +----------+----------+----------------+</span>
<span class="c">#    | IPv4addr | MaxENI   |     Type       |</span>
<span class="c">#    +----------+----------+----------------+</span>
<span class="c">#    |  30      |  8       |  c5d.12xlarge  |</span>
<span class="c">#    |  10      |  3       |  c5d.large     |</span>
<span class="c">#    |  10      |  3       |  c5n.large     |</span>
<span class="c">#    |  15      |  4       |  c5n.2xlarge   |</span>
<span class="c">#    |  30      |  8       |  c5.4xlarge    |</span>
<span class="c">#    |  15      |  4       |  c5a.xlarge    |</span>
<span class="c">#    |  30      |  8       |  c5a.4xlarge   |</span>
<span class="c">#    |  15      |  4       |  c5d.2xlarge   |</span>
<span class="c">#    |  50      |  15      |  c5d.24xlarge  |</span>
<span class="c">#    |  30      |  8       |  c5.12xlarge   |</span>
<span class="c">#    |  30      |  8       |  c5n.9xlarge   |</span>
<span class="c">#    |  30      |  8       |  c5a.12xlarge  |</span>
<span class="c">#    |  15      |  4       |  c5.xlarge     |</span>
<span class="c">#    |  30      |  8       |  c5n.4xlarge   |</span>
<span class="c">#    |  50      |  15      |  c5n.18xlarge  |</span>
<span class="c">#    |  50      |  15      |  c5.24xlarge   |</span>
<span class="c">#    |  30      |  8       |  c5d.4xlarge   |</span>
<span class="c">#    |  30      |  8       |  c5.9xlarge    |</span>
<span class="c">#    |  15      |  4       |  c5a.2xlarge   |</span>
<span class="c">#    |  50      |  15      |  c5.metal      |</span>
<span class="c">#    |  50      |  15      |  c5a.24xlarge  |</span>
<span class="c">#    |  50      |  15      |  c5d.18xlarge  |</span>
<span class="c">#    |  50      |  15      |  c5a.16xlarge  |</span>
<span class="c">#    |  30      |  8       |  c5a.8xlarge   |</span>
<span class="c">#    |  50      |  15      |  c5n.metal     |</span>
<span class="c">#    |  50      |  15      |  c5d.metal     |</span>
<span class="c">#    |  10      |  3       |  c5.large      |</span>
<span class="c">#    |  15      |  4       |  c5.2xlarge    |</span>
<span class="c">#    |  15      |  4       |  c5d.xlarge    |</span>
<span class="c">#    |  10      |  3       |  c5a.large     |</span>
<span class="c">#    |  50      |  15      |  c5.18xlarge   |</span>
<span class="c">#    |  30      |  8       |  c5d.9xlarge   |</span>
<span class="c">#    |  15      |  4       |  c5n.xlarge    |</span>
<span class="c">#    +----------+----------+----------------+  </span>

<span class="c"># 파드 사용 가능 계산 예시 : aws-node 와 kube-proxy 파드는 host-networking 사용으로 IP 2개 남음</span>
<span class="c"># ((MaxENI * (IPv4addr-1)) + 2)</span>
<span class="c"># t3.medium 경우 : ((3 * (6 - 1) + 2 ) = 17개 &gt;&gt; aws-node 와 kube-proxy 2개 제외하면 15개</span>

<span class="c"># 워커노드 상세 정보 확인 : 노드 상세 정보의 Allocatable 에 pods 에 17개 정보 확인</span>
<span class="nv">$ </span>kubectl describe node | <span class="nb">grep </span>Allocatable: <span class="nt">-A6</span>
<span class="c"># =&gt; Allocatable:</span>
<span class="c">#      cpu:                1930m</span>
<span class="c">#      ephemeral-storage:  27905944324</span>
<span class="c">#      hugepages-1Gi:      0</span>
<span class="c">#      hugepages-2Mi:      0</span>
<span class="c">#      memory:             3388304Ki</span>
<span class="c">#      pods:               17</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<h4 id="최대-파드-생성-및-확인">최대 파드 생성 및 확인</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 워커 노드 EC2 - 모니터링</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>ip <span class="nt">-br</span> <span class="nt">-c</span> addr show <span class="o">&amp;&amp;</span> <span class="nb">echo</span> <span class="s2">"--------------"</span> <span class="p">;</span> <span class="nb">date</span> <span class="s2">"+%Y-%m-%d %H:%M:%S"</span> <span class="p">;</span> <span class="nb">sleep </span>1<span class="p">;</span> <span class="k">done</span>

<span class="c"># 작업용 EC2 - 터미널1</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> <span class="s1">'kubectl get pods -o wide'</span>

<span class="c"># 작업용 EC2 - 터미널2</span>
<span class="c"># 디플로이먼트 생성</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nt">-O</span> https://raw.githubusercontent.com/gasida/PKOS/main/2/nginx-dp.yaml
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> nginx-dp.yaml
<span class="c"># =&gt; deployment.apps/nginx-deployment created</span>

<span class="c"># 파드 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-o</span> wide
<span class="nv">$ </span>kubectl get pod <span class="nt">-o</span><span class="o">=</span>custom-columns<span class="o">=</span>NAME:.metadata.name,IP:.status.podIP
<span class="c"># =&gt; NAME                                IP</span>
<span class="c">#    nginx-deployment-6f999cfffb-44rw7   192.168.1.230</span>
<span class="c">#    nginx-deployment-6f999cfffb-xk4nh   192.168.3.246</span>

<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="nv">$N1</span> <span class="nv">$N2</span> <span class="nv">$N3</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> ssh ec2-user@<span class="nv">$i</span> <span class="nb">sudo </span>ip <span class="nt">-brief</span> addr | <span class="nb">wc</span> <span class="nt">-l</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; node 192.168.1.186 &amp;lt;&amp;lt;</span>
<span class="c">#    5</span>
<span class="c">#    &amp;gt;&amp;gt; node 192.168.2.92 &amp;lt;&amp;lt;</span>
<span class="c">#    4</span>
<span class="c">#    &amp;gt;&amp;gt; node 192.168.3.235 &amp;lt;&amp;lt;</span>
<span class="c">#    5</span>

<span class="c"># 파드 증가 테스트 &gt;&gt; 파드 정상 생성 확인, 워커 노드에서 eth, eni 갯수 확인</span>
<span class="nv">$ </span>kubectl scale deployment nginx-deployment <span class="nt">--replicas</span><span class="o">=</span>8
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="nv">$N1</span> <span class="nv">$N2</span> <span class="nv">$N3</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> ssh ec2-user@<span class="nv">$i</span> <span class="nb">sudo </span>ip <span class="nt">-brief</span> addr | <span class="nb">wc</span> <span class="nt">-l</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; node 192.168.1.186 &amp;lt;&amp;lt;</span>
<span class="c">#    7</span>
<span class="c">#    &amp;gt;&amp;gt; node 192.168.2.92 &amp;lt;&amp;lt;</span>
<span class="c">#    6</span>
<span class="c">#    &amp;gt;&amp;gt; node 192.168.3.235 &amp;lt;&amp;lt;</span>
<span class="c">#    7</span>

<span class="c"># 파드 증가 테스트 &gt;&gt; 파드 정상 생성 확인, 워커 노드에서 eth, eni 갯수 확인 &gt;&gt; 어떤일이 벌어졌는가?</span>
<span class="nv">$ </span>kubectl scale deployment nginx-deployment <span class="nt">--replicas</span><span class="o">=</span>15
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="nv">$N1</span> <span class="nv">$N2</span> <span class="nv">$N3</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> ssh ec2-user@<span class="nv">$i</span> <span class="nb">sudo </span>ip <span class="nt">-brief</span> addr | <span class="nb">wc</span> <span class="nt">-l</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; node 192.168.1.186 &amp;lt;&amp;lt;</span>
<span class="c">#    9</span>
<span class="c">#    &amp;gt;&amp;gt; node 192.168.2.92 &amp;lt;&amp;lt;</span>
<span class="c">#    9</span>
<span class="c">#    &amp;gt;&amp;gt; node 192.168.3.235 &amp;lt;&amp;lt;</span>
<span class="c">#    10</span>

<span class="c"># 파드 증가 테스트 &gt;&gt; 파드 정상 생성 확인, 워커 노드에서 eth, eni 갯수 확인 &gt;&gt; 어떤일이 벌어졌는가?</span>
<span class="nv">$ </span>kubectl scale deployment nginx-deployment <span class="nt">--replicas</span><span class="o">=</span>30
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="nv">$N1</span> <span class="nv">$N2</span> <span class="nv">$N3</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> ssh ec2-user@<span class="nv">$i</span> <span class="nb">sudo </span>ip <span class="nt">-brief</span> addr | <span class="nb">wc</span> <span class="nt">-l</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; node 192.168.1.186 &amp;lt;&amp;lt;</span>
<span class="c">#    15</span>
<span class="c">#    &amp;gt;&amp;gt; node 192.168.2.92 &amp;lt;&amp;lt;</span>
<span class="c">#    15</span>
<span class="c">#    &amp;gt;&amp;gt; node 192.168.3.235 &amp;lt;&amp;lt;</span>
<span class="c">#    15</span>

<span class="c"># 파드 증가 테스트 &gt;&gt; 파드 정상 생성 확인, 워커 노드에서 eth, eni 갯수 확인 &gt;&gt; 어떤일이 벌어졌는가?</span>
<span class="nv">$ </span>kubectl scale deployment nginx-deployment <span class="nt">--replicas</span><span class="o">=</span>50
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="nv">$N1</span> <span class="nv">$N2</span> <span class="nv">$N3</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> ssh ec2-user@<span class="nv">$i</span> <span class="nb">sudo </span>ip <span class="nt">-brief</span> addr | <span class="nb">wc</span> <span class="nt">-l</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; node 192.168.1.186 &amp;lt;&amp;lt;</span>
<span class="c">#    19</span>
<span class="c">#    &amp;gt;&amp;gt; node 192.168.2.92 &amp;lt;&amp;lt;</span>
<span class="c">#    19</span>
<span class="c">#    &amp;gt;&amp;gt; node 192.168.3.235 &amp;lt;&amp;lt;</span>
<span class="c">#    19</span>

<span class="c"># 파드 생성 실패!</span>
<span class="nv">$ </span>kubectl get pods | <span class="nb">grep </span>Pending
<span class="c"># =&gt; nginx-deployment-6f999cfffb-59cj6   0/1     Pending   0          69s</span>
<span class="c">#    nginx-deployment-6f999cfffb-5z5qg   0/1     Pending   0          69s</span>
<span class="c">#    nginx-deployment-6f999cfffb-6gk4m   0/1     Pending   0          69s</span>
<span class="c">#    nginx-deployment-6f999cfffb-bhzc8   0/1     Pending   0          69s</span>
<span class="c">#    nginx-deployment-6f999cfffb-hlns8   0/1     Pending   0          69s</span>
<span class="c">#    nginx-deployment-6f999cfffb-n64nc   0/1     Pending   0          69s</span>
<span class="c">#    nginx-deployment-6f999cfffb-w8x7g   0/1     Pending   0          69s</span>
<span class="c">#    nginx-deployment-6f999cfffb-zb2pk   0/1     Pending   0          69s</span>

<span class="c">#$ kubectl describe pod &lt;Pending 파드&gt; | grep Events: -A5</span>
<span class="nv">$ </span>kubectl describe pod nginx-deployment-6f999cfffb-59cj6 | <span class="nb">grep </span>Events: <span class="nt">-A5</span>
<span class="c"># =&gt; Events:</span>
<span class="c">#      Type     Reason            Age   From               Message</span>
<span class="c">#      ----     ------            ----  ----               -------</span>
<span class="c">#      Warning  FailedScheduling  101s  default-scheduler  0/3 nodes are available: 3 Too many pods. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.</span>
</code></pre></div></div>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_30.png" alt="img.png" class="image-center" /></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 디플로이먼트 삭제</span>
<span class="nv">$ </span>kubectl delete deploy nginx-deployment
<span class="c"># =&gt; deployment.apps &amp;quot;nginx-deployment&amp;quot; deleted</span>
</code></pre></div></div>

<ul>
  <li>👉 해결 방안 : IPv4 Prefix Delegation, WARM &amp; MIN IP/Prefix Targets, Custom Network</li>
</ul>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_10.png" alt="img.png" class="image-center w-80" />
<em class="image-caption">IPv4 Prefix Delegation을 통한 IP 갯수 제한 해소</em></p>

<hr />

<h3 id="service--aws-loadbalancer-controller">Service &amp; AWS LoadBalancer Controller</h3>

<h4 id="서비스-종류">서비스 종류</h4>

<ul>
  <li>ClusterIP 타입</li>
</ul>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_16.png" alt="img.png" class="image-center w-90" /></p>

<ul>
  <li>NodePort 타입</li>
</ul>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_17.png" alt="img_1.png" class="image-center w-90" /></p>

<ul>
  <li>LoadBalancer 타입 (기본 모드) : NLB 인스턴스 유형</li>
</ul>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_18.png" alt="img_2.png" class="image-center w-90" /></p>

<ul>
  <li>Service (LoadBalancer Controller) : AWS Load Balancer Controller + NLB IP 모드 동작 with AWS VPC CNI</li>
</ul>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_19.png" alt="img_3.png" class="image-center w-90" /></p>

<h4 id="nlb-모드-전체-정리">NLB 모드 전체 정리</h4>

<h5 id="instance-mode">Instance mode</h5>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_20.png" alt="img_4.png" class="image-center w-90" />
<em class="image-caption"><a href="https://aws.amazon.com/blogs/networking-and-content-delivery/deploying-aws-load-balancer-controller-on-amazon-eks/">https://aws.amazon.com/blogs/networking-and-content-delivery/deploying-aws-load-balancer-controller-on-amazon-eks/</a></em></p>

<ul>
  <li><strong>externalTrafficPolicy</strong>에 따른 동작은 다음과 같습니다.
    <ul>
      <li><code class="language-plaintext highlighter-rouge">externalTrafficPolicy: ClusterIP</code> : 2번 분산 및 SNAT으로 Client IP 확인 불가능합니다. &lt;- LoadBalancer 타입 (기본 모드) 동작</li>
      <li><code class="language-plaintext highlighter-rouge">externalTrafficPolicy: Local</code> : 1번 분산 및 ClientIP가 유지되고, 워커 노드의 iptables을 사용합니다.
        <ul>
          <li>
            <p><strong>통신 흐름</strong> : 외부 클라이언트가 ‘로드밸런서’ 접속 시 부하분산 되어 노드 도달 후 iptables 룰로 목적지 파드와 통신됩니다.</p>

            <p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_21.png" alt="img_5.png" class="image-center w-90" />
<em class="image-caption"><code class="language-plaintext highlighter-rouge">externalTrafficPolicy: Local</code>일때의 통신흐름의 예</em></p>

            <p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_22.png" alt="img_6.png" class="image-center w-90" /></p>

            <ul>
              <li>노드는 외부에 공개되지 않고 로드밸런서만 외부에 공개되며, 외부 클라이언트는 로드밸랜서에 접속을 할 뿐 내부 노드의 정보를 알 수 없습니다.</li>
              <li>로드밸런서가 부하분산하여 파드가 존재하는 노드들에게 전달합니다. iptables 룰에서는 자신의 노드에 있는 파드만 연결합니다. (<code class="language-plaintext highlighter-rouge">externalTrafficPolicy: local</code>)</li>
              <li>DNAT가 2번 동작합니다. (1) 로드밸런서 접속 후 빠져 나갈때, (2) 노드의 iptables 룰에서 파드IP 전달 시</li>
              <li>외부 클라이언트의 IP가 보존됩니다. AWS NLB 는 <strong>타켓</strong>이 <strong>인스턴스</strong>일 경우 클라이언트 IP를 유지, iptables 룰 경우도 <code class="language-plaintext highlighter-rouge">externalTrafficPolicy: local</code> 로 클라이언트 IP를 보존합니다.</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>부하분산 최적화</strong> : 노드에 파드가 없을 경우 ‘로드밸런서’에서 노드에 헬스 체크(상태 검사)가 실패하여 해당 노드로는 외부 요청 트래픽을 전달하지 않습니다.</p>

    <p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_23.png" alt="img_7.png" class="image-center w-90" />
<img src="/assets/2024/kans-3th/w9/20241102_kans_w9_26.png" alt="img.png" /></p>

    <p>위의 이미지 처럼 3번째 인스턴스(Node3)은 상태 확인이 실패한 경우, 해당 노드로는 외부 요청 트래픽 전달하지 않습니다.</p>
  </li>
</ul>

<h5 id="ip-mode">IP mode</h5>

<ul>
  <li>
    <p>IP 모드는 반드시 AWS LoadBalancer 컨트롤러 파드 및 정책 설정이 필요합니다.</p>

    <p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_24.png" alt="img_8.png" class="image-center w-90" />
<em class="image-caption"><a href="https://aws.amazon.com/blogs/networking-and-content-delivery/deploying-aws-load-balancer-controller-on-amazon-eks/">https://aws.amazon.com/blogs/networking-and-content-delivery/deploying-aws-load-balancer-controller-on-amazon-eks/</a></em></p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">Proxy Protocol v2 비활성화</code> ⇒ NLB에서 바로 파드로 인입되며, 단 ClientIP가 NLB로 SNAT 되어 Client IP 확인 불가능합니다.</li>
      <li><code class="language-plaintext highlighter-rouge">Proxy Protocol v2 활성화</code> ⇒ NLB에서 바로 파드로 인입 및 ClientIP 확인 가능합니다. 단, PPv2를 애플리케이션이 인지할 수 있게 설정이 필요합니다.</li>
    </ul>
  </li>
  <li>
    <p><strong>AWS LoadBalancer Controller 배포</strong> - <a href="https://kubernetes-sigs.github.io/aws-load-balancer-controller/latest/deploy/installation/"><strong>Link</strong></a></p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Helm Chart 설치</span>
<span class="nv">$ </span>helm repo add eks https://aws.github.io/eks-charts
<span class="c"># =&gt; &amp;quot;eks&amp;quot; has been added to your repositories</span>
<span class="nv">$ </span>helm repo update
<span class="c"># =&gt; Hang tight while we grab the latest from your chart repositories...</span>
<span class="c">#    ...Successfully got an update from the &amp;quot;eks&amp;quot; chart repository</span>
<span class="c">#    ...Successfully got an update from the &amp;quot;geek-cookbook&amp;quot; chart repository</span>
<span class="c">#    Update Complete. ⎈Happy Helming!⎈</span>
<span class="nv">$ </span>helm <span class="nb">install </span>aws-load-balancer-controller eks/aws-load-balancer-controller <span class="nt">-n</span> kube-system <span class="nt">--set</span> <span class="nv">clusterName</span><span class="o">=</span><span class="nv">$CLUSTER_NAME</span>
<span class="c"># =&gt; NAME: aws-load-balancer-controller</span>
<span class="c">#    LAST DEPLOYED: Sat Oct  1 17:45:09 2024</span>
<span class="c">#    NAMESPACE: kube-system</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 1</span>
<span class="c">#    TEST SUITE: None</span>
<span class="c">#    NOTES:</span>
<span class="c">#    AWS Load Balancer controller installed!</span>
  
<span class="c">## 설치 확인</span>
<span class="nv">$ </span>kubectl get crd
<span class="c"># =&gt; NAME                                         CREATED AT</span>
<span class="c">#    ...</span>
<span class="c">#    ingressclassparams.elbv2.k8s.aws             2024-10-01T08:45:08Z</span>
<span class="c">#    ...</span>
<span class="c">#    targetgroupbindings.elbv2.k8s.aws            2024-10-01T08:45:08Z</span>
<span class="nv">$ </span>kubectl get deployment <span class="nt">-n</span> kube-system aws-load-balancer-controller
<span class="c"># =&gt; NAME                           READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    aws-load-balancer-controller   2/2     2            2           58s</span>
<span class="nv">$ </span>kubectl describe deploy <span class="nt">-n</span> kube-system aws-load-balancer-controller
<span class="nv">$ </span>kubectl describe deploy <span class="nt">-n</span> kube-system aws-load-balancer-controller | <span class="nb">grep</span> <span class="s1">'Service Account'</span>
<span class="c"># =&gt;   Service Account:  aws-load-balancer-controller</span>
  
<span class="c"># 클러스터롤, 롤 확인</span>
<span class="nv">$ </span>kubectl describe clusterrolebindings.rbac.authorization.k8s.io aws-load-balancer-controller-rolebinding
<span class="nv">$ </span>kubectl describe clusterroles.rbac.authorization.k8s.io aws-load-balancer-controller-role
<span class="c"># =&gt; ...</span>
<span class="c">#    PolicyRule:</span>
<span class="c">#      Resources                                     Non-Resource URLs  Resource Names  Verbs</span>
<span class="c">#      ---------                                     -----------------  --------------  -----</span>
<span class="c">#      targetgroupbindings.elbv2.k8s.aws             []                 []              [create delete get list patch update watch]</span>
<span class="c">#      events                                        []                 []              [create patch]</span>
<span class="c">#      configmaps                                    []                 []              [get delete create update]</span>
<span class="c">#      ingresses                                     []                 []              [get list patch update watch]</span>
<span class="c">#      services                                      []                 []              [get list patch update watch]</span>
<span class="c">#      ingresses.extensions                          []                 []              [get list patch update watch]</span>
<span class="c">#      services.extensions                           []                 []              [get list patch update watch]</span>
<span class="c">#      ingresses.networking.k8s.io                   []                 []              [get list patch update watch]</span>
<span class="c">#      services.networking.k8s.io                    []                 []              [get list patch update watch]</span>
<span class="c">#      endpoints                                     []                 []              [get list watch]</span>
<span class="c">#      namespaces                                    []                 []              [get list watch]</span>
<span class="c">#      nodes                                         []                 []              [get list watch]</span>
<span class="c">#      pods                                          []                 []              [get list watch]</span>
<span class="c">#      endpointslices.discovery.k8s.io               []                 []              [get list watch]</span>
<span class="c">#      ingressclassparams.elbv2.k8s.aws              []                 []              [get list watch]</span>
<span class="c">#      ingressclasses.networking.k8s.io              []                 []              [get list watch]</span>
<span class="c">#      ingresses/status                              []                 []              [update patch]</span>
<span class="c">#      pods/status                                   []                 []              [update patch]</span>
<span class="c">#      services/status                               []                 []              [update patch]</span>
<span class="c">#      targetgroupbindings/status                    []                 []              [update patch]</span>
<span class="c">#      ingresses.elbv2.k8s.aws/status                []                 []              [update patch]</span>
<span class="c">#      pods.elbv2.k8s.aws/status                     []                 []              [update patch]</span>
<span class="c">#      services.elbv2.k8s.aws/status                 []                 []              [update patch]</span>
<span class="c">#      targetgroupbindings.elbv2.k8s.aws/status      []                 []              [update patch]</span>
<span class="c">#      ingresses.extensions/status                   []                 []              [update patch]</span>
<span class="c">#      pods.extensions/status                        []                 []              [update patch]</span>
<span class="c">#      services.extensions/status                    []                 []              [update patch]</span>
<span class="c">#      targetgroupbindings.extensions/status         []                 []              [update patch]</span>
<span class="c">#      ingresses.networking.k8s.io/status            []                 []              [update patch]</span>
<span class="c">#      pods.networking.k8s.io/status                 []                 []              [update patch]</span>
<span class="c">#      services.networking.k8s.io/status             []                 []              [update patch]</span>
<span class="c">#      targetgroupbindings.networking.k8s.io/status  []                 []              [update patch]</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>서비스/파드 배포 테스트 with NLB - <a href="https://kubernetes-sigs.github.io/aws-load-balancer-controller/v2.4/guide/service/nlb/">링크</a> <a href="https://docs.aws.amazon.com/eks/latest/userguide/network-load-balancing.html">NLB</a></p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 모니터링</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> kubectl get pod,svc,ep
  
<span class="c"># 작업용 EC2 - 디플로이먼트 &amp; 서비스 생성</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nt">-O</span> https://raw.githubusercontent.com/gasida/PKOS/main/2/echo-service-nlb.yaml
<span class="nv">$ </span><span class="nb">cat </span>echo-service-nlb.yaml
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> echo-service-nlb.yaml
<span class="c"># =&gt; deployment.apps/deploy-echo created</span>
<span class="c">#    service/svc-nlb-ip-type created</span>
  
<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get deploy,pod
<span class="c"># =&gt; NAME                          READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/deploy-echo   2/2     2            2           10s</span>
<span class="c">#    </span>
<span class="c">#    NAME                               READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/deploy-echo-857b6cfb88-452cd   1/1     Running   0          10s</span>
<span class="c">#    pod/deploy-echo-857b6cfb88-5xz5j   1/1     Running   0          10s</span>
<span class="nv">$ </span>kubectl get svc,ep,ingressclassparams,targetgroupbindings
<span class="c"># =&gt; NAME                      TYPE           CLUSTER-IP      EXTERNAL-IP                                                                         PORT(S)        AGE</span>
<span class="c">#    service/kubernetes        ClusterIP      10.100.0.1      &amp;lt;none&amp;gt;                                                                              443/TCP        76m</span>
<span class="c">#    service/svc-nlb-ip-type   LoadBalancer   10.100.83.184   k8s-default-svcnlbip-50f5d03f41-f28c6aa861a2e815.elb.ap-northeast-2.amazonaws.com   80:30771/TCP   21s</span>
<span class="c">#    </span>
<span class="c">#    NAME                        ENDPOINTS                              AGE</span>
<span class="c">#    endpoints/kubernetes        192.168.1.65:443,192.168.3.189:443     76m</span>
<span class="c">#    endpoints/svc-nlb-ip-type   192.168.1.112:8080,192.168.2.24:8080   21s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                   GROUP-NAME   SCHEME   IP-ADDRESS-TYPE   AGE</span>
<span class="c">#    ingressclassparams.elbv2.k8s.aws/alb                                           3m9s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                                               SERVICE-NAME      SERVICE-PORT   TARGET-TYPE   AGE</span>
<span class="c">#    targetgroupbinding.elbv2.k8s.aws/k8s-default-svcnlbip-f58255c318   svc-nlb-ip-type   80             ip            16s</span>
<span class="nv">$ </span>kubectl get targetgroupbindings <span class="nt">-o</span> json | jq
<span class="c"># =&gt; {</span>
<span class="c">#      &amp;quot;apiVersion&amp;quot;: &amp;quot;v1&amp;quot;,</span>
<span class="c">#      &amp;quot;items&amp;quot;: [</span>
<span class="c">#        {</span>
<span class="c">#          &amp;quot;apiVersion&amp;quot;: &amp;quot;elbv2.k8s.aws/v1beta1&amp;quot;,</span>
<span class="c">#          &amp;quot;kind&amp;quot;: &amp;quot;TargetGroupBinding&amp;quot;,</span>
<span class="c">#          &amp;quot;metadata&amp;quot;: {</span>
<span class="c">#            &amp;quot;annotations&amp;quot;: {</span>
<span class="c">#              &amp;quot;elbv2.k8s.aws/checkpoint&amp;quot;: &amp;quot;gs98wrXMlQMdFGryEbrFbVngcODAXK0Yk4czpOdn9bg/biShKK1OQPD05qA040YQHH29qU6aPNq6J-fRu4M-dKY&amp;quot;,</span>
<span class="c">#              &amp;quot;elbv2.k8s.aws/checkpoint-timestamp&amp;quot;: &amp;quot;1730537287&amp;quot;</span>
<span class="c">#            },</span>
<span class="c">#            &amp;quot;creationTimestamp&amp;quot;: &amp;quot;2024-10-01T08:48:04Z&amp;quot;,</span>
<span class="c">#            &amp;quot;finalizers&amp;quot;: [</span>
<span class="c">#              &amp;quot;elbv2.k8s.aws/resources&amp;quot;</span>
<span class="c">#            ],</span>
<span class="c">#            &amp;quot;generation&amp;quot;: 1,</span>
<span class="c">#            &amp;quot;labels&amp;quot;: {</span>
<span class="c">#              &amp;quot;service.k8s.aws/stack-name&amp;quot;: &amp;quot;svc-nlb-ip-type&amp;quot;,</span>
<span class="c">#              &amp;quot;service.k8s.aws/stack-namespace&amp;quot;: &amp;quot;default&amp;quot;</span>
<span class="c">#            },</span>
<span class="c">#            &amp;quot;name&amp;quot;: &amp;quot;k8s-default-svcnlbip-f58255c318&amp;quot;,</span>
<span class="c">#            &amp;quot;namespace&amp;quot;: &amp;quot;default&amp;quot;,</span>
<span class="c">#            &amp;quot;resourceVersion&amp;quot;: &amp;quot;17369&amp;quot;,</span>
<span class="c">#            &amp;quot;uid&amp;quot;: &amp;quot;bdf37bcf-7fab-47ad-8b73-fb97c0239c9a&amp;quot;</span>
<span class="c">#          },</span>
<span class="c">#          &amp;quot;spec&amp;quot;: {</span>
<span class="c">#            &amp;quot;ipAddressType&amp;quot;: &amp;quot;ipv4&amp;quot;,</span>
<span class="c">#            &amp;quot;networking&amp;quot;: {</span>
<span class="c">#              &amp;quot;ingress&amp;quot;: [</span>
<span class="c">#                {</span>
<span class="c">#                  &amp;quot;from&amp;quot;: [</span>
<span class="c">#                    {</span>
<span class="c">#                      &amp;quot;securityGroup&amp;quot;: {</span>
<span class="c">#                        &amp;quot;groupID&amp;quot;: &amp;quot;sg-0a7a0dcdcda95c9fc&amp;quot;</span>
<span class="c">#                      }</span>
<span class="c">#                    }</span>
<span class="c">#                  ],</span>
<span class="c">#                  &amp;quot;ports&amp;quot;: [</span>
<span class="c">#                    {</span>
<span class="c">#                      &amp;quot;port&amp;quot;: 8080,</span>
<span class="c">#                      &amp;quot;protocol&amp;quot;: &amp;quot;TCP&amp;quot;</span>
<span class="c">#                    }</span>
<span class="c">#                  ]</span>
<span class="c">#                }</span>
<span class="c">#              ]</span>
<span class="c">#            },</span>
<span class="c">#            &amp;quot;serviceRef&amp;quot;: {</span>
<span class="c">#              &amp;quot;name&amp;quot;: &amp;quot;svc-nlb-ip-type&amp;quot;,</span>
<span class="c">#              &amp;quot;port&amp;quot;: 80</span>
<span class="c">#            },</span>
<span class="c">#            &amp;quot;targetGroupARN&amp;quot;: &amp;quot;arn:aws:elasticloadbalancing:ap-northeast-2:123456789012:targetgroup/k8s-default-svcnlbip-f58255c318/0cfa12d6c579f11b&amp;quot;,</span>
<span class="c">#            &amp;quot;targetType&amp;quot;: &amp;quot;ip&amp;quot;,</span>
<span class="c">#            &amp;quot;vpcID&amp;quot;: &amp;quot;vpc-0837921f515624150&amp;quot;</span>
<span class="c">#          },</span>
<span class="c">#          &amp;quot;status&amp;quot;: {</span>
<span class="c">#            &amp;quot;observedGeneration&amp;quot;: 1</span>
<span class="c">#          }</span>
<span class="c">#        }</span>
<span class="c">#      ],</span>
<span class="c">#      &amp;quot;kind&amp;quot;: &amp;quot;List&amp;quot;,</span>
<span class="c">#      &amp;quot;metadata&amp;quot;: {</span>
<span class="c">#        &amp;quot;resourceVersion&amp;quot;: &amp;quot;&amp;quot;</span>
<span class="c">#      }</span>
<span class="c">#    }</span>
  
<span class="c"># (옵션) 빠른 실습을 위해서 등록 취소 지연(드레이닝 간격) 수정 : 기본값 300초</span>
<span class="nv">$ </span>vi echo-service-nlb.yaml
<span class="nt">---</span>
..
apiVersion: v1
kind: Service
metadata:
  name: svc-nlb-ip-type
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: ip
    service.beta.kubernetes.io/aws-load-balancer-scheme: internet-facing
    service.beta.kubernetes.io/aws-load-balancer-healthcheck-port: <span class="s2">"8080"</span>
    service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: <span class="s2">"true"</span>
    service.beta.kubernetes.io/aws-load-balancer-target-group-attributes: deregistration_delay.timeout_seconds<span class="o">=</span>60
...
:wq!
<span class="nt">---</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> echo-service-nlb.yaml
<span class="c"># =&gt; deployment.apps/deploy-echo unchanged</span>
<span class="c">#    service/svc-nlb-ip-type configured</span>
  
<span class="c"># AWS ELB(NLB) 정보 확인</span>
<span class="nv">$ </span>aws elbv2 describe-load-balancers | jq
<span class="c"># =&gt; {</span>
<span class="c">#      &amp;quot;LoadBalancers&amp;quot;: [</span>
<span class="c">#        {</span>
<span class="c">#          &amp;quot;LoadBalancerArn&amp;quot;: &amp;quot;arn:aws:elasticloadbalancing:ap-northeast-2:123456789012:loadbalancer/net/k8s-default-svcnlbip-50f5d03f41/f28c6aa861a2e815&amp;quot;,</span>
<span class="c">#          &amp;quot;DNSName&amp;quot;: &amp;quot;k8s-default-svcnlbip-50f5d03f41-f28c6aa861a2e815.elb.ap-northeast-2.amazonaws.com&amp;quot;,</span>
<span class="c">#          &amp;quot;CanonicalHostedZoneId&amp;quot;: &amp;quot;ZIBE1TIR4HY56&amp;quot;,</span>
<span class="c">#          &amp;quot;CreatedTime&amp;quot;: &amp;quot;2024-10-01T08:48:03.532000+00:00&amp;quot;,</span>
<span class="c">#          &amp;quot;LoadBalancerName&amp;quot;: &amp;quot;k8s-default-svcnlbip-50f5d03f41&amp;quot;,</span>
<span class="c">#          &amp;quot;Scheme&amp;quot;: &amp;quot;internet-facing&amp;quot;,</span>
<span class="c">#          &amp;quot;VpcId&amp;quot;: &amp;quot;vpc-0837921f515624150&amp;quot;,</span>
<span class="c">#          &amp;quot;State&amp;quot;: {</span>
<span class="c">#            &amp;quot;Code&amp;quot;: &amp;quot;provisioning&amp;quot;</span>
<span class="c">#          },</span>
<span class="c">#          &amp;quot;Type&amp;quot;: &amp;quot;network&amp;quot;,</span>
<span class="c">#          &amp;quot;AvailabilityZones&amp;quot;: [</span>
<span class="c">#            {</span>
<span class="c">#              &amp;quot;ZoneName&amp;quot;: &amp;quot;ap-northeast-2a&amp;quot;,</span>
<span class="c">#              &amp;quot;SubnetId&amp;quot;: &amp;quot;subnet-0a06ed52d587bd707&amp;quot;,</span>
<span class="c">#              &amp;quot;LoadBalancerAddresses&amp;quot;: []</span>
<span class="c">#            },</span>
<span class="c">#            {</span>
<span class="c">#              &amp;quot;ZoneName&amp;quot;: &amp;quot;ap-northeast-2c&amp;quot;,</span>
<span class="c">#              &amp;quot;SubnetId&amp;quot;: &amp;quot;subnet-03c911c48452b41b2&amp;quot;,</span>
<span class="c">#              &amp;quot;LoadBalancerAddresses&amp;quot;: []</span>
<span class="c">#            },</span>
<span class="c">#            {</span>
<span class="c">#              &amp;quot;ZoneName&amp;quot;: &amp;quot;ap-northeast-2b&amp;quot;,</span>
<span class="c">#              &amp;quot;SubnetId&amp;quot;: &amp;quot;subnet-00b4dacf7eef35d33&amp;quot;,</span>
<span class="c">#              &amp;quot;LoadBalancerAddresses&amp;quot;: []</span>
<span class="c">#            }</span>
<span class="c">#          ],</span>
<span class="c">#          &amp;quot;SecurityGroups&amp;quot;: [</span>
<span class="c">#            &amp;quot;sg-0a7a0dcdcda95c9fc&amp;quot;,</span>
<span class="c">#            &amp;quot;sg-0e325a379a10ced56&amp;quot;</span>
<span class="c">#          ],</span>
<span class="c">#          &amp;quot;IpAddressType&amp;quot;: &amp;quot;ipv4&amp;quot;,</span>
<span class="c">#          &amp;quot;EnablePrefixForIpv6SourceNat&amp;quot;: &amp;quot;off&amp;quot;</span>
<span class="c">#        }</span>
<span class="c">#      ]</span>
<span class="c">#    }</span>
<span class="nv">$ </span>aws elbv2 describe-load-balancers <span class="nt">--query</span> <span class="s1">'LoadBalancers[*].State.Code'</span> <span class="nt">--output</span> text
<span class="c"># =&gt; provisioning</span>
<span class="nv">$ ALB_ARN</span><span class="o">=</span><span class="si">$(</span>aws elbv2 describe-load-balancers <span class="nt">--query</span> <span class="s1">'LoadBalancers[?contains(LoadBalancerName, `k8s-default-svcnlbip`) == `true`].LoadBalancerArn'</span> | jq <span class="nt">-r</span> <span class="s1">'.[0]'</span><span class="si">)</span>
<span class="nv">$ </span>aws elbv2 describe-target-groups <span class="nt">--load-balancer-arn</span> <span class="nv">$ALB_ARN</span> | jq
<span class="c"># =&gt; {</span>
<span class="c">#      &amp;quot;TargetGroups&amp;quot;: [</span>
<span class="c">#        {</span>
<span class="c">#          &amp;quot;TargetGroupArn&amp;quot;: &amp;quot;arn:aws:elasticloadbalancing:ap-northeast-2:123456789012:targetgroup/k8s-default-svcnlbip-f58255c318/0cfa12d6c579f11b&amp;quot;,</span>
<span class="c">#          &amp;quot;TargetGroupName&amp;quot;: &amp;quot;k8s-default-svcnlbip-f58255c318&amp;quot;,</span>
<span class="c">#          &amp;quot;Protocol&amp;quot;: &amp;quot;TCP&amp;quot;,</span>
<span class="c">#          &amp;quot;Port&amp;quot;: 8080,</span>
<span class="c">#          &amp;quot;VpcId&amp;quot;: &amp;quot;vpc-0837921f515624150&amp;quot;,</span>
<span class="c">#          &amp;quot;HealthCheckProtocol&amp;quot;: &amp;quot;TCP&amp;quot;,</span>
<span class="c">#          &amp;quot;HealthCheckPort&amp;quot;: &amp;quot;8080&amp;quot;,</span>
<span class="c">#          &amp;quot;HealthCheckEnabled&amp;quot;: true,</span>
<span class="c">#          &amp;quot;HealthCheckIntervalSeconds&amp;quot;: 10,</span>
<span class="c">#          &amp;quot;HealthCheckTimeoutSeconds&amp;quot;: 10,</span>
<span class="c">#          &amp;quot;HealthyThresholdCount&amp;quot;: 3,</span>
<span class="c">#          &amp;quot;UnhealthyThresholdCount&amp;quot;: 3,</span>
<span class="c">#          &amp;quot;LoadBalancerArns&amp;quot;: [</span>
<span class="c">#            &amp;quot;arn:aws:elasticloadbalancing:ap-northeast-2:123456789012:loadbalancer/net/k8s-default-svcnlbip-50f5d03f41/f28c6aa861a2e815&amp;quot;</span>
<span class="c">#          ],</span>
<span class="c">#          &amp;quot;TargetType&amp;quot;: &amp;quot;ip&amp;quot;,</span>
<span class="c">#          &amp;quot;IpAddressType&amp;quot;: &amp;quot;ipv4&amp;quot;</span>
<span class="c">#        }</span>
<span class="c">#      ]</span>
<span class="c">#    }</span>
<span class="nv">$ TARGET_GROUP_ARN</span><span class="o">=</span><span class="si">$(</span>aws elbv2 describe-target-groups <span class="nt">--load-balancer-arn</span> <span class="nv">$ALB_ARN</span> | jq <span class="nt">-r</span> <span class="s1">'.TargetGroups[0].TargetGroupArn'</span><span class="si">)</span>
<span class="nv">$ </span>aws elbv2 describe-target-health <span class="nt">--target-group-arn</span> <span class="nv">$TARGET_GROUP_ARN</span> | jq
<span class="c"># =&gt; {</span>
<span class="c">#      &amp;quot;TargetHealthDescriptions&amp;quot;: [</span>
<span class="c">#        {</span>
<span class="c">#          &amp;quot;Target&amp;quot;: {</span>
<span class="c">#            &amp;quot;Id&amp;quot;: &amp;quot;192.168.2.24&amp;quot;,</span>
<span class="c">#            &amp;quot;Port&amp;quot;: 8080,</span>
<span class="c">#            &amp;quot;AvailabilityZone&amp;quot;: &amp;quot;ap-northeast-2b&amp;quot;</span>
<span class="c">#          },</span>
<span class="c">#          &amp;quot;HealthCheckPort&amp;quot;: &amp;quot;8080&amp;quot;,</span>
<span class="c">#          &amp;quot;TargetHealth&amp;quot;: {</span>
<span class="c">#            &amp;quot;State&amp;quot;: &amp;quot;healthy&amp;quot;</span>
<span class="c">#          },</span>
<span class="c">#          &amp;quot;AdministrativeOverride&amp;quot;: {</span>
<span class="c">#            &amp;quot;State&amp;quot;: &amp;quot;no_override&amp;quot;,</span>
<span class="c">#            &amp;quot;Reason&amp;quot;: &amp;quot;AdministrativeOverride.NoOverride&amp;quot;,</span>
<span class="c">#            &amp;quot;Description&amp;quot;: &amp;quot;No override is currently active on target&amp;quot;</span>
<span class="c">#          }</span>
<span class="c">#        },</span>
<span class="c">#        {</span>
<span class="c">#          &amp;quot;Target&amp;quot;: {</span>
<span class="c">#            &amp;quot;Id&amp;quot;: &amp;quot;192.168.1.112&amp;quot;,</span>
<span class="c">#            &amp;quot;Port&amp;quot;: 8080,</span>
<span class="c">#            &amp;quot;AvailabilityZone&amp;quot;: &amp;quot;ap-northeast-2a&amp;quot;</span>
<span class="c">#          },</span>
<span class="c">#          &amp;quot;HealthCheckPort&amp;quot;: &amp;quot;8080&amp;quot;,</span>
<span class="c">#          &amp;quot;TargetHealth&amp;quot;: {</span>
<span class="c">#            &amp;quot;State&amp;quot;: &amp;quot;initial&amp;quot;,</span>
<span class="c">#            &amp;quot;Reason&amp;quot;: &amp;quot;Elb.InitialHealthChecking&amp;quot;,</span>
<span class="c">#            &amp;quot;Description&amp;quot;: &amp;quot;Initial health checks in progress&amp;quot;</span>
<span class="c">#          },</span>
<span class="c">#          &amp;quot;AdministrativeOverride&amp;quot;: {</span>
<span class="c">#            &amp;quot;State&amp;quot;: &amp;quot;no_override&amp;quot;,</span>
<span class="c">#            &amp;quot;Reason&amp;quot;: &amp;quot;AdministrativeOverride.NoOverride&amp;quot;,</span>
<span class="c">#            &amp;quot;Description&amp;quot;: &amp;quot;No override is currently active on target&amp;quot;</span>
<span class="c">#          }</span>
<span class="c">#        }</span>
<span class="c">#      ]</span>
<span class="c">#    }</span>
  
<span class="c"># 웹 접속 주소 확인</span>
<span class="nv">$ </span>kubectl get svc svc-nlb-ip-type <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.status.loadBalancer.ingress[0].hostname<span class="o">}</span> | <span class="nb">awk</span> <span class="s1">'{ print "Pod Web URL = http://"$1 }'</span>
<span class="c"># =&gt; Pod Web URL = http://k8s-default-svcnlbip-50f5d03f41-f28c6aa861a2e815.elb.ap-northeast-2.amazonaws.com</span>
  
<span class="c"># 파드 로깅 모니터링</span>
<span class="nv">$ </span>kubectl logs <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>deploy-websrv <span class="nt">-f</span>
  
<span class="c"># 분산 접속 확인</span>
<span class="nv">$ NLB</span><span class="o">=</span><span class="si">$(</span>kubectl get svc svc-nlb-ip-type <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.status.loadBalancer.ingress[0].hostname<span class="o">}</span><span class="si">)</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$NLB</span>
<span class="c"># =&gt; Hostname: deploy-echo-857b6cfb88-5xz5j</span>
<span class="c">#    </span>
<span class="c">#    Pod Information:</span>
<span class="c">#     -no pod information available-</span>
<span class="c">#    </span>
<span class="c">#    Server values:</span>
<span class="c">#     server_version=nginx: 1.13.0 - lua: 10008</span>
<span class="c">#    </span>
<span class="c">#    Request Information:</span>
<span class="c">#     client_address=192.168.3.171</span>
<span class="c">#     method=GET</span>
<span class="c">#     real path=/</span>
<span class="c">#     query=</span>
<span class="c">#     request_version=1.1</span>
<span class="c">#     request_uri=http://k8s-default-svcnlbip-50f5d03f41-f28c6aa861a2e815.elb.ap-northeast-2.amazonaws.com:8080/</span>
<span class="c">#    </span>
<span class="c">#    Request Headers:</span>
<span class="c">#     accept=*/*</span>
<span class="c">#     host=k8s-default-svcnlbip-50f5d03f41-f28c6aa861a2e815.elb.ap-northeast-2.amazonaws.com</span>
<span class="c">#     user-agent=curl/8.3.0</span>
<span class="c">#    </span>
<span class="c">#    Request Body:</span>
<span class="c">#     -no body in request-</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$NLB</span> | <span class="nb">grep </span>Hostname <span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt; 52 Hostname: deploy-echo-857b6cfb88-452cd</span>
<span class="c">#    48 Hostname: deploy-echo-857b6cfb88-5xz5j</span>
  
<span class="c"># 지속적인 접속 시도 : 아래 상세 동작 확인 시 유용(패킷 덤프 등)</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 <span class="nv">$NLB</span> | egrep <span class="s1">'Hostname|client_address'</span><span class="p">;</span> <span class="nb">echo</span> <span class="s2">"----------"</span> <span class="p">;</span> <span class="nb">date</span> <span class="s2">"+%Y-%m-%d %H:%M:%S"</span> <span class="p">;</span> <span class="nb">sleep </span>1<span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; Hostname: deploy-echo-857b6cfb88-5xz5j</span>
<span class="c">#     client_address=192.168.1.39</span>
<span class="c">#    ----------</span>
<span class="c">#    2024-10-01 17:52:08</span>
<span class="c">#    Hostname: deploy-echo-857b6cfb88-452cd</span>
<span class="c">#     client_address=192.168.3.171</span>
<span class="c">#    ----------</span>
<span class="c">#    2024-10-01 17:52:09</span>
<span class="c">#    Hostname: deploy-echo-857b6cfb88-5xz5j</span>
<span class="c">#     client_address=192.168.1.39</span>
<span class="c">#    ----------</span>
<span class="c">#    2024-10-01 17:52:10</span>
<span class="c">#    Hostname: deploy-echo-857b6cfb88-452cd</span>
<span class="c">#     client_address=192.168.3.171</span>
<span class="c">#    ...</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>파드 2개 → 1개 → 3개 설정 시 동작을 확인해보겠습니다. 파드의 IP가 auto discovery되는데 이것은 service에 엔드포인트 정보를 사용한 것입니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># (신규 터미널) 모니터링</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>aws elbv2 describe-target-health <span class="nt">--target-group-arn</span> <span class="nv">$TARGET_GROUP_ARN</span> <span class="nt">--output</span> text<span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; TARGETHEALTHDESCRIPTIONS 8080</span>
<span class="c">#    ADMINISTRATIVEOVERRIDE No override is currently active on target AdministrativeOverride.NoOverride no_override</span>
<span class="c">#    TARGET ap-northeast-2b 192.168.2.24  8080</span>
<span class="c">#    TARGETHEALTH healthy</span>
<span class="c">#    TARGETHEALTHDESCRIPTIONS 8080</span>
<span class="c">#    ADMINISTRATIVEOVERRIDE No override is currently active on target AdministrativeOverride.NoOverride no_override</span>
<span class="c">#    TARGET ap-northeast-2a 192.168.1.112 8080</span>
<span class="c">#    TARGETHEALTH healthy</span>
<span class="c">#    ...</span>
    
<span class="c"># 작업용 EC2 - 파드 1개 설정 </span>
<span class="nv">$ </span>kubectl scale deployment deploy-echo <span class="nt">--replicas</span><span class="o">=</span>1
    
<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get deploy,pod,svc,ep
<span class="c"># =&gt; NAME                          READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/deploy-echo   1/1     1            1           6m34s</span>
<span class="c">#    </span>
<span class="c">#    NAME                               READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/deploy-echo-857b6cfb88-452cd   1/1     Running   0          6m34s</span>
<span class="c">#    </span>
<span class="c">#    NAME                      TYPE           CLUSTER-IP      EXTERNAL-IP                                                                         PORT(S)        AGE</span>
<span class="c">#    service/kubernetes        ClusterIP      10.100.0.1      &amp;lt;none&amp;gt;                                                                              443/TCP        82m</span>
<span class="c">#    service/svc-nlb-ip-type   LoadBalancer   10.100.83.184   k8s-default-svcnlbip-50f5d03f41-f28c6aa861a2e815.elb.ap-northeast-2.amazonaws.com   80:30771/TCP   6m34s</span>
<span class="c">#    </span>
<span class="c">#    NAME                        ENDPOINTS                            AGE</span>
<span class="c">#    endpoints/kubernetes        192.168.1.65:443,192.168.3.189:443   82m</span>
<span class="c">#    endpoints/svc-nlb-ip-type   192.168.2.24:8080                    6m34s</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$NLB</span>
<span class="c"># =&gt; Hostname: deploy-echo-857b6cfb88-452cd</span>
<span class="c">#    </span>
<span class="c">#    Pod Information:</span>
<span class="c">#     -no pod information available-</span>
<span class="c">#    </span>
<span class="c">#    Server values:</span>
<span class="c">#     server_version=nginx: 1.13.0 - lua: 10008</span>
<span class="c">#    </span>
<span class="c">#    Request Information:</span>
<span class="c">#     client_address=192.168.3.171</span>
<span class="c">#     method=GET</span>
<span class="c">#     real path=/</span>
<span class="c">#     query=</span>
<span class="c">#     request_version=1.1</span>
<span class="c">#     request_uri=http://k8s-default-svcnlbip-50f5d03f41-f28c6aa861a2e815.elb.ap-northeast-2.amazonaws.com:8080/</span>
<span class="c">#    </span>
<span class="c">#    Request Headers:</span>
<span class="c">#     accept=*/*</span>
<span class="c">#     host=k8s-default-svcnlbip-50f5d03f41-f28c6aa861a2e815.elb.ap-northeast-2.amazonaws.com</span>
<span class="c">#     user-agent=curl/8.3.0</span>
<span class="c">#    </span>
<span class="c">#    Request Body:</span>
<span class="c">#     -no body in request-</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 <span class="nv">$NLB</span> | <span class="nb">grep </span>Hostname <span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;     100 Hostname: deploy-echo-857b6cfb88-452cd</span>
    
<span class="c"># 작업용 EC2 - 파드 3개 설정 </span>
<span class="nv">$ </span>kubectl scale deployment deploy-echo <span class="nt">--replicas</span><span class="o">=</span>3
<span class="c"># =&gt; deployment.apps/deploy-echo scaled</span>
    
<span class="c"># 확인 : NLB 대상 타켓이 아직 initial 일 때 100번 반복 접속 시 어떻게 되는지 확인해보자!</span>
<span class="nv">$ </span>kubectl get deploy,pod,svc,ep
<span class="c"># =&gt; NAME                          READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/deploy-echo   3/3     3            3           7m41s</span>
<span class="c">#    </span>
<span class="c">#    NAME                               READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    ...</span>
<span class="c">#    pod/deploy-echo-857b6cfb88-8wn7b   1/1     Running   0          10s</span>
<span class="c">#    pod/deploy-echo-857b6cfb88-qhqbt   1/1     Running   0          10s</span>
<span class="c">#    </span>
<span class="c">#    ...</span>
<span class="c">#    </span>
<span class="c">#    NAME                        ENDPOINTS                                                 AGE</span>
<span class="c">#    ...</span>
<span class="c">#    endpoints/svc-nlb-ip-type   192.168.1.161:8080,192.168.2.24:8080,192.168.3.241:8080   7m41s</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$NLB</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 <span class="nv">$NLB</span> | <span class="nb">grep </span>Hostname <span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;      37 Hostname: deploy-echo-857b6cfb88-452cd</span>
<span class="c">#         33 Hostname: deploy-echo-857b6cfb88-8wn7b</span>
<span class="c">#         30 Hostname: deploy-echo-857b6cfb88-qhqbt</span>
    
<span class="c"># </span>
<span class="nv">$ </span>kubectl describe deploy <span class="nt">-n</span> kube-system aws-load-balancer-controller | <span class="nb">grep</span> <span class="nt">-i</span> <span class="s1">'Service Account'</span>
<span class="c"># =&gt;   Service Account:  aws-load-balancer-controller</span>
    
<span class="c"># [AWS LB Ctrl] 클러스터 롤 바인딩 정보 확인</span>
<span class="nv">$ </span>kubectl describe clusterrolebindings.rbac.authorization.k8s.io aws-load-balancer-controller-rolebinding
    
<span class="c"># [AWS LB Ctrl] 클러스터롤 확인 </span>
<span class="nv">$ </span>kubectl describe clusterroles.rbac.authorization.k8s.io aws-load-balancer-controller-role
</code></pre></div>    </div>

    <ul>
      <li>실습 리소스 삭제:  <code class="language-plaintext highlighter-rouge">kubectl delete deploy deploy-echo; kubectl delete svc svc-nlb-ip-type</code></li>
    </ul>
  </li>
  <li><strong>(심화) Pod readiness gate</strong> : ALB/NLB 대상(ip mode)이 ALB/NLB의 헬스체크에 의해 정상일 경우 해당 파드로 전달할 수 있는 기능입니다. - <a href="https://kubernetes-sigs.github.io/aws-load-balancer-controller/v2.7/deploy/pod_readiness_gate/">Link</a> <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#pod-readiness-gate">K8S</a>
    <ul>
      <li>
        <p>사전 준비</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 바로 위에서 실습 리소스 삭제했다면, 다시 생성 : deregistration_delay.timeout_seconds=60 확인</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> echo-service-nlb.yaml
<span class="c"># =&gt; deployment.apps/deploy-echo created</span>
<span class="c">#    service/svc-nlb-ip-type created</span>
<span class="nv">$ </span>kubectl scale deployment deploy-echo <span class="nt">--replicas</span><span class="o">=</span>1
<span class="c"># =&gt; deployment.apps/deploy-echo scaled</span>
    
<span class="c">#</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                           READY   STATUS    RESTARTS   AGE   IP              NODE                                               NOMINATED NODE   READINESS GATES</span>
<span class="c">#    deploy-echo-857b6cfb88-sx8lg   1/1     Running   0          14m   192.168.3.124   ip-192-168-3-235.ap-northeast-2.compute.internal   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
    
<span class="c"># mutatingwebhookconfigurations 확인 : mutating 대상(네임스페이스에 아래 매칭 시)</span>
<span class="nv">$ </span>kubectl get mutatingwebhookconfigurations
<span class="c"># =&gt; NAME                            WEBHOOKS   AGE</span>
<span class="c">#    aws-load-balancer-webhook       3          28m</span>
<span class="c">#    pod-identity-webhook            1          102m</span>
<span class="c">#    vpc-resource-mutating-webhook   1          102m</span>
<span class="nv">$ </span>kubectl get mutatingwebhookconfigurations aws-load-balancer-webhook <span class="nt">-o</span> yaml | kubectl neat
<span class="c"># =&gt; ...</span>
<span class="c">#      name: mpod.elbv2.k8s.aws</span>
<span class="c">#      namespaceSelector:</span>
<span class="c">#        matchExpressions:</span>
<span class="c">#        - key: elbv2.k8s.aws/pod-readiness-gate-inject</span>
<span class="c">#          operator: In</span>
<span class="c">#          values:</span>
<span class="c">#          - enabled</span>
<span class="c">#      objectSelector:</span>
<span class="c">#        matchExpressions:</span>
<span class="c">#        - key: app.kubernetes.io/name</span>
<span class="c">#          operator: NotIn</span>
<span class="c">#          values:</span>
<span class="c">#          - aws-load-balancer-controller</span>
<span class="c">#    ...</span>
    
<span class="c"># 현재 확인</span>
<span class="nv">$ </span>kubectl get ns <span class="nt">--show-labels</span>
<span class="c"># =&gt; NAME              STATUS   AGE    LABELS</span>
<span class="c">#    default           Active   103m   kubernetes.io/metadata.name=default</span>
<span class="c">#    kube-node-lease   Active   103m   kubernetes.io/metadata.name=kube-node-lease</span>
<span class="c">#    kube-public       Active   103m   kubernetes.io/metadata.name=kube-public</span>
<span class="c">#    kube-system       Active   103m   kubernetes.io/metadata.name=kube-system</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p>설정 및 확인</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># (터미널 각각 2개) 모니터링</span>
<span class="nv">$ ALB_ARN</span><span class="o">=</span><span class="si">$(</span>aws elbv2 describe-load-balancers <span class="nt">--query</span> <span class="s1">'LoadBalancers[?contains(LoadBalancerName, `k8s-default-svcnlbip`) == `true`].LoadBalancerArn'</span> | jq <span class="nt">-r</span> <span class="s1">'.[0]'</span><span class="si">)</span>
<span class="nv">$ TARGET_GROUP_ARN</span><span class="o">=</span><span class="si">$(</span>aws elbv2 describe-target-groups <span class="nt">--load-balancer-arn</span> <span class="nv">$ALB_ARN</span> | jq <span class="nt">-r</span> <span class="s1">'.TargetGroups[0].TargetGroupArn'</span><span class="si">)</span>
    
<span class="nv">$ </span>watch <span class="nt">-d</span> kubectl get pod,svc,ep <span class="nt">-owide</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>aws elbv2 describe-target-health <span class="nt">--target-group-arn</span> <span class="nv">$TARGET_GROUP_ARN</span> <span class="nt">--output</span> text<span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
    
<span class="c">#</span>
<span class="nv">$ </span>kubectl label namespace default elbv2.k8s.aws/pod-readiness-gate-inject<span class="o">=</span>enabled
<span class="c"># =&gt; namespace/default labeled</span>
<span class="nv">$ </span>kubectl get ns <span class="nt">--show-labels</span>
<span class="c"># =&gt; NAME              STATUS   AGE    LABELS</span>
<span class="c">#    default           Active   108m   elbv2.k8s.aws/pod-readiness-gate-inject=enabled,kubernetes.io/metadata.name=default</span>
<span class="c">#    kube-node-lease   Active   108m   kubernetes.io/metadata.name=kube-node-lease</span>
<span class="c">#    kube-public       Active   108m   kubernetes.io/metadata.name=kube-public</span>
<span class="c">#    kube-system       Active   108m   kubernetes.io/metadata.name=kube-system</span>
    
<span class="c"># READINESS GATES 항목 추가 확인</span>
<span class="nv">$ </span>kubectl describe pod
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                           READY   STATUS    RESTARTS   AGE   IP              NODE                                               NOMINATED NODE   READINESS GATES</span>
<span class="c">#    deploy-echo-857b6cfb88-sx8lg   1/1     Running   0          20m   192.168.3.124   ip-192-168-3-235.ap-northeast-2.compute.internal   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
    
<span class="c">#</span>
<span class="nv">$ </span>kubectl delete pod <span class="nt">--all</span>
<span class="c"># =&gt; pod &amp;quot;deploy-echo-857b6cfb88-sx8lg&amp;quot; deleted</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                           READY   STATUS    RESTARTS   AGE   IP             NODE                                              NOMINATED NODE   READINESS GATES</span>
<span class="c">#    deploy-echo-857b6cfb88-njwdj   1/1     Running   0          54s   192.168.2.18   ip-192-168-2-92.ap-northeast-2.compute.internal   &amp;lt;none&amp;gt;           1/1</span>
    
<span class="nv">$ </span>kubectl describe pod
<span class="c"># =&gt; ...</span>
<span class="c">#    Readiness Gates:</span>
<span class="c">#      Type                                                          Status</span>
<span class="c">#      target-health.elbv2.k8s.aws/k8s-default-svcnlbip-2e5acb9719   True</span>
<span class="c">#    Conditions:</span>
<span class="c">#      Type                                                          Status</span>
<span class="c">#      target-health.elbv2.k8s.aws/k8s-default-svcnlbip-2e5acb9719   True</span>
<span class="c">#      PodReadyToStartContainers                                     True</span>
<span class="c">#      Initialized                                                   True</span>
<span class="c">#      Ready                                                         True</span>
<span class="c">#      ContainersReady                                               True</span>
<span class="c">#      PodScheduled                                                  True</span>
<span class="c">#      ...</span>
    
<span class="nv">$ </span>kubectl get pod <span class="nt">-o</span> yaml | yh
<span class="c"># =&gt; ...</span>
<span class="c">#        readinessGates:</span>
<span class="c">#        - conditionType: target-health.elbv2.k8s.aws/k8s-default-svcnlbip-2e5acb9719</span>
<span class="c">#    ...</span>
<span class="c">#      status:</span>
<span class="c">#        conditions:</span>
<span class="c">#        - lastProbeTime: null</span>
<span class="c">#          lastTransitionTime: &amp;quot;2024-10-01T09:21:28Z&amp;quot;</span>
<span class="c">#          status: &amp;quot;True&amp;quot;</span>
<span class="c">#          type: target-health.elbv2.k8s.aws/k8s-default-svcnlbip-2e5acb9719</span>
<span class="c">#    ...</span>
    
<span class="c"># 분산 접속 확인</span>
<span class="nv">$ NLB</span><span class="o">=</span><span class="si">$(</span>kubectl get svc svc-nlb-ip-type <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.status.loadBalancer.ingress[0].hostname<span class="o">}</span><span class="si">)</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$NLB</span>
<span class="c"># =&gt; Hostname: deploy-echo-857b6cfb88-njwdj</span>
<span class="c">#    </span>
<span class="c">#    Pod Information:</span>
<span class="c">#     -no pod information available-</span>
<span class="c">#    </span>
<span class="c">#    Server values:</span>
<span class="c">#     server_version=nginx: 1.13.0 - lua: 10008</span>
<span class="c">#    </span>
<span class="c">#    Request Information:</span>
<span class="c">#     client_address=192.168.3.71</span>
<span class="c">#     method=GET</span>
<span class="c">#     real path=/</span>
<span class="c">#     query=</span>
<span class="c">#     request_version=1.1</span>
<span class="c">#     request_uri=http://k8s-default-svcnlbip-f4c21d9697-0d3512de2bf74357.elb.ap-northeast-2.amazonaws.com:8080/</span>
<span class="c">#    </span>
<span class="c">#    Request Headers:</span>
<span class="c">#     accept=*/*</span>
<span class="c">#     host=k8s-default-svcnlbip-f4c21d9697-0d3512de2bf74357.elb.ap-northeast-2.amazonaws.com</span>
<span class="c">#     user-agent=curl/8.3.0</span>
<span class="c">#    </span>
<span class="c">#    Request Body:</span>
<span class="c">#     -no body in request-</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$NLB</span> | <span class="nb">grep </span>Hostname <span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;     100 Hostname: deploy-echo-857b6cfb88-njwdj</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p>실습 리소스 삭제:  <code class="language-plaintext highlighter-rouge">kubectl delete deploy deploy-echo; kubectl delete svc svc-nlb-ip-type</code></p>
      </li>
    </ul>
  </li>
  <li>NLB 대상 타켓을 <strong>Instance mode</strong> 로 설정해보기
    <ul>
      <li>다음 링크에서 확인해볼 수 있습니다.
<a href="https://www.notion.so/AWS-NLB-Client-IP-Proxy-protocol-57827e2c83fc474992b37e65db81f669?pvs=21">AWS NLB - Client IP 확인 &amp; Proxy protocol</a></li>
    </ul>
  </li>
  <li>
    <p>NLB IP Target &amp; <strong>Proxy Protocol v2</strong> 활성화 : NLB에서 바로 파드로 인입 및 ClientIP 확인 설정 - <a href="https://www.notion.so/AWS-NLB-Client-IP-Proxy-protocol-57827e2c83fc474992b37e65db81f669?pvs=21">링크</a> <a href="https://hub.docker.com/r/gasida/httpd/tags">image</a> <a href="https://canaryrelease.tistory.com/42">참고</a></p>

    <p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_25.png" alt="img_9.png" class="image-center w-90" /></p>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 생성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: gasida-web
spec:
  replicas: 1
  selector:
    matchLabels:
      app: gasida-web
  template:
    metadata:
      labels:
        app: gasida-web
    spec:
      terminationGracePeriodSeconds: 0
      containers:
      - name: gasida-web
        image: sweetlittlebird/httpd:pp
        ports:
        - containerPort: 8080
---
apiVersion: v1
kind: Service
metadata:
  name: svc-nlb-ip-type-pp
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: ip
    service.beta.kubernetes.io/aws-load-balancer-scheme: internet-facing
    service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: "true"
    service.beta.kubernetes.io/aws-load-balancer-proxy-protocol: "*"
spec:
  ports:
    - port: 80
      targetPort: 80
      protocol: TCP
  type: LoadBalancer
  loadBalancerClass: service.k8s.aws/nlb
  selector:
    app: gasida-web
</span><span class="no">EOF
</span><span class="c"># =&gt; deployment.apps/gasida-web created</span>
<span class="c">#    service/svc-nlb-ip-type-pp created</span>

<span class="c"># apache에 proxy protocol 활성화 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>deploy/gasida-web <span class="nt">--</span> apachectl <span class="nt">-t</span> <span class="nt">-D</span> DUMP_MODULES
<span class="c"># =&gt; Loaded Modules:</span>
<span class="c">#     ...</span>
<span class="c">#     remoteip_module (shared)</span>
<span class="c">#     ...</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>deploy/gasida-web <span class="nt">--</span> <span class="nb">cat</span> /usr/local/apache2/conf/httpd.conf
<span class="c"># =&gt; ...</span>
<span class="c">#    RemoteIPProxyProtocol On</span>
<span class="c">#    ...</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get svc,ep
<span class="c"># =&gt; NAME                         TYPE           CLUSTER-IP       EXTERNAL-IP                                                                         PORT(S)        AGE</span>
<span class="c">#    service/kubernetes           ClusterIP      10.100.0.1       &amp;lt;none&amp;gt;                                                                              443/TCP        5h52m</span>
<span class="c">#    service/svc-nlb-ip-type-pp   LoadBalancer   10.100.160.172   k8s-default-svcnlbip-c11e4bd02e-ec82d8f688f176d3.elb.ap-northeast-2.amazonaws.com   80:31348/TCP   36m</span>
<span class="c">#    </span>
<span class="c">#    NAME                           ENDPOINTS                            AGE</span>
<span class="c">#    endpoints/kubernetes           192.168.1.65:443,192.168.3.189:443   5h52m</span>
<span class="c">#    endpoints/svc-nlb-ip-type-pp   192.168.2.51:80                      36m</span>
<span class="nv">$ </span>kubectl describe svc svc-nlb-ip-type-pp
<span class="nv">$ </span>kubectl describe svc svc-nlb-ip-type-pp | <span class="nb">grep </span>Annotations: <span class="nt">-A5</span>
<span class="c"># =&gt; Annotations: service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: true</span>
<span class="c">#                 service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: ip   # &lt;span style="color: green;"&gt;👉 NLB Target Type이 IP입니다.&lt;/span&gt;</span>
<span class="c">#                 service.beta.kubernetes.io/aws-load-balancer-proxy-protocol: *</span>
<span class="c">#                 service.beta.kubernetes.io/aws-load-balancer-scheme: internet-facing</span>
<span class="c">#    Selector:    app=gasida-web</span>
<span class="c">#    Type:        LoadBalancer</span>

<span class="c"># 접속 확인</span>
<span class="nv">$ NLB</span><span class="o">=</span><span class="si">$(</span>kubectl get svc svc-nlb-ip-type-pp <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.status.loadBalancer.ingress[0].hostname<span class="o">}</span><span class="si">)</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$NLB</span>
<span class="c"># =&gt; &amp;lt;html&amp;gt;&amp;lt;body&amp;gt;&amp;lt;h1&amp;gt;It works!&amp;lt;/h1&amp;gt;&amp;lt;/body&amp;gt;&amp;lt;/html&amp;gt;</span>

<span class="c"># 지속적인 접속 시도 : 아래 상세 동작 확인 시 유용(패킷 덤프 등)</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 <span class="nv">$NLB</span><span class="p">;</span> <span class="nb">echo</span> <span class="s2">"----------"</span> <span class="p">;</span> <span class="nb">date</span> <span class="s2">"+%Y-%m-%d %H:%M:%S"</span> <span class="p">;</span> <span class="nb">sleep </span>1<span class="p">;</span> <span class="k">done</span>

<span class="c"># 베스쳔 호스트 IP 확인</span>
<span class="nv">$ </span>curl ipinfo.io/ip
<span class="c"># =&gt; 3.35.140.75</span>

<span class="c"># 로그 확인</span>
<span class="nv">$ </span>kubectl logs <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>gasida-web <span class="nt">-f</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    3.35.140.75 - - [01/Oct/2024:13:46:35 +0000] &amp;quot;GET / HTTP/1.1&amp;quot; 200 45</span>
<span class="c">#    3.35.140.75 - - [01/Oct/2024:13:46:36 +0000] &amp;quot;GET / HTTP/1.1&amp;quot; 200 45</span>
<span class="c">#    3.35.140.75 - - [01/Oct/2024:13:46:37 +0000] &amp;quot;GET / HTTP/1.1&amp;quot; 200 45</span>
<span class="c">#    3.35.140.75 - - [01/Oct/2024:13:46:38 +0000] &amp;quot;GET / HTTP/1.1&amp;quot; 200 45</span>

<span class="c"># &lt;span style="color: green;"&gt;👉 proxy protocol을 통해 외부 클라이언트의 IP가 전달되어 로그에 남는것을 확인할 수 있었습니다.&lt;/span&gt;</span>

<span class="c"># 삭제</span>
<span class="nv">$ </span>kubectl delete deploy gasida-web<span class="p">;</span> kubectl delete svc svc-nlb-ip-type-pp
</code></pre></div></div>

<hr />

<h3 id="ingress">Ingress</h3>

<ul>
  <li>Ingress는 클러스터 내부의 서비스(ClusterIP, NodePort, Loadbalancer)를 외부로 노출(<strong>HTTP/HTTPS</strong>)시키는 일종의 Web Proxy 역할을 수행합니다.</li>
</ul>

<h4 id="aws-load-balancer-controller--ingress-alb-ip-모드-동작-with-aws-vpc-cni"><strong>AWS Load Balancer Controller</strong> + <strong>Ingress (ALB) IP 모드</strong> 동작 with <strong>AWS VPC CNI</strong></h4>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_11.png" alt="img.png" class="image-center w-90" /></p>

<ul>
  <li>
    <p>서비스/파드 배포 테스트 with Ingress(ALB) - <a href="https://docs.aws.amazon.com/eks/latest/userguide/alb-ingress.html">ALB</a></p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 게임 파드와 Service, Ingress 배포</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nt">-O</span> https://raw.githubusercontent.com/gasida/PKOS/main/3/ingress1.yaml
<span class="nv">$ </span><span class="nb">cat </span>ingress1.yaml
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> ingress1.yaml
<span class="c"># =&gt; namespace/game-2048 created</span>
<span class="c">#    deployment.apps/deployment-2048 created</span>
<span class="c">#    service/service-2048 created</span>
<span class="c">#    ingress.networking.k8s.io/ingress-2048 created</span>
  
<span class="c"># 모니터링</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> kubectl get pod,ingress,svc,ep <span class="nt">-n</span> game-2048
  
<span class="c"># 생성 확인</span>
<span class="nv">$ </span>kubectl get-all <span class="nt">-n</span> game-2048
<span class="c"># =&gt; NAME                                                               NAMESPACE  AGE</span>
<span class="c">#    configmap/kube-root-ca.crt                                         game-2048  38s</span>
<span class="c">#    endpoints/service-2048                                             game-2048  38s</span>
<span class="c">#    pod/deployment-2048-85f8c7d69-gz295                                game-2048  38s</span>
<span class="c">#    pod/deployment-2048-85f8c7d69-t2blb                                game-2048  38s</span>
<span class="c">#    serviceaccount/default                                             game-2048  38s</span>
<span class="c">#    service/service-2048                                               game-2048  38s</span>
<span class="c">#    deployment.apps/deployment-2048                                    game-2048  38s</span>
<span class="c">#    replicaset.apps/deployment-2048-85f8c7d69                          game-2048  38s</span>
<span class="c">#    endpointslice.discovery.k8s.io/service-2048-s58q4                  game-2048  38s</span>
<span class="c">#    targetgroupbinding.elbv2.k8s.aws/k8s-game2048-service2-00c3b27023  game-2048  34s</span>
<span class="c">#    ingress.networking.k8s.io/ingress-2048                             game-2048  38s</span>
<span class="nv">$ </span>kubectl get ingress,svc,ep,pod <span class="nt">-n</span> game-2048
<span class="c"># =&gt; NAME                                     CLASS   HOSTS   ADDRESS                                                                       PORTS   AGE</span>
<span class="c">#    ingress.networking.k8s.io/ingress-2048   alb     *       k8s-game2048-ingress2-70d50ce3fd-333540411.ap-northeast-2.elb.amazonaws.com   80      49s</span>
<span class="c">#    </span>
<span class="c">#    NAME                   TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE</span>
<span class="c">#    service/service-2048   NodePort   10.100.41.151   &amp;lt;none&amp;gt;        80:32522/TCP   49s</span>
<span class="c">#    </span>
<span class="c">#    NAME                     ENDPOINTS                          AGE</span>
<span class="c">#    endpoints/service-2048   192.168.1.112:80,192.168.2.18:80   49s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                  READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/deployment-2048-85f8c7d69-gz295   1/1     Running   0          49s</span>
<span class="c">#    pod/deployment-2048-85f8c7d69-t2blb   1/1     Running   0          49s</span>
<span class="nv">$ </span>kubectl get targetgroupbindings <span class="nt">-n</span> game-2048
<span class="c"># =&gt; NAME                               SERVICE-NAME   SERVICE-PORT   TARGET-TYPE   AGE</span>
<span class="c">#    k8s-game2048-service2-00c3b27023   service-2048   80             ip            56s</span>
  
<span class="c"># ALB 생성 확인</span>
<span class="nv">$ </span>aws elbv2 describe-load-balancers <span class="nt">--query</span> <span class="s1">'LoadBalancers[?contains(LoadBalancerName, `k8s-game2048`) == `true`]'</span> | jq
<span class="nv">$ ALB_ARN</span><span class="o">=</span><span class="si">$(</span>aws elbv2 describe-load-balancers <span class="nt">--query</span> <span class="s1">'LoadBalancers[?contains(LoadBalancerName, `k8s-game2048`) == `true`].LoadBalancerArn'</span> | jq <span class="nt">-r</span> <span class="s1">'.[0]'</span><span class="si">)</span>
<span class="nv">$ </span>aws elbv2 describe-target-groups <span class="nt">--load-balancer-arn</span> <span class="nv">$ALB_ARN</span>
<span class="nv">$ TARGET_GROUP_ARN</span><span class="o">=</span><span class="si">$(</span>aws elbv2 describe-target-groups <span class="nt">--load-balancer-arn</span> <span class="nv">$ALB_ARN</span> | jq <span class="nt">-r</span> <span class="s1">'.TargetGroups[0].TargetGroupArn'</span><span class="si">)</span>
<span class="nv">$ </span>aws elbv2 describe-target-health <span class="nt">--target-group-arn</span> <span class="nv">$TARGET_GROUP_ARN</span> | jq
<span class="c"># =&gt; {</span>
<span class="c">#      &amp;quot;TargetHealthDescriptions&amp;quot;: [</span>
<span class="c">#        {</span>
<span class="c">#          &amp;quot;Target&amp;quot;: {</span>
<span class="c">#            &amp;quot;Id&amp;quot;: &amp;quot;192.168.1.112&amp;quot;,</span>
<span class="c">#            &amp;quot;Port&amp;quot;: 80,</span>
<span class="c">#            &amp;quot;AvailabilityZone&amp;quot;: &amp;quot;ap-northeast-2a&amp;quot;</span>
<span class="c">#          },</span>
<span class="c">#          &amp;quot;HealthCheckPort&amp;quot;: &amp;quot;80&amp;quot;,</span>
<span class="c">#          &amp;quot;TargetHealth&amp;quot;: {</span>
<span class="c">#            &amp;quot;State&amp;quot;: &amp;quot;healthy&amp;quot;</span>
<span class="c">#          }</span>
<span class="c">#        },</span>
<span class="c">#        {</span>
<span class="c">#          &amp;quot;Target&amp;quot;: {</span>
<span class="c">#            &amp;quot;Id&amp;quot;: &amp;quot;192.168.2.18&amp;quot;,</span>
<span class="c">#            &amp;quot;Port&amp;quot;: 80,</span>
<span class="c">#            &amp;quot;AvailabilityZone&amp;quot;: &amp;quot;ap-northeast-2b&amp;quot;</span>
<span class="c">#          },</span>
<span class="c">#          &amp;quot;HealthCheckPort&amp;quot;: &amp;quot;80&amp;quot;,</span>
<span class="c">#          &amp;quot;TargetHealth&amp;quot;: {</span>
<span class="c">#            &amp;quot;State&amp;quot;: &amp;quot;healthy&amp;quot;</span>
<span class="c">#          }</span>
<span class="c">#        }</span>
<span class="c">#      ]</span>
<span class="c">#    }</span>
  
<span class="c"># Ingress 확인</span>
<span class="nv">$ </span>kubectl describe ingress <span class="nt">-n</span> game-2048 ingress-2048
<span class="nv">$ </span>kubectl get ingress <span class="nt">-n</span> game-2048 ingress-2048 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.status.loadBalancer.ingress[*].hostname}{'</span><span class="se">\n</span><span class="s2">'}"</span>
<span class="c"># =&gt; k8s-game2048-ingress2-70d50ce3fd-333540411.ap-northeast-2.elb.amazonaws.com</span>
  
<span class="c"># 게임 접속 : ALB 주소로 웹 접속</span>
<span class="nv">$ </span>kubectl get ingress <span class="nt">-n</span> game-2048 ingress-2048 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.status.loadBalancer.ingress[0].hostname<span class="o">}</span> | <span class="nb">awk</span> <span class="s1">'{ print "Game URL = http://"$1 }'</span>
<span class="c"># =&gt; Game URL = http://k8s-game2048-ingress2-70d50ce3fd-333540411.ap-northeast-2.elb.amazonaws.com</span>
  
<span class="c"># 파드 IP 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-n</span> game-2048 <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                              READY   STATUS    RESTARTS   AGE     IP              NODE                                               NOMINATED NODE   READINESS GATES</span>
<span class="c">#    deployment-2048-85f8c7d69-gz295   1/1     Running   0          3m42s   192.168.2.18    ip-192-168-2-92.ap-northeast-2.compute.internal    &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    deployment-2048-85f8c7d69-t2blb   1/1     Running   0          3m42s   192.168.1.112   ip-192-168-1-186.ap-northeast-2.compute.internal   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
</code></pre></div>    </div>
    <p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_31.png" alt="img.png" /></p>

    <ul>
      <li>
        <p><strong>ALB 대상 그룹</strong>에 등록된 대상 확인 : ALB에서 파드 IP로 직접 전달</p>

        <p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_32.png" alt="img.png" class="image-center" />
<em class="image-caption">파드 IP로 바로 직접 연결된 ALB 대상 그룹</em></p>
      </li>
      <li>
        <p>파드 3개로 증가</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 터미널1</span>
<span class="nv">$ </span>watch kubectl get pod <span class="nt">-n</span> game-2048
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>aws elbv2 describe-target-health <span class="nt">--target-group-arn</span> <span class="nv">$TARGET_GROUP_ARN</span> <span class="nt">--output</span> text<span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
    
<span class="c"># 터미널2 : 파드 3개로 증가</span>
<span class="nv">$ </span>kubectl scale deployment <span class="nt">-n</span> game-2048 deployment-2048 <span class="nt">--replicas</span> 3
<span class="c"># =&gt; deployment.apps/deployment-2048 scaled</span>
</code></pre></div>        </div>
        <p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_33.png" alt="img.png" class="image-center" />
<em class="image-caption">추가된 파드 IP가 연결됨</em></p>
      </li>
      <li>
        <p>파드 1개로 감소</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 터미널2 : 파드 1개로 감소</span>
<span class="nv">$ </span>kubectl scale deployment <span class="nt">-n</span> game-2048 deployment-2048 <span class="nt">--replicas</span> 1
<span class="c"># =&gt; deployment.apps/deployment-2048 scaled</span>
</code></pre></div>        </div>

        <p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_34.png" alt="img.png" class="image-center" />
<em class="image-caption">삭제되는 2개의 파드가 삭제 중임을 확인</em></p>
      </li>
      <li>
        <p>실습 리소스  삭제</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl delete ingress ingress-2048 <span class="nt">-n</span> game-2048
<span class="nv">$ </span>kubectl delete svc service-2048 <span class="nt">-n</span> game-2048 <span class="o">&amp;&amp;</span> kubectl delete deploy deployment-2048 <span class="nt">-n</span> game-2048 <span class="o">&amp;&amp;</span> kubectl delete ns game-2048
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
</ul>

<h4 id="kubernetes-응용프로그램을-외부로-노출-시키는-방법들-비교">Kubernetes 응용프로그램을 외부로 노출 시키는 방법들 비교</h4>

<ul>
  <li>간략하게 Kubernetes 응용프로그램을 외부로 노출 시기는 방법들을 비교해보겠습니다.</li>
  <li>자세한 내용은 다음 블로그에서 살펴 볼 수 있습니다. <a href="https://aws.amazon.com/blogs/containers/exposing-kubernetes-applications-part-1-service-and-ingress-resources/">Exposing Kubernetes Applications, Part 1: Service and Ingress Resources </a>
    <ol>
      <li>Exposing a <strong>Service</strong> : In-tree Service Controller
  <img src="/assets/2024/kans-3th/w9/20241102_kans_w9_12.png" alt="img.png" class="image-center" />
        <ul>
          <li>AWS CLB(Classic Load Balancer)나 AWS NLB(Network Load Balancer)를 사용하여 서비스를 직접 외부로 노출합니다.
 하지만 서비스 수가 많아지면 Load Balancer의 수도 많아지게 되어 관리가 어려워집니다.</li>
        </ul>
      </li>
      <li><strong>Ingress Implementations : External Load Balancer</strong>
  <img src="/assets/2024/kans-3th/w9/20241102_kans_w9_13.png" alt="img.png" class="image-center" />
        <ul>
          <li>외부에 ALB(Application Load Balancer)를 생성하고 라우팅합니다. 이때 외부의 ALB가 Ingress rule을 ALB rule로 변환하여 
 외부 ALB가 직접 파드와 통신합니다. 앞에서 본 서비스를 직접 외부로 노출하는것 보다, CSP(Cloud Service Provider)에서 제공하는
 확장성이나, DDOS 방어기능 등을 활용 할 수 있습니다.</li>
        </ul>
      </li>
      <li><strong>Ingress Implementations : Internal Reverse Proxy</strong>
  <img src="/assets/2024/kans-3th/w9/20241102_kans_w9_14.png" alt="img.png" class="image-center" />
        <ul>
          <li>외부의 ALB에 더해 nginx 등의 Layer 7 리버스 프록시를 두는 방식입니다. 이 방식은 외부 ALB가 직접 파드와 통신하는 것이 아니라,
 리버스 프록시를 통해 통신하게 됩니다. 성능상으로는 불이익이 있지만 L7 리버스 프록시에서 제공하는 추가 기능들을 활용 할 수 있습니다.</li>
          <li>하지만 관리요소가 추가되는 것이기 때문에 이를 고려하여 사용해야 합니다.</li>
        </ul>
      </li>
      <li><strong>Kubernetes Gateway API</strong>
  <img src="/assets/2024/kans-3th/w9/20241102_kans_w9_15.png" alt="img.png" class="image-center" />
        <ul>
          <li>Kubernetes Gateway API는 Ingress Controller를 대체하는 새로운 API로 현시점에서 Beta 상태로, 정식 지원하지는 않는듯하며,
 외부 Loadbalancer나 Internal reverse proxy 방식처럼 사용할 수 있습니다.</li>
        </ul>
      </li>
    </ol>
  </li>
</ul>

<h3 id="externaldns">ExternalDNS</h3>

<ul>
  <li>
    <p>K8S 서비스/인그레스 생성 시 도메인을 설정하면, AWS(Route 53), Azure(DNS), GCP(Cloud DNS)에 A 레코드(TXT 레코드)가 자동으로 생성/삭제됩니다.
<img src="/assets/2024/kans-3th/w9/20241102_kans_w9_27.png" alt="img.png" class="image-center" />
<em class="image-caption"><a href="https://edgehog.blog/a-self-hosted-external-dns-resolver-for-kubernetes-111a27d6fc2c">https://edgehog.blog/a-self-hosted-external-dns-resolver-for-kubernetes-111a27d6fc2c</a></em></p>
  </li>
  <li>
    <p>AWS Route 53 정보 확인 &amp; 변수 지정 : Public 도메인 소유를 하고 있어야 합니다</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 자신의 도메인 변수 지정 : 소유하고 있는 자신의 도메인을 입력하시면 됩니다</span>
<span class="c">#$ MyDomain=&lt;자신의 도메인&gt;</span>
<span class="nv">$ MyDomain</span><span class="o">=</span>kans.loremipsum.sweetlittlebird.io
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"export MyDomain=kans.loremipsum.sweetlittlebird.io"</span> <span class="o">&gt;&gt;</span> /etc/profile
  
<span class="c"># 자신의 Route 53 도메인 ID 조회 및 변수 지정</span>
<span class="nv">$ </span>aws route53 list-hosted-zones-by-name <span class="nt">--dns-name</span> <span class="s2">"</span><span class="k">${</span><span class="nv">MyDomain</span><span class="k">}</span><span class="s2">."</span> | jq
<span class="c"># =&gt; {</span>
<span class="c">#      &amp;quot;HostedZones&amp;quot;: [</span>
<span class="c">#        {</span>
<span class="c">#          &amp;quot;Id&amp;quot;: &amp;quot;/hostedzone/Z0416620XQJAGAPWXO31&amp;quot;,</span>
<span class="c">#          &amp;quot;Name&amp;quot;: &amp;quot;kans.loremipsum.sweetlittlebird.io.&amp;quot;,</span>
<span class="c">#          &amp;quot;CallerReference&amp;quot;: &amp;quot;3aba3324-d6a0-44a4-82b5-004044e06dd6&amp;quot;,</span>
<span class="c">#          &amp;quot;Config&amp;quot;: {</span>
<span class="c">#            &amp;quot;Comment&amp;quot;: &amp;quot;&amp;quot;,</span>
<span class="c">#            &amp;quot;PrivateZone&amp;quot;: false</span>
<span class="c">#          },</span>
<span class="c">#          &amp;quot;ResourceRecordSetCount&amp;quot;: 3</span>
<span class="c">#        }</span>
<span class="c">#      ],</span>
<span class="c">#      &amp;quot;DNSName&amp;quot;: &amp;quot;kans.loremipsum.sweetlittlebird.io.&amp;quot;,</span>
<span class="c">#      &amp;quot;IsTruncated&amp;quot;: false,</span>
<span class="c">#      &amp;quot;MaxItems&amp;quot;: &amp;quot;100&amp;quot;</span>
<span class="c">#    }</span>
<span class="nv">$ </span>aws route53 list-hosted-zones-by-name <span class="nt">--dns-name</span> <span class="s2">"</span><span class="k">${</span><span class="nv">MyDomain</span><span class="k">}</span><span class="s2">."</span> <span class="nt">--query</span> <span class="s2">"HostedZones[0].Name"</span>
<span class="c"># =&gt; &amp;quot;kans.loremipsum.sweetlittlebird.io.&amp;quot;</span>
<span class="nv">$ </span>aws route53 list-hosted-zones-by-name <span class="nt">--dns-name</span> <span class="s2">"</span><span class="k">${</span><span class="nv">MyDomain</span><span class="k">}</span><span class="s2">."</span> <span class="nt">--query</span> <span class="s2">"HostedZones[0].Id"</span> <span class="nt">--output</span> text
<span class="c"># =&gt; /hostedzone/Z0416620XQJAGAPWXO31</span>
<span class="nv">$ MyDnzHostedZoneId</span><span class="o">=</span><span class="sb">`</span>aws route53 list-hosted-zones-by-name <span class="nt">--dns-name</span> <span class="s2">"</span><span class="k">${</span><span class="nv">MyDomain</span><span class="k">}</span><span class="s2">."</span> <span class="nt">--query</span> <span class="s2">"HostedZones[0].Id"</span> <span class="nt">--output</span> text<span class="sb">`</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$MyDnzHostedZoneId</span>
<span class="c"># =&gt; /hostedzone/Z0416620XQJAGAPWXO31</span>
  
<span class="c"># (옵션) NS 레코드 타입 첫번째 조회</span>
<span class="nv">$ </span>aws route53 list-resource-record-sets <span class="nt">--output</span> json <span class="nt">--hosted-zone-id</span> <span class="s2">"</span><span class="k">${</span><span class="nv">MyDnzHostedZoneId</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--query</span> <span class="s2">"ResourceRecordSets[?Type == 'NS']"</span> | jq <span class="nt">-r</span> <span class="s1">'.[0].ResourceRecords[].Value'</span>
<span class="c"># =&gt; ns-979.awsdns-58.net.</span>
<span class="c">#    ns-1489.awsdns-58.org.</span>
<span class="c">#    ns-355.awsdns-44.com.</span>
<span class="c">#    ns-1760.awsdns-28.co.uk.</span>
<span class="c"># (옵션) A 레코드 타입 모두 조회</span>
<span class="nv">$ </span>aws route53 list-resource-record-sets <span class="nt">--output</span> json <span class="nt">--hosted-zone-id</span> <span class="s2">"</span><span class="k">${</span><span class="nv">MyDnzHostedZoneId</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--query</span> <span class="s2">"ResourceRecordSets[?Type == 'A']"</span>
<span class="c"># =&gt; []</span>
  
<span class="c"># A 레코드 타입 조회</span>
<span class="nv">$ </span>aws route53 list-resource-record-sets <span class="nt">--hosted-zone-id</span> <span class="s2">"</span><span class="k">${</span><span class="nv">MyDnzHostedZoneId</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--query</span> <span class="s2">"ResourceRecordSets[?Type == 'A']"</span> | jq
<span class="nv">$ </span>aws route53 list-resource-record-sets <span class="nt">--hosted-zone-id</span> <span class="s2">"</span><span class="k">${</span><span class="nv">MyDnzHostedZoneId</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--query</span> <span class="s2">"ResourceRecordSets[?Type == 'A'].Name"</span> | jq
<span class="nv">$ </span>aws route53 list-resource-record-sets <span class="nt">--hosted-zone-id</span> <span class="s2">"</span><span class="k">${</span><span class="nv">MyDnzHostedZoneId</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--query</span> <span class="s2">"ResourceRecordSets[?Type == 'A'].Name"</span> <span class="nt">--output</span> text
  
<span class="c"># A 레코드 값 반복 조회</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>aws route53 list-resource-record-sets <span class="nt">--hosted-zone-id</span> <span class="s2">"</span><span class="k">${</span><span class="nv">MyDnzHostedZoneId</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--query</span> <span class="s2">"ResourceRecordSets[?Type == 'A']"</span> | jq <span class="p">;</span> <span class="nb">date</span> <span class="p">;</span> <span class="nb">echo</span> <span class="p">;</span> <span class="nb">sleep </span>1<span class="p">;</span> <span class="k">done</span>
</code></pre></div>    </div>
  </li>
  <li>ExternalDNS 설치 - <a href="https://github.com/kubernetes-sigs/external-dns/blob/master/docs/tutorials/aws.md">링크</a>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># EKS 배포 시 Node IAM Role 설정되어 있음</span>
<span class="c"># eksctl create cluster ... --external-dns-access ...</span>
  
<span class="c"># </span>
<span class="c">#$ MyDomain=&lt;자신의 도메인&gt;</span>
<span class="nv">$ MyDomain</span><span class="o">=</span>kans.loremipsum.sweetlittlebird.io
  
<span class="c"># 자신의 Route 53 도메인 ID 조회 및 변수 지정</span>
<span class="nv">$ MyDnzHostedZoneId</span><span class="o">=</span><span class="si">$(</span>aws route53 list-hosted-zones-by-name <span class="nt">--dns-name</span> <span class="s2">"</span><span class="k">${</span><span class="nv">MyDomain</span><span class="k">}</span><span class="s2">."</span> <span class="nt">--query</span> <span class="s2">"HostedZones[0].Id"</span> <span class="nt">--output</span> text<span class="si">)</span>
  
<span class="c"># 변수 확인</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$MyDomain</span>, <span class="nv">$MyDnzHostedZoneId</span>
<span class="c"># =&gt; kans.loremipsum.sweetlittlebird.io, /hostedzone/Z0416620XQJAGAPWXO31</span>
  
<span class="c"># ExternalDNS 배포</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nt">-O</span> https://raw.githubusercontent.com/gasida/PKOS/main/aews/externaldns.yaml
<span class="nv">$ </span><span class="nb">cat </span>externaldns.yaml
<span class="nv">$ MyDomain</span><span class="o">=</span><span class="nv">$MyDomain</span> <span class="nv">MyDnzHostedZoneId</span><span class="o">=</span><span class="nv">$MyDnzHostedZoneId</span> envsubst &lt; externaldns.yaml | kubectl apply <span class="nt">-f</span> -
<span class="c"># =&gt; serviceaccount/external-dns created</span>
<span class="c">#    clusterrole.rbac.authorization.k8s.io/external-dns created</span>
<span class="c">#    clusterrolebinding.rbac.authorization.k8s.io/external-dns-viewer created</span>
<span class="c">#    deployment.apps/external-dns created</span>
  
<span class="c"># 확인 및 로그 모니터링</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-l</span> app.kubernetes.io/name<span class="o">=</span>external-dns <span class="nt">-n</span> kube-system
<span class="c"># =&gt; NAME                            READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    external-dns-648996678b-7r4mz   1/1     Running   0          12s</span>
<span class="nv">$ </span>kubectl logs deploy/external-dns <span class="nt">-n</span> kube-system <span class="nt">-f</span>
</code></pre></div>    </div>

    <ul>
      <li>
        <p>(참고) 기존에 ExternalDNS를 통해 사용한 A/TXT 레코드가 있는 존의 경우에 policy 정책을 upsert-only 로 설정 후 사용 하자 - <a href="https://github.com/kubernetes-sigs/external-dns/blob/master/docs/tutorials/aws.md#deploy-externaldns">Link</a></p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- <span class="c">#--policy=upsert-only # would prevent ExternalDNS from deleting any records, omit to enable full synchronization</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li>Service(<strong>NLB</strong>) + 도메인 연동(<strong>ExternalDNS</strong>) - <a href="https://www.whatsmydns.net/">도메인체크</a>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 터미널1 (모니터링)</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> <span class="s1">'kubectl get pod,svc'</span>
<span class="nv">$ </span>kubectl logs deploy/external-dns <span class="nt">-n</span> kube-system <span class="nt">-f</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    time=&amp;quot;2024-10-01T14:18:10Z&amp;quot; level=info msg=&amp;quot;Instantiating new Kubernetes client&amp;quot;</span>
<span class="c">#    time=&amp;quot;2024-10-01T14:18:10Z&amp;quot; level=info msg=&amp;quot;Using inCluster-config based on serviceaccount-token&amp;quot;</span>
<span class="c">#    time=&amp;quot;2024-10-01T14:18:10Z&amp;quot; level=info msg=&amp;quot;Created Kubernetes client https://10.100.0.1:443&amp;quot;</span>
<span class="c">#    time=&amp;quot;2024-10-01T14:18:11Z&amp;quot; level=info msg=&amp;quot;Applying provider record filter for domains: [kans.loremipsum.sweetlittlebird.io. .kans.loremipsum.sweetlittlebird.io.]&amp;quot;</span>
<span class="c">#    time=&amp;quot;2024-10-01T14:18:11Z&amp;quot; level=info msg=&amp;quot;All records are already up to date&amp;quot;</span>
<span class="c">#    ... (deployment 배포 후) ...</span>
<span class="c">#    time=&amp;quot;2024-10-01T14:20:11Z&amp;quot; level=info msg=&amp;quot;Applying provider record filter for domains: [kans.loremipsum.sweetlittlebird.io. .kans.loremipsum.sweetlittlebird.io.]&amp;quot;</span>
<span class="c">#    time=&amp;quot;2024-10-01T14:20:12Z&amp;quot; level=info msg=&amp;quot;Desired change: CREATE cname-tetris.kans.loremipsum.sweetlittlebird.io TXT&amp;quot; profile=default zoneID=/hostedzone/Z0416620XQJAGAPWXO31 zoneName=kans.loremipsum.sweetlittlebird.io.</span>
<span class="c">#    time=&amp;quot;2024-10-01T14:20:12Z&amp;quot; level=info msg=&amp;quot;Desired change: CREATE tetris.kans.loremipsum.sweetlittlebird.io A&amp;quot; profile=default zoneID=/hostedzone/Z0416620XQJAGAPWXO31 zoneName=kans.loremipsum.sweetlittlebird.io.</span>
<span class="c">#    time=&amp;quot;2024-10-01T14:20:12Z&amp;quot; level=info msg=&amp;quot;Desired change: CREATE tetris.kans.loremipsum.sweetlittlebird.io TXT&amp;quot; profile=default zoneID=/hostedzone/Z0416620XQJAGAPWXO31 zoneName=kans.loremipsum.sweetlittlebird.io.</span>
<span class="c">#    time=&amp;quot;2024-10-01T14:20:12Z&amp;quot; level=info msg=&amp;quot;3 record(s) were successfully updated&amp;quot; profile=default zoneID=/hostedzone/Z0416620XQJAGAPWXO31 zoneName=kans.loremipsum.sweetlittlebird.io.</span>
  
<span class="c"># 테트리스 디플로이먼트 배포</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: tetris
  labels:
    app: tetris
spec:
  replicas: 1
  selector:
    matchLabels:
      app: tetris
  template:
    metadata:
      labels:
        app: tetris
    spec:
      containers:
      - name: tetris
        image: bsord/tetris
---
apiVersion: v1
kind: Service
metadata:
  name: tetris
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: ip
    service.beta.kubernetes.io/aws-load-balancer-scheme: internet-facing
    service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: "true"
    service.beta.kubernetes.io/aws-load-balancer-backend-protocol: "http"
    #service.beta.kubernetes.io/aws-load-balancer-healthcheck-port: "80"
spec:
  selector:
    app: tetris
  ports:
  - port: 80
    protocol: TCP
    targetPort: 80
  type: LoadBalancer
  loadBalancerClass: service.k8s.aws/nlb
</span><span class="no">EOF
  
</span><span class="c"># 배포 확인</span>
<span class="nv">$ </span>kubectl get deploy,svc,ep tetris
<span class="c"># =&gt; NAME                     READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/tetris   0/1     1            0           5s</span>
<span class="c">#    </span>
<span class="c">#    NAME             TYPE           CLUSTER-IP      EXTERNAL-IP                                                                       PORT(S)        AGE</span>
<span class="c">#    service/tetris   LoadBalancer   10.100.39.204   k8s-default-tetris-4d2a39458c-e91cd840ce214644.elb.ap-northeast-2.amazonaws.com   80:32310/TCP   5s</span>
<span class="c">#    </span>
<span class="c">#    NAME               ENDPOINTS   AGE</span>
<span class="c">#    endpoints/tetris   &amp;lt;none&amp;gt;      5s</span>
  
<span class="c"># NLB에 ExternanDNS 로 도메인 연결</span>
<span class="nv">$ </span>kubectl annotate service tetris <span class="s2">"external-dns.alpha.kubernetes.io/hostname=tetris.</span><span class="nv">$MyDomain</span><span class="s2">"</span>
<span class="c"># =&gt; service/tetris annotated</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>aws route53 list-resource-record-sets <span class="nt">--hosted-zone-id</span> <span class="s2">"</span><span class="k">${</span><span class="nv">MyDnzHostedZoneId</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--query</span> <span class="s2">"ResourceRecordSets[?Type == 'A']"</span> | jq <span class="p">;</span> <span class="nb">date</span> <span class="p">;</span> <span class="nb">echo</span> <span class="p">;</span> <span class="nb">sleep </span>1<span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; [</span>
<span class="c">#      {</span>
<span class="c">#        &amp;quot;Name&amp;quot;: &amp;quot;tetris.kans.loremipsum.sweetlittlebird.io.&amp;quot;,</span>
<span class="c">#        &amp;quot;Type&amp;quot;: &amp;quot;A&amp;quot;,</span>
<span class="c">#        &amp;quot;AliasTarget&amp;quot;: {</span>
<span class="c">#          &amp;quot;HostedZoneId&amp;quot;: &amp;quot;ZIBE1TIR4HY56&amp;quot;,</span>
<span class="c">#          &amp;quot;DNSName&amp;quot;: &amp;quot;k8s-default-tetris-4d2a39458c-e91cd840ce214644.elb.ap-northeast-2.amazonaws.com.&amp;quot;,</span>
<span class="c">#          &amp;quot;EvaluateTargetHealth&amp;quot;: true</span>
<span class="c">#        }</span>
<span class="c">#      }</span>
<span class="c">#    ]</span>
<span class="c">#    Sat Oct  1 23:21:27 KST 2024</span>
<span class="c">#    ...</span>
  
<span class="c"># Route53에 A레코드 확인</span>
<span class="nv">$ </span>aws route53 list-resource-record-sets <span class="nt">--hosted-zone-id</span> <span class="s2">"</span><span class="k">${</span><span class="nv">MyDnzHostedZoneId</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--query</span> <span class="s2">"ResourceRecordSets[?Type == 'A']"</span> | jq
<span class="c"># =&gt; [</span>
<span class="c">#      {</span>
<span class="c">#        &amp;quot;Name&amp;quot;: &amp;quot;tetris.kans.loremipsum.sweetlittlebird.io.&amp;quot;,</span>
<span class="c">#        &amp;quot;Type&amp;quot;: &amp;quot;A&amp;quot;,</span>
<span class="c">#        &amp;quot;AliasTarget&amp;quot;: {</span>
<span class="c">#          &amp;quot;HostedZoneId&amp;quot;: &amp;quot;ZIBE1TIR4HY56&amp;quot;,</span>
<span class="c">#          &amp;quot;DNSName&amp;quot;: &amp;quot;k8s-default-tetris-4d2a39458c-e91cd840ce214644.elb.ap-northeast-2.amazonaws.com.&amp;quot;,</span>
<span class="c">#          &amp;quot;EvaluateTargetHealth&amp;quot;: true</span>
<span class="c">#        }</span>
<span class="c">#      }</span>
<span class="c">#    ]</span>
<span class="nv">$ </span>aws route53 list-resource-record-sets <span class="nt">--hosted-zone-id</span> <span class="s2">"</span><span class="k">${</span><span class="nv">MyDnzHostedZoneId</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--query</span> <span class="s2">"ResourceRecordSets[?Type == 'A'].Name"</span> | jq .[]
<span class="c"># =&gt; &amp;quot;tetris.kans.loremipsum.sweetlittlebird.io.&amp;quot;</span>
  
<span class="c"># 확인</span>
<span class="nv">$ </span>dig +short tetris.<span class="nv">$MyDomain</span> @8.8.8.8
<span class="c"># =&gt; 3.38.82.70</span>
<span class="c">#    3.36.187.152</span>
<span class="c">#    3.35.184.161</span>
<span class="nv">$ </span>dig +short tetris.<span class="nv">$MyDomain</span>
<span class="c"># =&gt; 3.38.82.70</span>
  
<span class="c"># 도메인 체크</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"My Domain Checker = https://www.whatsmydns.net/#A/tetris.</span><span class="nv">$MyDomain</span><span class="s2">"</span>
<span class="c"># =&gt; My Domain Checker = https://www.whatsmydns.net/#A/tetris.kans.loremipsum.sweetlittlebird.io</span>
  
<span class="c"># 웹 접속 주소 확인 및 접속</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"Tetris Game URL = http://tetris.</span><span class="nv">$MyDomain</span><span class="s2">"</span>
<span class="c"># =&gt; Tetris Game URL = http://tetris.kans.loremipsum.sweetlittlebird.io</span>
</code></pre></div>    </div>

    <ul>
      <li>
        <p>웹 접속(http) → 화살표키, 일시중지(space bar)</p>

        <p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_35.png" alt="img.png" class="image-center" /></p>
      </li>
    </ul>
  </li>
  <li>
    <p>Ingress(ALB + HTTPS) + 도메인 연동(ExternalDNS)</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 테트리스 디플로이먼트 배포</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: tetris
  labels:
    app: tetris
spec:
  replicas: 1
  selector:
    matchLabels:
      app: tetris
  template:
    metadata:
      labels:
        app: tetris
    spec:
      containers:
      - name: tetris
        image: bsord/tetris
---
apiVersion: v1
kind: Service
metadata:
  name: tetris
  labels:
    app: tetris
spec:
  selector:
    app: tetris
  ports:
  - port: 80
    protocol: TCP
    targetPort: 80
  type: LoadBalancer
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: tetris-ingress
  annotations:
    kubernetes.io/ingress.class: alb
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/certificate-arn: arn:aws:acm:ap-northeast-2:123456789012:certificate/256538f4-6c5d-4109-9d4d-9aa6af41adaa
    alb.ingress.kubernetes.io/listen-ports: '[{"HTTP": 80}, {"HTTPS":443}]'
    alb.ingress.kubernetes.io/actions.ssl-redirect: '{"Type": "redirect", "RedirectConfig": { "Protocol": "HTTPS", "Port": "443", "StatusCode": "HTTP_301"}}'
spec:
  ingressClassName: alb
  rules:
    - http:
        paths:
        - path: /
          pathType: Prefix
          backend:
            service:
              name: tetris
              port:
                number: 80  
</span><span class="no">EOF
</span><span class="c"># =&gt; deployment.apps/tetris created</span>
<span class="c">#    service/tetris created</span>
<span class="c">#    ingress.networking.k8s.io/tetris-ingress created</span>
  
<span class="c"># ingress에 도메인 부여</span>
<span class="nv">$ </span>kubectl annotate ingress tetris-ingress <span class="s2">"external-dns.alpha.kubernetes.io/hostname=tetris2.</span><span class="nv">$MyDomain</span><span class="s2">"</span>
<span class="c"># =&gt; ingress.networking.k8s.io/tetris-ingress annotated</span>
  
<span class="c"># &lt;span style="color: green;"&gt;👉 기존에 사용했던 도메인(tetris.$MyDomain)을 사용하면 DNS 레코드가 전파되는데 시간이 더 걸리기 때문에&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   다른 도메인 (tetris2.$MyDomain)을 사용하였습니다.&lt;/span&gt;</span>
</code></pre></div>    </div>

    <p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_36.png" alt="img.png" class="image-center" />
<em class="image-caption">dns 적용 확인 (<a href="https://www.whatsmydns.net/">확인 사이트 링크</a>)</em></p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">https://tetris2.kans.loremipsum.sweetlittlebird.io</code> 로 접속하여 https 통신 확인
<img src="/assets/2024/kans-3th/w9/20241102_kans_w9_37.png" alt="img.png" class="image-center" />
<em class="image-caption">https 적용 확인</em></li>
    </ul>
  </li>
  <li><strong>리소스 삭제</strong> : <code class="language-plaintext highlighter-rouge">kubectl delete deploy,svc tetris</code> ← 삭제 시 externaldns 에 의해서 A레코드도 같이 삭제됩니다.</li>
</ul>

<ul>
  <li>
    <p>(참고) ACM 퍼블릭 인증서 요청 및 해당 인증서에 대한 Route53 도메인 검증 설정 with AWS CLI</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 각자 자신의 도메인 변수 지정</span>
<span class="c">#$ MyDomain=&lt;각자 자신의 도메인&gt;</span>
<span class="nv">$ MyDomain</span><span class="o">=</span>kans.loremipsum.sweetlittlebird.io
  
<span class="c"># ACM 퍼블릭 인증서 요청</span>
<span class="nv">$ CERT_ARN</span><span class="o">=</span><span class="si">$(</span>aws acm request-certificate <span class="se">\</span>
  <span class="nt">--domain-name</span> <span class="nv">$MyDomain</span> <span class="se">\</span>
  <span class="nt">--validation-method</span> <span class="s1">'DNS'</span> <span class="se">\</span>
  <span class="nt">--key-algorithm</span> <span class="s1">'RSA_2048'</span> <span class="se">\</span>
  | jq <span class="nt">--raw-output</span> <span class="s1">'.CertificateArn'</span><span class="si">)</span>
  
<span class="c"># 생성한 인증서 CNAME 이름 가져오기</span>
<span class="nv">$ CnameName</span><span class="o">=</span><span class="si">$(</span>aws acm describe-certificate <span class="se">\</span>
  <span class="nt">--certificate-arn</span> <span class="nv">$CERT_ARN</span> <span class="se">\</span>
  <span class="nt">--query</span> <span class="s1">'Certificate.DomainValidationOptions[*].ResourceRecord.Name'</span> <span class="se">\</span>
  <span class="nt">--output</span> text<span class="si">)</span>
  
<span class="c"># 생성한 인증서 CNAME 값 가져오기</span>
<span class="nv">$ CnameValue</span><span class="o">=</span><span class="si">$(</span>aws acm describe-certificate <span class="se">\</span>
  <span class="nt">--certificate-arn</span> <span class="nv">$CERT_ARN</span> <span class="se">\</span>
  <span class="nt">--query</span> <span class="s1">'Certificate.DomainValidationOptions[*].ResourceRecord.Value'</span> <span class="se">\</span>
  <span class="nt">--output</span> text<span class="si">)</span>
  
<span class="c"># 정상 출력 확인하기</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$CERT_ARN</span>, <span class="nv">$CnameName</span>, <span class="nv">$CnameValue</span>
<span class="c"># =&gt; arn:aws:acm:ap-northeast-2:123456789012:certificate/256538f4-6c5d-4109-9d4d-9aa6af41adaa, _e784949706a5e6eee7f350436cc9d501.kans.loremipsum.sweetlittlebird.io., _e62ee6e59a48ea2f3d1ab952d289bcea.djqtsrsxkq.acm-validations.aws.</span>
  
<span class="c"># 레코드 파일</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh"> &gt; cname.json
{
  "Comment": "create a acm's CNAME record",
  "Changes": [
    {
      "Action": "CREATE",
      "ResourceRecordSet": {
        "Name": "CnameName",
        "Type": "CNAME",
        "TTL": 300,
        "ResourceRecords": [
          {
            "Value": "CnameValue"
          }
        ]
      }
    }
  ]
}
</span><span class="no">EOT
  
</span><span class="c"># CNAME 이름, 값 치환하기</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/CnameName/</span><span class="nv">$CnameName</span><span class="s2">/g"</span> cname.json
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/CnameValue/</span><span class="nv">$CnameValue</span><span class="s2">/g"</span> cname.json
<span class="nv">$ </span><span class="nb">cat </span>cname.json
<span class="c"># =&gt; {</span>
<span class="c">#      &amp;quot;Comment&amp;quot;: &amp;quot;create a acm's CNAME record&amp;quot;,</span>
<span class="c">#      &amp;quot;Changes&amp;quot;: [</span>
<span class="c">#        {</span>
<span class="c">#          &amp;quot;Action&amp;quot;: &amp;quot;CREATE&amp;quot;,</span>
<span class="c">#          &amp;quot;ResourceRecordSet&amp;quot;: {</span>
<span class="c">#            &amp;quot;Name&amp;quot;: &amp;quot;_e784949706a5e6eee7f350436cc9d501.kans.loremipsum.sweetlittlebird.io.&amp;quot;,</span>
<span class="c">#            &amp;quot;Type&amp;quot;: &amp;quot;CNAME&amp;quot;,</span>
<span class="c">#            &amp;quot;TTL&amp;quot;: 300,</span>
<span class="c">#            &amp;quot;ResourceRecords&amp;quot;: [</span>
<span class="c">#              {</span>
<span class="c">#                &amp;quot;Value&amp;quot;: &amp;quot;_e62ee6e59a48ea2f3d1ab952d289bcea.djqtsrsxkq.acm-validations.aws.&amp;quot;</span>
<span class="c">#              }</span>
<span class="c">#            ]</span>
<span class="c">#          }</span>
<span class="c">#        }</span>
<span class="c">#      ]</span>
<span class="c">#    }</span>
  
<span class="c"># 해당 인증서에 대한 Route53 도메인 검증 설정을 위한 Route53 레코드 생성</span>
<span class="nv">$ </span>aws route53 change-resource-record-sets <span class="nt">--hosted-zone-id</span> <span class="nv">$MyDnzHostedZoneId</span> <span class="nt">--change-batch</span> file://cname.json
</code></pre></div>    </div>
  </li>
</ul>

<h3 id="실습-완료-후-자원-삭제">실습 완료 후 자원 삭제</h3>

<ul>
  <li>삭제 : 장점(1줄 명령어로 완전 삭제), 단점(삭제 실행과 완료까지 SSH 세션 유지 필요)
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>eksctl delete cluster <span class="nt">--name</span> <span class="nv">$CLUSTER_NAME</span> <span class="o">&amp;&amp;</span> aws cloudformation delete-stack <span class="nt">--stack-name</span> <span class="nv">$CLUSTER_NAME</span>
</code></pre></div>    </div>
  </li>
</ul>

<hr />

<h2 id="마치며">마치며</h2>

<p>와.. 드디어 마지막 주차인 9주차 과제를 완료하였습니다.
마지막 주차인 만큼 과제를 빨리 마치고 싶었지만, 생각보다 시간이 많이 걸려서 결국 오늘도 자정을 넘긴 일요일입니다. :cry:
매과제마다 저도 시간을 많이 쏟지만, 가시다 님을 비롯하여 스터디 조력자분들이 이 스터디를 위해 지금까지 얼마나 많은 시간을 투자하셨을지
생각하면 스스로가 머쓱하면서도, 감사함과 존경심을 느낍니다.</p>

<p>이번 스터디를 통해 많은 것을 배웠고, 블로그를 작성하는데 있어서도 많은 도움이 되었습니다.
회사에서 필요한 글만 쓰다가, 정말 오랜만에 개인을 위한 글도 이렇게 꾸준히 쓴것도 참 오랜만입니다. 
지난 테라폼 스터디부터 하면 5개월 정도는 거의 매주 글을 썼던 것 같습니다. 
—물론 실습 위주여서 “글”을 쓴게 맞냐는 문제가 있긴합니다.— 
예전에는 정말 시덥잖은 블로그 글도 많이 썼었는데, 나이도 들고, 사회적 지위도 (아직은 낮지만 예전보다) 높아지다보니
글을 쓰는데 있어서도 조금은 부담이 되었었는데, 이번 스터디를 통해 다시 글을 쓰는 재미와 글을 쓸 수 있다는 자신감을 느끼게 되었습니다.
앞으로도 스터디가 아니더라도 꾸준히 글을 쓰고 싶습니다.</p>

<p>약 3개월 간 스터디를 잘 이끌어주신 가시다 님과 조력자 분들께 큰 감사를 드립니다. :bow:</p>

<p>스터디에 참여하신 모든 분들도 고생 많으셨습니다. 다음에 또 뵐 수 있기를 기대합니다. :smile:</p>]]></content><author><name></name></author><category term="kans" /><category term="kubernetes," /><category term="network," /><category term="linux" /><summary type="html"><![CDATA[이번 주에는 AWS EKS의 VPC CNI에 대해 알아보겠습니다.]]></summary></entry><entry><title type="html">[KANS 3기] Cilium CNI</title><link href="https://sweetlittlebird.github.io/posts/2024-10-26-KANS-Study-Week8/" rel="alternate" type="text/html" title="[KANS 3기] Cilium CNI" /><published>2024-10-26T01:00:18+09:00</published><updated>2024-10-26T01:00:18+09:00</updated><id>https://sweetlittlebird.github.io/posts/KANS%20Study%20-%20Week8</id><content type="html" xml:base="https://sweetlittlebird.github.io/posts/2024-10-26-KANS-Study-Week8/"><![CDATA[<h2 id="들어가며">들어가며</h2>

<p>이번주에는 드디어 CNI의 끝판 왕(제가 아는 한에서)인 Cilium에 대해 알아보겠습니다.
어떤 것들이 가능할지 궁금합니다. 
KANS 3기 8주차 스터디를 시작하겠습니다.</p>

<hr />

<h2 id="cilium">Cilium</h2>

<p>Cilium은 eBPF(Berkeley Packet Filter)를 사용하여 네트워크 보안 및 라우팅을 제공하는 CNI(Container Network Interface) 플러그인입니다.
먼저 Cilium의 근간이 되는 eBPF에 대해 간단히 소개하고, Cilium에 대한 소개와 실습을 진행하겠습니다.</p>

<h3 id="bpfebpf-소개">BPF/eBPF 소개</h3>

<ul>
  <li>소개글 : <a href="https://hyeyoo.com/133">링크</a></li>
</ul>

<p><img src="/assets/2024/kans-3th/w8/20241026_kans_w8_1.png" alt="img.png" class="image-center" />
<em class="image-caption">기존 리눅스 Netfilter 기반 네트워크 스택</em></p>

<p>기존의 네트워크 스택은 Netfilter 기반으로 동작하며, 복잡한 네트워크 레이어를 거쳐야하고 이 레이어를 건너뛰기 어렵습니다.
또한 kube-proxy와 같은 userland 프로세스를 통해 네트워크 패킷을 처리합니다. 
그러다보니 오버헤드가 커져서 성능이 떨어지고, 룰이 복잡해질 경우 수 많은 룰을 관리해야하는 문제가 있습니다.</p>

<p><img src="/assets/2024/kans-3th/w8/20241026_kans_w8_2.png" alt="img_1.png" class="image-center" />
<em class="image-caption">eBPF 기반 네트워크 스택</em></p>

<p>eBPF는 커널 내부에서 동작하는 프로그램을 실행할 수 있으며, 이를 통해 네트워크 스택을 확장할 수 있습니다.
특히 샌드박스 방식을 통해 eBPF 프로그램이 커널에 영향을 미치지 않도록 보호할 수 있습니다. 
즉, eBPF 프로그램이 잘못된 동작을 하더라도 커널 패닉등의 발생이 거의 없습니다.</p>

<p>또한 XDP(eXpress Data Path)를 통해 네트워크 패킷을 처리할 수 있으며, 
이 XDP는 네트워크 카드(Offloaded mode), 네트워크 드라이버(Native mode), 커널 스페이스(Generic Mode)에서
동작하여 훨씬 빠르게 패킷을 처리할 수 있습니다.</p>

<p><img src="/assets/2024/kans-3th/w8/20241026_kans_w8_3.png" alt="img.png" class="image-center w-80" />
<em class="image-caption">iptables와 eBPF 성능 비교</em></p>

<ul>
  <li>eBPF 활용처
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_4.png" alt="img.png" class="image-center w-80" />
    <ul>
      <li><strong>Security</strong> (보안) : eBPF는 하드웨어 레벨에서 부터 모든 시스템 콜을 이해하고 처리할 수 있기 때문에 보다 더 세밀하고 강력한 보안 정책을 적용할 수 있습니다.</li>
      <li><strong>Tracing &amp; Profiling</strong> (추적 및 프로파일링) : eBPF는 커널 내부의 모든 이벤트를 추적하고 프로파일링 할 수 있습니다. 기존에 해결하기 어려웠던 성능 문제들도 eBPF를 통해 해결할 수 있습니다.</li>
      <li><strong>Networking</strong> (네트워킹) : eBPF는 커널 스페이스를 떠나지 않고 새로운 프로토콜을 만든다던지, 라우팅을 구현하는 등의 다양한 네트워크 기능을 만들 수 있습니다.</li>
      <li><strong>Observability</strong> (가시성) : 커널내부에서 다양한 소스에서 메트릭을 수집하고, 처리할 수 있고, 일부 데이터만 샘플링하는 것이 아닌 모든 데이터를 수집할 수 있습니다.</li>
    </ul>
  </li>
</ul>

<h3 id="cilium-소개">Cilium 소개</h3>

<ul>
  <li><strong>Cilium</strong>은 기존의 복잡한 네트워크 스택을 <strong>eBPF</strong>를 통해 <strong>간소화</strong>하고, <strong>빠르게 처리</strong>할 수 있도록 하는 CNI 플러그인입니다.</li>
</ul>

<p><img src="/assets/2024/kans-3th/w8/20241026_kans_w8_5.png" alt="img.png" class="image-center w-80" />
<em class="image-caption"><a href="https://isovalent.com/blog/post/migrating-from-metallb-to-cilium/">https://isovalent.com/blog/post/migrating-from-metallb-to-cilium/</a></em></p>

<ul>
  <li>Cilium eBPF는 추가적인 코드 수정이나 설정 변경없이, 리눅스 커널에서 동작하는 Bytecode를 자유롭게 프로그래밍하여 커널에 로딩시켜 동작이 가능합니다. <a href="https://www.youtube.com/watch?v=qsnR-s4XuGo&amp;t=1059s">링크</a></li>
  <li>또한 eBPF는 모든 패킷을 가로채기 위해서 수신 NIC의 ingress TC(<a href="https://netbeez.net/blog/how-to-use-the-linux-traffic-control/">Traffic Control</a>) hooks를 사용할 수 있습니다.
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_6.png" alt="img.png" class="image-center w-60" />
<em class="image-caption">NIC의 TC Hooks에 eBPF 프로그램이 attach 된 예</em></li>
  <li>Cilium은 터널모드(VXLAN, GENEVE), 네이티브 라우팅 모드의 2가지 네트워크 모드를 제공합니다.
    <ul>
      <li><strong>터널모드</strong> : Cilium이 VXLAN(UDP 8472), GENEVE(UDP 6081) 인터페이스를 만들어서 이들을 통해 트래픽을 전달합니다. Encapsulation 모드라고도 합니다.</li>
      <li><strong>네이티브 라우팅 모드</strong> : Cilium가 패킷 전달을 위해 구성을 변경하지 않고, 외부에서 제공되는 패킷 전달 방법(클라우드 또는 BGP 라우팅등)을 사용합니다. Direct Routing 모드라고도 합니다.
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_7.png" alt="img.png" class="image-center w-80" />
<em class="image-caption">Cilium 네트워크 모드 - <a href="https://docs.cilium.io/en/stable/network/concepts/routing/">링크</a></em></li>
    </ul>
  </li>
  <li>2021년 10월 Cilium은 CNCF에 채택되었습니다. <a href="https://cilium.io/blog/2021/10/13/cilium-joins-cncf/">링크</a></li>
  <li>Googke GKE dataplane과 AWS EKS Anywhere에서 기본 CNI로 Cilium을 사용하고 있습니다. <a href="https://isovalent.com/blog/post/2021-09-aws-eks-anywhere-chooses-cilium/">링크</a></li>
  <li>Cilium은 Kube-Proxy를 100% 대체 가능합니다.
    <ul>
      <li>iptables를 거의 사용하지 않고도 동작하며, 이를 통해 성능을 향상시킬 수 있습니다.</li>
      <li>하지만 istio, FHRP, VRRP 등과 같이 iptables 기능을 활용하는 동작들은 이슈가 발생할 수 있으며, 차츰 해결해 나가고 있습니다.</li>
    </ul>
  </li>
</ul>

<h4 id="cilium-아키텍쳐">Cilium 아키텍쳐</h4>

<ul>
  <li>구성요소 - <a href="https://ssup2.github.io/blog-software/docs/theory-analysis/kubernetes-cilium-plugin/">링크</a>
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_8.png" alt="img.png" class="image-center w-80" />
<em class="image-caption">Cilium 아키텍쳐 - <a href="https://github.com/cilium/cilium">출처</a></em>
    <ul>
      <li>Cilium <strong>Agent</strong> : 데몬셋으로 실행, K8S API 설정으로 부터 ‘네트워크 설정, 네트워크 정책, 서비스 부하분산, 모니터링’ 등을 수행하며, eBPF 프로그램을 관리합니다.</li>
      <li>Cilium <strong>Client</strong> (CLI) : Cilium 커멘드툴로 eBPF maps 에 직접 접속하여 상태를 확인할 수 있습니다.</li>
      <li>Cilium <strong>Operator</strong> : K8S 클러스터에 대한 한 번씩 처리해야 하는 작업을 관리합니다.</li>
      <li><strong>Hubble</strong> : 네트워크와 보안 모니터링 플랫폼 역할을 하여, Server, Relay, Client, Graphical UI 로 구성되어 있습니다.</li>
      <li><strong>Data Store</strong> : Cilium Agent 간의 상태를 저장하고 전파하는 데이터 저장소, 2가지 종류 중 선택(K8S CRDs, Key-Value Store)할 수 있습니다.</li>
    </ul>
  </li>
</ul>

<h3 id="cilium-실습">Cilium 실습</h3>

<p>실습을 통해 Cilium CNI에 대해서 알아보겠습니다. 먼저 Cilium을 설치하고, 기본적인 설정을 확인하고, 네트워크 정책을 설정해보겠습니다.</p>

<h4 id="cilium-설치">Cilium 설치</h4>

<h5 id="helm을-통한-설치-및-확인">Helm을 통한 설치 및 확인</h5>

<ul>
  <li>helm 옵션 : <a href="https://docs.cilium.io/en/stable/helm-reference/">https://docs.cilium.io/en/stable/helm-reference/</a></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 모니터링</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> kubectl get node,pod <span class="nt">-A</span> <span class="nt">-owide</span>

<span class="c">#</span>
<span class="nv">$ </span>helm repo add cilium https://helm.cilium.io/
<span class="c"># =&gt; &amp;quot;cilium&amp;quot; has been added to your repositories</span>
<span class="nv">$ </span>helm repo update
<span class="c"># =&gt; ...Successfully got an update from the &amp;quot;cilium&amp;quot; chart repository</span>
<span class="c">#    Update Complete. ⎈Happy Helming!⎈</span>

<span class="c">#</span>
<span class="nv">$ </span>helm <span class="nb">install </span>cilium cilium/cilium <span class="nt">--version</span> 1.16.3 <span class="nt">--namespace</span> kube-system <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">k8sServiceHost</span><span class="o">=</span>192.168.10.10 <span class="nt">--set</span> <span class="nv">k8sServicePort</span><span class="o">=</span>6443 <span class="nt">--set</span> debug.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">rollOutCiliumPods</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> <span class="nv">routingMode</span><span class="o">=</span>native <span class="nt">--set</span> <span class="nv">autoDirectNodeRoutes</span><span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> bpf.masquerade<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> bpf.hostRouting<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> endpointRoutes.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> ipam.mode<span class="o">=</span>kubernetes <span class="nt">--set</span> k8s.requireIPv4PodCIDR<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> <span class="nv">kubeProxyReplacement</span><span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">ipv4NativeRoutingCIDR</span><span class="o">=</span>192.168.0.0/16 <span class="nt">--set</span> <span class="nv">installNoConntrackIptablesRules</span><span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> hubble.ui.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> hubble.relay.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> prometheus.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> operator.prometheus.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> hubble.metrics.enableOpenMetrics<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> hubble.metrics.enabled<span class="o">=</span><span class="s2">"{dns:query;ignoreAAAA,drop,tcp,flow,port-distribution,icmp,httpV2:exemplars=true;labelsContext=source_ip</span><span class="se">\,</span><span class="s2">source_namespace</span><span class="se">\,</span><span class="s2">source_workload</span><span class="se">\,</span><span class="s2">destination_ip</span><span class="se">\,</span><span class="s2">destination_namespace</span><span class="se">\,</span><span class="s2">destination_workload</span><span class="se">\,</span><span class="s2">traffic_direction}"</span> <span class="se">\</span>
  <span class="nt">--set</span> operator.replicas<span class="o">=</span>1
<span class="c"># =&gt; NAME: cilium</span>
<span class="c">#    LAST DEPLOYED: Sat Oct 01 07:23:34 2024</span>
<span class="c">#    NAMESPACE: kube-system</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 1</span>
<span class="c">#    TEST SUITE: None</span>
<span class="c">#    NOTES:</span>
<span class="c">#    You have successfully installed Cilium with Hubble Relay and Hubble UI.</span>
<span class="c">#    </span>
<span class="c">#    Your release version is 1.16.3.</span>
<span class="c">#    </span>
<span class="c">#    For any further help, visit https://docs.cilium.io/en/v1.16/gettinghelp</span>

<span class="c">## 주요 파라미터 설명</span>
<span class="c"># --set debug.enabled=true # cilium 파드에 로그 레벨을 debug 설정</span>
<span class="c"># --set autoDirectNodeRoutes=true # 동일 대역 내의 노드들 끼리는 상대 노드의 podCIDR 대역의 라우팅이 자동으로 설정</span>
<span class="c"># --set endpointRoutes.enabled=true # 호스트에 endpoint(파드)별 개별 라우팅 설정</span>
<span class="c"># --set hubble.relay.enabled=true --set hubble.ui.enabled=true # hubble 활성화</span>
<span class="c"># --set ipam.mode=kubernetes --set k8s.requireIPv4PodCIDR=true # k8s IPAM 활용</span>
<span class="c"># --set kubeProxyReplacement=true # kube-proxy 없이 (최대한) 대처할수 있수 있게</span>
<span class="c"># --set ipv4NativeRoutingCIDR=192.168.0.0/16 # 해당 대역과 통신 시 IP Masq 하지 않음, 보통 사내망 대역을 지정</span>
<span class="c"># --set operator.replicas=1 # cilium-operator 파드 기본 1개</span>
<span class="c"># --set enableIPv4Masquerade=true --set bpf.masquerade=true # 파드를 위한 Masquerade , 추가로 Masquerade 을 BPF 로 처리 &gt;&gt; enableIPv4Masquerade=true 인 상태에서 추가로 bpf.masquerade=true 적용이 가능</span>

<span class="c"># 설정 및 확인</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> addr
<span class="c"># =&gt; ...</span>
<span class="c">#    4: cilium_net@cilium_host: &amp;lt;BROADCAST,MULTICAST,NOARP,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span>
<span class="c">#        link/ether 3a:03:2f:7e:cc:72 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet6 fe80::3803:2fff:fe7e:cc72/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    5: cilium_host@cilium_net: &amp;lt;BROADCAST,MULTICAST,NOARP,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span>
<span class="c">#        link/ether ca:73:d2:a6:00:b4 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet 172.16.0.227/32 scope global cilium_host</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#        inet6 fe80::c873:d2ff:fea6:b4/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>kubectl get node,pod,svc <span class="nt">-A</span> <span class="nt">-owide</span>
<span class="c"># =&gt; NAME          STATUS   ROLES                  AGE     VERSION        INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION       CONTAINER-RUNTIME</span>
<span class="c">#    node/k3s-m    Ready    control-plane,master   3h58m   v1.30.5+k3s1   192.168.10.10    &amp;lt;none&amp;gt;        Ubuntu 22.04.5 LTS   5.15.0-119-generic   containerd://1.7.21-k3s2</span>
<span class="c">#    node/k3s-w1   Ready    &amp;lt;none&amp;gt;                 3h57m   v1.30.5+k3s1   192.168.10.101   &amp;lt;none&amp;gt;        Ubuntu 22.04.5 LTS   5.15.0-119-generic   containerd://1.7.21-k3s2</span>
<span class="c">#    node/k3s-w2   Ready    &amp;lt;none&amp;gt;                 3h55m   v1.30.5+k3s1   192.168.10.102   &amp;lt;none&amp;gt;        Ubuntu 22.04.5 LTS   5.15.0-119-generic   containerd://1.7.21-k3s2</span>
<span class="c">#    </span>
<span class="c">#    NAMESPACE     NAME                                          READY   STATUS    RESTARTS         AGE     IP               NODE     NOMINATED NODE   READINESS GATES</span>
<span class="c">#    kube-system   pod/cilium-envoy-9q7c6                        1/1     Running   0                5m19s   192.168.10.102   k3s-w2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system   pod/cilium-ljv9t                              1/1     Running   0                5m19s   192.168.10.101   k3s-w1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system   pod/cilium-operator-76bb588dbc-gxrqx          1/1     Running   0                5m19s   192.168.10.101   k3s-w1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system   pod/cilium-q96l4                              1/1     Running   0                5m19s   192.168.10.102   k3s-w2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system   pod/coredns-7b98449c4-x5756                   1/1     Running   0                2m59s   172.16.1.21      k3s-w1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system   pod/hubble-relay-88f7f89d4-fcq2s              1/1     Running   0                5m19s   172.16.1.99      k3s-w1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system   pod/hubble-ui-59bb4cb67b-r48tz                2/2     Running   0                5m19s   172.16.0.238     k3s-m    &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system   pod/local-path-provisioner-6795b5f9d8-84m96   1/1     Running   11 (5m28s ago)   3h58m   172.16.2.184     k3s-w2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system   pod/metrics-server-cdcc87586-g5m2d            1/1     Running   11 (5m10s ago)   3h58m   172.16.2.223     k3s-w2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    ...</span>
<span class="c">#    </span>
<span class="c">#    NAMESPACE     NAME                     TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                  AGE     SELECTOR</span>
<span class="c">#    default       service/kubernetes       ClusterIP   10.10.200.1     &amp;lt;none&amp;gt;        443/TCP                  3h58m   &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system   service/cilium-envoy     ClusterIP   None            &amp;lt;none&amp;gt;        9964/TCP                 5m19s   k8s-app=cilium-envoy</span>
<span class="c">#    kube-system   service/hubble-metrics   ClusterIP   None            &amp;lt;none&amp;gt;        9965/TCP                 5m19s   k8s-app=cilium</span>
<span class="c">#    kube-system   service/hubble-peer      ClusterIP   10.10.200.203   &amp;lt;none&amp;gt;        443/TCP                  5m19s   k8s-app=cilium</span>
<span class="c">#    kube-system   service/hubble-relay     ClusterIP   10.10.200.175   &amp;lt;none&amp;gt;        80/TCP                   5m19s   k8s-app=hubble-relay</span>
<span class="c">#    kube-system   service/hubble-ui        ClusterIP   10.10.200.125   &amp;lt;none&amp;gt;        80/TCP                   5m19s   k8s-app=hubble-ui</span>
<span class="c">#    kube-system   service/kube-dns         ClusterIP   10.10.200.10    &amp;lt;none&amp;gt;        53/UDP,53/TCP,9153/TCP   3h58m   k8s-app=kube-dns</span>
<span class="c">#    kube-system   service/metrics-server   ClusterIP   10.10.200.180   &amp;lt;none&amp;gt;        443/TCP                  3h58m   k8s-app=metrics-server</span>

<span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> filter <span class="nt">-S</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> raw <span class="nt">-S</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> mangle <span class="nt">-S</span>
<span class="nv">$ </span>conntrack <span class="nt">-L</span>

<span class="nv">$ </span>kubectl get crd | <span class="nb">grep </span>cilium
<span class="c"># =&gt; ciliumcidrgroups.cilium.io                   2024-10-01T11:10:57Z</span>
<span class="c">#    ciliumclusterwidenetworkpolicies.cilium.io   2024-10-01T11:10:58Z</span>
<span class="c">#    ciliumendpoints.cilium.io                    2024-10-01T11:10:57Z</span>
<span class="c">#    ciliumexternalworkloads.cilium.io            2024-10-01T11:10:57Z</span>
<span class="c">#    ciliumidentities.cilium.io                   2024-10-01T11:10:58Z</span>
<span class="c">#    ciliuml2announcementpolicies.cilium.io       2024-10-01T11:10:57Z</span>
<span class="c">#    ciliumloadbalancerippools.cilium.io          2024-10-01T11:10:57Z</span>
<span class="c">#    ciliumnetworkpolicies.cilium.io              2024-10-01T11:10:58Z</span>
<span class="c">#    ciliumnodeconfigs.cilium.io                  2024-10-01T11:10:57Z</span>
<span class="c">#    ciliumnodes.cilium.io                        2024-10-01T11:10:57Z</span>
<span class="c">#    ciliumpodippools.cilium.io                   2024-10-01T11:10:57Z</span>
<span class="nv">$ </span>kubectl get ciliumnodes <span class="c"># cilium_host 인터페이스의 IP 확인 : CILIUMINTERNALIP</span>
<span class="c"># =&gt; NAME     CILIUMINTERNALIP   INTERNALIP       AGE</span>
<span class="c">#    k3s-m    172.16.0.227       192.168.10.10    21m</span>
<span class="c">#    k3s-w1   172.16.1.82        192.168.10.101   21m</span>
<span class="c">#    k3s-w2   172.16.2.25        192.168.10.102   21m</span>
<span class="nv">$ </span>kubectl get ciliumendpoints <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE     NAME                                      SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    kube-system   coredns-7b98449c4-x5756                   11970               ready            172.16.1.21</span>
<span class="c">#    kube-system   hubble-relay-88f7f89d4-fcq2s              4124                ready            172.16.1.99</span>
<span class="c">#    kube-system   hubble-ui-59bb4cb67b-r48tz                37523               ready            172.16.0.238</span>
<span class="c">#    kube-system   local-path-provisioner-6795b5f9d8-84m96   11088               ready            172.16.2.184</span>
<span class="c">#    kube-system   metrics-server-cdcc87586-g5m2d            27624               ready            172.16.2.223</span>

<span class="nv">$ </span>kubectl get cm <span class="nt">-n</span> kube-system cilium-config <span class="nt">-o</span> json | jq

<span class="nv">$ </span>kubetail <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium <span class="nt">--since</span> 1h
<span class="nv">$ </span>kubetail <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium-envoy <span class="nt">--since</span> 1h

<span class="c"># Native XDP 지원 NIC 확인 : https://docs.cilium.io/en/stable/bpf/progtypes/#xdp-drivers</span>
<span class="nv">$ </span>ethtool <span class="nt">-i</span> enp0s8
<span class="c"># =&gt; driver: virtio_net   # &gt;= XDP 4.10 부터 지원되는듯 합니다.</span>
<span class="c">#    version: 1.0.0</span>
<span class="c">#    ...</span>

<span class="c"># https://docs.cilium.io/en/stable/operations/performance/tuning/#bypass-iptables-connection-tracking</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> kubectl get pod <span class="nt">-A</span> <span class="c"># 모니터링</span>
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--namespace</span> kube-system <span class="nt">--reuse-values</span> <span class="nt">--set</span> <span class="nv">installNoConntrackIptablesRules</span><span class="o">=</span><span class="nb">true</span>
<span class="c"># =&gt; Release &amp;quot;cilium&amp;quot; has been upgraded. Happy Helming!</span>
<span class="c">#    NAME: cilium</span>
<span class="c">#    LAST DEPLOYED: Sat Oct 01 11:42:10 2024</span>
<span class="c">#    NAMESPACE: kube-system</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 2</span>
<span class="c">#    TEST SUITE: None</span>
<span class="c">#    NOTES:</span>
<span class="c">#    You have successfully installed Cilium with Hubble Relay and Hubble UI.</span>
<span class="c">#    </span>
<span class="c">#    Your release version is 1.16.3.</span>
<span class="c">#    </span>
<span class="c">#    For any further help, visit https://docs.cilium.io/en/v1.16/gettinghelp</span>

<span class="c"># 확인: 기존 raw 에 아래 rule 추가 확인</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> raw <span class="nt">-S</span> | <span class="nb">grep </span>notrack
<span class="c"># =&gt; -A CILIUM_OUTPUT_raw -d 192.168.0.0/16 -m comment --comment "cilium: NOTRACK for pod traffic" -j CT --notrack</span>
<span class="c">#    -A CILIUM_OUTPUT_raw -s 192.168.0.0/16 -m comment --comment "cilium: NOTRACK for pod traffic" -j CT --notrack</span>
<span class="c">#    ...</span>

<span class="nv">$ </span>conntrack <span class="nt">-F</span>
<span class="nv">$ </span>conntrack <span class="nt">-L</span>
<span class="nv">$ </span>conntrack <span class="nt">-L</span> |grep <span class="nt">-v</span> 2379
</code></pre></div></div>

<h5 id="cilium-cli를-통한-확인">Cilium CLI를 통한 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># cilium CLI 설치</span>
<span class="nv">$ CILIUM_CLI_VERSION</span><span class="o">=</span><span class="si">$(</span>curl <span class="nt">-s</span> https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt<span class="si">)</span>
<span class="nv">$ CLI_ARCH</span><span class="o">=</span>amd64
<span class="nv">$ </span><span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span><span class="si">)</span><span class="s2">"</span> <span class="o">=</span> <span class="s2">"aarch64"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then </span><span class="nv">CLI_ARCH</span><span class="o">=</span>arm64<span class="p">;</span> <span class="k">fi</span>
<span class="nv">$ </span>curl <span class="nt">-L</span> <span class="nt">--fail</span> <span class="nt">--remote-name-all</span> https://github.com/cilium/cilium-cli/releases/download/<span class="k">${</span><span class="nv">CILIUM_CLI_VERSION</span><span class="k">}</span>/cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz<span class="o">{</span>,.sha256sum<span class="o">}</span>
<span class="nv">$ </span><span class="nb">sha256sum</span> <span class="nt">--check</span> cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz.sha256sum
<span class="nv">$ </span><span class="nb">sudo tar </span>xzvfC cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz /usr/local/bin
<span class="nv">$ </span><span class="nb">rm </span>cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz<span class="o">{</span>,.sha256sum<span class="o">}</span>

<span class="c"># 테스트</span>
<span class="nv">$ </span>cilium status <span class="nt">--wait</span>
<span class="c"># =&gt;     /¯¯\</span>
<span class="c">#     /¯¯\__/¯¯\    Cilium:             OK</span>
<span class="c">#     \__/¯¯\__/    Operator:           OK</span>
<span class="c">#     /¯¯\__/¯¯\    Envoy DaemonSet:    OK</span>
<span class="c">#     \__/¯¯\__/    Hubble Relay:       OK</span>
<span class="c">#        \__/       ClusterMesh:        disabled</span>
<span class="c">#    </span>
<span class="c">#    DaemonSet              cilium             Desired: 3, Ready: 3/3, Available: 3/3</span>
<span class="c">#    DaemonSet              cilium-envoy       Desired: 3, Ready: 3/3, Available: 3/3</span>
<span class="c">#    Deployment             cilium-operator    Desired: 1, Ready: 1/1, Available: 1/1</span>
<span class="c">#    Deployment             hubble-relay       Desired: 1, Ready: 1/1, Available: 1/1</span>
<span class="c">#    Deployment             hubble-ui          Desired: 1, Ready: 1/1, Available: 1/1</span>
<span class="c">#    Containers:            cilium             Running: 3</span>
<span class="c">#                           cilium-envoy       Running: 3</span>
<span class="c">#                           cilium-operator    Running: 1</span>
<span class="c">#                           hubble-relay       Running: 1</span>
<span class="c">#                           hubble-ui          Running: 1</span>
<span class="c">#    Cluster Pods:          5/5 managed by Cilium</span>
<span class="c">#    Helm chart version:    1.16.3</span>
<span class="c">#    Image versions         cilium             quay.io/cilium/cilium:v1.16.3@sha256:62d2a09bbef840a46099ac4c69421c90f84f28d018d479749049011329aa7f28: 3</span>
<span class="c">#                           cilium-envoy       quay.io/cilium/cilium-envoy:v1.29.9-1728346947-0d05e48bfbb8c4737ec40d5781d970a550ed2bbd@sha256:42614a44e508f70d03a04470df5f61e3cffd22462471a0be0544cf116f2c50ba: 3</span>
<span class="c">#                           cilium-operator    quay.io/cilium/operator-generic:v1.16.3@sha256:6e2925ef47a1c76e183c48f95d4ce0d34a1e5e848252f910476c3e11ce1ec94b: 1</span>
<span class="c">#                           hubble-relay       quay.io/cilium/hubble-relay:v1.16.3@sha256:feb60efd767e0e7863a94689f4a8db56a0acc7c1d2b307dee66422e3dc25a089: 1</span>
<span class="c">#                           hubble-ui          quay.io/cilium/hubble-ui-backend:v0.13.1@sha256:0e0eed917653441fded4e7cdb096b7be6a3bddded5a2dd10812a27b1fc6ed95b: 1</span>
<span class="c">#                           hubble-ui          quay.io/cilium/hubble-ui:v0.13.1@sha256:e2e9313eb7caf64b0061d9da0efbdad59c6c461f6ca1752768942bfeda0796c6: 1</span>

<span class="nv">$ </span>cilium connectivity <span class="nb">test</span>

<span class="nv">$ </span>cilium config view
<span class="c"># =&gt; agent-not-ready-taint-key                         node.cilium.io/agent-not-ready</span>
<span class="c">#    arping-refresh-period                             30s</span>
<span class="c">#    auto-direct-node-routes                           true</span>
<span class="c">#    bpf-events-drop-enabled                           true</span>
<span class="c">#    bpf-events-policy-verdict-enabled                 true</span>
<span class="c">#    bpf-events-trace-enabled                          true</span>
<span class="c">#    bpf-lb-acceleration                               disabled</span>
<span class="c">#    bpf-lb-external-clusterip                         false</span>
<span class="c">#    bpf-lb-map-max                                    65536</span>
<span class="c">#    bpf-lb-sock                                       false</span>
<span class="c">#    bpf-lb-sock-terminate-pod-connections             false</span>
<span class="c">#    bpf-map-dynamic-size-ratio                        0.0025</span>
<span class="c">#    bpf-policy-map-max                                16384</span>
<span class="c">#    bpf-root                                          /sys/fs/bpf</span>
<span class="c">#    ...</span>
<span class="c">#    ipv4-native-routing-cidr                          192.168.0.0/16</span>
<span class="c">#    ...</span>
<span class="c">#    kube-proxy-replacement                            true</span>
<span class="c">#    kube-proxy-replacement-healthz-bind-address</span>
<span class="c">#    max-connected-clusters                            255</span>
<span class="c">#    mesh-auth-enabled                                 true</span>
<span class="c">#    ...</span>

<span class="c"># cilium 데몬셋 파드 내에서 cilium 명령어로 상태 확인</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD0</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k3s-m  <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c0</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD0</span><span class="s2"> -n kube-system -c cilium-agent -- cilium"</span>
<span class="nv">$ </span>c0 status <span class="nt">--verbose</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    KubeProxyReplacement:   True   [enp0s3   10.0.2.15 fe80::6d:daff:feb3:d4d3, enp0s8   192.168.10.10 fe80::27ff:fe8a:de00 (Direct Routing)]</span>
<span class="c">#    ...</span>
<span class="c">#    IPAM:                   IPv4: 4/254 allocated from 172.16.0.0/24, </span>
<span class="c">#    Allocated addresses:</span>
<span class="c">#      172.16.0.223 (kube-system/hubble-ui-59bb4cb67b-r48tz)</span>
<span class="c">#      172.16.0.227 (router)</span>
<span class="c">#      172.16.0.26 (health)</span>
<span class="c">#      172.16.0.44 (cilium-test-1/client3-67f959dd9b-ptl65)</span>
<span class="c">#    ...</span>
<span class="c">#    Routing:                Network: Native   Host: BPF</span>
<span class="c">#    ...</span>
<span class="c">#    Device Mode:            veth</span>
<span class="c">#    Masquerading:           BPF   [ens5]   192.168.0.0/16 [IPv4: Enabled, IPv6: Disabled]</span>
<span class="c">#    ...  </span>
<span class="c">#    Proxy Status:            OK, ip 172.16.0.227, 0 redirects active on ports 10000-20000, Envoy: external</span>
<span class="c">#    ...</span>
<span class="c">#    KubeProxyReplacement Details:</span>
<span class="c">#      Status:                 True</span>
<span class="c">#      Socket LB:              Enabled</span>
<span class="c">#      Socket LB Tracing:      Enabled</span>
<span class="c">#      Socket LB Coverage:     Full</span>
<span class="c">#      Devices:                enp0s3   10.0.2.15 fe80::6d:daff:feb3:d4d3, enp0s8   192.168.10.10 fe80::27ff:fe8a:de00 (Direct Routing)</span>
<span class="c">#      Mode:                   SNAT</span>
<span class="c">#      Backend Selection:      Random</span>
<span class="c">#      Session Affinity:       Enabled</span>
<span class="c">#      Graceful Termination:   Enabled</span>
<span class="c">#      NAT46/64 Support:       Disabled</span>
<span class="c">#      XDP Acceleration:       Disabled</span>
<span class="c">#      Services:</span>
<span class="c">#      - ClusterIP:      Enabled</span>
<span class="c">#      - NodePort:       Enabled (Range: 30000-32767) </span>
<span class="c">#      - LoadBalancer:   Enabled </span>
<span class="c">#      - externalIPs:    Enabled </span>
<span class="c">#      - HostPort:       Enabled</span>
<span class="c">#    BPF Maps:   dynamic sizing: on (ratio: 0.002500)</span>
<span class="c">#    ...</span>

<span class="c"># Native Routing 확인 : # 192.168.0.0/16 대역은 IP Masq 없이 라우팅</span>
<span class="nv">$ </span>c0 status | <span class="nb">grep </span>KubeProxyReplacement
<span class="c"># =&gt; KubeProxyReplacement:    True   [enp0s3   10.0.2.15 fe80::6d:daff:feb3:d4d3, enp0s8   192.168.10.10 fe80::27ff:fe8a:de00 (Direct Routing)]</span>

<span class="c"># enableIPv4Masquerade=true(기본값) , bpf.masquerade=true 확인</span>
<span class="nv">$ </span>cilium config view | egrep <span class="s1">'enable-ipv4-masquerade|enable-bpf-masquerade'</span>
<span class="c"># =&gt; enable-bpf-masquerade                             true</span>
<span class="c">#    enable-ipv4-masquerade                            true</span>

<span class="nv">$ </span>c0 status <span class="nt">--verbose</span> | <span class="nb">grep </span>Masquerading
<span class="c"># =&gt; Masquerading:           BPF   [enp0s3, enp0s8]   192.168.0.0/16 [IPv4: Enabled, IPv6: Disabled]</span>

<span class="c"># Configure the eBPF-based ip-masq-agent</span>
<span class="c"># https://docs.cilium.io/en/stable/network/concepts/masquerading/</span>
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--namespace</span> kube-system <span class="nt">--reuse-values</span> <span class="nt">--set</span> ipMasqAgent.enabled<span class="o">=</span><span class="nb">true</span>
<span class="c"># =&gt; Release &amp;quot;cilium&amp;quot; has been upgraded. Happy Helming!</span>
<span class="c">#    ...</span>

<span class="c">#</span>
<span class="nv">$ </span>cilium config view | <span class="nb">grep</span> <span class="nt">-i</span> masq
<span class="c"># =&gt; enable-bpf-masquerade                             true</span>
<span class="c">#    enable-ip-masq-agent                              true</span>
<span class="c">#    ...</span>

<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD0</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k3s-m  <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c0</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD0</span><span class="s2"> -n kube-system -c cilium-agent -- cilium"</span>
<span class="nv">$ </span>c0 status <span class="nt">--verbose</span> | <span class="nb">grep </span>Masquerading
<span class="c"># =&gt; Masquerading:           BPF (ip-masq-agent)   [enp0s3, enp0s8]   192.168.0.0/16 [IPv4: Enabled, IPv6: Disabled]</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 BPF가 BPF (ip-masq-agent)로 변경되었습니다.&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   ip-masq-agent는 k8s 클러스터 내부에서 IP 마스커레이딩을 관리하는 컴포넌트로,&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   마스커레이딩 여부를 결정하여 네트워크 자원 사용을 최적화 해줍니다.&lt;/span&gt;</span>

<span class="nv">$ </span>kubectl get cm <span class="nt">-n</span> kube-system cilium-config <span class="nt">-o</span> yaml  | <span class="nb">grep </span>ip-masq
<span class="c"># =&gt;   enable-ip-masq-agent: &amp;quot;true&amp;quot;</span>
</code></pre></div></div>

<h4 id="cilium-기본정보-확인">Cilium 기본정보 확인</h4>

<h5 id="변수--단축키">변수 &amp; 단축키</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># cilium 파드 이름</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD0</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k3s-m  <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD1</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k3s-w1 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD2</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k3s-w2 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>

<span class="c"># 단축키(alias) 지정</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c0</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD0</span><span class="s2"> -n kube-system -c cilium-agent -- cilium"</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c1</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD1</span><span class="s2"> -n kube-system -c cilium-agent -- cilium"</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c2</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD2</span><span class="s2"> -n kube-system -c cilium-agent -- cilium"</span>

<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c0bpf</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD0</span><span class="s2"> -n kube-system -c cilium-agent -- bpftool"</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c1bpf</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD1</span><span class="s2"> -n kube-system -c cilium-agent -- bpftool"</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c2bpf</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD2</span><span class="s2"> -n kube-system -c cilium-agent -- bpftool"</span>

<span class="c"># Hubble UI 웹 접속</span>
<span class="nv">$ </span>kubectl patch <span class="nt">-n</span> kube-system svc hubble-ui <span class="nt">-p</span> <span class="s1">'{"spec": {"type": "NodePort"}}'</span>
<span class="c"># =&gt; service/hubble-ui patched</span>
<span class="nv">$ HubbleUiNodePort</span><span class="o">=</span><span class="si">$(</span>kubectl get svc <span class="nt">-n</span> kube-system hubble-ui <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.spec.ports[0].nodePort<span class="o">}</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"Hubble UI URL = http://</span><span class="si">$(</span>curl <span class="nt">-s</span> ipinfo.io/ip<span class="si">)</span><span class="s2">:</span><span class="nv">$HubbleUiNodePort</span><span class="s2">"</span>
<span class="c"># =&gt; Hubble UI URL = http://54.180.146.116:30732</span>
</code></pre></div></div>

<h5 id="자주-쓰는-cilium-cli-명령어">자주 쓰는 Cilium CLI 명령어</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># cilium 파드 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium <span class="nt">-owide</span>
<span class="c"># =&gt; NAME           READY   STATUS    RESTARTS   AGE     IP               NODE     NOMINATED NODE   READINESS GATES</span>
<span class="c">#    cilium-5gx8w   1/1     Running   0          9m12s   192.168.10.102   k3s-w2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    cilium-92k6s   1/1     Running   0          8m53s   192.168.10.101   k3s-w1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    cilium-zv22g   1/1     Running   0          9m12s   192.168.10.10    k3s-m    &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>

<span class="c"># cilium 파드 재시작</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system rollout restart ds/cilium
<span class="c"># =&gt; daemonset.apps/cilium restarted</span>
<span class="c"># 혹은</span>
<span class="nv">$ </span>kubectl delete pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium
<span class="c"># =&gt; pod &amp;quot;cilium-5p4q4&amp;quot; deleted</span>
<span class="c">#    pod &amp;quot;cilium-bc7jz&amp;quot; deleted</span>
<span class="c">#    pod &amp;quot;cilium-zqs9l&amp;quot; deleted</span>

<span class="c"># cilium 설정 정보 확인</span>
<span class="nv">$ </span>cilium config view

<span class="c"># cilium 파드의 cilium 상태 확인</span>
<span class="nv">$ </span>c0 status <span class="nt">--verbose</span>

<span class="c"># cilium 엔드포인트 확인</span>
<span class="nv">$ </span>kubectl get ciliumendpoints <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE       NAME                                      SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    kube-system     coredns-7b98449c4-x5756                   11970               ready            172.16.1.21</span>
<span class="c">#    kube-system     hubble-relay-88f7f89d4-fcq2s              4124                ready            172.16.1.99</span>
<span class="c">#    kube-system     hubble-ui-59bb4cb67b-r48tz                37523               ready            172.16.0.223</span>
<span class="c">#    kube-system     local-path-provisioner-6795b5f9d8-84m96   11088               ready            172.16.2.184</span>
<span class="c">#    kube-system     metrics-server-cdcc87586-g5m2d            27624               ready            172.16.2.223</span>
<span class="nv">$ </span>c0 endpoint list
<span class="c"># =&gt; ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])                                                  IPv6   IPv4           STATUS</span>
<span class="c">#               ENFORCEMENT        ENFORCEMENT</span>
<span class="c">#    640        Disabled           Disabled          37523      k8s:app.kubernetes.io/name=hubble-ui                                                172.16.0.223   ready</span>
<span class="c">#                                                               k8s:app.kubernetes.io/part-of=cilium</span>
<span class="c">#                                                               k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=kube-system</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.cluster=default</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.serviceaccount=hubble-ui</span>
<span class="c">#                                                               k8s:io.kubernetes.pod.namespace=kube-system</span>
<span class="c">#                                                               k8s:k8s-app=hubble-ui</span>
<span class="c">#    1196       Disabled           Disabled          1          k8s:node-role.kubernetes.io/control-plane=true                                                     ready</span>
<span class="c">#                                                               k8s:node-role.kubernetes.io/master=true</span>
<span class="c">#                                                               k8s:node.kubernetes.io/instance-type=k3s</span>
<span class="c">#                                                               reserved:host</span>
<span class="c">#    1598       Disabled           Disabled          4          reserved:health                                                                     172.16.0.26    ready</span>
<span class="nv">$ </span>c0 bpf endpoint list
<span class="c"># =&gt; IP ADDRESS        LOCAL ENDPOINT INFO</span>
<span class="c">#    172.16.0.26:0     id=1598  sec_id=4     flags=0x0000 ifindex=17  mac=CE:24:50:27:35:B9 nodemac=FE:57:C1:AD:A6:28</span>
<span class="c">#    172.16.0.223:0    id=640   sec_id=37523 flags=0x0000 ifindex=9   mac=AE:B8:81:A6:B1:28 nodemac=C2:21:B8:92:DA:FD</span>
<span class="c">#    172.16.0.227:0    (localhost)</span>
<span class="c">#    192.168.10.10:0   (localhost)</span>
<span class="c">#    10.0.2.15:0       (localhost)</span>
<span class="nv">$ </span>c0 map get cilium_lxc
<span class="c"># =&gt; Key              Value                                                                                            State   Error</span>
<span class="c">#    172.16.0.223:0   id=640   sec_id=37523 flags=0x0000 ifindex=9   mac=AE:B8:81:A6:B1:28 nodemac=C2:21:B8:92:DA:FD   sync</span>
<span class="c">#    172.16.0.26:0    id=1598  sec_id=4     flags=0x0000 ifindex=17  mac=CE:24:50:27:35:B9 nodemac=FE:57:C1:AD:A6:28   sync</span>
<span class="nv">$ </span>c0 ip list

<span class="c"># Manage the IPCache mappings for IP/CIDR &lt;-&gt; Identity</span>
<span class="nv">$ </span>c0 bpf ipcache list

<span class="c"># Service/NAT List 확인</span>
<span class="nv">$ </span>c0 service list
<span class="c"># =&gt; ID   Frontend              Service Type   Backend</span>
<span class="c">#    1    10.10.200.1:443       ClusterIP      1 =&amp;gt; 192.168.10.10:6443 (active)</span>
<span class="c">#    ...</span>
<span class="c">#    6    10.10.200.10:9153     ClusterIP      1 =&amp;gt; 172.16.1.21:9153 (active)</span>
<span class="c">#    7    10.10.200.180:443     ClusterIP      1 =&amp;gt; 172.16.2.223:10250 (active)</span>
<span class="c">#    16   0.0.0.0:30732         NodePort       1 =&amp;gt; 172.16.0.223:8081 (active)</span>
<span class="c">#    17   10.0.2.15:30732       NodePort       1 =&amp;gt; 172.16.0.223:8081 (active)</span>
<span class="c">#    18   192.168.10.10:30732   NodePort       1 =&amp;gt; 172.16.0.223:8081 (active)</span>
<span class="nv">$ </span>c0 bpf lb list
<span class="c"># =&gt; SERVICE ADDRESS           BACKEND ADDRESS (REVNAT_ID) (SLOT)</span>
<span class="c">#    10.10.200.1:443 (0)       0.0.0.0:0 (1) (0) [ClusterIP, non-routable]</span>
<span class="c">#    ...</span>
<span class="c">#    10.10.200.10:9153 (0)     0.0.0.0:0 (6) (0) [ClusterIP, non-routable]</span>
<span class="c">#    10.10.200.180:443 (1)     172.16.2.223:10250 (7) (1)</span>
<span class="c">#    0.0.0.0:30732 (0)         0.0.0.0:0 (16) (0) [NodePort, non-routable]</span>
<span class="c">#    192.168.10.10:30732 (0)   0.0.0.0:0 (18) (0) [NodePort]</span>
<span class="c">#    10.0.2.15:30732 (0)       0.0.0.0:0 (17) (0) [NodePort]</span>
<span class="nv">$ </span>c0 bpf lb list <span class="nt">--revnat</span>
<span class="c"># =&gt; ID   BACKEND ADDRESS (REVNAT_ID) (SLOT)</span>
<span class="c">#    7    10.10.200.180:443</span>
<span class="c">#    6    10.10.200.10:9153</span>
<span class="c">#    ...</span>
<span class="c">#    1    10.10.200.1:443</span>
<span class="c">#    17   10.0.2.15:30732</span>
<span class="c">#    16   0.0.0.0:30732</span>
<span class="c">#    18   192.168.10.10:30732</span>
<span class="nv">$ </span>c0 bpf nat list
<span class="c"># =&gt; TCP OUT 192.168.10.10:34576 -&amp;gt; 192.168.10.101:4240 XLATE_SRC 192.168.10.10:34576 Created=409sec ago NeedsCT=1</span>
<span class="c">#    TCP IN 192.168.10.101:4240 -&amp;gt; 192.168.10.10:34576 XLATE_DST 192.168.10.10:34576 Created=409sec ago NeedsCT=1</span>
<span class="c">#    ICMP OUT 192.168.10.10:35656 -&amp;gt; 172.16.1.224:0 XLATE_SRC 192.168.10.10:35656 Created=169sec ago NeedsCT=1</span>
<span class="c">#    ICMP OUT 192.168.10.10:35656 -&amp;gt; 192.168.10.102:0 XLATE_SRC 192.168.10.10:35656 Created=169sec ago NeedsCT=1</span>
<span class="c">#    ...</span>

<span class="c"># List all open BPF maps</span>
<span class="nv">$ </span>c0 map list
<span class="c"># =&gt; Name                       Num entries   Num errors   Cache enabled</span>
<span class="c">#    cilium_lb4_backends_v3     2             0            true</span>
<span class="c">#    cilium_lb4_source_range    0             0            true</span>
<span class="c">#    cilium_policy_01196        2             0            true</span>
<span class="c">#    cilium_policy_01598        3             0            true</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>c0 map list <span class="nt">--verbose</span>

<span class="c"># List contents of a policy BPF map : Dump all policy maps</span>
<span class="nv">$ </span>c0 bpf policy get <span class="nt">--all</span>
<span class="nv">$ </span>c0 bpf policy get <span class="nt">--all</span> <span class="nt">-n</span>

<span class="c"># cilium monitor</span>
<span class="nv">$ </span>c0 monitor <span class="nt">-v</span>
<span class="c"># =&gt; Listening for events on 4 CPUs with 64x4096 of shared memory</span>
<span class="c">#    Press Ctrl-C to quit</span>
<span class="c">#    time=&amp;quot;2024-10-01T12:11:28Z&amp;quot; level=info msg=&amp;quot;Initializing dissection cache...&amp;quot; subsys=monitor</span>
<span class="c">#    -&amp;gt; network flow 0x206747a1 , identity health-&amp;gt;remote-node state reply ifindex enp0s8 orig-ip 0.0.0.0: 172.16.0.26:4240 -&amp;gt; 192.168.10.102:39142 tcp ACK</span>
<span class="c">#    -&amp;gt; endpoint 1598 flow 0x0 , identity remote-node-&amp;gt;health state established ifindex lxc_health orig-ip 192.168.10.102: 192.168.10.102:39142 -&amp;gt; 172.16.0.26:4240 tcp ACK</span>
<span class="c">#    -&amp;gt; endpoint 640 flow 0x665dd157 , identity host-&amp;gt;37523 state new ifindex lxcdd00fea91485 orig-ip 10.0.2.15: 10.0.2.15:37040 -&amp;gt; 172.16.0.223:8081 tcp SYN</span>
<span class="c">#    -&amp;gt; stack flow 0xf0f2648f , identity 37523-&amp;gt;host state reply ifindex 0 orig-ip 0.0.0.0: 172.16.0.223:8081 -&amp;gt; 10.0.2.15:37040 tcp SYN, ACK</span>
<span class="c">#    -&amp;gt; endpoint 640 flow 0x665dd157 , identity host-&amp;gt;37523 state established ifindex lxcdd00fea91485 orig-ip 10.0.2.15: 10.0.2.15:37040 -&amp;gt; 172.16.0.223:8081 tcp ACK</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 cilium monitor는 자체적으로 마치 tcpdump처럼 패킷의 이동을 모니터링 할 수 있습니다.&lt;/span&gt;</span>
<span class="nv">$ </span>c0 monitor <span class="nt">-v</span> <span class="nt">--type</span> l7   <span class="c"># Layer 7 (Application layer) 만을 모니터링할 수도 있습니다.</span>
<span class="c"># =&gt; CPU 01: [pre-xlate-rev] cgroup_id: 5161 sock_cookie: 14187, dst [10.0.2.15]:43070 tcp</span>
<span class="c">#    CPU 01: [pre-xlate-rev] cgroup_id: 2800 sock_cookie: 14188, dst [172.16.0.223]:8081 tcp</span>
<span class="c">#    CPU 01: [pre-xlate-rev] cgroup_id: 5161 sock_cookie: 14189, dst [10.0.2.15]:43080 tcp</span>
<span class="c">#    CPU 01: [pre-xlate-rev] cgroup_id: 2800 sock_cookie: 10103, dst [172.16.0.223]:8081 tcp</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<h5 id="네트워크-기본-정보-확인--k3s-w1w2-에-ssh-접속-후-ip--c-linkroute-정보-확인">네트워크 기본 정보 확인 : k3s-w1/w2 에 SSH 접속 후 ip -c link/route 정보 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 네트워크 인터페이스 정보 확인</span>
<span class="nv">$ </span>ip <span class="nt">-br</span> <span class="nt">-c</span> <span class="nb">link</span>
<span class="c"># =&gt; lo               UNKNOWN        00:00:00:00:00:00 &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt;</span>
<span class="c">#    enp0s3           UP             02:6d:da:b3:d4:d3 &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt;</span>
<span class="c">#    enp0s8           UP             08:00:27:35:1b:07 &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt;</span>
<span class="c">#    cilium_net@cilium_host UP             16:9d:bb:67:fc:a0 &amp;lt;BROADCAST,MULTICAST,NOARP,UP,LOWER_UP&amp;gt;</span>
<span class="c">#    cilium_host@cilium_net UP             7e:ea:43:69:1e:4b &amp;lt;BROADCAST,MULTICAST,NOARP,UP,LOWER_UP&amp;gt;</span>
<span class="c">#    lxcb0b60514c056@if10 UP             be:61:78:59:9a:b9 &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt;</span>
<span class="c">#    lxcb6d4cfe53c6a@if12 UP             b6:62:74:02:2f:32 &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt;</span>
<span class="c">#    lxc_health@if18  UP             aa:7e:99:a8:fd:c3 &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt;</span>
<span class="nv">$ </span>ip <span class="nt">-br</span> <span class="nt">-c</span> addr
<span class="c"># =&gt; lo               UNKNOWN        127.0.0.1/8 ::1/128</span>
<span class="c">#    enp0s3           UP             10.0.2.15/24 metric 100 fe80::6d:daff:feb3:d4d3/64</span>
<span class="c">#    enp0s8           UP             192.168.10.101/24 fe80::a00:27ff:fe35:1b07/64</span>
<span class="c">#    cilium_net@cilium_host UP             fe80::149d:bbff:fe67:fca0/64</span>
<span class="c">#    cilium_host@cilium_net UP             172.16.1.82/32 fe80::7cea:43ff:fe69:1e4b/64</span>
<span class="c">#    lxcb0b60514c056@if10 UP             fe80::bc61:78ff:fe59:9ab9/64</span>
<span class="c">#    lxcb6d4cfe53c6a@if12 UP             fe80::b462:74ff:fe02:2f32/64</span>
<span class="c">#    lxc_health@if18  UP             fe80::a87e:99ff:fea8:fdc3/64</span>

<span class="nt">--------------------------------------------</span>
<span class="c"># cilium_net 과 cilium_host 는 veth peer 관계이며, cilium_host 는 파드의 GW IP 주소로 지정되며 32bit 이다</span>
<span class="c"># =&gt; 4: cilium_net@cilium_host: &amp;lt;BROADCAST,MULTICAST,NOARP,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span>
<span class="c">#        link/ether 16:9d:bb:67:fc:a0 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet6 fe80::149d:bbff:fe67:fca0/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    5: cilium_host@cilium_net: &amp;lt;BROADCAST,MULTICAST,NOARP,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span>
<span class="c">#        link/ether 7e:ea:43:69:1e:4b brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet 172.16.1.82/32 scope global cilium_host</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#        inet6 fe80::7cea:43ff:fe69:1e4b/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>

<span class="c"># proxy arp 는 disable(0) 상태이며, 파드와 연결된 lxc 도 모두 0 이다</span>
<span class="c"># 파드의 32bit ip의 gw 가 각각 연결된 veth 인터페이스의 mac 으로 cilium_host 의 IP/MAC 응답을 처리한다, 어떻게 동작이 되는걸까요? &gt;&gt; eBPF program!!!</span>
<span class="nv">$ </span><span class="nb">cat</span> /proc/sys/net/ipv4/conf/cilium_net/proxy_arp
<span class="c"># =&gt; 0</span>
<span class="nv">$ </span><span class="nb">cat</span> /proc/sys/net/ipv4/conf/cilium_host/proxy_arp
<span class="c"># =&gt; 0</span>

<span class="c"># lxc_health 인터페이스는 veth 로 cilium(NET NS 0, 호스트와 다름)과 veth pair 이다 - 링크</span>
<span class="c"># cilium 인터페이스에 파드 IP가 할당되어 있으며, cilium-health-responder 로 동작한다</span>
<span class="nv">$ </span>lsns <span class="nt">-t</span> net
<span class="c"># =&gt;         NS TYPE NPROCS   PID USER     NETNSID NSFS                                                COMMAND</span>
<span class="c">#    4026531840 net     133     1 root  unassigned                                                     /sbin/init</span>
<span class="c">#    4026532195 net       2  8433 65535          1 /run/netns/cni-0943b57a-e695-904e-87f6-7edb4fb0cd92 /pause</span>
<span class="c">#    4026532350 net       1 18060 root           0                                                     cilium-health-responder --listen 4240 --pidfile /var/run/cilium/state/health-endp</span>
<span class="c">#    4026532359 net       2 10652 65535          2 /run/netns/cni-1b359731-9a53-2db0-eee1-63b0c5643c27 /pause</span>
</code></pre></div></div>

<h4 id="hubble">Hubble</h4>

<p>Cillium은 Hubble을 통해 통신 및 서비스와 네트워킹 인프라의 동작에 대한 심층적인 가시성을 완전히 투명한 방식으로 관찰성을 제공합니다. - <a href="https://cilium.io/blog/2019/11/19/announcing-hubble/">참고</a></p>
<ul>
  <li>Hubble은 <strong>완전히 분산된 네트워킹 및 보안 모니터링</strong> 플랫폼입니다</li>
  <li>Cilium 과 eBPF 기반으로 동작하며, <strong>어플리케이션 수정없이도</strong> 보다 심도있는 가시성을 제공합니다.</li>
  <li>Hubble은 컨테이너 기반 워크로드 뿐만 아니라 전통적인 <strong>표준 리눅스 프로세스나 VM 기반 워크로드에 대해서도 가시성을 제공</strong>합니다.</li>
  <li>eBPF를 사용함으로써 전통적인 IP 기반이 아닌 <strong>서비스/파드/컨테이너 수준의 네트워크 트래픽</strong>에 대해서 보안 가시성 및 통제를 제공할 수 있습니다.
또한 <strong>어플리케이션 레이어(L7)에서 필터링 할 수 도</strong> 있습니다.</li>
  <li>기본적으로 Hubble API는 Cilium 에이전트가 실행되는 개별 노드의 범위 내에서 작동합니다. 
이는 네트워크 통찰력을 로컬 Cilium 에이전트가 관찰한 트래픽으로 제한합니다.<br />
Hubble <strong>CLI</strong>(<code class="language-plaintext highlighter-rouge">hubble</code>)를 사용하여 <strong>로컬 Unix Domain Socket</strong>을 통해 제공된 <strong>Hubble API를 쿼리</strong>할 수 있습니다. Hubble CLI 바이너리는 기본적으로 Cilium 에이전트 포드에 설치됩니다.</li>
  <li><strong>Hubble Relay</strong>를 배포하면 전체 클러스터 또는 ClusterMesh 시나리오의 여러 <strong>클러스터에 대한 네트워크 가시성</strong>이 제공됩니다. 이 모드에서 Hubble 데이터는 Hubble CLI(<code class="language-plaintext highlighter-rouge">hubble</code>)를 Hubble Relay 서비스로 지정하거나 Hubble UI를 통해 액세스할 수 있습니다. Hubble UI는 L3/L4 및 L7 계층에서 서비스 종속성 그래프를 자동으로 검색할 수 있는 웹 인터페이스로, 사용자 친화적인 시각화 및 서비스 맵으로서의 데이터 흐름 필터링을 허용합니다.
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_10.png" alt="img.png" class="image-center w-80" />
<em class="image-caption">Hubble Relay를 통한 전체 클러스터 모니터링 <a href="https://cilium.io/blog/2020/06/22/cilium-18/">링크</a></em></li>
  <li>메트릭은 <strong>Prometheus</strong>로 수집되며, <strong>Grafana</strong>를 통해 시각화할 수도 있어서 기존의 대시보드와 통합도 가능합니다.
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_9.png" alt="img.png" class="image-center w-80" />
<em class="image-caption"><a href="https://cilium.io/blog/2019/11/19/announcing-hubble/">https://cilium.io/blog/2019/11/19/announcing-hubble/</a></em></li>
  <li>Hubble UI 화면
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_11.png" alt="img.png" class="image-center w-100" />
<em class="image-caption">서비스 종속성 그래프</em></li>
  <li>통제 예시
    <ul>
      <li><code class="language-plaintext highlighter-rouge">/public/.*</code> 경로에 대한 <code class="language-plaintext highlighter-rouge">GET</code> 요청만 허용하고, 다른 모든 요청은 거부</li>
      <li><code class="language-plaintext highlighter-rouge">service1</code>이 <code class="language-plaintext highlighter-rouge">topic1</code>이라는 토픽을 생산하고, <code class="language-plaintext highlighter-rouge">service2</code>가 <code class="language-plaintext highlighter-rouge">topic1</code>을 소비하도록 허용하고, 그 외의 모든 카프카 메시지는 거부</li>
      <li>HTTP 헤더에 <code class="language-plaintext highlighter-rouge">X-Token: [0-9]+</code>가 포함된 모든 요청을 허용하고, 그렇지 않은 요청은 거부</li>
    </ul>
  </li>
</ul>

<h5 id="hubble-uicli-접근-및-확인">Hubble UI/CLI 접근 및 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 확인</span>
<span class="nv">$ </span>cilium status
<span class="c"># =&gt;     /¯¯\</span>
<span class="c">#     /¯¯\__/¯¯\    Cilium:             OK</span>
<span class="c">#     \__/¯¯\__/    Operator:           OK</span>
<span class="c">#     /¯¯\__/¯¯\    Envoy DaemonSet:    OK</span>
<span class="c">#     \__/¯¯\__/    Hubble Relay:       OK</span>
<span class="c">#        \__/       ClusterMesh:        disabled</span>
<span class="c">#    </span>
<span class="c">#    DaemonSet              cilium             Desired: 3, Ready: 3/3, Available: 3/3</span>
<span class="c">#    ...</span>

<span class="c"># UI 파드 정보 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>hubble-ui <span class="nt">-o</span> wide
<span class="c"># =&gt; NAME                         READY   STATUS    RESTARTS      AGE    IP             NODE    NOMINATED NODE   READINESS GATES</span>
<span class="c">#    hubble-ui-59bb4cb67b-r48tz   2/2     Running   2 (87m ago)   101m   172.16.0.223   k3s-m   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>

<span class="c"># Hubble UI 웹 접속</span>
<span class="nv">$ </span>kubectl patch <span class="nt">-n</span> kube-system svc hubble-ui <span class="nt">-p</span> <span class="s1">'{"spec": {"type": "NodePort"}}'</span>
<span class="c"># =&gt; service/hubble-ui patched</span>
<span class="nv">$ HubbleUiNodePort</span><span class="o">=</span><span class="si">$(</span>kubectl get svc <span class="nt">-n</span> kube-system hubble-ui <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.spec.ports[0].nodePort<span class="o">}</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"Hubble UI URL = http://</span><span class="si">$(</span>curl <span class="nt">-s</span> ipinfo.io/ip<span class="si">)</span><span class="s2">:</span><span class="nv">$HubbleUiNodePort</span><span class="s2">"</span>
<span class="c"># =&gt; Hubble UI URL = http://54.180.146.116:30732</span>

<span class="c">## Service NodePort 생성 후 아래 정보 확인!</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span>
<span class="c"># =&gt; -P PREROUTING ACCEPT</span>
<span class="c">#    -P INPUT ACCEPT</span>
<span class="c">#    -P OUTPUT ACCEPT</span>
<span class="c">#    -P POSTROUTING ACCEPT</span>
<span class="c">#    ...</span>
<span class="c">#    -N KUBE-EXT-ZGWW2L4XLRSDZ3EF</span>
<span class="c">#    -N KUBE-MARK-MASQ</span>
<span class="c">#    -N KUBE-NODEPORTS</span>
<span class="c">#    ...</span>
<span class="c">#    -N KUBE-SEP-UOFUVE4S3JB7NP6T</span>
<span class="c">#    -N KUBE-SERVICES</span>
<span class="c">#    ...</span>
<span class="c">#    # &lt;span style="color: green;"&gt;👉 (1)&lt;/span&gt;-A PREROUTING -m comment --comment &amp;quot;kubernetes service portals&amp;quot; -j KUBE-SERVICES</span>
<span class="c">#    ...</span>
<span class="c">#    # &lt;span style="color: green;"&gt;👉 (4)&lt;/span&gt;-A KUBE-EXT-ZGWW2L4XLRSDZ3EF -m comment --comment &amp;quot;masquerade traffic for kube-system/hubble-ui:http external destinations&amp;quot; -j KUBE-MARK-MASQ</span>
<span class="c">#    # &lt;span style="color: green;"&gt;👉 (5)&lt;/span&gt;-A KUBE-EXT-ZGWW2L4XLRSDZ3EF -j KUBE-SVC-ZGWW2L4XLRSDZ3EF</span>
<span class="c">#    -A KUBE-MARK-MASQ -j MARK --set-xmark 0x4000/0x4000</span>
<span class="c">#    # &lt;span style="color: green;"&gt;👉 (3)&lt;/span&gt;-A KUBE-NODEPORTS -p tcp -m comment --comment &amp;quot;kube-system/hubble-ui:http&amp;quot; -m tcp --dport 30732 -j KUBE-EXT-ZGWW2L4XLRSDZ3EF</span>
<span class="c">#    ...</span>
<span class="c">#    # &lt;span style="color: green;"&gt;👉 (8)&lt;/span&gt;-A KUBE-SEP-UOFUVE4S3JB7NP6T -s 172.16.0.223/32 -m comment --comment &amp;quot;kube-system/hubble-ui:http&amp;quot; -j KUBE-MARK-MASQ</span>
<span class="c">#    # &lt;span style="color: green;"&gt;👉 (9)&lt;/span&gt;-A KUBE-SEP-UOFUVE4S3JB7NP6T -p tcp -m comment --comment &amp;quot;kube-system/hubble-ui:http&amp;quot; -m tcp -j DNAT --to-destination 172.16.0.223:8081</span>
<span class="c">#    ...</span>
<span class="c">#    # &lt;span style="color: green;"&gt;👉 (2)&lt;/span&gt;-A KUBE-SERVICES -m comment --comment &amp;quot;kubernetes service nodeports; NOTE: this must be the last rule in this chain&amp;quot; -m addrtype --dst-type LOCAL -j KUBE-NODEPORTS</span>
<span class="c">#    ...</span>
<span class="c">#    # &lt;span style="color: green;"&gt;👉 (6)&lt;/span&gt;-A KUBE-SVC-ZGWW2L4XLRSDZ3EF ! -s 172.16.0.0/16 -d 10.10.200.125/32 -p tcp -m comment --comment &amp;quot;kube-system/hubble-ui:http cluster IP&amp;quot; -m tcp --dport 80 -j KUBE-MARK-MASQ</span>
<span class="c">#    # &lt;span style="color: green;"&gt;👉 (7)&lt;/span&gt;-A KUBE-SVC-ZGWW2L4XLRSDZ3EF -m comment --comment &amp;quot;kube-system/hubble-ui:http -&amp;gt; 172.16.0.223:8081&amp;quot; -j KUBE-SEP-UOFUVE4S3JB7NP6T</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 (1) PREROUTING =&gt; (2) KUBE-SERVICES =&gt; (3) KUBE-NODEPORTS &lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;    if 노드 포트인 30732로 접속:&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;        =&gt; (4,5) KUBE-EXT-ZGWW2L4XLRSDZ3EF&lt;/span&gt; </span>
<span class="c"># &lt;span style="color: green;"&gt;        =&gt; (6,7) KUBE-SVC-ZGWW2L4XLRSDZ3EF =&gt; (8,9) KUBE-SEP-UOFUVE4S3JB7NP6T =&gt; 172.16.0.223:8081&lt;/span&gt;</span>

<span class="nv">$ </span>conntrack <span class="nt">-L</span>
<span class="nv">$ </span>conntrack <span class="nt">-L</span> |grep <span class="nt">-v</span> 2379

<span class="c"># Install Hubble Client</span>
<span class="nv">$ HUBBLE_VERSION</span><span class="o">=</span><span class="si">$(</span>curl <span class="nt">-s</span> https://raw.githubusercontent.com/cilium/hubble/master/stable.txt<span class="si">)</span>
<span class="nv">$ HUBBLE_ARCH</span><span class="o">=</span>amd64
<span class="nv">$ </span><span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span><span class="si">)</span><span class="s2">"</span> <span class="o">=</span> <span class="s2">"aarch64"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then </span><span class="nv">HUBBLE_ARCH</span><span class="o">=</span>arm64<span class="p">;</span> <span class="k">fi</span>
<span class="nv">$ </span>curl <span class="nt">-L</span> <span class="nt">--fail</span> <span class="nt">--remote-name-all</span> https://github.com/cilium/hubble/releases/download/<span class="nv">$HUBBLE_VERSION</span>/hubble-linux-<span class="k">${</span><span class="nv">HUBBLE_ARCH</span><span class="k">}</span>.tar.gz<span class="o">{</span>,.sha256sum<span class="o">}</span>
<span class="nv">$ </span><span class="nb">sha256sum</span> <span class="nt">--check</span> hubble-linux-<span class="k">${</span><span class="nv">HUBBLE_ARCH</span><span class="k">}</span>.tar.gz.sha256sum
<span class="nv">$ </span><span class="nb">sudo tar </span>xzvfC hubble-linux-<span class="k">${</span><span class="nv">HUBBLE_ARCH</span><span class="k">}</span>.tar.gz /usr/local/bin
<span class="c"># =&gt; hubble</span>
<span class="nv">$ </span><span class="nb">rm </span>hubble-linux-<span class="k">${</span><span class="nv">HUBBLE_ARCH</span><span class="k">}</span>.tar.gz<span class="o">{</span>,.sha256sum<span class="o">}</span>

<span class="c"># Hubble API Access : localhost TCP 4245 Relay 를 통해 접근, observe 를 통해서 flow 쿼리 확인 가능!</span>
<span class="nv">$ </span>cilium hubble port-forward &amp;
<span class="c"># =&gt; [1] 16534</span>

<span class="c"># CLI 로 Hubble API 상태 확인</span>
<span class="nv">$ </span>hubble status
<span class="c"># =&gt; Healthcheck (via localhost:4245): Ok</span>
<span class="c">#    Current/Max Flows: 12,285/12,285 (100.00%)</span>
<span class="c">#    Flows/s: 24.50</span>
<span class="c">#    Connected Nodes: 3/3</span>

<span class="c"># query the flow API and look for flows</span>
<span class="nv">$ </span>hubble observe
<span class="c"># =&gt; Oct 01 13:26:17.501: kube-system/local-path-provisioner-6795b5f9d8-84m96:60994 (ID:11088) -&amp;gt; 192.168.10.10:6443 (kube-apiserver) to-network FORWARDED (TCP Flags: ACK)</span>
<span class="c">#    Oct 01 13:26:17.660: kube-system/hubble-ui-59bb4cb67b-r48tz:47372 (ID:37523) -&amp;gt; kube-system/hubble-relay-88f7f89d4-fcq2s:4245 (ID:4124) to-network FORWARDED (TCP Flags: ACK)</span>
<span class="c">#    Oct 01 13:26:17.797: 127.0.0.1:36150 (world) &amp;lt;&amp;gt; kube-system/hubble-ui-59bb4cb67b-r48tz (ID:37523) pre-xlate-rev TRACED (TCP)</span>
<span class="c">#    Oct 01 13:26:17.914: 192.168.10.102:38716 (host) -&amp;gt; 192.168.10.10:6443 (kube-apiserver) to-network FORWARDED (TCP Flags: ACK)</span>
<span class="c">#    Oct 01 13:26:18.011: 127.0.0.1:36160 (world) &amp;lt;&amp;gt; kube-system/hubble-ui-59bb4cb67b-r48tz (ID:37523) pre-xlate-rev TRACED (TCP)</span>
<span class="c">#    Oct 01 13:26:18.067: 10.0.2.15:59486 (host) -&amp;gt; kube-system/metrics-server-cdcc87586-g5m2d:10250 (ID:27624) to-endpoint FORWARDED (TCP Flags: SYN)</span>
<span class="c">#    Oct 01 13:26:18.067: 10.0.2.15:59486 (host) &amp;lt;- kube-system/metrics-server-cdcc87586-g5m2d:10250 (ID:27624) to-stack FORWARDED (TCP Flags: SYN, ACK)</span>
<span class="c">#    ...</span>
<span class="c"># hubble observe --pod netpod</span>
<span class="c"># hubble observe --namespace galaxy --http-method POST --http-path /v1/request-landing</span>
<span class="c"># hubble observe --pod deathstar --protocol http</span>
<span class="c"># hubble observe --pod deathstar --verdict DROPPED</span>
</code></pre></div></div>

<h4 id="노드간-파드-통신">노드간 파드 통신</h4>

<ul>
  <li>
    <p>Endpoint to Endpoint 통신 패킷 흐름도
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_12.png" alt="img.png" class="image-center w-100" /></p>
  </li>
  <li>
    <p>Egress to Endpoint 통신 패킷 흐름도
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_13.png" alt="img_1.png" class="image-center w-100" /></p>
  </li>
  <li>
    <p>Ingress to Endpoint 통신 패킷 흐름도
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_14.png" alt="img_2.png" class="image-center w-100" /></p>
  </li>
  <li>
    <p>파드 생성 및 확인</p>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl create -f -
apiVersion: v1
kind: Pod
metadata:
  name: netpod
  labels:
    app: netpod
spec:
  nodeName: k3s-m
  containers:
  - name: netshoot-pod
    image: nicolaka/netshoot
    command: ["tail"]
    args: ["-f", "/dev/null"]
  terminationGracePeriodSeconds: 0
---
apiVersion: v1
kind: Pod
metadata:
  name: webpod1
  labels:
    app: webpod
spec:
  nodeName: k3s-w1
  containers:
  - name: container
    image: traefik/whoami
  terminationGracePeriodSeconds: 0
---
apiVersion: v1
kind: Pod
metadata:
  name: webpod2
  labels:
    app: webpod
spec:
  nodeName: k3s-w2
  containers:
  - name: container
    image: traefik/whoami
  terminationGracePeriodSeconds: 0
</span><span class="no">EOF
</span><span class="c"># =&gt; pod/netpod created</span>
<span class="c">#    pod/webpod1 created</span>
<span class="c">#    pod/webpod2 created</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-o</span> wide
<span class="c"># =&gt; NAME      READY   STATUS    RESTARTS   AGE   IP             NODE     NOMINATED NODE   READINESS GATES</span>
<span class="c">#    netpod    1/1     Running   0          36s   172.16.0.147   k3s-m    &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    webpod1   1/1     Running   0          36s   172.16.1.247   k3s-w1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    webpod2   1/1     Running   0          36s   172.16.2.84    k3s-w2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="nv">$ </span>c0 status <span class="nt">--verbose</span> | <span class="nb">grep </span>Allocated <span class="nt">-A5</span>
<span class="c"># =&gt; Allocated addresses:</span>
<span class="c">#      172.16.0.147 (default/netpod)</span>
<span class="c">#      172.16.0.223 (kube-system/hubble-ui-59bb4cb67b-r48tz [restored])</span>
<span class="c">#      172.16.0.227 (router)</span>
<span class="c">#      172.16.0.26 (health)</span>
<span class="c">#    IPv4 BIG TCP:           Disabled</span>
<span class="nv">$ </span>c1 status <span class="nt">--verbose</span> | <span class="nb">grep </span>Allocated <span class="nt">-A5</span>
<span class="c"># =&gt; Allocated addresses:</span>
<span class="c">#      172.16.1.21 (kube-system/coredns-7b98449c4-x5756 [restored])</span>
<span class="c">#      172.16.1.224 (health)</span>
<span class="c">#      172.16.1.247 (default/webpod1)</span>
<span class="c">#      172.16.1.82 (router)</span>
<span class="c">#      172.16.1.99 (kube-system/hubble-relay-88f7f89d4-fcq2s [restored])</span>
<span class="nv">$ </span>c2 status <span class="nt">--verbose</span> | <span class="nb">grep </span>Allocated <span class="nt">-A5</span>
<span class="c"># =&gt; Allocated addresses:</span>
<span class="c">#      172.16.2.184 (kube-system/local-path-provisioner-6795b5f9d8-84m96 [restored])</span>
<span class="c">#      172.16.2.223 (kube-system/metrics-server-cdcc87586-g5m2d [restored])</span>
<span class="c">#      172.16.2.25 (router)</span>
<span class="c">#      172.16.2.8 (health)</span>
<span class="c">#      172.16.2.84 (default/webpod2)</span>

<span class="nv">$ </span>kubectl get ciliumendpoints
<span class="c"># =&gt; NAME      SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    netpod    27629               ready            172.16.0.147</span>
<span class="c">#    webpod1   64309               ready            172.16.1.247</span>
<span class="c">#    webpod2   64309               ready            172.16.2.84</span>
<span class="nv">$ </span>kubectl get ciliumendpoints <span class="nt">-A</span>
<span class="c"># =&gt; root@k3s-m:~# kubectl get ciliumendpoints -A</span>
<span class="c">#    NAMESPACE     NAME                                      SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    default       netpod                                    27629               ready            172.16.0.147</span>
<span class="c">#    default       webpod1                                   64309               ready            172.16.1.247</span>
<span class="c">#    default       webpod2                                   64309               ready            172.16.2.84</span>
<span class="c">#    kube-system   coredns-7b98449c4-x5756                   11970               ready            172.16.1.21</span>
<span class="c">#    kube-system   hubble-relay-88f7f89d4-fcq2s              4124                ready            172.16.1.99</span>
<span class="c">#    kube-system   hubble-ui-59bb4cb67b-r48tz                37523               ready            172.16.0.223</span>
<span class="c">#    kube-system   local-path-provisioner-6795b5f9d8-84m96   11088               ready            172.16.2.184</span>
<span class="c">#    kube-system   metrics-server-cdcc87586-g5m2d            27624               ready            172.16.2.223</span>
<span class="nv">$ </span>c0 endpoint list
<span class="c"># =&gt; ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])                                                  IPv6   IPv4           STATUS</span>
<span class="c">#               ENFORCEMENT        ENFORCEMENT</span>
<span class="c">#    640        Disabled           Disabled          37523      k8s:app.kubernetes.io/name=hubble-ui                                                172.16.0.223   ready</span>
<span class="c">#                                                               k8s:app.kubernetes.io/part-of=cilium</span>
<span class="c">#                                                               k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=kube-system</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.cluster=default</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.serviceaccount=hubble-ui</span>
<span class="c">#                                                               k8s:io.kubernetes.pod.namespace=kube-system</span>
<span class="c">#                                                               k8s:k8s-app=hubble-ui</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>c0 bpf endpoint list
<span class="c"># =&gt; IP ADDRESS        LOCAL ENDPOINT INFO</span>
<span class="c">#    192.168.10.10:0   (localhost)</span>
<span class="c">#    10.0.2.15:0       (localhost)</span>
<span class="c">#    172.16.0.147:0    id=2724  sec_id=27629 flags=0x0000 ifindex=19  mac=52:59:78:2F:C0:BE nodemac=7E:77:FA:0A:D3:CC</span>
<span class="c">#    172.16.0.26:0     id=1598  sec_id=4     flags=0x0000 ifindex=17  mac=CE:24:50:27:35:B9 nodemac=FE:57:C1:AD:A6:28</span>
<span class="c">#    172.16.0.223:0    id=640   sec_id=37523 flags=0x0000 ifindex=9   mac=AE:B8:81:A6:B1:28 nodemac=C2:21:B8:92:DA:FD</span>
<span class="c">#    172.16.0.227:0    (localhost)</span>
<span class="nv">$ </span>c0 map get cilium_lxc
<span class="c"># =&gt; Key              Value                                                                                            State   Error</span>
<span class="c">#    172.16.0.147:0   id=2724  sec_id=27629 flags=0x0000 ifindex=19  mac=52:59:78:2F:C0:BE nodemac=7E:77:FA:0A:D3:CC   sync</span>
<span class="c">#    172.16.0.223:0   id=640   sec_id=37523 flags=0x0000 ifindex=9   mac=AE:B8:81:A6:B1:28 nodemac=C2:21:B8:92:DA:FD   sync</span>
<span class="c">#    172.16.0.26:0    id=1598  sec_id=4     flags=0x0000 ifindex=17  mac=CE:24:50:27:35:B9 nodemac=FE:57:C1:AD:A6:28   sync</span>
<span class="nv">$ </span>c0 ip list
<span class="c"># =&gt; IP                  IDENTITY                                                                         SOURCE</span>
<span class="c">#    0.0.0.0/0           reserved:world</span>
<span class="c">#    10.0.2.15/32        reserved:host</span>
<span class="c">#                        reserved:kube-apiserver</span>
<span class="c">#    172.16.0.26/32      reserved:health</span>
<span class="c">#    172.16.0.147/32     k8s:app=netpod                                                                   custom-resource</span>
<span class="c">#                        k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<ul>
  <li>파드 변수 지정</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 테스트 파드들 IP</span>
<span class="nv">$ NETPODIP</span><span class="o">=</span><span class="si">$(</span>kubectl get pods netpod <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.podIP}'</span><span class="si">)</span>
<span class="nv">$ WEBPOD1IP</span><span class="o">=</span><span class="si">$(</span>kubectl get pods webpod1 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.podIP}'</span><span class="si">)</span>
<span class="nv">$ WEBPOD2IP</span><span class="o">=</span><span class="si">$(</span>kubectl get pods webpod2 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.podIP}'</span><span class="si">)</span>

<span class="c"># 단축키(alias) 지정</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">p0</span><span class="o">=</span><span class="s2">"kubectl exec -it netpod  -- "</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">p1</span><span class="o">=</span><span class="s2">"kubectl exec -it webpod1 -- "</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">p2</span><span class="o">=</span><span class="s2">"kubectl exec -it webpod2 -- "</span>
</code></pre></div></div>

<ul>
  <li>파드의 ARP 동작 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># netpod 네트워크 정보 확인</span>
<span class="nv">$ </span>p0 ip <span class="nt">-c</span> <span class="nt">-4</span> addr
<span class="c"># =&gt; ...</span>
<span class="c">#    18: eth0@if19: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UP group default qlen 1000 link-netnsid 0</span>
<span class="c">#        inet 172.16.0.147/32 scope global eth0</span>
<span class="nv">$ </span>p0 route <span class="nt">-n</span>
<span class="c"># =&gt; Kernel IP routing table</span>
<span class="c">#    Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span>
<span class="c">#    0.0.0.0         172.16.0.227    0.0.0.0         UG    0      0        0 eth0</span>
<span class="c">#    172.16.0.227    0.0.0.0         255.255.255.255 UH    0      0        0 eth0</span>
<span class="nv">$ </span>p0 ping <span class="nt">-c</span> 1 <span class="nv">$WEBPOD1IP</span> <span class="o">&amp;&amp;</span> p0 ping <span class="nt">-c</span> 1 <span class="nv">$WEBPOD2IP</span>
<span class="c"># =&gt; PING 172.16.1.247 (172.16.1.247) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 172.16.1.247: icmp_seq=1 ttl=62 time=0.642 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 172.16.1.247 ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 0.642/0.642/0.642/0.000 ms</span>
<span class="c">#    PING 172.16.2.84 (172.16.2.84) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 172.16.2.84: icmp_seq=1 ttl=62 time=0.716 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 172.16.2.84 ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 0.716/0.716/0.716/0.000 ms</span>
</code></pre></div></div>

<p><img src="/assets/2024/kans-3th/w8/20241026_kans_w8_15.png" alt="img.png" /></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>p0 curl <span class="nt">-s</span> <span class="nv">$WEBPOD1IP</span> <span class="o">&amp;&amp;</span> p0 curl <span class="nt">-s</span> <span class="nv">$WEBPOD2IP</span>
<span class="c"># =&gt; Hostname: webpod1</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: 172.16.1.247</span>
<span class="c">#    RemoteAddr: 172.16.0.147:51692</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: 172.16.1.247</span>
<span class="c">#    User-Agent: curl/8.7.1</span>
<span class="c">#    Accept: */*</span>
<span class="c">#    </span>
<span class="c">#    Hostname: webpod2</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: 172.16.2.84</span>
<span class="c">#    RemoteAddr: 172.16.0.147:32796</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: 172.16.2.84</span>
<span class="c">#    User-Agent: curl/8.7.1</span>
<span class="c">#    Accept: */*</span>
<span class="nv">$ </span>p0 curl <span class="nt">-s</span> <span class="nv">$WEBPOD1IP</span>:8080 <span class="p">;</span> p0 curl <span class="nt">-s</span> <span class="nv">$WEBPOD2IP</span>:8080
<span class="c"># =&gt; command terminated with exit code 7</span>
<span class="c">#    command terminated with exit code 7</span>
<span class="nv">$ </span>p0 ping <span class="nt">-c</span> 1 8.8.8.8 <span class="o">&amp;&amp;</span> p0 curl <span class="nt">-s</span> wttr.in/seoul
<span class="c"># =&gt; PING 8.8.8.8 (8.8.8.8) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 8.8.8.8: icmp_seq=1 ttl=61 time=39.1 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 8.8.8.8 ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 39.095/39.095/39.095/0.000 ms</span>
<span class="c">#    Weather report: seoul</span>
<span class="c">#    </span>
<span class="c">#         \  /       Partly cloudy</span>
<span class="c">#       _ /&amp;quot;&amp;quot;.-.     16 °C</span>
<span class="c">#         \_(   ).   ← 4 km/h</span>
<span class="c">#         /(___(__)  10 km</span>
<span class="c">#                    0.0 mm</span>
<span class="c">#                                                           ┌─────────────┐</span>
<span class="c">#    ┌──────────────────────────────┬───────────────────────┤  Sat 26 Oct ├───────────────────────┬──────────────────────────────┐</span>
<span class="c">#    │            Morning           │             Noon      └──────┬──────┘     Evening           │             Night            │</span>
<span class="c">#    ├──────────────────────────────┼──────────────────────────────┼──────────────────────────────┼──────────────────────────────┤</span>
<span class="c">#    │     \   /     Sunny          │     \   /     Sunny          │               Overcast       │    \  /       Partly Cloudy  │</span>
<span class="c">#    │      .-.      16 °C          │      .-.      21 °C          │      .--.     20 °C          │  _ /&amp;quot;&amp;quot;.-.     19 °C          │</span>
<span class="c">#    │   ― (   ) ―   ↙ 5-7 km/h     │   ― (   ) ―   ↙ 5-6 km/h     │   .-(    ).   ← 4-6 km/h     │    \_(   ).   ↙ 4-7 km/h     │</span>
<span class="c">#    │      `-’      10 km          │      `-’      10 km          │  (___.__)__)  10 km          │    /(___(__)  10 km          │</span>
<span class="c">#    │     /   \     0.0 mm | 0%    │     /   \     0.0 mm | 0%    │               0.0 mm | 0%    │               0.0 mm | 0%    │</span>
<span class="c">#    └──────────────────────────────┴──────────────────────────────┴──────────────────────────────┴──────────────────────────────┘</span>
<span class="c">#                                                           ┌─────────────┐</span>
<span class="c">#    ┌──────────────────────────────┬───────────────────────┤  Sun 27 Oct ├───────────────────────┬──────────────────────────────┐</span>
<span class="c">#    │            Morning           │             Noon      └──────┬──────┘     Evening           │             Night            │</span>
<span class="c">#    ├──────────────────────────────┼──────────────────────────────┼──────────────────────────────┼──────────────────────────────┤</span>
<span class="c">#    │               Overcast       │               Cloudy         │     \   /     Clear          │     \   /     Clear          │</span>
<span class="c">#    │      .--.     16 °C          │      .--.     19 °C          │      .-.      19 °C          │      .-.      17 °C          │</span>
<span class="c">#    │   .-(    ).   ← 1 km/h       │   .-(    ).   ↓ 4-5 km/h     │   ― (   ) ―   ↘ 9-13 km/h    │   ― (   ) ―   ↘ 5-7 km/h     │</span>
<span class="c">#    │  (___.__)__)  10 km          │  (___.__)__)  10 km          │      `-’      10 km          │      `-’      10 km          │</span>
<span class="c">#    │               0.0 mm | 0%    │               0.0 mm | 0%    │     /   \     0.0 mm | 0%    │     /   \     0.0 mm | 0%    │</span>
<span class="c">#    └──────────────────────────────┴──────────────────────────────┴──────────────────────────────┴──────────────────────────────┘</span>
<span class="c">#                                                           ┌─────────────┐</span>
<span class="c">#    ┌──────────────────────────────┬───────────────────────┤  Mon 28 Oct ├───────────────────────┬──────────────────────────────┐</span>
<span class="c">#    │            Morning           │             Noon      └──────┬──────┘     Evening           │             Night            │</span>
<span class="c">#    ├──────────────────────────────┼──────────────────────────────┼──────────────────────────────┼──────────────────────────────┤</span>
<span class="c">#    │     \   /     Sunny          │    \  /       Partly Cloudy  │               Cloudy         │  _`/&amp;quot;&amp;quot;.-.     Patchy rain ne…│</span>
<span class="c">#    │      .-.      16 °C          │  _ /&amp;quot;&amp;quot;.-.     20 °C          │      .--.     20 °C          │   ,\_(   ).   19 °C          │</span>
<span class="c">#    │   ― (   ) ―   ← 5-6 km/h     │    \_(   ).   ← 6-7 km/h     │   .-(    ).   ↙ 6-9 km/h     │    /(___(__)  ← 8-10 km/h    │</span>
<span class="c">#    │      `-’      10 km          │    /(___(__)  10 km          │  (___.__)__)  10 km          │      ‘ ‘ ‘ ‘  10 km          │</span>
<span class="c">#    │     /   \     0.0 mm | 0%    │               0.0 mm | 0%    │               0.0 mm | 0%    │     ‘ ‘ ‘ ‘   0.0 mm | 67%   │</span>
<span class="c">#    └──────────────────────────────┴──────────────────────────────┴──────────────────────────────┴──────────────────────────────┘</span>
<span class="c">#    Location: 서울특별시, 대한민국 [37.5666791,126.9782914]</span>
<span class="c">#    </span>
<span class="c">#    Follow @igor_chubin for wttr.in updates</span>

<span class="nv">$ </span>p0 ip <span class="nt">-c</span> neigh
<span class="c"># =&gt; 172.16.0.227 dev eth0 lladdr 7e:77:fa:0a:d3:cc STALE</span>

<span class="c"># hubble cli 확인</span>
<span class="nv">$ </span>hubble observe <span class="nt">--pod</span> netpod
<span class="c"># =&gt; Oct 01 14:29:21.248: kube-system/coredns-7b98449c4-7kqtg:53 (ID:11970) &amp;lt;&amp;gt; default/netpod (ID:27629) pre-xlate-rev TRACED (UDP)</span>
<span class="c">#    Oct 01 14:29:21.248: kube-system/kube-dns:53 (world) &amp;lt;&amp;gt; default/netpod (ID:27629) post-xlate-rev TRANSLATED (UDP)</span>
<span class="c">#    Oct 01 14:29:21.248: default/netpod:34162 (ID:27629) -&amp;gt; 5.9.243.187:80 (world) to-network FORWARDED (TCP Flags: SYN)</span>
<span class="c">#    Oct 01 14:29:21.481: default/netpod:34162 (ID:27629) -&amp;gt; 5.9.243.187:80 (world) to-network FORWARDED (TCP Flags: ACK, PSH)</span>
<span class="c">#    Oct 01 14:29:21.481: default/netpod:34162 (ID:27629) &amp;lt;- 5.9.243.187:80 (world) to-endpoint FORWARDED (TCP Flags: SYN, ACK)</span>
<span class="c">#    Oct 01 14:29:21.481: default/netpod:34162 (ID:27629) -&amp;gt; 5.9.243.187:80 (world) to-network FORWARDED (TCP Flags: ACK)</span>
<span class="c">#    Oct 01 14:29:21.816: default/netpod:34162 (ID:27629) &amp;lt;- 5.9.243.187:80 (world) to-endpoint FORWARDED (TCP Flags: ACK, PSH)</span>
<span class="c">#    Oct 01 14:29:21.819: default/netpod:34162 (ID:27629) -&amp;gt; 5.9.243.187:80 (world) to-network FORWARDED (TCP Flags: ACK, FIN)</span>
<span class="c">#    Oct 01 14:29:22.052: default/netpod:34162 (ID:27629) &amp;lt;- 5.9.243.187:80 (world) to-endpoint FORWARDED (TCP Flags: ACK, FIN)</span>
<span class="c">#    Oct 01 14:29:22.052: default/netpod:34162 (ID:27629) -&amp;gt; 5.9.243.187:80 (world) to-network FORWARDED (TCP Flags: ACK)</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>hubble observe <span class="nt">--pod</span> webpod1
<span class="c"># =&gt; Oct 01 14:33:40.392: default/netpod:60282 (ID:27629) -&amp;gt; default/webpod1:80 (ID:64309) to-endpoint FORWARDED (TCP Flags: SYN)</span>
<span class="c">#    Oct 01 14:33:40.392: default/netpod:60282 (ID:27629) &amp;lt;- default/webpod1:80 (ID:64309) to-network FORWARDED (TCP Flags: SYN, ACK)</span>
<span class="c">#    Oct 01 14:33:40.392: default/netpod:60282 (ID:27629) &amp;lt;&amp;gt; default/webpod1 (ID:64309) pre-xlate-rev TRACED (TCP)</span>
<span class="c">#    Oct 01 14:33:40.392: default/netpod:60282 (ID:27629) -&amp;gt; default/webpod1:80 (ID:64309) to-endpoint FORWARDED (TCP Flags: ACK)</span>
<span class="c">#    Oct 01 14:33:40.392: default/netpod:60282 (ID:27629) -&amp;gt; default/webpod1:80 (ID:64309) to-endpoint FORWARDED (TCP Flags: ACK, PSH)</span>
<span class="c">#    Oct 01 14:33:40.393: default/netpod:60282 (ID:27629) &amp;lt;- default/webpod1:80 (ID:64309) to-network FORWARDED (TCP Flags: ACK, PSH)</span>
<span class="c">#    Oct 01 14:33:40.393: default/netpod:60282 (ID:27629) -&amp;gt; default/webpod1:80 (ID:64309) to-endpoint FORWARDED (TCP Flags: ACK, FIN)</span>
<span class="c">#    Oct 01 14:33:40.393: default/netpod:60282 (ID:27629) &amp;lt;- default/webpod1:80 (ID:64309) to-network FORWARDED (TCP Flags: ACK, FIN)</span>
<span class="c">#    Oct 01 14:33:40.394: default/netpod:60282 (ID:27629) -&amp;gt; default/webpod1:80 (ID:64309) to-endpoint FORWARDED (TCP Flags: ACK)</span>
<span class="c">#    Oct 01 14:33:40.405: default/netpod:60282 (ID:27629) -&amp;gt; default/webpod1:80 (ID:64309) to-network FORWARDED (TCP Flags: SYN)</span>
<span class="c">#    Oct 01 14:33:40.406: default/netpod:60282 (ID:27629) &amp;lt;- default/webpod1:80 (ID:64309) to-endpoint FORWARDED (TCP Flags: SYN, ACK)</span>
<span class="c">#    Oct 01 14:33:40.406: default/netpod:60282 (ID:27629) -&amp;gt; default/webpod1:80 (ID:64309) to-network FORWARDED (TCP Flags: ACK)</span>
<span class="c">#    Oct 01 14:33:40.406: default/netpod:60282 (ID:27629) -&amp;gt; default/webpod1:80 (ID:64309) to-network FORWARDED (TCP Flags: ACK, PSH)</span>
<span class="c">#    Oct 01 14:33:40.407: default/netpod:60282 (ID:27629) &amp;lt;- default/webpod1:80 (ID:64309) to-endpoint FORWARDED (TCP Flags: ACK, PSH)</span>
<span class="c">#    Oct 01 14:33:40.407: default/netpod:60282 (ID:27629) -&amp;gt; default/webpod1:80 (ID:64309) to-network FORWARDED (TCP Flags: ACK, FIN)</span>
<span class="c">#    Oct 01 14:33:40.408: default/netpod:60282 (ID:27629) &amp;lt;- default/webpod1:80 (ID:64309) to-endpoint FORWARDED (TCP Flags: ACK, FIN)</span>
<span class="c">#    Oct 01 14:33:40.408: default/netpod:60282 (ID:27629) -&amp;gt; default/webpod1:80 (ID:64309) to-network FORWARDED (TCP Flags: ACK)</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 80포트로 접속했을때 정상적인 응답 패킷들&lt;/span&gt;</span>

<span class="c">#    Oct 01 14:33:43.956: default/netpod:34488 (ID:27629) -&amp;gt; default/webpod1:8080 (ID:64309) to-endpoint FORWARDED (TCP Flags: SYN)</span>
<span class="c">#    Oct 01 14:33:43.956: default/netpod:34488 (ID:27629) &amp;lt;- default/webpod1:8080 (ID:64309) to-network FORWARDED (TCP Flags: ACK, RST)</span>
<span class="c">#    Oct 01 14:33:43.970: default/netpod:34488 (ID:27629) -&amp;gt; default/webpod1:8080 (ID:64309) to-network FORWARDED (TCP Flags: SYN)</span>
<span class="c">#    Oct 01 14:33:43.970: default/netpod:34488 (ID:27629) &amp;lt;- default/webpod1:8080 (ID:64309) to-endpoint FORWARDED (TCP Flags: ACK, RST)</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 열려있지 않은 8080포트로 접속했을때 오류가 발생한 패킷들&lt;/span&gt;</span>

<span class="nv">$ </span>hubble observe <span class="nt">--pod</span> webpod2

<span class="c"># BPF maps : 목적지 파드와 통신 시 어느곳으로 보내야 될지 확인할 수 있다</span>
<span class="nv">$ </span>c0 map get cilium_ipcache
<span class="c"># =&gt; Key                 Value                                                                     State   Error</span>
<span class="c">#    172.16.2.182/32     identity=27624 encryptkey=0 tunnelendpoint=192.168.10.102, flags=&amp;lt;none&amp;gt;   sync</span>
<span class="c">#    172.16.2.8/32       identity=4 encryptkey=0 tunnelendpoint=192.168.10.102, flags=&amp;lt;none&amp;gt;       sync</span>
<span class="c">#    172.16.0.147/32     identity=27629 encryptkey=0 tunnelendpoint=0.0.0.0, flags=&amp;lt;none&amp;gt;          sync</span>
<span class="c">#    172.16.0.223/32     identity=37523 encryptkey=0 tunnelendpoint=0.0.0.0, flags=&amp;lt;none&amp;gt;          sync</span>
<span class="c">#    192.168.10.10/32    identity=1 encryptkey=0 tunnelendpoint=0.0.0.0, flags=&amp;lt;none&amp;gt;              sync</span>
<span class="c">#    172.16.0.26/32      identity=4 encryptkey=0 tunnelendpoint=0.0.0.0, flags=&amp;lt;none&amp;gt;              sync</span>
<span class="c">#    10.0.2.15/32        identity=1 encryptkey=0 tunnelendpoint=0.0.0.0, flags=&amp;lt;none&amp;gt;              sync</span>
<span class="c">#    192.168.10.102/32   identity=6 encryptkey=0 tunnelendpoint=0.0.0.0, flags=&amp;lt;none&amp;gt;              sync</span>
<span class="c">#    172.16.1.82/32      identity=6 encryptkey=0 tunnelendpoint=192.168.10.101, flags=&amp;lt;none&amp;gt;       sync</span>
<span class="c">#    172.16.2.237/32     identity=11970 encryptkey=0 tunnelendpoint=192.168.10.102, flags=&amp;lt;none&amp;gt;   sync</span>
<span class="c">#    172.16.2.216/32     identity=64309 encryptkey=0 tunnelendpoint=192.168.10.102, flags=&amp;lt;none&amp;gt;   sync</span>
<span class="c">#    0.0.0.0/0           identity=2 encryptkey=0 tunnelendpoint=0.0.0.0, flags=&amp;lt;none&amp;gt;              sync</span>
<span class="c">#    172.16.2.111/32     identity=11088 encryptkey=0 tunnelendpoint=192.168.10.102, flags=&amp;lt;none&amp;gt;   sync</span>
<span class="c">#    172.16.1.224/32     identity=4 encryptkey=0 tunnelendpoint=192.168.10.101, flags=&amp;lt;none&amp;gt;       sync</span>
<span class="c">#    172.16.2.25/32      identity=6 encryptkey=0 tunnelendpoint=192.168.10.102, flags=&amp;lt;none&amp;gt;       sync</span>
<span class="c">#    192.168.10.101/32   identity=6 encryptkey=0 tunnelendpoint=0.0.0.0, flags=&amp;lt;none&amp;gt;              sync</span>
<span class="c">#    172.16.0.148/32     identity=4124 encryptkey=0 tunnelendpoint=0.0.0.0, flags=&amp;lt;none&amp;gt;           sync</span>
<span class="c">#    172.16.1.247/32     identity=64309 encryptkey=0 tunnelendpoint=192.168.10.101, flags=&amp;lt;none&amp;gt;   sync</span>
<span class="c">#    172.16.0.227/32     identity=1 encryptkey=0 tunnelendpoint=0.0.0.0, flags=&amp;lt;none&amp;gt;              sync</span>
<span class="nv">$ </span>c0 map get cilium_ipcache | <span class="nb">grep</span> <span class="nv">$WEBPOD1IP</span>
<span class="c"># =&gt; 172.16.1.247/32     identity=64309 encryptkey=0 tunnelendpoint=192.168.10.101, flags=&amp;lt;none&amp;gt;   sync</span>

<span class="c"># netpod 의 LXC 변수 지정</span>
<span class="c">#$ LXC=&lt;k3s-m의 가장 나중에 lxc 이름&gt;</span>
<span class="nv">$ LXC</span><span class="o">=</span>lxcd551b3b4058f

<span class="c"># 파드와 veth pair 에 IP가 없습니다! proxy_arp 도 없습니다! 하지만 GW MAC 요청 시 lxc(veth)의 MAC 으로 응답이 옵니다! &gt;&gt; eBPF Magic!</span>
<span class="c"># Cilium hijacks ARP table of POD1, forces the next hop to be the peer end (host side) of the veth pair.</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> addr show dev <span class="nv">$LXC</span>
<span class="c"># =&gt; 23: lxcd551b3b4058f@if22: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span>
<span class="c">#        link/ether fa:32:54:4b:16:d7 brd ff:ff:ff:ff:ff:ff link-netns cni-8634ff07-8cb9-608a-1baf-dc929d510a84</span>
<span class="c">#        inet6 fe80::f832:54ff:fe4b:16d7/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
</code></pre></div></div>

<p><img src="/assets/2024/kans-3th/w8/20241026_kans_w8_16.png" alt="img.png" class="image-center" />
<em class="image-caption">webpod1,2와 wttr.in 접속 테스트 후 Hubble UI</em></p>

<h4 id="서비스-통신-확인">서비스 통신 확인</h4>

<h5 id="소켓-기반-로드밸런싱-소개">소켓 기반 로드밸런싱 소개</h5>

<ul>
  <li>참고 : <a href="https://velog.io/@haruband/K8SCilium-Socket-Based-LoadBalancing-%EA%B8%B0%EB%B2%95">https://velog.io/@haruband/K8SCilium-Socket-Based-LoadBalancing-%EA%B8%B0%EB%B2%95</a></li>
  <li>네트워크 기반 로드밸런싱(왼쪽) vs 소켓 기반 로드밸런싱(오른쪽) 비교
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_17.png" alt="img.png" />
위의 그림에서 처럼 네트워크 기반 로드밸런싱은 서비스를 통해 DNAT 되는 과정을 거치는데, <strong>소켓기반 로드밸런싱은 DNAT하는 과정이 필요가 없습</strong>니다.
    <ul>
      <li>위의 그림을 풀어서 설명하자면 위의 예에서 Pod1에서 동작하는 앱이 <code class="language-plaintext highlighter-rouge">connect()</code> 시스템 콜을 이용해서 소켓을 연결할때 목적지 주소가
서비스 주소 (192.168.0.1)이면 소켓의 목적지 주소를 바로 백엔드 주소(10.0.0.2)으로 설정합니다. 이후 데이터 전송은 
<strong>바로 백엔드 주소(10.0.0.2)로 전송되기 때문</strong>에 <strong>DNAT 변환 및 역변환 과정이 필요없어</strong>집니다.</li>
      <li><em>이는 cilium이 L7에서 파드/서비스의 의미를 이해하고 처리하기 때문입니다!</em></li>
      <li>심지어 서비스 주소를 백엔드 주소로 변경하는 것은 <strong>시스템콜 레벨에서 이루어지며</strong>, 커널에서 패킷이 생성되기도 전입니다.</li>
    </ul>
  </li>
  <li>Socket Operations : BPF Socket Operations program은 root cgroup에 연결되며 TCP event(ESTABLISHED)에서 실행합니다.</li>
  <li>Socket send/recv : Socket send/recv 훅은 TCP socket의 모든 송수신 작업에서 실행되며, hook에서 검사/삭제/리다이렉션 할 수 있습니다.</li>
  <li><code class="language-plaintext highlighter-rouge">connect()</code>와 <code class="language-plaintext highlighter-rouge">sendto()</code> 소켓 함수에 연결된 프로그램(<code class="language-plaintext highlighter-rouge">connect4</code>, <code class="language-plaintext highlighter-rouge">sendmsg4</code>)에서는 소켓의 목적지 주소를 백엔드 주소와 포트로 변환하고, 
cilium_lb4_backends 맵에 백엔드 주소와 포트를 등록해놓습니다. 이후 <code class="language-plaintext highlighter-rouge">recvmsg()</code> 소켓 함수에 연결된 프로그램(<code class="language-plaintext highlighter-rouge">recvmsg4</code>)에서는
ilium_lb4_reverse_nat 맵을 이용해서 목적지 주소와 포트를 다시 서비스 주소와 포트로 변환합니다.
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_18.png" alt="img.png" class="image-center" />
<em class="image-caption">cilium의 소켓 기반 로드밸런싱 동작 방식 - <a href="https://k8s.networkop.co.uk/services/clusterip/dataplane/ebpf/">링크</a></em></li>
</ul>

<h5 id="서비스-생성-및-접속-확인">서비스 생성 및 접속 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 서비스 생성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl create -f -
apiVersion: v1
kind: Service
metadata:
  name: svc
spec:
  ports:
    - name: svc-webport
      port: 80
      targetPort: 80
  selector:
    app: webpod
  type: ClusterIP
</span><span class="no">EOF
</span><span class="c"># =&gt; service/svc created</span>

<span class="c"># 서비스 생성 확인</span>
<span class="nv">$ </span>kubectl get svc,ep svc
<span class="c"># =&gt; NAME          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE</span>
<span class="c">#    service/svc   ClusterIP   10.10.200.121   &amp;lt;none&amp;gt;        80/TCP    13s</span>
<span class="c">#    </span>
<span class="c">#    NAME            ENDPOINTS                         AGE</span>
<span class="c">#    endpoints/svc   172.16.1.247:80,172.16.2.216:80   13s</span>

<span class="c"># 노드에 iptables 더이상 KUBE-SVC rule 이 생성되지 않는다!</span>
<span class="nv">$ </span>iptables-save | <span class="nb">grep </span>KUBE-SVC
<span class="nv">$ </span>iptables-save | <span class="nb">grep </span>CILIUM

<span class="c"># 서비스IP를 변수에 지정</span>
<span class="nv">$ SVCIP</span><span class="o">=</span><span class="si">$(</span>kubectl get svc svc <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.spec.clusterIP}'</span><span class="si">)</span>

<span class="c"># Pod1 에서 Service(ClusterIP) 접속 트래픽 발생</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>netpod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nv">$SVCIP</span>
<span class="c"># =&gt; Hostname: webpod2</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: ::1</span>
<span class="c">#    IP: 172.16.2.216</span>
<span class="c">#    IP: fe80::844e:b2ff:fed0:7d5</span>
<span class="c">#    RemoteAddr: 172.16.0.147:36844</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: 10.10.200.121</span>
<span class="c">#    User-Agent: curl/8.7.1</span>
<span class="c">#    Accept: */*</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>netpod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nv">$SVCIP</span> | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod1</span>

<span class="c"># 지속적으로 접속 트래픽 발생</span>
<span class="nv">$ SVCIP</span><span class="o">=</span><span class="si">$(</span>kubectl get svc svc <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.spec.clusterIP}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>kubectl <span class="nb">exec </span>netpod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nv">$SVCIP</span> | <span class="nb">grep </span>Hostname<span class="p">;</span><span class="nb">echo</span> <span class="s2">"-----"</span><span class="p">;</span><span class="nb">sleep </span>1<span class="p">;</span><span class="k">done</span>

<span class="nv">$ </span>kubectl <span class="nb">exec </span>netpod <span class="nt">--</span> tcpdump <span class="nt">-enni</span> any <span class="nt">-q</span>
<span class="c"># =&gt; 15:01:03.468433 eth0  Out ifindex 18 52:59:78:2f:c0:be 172.16.0.147.57744 &amp;gt; 172.16.1.247.80: tcp 0</span>
<span class="c">#    15:01:03.468761 eth0  In  ifindex 18 7e:77:fa:0a:d3:cc 172.16.1.247.80 &amp;gt; 172.16.0.147.57744: tcp 0</span>
<span class="c">#    15:01:03.468801 eth0  Out ifindex 18 52:59:78:2f:c0:be 172.16.0.147.57744 &amp;gt; 172.16.1.247.80: tcp 0</span>
<span class="c">#    15:01:03.469249 eth0  Out ifindex 18 52:59:78:2f:c0:be 172.16.0.147.57744 &amp;gt; 172.16.1.247.80: tcp 76</span>
<span class="c">#    15:01:03.469852 eth0  In  ifindex 18 7e:77:fa:0a:d3:cc 172.16.1.247.80 &amp;gt; 172.16.0.147.57744: tcp 0</span>
<span class="c">#    15:01:03.469852 eth0  In  ifindex 18 7e:77:fa:0a:d3:cc 172.16.1.247.80 &amp;gt; 172.16.0.147.57744: tcp 312</span>
<span class="c">#    15:01:03.469888 eth0  Out ifindex 18 52:59:78:2f:c0:be 172.16.0.147.57744 &amp;gt; 172.16.1.247.80: tcp 0</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 파드에서 SVC(ClusterIP) 접속 시 tcpdump 로 확인 &gt;&gt; 파드 내부 캡쳐인데,&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;    SVC(10.10.200.121)는 보이지 않고, DNAT 된 web-pod 의 IP가 확인됩니다! It's Magic!&lt;/span&gt;</span>

<span class="nv">$ </span>kubectl <span class="nb">exec </span>netpod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s2">"ngrep -tW byline -d eth0 '' 'tcp port 80'"</span>
<span class="c"># =&gt; T 2024/10/01 15:02:58.406586 172.16.0.147:48018 -&amp;gt; 172.16.2.216:80 [AP] #4</span>
<span class="c">#    GET / HTTP/1.1.</span>
<span class="c">#    Host: 10.10.200.121.</span>
<span class="c">#    User-Agent: curl/8.7.1.</span>
<span class="c">#    Accept: */*.</span>
<span class="c">#    ...</span>

<span class="c"># 서비스 정보 확인</span>
<span class="nv">$ </span>c0 service list
<span class="c"># =&gt; ID   Frontend              Service Type   Backend</span>
<span class="c">#    ...</span>
<span class="c">#    11   10.10.200.121:80      ClusterIP      1 =&amp;gt; 172.16.1.247:80 (active)</span>
<span class="c">#                                              2 =&amp;gt; 172.16.2.216:80 (active)</span>
<span class="nv">$ </span>c0 bpf lb list
<span class="c"># =&gt; SERVICE ADDRESS           BACKEND ADDRESS (REVNAT_ID) (SLOT)</span>
<span class="c">#    0.0.0.0:30405 (0)         0.0.0.0:0 (8) (0) [NodePort, non-routable]</span>
<span class="c">#    ...</span>
<span class="c">#    10.10.200.121:80 (1)      172.16.1.247:80 (11) (1)</span>
<span class="c">#    10.10.200.121:80 (2)      172.16.2.216:80 (11) (2)</span>
<span class="c">#    ...</span>

<span class="c"># BPF maps</span>
<span class="nv">$ </span>c0 map list <span class="nt">--verbose</span>
<span class="nv">$ </span>c0 map list <span class="nt">--verbose</span> | <span class="nb">grep </span>lb
<span class="c"># =&gt; ## Map: cilium_lb4_backends_v3</span>
<span class="c">#    ## Map: cilium_lb_affinity_match</span>
<span class="c">#    ## Map: cilium_lb4_source_range</span>
<span class="c">#    ## Map: cilium_lb4_affinity</span>
<span class="c">#    ## Map: cilium_lb4_services_v2</span>
<span class="c">#    ## Map: cilium_lb4_reverse_nat</span>
<span class="c">#    ## Map: cilium_lb4_reverse_sk</span>
<span class="c">#    ## Map: cilium_skip_lb4</span>
<span class="nv">$ </span>c0 map get cilium_lb4_services_v2
<span class="c"># =&gt; Key                       Value                 State   Error</span>
<span class="c">#    ...</span>
<span class="c">#    10.10.200.121:80 (1)      20 0 (11) [0x0 0x0]   sync</span>
<span class="c">#    10.10.200.121:80 (0)      0 2 (11) [0x0 0x0]    sync</span>
<span class="c">#    10.10.200.121:80 (2)      21 0 (11) [0x0 0x0]   sync</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>c0 map get cilium_lb4_backends_v3
<span class="c"># =&gt; Key                       Value                 State   Error</span>
<span class="c">#    ...</span>
<span class="c">#    21    ANY://172.16.2.216    sync</span>
<span class="c">#    20    ANY://172.16.1.247    sync</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>c0 map get cilium_lb4_reverse_nat
<span class="c"># =&gt; Key                       Value                 State   Error</span>
<span class="c">#    ...</span>
<span class="c">#    11    10.10.200.121:80      sync</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>c0 map get cilium_lb4_reverse_sk
<span class="c"># =&gt; Key                       Value                 State   Error</span>
<span class="c">#    ...</span>
<span class="c">#    [172.16.2.216]:20480, 22906     [10.10.200.121]:20480, 2816</span>
<span class="c">#    [172.16.1.247]:20480, 19024     [10.10.200.121]:20480, 2816</span>
<span class="c">#    [172.16.2.216]:20480, 30734     [10.10.200.121]:20480, 2816</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>c0 map get cilium_lxc
<span class="c"># =&gt; Key              Value                                                                                            State   Error</span>
<span class="c">#    172.16.0.147:0   id=2724  sec_id=27629 flags=0x0000 ifindex=19  mac=52:59:78:2F:C0:BE nodemac=7E:77:FA:0A:D3:CC   sync</span>
<span class="c">#    172.16.0.223:0   id=640   sec_id=37523 flags=0x0000 ifindex=9   mac=AE:B8:81:A6:B1:28 nodemac=C2:21:B8:92:DA:FD   sync</span>
<span class="c">#    172.16.0.26:0    id=1606  sec_id=4     flags=0x0000 ifindex=21  mac=A2:52:92:B7:C0:D9 nodemac=C2:C0:3A:67:BE:B2   sync</span>
<span class="c">#    172.16.0.148:0   id=655   sec_id=4124  flags=0x0000 ifindex=23  mac=2E:AF:13:F1:DD:88 nodemac=FA:32:54:4B:16:D7   sync</span>
<span class="nv">$ </span>c0 map get cilium_ipcache
<span class="c"># =&gt; 172.16.2.216/32     identity=64309 encryptkey=0 tunnelendpoint=192.168.10.102, flags=&amp;lt;none&amp;gt;   sync</span>
<span class="c">#    172.16.1.247/32     identity=64309 encryptkey=0 tunnelendpoint=192.168.10.101, flags=&amp;lt;none&amp;gt;   sync</span>
</code></pre></div></div>

<h4 id="prometheus와-grafana를-통한-cilium-모니터링">Prometheus와 Grafana를 통한 Cilium 모니터링</h4>

<h5 id="설정">설정</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 배포</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/cilium/cilium/1.16.3/examples/kubernetes/addons/prometheus/monitoring-example.yaml
<span class="c"># =&gt; namespace/cilium-monitoring created</span>
<span class="c">#    serviceaccount/prometheus-k8s created</span>
<span class="c">#    configmap/grafana-config created</span>
<span class="c">#    configmap/grafana-cilium-dashboard created</span>
<span class="c">#    configmap/grafana-cilium-operator-dashboard created</span>
<span class="c">#    configmap/grafana-hubble-dashboard created</span>
<span class="c">#    configmap/grafana-hubble-l7-http-metrics-by-workload created</span>
<span class="c">#    configmap/prometheus created</span>
<span class="c">#    clusterrole.rbac.authorization.k8s.io/prometheus created</span>
<span class="c">#    clusterrolebinding.rbac.authorization.k8s.io/prometheus created</span>
<span class="c">#    service/grafana created</span>
<span class="c">#    service/prometheus created</span>
<span class="c">#    deployment.apps/grafana created</span>
<span class="c">#    deployment.apps/prometheus created</span>
<span class="nv">$ </span>kubectl get all <span class="nt">-n</span> cilium-monitoring
<span class="c"># =&gt; NAME                              READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/grafana-65d4578dc4-zcmgz      1/1     Running   0          36s</span>
<span class="c">#    pod/prometheus-7cc8784659-bqchf   1/1     Running   0          36s</span>
<span class="c">#    </span>
<span class="c">#    NAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE</span>
<span class="c">#    service/grafana      ClusterIP   10.10.200.223   &amp;lt;none&amp;gt;        3000/TCP   36s</span>
<span class="c">#    service/prometheus   ClusterIP   10.10.200.90    &amp;lt;none&amp;gt;        9090/TCP   36s</span>
<span class="c">#    </span>
<span class="c">#    NAME                         READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/grafana      1/1     1            1           36s</span>
<span class="c">#    deployment.apps/prometheus   1/1     1            1           36s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                    DESIRED   CURRENT   READY   AGE</span>
<span class="c">#    replicaset.apps/grafana-65d4578dc4      1         1         1       36s</span>
<span class="c">#    replicaset.apps/prometheus-7cc8784659   1         1         1       36s</span>

<span class="c"># 파드와 서비스 확인</span>
<span class="nv">$ </span>kubectl get pod,svc,ep <span class="nt">-o</span> wide <span class="nt">-n</span> cilium-monitoring
<span class="c"># =&gt; NAME                              READY   STATUS    RESTARTS   AGE   IP             NODE     NOMINATED NODE   READINESS GATES</span>
<span class="c">#    pod/grafana-65d4578dc4-zcmgz      1/1     Running   0          49s   172.16.1.208   k3s-w1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    pod/prometheus-7cc8784659-bqchf   1/1     Running   0          49s   172.16.1.248   k3s-w1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    </span>
<span class="c">#    NAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE   SELECTOR</span>
<span class="c">#    service/grafana      ClusterIP   10.10.200.223   &amp;lt;none&amp;gt;        3000/TCP   49s   app=grafana</span>
<span class="c">#    service/prometheus   ClusterIP   10.10.200.90    &amp;lt;none&amp;gt;        9090/TCP   49s   app=prometheus</span>
<span class="c">#    </span>
<span class="c">#    NAME                   ENDPOINTS           AGE</span>
<span class="c">#    endpoints/grafana      172.16.1.208:3000   49s</span>
<span class="c">#    endpoints/prometheus   172.16.1.248:9090   49s</span>

<span class="c"># NodePort 설정</span>
<span class="nv">$ </span>kubectl patch svc grafana <span class="nt">-n</span> cilium-monitoring <span class="nt">-p</span> <span class="s1">'{"spec": {"type": "NodePort"}}'</span>
<span class="nv">$ </span>kubectl patch svc prometheus <span class="nt">-n</span> cilium-monitoring <span class="nt">-p</span> <span class="s1">'{"spec": {"type": "NodePort"}}'</span>

<span class="c"># Grafana 웹 접속</span>
<span class="nv">$ GPT</span><span class="o">=</span><span class="si">$(</span>kubectl get svc <span class="nt">-n</span> cilium-monitoring grafana <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.spec.ports[0].nodePort<span class="o">}</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"Grafana URL = http://</span><span class="si">$(</span>curl <span class="nt">-s</span> ipinfo.io/ip<span class="si">)</span><span class="s2">:</span><span class="nv">$GPT</span><span class="s2">"</span>
<span class="c"># =&gt; Grafana URL = http://54.180.146.116:32172</span>

<span class="c"># Prometheus 웹 접속 정보 확인</span>
<span class="nv">$ PPT</span><span class="o">=</span><span class="si">$(</span>kubectl get svc <span class="nt">-n</span> cilium-monitoring prometheus <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.spec.ports[0].nodePort<span class="o">}</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"Prometheus URL = http://</span><span class="si">$(</span>curl <span class="nt">-s</span> ipinfo.io/ip<span class="si">)</span><span class="s2">:</span><span class="nv">$PPT</span><span class="s2">"</span>
<span class="c"># =&gt; Prometheus URL = http://54.180.146.116:30426</span>
</code></pre></div></div>

<h5 id="grafana--prometheus-nodeport-로-웹-접속-후-확인">grafana , prometheus NodePort 로 웹 접속 후 확인</h5>

<p><img src="/assets/2024/kans-3th/w8/20241026_kans_w8_19.png" alt="img.png" class="image-center" />
<em class="image-caption">Prometheus 모니터링 화면</em></p>

<p><img src="/assets/2024/kans-3th/w8/20241026_kans_w8_21.png" alt="img_1.png" class="image-center" />
<em class="image-caption">Grafana 모니터링 화면</em></p>

<h4 id="network-policy-l3-l4-l7">Network Policy (L3, L4, L7)</h4>

<h5 id="cilium-보안-소개">Cilium 보안 소개</h5>

<p>Cilium은 여러 레벨의 보안 기능을 제공합니다. <a href="https://docs.cilium.io/en/stable/security/network/intro/">문서</a>
그 중에서 다음 3가지를 알아보겠습니다.</p>

<ul>
  <li>ID 기반 (L3) : 엔드포인트 간의 연결 정책을 정의할 때, 엔드포인트의 ID를 사용합니다. 이 ID는 엔드포인트의 네트워크 주소와 무관하게 유지되며, 
k8s의 label을 통해 만들어집니다. 즉, 파드간에 공유할 수 있으며, 네트워크 주소가 변경되어도 유지됩니다.
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_22.png" alt="img.png" class="image-center w-80" />
<em class="image-caption"><a href="https://docs.cilium.io/en/stable/security/network/identity/">https://docs.cilium.io/en/stable/security/network/identity/</a></em></li>
  <li>포트기반 (L4) : 엔드포인트 간의 연결 정책을 정의할 때, 포트를 사용합니다. 이는 L3 정책과 함께 사용될 수 있어서,
<code class="language-plaintext highlighter-rouge">role=frontend</code>라는 레이블을 가진 엔드포인트는 443 포트로 outgoing 연결을 허용하고, <code class="language-plaintext highlighter-rouge">role=backend</code>라는 레이블을 가진 엔드포인트는 
443 포트로 incoming 연결을 허용하는 등의 정책을 정의할 수 있습니다.</li>
  <li>어플리케이션 (http) 기반 (L7) : HTTP통신과 RPC 프로토콜의 보안을 위해서 어플리케이션 레벨에서 정밀하게 정책을 정의할 수 있습니다.
이는 HTTP 헤더, 메소드, 경로, 쿼리 파라미터 등을 사용하여 정책을 정의할 수 있습니다.
    <ul>
      <li>프록시 주입 : Envoy - <a href="https://docs.cilium.io/en/stable/security/network/proxy/">Docs</a>, <a href="https://docs.cilium.io/en/stable/security/network/proxy/envoy/">Envoy</a>
        <ul>
          <li>Cilium은 모든 네트워크 연결에 대해 Layer 4 프록시(예) Envoy)를 주입시킬 수 있습니다.
이는 고차원의 네트워크 정책을 강제할 수 있는 기반이 됩니다.
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_23.png" alt="img.png" class="image-center" />
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_24.png" alt="img.png" class="image-center" /></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h5 id="network-policy-관련-ebpf-datapath">Network Policy 관련 eBPF Datapath</h5>

<p><img src="/assets/2024/kans-3th/w8/20241026_kans_w8_25.png" alt="img.png" class="image-center w-80" /></p>

<ul>
  <li>Prefilter : Prefilter는 XDP 프로그램을 통해 수행되며, 최고의 성능을 위해 네트워크 패킷을 필터링하는 prefilter 규칙들을 제공합니다.
특히 CIDR map들을 사용해 IP 주소를 필터링하는 등의 동작을 할 수 있습니다.</li>
  <li>Endpoint policy : 정책에 따라 패킷을 차단/전달하거나, 서비스로 전달하거나, L7로 정책 전달을 할 수 있습니다.
    <ul>
      <li>Cilium datapath는 L3와 L4 정책을 강제하거나, 패킷과 ID를 매핑하는 역할을 수행합니다.</li>
    </ul>
  </li>
  <li>L7 policy : L7 정책은 프록시 트래픽을 Cilium의 userspace proxy instance, 즉 Envoy로 전달합니다. Envoy 는 트래픽을 전달하거나
L7 정책에 의해 차단할 수 있습니다.
    <ul>
      <li>👉 L7 정책은 hook과 Userspace Proxy(envoy)를 사용하기 때문에 성능이 조금 떨어질 수 있습니다.</li>
    </ul>
  </li>
</ul>

<h5 id="실습">실습</h5>

<ul>
  <li>스타워즈에서 영감받은 예제를 통해 Network Policy를 적용해보겠습니다.
    <ul>
      <li>디플로이먼트(웹 서버, deathstar, replicas 2), 파드(xwing, tiefighter), 서비스(ClusterIP, service/deathstar)</li>
    </ul>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 배포</span>
<span class="nv">$ </span>kubectl create <span class="nt">-f</span> https://raw.githubusercontent.com/cilium/cilium/1.16.3/examples/minikube/http-sw-app.yaml
<span class="c"># =&gt; service/deathstar created</span>
<span class="c">#    deployment.apps/deathstar created</span>
<span class="c">#    pod/tiefighter created</span>
<span class="c">#    pod/xwing created</span>
<span class="nv">$ </span>kubectl get all
<span class="c"># =&gt; NAME                             READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/deathstar-689f66b57d-mm72v   1/1     Running   0          15s</span>
<span class="c">#    pod/deathstar-689f66b57d-pz56p   1/1     Running   0          15s</span>
<span class="c">#    pod/tiefighter                   1/1     Running   0          15s</span>
<span class="c">#    pod/xwing                        1/1     Running   0          15s</span>
<span class="c">#    </span>
<span class="c">#    NAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE</span>
<span class="c">#    service/deathstar    ClusterIP   10.10.200.162   &amp;lt;none&amp;gt;        80/TCP    15s</span>
<span class="c">#    service/kubernetes   ClusterIP   10.10.200.1     &amp;lt;none&amp;gt;        443/TCP   8h</span>
<span class="c">#    </span>
<span class="c">#    NAME                        READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/deathstar   2/2     2            2           15s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                   DESIRED   CURRENT   READY   AGE</span>
<span class="c">#    replicaset.apps/deathstar-689f66b57d   2         2         2       15s</span>

<span class="c"># 파드 라벨 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">--show-labels</span>
<span class="c"># =&gt; NAME                         READY   STATUS    RESTARTS   AGE   LABELS</span>
<span class="c">#    deathstar-689f66b57d-mm72v   1/1     Running   0          24s   app.kubernetes.io/name=deathstar,class=deathstar,org=empire,pod-template-hash=689f66b57d</span>
<span class="c">#    deathstar-689f66b57d-pz56p   1/1     Running   0          24s   app.kubernetes.io/name=deathstar,class=deathstar,org=empire,pod-template-hash=689f66b57d</span>
<span class="c">#    tiefighter                   1/1     Running   0          24s   app.kubernetes.io/name=tiefighter,class=tiefighter,org=empire</span>
<span class="c">#    xwing                        1/1     Running   0          24s   app.kubernetes.io/name=xwing,class=xwing,org=alliance</span>

<span class="c"># cilium endpoint 확인</span>
<span class="nv">$ </span>kubectl get ciliumendpoints
<span class="c"># =&gt; NAME                         SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    deathstar-689f66b57d-mm72v   391                 ready            172.16.2.35</span>
<span class="c">#    deathstar-689f66b57d-pz56p   391                 ready            172.16.1.232</span>
<span class="c">#    tiefighter                   9002                ready            172.16.0.5</span>
<span class="c">#    xwing                        10812               ready            172.16.2.31</span>

<span class="nv">$ </span>c0 endpoint list
<span class="c"># =&gt; ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])                                                  IPv6   IPv4           STATUS</span>
<span class="c">#               ENFORCEMENT        ENFORCEMENT</span>
<span class="c">#    ...</span>
<span class="c">#    2481       Disabled           Disabled          9002       k8s:app.kubernetes.io/name=tiefighter                                               172.16.0.5     ready</span>
<span class="c">#                                                               k8s:class=tiefighter</span>
<span class="c">#                                                               k8s:org=empire</span>
<span class="nv">$ </span>c1 endpoint list
<span class="c"># =&gt; ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])                                                        IPv6   IPv4           STATUS</span>
<span class="c">#               ENFORCEMENT        ENFORCEMENT</span>
<span class="c">#    ...</span>
<span class="c">#    1063       Disabled           Disabled          391        k8s:app.kubernetes.io/name=deathstar                                                      172.16.1.232   ready</span>
<span class="c">#                                                               k8s:class=deathstar</span>
<span class="c">#                                                               k8s:org=empire</span>
<span class="nv">$ </span>c2 endpoint list
<span class="c"># =&gt; ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])                                                      IPv6   IPv4           STATUS</span>
<span class="c">#               ENFORCEMENT        ENFORCEMENT</span>
<span class="c">#    ...</span>
<span class="c">#    1695       Disabled           Disabled          391        k8s:app.kubernetes.io/name=deathstar                                                    172.16.2.35    ready</span>
<span class="c">#                                                               k8s:class=deathstar</span>
<span class="c">#                                                               k8s:org=empire</span>
<span class="c">#    2810       Disabled           Disabled          10812      k8s:app.kubernetes.io/name=xwing                                                        172.16.2.31    ready</span>
<span class="c">#                                                               k8s:class=xwing</span>
<span class="c">#                                                               k8s:org=alliance</span>

<span class="c"># 데스스타 SVC(ClusterIP) 접속하여 웹 파드 연결 확인 &gt;&gt; Hubble UI 에서 실시간 확인해보자!</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>xwing <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPOST</span> deathstar.default.svc.cluster.local/v1/request-landing
<span class="c"># =&gt; Ship landed</span>

<span class="nv">$ </span>kubectl <span class="nb">exec </span>tiefighter <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPOST</span> deathstar.default.svc.cluster.local/v1/request-landing
<span class="c"># =&gt; Ship landed</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>hubble observe
</code></pre></div></div>

<p><img src="/assets/2024/kans-3th/w8/20241026_kans_w8_26.png" alt="img.png" /></p>

<ul>
  <li>Identity-Aware and HTTP-Aware Policy Enforcement <code class="language-plaintext highlighter-rouge">Apply an L3/L4 Policy</code> - <a href="https://docs.cilium.io/en/stable/gettingstarted/demo/#apply-an-l3-l4-policy">Link</a> &amp; Hubble CLI - <a href="https://docs.cilium.io/en/stable/gettingstarted/hubble_cli/">링크</a>
    <ul>
      <li>Cilium 에서는 Endpoint IP 대신, <strong>파드</strong>의 <strong>Labels(라벨)</strong>을 사용(기준)하여 <strong>보안 정책을 적용</strong>합니다.</li>
      <li><strong>IP/Port</strong> 필터링을 <strong>L3/L4 네트워크 정책</strong>이라고 합니다.</li>
      <li>아래 처럼 ‘org=empire’ Labels(라벨) 부착된 파드만 허용해보겠습니다.</li>
      <li>Cilium 은 <strong>stateful connection tracking</strong>을 지원하므로 리턴 트래픽은 자동으로 허용됩니다.</li>
    </ul>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># L3/L4 정책 생성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f - 
apiVersion: "cilium.io/v2"
kind: CiliumNetworkPolicy
metadata:
  name: "rule1"
spec:
  description: "L3-L4 policy to restrict deathstar access to empire ships only"
  endpointSelector:
    matchLabels:
      org: empire
      class: deathstar
  ingress:
  - fromEndpoints:
    - matchLabels:
        org: empire
    toPorts:
    - ports:
      - port: "80"
        protocol: TCP
</span><span class="no">EOF
</span><span class="c"># =&gt; ciliumnetworkpolicy.cilium.io/rule1 created</span>

<span class="c"># 정책 확인</span>
<span class="nv">$ </span>kubectl get cnp
<span class="c"># =&gt; NAME    AGE</span>
<span class="c">#    rule1   9s</span>
<span class="nv">$ </span>kubectl describe cnp rule1
<span class="nv">$ </span>c0 policy get
<span class="c"># =&gt; [</span>
<span class="c">#      {</span>
<span class="c">#        &amp;quot;endpointSelector&amp;quot;: {</span>
<span class="c">#          &amp;quot;matchLabels&amp;quot;: {</span>
<span class="c">#            &amp;quot;any:class&amp;quot;: &amp;quot;deathstar&amp;quot;,</span>
<span class="c">#            &amp;quot;any:org&amp;quot;: &amp;quot;empire&amp;quot;,</span>
<span class="c">#            &amp;quot;k8s:io.kubernetes.pod.namespace&amp;quot;: &amp;quot;default&amp;quot;</span>
<span class="c">#          }</span>
<span class="c">#        },</span>
<span class="c">#        &amp;quot;ingress&amp;quot;: [</span>
<span class="c">#          {</span>
<span class="c">#            &amp;quot;fromEndpoints&amp;quot;: [</span>
<span class="c">#              {</span>
<span class="c">#                &amp;quot;matchLabels&amp;quot;: {</span>
<span class="c">#                  &amp;quot;any:org&amp;quot;: &amp;quot;empire&amp;quot;,</span>
<span class="c">#                  &amp;quot;k8s:io.kubernetes.pod.namespace&amp;quot;: &amp;quot;default&amp;quot;</span>
<span class="c">#                }</span>
<span class="c">#              }</span>
<span class="c">#            ],</span>
<span class="c">#            &amp;quot;toPorts&amp;quot;: [</span>
<span class="c">#              {</span>
<span class="c">#                &amp;quot;ports&amp;quot;: [</span>
<span class="c">#                  {</span>
<span class="c">#                    &amp;quot;port&amp;quot;: &amp;quot;80&amp;quot;,</span>
<span class="c">#                    &amp;quot;protocol&amp;quot;: &amp;quot;TCP&amp;quot;</span>
<span class="c">#                  }</span>
<span class="c">#                ]</span>
<span class="c">#              }</span>
<span class="c">#            ]</span>
<span class="c">#          }</span>
<span class="c">#        ],</span>
<span class="c">#        ...</span>
<span class="c">#        &amp;quot;enableDefaultDeny&amp;quot;: {</span>
<span class="c">#          &amp;quot;ingress&amp;quot;: true,</span>
<span class="c">#          &amp;quot;egress&amp;quot;: false</span>
<span class="c">#        },</span>
<span class="c">#        ...</span>
<span class="c">#      }</span>
<span class="c">#    ]</span>

<span class="c"># 파드 curl 접속 시도 시 파드 sh 접속 후 curl 시도하자!</span>
<span class="c"># 데스스타 SVC(ClusterIP) 접속하여 웹 파드 연결 확인 &gt;&gt; Hubble UI 에서 drop 확인!</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>tiefighter <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPOST</span> deathstar.default.svc.cluster.local/v1/request-landing
<span class="c"># =&gt; Ship landed</span>

<span class="nv">$ </span>kubectl <span class="nb">exec </span>xwing <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPOST</span> deathstar.default.svc.cluster.local/v1/request-landing
<span class="c"># =&gt; (없음)</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 접속이 drop 됩니다. xwing은 허용되는 `org=empire`인 엔드포인트가 아닌 `org=alliance`인 엔드포인트이기 때문입니다.&lt;/span&gt;</span>

<span class="c"># hubble cli 모니터링 </span>
<span class="nv">$ </span>hubble observe <span class="nt">--pod</span> xwing
<span class="nv">$ </span>hubble observe <span class="nt">--pod</span> tiefighter
<span class="nv">$ </span>hubble observe <span class="nt">--pod</span> deathstar
<span class="c"># =&gt; Oct 01 16:28:28.825: default/xwing:39224 (ID:10812) &amp;lt;&amp;gt; default/deathstar-689f66b57d-mm72v:80 (ID:391) policy-verdict:none INGRESS DENIED (TCP Flags: SYN)</span>
<span class="c">#    Oct 01 16:28:28.825: default/xwing:39224 (ID:10812) &amp;lt;&amp;gt; default/deathstar-689f66b57d-mm72v:80 (ID:391) Policy denied DROPPED (TCP Flags: SYN)</span>

<span class="nv">$ </span>hubble observe <span class="nt">--pod</span> deathstar <span class="nt">--verdict</span> DROPPED
<span class="c"># =&gt; Oct 01 16:27:50.894: default/xwing:43148 (ID:10812) &amp;lt;&amp;gt; default/deathstar-689f66b57d-pz56p:80 (ID:391) policy-verdict:none INGRESS DENIED (TCP Flags: SYN)</span>
<span class="c">#    Oct 01 16:27:50.894: default/xwing:43148 (ID:10812) &amp;lt;&amp;gt; default/deathstar-689f66b57d-pz56p:80 (ID:391) Policy denied DROPPED (TCP Flags: SYN)</span>
<span class="c">#    Oct 01 16:28:24.676: default/xwing:43148 (ID:10812) &amp;lt;&amp;gt; default/deathstar-689f66b57d-pz56p:80 (ID:391) policy-verdict:none INGRESS DENIED (TCP Flags: SYN)</span>
<span class="c">#    Oct 01 16:28:24.676: default/xwing:43148 (ID:10812) &amp;lt;&amp;gt; default/deathstar-689f66b57d-pz56p:80 (ID:391) Policy denied DROPPED (TCP Flags: SYN)</span>

<span class="c"># Inspecting the Policy</span>
<span class="c"># If we run cilium endpoint list again we will see that the pods with the label org=empire and class=deathstar</span>
<span class="c"># now have ingress policy enforcement enabled as per the policy above.</span>

<span class="c"># endpoint list 에서 정책 적용 확인</span>
<span class="nv">$ </span>c0 endpoint list
<span class="c"># =&gt; ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])                                                  IPv6   IPv4           STATUS</span>
<span class="c">#               ENFORCEMENT        ENFORCEMENT</span>
<span class="c">#    2481       Disabled           Disabled          9002       k8s:app.kubernetes.io/name=tiefighter                                               172.16.0.5     ready</span>
<span class="c">#                                                               k8s:class=tiefighter</span>
<span class="c">#                                                               k8s:org=empire </span>
<span class="nv">$ </span>c1 endpoint list | <span class="nb">grep </span>deathstar
<span class="c"># =&gt; 1063       Enabled            Disabled          391        k8s:app.kubernetes.io/name=deathstar                                                      172.16.1.232   ready</span>
<span class="c">#                                                               k8s:class=deathstar</span>
<span class="nv">$ </span>c2 endpoint list
<span class="c"># =&gt; ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])                                                      IPv6   IPv4           STATUS</span>
<span class="c">#               ENFORCEMENT        ENFORCEMENT</span>
<span class="c">#    1695       Enabled            Disabled          391        k8s:app.kubernetes.io/name=deathstar                                                    172.16.2.35    ready</span>
<span class="c">#                                                               k8s:class=deathstar</span>
<span class="c">#                                                               k8s:org=empire</span>
<span class="c">#    2810       Disabled           Disabled          10812      k8s:app.kubernetes.io/name=xwing                                                        172.16.2.31    ready</span>
<span class="c">#                                                               k8s:class=xwing</span>
<span class="c">#                                                               k8s:org=alliance</span>
</code></pre></div></div>

<ul>
  <li>Identity-Aware and HTTP-Aware Policy Enforcement Apply and Test HTTP-aware L7 Policy - <a href="https://docs.cilium.io/en/stable/gettingstarted/demo/#apply-and-test-http-aware-l7-policy">Docs</a>
    <ul>
      <li>HTTP L7 필터링을 적용 : PUT /v1/exhaust-port 요청을 차단해보겠습니다.</li>
    </ul>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 데스스타 SVC(ClusterIP) 접속</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>tiefighter <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPUT</span> deathstar.default.svc.cluster.local/v1/exhaust-port
<span class="c"># =&gt; Panic: deathstar exploded</span>
<span class="c">#    ...</span>

<span class="c"># POST /v1/request-landing API 호출만 허용 정책으로 기존 정책 내용을 업데이트(configured)!</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f - 
apiVersion: "cilium.io/v2"
kind: CiliumNetworkPolicy
metadata:
  name: "rule1"
spec:
  description: "L7 policy to restrict access to specific HTTP call"
  endpointSelector:
    matchLabels:
      org: empire
      class: deathstar
  ingress:
  - fromEndpoints:
    - matchLabels:
        org: empire
    toPorts:
    - ports:
      - port: "80"
        protocol: TCP
      rules:
        http:
        - method: "POST"
          path: "/v1/request-landing"
</span><span class="no">EOF

</span><span class="c"># 정책 확인</span>
<span class="nv">$ </span>kubectl describe ciliumnetworkpolicies
<span class="c"># =&gt; Name:         rule1</span>
<span class="c">#    Namespace:    default</span>
<span class="c">#    Labels:       &amp;lt;none&amp;gt;</span>
<span class="c">#    Annotations:  &amp;lt;none&amp;gt;</span>
<span class="c">#    API Version:  cilium.io/v2</span>
<span class="c">#    Kind:         CiliumNetworkPolicy</span>
<span class="c">#    Metadata:</span>
<span class="c">#      Creation Timestamp:  2024-10-01T16:24:53Z</span>
<span class="c">#      Generation:          2</span>
<span class="c">#      Resource Version:    32642</span>
<span class="c">#      UID:                 d3527eec-5832-4273-b805-c006c728a8af</span>
<span class="c">#    Spec:</span>
<span class="c">#      Description:  L7 policy to restrict access to specific HTTP call</span>
<span class="c">#      Endpoint Selector:</span>
<span class="c">#        Match Labels:</span>
<span class="c">#          Class:  deathstar</span>
<span class="c">#          Org:    empire</span>
<span class="c">#      Ingress:</span>
<span class="c">#        From Endpoints:</span>
<span class="c">#          Match Labels:</span>
<span class="c">#            Org:  empire</span>
<span class="c">#        To Ports:</span>
<span class="c">#          Ports:</span>
<span class="c">#            Port:      80</span>
<span class="c">#            Protocol:  TCP</span>
<span class="c">#          Rules:</span>
<span class="c">#            Http:</span>
<span class="c">#              Method:  POST</span>
<span class="c">#              Path:    /v1/request-landing</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>c0 policy get

<span class="c"># 모니터링</span>
<span class="nv">$ </span>c1 monitor <span class="nt">-v</span> <span class="nt">--type</span> l7
<span class="nv">$ </span>c2 monitor <span class="nt">-v</span> <span class="nt">--type</span> l7
<span class="c"># =&gt; &amp;lt;- Request http from 0 ([k8s:app.kubernetes.io/name=tiefighter k8s:class=tiefighter k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default k8s:io.cilium.k8s.policy.cluster=default k8s:io.cilium.k8s.policy.serviceaccount=default k8s:io.kubernetes.pod.namespace=default k8s:org=empire]) to 1695 ([k8s:app.kubernetes.io/name=deathstar k8s:class=deathstar k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default k8s:io.cilium.k8s.policy.cluster=default k8s:io.cilium.k8s.policy.serviceaccount=default k8s:io.kubernetes.pod.namespace=default k8s:org=empire]), identity 9002-&amp;gt;391, verdict Forwarded POST http://deathstar.default.svc.cluster.local/v1/request-landing =&amp;gt; 0</span>
<span class="c">#    &amp;lt;- Response http to 0 ([k8s:app.kubernetes.io/name=tiefighter k8s:class=tiefighter k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default k8s:io.cilium.k8s.policy.cluster=default k8s:io.cilium.k8s.policy.serviceaccount=default k8s:io.kubernetes.pod.namespace=default k8s:org=empire]) from 1695 ([k8s:app.kubernetes.io/name=deathstar k8s:class=deathstar k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default k8s:io.cilium.k8s.policy.cluster=default k8s:io.cilium.k8s.policy.serviceaccount=default k8s:io.kubernetes.pod.namespace=default k8s:org=empire]), identity 391-&amp;gt;9002, verdict Forwarded POST http://deathstar.default.svc.cluster.local/v1/request-landing =&amp;gt; 200</span>
<span class="nv">$ </span>hubble observe <span class="nt">--pod</span> deathstar
<span class="nv">$ </span>hubble observe <span class="nt">--pod</span> deathstar <span class="nt">--verdict</span> DROPPED

<span class="c"># 접근 테스트</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>tiefighter <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPOST</span> deathstar.default.svc.cluster.local/v1/request-landing
<span class="c"># =&gt; Ship landed</span>

<span class="nv">$ </span>kubectl <span class="nb">exec </span>tiefighter <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPUT</span> deathstar.default.svc.cluster.local/v1/exhaust-port
<span class="c"># =&gt; Access denied</span>

<span class="c">## hubble cli 에 차단 로그 확인</span>
<span class="nv">$ </span>hubble observe <span class="nt">--pod</span> deathstar <span class="nt">--verdict</span> DROPPED
<span class="c"># =&gt; Oct 01 16:41:48.094: default/tiefighter:51860 (ID:9002) -&amp;gt; default/deathstar-689f66b57d-mm72v:80 (ID:391) http-request DROPPED (HTTP/1.1 PUT http://deathstar.default.svc.cluster.local/v1/exhaust-port)</span>
<span class="c">#    Oct 01 16:41:48.094: default/tiefighter:51860 (ID:9002) &amp;lt;- default/deathstar-689f66b57d-mm72v:80 (ID:391) http-response FORWARDED (HTTP/1.1 403 0ms (PUT http://deathstar.default.svc.cluster.local/v1/exhaust-port))</span>

<span class="nv">$ </span>hubble observe <span class="nt">--pod</span> deathstar <span class="nt">--protocol</span> http
<span class="c"># =&gt; Oct 01 16:39:57.041: default/tiefighter:57616 (ID:9002) &amp;lt;- default/deathstar-689f66b57d-mm72v:80 (ID:391) http-response FORWARDED (HTTP/1.1 200 2ms (POST http://deathstar.default.svc.cluster.local/v1/request-landing))</span>

<span class="c"># 삭제</span>
<span class="nv">$ </span>kubectl delete <span class="nt">-f</span> https://raw.githubusercontent.com/cilium/cilium/1.16.3/examples/minikube/http-sw-app.yaml
<span class="c"># =&gt; service &amp;quot;deathstar&amp;quot; deleted</span>
<span class="c">#    deployment.apps &amp;quot;deathstar&amp;quot; deleted</span>
<span class="c">#    pod &amp;quot;tiefighter&amp;quot; deleted</span>
<span class="c">#    pod &amp;quot;xwing&amp;quot; deleted</span>
<span class="nv">$ </span>kubectl delete cnp rule1
<span class="c"># =&gt; ciliumnetworkpolicy.cilium.io &amp;quot;rule1&amp;quot; deleted</span>
</code></pre></div></div>

<h4 id="bandwidth-manager">Bandwidth Manager</h4>

<h5 id="bandwidth-manager-소개">Bandwidth Manager 소개</h5>

<ul>
  <li>Cilium은 Bandwidth(네트워크 대역폭)과 Latency optimization(지연 시간 최적화)를 지원합니다. - <a href="https://docs.cilium.io/en/stable/network/kubernetes/bandwidth-manager/">Link</a> , <a href="https://cilium.io/use-cases/bandwidth-optimization/">Home</a> , <a href="https://www.youtube.com/watch?v=QTSS6ktK8hY">Youtube</a>
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_27.png" alt="img.png" class="image-center w-80" />
<em class="image-caption"><a href="https://cilium.io/use-cases/bandwidth-optimization/">https://cilium.io/use-cases/bandwidth-optimization/</a></em>
    <ul>
      <li>bandwidth manager는 TCP와 UDP 부하를 최적화 하고, 효율적으로 개별 파드의 접속률을 제한할 수 있습니다. - <strong>EDT</strong>(Earliest Departure Time) 와 <strong>eBPF</strong> 사용</li>
      <li><code class="language-plaintext highlighter-rouge">kubernetes.io/egress-bandwidth</code> Pod <strong>annotation</strong> 은 egress 트래픽에 대해 호스트 네트워크 장치의 대역폭 제한을 설정합니다.</li>
      <li><del><code class="language-plaintext highlighter-rouge">kubernetes.io/ingress-bandwidth</code></del> <strong>annotation</strong> 은 지원되지 않습니다.</li>
      <li>direct routing mode, tunneling mode 둘 다 지원합니다.</li>
      <li>Limitations : L7 정책과 함께 사용할 수 없습니다.
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_28.png" alt="img.png" class="image-center w-80" /></li>
    </ul>
  </li>
</ul>

<h5 id="설정-및-확인">설정 및 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 인터페이스 tc qdisc 확인</span>
<span class="nv">$ </span>tc qdisc show dev enp0s8
<span class="c"># =&gt; qdisc fq_codel 0: root refcnt 2 limit 10240p flows 1024 quantum 1514 target 5ms interval 100ms memory_limit 32Mb ecn drop_batch 64</span>
<span class="c">#    qdisc clsact ffff: parent ffff:fff1</span>

<span class="c"># 설정</span>
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--namespace</span> kube-system <span class="nt">--reuse-values</span> <span class="nt">--set</span> bandwidthManager.enabled<span class="o">=</span><span class="nb">true</span>
<span class="c"># =&gt; Release &amp;quot;cilium&amp;quot; has been upgraded. Happy Helming!</span>
<span class="c">#    ...</span>

<span class="c"># 적용 확인</span>
<span class="nv">$ </span>cilium config view | <span class="nb">grep </span>bandwidth
<span class="c"># =&gt; enable-bandwidth-manager                          true</span>

<span class="c"># egress bandwidth limitation 동작하는 인터페이스 확인</span>
<span class="nv">$ </span>c0 status | <span class="nb">grep  </span>BandwidthManager
<span class="c"># =&gt; BandwidthManager:        EDT with BPF [CUBIC] [enp0s3, enp0s8]</span>

<span class="c"># 인터페이스 tc qdisc 확인 : 설정 전후 옵션값들이 상당히 추가된다</span>
<span class="nv">$ </span>tc qdisc
<span class="nv">$ </span>tc qdisc show dev enp0s8
<span class="c"># =&gt; qdisc fq 8006: root refcnt 2 limit 10000p flow_limit 100p buckets 32768 orphan_mask 1023 quantum 3028b initial_quantum 15140b low_rate_threshold 550Kbit refill_delay 40ms timer_slack 10us horizon 2s horizon_cap</span>
<span class="c">#    qdisc clsact ffff: parent ffff:fff1</span>
</code></pre></div></div>

<h5 id="동작-및-확인">동작 및 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 테스트를 위한 트래픽 발생 서버/클라이언트 파드 생성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
---
apiVersion: v1
kind: Pod
metadata:
  annotations:
    # Limits egress bandwidth to 10Mbit/s.
    kubernetes.io/egress-bandwidth: "10M"
  labels:
    # This pod will act as server.
    app.kubernetes.io/name: netperf-server
  name: netperf-server
spec:
  containers:
  - name: netperf
    image: cilium/netperf
    ports:
    - containerPort: 12865
---
apiVersion: v1
kind: Pod
metadata:
  # This Pod will act as client.
  name: netperf-client
spec:
  affinity:
    # Prevents the client from being scheduled to the
    # same node as the server.
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: app.kubernetes.io/name
            operator: In
            values:
            - netperf-server
        topologyKey: kubernetes.io/hostname
  containers:
  - name: netperf
    args:
    - sleep
    - infinity
    image: cilium/netperf
</span><span class="no">EOF
</span><span class="c"># =&gt; pod/netperf-server created</span>
<span class="c">#    pod/netperf-client created</span>

<span class="c"># egress BW 제한 정보 확인</span>
<span class="nv">$ </span>kubectl describe pod netperf-server | <span class="nb">grep </span>Annotations:
<span class="c"># =&gt; Annotations:      kubernetes.io/egress-bandwidth: 10M</span>

<span class="c"># egress BW 제한이 설정된 파드가 있는 cilium pod 에서 제한 정보 확인</span>
<span class="nv">$ </span>c0 bpf bandwidth list
<span class="nv">$ </span>c1 bpf bandwidth list
<span class="nv">$ </span>c2 bpf bandwidth list
<span class="c"># =&gt; IDENTITY   EGRESS BANDWIDTH (BitsPerSec)</span>
<span class="c">#    1391       10M</span>

<span class="nv">$ </span>c0 endpoint list
<span class="nv">$ </span>c1 endpoint list
<span class="nv">$ </span>c2 endpoint list
<span class="c"># =&gt; ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])                                                      IPv6   IPv4           STATUS</span>
<span class="c">#               ENFORCEMENT        ENFORCEMENT</span>
<span class="c">#    1391       Disabled           Disabled          8191       k8s:app.kubernetes.io/name=netperf-server                                               172.16.2.106   ready</span>
<span class="c">#    ...</span>

<span class="c"># 트래픽 발생 &gt;&gt; Hubble UI 에서 확인</span>
<span class="c"># egress traffic of the netperf-server Pod has been limited to 10Mbit per second. </span>
<span class="nv">$ NETPERF_SERVER_IP</span><span class="o">=</span><span class="si">$(</span>kubectl get pod netperf-server <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.podIP}'</span><span class="si">)</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>netperf-client <span class="nt">--</span> netperf <span class="nt">-t</span> TCP_MAERTS <span class="nt">-H</span> <span class="s2">"</span><span class="k">${</span><span class="nv">NETPERF_SERVER_IP</span><span class="k">}</span><span class="s2">"</span>
<span class="c"># =&gt; Recv   Send    Send</span>
<span class="c">#    Socket Socket  Message  Elapsed</span>
<span class="c">#    Size   Size    Size     Time     Throughput</span>
<span class="c">#    bytes  bytes   bytes    secs.    10^6bits/sec</span>
<span class="c">#    131072  16384  16384    10.01       9.13</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 10Mbps 제한 확인!&lt;/span&gt;</span>

<span class="c"># 5M 제한 설정 후 테스트</span>
<span class="nv">$ </span>kubectl get pod netperf-server <span class="nt">-o</span> json | <span class="nb">sed</span> <span class="nt">-e</span> <span class="s1">'s|10M|5M|g'</span> | kubectl apply <span class="nt">-f</span> -
<span class="c"># =&gt; pod/netperf-server configured</span>
<span class="nv">$ </span>c0 bpf bandwidth list
<span class="nv">$ </span>c1 bpf bandwidth list
<span class="nv">$ </span>c2 bpf bandwidth list
<span class="c"># =&gt; IDENTITY   EGRESS BANDWIDTH (BitsPerSec)</span>
<span class="c">#    1391       5M</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>netperf-client <span class="nt">--</span> netperf <span class="nt">-t</span> TCP_MAERTS <span class="nt">-H</span> <span class="s2">"</span><span class="k">${</span><span class="nv">NETPERF_SERVER_IP</span><span class="k">}</span><span class="s2">"</span>
<span class="c"># =&gt; Recv   Send    Send</span>
<span class="c">#    Socket Socket  Message  Elapsed</span>
<span class="c">#    Size   Size    Size     Time     Throughput</span>
<span class="c">#    bytes  bytes   bytes    secs.    10^6bits/sec</span>
<span class="c">#    </span>
<span class="c">#    131072  16384  16384    10.01       4.59</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 4.5Mbps 제한 확인!&lt;/span&gt;</span>

<span class="c"># 20M 제한 설정 후 테스트</span>
<span class="nv">$ </span>kubectl get pod netperf-server <span class="nt">-o</span> json | <span class="nb">sed</span> <span class="nt">-e</span> <span class="s1">'s|5M|20M|g'</span> | kubectl apply <span class="nt">-f</span> -
<span class="c"># =&gt; pod/netperf-server configured</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>netperf-client <span class="nt">--</span> netperf <span class="nt">-t</span> TCP_MAERTS <span class="nt">-H</span> <span class="s2">"</span><span class="k">${</span><span class="nv">NETPERF_SERVER_IP</span><span class="k">}</span><span class="s2">"</span>
<span class="c"># =&gt; Recv   Send    Send</span>
<span class="c">#    Socket Socket  Message  Elapsed</span>
<span class="c">#    Size   Size    Size     Time     Throughput</span>
<span class="c">#    bytes  bytes   bytes    secs.    10^6bits/sec</span>
<span class="c">#    131072  16384  16384    10.00      18.40</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 19Mbps 제한 확인!&lt;/span&gt;</span>

<span class="nv">$ </span>tc qdisc show dev enp0s8
<span class="c"># =&gt; qdisc fq 8006: root refcnt 2 limit 10000p flow_limit 100p buckets 32768 orphan_mask 1023 quantum 3028b initial_quantum 15140b low_rate_threshold 550Kbit refill_delay 40ms timer_slack 10us horizon 2s horizon_cap</span>
<span class="c">#    qdisc clsact ffff: parent ffff:fff1</span>

<span class="c"># 삭제</span>
<span class="nv">$ </span>kubectl delete pod netperf-client netperf-server
</code></pre></div></div>

<h4 id="l2-announcements--l2-aware-lb-beta">L2 Announcements / L2 Aware LB (Beta)</h4>

<ul>
  <li>참고 링크 : <a href="https://docs.cilium.io/en/stable/network/l2-announcements/">Link</a> , <a href="https://isovalent.com/blog/post/migrating-from-metallb-to-cilium/">Blog</a></li>
  <li>L2 Announcements는 로컬 영역 네트워크에서 서비스를 표시하고 도달 가능하게 만드는 기능입니다. 
이 기능은 주로 사무실 또는 캠퍼스 네트워크와 같이 BGP 기반 라우팅이 없는 네트워크 내에서 온프레미스 배포를 위해 고안되었습니다.</li>
  <li>이 기능을 사용하면 ExternalIP 및 LoadBalancer IP에 대한 ARP 쿼리에 응답합니다. 
이러한 IP는 여러 노드의 가상 IP(네트워크 장치에 설치되지 않음)이므로 각 서비스에 대해 한 번에 한 노드가 
ARP 쿼리에 응답하고 MAC 주소로 응답합니다.
이 노드는 서비스 로드 밸런싱 기능으로 로드 밸런싱을 수행하여 북쪽/남쪽 로드 밸런서 역할을 합니다.</li>
  <li>NodePort 서비스에 비해 이 기능의 장점은 각 서비스가 고유한 IP를 사용할 수 있으므로 여러 서비스가 동일한 포트 번호를
사용할 수 있다는 것입니다. 
NodePort를 사용할 때 트래픽을 보낼 호스트를 결정하는 것은 클라이언트에게 달려 있으며 노드가 다운되면
IP+Port 콤보를 사용할 수 없게 됩니다. L2 공지를 사용하면 서비스 VIP가 다른 노드로 간단히 마이그레이션되고 계속 작동합니다.</li>
  <li>이를 통해 MetalLB와 같은 외부 로드 밸런서를 Cilium으로 대체할 수 있습니다.</li>
</ul>

<p><img src="/assets/2024/kans-3th/w8/20241026_kans_w8_29.png" alt="img.png" class="image-center w-80" />
<em class="image-caption"><a href="https://isovalent.com/blog/post/migrating-from-metallb-to-cilium/">https://isovalent.com/blog/post/migrating-from-metallb-to-cilium/</a></em></p>

<h5 id="설정-및-확인-1">설정 및 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--namespace</span> kube-system <span class="nt">--reuse-values</span> <span class="se">\</span>
  <span class="nt">--set</span> l2announcements.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> externalIPs.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> l2announcements.leaseDuration<span class="o">=</span>3s <span class="nt">--set</span> l2announcements.leaseRenewDeadline<span class="o">=</span>1s <span class="nt">--set</span> l2announcements.leaseRetryPeriod<span class="o">=</span>200ms
<span class="c"># =&gt; Release &amp;quot;cilium&amp;quot; has been upgraded. Happy Helming!</span>
<span class="c">#    ...</span>
 
<span class="c">#</span>
<span class="nv">$ </span>c0 config <span class="nt">--all</span> | <span class="nb">grep </span>L2
<span class="c"># =&gt; EnableL2Announcements             : true</span>
<span class="c">#    EnableL2NeighDiscovery            : true</span>

<span class="c"># CiliumL2AnnouncementPolicy 생성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f - 
apiVersion: "cilium.io/v2alpha1"
kind: CiliumL2AnnouncementPolicy
metadata:
  name: policy1
spec:
  serviceSelector:
    matchLabels:
      color: blue
  nodeSelector:
    matchExpressions:
      - key: node-role.kubernetes.io/control-plane
        operator: DoesNotExist
  interfaces:
  - ^enp0s[0-9]+
  externalIPs: true
  loadBalancerIPs: true
</span><span class="no">EOF
</span><span class="c"># =&gt; ciliuml2announcementpolicy.cilium.io/policy1 created</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get ciliuml2announcementpolicy
<span class="c"># =&gt; NAME      AGE</span>
<span class="c">#    policy1   7s</span>
<span class="nv">$ </span>kubectl describe l2announcement

<span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f - 
apiVersion: "cilium.io/v2alpha1"
kind: CiliumLoadBalancerIPPool
metadata:
  name: "cilium-pool"
spec:
  allowFirstLastIPs: "No"
  blocks:
  - cidr: "10.10.200.0/29"
</span><span class="no">EOF
</span><span class="c"># =&gt; ciliumloadbalancerippool.cilium.io/cilium-pool created</span>

<span class="c"># cilium ip pool 조회</span>
<span class="nv">$ </span>kubectl get CiliumLoadBalancerIPPool
<span class="c"># =&gt; NAME          DISABLED   CONFLICTING   IPS AVAILABLE   AGE</span>
<span class="c">#    cilium-pool   false      False         6               9s</span>
</code></pre></div></div>

<h5 id="테스트용-파드-서비스-생성">테스트용 파드, 서비스 생성</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: webpod1
  labels:
    app: webpod
spec:
  nodeName: k3s-w1
  containers:
  - name: container
    image: traefik/whoami
  terminationGracePeriodSeconds: 0
---
apiVersion: v1
kind: Pod
metadata:
  name: webpod2
  labels:
    app: webpod
spec:
  nodeName: k3s-w2
  containers:
  - name: container
    image: traefik/whoami
  terminationGracePeriodSeconds: 0
---
apiVersion: v1
kind: Service
metadata:
  name: svc1
spec:
  ports:
    - name: svc1-webport
      port: 80
      targetPort: 80
  selector:
    app: webpod
  type: LoadBalancer  # 👉 서비스 타입이 LoadBalancer
---
apiVersion: v1
kind: Service
metadata:
  name: svc2
spec:
  ports:
    - name: svc2-webport
      port: 80
      targetPort: 80
  selector:
    app: webpod
  type: LoadBalancer  # 👉 서비스 타입이 LoadBalancer
---
apiVersion: v1
kind: Service
metadata:
  name: svc3
spec:
  ports:
    - name: svc3-webport
      port: 80
      targetPort: 80
  selector:
    app: webpod
  type: LoadBalancer  # 👉 서비스 타입이 LoadBalancer
</span><span class="no">EOF
</span><span class="c"># =&gt; pod/webpod1 created</span>
<span class="c">#    pod/webpod2 created</span>
<span class="c">#    service/svc1 created</span>
<span class="c">#    service/svc2 created</span>
<span class="c">#    service/svc3 created</span>
</code></pre></div></div>

<h5 id="접속-확인">접속 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>kubectl get svc,ep
<span class="c"># =&gt; NAME                 TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE</span>
<span class="c">#    service/kubernetes   ClusterIP      10.10.200.1     &amp;lt;none&amp;gt;        443/TCP        10h</span>
<span class="c">#    service/svc1         LoadBalancer   10.10.200.214   10.10.200.1   80:30456/TCP   98s</span>
<span class="c">#    service/svc2         LoadBalancer   10.10.200.240   10.10.200.2   80:30367/TCP   98s</span>
<span class="c">#    service/svc3         LoadBalancer   10.10.200.155   10.10.200.3   80:31800/TCP   98s</span>
<span class="c">#    </span>
<span class="c">#    NAME                   ENDPOINTS                        AGE</span>
<span class="c">#    endpoints/kubernetes   192.168.10.10:6443               10h</span>
<span class="c">#    endpoints/svc1         172.16.1.32:80,172.16.2.115:80   98s</span>
<span class="c">#    endpoints/svc2         172.16.1.32:80,172.16.2.115:80   98s</span>
<span class="c">#    endpoints/svc3         172.16.1.32:80,172.16.2.115:80   98s</span>

<span class="c">#</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> 10.10.200.1
<span class="c"># =&gt; Hostname: webpod1</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: 172.16.1.32</span>
<span class="c">#    RemoteAddr: 192.168.10.10:58036</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: 10.10.200.1</span>
<span class="c">#    User-Agent: curl/7.81.0</span>
<span class="c">#    Accept: */*</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> 10.10.200.2
<span class="c"># =&gt; Hostname: webpod2</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: 172.16.2.115</span>
<span class="c">#    RemoteAddr: 192.168.10.10:53496</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: 10.10.200.2</span>
<span class="c">#    User-Agent: curl/7.81.0</span>
<span class="c">#    Accept: */*</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> 10.10.200.3
<span class="c"># =&gt; Hostname: webpod1</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: 172.16.1.32</span>
<span class="c">#    RemoteAddr: 192.168.10.10:54098</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: 10.10.200.3</span>
<span class="c">#    User-Agent: curl/7.81.0</span>
<span class="c">#    Accept: */*</span>
</code></pre></div></div>

<p>이상과 같이 Cilium 만으로 Loadbalancer유형의 Service를 구성할 수 있었습니다.</p>

<hr />

<h2 id="마치며">마치며</h2>

<p>이번 글에서는 Cilium CNI의 다양한 기능들을 살펴보았습니다.
Cilium CNI은 알면 알수록 “끝판왕”, “It’s magic!”이라는 말이 계속 떠올랐습니다.
아래의 말과 참 맞닿는것 같습니다.</p>

<blockquote>
  <p>“충분히 발달한 과학 기술은 마법과 구별할 수 없다” - 아서 클라크</p>
</blockquote>

<p>스터디 중에도 가시다 님이 “됩니다”를 연발하셔서 “다 되는 페이” KB 페이 광고가 생각났습니다. 
정말 다 되는 CNI인것 같습니다.
물론 eBPF나 Envoy와 같은 기술들이 있었기에 Cilium이 가능한 것이지만, 참 대단합니다.
이번에 실습한것 외에도 더 다양한 기능들이 있어서, 더욱더 공부해야겠다는 생각이 듭니다.</p>

<p>어느덧 다음주가 마지막 주차입니다. 이런 저런 일들로 스터디 포기할까 하는 때도 있었는데 어찌저찌 잘 버텼습니다. 
다음주에는 좀 더 일찍 과제를 제출할 수 있기를 바라며
이만 포스팅을 마치겠습니다.</p>]]></content><author><name></name></author><category term="kans" /><category term="kubernetes," /><category term="network," /><category term="linux" /><summary type="html"><![CDATA[이번주에는 드디어 CNI의 끝판 왕(제가 아는 한에서)인 Cilium에 대해 알아보겠습니다.]]></summary></entry></feed>