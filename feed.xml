<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="ko"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://sweetlittlebird.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://sweetlittlebird.github.io/" rel="alternate" type="text/html" hreflang="ko" /><updated>2025-06-28T18:02:05+09:00</updated><id>https://sweetlittlebird.github.io/feed.xml</id><title type="html">Sweet Little Bird</title><subtitle>공부 기록과 개발 이야기를 담은 블로그입니다.</subtitle><entry><title type="html">MacOS 업데이트 후 Magnet이 자동 시작이 안 될 때 해결 방법</title><link href="https://sweetlittlebird.github.io/posts/2025-06-28-MacOS-%EC%97%85%EB%8D%B0%EC%9D%B4%ED%8A%B8-%ED%9B%84-Magnet%EC%9D%B4-%EC%9E%90%EB%8F%99-%EC%8B%9C%EC%9E%91%EC%9D%B4-%EC%95%88-%EB%90%A0-%EB%95%8C-%ED%95%B4%EA%B2%B0-%EB%B0%A9%EB%B2%95/" rel="alternate" type="text/html" title="MacOS 업데이트 후 Magnet이 자동 시작이 안 될 때 해결 방법" /><published>2025-06-28T10:00:00+09:00</published><updated>2025-06-28T10:00:00+09:00</updated><id>https://sweetlittlebird.github.io/posts/MacOS%20%EC%97%85%EB%8D%B0%EC%9D%B4%ED%8A%B8%20%ED%9B%84%20Magnet%EC%9D%B4%20%EC%9E%90%EB%8F%99%20%EC%8B%9C%EC%9E%91%EC%9D%B4%20%EC%95%88%20%EB%90%A0%20%EB%95%8C%20%ED%95%B4%EA%B2%B0%20%EB%B0%A9%EB%B2%95</id><content type="html" xml:base="https://sweetlittlebird.github.io/posts/2025-06-28-MacOS-%EC%97%85%EB%8D%B0%EC%9D%B4%ED%8A%B8-%ED%9B%84-Magnet%EC%9D%B4-%EC%9E%90%EB%8F%99-%EC%8B%9C%EC%9E%91%EC%9D%B4-%EC%95%88-%EB%90%A0-%EB%95%8C-%ED%95%B4%EA%B2%B0-%EB%B0%A9%EB%B2%95/"><![CDATA[<h2 id="들어가며">들어가며</h2>

<p><img src="/assets/2025/2025-06-28/img.png" alt="img.png" class="w-20 image-center" /></p>

<p>Magnet은 MacOS에서 창 관리를 도와주는 유용한 앱입니다. 
유료 앱이고 Mac App Store에서 구매해야 하지만, 그만한 가치를 제공합니다.
무료로 사용할 수 있는 <a href="https://rectangleapp.com/">Rectangle</a>과 같은 대안도 있지만, 
무상 업데이트를 계속 해주고 있고 Mac App Store에서 구매할 수 있기 때문에 믿을 수 있어서
계속 사용하고 있습니다.</p>

<p>하지만 MacOS 업데이트 후 Magnet이 자동으로 시작되지 않는 문제가 발생할 수 있습니다. 이 글에서는 이 문제를 해결하는 방법을 알아보겠습니다.</p>

<h2 id="문제-발생">문제 발생</h2>

<p>MacOS Ventura에서 Sequoia로 업데이트한 후 Magnet이 기능은 정상적으로 동작하지만,
자동으로 시작되지 않는 문제가 발생했습니다.
시스템 설정에서 
<code class="language-plaintext highlighter-rouge">시스템 설정 &gt; 일반 &gt; 로그인 항목</code>에 Magnet이 등록되어있지 않고 
<code class="language-plaintext highlighter-rouge">시스템 설정 &gt; 일반 &gt; 로그인 항목 &gt; + 버튼</code>을 눌러서 Magnet을 추가해도 추가되지 않았습니다.</p>

<p>수동으로 켜면 되지만 매번 수동으로 켜는 것은 번거롭기 때문에
문제 해결 방법을 찾아보았습니다.</p>

<h2 id="해결-방법">해결 방법</h2>

<p><a href="https://www.reddit.com/r/MacOS/comments/101s7d3/magnet_app_does_not_start_on_boot/">레딧 글</a>에서 해결방법을 찾아서
여기에 남겨 봅니다.</p>

<ol>
  <li>접근성 권한 재설정
    <ul>
      <li>Magnet 종료 → <code class="language-plaintext highlighter-rouge">시스템 설정 &gt; 개인정보 보호 및 보안 &gt; 접근성</code>에서 Magnet 비활성화 및 제거</li>
    </ul>
  </li>
  <li>앱 및 설정 파일 완전 삭제
    <ul>
      <li>Magnet 앱을 응용 프로그램 폴더에서 삭제.</li>
      <li>~/Library/Preferences 폴더에서 com.crowdcafe.windowmagnet.plist 파일 삭제.</li>
      <li>휴지통 비우기 및 Mac 재시동.</li>
    </ul>
  </li>
  <li>앱 재설치 및 권한 재부여
    <ul>
      <li>App Store에서 Magnet 최신 버전 다운로드 및 설치.</li>
      <li>Magnet 실행 후 접근성 권한 요청 시, 반드시 허용.</li>
      <li>Magnet 환경설정에서 ‘로그인 시 자동 실행(Launch at Login)’ 옵션 활성화.</li>
    </ul>
  </li>
  <li>문제 지속 시
    <ul>
      <li>위 과정을 반복해도 문제가 계속된다면, Magnet 개발사에 버그 리포트 제출</li>
    </ul>
  </li>
</ol>

<h2 id="마치며">마치며</h2>

<p>이 방법으로 Magnet이 자동으로 시작되지 않는 문제를 해결할 수 있었습니다.
블로그 글을 쓰다보니 해결하는 방법보다 부가적인 내용을 더 많이 작성한 것 같습니다.
이게 맞나 싶긴한데 반년동안 방치했던 블로그를 다시 시작하는 의미로
작성해봅니다. 다음번에는 더 유익한 글로 찾아뵙기를 기원해봅니다. :pray:</p>

<p>ps. 업데이트 후 Magnet에 설정기능이 굉장히 강력해진것을 발견했습니다.
무상으로 이렇게 좋은 기능을 제공해주다니 개발사에 감사할 따름입니다.</p>

<p><img src="/assets/2025/2025-06-28/20250628_magnet.png" alt="img.png" class="w-80 image-center" /></p>]]></content><author><name></name></author><category term="macos," /><category term="troubleshooting" /><category term="macos," /><category term="magnet," /><category term="troubleshooting" /><summary type="html"><![CDATA[Magnet은 MacOS에서 창 관리를 도와주는 유용한 앱입니다. MacOS 업데이트 후 Magnet이 자동으로 시작되지 않는 문제를 해결하는 방법을 알아봅니다.]]></summary></entry><entry><title type="html">[CI/CD] Jenkins CI/ArgoCD + K8S</title><link href="https://sweetlittlebird.github.io/posts/2024-12-22-CICD-Lite-Week3/" rel="alternate" type="text/html" title="[CI/CD] Jenkins CI/ArgoCD + K8S" /><published>2024-12-22T00:01:18+09:00</published><updated>2024-12-22T00:01:18+09:00</updated><id>https://sweetlittlebird.github.io/posts/CICD%20Lite%20-%20Week3</id><content type="html" xml:base="https://sweetlittlebird.github.io/posts/2024-12-22-CICD-Lite-Week3/"><![CDATA[<h2 id="들어가며">들어가며</h2>

<p>이번 주에는 ArgoCD와 Jenkins를 사용하여 Kubernetes로의 배포를 하는 CI/CD를 구성해보겠습니다.</p>

<h2 id="jenkins-ciargocd--k8s">Jenkins CI/ArgoCD + K8S</h2>

<h3 id="실습환경-구성">실습환경 구성</h3>

<ul>
  <li>이번에는 개발 PC에 Jenkins와 Gogs를 설치하고, Kind를 사용하여 Kubernetes 클러스터를 구성하고 ArgoCD를 설치하여 CI/CD를 구성해보겠습니다.</li>
</ul>

<h4 id="jenkins-gogs-설치">Jenkins, Gogs 설치</h4>

<ul>
  <li>Jenkins의 경우 1주차에서 설치하였지만 다시 한번 되짚어 보겠습니다.</li>
  <li>또한 이번에는 Gitlab 클라우드 서비스 대신, 자체 PC에 Gogs를 설치하여 사용해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 작업 디렉토리 생성 후 이동</span>
<span class="nv">$ </span><span class="nb">mkdir </span>cicd-labs
<span class="nv">$ </span><span class="nb">cd </span>cicd-labs

<span class="c"># </span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh"> &gt; docker-compose.yaml
services:

  jenkins:
    container_name: jenkins
    image: jenkins/jenkins
    restart: unless-stopped
    networks:
      - cicd-network
    ports:
      - "8080:8080"
      - "50000:50000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - jenkins_home:/var/jenkins_home

  gogs:
    container_name: gogs
    image: gogs/gogs
    restart: unless-stopped
    networks:
      - cicd-network
    ports:
      - "10022:22"
      - "3000:3000"
    volumes:
      - gogs-data:/data

volumes:
  jenkins_home:
  gogs-data:

networks:
  cicd-network:
    driver: bridge
</span><span class="no">EOT


</span><span class="c"># 배포</span>
<span class="nv">$ </span>docker compose up <span class="nt">-d</span>
<span class="c"># =&gt; [+] Running 2/2</span>
<span class="c">#     ⠿ Container jenkins  Started  0.5s</span>
<span class="c">#     ⠿ Container gogs     Started  0.5s</span>
<span class="nv">$ </span>docker compose ps
<span class="c"># =&gt; NAME                COMMAND                  SERVICE             STATUS              PORTS</span>
<span class="c">#    gogs                &amp;quot;/app/gogs/docker/st…&amp;quot;   gogs                running (healthy)   0.0.0.0:10022-&amp;gt;22/tcp, 0.0.0.0:3000-&amp;gt;3000/tcp</span>
<span class="c">#    jenkins             &amp;quot;/usr/bin/tini -- /u…&amp;quot;   jenkins             running             0.0.0.0:8080-&amp;gt;8080/tcp, 0.0.0.0:50000-&amp;gt;50000/tcp</span>

<span class="c"># 기본 정보 확인</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>gogs jenkins <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; container : </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker compose <span class="nb">exec</span> <span class="nv">$i</span> sh <span class="nt">-c</span> <span class="s2">"whoami &amp;&amp; pwd"</span><span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; container : gogs &amp;lt;&amp;lt;</span>
<span class="c">#    root</span>
<span class="c">#    /app/gogs</span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; container : jenkins &amp;lt;&amp;lt;</span>
<span class="c">#    jenkins</span>
<span class="c">#    /</span>

<span class="c"># 도커를 이용하여 각 컨테이너로 접속</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins bash
<span class="nv">$ </span><span class="nb">exit</span>

<span class="nv">$ </span>docker compose <span class="nb">exec </span>gogs bash
<span class="nv">$ </span><span class="nb">exit</span>
</code></pre></div></div>

<h4 id="jenkins-컨테이너-초기설정">Jenkins 컨테이너 초기설정</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Jenkins 초기 암호 확인</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins <span class="nb">cat</span> /var/jenkins_home/secrets/initialAdminPassword
<span class="c"># =&gt; 3da38dccc7d14d1a8bee4b02c4e09da8</span>

<span class="c"># Jenkins 웹 접속 주소 확인 : 계정 / 암호 입력 &gt;&gt; **admin / qwe123**</span>
<span class="nv">$ </span>open <span class="s2">"http://127.0.0.1:8080"</span> <span class="c"># macOS</span>

<span class="c"># (참고) 로그 확인 : 플러그인 설치 과정 확인</span>
<span class="nv">$ </span>docker compose logs jenkins <span class="nt">-f</span>

<span class="c"># IP 확인 (MacOS 기준)</span>
<span class="nv">$ </span>ifconfig | <span class="nb">grep</span> <span class="s2">"inet "</span> | <span class="nb">grep</span> <span class="nt">-v</span> 127.0.0
<span class="c"># =&gt; inet &lt;span style="color: red;"&gt;10.0.4.3&lt;/span&gt; netmask 0xffffff00 broadcast 10.0.4.255</span>
<span class="c"># 또는</span>
<span class="nv">$ </span>ipconfig getifaddr en0
<span class="c"># =&gt; &lt;span style="color: red;"&gt;10.0.4.3&lt;/span&gt;</span>
</code></pre></div></div>

<ul>
  <li>Jenkins URL 설정</li>
</ul>

<p>앞서 확인한 IP 주소를 이용하여 Jenkins URL을 설정합니다.</p>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_1.png" alt="img.png" /></p>

<ul>
  <li>1주차때와 마찬가지로 Docker-out-of-Docker를 사용하겠습니다. 자세한 내용은 <a href="https://sweetlittlebird.github.io/posts/2024-12-08-CICD-Lite-Week1/#jenkins-%EC%86%8C%EA%B0%9C">1주차 내용</a>을 참고하세요.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Jenkins 컨테이너 내부에 도커 실행 파일 설치</span>
<span class="nv">$ </span>docker compose <span class="nb">exec</span> <span class="nt">--privileged</span> <span class="nt">-u</span> root jenkins bash
<span class="nt">-----------------------------------------------------</span>
<span class="nv">$ </span><span class="nb">id</span>

<span class="nv">$ </span>curl <span class="nt">-fsSL</span> https://download.docker.com/linux/debian/gpg <span class="nt">-o</span> /etc/apt/keyrings/docker.asc
<span class="c"># =&gt; uid=0(root) gid=0(root) groups=0(root)</span>
<span class="nv">$ </span><span class="nb">chmod </span>a+r /etc/apt/keyrings/docker.asc
<span class="nv">$ </span><span class="nb">echo</span> <span class="se">\</span>
  <span class="s2">"deb [arch=</span><span class="si">$(</span>dpkg <span class="nt">--print-architecture</span><span class="si">)</span><span class="s2"> signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/debian </span><span class="se">\</span><span class="s2">
  </span><span class="si">$(</span><span class="nb">.</span> /etc/os-release <span class="o">&amp;&amp;</span> <span class="nb">echo</span> <span class="s2">"</span><span class="nv">$VERSION_CODENAME</span><span class="s2">"</span><span class="si">)</span><span class="s2"> stable"</span> | <span class="se">\</span>
  <span class="nb">tee</span> /etc/apt/sources.list.d/docker.list <span class="o">&gt;</span> /dev/null
<span class="nv">$ </span>apt-get update <span class="o">&amp;&amp;</span> apt <span class="nb">install </span>docker-ce-cli curl tree jq yq <span class="nt">-y</span>

<span class="nv">$ </span>docker info
<span class="c"># =&gt; Client: Docker Engine - Community</span>
<span class="c">#     Version:    27.4.1</span>
<span class="c">#     Context:    default</span>
<span class="c">#     Debug Mode: false</span>
<span class="c">#     Plugins:</span>
<span class="c">#      buildx: Docker Buildx (Docker Inc.)</span>
<span class="c">#        Version:  v0.19.3</span>
<span class="c">#        Path:     /usr/libexec/docker/cli-plugins/docker-buildx</span>
<span class="c">#      compose: Docker Compose (Docker Inc.)</span>
<span class="c">#        Version:  v2.32.1</span>
<span class="c">#        Path:     /usr/libexec/docker/cli-plugins/docker-compose</span>
<span class="c">#    </span>
<span class="c">#    Server:</span>
<span class="c">#     Containers: 29</span>
<span class="c">#      Running: 2</span>
<span class="c">#      Paused: 0</span>
<span class="c">#      Stopped: 27</span>
<span class="c">#     Images: 42</span>
<span class="c">#     Server Version: 20.10.12</span>
<span class="c">#     Storage Driver: overlay2</span>
<span class="c">#      Backing Filesystem: extfs</span>
<span class="c">#      Supports d_type: true</span>
<span class="c">#      Native Overlay Diff: true</span>
<span class="c">#      userxattr: false</span>
<span class="c">#     Logging Driver: json-file</span>
<span class="c">#     Cgroup Driver: cgroupfs</span>
<span class="c">#     Cgroup Version: 2</span>
<span class="c">#     ...</span>
<span class="c">#     Insecure Registries:</span>
<span class="c">#      hubproxy.docker.internal:5000</span>
<span class="c">#      127.0.0.0/8</span>
<span class="c">#     Live Restore Enabled: false</span>
<span class="nv">$ </span>docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE             COMMAND                  CREATED        STATUS                    PORTS                                              NAMES</span>
<span class="c">#    110494b9ca48   gogs/gogs         &amp;quot;/app/gogs/docker/st…&amp;quot;   14 hours ago   Up 37 minutes (healthy)   0.0.0.0:3000-&amp;gt;3000/tcp, 0.0.0.0:10022-&amp;gt;22/tcp      gogs</span>
<span class="c">#    8b7c591c828d   jenkins/jenkins   &amp;quot;/usr/bin/tini -- /u…&amp;quot;   14 hours ago   Up 37 minutes             0.0.0.0:8080-&amp;gt;8080/tcp, 0.0.0.0:50000-&amp;gt;50000/tcp   jenkins</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 DooD이기 때문에 호스트에서 동작중인 컨테이너가 보입니다.&lt;/span&gt;</span>
<span class="nv">$ </span>which docker
<span class="c"># =&gt; /usr/bin/docker</span>

<span class="c"># Jenkins 컨테이너 내부에서 root가 아닌 jenkins 유저도 docker를 실행할 수 있도록 권한을 부여</span>
<span class="nv">$ </span>groupadd <span class="nt">-g</span> 2000 <span class="nt">-f</span> docker  <span class="c"># macOS(Container)</span>
<span class="c"># $ groupadd -g 1001 -f docker  # Windows WSL2(Container) &gt;&gt; cat /etc/group 에서 docker 그룹ID를 지정</span>

<span class="nv">$ </span><span class="nb">chgrp </span>docker /var/run/docker.sock
<span class="nv">$ </span><span class="nb">chmod </span>g+w /var/run/docker.sock
<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-l</span> /var/run/docker.sock
<span class="c"># =&gt; srwxrwxr-x 1 root docker 0 Oct 01 06:03 /var/run/docker.sock</span>
<span class="nv">$ </span>usermod <span class="nt">-aG</span> docker jenkins
<span class="nv">$ </span><span class="nb">cat</span> /etc/group | <span class="nb">grep </span>docker
<span class="c"># =&gt; docker:x:2000:jenkins</span>

<span class="nb">exit</span>
<span class="nt">--------------------------------------------</span>

<span class="c"># jenkins item 실행 시 docker 명령 실행 권한 에러 발생 : Jenkins 컨테이너 재기동으로 위 설정 내용을 Jenkins app 에도 적용 필요</span>
<span class="nv">$ </span>docker compose restart jenkins
<span class="c"># =&gt; [+] Running 1/1</span>
<span class="c">#     ⠿ Container jenkins  Started    0.9s</span>
<span class="c"># $ sudo docker compose restart jenkins  # Windows 경우 이후부터 sudo 붙여서 실행하자</span>

<span class="c"># jenkins user로 docker 명령 실행 확인</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins <span class="nb">id</span>
<span class="c"># =&gt; uid=1000(jenkins) gid=1000(jenkins) groups=1000(jenkins),2000(docker)</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins docker info
<span class="c"># =&gt; Client: Docker Engine - Community</span>
<span class="c">#     Version:    27.4.1</span>
<span class="c">#     ...</span>
<span class="c">#    </span>
<span class="c">#    Server:</span>
<span class="c">#     Containers: 29</span>
<span class="c">#      Running: 2</span>
<span class="c">#      Paused: 0</span>
<span class="c">#      Stopped: 27</span>
<span class="c">#     Images: 42</span>
<span class="c">#     Server Version: 20.10.12</span>
<span class="c">#     ...</span>
<span class="c">#     Live Restore Enabled: false</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE             COMMAND                  CREATED        STATUS                    PORTS                                              NAMES</span>
<span class="c">#    110494b9ca48   gogs/gogs         &amp;quot;/app/gogs/docker/st…&amp;quot;   14 hours ago   Up 41 minutes (healthy)   0.0.0.0:3000-&amp;gt;3000/tcp, 0.0.0.0:10022-&amp;gt;22/tcp      gogs</span>
<span class="c">#    8b7c591c828d   jenkins/jenkins   &amp;quot;/usr/bin/tini -- /u…&amp;quot;   14 hours ago   Up 57 seconds             0.0.0.0:8080-&amp;gt;8080/tcp, 0.0.0.0:50000-&amp;gt;50000/tcp   jenkins</span>
</code></pre></div></div>

<ul>
  <li>OS 재부팅시에 jenkins 컨테이너에서 docker 실행이 실패하는 경우가 있는데, 그럴 경우 아래와 같이 docker 그룹을 다시 지정합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 소켓 파일의 권한 확인</span>
<span class="nv">$ </span>docker compose <span class="nb">exec</span> <span class="nt">--privileged</span> <span class="nt">-u</span> root jenkins <span class="nb">ls</span> <span class="nt">-l</span> /var/run/docker.sock
<span class="c"># =&gt; srwxr-xr-x 1 root root 0 Oct 01 05:22 /var/run/docker.sock</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 그룹이 root로 복구되어있습니다. docker 그룹으로 다시 변경해야 합니다.&lt;/span&gt;</span>

<span class="c"># 소켓 파일에 docker 그룹을 다시 지정</span>
<span class="nv">$ </span>docker compose <span class="nb">exec</span> <span class="nt">--privileged</span> <span class="nt">-u</span> root jenkins <span class="nb">chgrp </span>docker /var/run/docker.sock

<span class="c"># 소켓 파일에 docker 그룹 쓰기권한 다시 지정</span>
<span class="nv">$ </span>docker compose <span class="nb">exec</span> <span class="nt">--privileged</span> <span class="nt">-u</span> root jenkins <span class="nb">chmod </span>g+w /var/run/docker.sock

<span class="c"># 확인</span>
<span class="nv">$ </span>docker compose <span class="nb">exec</span> <span class="nt">--privileged</span> <span class="nt">-u</span> root jenkins <span class="nb">ls</span> <span class="nt">-l</span> /var/run/docker.sock
<span class="c"># =&gt; srwxrwxr-x 1 root docker 0 Oct 01 05:22 /var/run/docker.sock</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins docker info
</code></pre></div></div>

<h4 id="gogs-초기-설정">Gogs 초기 설정</h4>

<ul>
  <li>초기설정을 위해 웹 접속을 합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 초기 설정 웹 접속</span>
<span class="nv">$ </span>open <span class="s2">"http://127.0.0.1:3000/install"</span> <span class="c"># macOS</span>
<span class="c"># 웹 브라우저에서 http://127.0.0.1:3000/install 접속 # Windows</span>
</code></pre></div></div>

<ul>
  <li>다음과 같이 설정값을 변경합니다.
    <ul>
      <li>Database Type : SQLite3</li>
      <li>Application URL : <code class="language-plaintext highlighter-rouge">http://&lt;앞에서 확인한 IP&gt;:3000/</code></li>
      <li>Default Branch : main</li>
      <li>관리자 계정 설정 클릭 : username : devops, password : qwe123, email입력
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_2.png" alt="img.png" /></li>
    </ul>
  </li>
  <li>Install Gogs 버튼 클릭 =&gt; 관리자 계정으로 로그인</li>
</ul>

<h5 id="access-token-발행">Access Token 발행</h5>

<ul>
  <li>로그인 후 Your Settings &gt; Applications &gt; Generate New Token 클릭 &gt; Token Name(devops) &gt; Generate Token 클릭하여 토큰을 발행합니다.</li>
  <li>발행된 토큰(<code class="language-plaintext highlighter-rouge">a85f33b7fd28ac1ed83c3233fc4ca3a67c04c296</code>)을 복사하여 안전한 곳에 기록해둡니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_3.png" alt="img.png" /></p>

<h5 id="repository-생성">Repository 생성</h5>

<ul>
  <li>우측상단의 <code class="language-plaintext highlighter-rouge">+</code> 버튼을 클릭하여 나오는 메뉴에서 New Repository를 클릭해서 새로운 Repository를 다음과 같이 2개 생성합니다.</li>
  <li><strong>개발팀용</strong>
    <ul>
      <li>Repository Name : <strong>dev-app</strong></li>
      <li>Visibility : (<strong>Check</strong>) This repository is <strong>Private</strong></li>
      <li>.gitignore : <strong>Python</strong></li>
      <li>Readme : Default → (Check) initialize this repository with selected files and template</li>
    </ul>

    <p>⇒ Create Repository 클릭 =&gt; Repo 주소 확인 (<code class="language-plaintext highlighter-rouge">http://10.0.4.3:3000/devops/dev-apps.git</code>)</p>
  </li>
  <li><strong>데브옵스팀용</strong>
    <ul>
      <li>Repository Name : <strong>ops-deploy</strong></li>
      <li>Visibility : (<strong>체크</strong>) This repository is <strong>Private</strong></li>
      <li>Readme : Default → (체크) initialize this repository with selected files and template</li>
    </ul>

    <p>⇒ Create Repository 클릭 =&gt; Repo 주소 확인 (<code class="language-plaintext highlighter-rouge">http://10.0.4.3:3000/devops/ops-deploy.git</code>)</p>
  </li>
</ul>

<h5 id="gogs-실습을-위해-호스트-pc의-git-설정">Gogs 실습을 위해 호스트 PC의 git 설정</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># (옵션) GIT 인증 정보 초기화</span>
<span class="nv">$ </span>git credential-cache <span class="nb">exit</span>

<span class="c">#</span>
<span class="c"># $ git clone &lt;각자 Gogs dev-app repo 주소&gt;</span>
<span class="nv">$ </span>git clone http://10.0.4.3:3000/devops/dev-app.git
<span class="c"># =&gt; Cloning into 'dev-app'...</span>
<span class="c">#    Username for 'http://10.0.4.3:3000': devops</span>
<span class="c">#    Password for 'http://a@10.0.4.3:3000': # &lt;span style="color: green;"&gt;앞서 발급받은 access key 입력&lt;/span&gt;</span>

<span class="c">#    remote: Enumerating objects: 4, done.</span>
<span class="c">#    remote: Counting objects: 100% (4/4), done.</span>
<span class="c">#    remote: Compressing objects: 100% (3/3), done.</span>
<span class="c">#    remote: Total 4 (delta 0), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    Unpacking objects: 100% (4/4), 705 bytes | 352.00 KiB/s, done.</span>

<span class="c">#</span>
<span class="nv">$ </span><span class="nb">cd </span>dev-app

<span class="c">#</span>
<span class="nv">$ </span>git config user.name <span class="s2">"devops"</span>
<span class="nv">$ </span>git config user.email <span class="s2">"a@a.com"</span>
<span class="nv">$ </span>git config init.defaultBranch main
<span class="nv">$ </span>git config credential.helper store

<span class="c">#</span>
<span class="nv">$ </span>git branch
<span class="c"># =&gt; * main</span>
<span class="nv">$ </span>git remote <span class="nt">-v</span>
<span class="c"># =&gt; origin  http://10.0.4.3:3000/devops/dev-app.git (fetch)</span>
<span class="c">#    origin  http://10.0.4.3:3000/devops/dev-app.git (push)</span>

<span class="c"># server.py 파일 작성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> server.py <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
from http.server import ThreadingHTTPServer, BaseHTTPRequestHandler
from datetime import datetime
import socket

class RequestHandler(BaseHTTPRequestHandler):
    def do_GET(self):
        self.send_response(200)
        self.send_header('Content-type', 'text/plain')
        self.end_headers()
        
        now = datetime.now()
        hostname = socket.gethostname()
        response_string = now.strftime("The time is %-I:%M:%S %p, VERSION 0.0.1</span><span class="se">\n</span><span class="sh">")
        response_string += f"Server hostname: {hostname}</span><span class="se">\n</span><span class="sh">"
        self.wfile.write(bytes(response_string, "utf-8")) 

def startServer():
    try:
        server = ThreadingHTTPServer(('', 80), RequestHandler)
        print("Listening on " + ":".join(map(str, server.server_address)))
        server.serve_forever()
    except KeyboardInterrupt:
        server.shutdown()

if __name__ == "__main__":
    startServer()
</span><span class="no">EOF

</span><span class="c"># Dockerfile 생성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Dockerfile <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
FROM python:3.12
ENV PYTHONUNBUFFERED 1
COPY . /app
WORKDIR /app 
CMD python3 server.py
</span><span class="no">EOF

</span><span class="c"># VERSION 파일 생성</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"0.0.1"</span> <span class="o">&gt;</span> VERSION

<span class="c">#</span>
<span class="nv">$ </span>git status
<span class="c"># =&gt; On branch main</span>
<span class="c">#    Your branch is up to date with 'origin/main'.</span>
<span class="c">#    </span>
<span class="c">#    Untracked files:</span>
<span class="c">#      (use &amp;quot;git add &amp;lt;file&amp;gt;...&amp;quot; to include in what will be committed)</span>
<span class="c">#            Dockerfile</span>
<span class="c">#            VERSION</span>
<span class="c">#            server.py</span>
<span class="c">#    </span>
<span class="c">#    nothing added to commit but untracked files present (use &amp;quot;git add&amp;quot; to track)</span>
<span class="nv">$ </span>git add <span class="nb">.</span>
<span class="nv">$ </span>git commit <span class="nt">-m</span> <span class="s2">"Add dev-app"</span>
<span class="c"># =&gt; [main 3531233] Add dev-app</span>
<span class="c">#     3 files changed, 32 insertions(+)</span>
<span class="c">#     create mode 100644 Dockerfile</span>
<span class="c">#     create mode 100644 VERSION</span>
<span class="c">#     create mode 100644 server.py</span>
<span class="nv">$ </span>git push <span class="nt">-u</span> origin main
<span class="c"># =&gt; Enumerating objects: 6, done.</span>
<span class="c">#    Counting objects: 100% (6/6), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (4/4), done.</span>
<span class="c">#    Writing objects: 100% (5/5), 900 bytes | 900.00 KiB/s, done.</span>
<span class="c">#    Total 5 (delta 0), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To http://10.0.4.3:3000/devops/dev-app.git</span>
<span class="c">#       5c906c3..3531233  main -&amp;gt; main</span>
<span class="c">#    branch 'main' set up to track 'origin/main'.</span>
</code></pre></div></div>

<ul>
  <li>Gogs Repo에서 확인
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_4.png" alt="img.png" /></li>
</ul>

<h4 id="도커-허브--설정">도커 허브  설정</h4>

<ul>
  <li>도커 허브에 로그인하여 dev-app이라는 Repository를 생성합니다. 도커허브 소개와 Repository 생성은 <a href="https://sweetlittlebird.github.io/posts/2024-12-08-CICD-Lite-Week1/#docker-hub-%EC%86%8C%EA%B0%9C">1주차 내용</a>을 참고하세요.</li>
  <li>배포를 편하게 하기위해 Token도 발급하여 사용해보겠습니다.
    <ol>
      <li>계정 &gt; Account Settings &gt; Security 클릭
  <img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_5.png" alt="img.png" class="image-center" /></li>
      <li>New Access Token 클릭
        <ul>
          <li>Token Name : devops</li>
          <li>Expireation date : 만료일을 적절히 선택합니다.</li>
          <li>권한은 Read, Write, Delete를 선택합니다.</li>
          <li>Create 클릭하여 토큰을 생성하고, 발급된 토큰을 복사하여 안전한 곳에 저장합니다.
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_6.png" alt="img.png" class="image-center" />
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_7.png" alt="img_1.png" class="image-center" /></li>
          <li>발급된 토큰 : <code class="language-plaintext highlighter-rouge">dckr_****</code></li>
        </ul>
      </li>
    </ol>
  </li>
</ul>

<hr />

<h3 id="jenkins-ci--k8s-kind">Jenkins CI + K8S (Kind)</h3>

<h4 id="kind-소개-및-설치">Kind 소개 및 설치</h4>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_8.png" alt="img.png" class="w-20 image-center" /></p>

<ul>
  <li>Kind는 Kubernetes in Docker의 줄임말로, 로컬 환경에서 쉽게 Kubernetes 클러스터를 구성할 수 있도록 도와주는 도구입니다.</li>
  <li>이름처럼 Docker를 이용하여 Kubernetes 클러스터를 구성하며, Docker를 이용하기 때문에 다양한 환경에서 쉽게 사용할 수 있습니다.</li>
  <li>Kind는 HA를 포함한 멀티노드를 지원하지만, 테스트와 실험적인 목적으로만 사용하기를 추천합니다.</li>
  <li>Kind는 클러스터를 구성하기 위해 kubeadm을 사용합니다.</li>
  <li><a href="https://sweetlittlebird.github.io/posts/2024-09-07-KANS-Study-Week2/#kind-%EC%86%8C%EA%B0%9C-%EB%B0%8F-%EC%84%A4%EC%B9%98">Kind 소개 및 설치</a>, <a href="https://kind.sigs.k8s.io/docs/user/quick-start/">Kind 공식문서</a></li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_9.png" alt="img.png" class="image-center" />
<em class="image-caption">Kind 구성도</em></p>

<h5 id="kind-및-툴-설치">Kind 및 툴 설치</h5>

<ul>
  <li>필수 툴 설치</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Install Kind</span>
<span class="nv">$ </span>brew <span class="nb">install </span>kind
<span class="nv">$ </span>kind <span class="nt">--version</span>
<span class="c"># =&gt; kind version 0.26.0</span>

<span class="c"># Install kubectl</span>
<span class="nv">$ </span>brew <span class="nb">install </span>kubernetes-cli
<span class="nv">$ </span>kubectl version <span class="nt">--client</span><span class="o">=</span><span class="nb">true</span>
<span class="c"># =&gt; Client Version: v1.31.0</span>
<span class="c">#    Kustomize Version: v5.4.2</span>
<span class="c">#    Kubecolor Version: v0.4.0</span>

<span class="c">## kubectl -&gt; k 단축키 설정</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"alias kubectl=kubecolor"</span> <span class="o">&gt;&gt;</span> ~/.zshrc

<span class="c"># Install Helm</span>
<span class="nv">$ </span>brew <span class="nb">install </span>helm
<span class="nv">$ </span>helm version
<span class="c"># =&gt; version.BuildInfo{Version:&amp;quot;v3.15.4&amp;quot;, GitCommit:&amp;quot;fa9efb07d9d8debbb4306d72af76a383895aa8c4&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;, GoVersion:&amp;quot;go1.22.6&amp;quot;}</span>
</code></pre></div></div>

<ul>
  <li>(권장) 유용한 툴 설치</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 툴 설치</span>
<span class="nv">$ </span>brew <span class="nb">install </span>krew
<span class="nv">$ </span>brew <span class="nb">install </span>kube-ps1
<span class="nv">$ </span>brew <span class="nb">install </span>kubectx

<span class="c"># kubectl 출력 시 하이라이트 처리</span>
<span class="nv">$ </span>brew <span class="nb">install </span>kubecolor
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"alias kubectl=kubecolor"</span> <span class="o">&gt;&gt;</span> ~/.zshrc
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"compdef kubecolor=kubectl"</span> <span class="o">&gt;&gt;</span> ~/.zshrc

<span class="c"># krew 플러그인 설치</span>
<span class="nv">$ </span>kubectl krew <span class="nb">install </span>neat stren
</code></pre></div></div>

<h5 id="kind-기본-사용---클러스터-배포-및-확인">Kind 기본 사용 - 클러스터 배포 및 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 클러스터 배포 전 확인</span>
<span class="nv">$ </span>docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE             COMMAND                  CREATED        STATUS                 PORTS                                              NAMES</span>
<span class="c">#    110494b9ca48   gogs/gogs         &amp;quot;/app/gogs/docker/st…&amp;quot;   19 hours ago   Up 5 hours (healthy)   0.0.0.0:3000-&amp;gt;3000/tcp, 0.0.0.0:10022-&amp;gt;22/tcp      gogs</span>
<span class="c">#    8b7c591c828d   jenkins/jenkins   &amp;quot;/usr/bin/tini -- /u…&amp;quot;   19 hours ago   Up 4 hours             0.0.0.0:8080-&amp;gt;8080/tcp, 0.0.0.0:50000-&amp;gt;50000/tcp   jenkins</span>

<span class="c"># Create a cluster with kind</span>
<span class="nv">$ </span>kind create cluster
<span class="c"># =&gt; Creating cluster &amp;quot;kind&amp;quot; ...</span>
<span class="c">#     ✓ Ensuring node image (kindest/node:v1.32.0) 🖼</span>
<span class="c">#     ✓ Preparing nodes 📦</span>
<span class="c">#     ✓ Writing configuration 📜</span>
<span class="c">#     ✓ Starting control-plane 🕹️</span>
<span class="c">#     ✓ Installing CNI 🔌</span>
<span class="c">#     ✓ Installing StorageClass 💾</span>
<span class="c">#    Set kubectl context to &amp;quot;kind-kind&amp;quot;</span>
<span class="c">#    You can now use your cluster with:</span>
<span class="c">#    </span>
<span class="c">#    kubectl cluster-info --context kind-kind</span>
<span class="c">#    </span>
<span class="c">#    Not sure what to do next? 😅  Check out https://kind.sigs.k8s.io/docs/user/quick-start/</span>

<span class="c"># 클러스터 배포 확인</span>
<span class="nv">$ </span>kind get clusters
<span class="c"># =&gt; kind</span>
<span class="nv">$ </span>kind get nodes
<span class="c"># =&gt; kind-control-plane</span>
<span class="nv">$ </span>kubectl cluster-info
<span class="c"># =&gt; Kubernetes control plane is running at https://127.0.0.1:64234</span>
<span class="c">#    CoreDNS is running at https://127.0.0.1:64234/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</span>
<span class="c">#    </span>
<span class="c">#    To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.</span>

<span class="c"># 노드 정보 확인</span>
<span class="nv">$ </span>kubectl get node <span class="nt">-o</span> wide
<span class="c"># =&gt; NAME                 STATUS   ROLES           AGE   VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE                         KERNEL-VERSION     CONTAINER-RUNTIME</span>
<span class="c">#    kind-control-plane   Ready    control-plane   63s   v1.32.0   172.20.0.2    &amp;lt;none&amp;gt;        Debian GNU/Linux 12 (bookworm)   5.10.76-linuxkit   containerd://1.7.24</span>

<span class="c"># 파드 정보 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE            NAME                                         READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    kube-system          coredns-668d6bf9bc-8pqmk                     1/1     Running   0          67s</span>
<span class="c">#    kube-system          coredns-668d6bf9bc-9ngw2                     1/1     Running   0          67s</span>
<span class="c">#    kube-system          etcd-kind-control-plane                      1/1     Running   0          74s</span>
<span class="c">#    kube-system          kindnet-zlwz2                                1/1     Running   0          67s</span>
<span class="c">#    kube-system          kube-apiserver-kind-control-plane            1/1     Running   0          74s</span>
<span class="c">#    kube-system          kube-controller-manager-kind-control-plane   1/1     Running   0          74s</span>
<span class="c">#    kube-system          kube-proxy-nbp2t                             1/1     Running   0          67s</span>
<span class="c">#    kube-system          kube-scheduler-kind-control-plane            1/1     Running   0          74s</span>
<span class="c">#    local-path-storage   local-path-provisioner-58cc7856b6-wl6z8      1/1     Running   0          67s</span>
<span class="nv">$ </span>kubectl get componentstatuses
<span class="c"># =&gt; NAME                 STATUS    MESSAGE   ERROR</span>
<span class="c">#    controller-manager   Healthy   ok</span>
<span class="c">#    scheduler            Healthy   ok</span>
<span class="c">#    etcd-0               Healthy   ok</span>

<span class="c"># 컨트롤플레인 (컨테이너) 노드 1대가 실행</span>
<span class="nv">$ </span>docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE                  COMMAND                  CREATED              STATUS                 PORTS                                              NAMES</span>
<span class="c">#    3d4063180754   kindest/node:v1.32.0   &amp;quot;/usr/local/bin/entr…&amp;quot;   About a minute ago   Up About a minute      127.0.0.1:64234-&amp;gt;6443/tcp                          kind-control-plane</span>
<span class="c">#    110494b9ca48   gogs/gogs              &amp;quot;/app/gogs/docker/st…&amp;quot;   19 hours ago         Up 5 hours (healthy)   0.0.0.0:3000-&amp;gt;3000/tcp, 0.0.0.0:10022-&amp;gt;22/tcp      gogs</span>
<span class="c">#    8b7c591c828d   jenkins/jenkins        &amp;quot;/usr/bin/tini -- /u…&amp;quot;   19 hours ago         Up 4 hours             0.0.0.0:8080-&amp;gt;8080/tcp, 0.0.0.0:50000-&amp;gt;50000/tcp   jenkins</span>
<span class="nv">$ </span>docker images
<span class="c"># =&gt; REPOSITORY                                                                   TAG           IMAGE ID       CREATED         SIZE</span>
<span class="c">#    kindest/node                                                                 &amp;lt;none&amp;gt;        b5a8f8764a3e   7 days ago      1.05GB</span>

<span class="c"># kube config 파일 확인</span>
<span class="nv">$ </span><span class="nb">cat</span> ~/.kube/config
<span class="c"># 혹은</span>
<span class="c"># $ cat $KUBECONFIG # KUBECONFIG 변수 지정 사용 시</span>

<span class="c"># nginx 파드 배포 및 확인 : 컨트롤플레인 노드인데 파드가 배포 될까요?</span>
<span class="nv">$ </span>kubectl run nginx <span class="nt">--image</span><span class="o">=</span>nginx:alpine
<span class="c"># =&gt; pod/nginx created</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME    READY   STATUS    RESTARTS   AGE   IP           NODE                 NOMINATED NODE   READINESS GATES</span>
<span class="c">#    nginx   1/1     Running   0          10s   10.244.0.5   kind-control-plane   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>

<span class="c"># 노드에 Taints 정보 확인</span>
<span class="nv">$ </span>kubectl describe node | <span class="nb">grep </span>Taints
<span class="c"># =&gt; Taints:             &amp;lt;none&amp;gt;</span>

<span class="c"># 클러스터 삭제</span>
<span class="nv">$ </span>kind delete cluster
<span class="c"># =&gt; Deleting cluster &amp;quot;kind&amp;quot; ...</span>
<span class="c">#    Deleted nodes: [&amp;quot;kind-control-plane&amp;quot;]</span>

<span class="c"># kube config 삭제 확인</span>
<span class="nv">$ </span><span class="nb">cat</span> ~/.kube/config
<span class="c"># 혹은</span>
<span class="c"># $ cat $KUBECONFIG # KUBECONFIG 변수 지정 사용 시</span>
</code></pre></div></div>

<h4 id="kind로-kubernetes-클러스터-배포---3노드">Kind로 Kubernetes 클러스터 배포 - 3노드</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 클러스터 배포 전 확인</span>
<span class="nv">$ </span>docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE             COMMAND                  CREATED        STATUS                 PORTS                                              NAMES</span>
<span class="c">#    110494b9ca48   gogs/gogs         &amp;quot;/app/gogs/docker/st…&amp;quot;   19 hours ago   Up 5 hours (healthy)   0.0.0.0:3000-&amp;gt;3000/tcp, 0.0.0.0:10022-&amp;gt;22/tcp      gogs</span>
<span class="c">#    8b7c591c828d   jenkins/jenkins   &amp;quot;/usr/bin/tini -- /u…&amp;quot;   19 hours ago   Up 4 hours             0.0.0.0:8080-&amp;gt;8080/tcp, 0.0.0.0:50000-&amp;gt;50000/tcp   jenkins</span>

<span class="c"># 방안1 : 환경변수 지정</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">KUBECONFIG</span><span class="o">=</span><span class="nv">$PWD</span>/kubeconfig

<span class="c"># Create a cluster with kind</span>
<span class="c"># $ MyIP=&lt;각자 자신의 PC IP&gt;</span>
<span class="nv">$ MyIP</span><span class="o">=</span>10.0.4.3

<span class="nv">$ </span><span class="nb">cd</span> ..
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> kind-3node.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
networking:
  apiServerAddress: "</span><span class="nv">$MyIP</span><span class="sh">"
nodes:
- role: control-plane
  extraPortMappings:
  - containerPort: 30000
    hostPort: 30000
  - containerPort: 30001
    hostPort: 30001
  - containerPort: 30002
    hostPort: 30002
  - containerPort: 30003
    hostPort: 30003
- role: worker
- role: worker
</span><span class="no">EOF
</span><span class="nv">$ </span>kind create cluster <span class="nt">--config</span> kind-3node.yaml <span class="nt">--name</span> myk8s <span class="nt">--image</span> kindest/node:v1.30.6
<span class="c"># =&gt; Creating cluster &amp;quot;myk8s&amp;quot; ...</span>
<span class="c">#     ✓ Ensuring node image (kindest/node:v1.30.6) 🖼</span>
<span class="c">#     ✓ Preparing nodes 📦 📦 📦</span>
<span class="c">#     ✓ Writing configuration 📜</span>
<span class="c">#     ✓ Starting control-plane 🕹️</span>
<span class="c">#     ✓ Installing CNI 🔌</span>
<span class="c">#     ✓ Installing StorageClass 💾</span>
<span class="c">#     ✓ Joining worker nodes 🚜</span>
<span class="c">#    Set kubectl context to &amp;quot;kind-myk8s&amp;quot;</span>
<span class="c">#    You can now use your cluster with:</span>
<span class="c">#    </span>
<span class="c">#    kubectl cluster-info --context kind-myk8s</span>
<span class="c">#    </span>
<span class="c">#    Thanks for using kind! 😊</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kind get nodes <span class="nt">--name</span> myk8s
<span class="c"># =&gt; myk8s-control-plane</span>
<span class="c">#    myk8s-worker</span>
<span class="c">#    myk8s-worker2</span>
<span class="nv">$ </span>kubens default
<span class="c"># =&gt; Context &amp;quot;kind-myk8s&amp;quot; modified.</span>
<span class="c">#    Active namespace is &amp;quot;default&amp;quot;.</span>

<span class="c"># kind 는 별도 도커 네트워크 생성 후 사용 : 기본값 172.18.0.0/16</span>
<span class="nv">$ </span>docker network <span class="nb">ls</span>
<span class="c"># =&gt; NETWORK ID     NAME                     DRIVER    SCOPE</span>
<span class="c">#    8204a0851463   host                     host      local</span>
<span class="c">#    3bbcc6aa8f38   kind                     bridge    local</span>
<span class="nv">$ </span>docker inspect kind | jq
<span class="c"># =&gt; [</span>
<span class="c">#      {</span>
<span class="c">#        &amp;quot;Name&amp;quot;: &amp;quot;kind&amp;quot;,</span>
<span class="c">#        &amp;quot;Id&amp;quot;: &amp;quot;3bbcc6aa8f388f86f02478f41de1e4dd917e5812b6cf6257972e4af0bedf5021&amp;quot;,</span>
<span class="c">#        &amp;quot;Created&amp;quot;: &amp;quot;2024-10-01T11:37:09.195259833Z&amp;quot;,</span>
<span class="c">#        &amp;quot;Scope&amp;quot;: &amp;quot;local&amp;quot;,</span>
<span class="c">#        &amp;quot;Driver&amp;quot;: &amp;quot;bridge&amp;quot;,</span>
<span class="c">#        &amp;quot;EnableIPv6&amp;quot;: true,</span>
<span class="c">#        &amp;quot;IPAM&amp;quot;: {</span>
<span class="c">#          &amp;quot;Driver&amp;quot;: &amp;quot;default&amp;quot;,</span>
<span class="c">#          &amp;quot;Options&amp;quot;: {},</span>
<span class="c">#          &amp;quot;Config&amp;quot;: [</span>
<span class="c">#            {</span>
<span class="c">#              &amp;quot;Subnet&amp;quot;: &amp;quot;172.20.0.0/16&amp;quot;,</span>
<span class="c">#              &amp;quot;Gateway&amp;quot;: &amp;quot;172.20.0.1&amp;quot;</span>
<span class="c">#            }</span>
<span class="c">#          ]</span>
<span class="c">#        },</span>
<span class="c">#        &amp;quot;Internal&amp;quot;: false,</span>
<span class="c">#        &amp;quot;Attachable&amp;quot;: false,</span>
<span class="c">#        &amp;quot;Ingress&amp;quot;: false,</span>
<span class="c">#        &amp;quot;ConfigFrom&amp;quot;: {</span>
<span class="c">#          &amp;quot;Network&amp;quot;: &amp;quot;&amp;quot;</span>
<span class="c">#        },</span>
<span class="c">#        &amp;quot;ConfigOnly&amp;quot;: false,</span>
<span class="c">#        &amp;quot;Containers&amp;quot;: {</span>
<span class="c">#          &amp;quot;35739bf3542771236d47fd4dcb27da13814184a3de57c7203904f66ecbab4710&amp;quot;: {</span>
<span class="c">#            &amp;quot;Name&amp;quot;: &amp;quot;myk8s-worker&amp;quot;,</span>
<span class="c">#            &amp;quot;EndpointID&amp;quot;: &amp;quot;5de8e9e48e611f2c4cb908649f5dcdf63c82d624b85f85a6573ced7cbd454554&amp;quot;,</span>
<span class="c">#            &amp;quot;MacAddress&amp;quot;: &amp;quot;02:42:ac:14:00:03&amp;quot;,</span>
<span class="c">#            &amp;quot;IPv4Address&amp;quot;: &amp;quot;172.20.0.3/16&amp;quot;,</span>
<span class="c">#          },</span>
<span class="c">#          &amp;quot;48023a25d056141b00747f14ff52da2b46c46c0d0edbeb714dedd1f3c71360e4&amp;quot;: {</span>
<span class="c">#            &amp;quot;Name&amp;quot;: &amp;quot;myk8s-control-plane&amp;quot;,</span>
<span class="c">#            &amp;quot;EndpointID&amp;quot;: &amp;quot;9d51136474882d6ca7a4aabe7291e26527f44c3b88c7191b654506fdf1d65c84&amp;quot;,</span>
<span class="c">#            &amp;quot;MacAddress&amp;quot;: &amp;quot;02:42:ac:14:00:04&amp;quot;,</span>
<span class="c">#            &amp;quot;IPv4Address&amp;quot;: &amp;quot;172.20.0.4/16&amp;quot;,</span>
<span class="c">#          },</span>
<span class="c">#          &amp;quot;fefdfb00a2228f646119483a24503e1dc8bd74292e462fc9fa2ef3446004b4af&amp;quot;: {</span>
<span class="c">#            &amp;quot;Name&amp;quot;: &amp;quot;myk8s-worker2&amp;quot;,</span>
<span class="c">#            &amp;quot;EndpointID&amp;quot;: &amp;quot;c669ce7940abb8722b7ac41cc533c260838d31881c915a49147829e9d28a746c&amp;quot;,</span>
<span class="c">#            &amp;quot;MacAddress&amp;quot;: &amp;quot;02:42:ac:14:00:02&amp;quot;,</span>
<span class="c">#            &amp;quot;IPv4Address&amp;quot;: &amp;quot;172.20.0.2/16&amp;quot;,</span>
<span class="c">#          }</span>
<span class="c">#        },</span>
<span class="c">#        &amp;quot;Options&amp;quot;: {</span>
<span class="c">#          &amp;quot;com.docker.network.bridge.enable_ip_masquerade&amp;quot;: &amp;quot;true&amp;quot;,</span>
<span class="c">#          &amp;quot;com.docker.network.driver.mtu&amp;quot;: &amp;quot;1500&amp;quot;</span>
<span class="c">#        },</span>
<span class="c">#        &amp;quot;Labels&amp;quot;: {}</span>
<span class="c">#      }</span>
<span class="c">#    ]</span>

<span class="c"># k8s api 주소 확인 : 어떻게 로컬에서 접속이 되는 걸까?</span>
<span class="nv">$ </span>kubectl cluster-info
<span class="c"># =&gt; Kubernetes control plane is running at https://10.0.4.3:51235</span>
<span class="c">#    CoreDNS is running at https://10.0.4.3:51235/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</span>
<span class="c">#    </span>
<span class="c">#    To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 docker가 10.0.4.3:51235 접속시 kind 컨테이너의 6443 포트로 포워딩 해주고&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   ~/.kube/config 에서 10.0.4.3:51235를 apiserver 주소로 지정하고 있기 때문에 접속이 가능합니다.&lt;/span&gt;</span>

<span class="c"># 노드 정보 확인 : CRI 는 containerd 사용</span>
<span class="nv">$ </span>kubectl get node <span class="nt">-o</span> wide
<span class="c"># =&gt; NAME                  STATUS   ROLES           AGE     VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE                         KERNEL-VERSION     CONTAINER-RUNTIME</span>
<span class="c">#    myk8s-control-plane   Ready    control-plane   3m8s    v1.30.6   172.20.0.4    &amp;lt;none&amp;gt;        Debian GNU/Linux 12 (bookworm)   5.10.76-linuxkit   containerd://1.7.18</span>
<span class="c">#    myk8s-worker          Ready    &amp;lt;none&amp;gt;          2m48s   v1.30.6   172.20.0.3    &amp;lt;none&amp;gt;        Debian GNU/Linux 12 (bookworm)   5.10.76-linuxkit   containerd://1.7.18</span>
<span class="c">#    myk8s-worker2         Ready    &amp;lt;none&amp;gt;          2m48s   v1.30.6   172.20.0.2    &amp;lt;none&amp;gt;        Debian GNU/Linux 12 (bookworm)   5.10.76-linuxkit   containerd://1.7.18</span>

<span class="c"># 파드 정보 확인 : CNI 는 kindnet 사용</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-A</span> <span class="nt">-o</span> wide
<span class="c"># =&gt; NAMESPACE            NAME                                          READY   STATUS    RESTARTS   AGE     IP           NODE                  NOMINATED NODE   READINESS GATES</span>
<span class="c">#    kube-system          coredns-55cb58b774-m7h2c                      1/1     Running   0          3m7s    10.244.0.2   myk8s-control-plane   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          coredns-55cb58b774-z88v5                      1/1     Running   0          3m7s    10.244.0.3   myk8s-control-plane   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          etcd-myk8s-control-plane                      1/1     Running   0          3m22s   172.20.0.4   myk8s-control-plane   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          kindnet-mp6mj                                 1/1     Running   0          3m7s    172.20.0.4   myk8s-control-plane   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          kindnet-q2k9w                                 1/1     Running   0          3m4s    172.20.0.2   myk8s-worker2         &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          kindnet-t99c4                                 1/1     Running   0          3m4s    172.20.0.3   myk8s-worker          &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          kube-apiserver-myk8s-control-plane            1/1     Running   0          3m21s   172.20.0.4   myk8s-control-plane   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          kube-controller-manager-myk8s-control-plane   1/1     Running   0          3m21s   172.20.0.4   myk8s-control-plane   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          kube-proxy-f85sx                              1/1     Running   0          3m7s    172.20.0.4   myk8s-control-plane   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          kube-proxy-ltckc                              1/1     Running   0          3m4s    172.20.0.2   myk8s-worker2         &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          kube-proxy-njr42                              1/1     Running   0          3m4s    172.20.0.3   myk8s-worker          &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system          kube-scheduler-myk8s-control-plane            1/1     Running   0          3m21s   172.20.0.4   myk8s-control-plane   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    local-path-storage   local-path-provisioner-7d4d9bdcc5-jhl5h       1/1     Running   0          3m7s    10.244.0.4   myk8s-control-plane   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>

<span class="c"># 쿠버네티스 네임스페이스 확인 &gt;&gt; 도커 컨테이너에서 배운 네임스페이스와 다릅니다!</span>
<span class="nv">$ </span>kubectl get namespaces
<span class="c"># =&gt; NAME                 STATUS   AGE</span>
<span class="c">#    default              Active   3m42s</span>
<span class="c">#    kube-node-lease      Active   3m42s</span>
<span class="c">#    kube-public          Active   3m42s</span>
<span class="c">#    kube-system          Active   3m42s</span>
<span class="c">#    local-path-storage   Active   3m35s</span>

<span class="c"># 컨트롤플레인/워커 노드(컨테이너) 확인 : 도커 컨테이너 이름은 myk8s-control-plane , myk8s-worker/worker-2 임을 확인</span>
<span class="nv">$ </span>docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE                  COMMAND                  CREATED         STATUS                 PORTS                                                            NAMES</span>
<span class="c">#    35739bf35427   kindest/node:v1.30.6   &amp;quot;/usr/local/bin/entr…&amp;quot;   4 minutes ago   Up 4 minutes                                                                            myk8s-worker</span>
<span class="c">#    48023a25d056   kindest/node:v1.30.6   &amp;quot;/usr/local/bin/entr…&amp;quot;   4 minutes ago   Up 4 minutes           0.0.0.0:30000-30003-&amp;gt;30000-30003/tcp, 10.0.4.3:51235-&amp;gt;6443/tcp   myk8s-control-plane</span>
<span class="c">#    fefdfb00a222   kindest/node:v1.30.6   &amp;quot;/usr/local/bin/entr…&amp;quot;   4 minutes ago   Up 4 minutes                                                                            myk8s-worker2</span>
<span class="nv">$ </span>docker images

<span class="c"># 디버그용 내용 출력에 ~/.kube/config 권한 인증 로드</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-v6</span>
<span class="c"># =&gt; I1221 20:19:47.265879   56969 loader.go:395] Config loaded from file:  /Users/anonym/Documents/GitHub/cicd-lite/w3/1/dev-app/kubeconfig</span>
<span class="c">#    I1221 20:19:47.354543   56969 round_trippers.go:553] GET https://10.0.4.3:51235/api/v1/namespaces/default/pods?limit=500 200 OK in 79 milliseconds</span>
<span class="c">#    No resources found in default namespace.</span>

<span class="c"># kube config 파일 확인</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="nv">$KUBECONFIG</span>
<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-l</span> <span class="nv">$KUBECONFIG</span>
<span class="c"># =&gt; .rw------- anonym staff 5.5 KB Sat Oct 01 20:16:21 2024  /Users/user/Documents/GitHub/cicd-lite/w3/1/dev-app/kubeconfig</span>
</code></pre></div></div>

<h5 id="kube-ops-view-설치">kube-ops-view 설치</h5>

<ul>
  <li>kube-ops-view는 쿠버네티스 클러스터의 상태를 시각적으로 보여주는 대시보드입니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># kube-ops-view</span>
<span class="c"># helm show values geek-cookbook/kube-ops-view</span>
<span class="nv">$ </span>helm repo add geek-cookbook https://geek-cookbook.github.io/charts/
<span class="nv">$ </span>helm <span class="nb">install </span>kube-ops-view geek-cookbook/kube-ops-view <span class="nt">--version</span> 1.2.2 <span class="nt">--set</span> service.main.type<span class="o">=</span>NodePort,service.main.ports.http.nodePort<span class="o">=</span>30001 <span class="nt">--set</span> env.TZ<span class="o">=</span><span class="s2">"Asia/Seoul"</span> <span class="nt">--namespace</span> kube-system

<span class="c"># 설치 확인</span>
<span class="nv">$ </span>kubectl get deploy,pod,svc,ep <span class="nt">-n</span> kube-system <span class="nt">-l</span> app.kubernetes.io/instance<span class="o">=</span>kube-ops-view
<span class="c"># =&gt; NAME                            READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/kube-ops-view   1/1     1            1           25s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                 READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/kube-ops-view-796947d6dc-6b6xx   1/1     Running   0          25s</span>
<span class="c">#    </span>
<span class="c">#    NAME                    TYPE       CLUSTER-IP    EXTERNAL-IP   PORT(S)          AGE</span>
<span class="c">#    service/kube-ops-view   NodePort   10.96.18.59   &amp;lt;none&amp;gt;        8080:30001/TCP   25s</span>
<span class="c">#    </span>
<span class="c">#    NAME                      ENDPOINTS         AGE</span>
<span class="c">#    endpoints/kube-ops-view   10.244.1.2:8080   25s</span>

<span class="c"># kube-ops-view 접속 URL 확인 (1.5 , 2 배율)</span>
<span class="nv">$ </span>open <span class="s2">"http://127.0.0.1:30001/#scale=1.5"</span>
<span class="nv">$ </span>open <span class="s2">"http://127.0.0.1:30001/#scale=2"</span>
</code></pre></div></div>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_10.png" alt="img.png" class="w-80 image-center" /></p>

<h5 id="클러스터-삭제">클러스터 삭제</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 클러스터 삭제</span>
<span class="nv">$ </span>kind delete cluster <span class="nt">--name</span> myk8s
<span class="c"># =&gt; Deleting cluster &amp;quot;myk8s&amp;quot; ...</span>
<span class="c">#    Deleted nodes: [&amp;quot;myk8s-worker&amp;quot; &amp;quot;myk8s-control-plane&amp;quot; &amp;quot;myk8s-worker2&amp;quot;]</span>
<span class="nv">$ </span>docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE             COMMAND                  CREATED        STATUS                 PORTS                                              NAMES</span>
<span class="c">#    110494b9ca48   gogs/gogs         &amp;quot;/app/gogs/docker/st…&amp;quot;   19 hours ago   Up 6 hours (healthy)   0.0.0.0:3000-&amp;gt;3000/tcp, 0.0.0.0:10022-&amp;gt;22/tcp      gogs</span>
<span class="c">#    8b7c591c828d   jenkins/jenkins   &amp;quot;/usr/bin/tini -- /u…&amp;quot;   19 hours ago   Up 5 hours             0.0.0.0:8080-&amp;gt;8080/tcp, 0.0.0.0:50000-&amp;gt;50000/tcp   jenkins</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="nv">$KUBECONFIG</span>
<span class="nv">$ </span><span class="nb">unset </span>KUBECONFIG
</code></pre></div></div>

<h4 id="jenkins-설정--plugin-설치-자격증명-설정">Jenkins 설정 : Plugin 설치, 자격증명 설정</h4>

<ul>
  <li>Jenkins Plugin 설치 : Dashboard &gt; Manage Jenkins &gt; Plugins &gt; Available plugins 탭에서 설치
    <ul>
      <li><strong>Pipeline Stage View</strong> - <a href="https://plugins.jenkins.io/pipeline-stage-view/">Docs</a></li>
      <li><strong>Docker Pipeline</strong> : building, testing, and using Docker images from Jenkins Pipeline - <a href="https://plugins.jenkins.io/docker-workflow/">Docs</a></li>
      <li><strong>Gogs</strong> : Webhook Plugin - <a href="https://plugins.jenkins.io/gogs-webhook/">Docs</a>
        <ul>
          <li>예시 : <code class="language-plaintext highlighter-rouge">http(s)://&lt;&lt; jenkins-server &gt;&gt;/gogs-webhook/?job=&lt;&lt;jobname&gt;&gt;</code></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>자격증명 설정 : Dashboard &gt; Manage Jenkins &gt; Credentials &gt; Global &gt; Add Credentials 에서 추가
    <ol>
      <li>Gogs Repo 자격증명 설정 : <strong>gogs-crd</strong>
        <ul>
          <li>Kind : Username with password</li>
          <li>Username : <code class="language-plaintext highlighter-rouge">devops</code></li>
          <li>Password : <code class="language-plaintext highlighter-rouge">&lt;Gogs 토큰&gt;</code></li>
          <li>ID : <code class="language-plaintext highlighter-rouge">gogs-crd</code></li>
        </ul>
      </li>
      <li>도커 허브 자격증명 설정 : <strong>dockerhub-crd</strong>
        <ul>
          <li>Kind : Username with password</li>
          <li>Username : <code class="language-plaintext highlighter-rouge">&lt;도커 계정명&gt;</code></li>
          <li>Password : <code class="language-plaintext highlighter-rouge">&lt;도커 계정 암호 혹은 토큰&gt;</code></li>
          <li>ID : <code class="language-plaintext highlighter-rouge">dockerhub-crd</code></li>
        </ul>
      </li>
      <li>k8s(kind) 자격증명 설정 : <strong>k8s-crd</strong>
        <ul>
          <li>Kind : <code class="language-plaintext highlighter-rouge">Secret file</code></li>
          <li>File : <code class="language-plaintext highlighter-rouge">&lt;kubeconfig 파일 업로드&gt;</code></li>
          <li>ID : <code class="language-plaintext highlighter-rouge">k8s-crd</code></li>
        </ul>
      </li>
    </ol>
  </li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_11.png" alt="img.png" class="image-center" />
<em class="image-caption">Jenkins 자격증명 설정 결과</em></p>

<h5 id="jenkins-item-생성-pipeline">Jenkins item 생성 (Pipeline)</h5>

<ul>
  <li>간단한 Pipeline 스크립트를 작성하여 gogs와 도커허브의 자격증명이 잘 연동됨을 확인해보겠습니다.</li>
  <li>아래의 Pipeline 스크립트를 <code class="language-plaintext highlighter-rouge">pipeline-ci</code>라는 이름으로 생성합니다.</li>
</ul>

<div class="language-gradle highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pipeline</span> <span class="o">{</span>
    <span class="n">agent</span> <span class="n">any</span>
    <span class="n">environment</span> <span class="o">{</span>
        <span class="n">DOCKER_IMAGE</span> <span class="o">=</span> <span class="s1">'&lt;자신의 도커 허브 계정&gt;/dev-app'</span> <span class="c1">// Docker 이미지 이름</span>
    <span class="o">}</span>
    <span class="n">stages</span> <span class="o">{</span>
        <span class="n">stage</span><span class="o">(</span><span class="s1">'Checkout'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                 <span class="n">git</span> <span class="nl">branch:</span> <span class="s1">'main'</span><span class="o">,</span>
                 <span class="nl">url:</span> <span class="s1">'http://&lt;PC의 IP&gt;:3000/devops/dev-app.git'</span><span class="o">,</span>  <span class="c1">// Git에서 코드 체크아웃</span>
                 <span class="nl">credentialsId:</span> <span class="s1">'gogs-crd'</span>  <span class="c1">// Credentials ID</span>
            <span class="o">}</span>
        <span class="o">}</span>
        <span class="n">stage</span><span class="o">(</span><span class="s1">'Read VERSION'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">script</span> <span class="o">{</span>
                    <span class="c1">// VERSION 파일 읽기</span>
                    <span class="kt">def</span> <span class="n">version</span> <span class="o">=</span> <span class="n">readFile</span><span class="o">(</span><span class="s1">'VERSION'</span><span class="o">).</span><span class="na">trim</span><span class="o">()</span>
                    <span class="n">echo</span> <span class="s2">"Version found: ${version}"</span>
                    <span class="c1">// 환경 변수 설정</span>
                    <span class="n">env</span><span class="o">.</span><span class="na">DOCKER_TAG</span> <span class="o">=</span> <span class="n">version</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
        <span class="n">stage</span><span class="o">(</span><span class="s1">'Docker Build and Push'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">script</span> <span class="o">{</span>
                    <span class="n">docker</span><span class="o">.</span><span class="na">withRegistry</span><span class="o">(</span><span class="s1">'https://index.docker.io/v1/'</span><span class="o">,</span> <span class="s1">'dockerhub-crd'</span><span class="o">)</span> <span class="o">{</span>
                        <span class="c1">// DOCKER_TAG 사용</span>
                        <span class="kt">def</span> <span class="n">appImage</span> <span class="o">=</span> <span class="n">docker</span><span class="o">.</span><span class="na">build</span><span class="o">(</span><span class="s2">"${DOCKER_IMAGE}:${DOCKER_TAG}"</span><span class="o">)</span>
                        <span class="n">appImage</span><span class="o">.</span><span class="na">push</span><span class="o">()</span>
                        <span class="n">appImage</span><span class="o">.</span><span class="na">push</span><span class="o">(</span><span class="s2">"latest"</span><span class="o">)</span>
                    <span class="o">}</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
    <span class="n">post</span> <span class="o">{</span>
        <span class="n">success</span> <span class="o">{</span>
            <span class="n">echo</span> <span class="s2">"Docker image ${DOCKER_IMAGE}:${DOCKER_TAG} has been built and pushed successfully!"</span>
        <span class="o">}</span>
        <span class="n">failure</span> <span class="o">{</span>
            <span class="n">echo</span> <span class="s2">"Pipeline failed. Please check the logs."</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<ul>
  <li>지금 빌드 =&gt; 콘솔 Output 확인
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_12.png" alt="img.png" class="image-center" /></li>
  <li>도커 허브 확인
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_13.png" alt="img.png" class="image-center" />
    <ul>
      <li>자격증명들이 잘 연동되어, 파이프라인에서 지정한것 처럼 버전명의 태그(0.0.1)과 latest 태그가 잘 생성되었습니다!</li>
    </ul>
  </li>
</ul>

<h4 id="kubernetes-클러스터에-응용프로그램-배포하기">Kubernetes 클러스터에 응용프로그램 배포하기</h4>

<ul>
  <li>Jenkins Pipeline을 통해 Kubernetes 클러스터에 응용프로그램을 배포해보겠습니다.</li>
  <li>먼저 Kubernetes 클러스터에 배포할때 사용하는 deployment에 대해 알아보겠습니다.</li>
</ul>

<h5 id="deployment-소개">Deployment 소개</h5>

<script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
<div class="mermaid">
  graph TD
      subgraph Deployment
          subgraph ReplicaSet
              direction TB
              subgraph Pod[Pod]
                  direction LR
                  Container1(Container)
                  Container2(Container)
              end
              subgraph Pod2[Pod]
                  direction LR
                  Container3(Container)
                  Container4(Container)
              end
              subgraph Pod3[Pod]
                  direction LR
                  Container5(Container)
              end
          end
      end
  classDef Pod fill:#fff,stroke:#ccc,stroke-width:2px;
  classDef ReplicaSet fill:#fff,stroke:#ccc,stroke-width:2px;
  classDef Deployment fill:#fff,stroke:#ccc,stroke-width:2px;
  class Pod,Pod2,Pod3 Pod;
  class Deployment Deployment;
  </div>
<p><em class="image-caption">Kubernetes 배포 구조</em></p>

<ul>
  <li>Kubernetes를 배포하는 최소단위는 <strong>Pod</strong>이며, <strong>하나 이상의 컨테이너로 구성</strong>됩니다.</li>
  <li>Pod는 <strong>ReplicaSet</strong>에 의해 관리되며, ReplicaSet은 <strong>Pod의 수를 유지하도록 관리</strong>합니다.</li>
  <li>
    <p><strong>Deployment</strong>는 <strong>ReplicaSet을 관리하며, Pod의 배포 및 업데이트를 관리</strong>합니다.</p>
  </li>
  <li>Kubernetes는 manifest라는 yaml 파일을 통해 리소스를 정의하고, 선언형 방식으로 원하는 상태를 선언시 해당 상태를 충족시키기 위해 클러스터를 조정합니다.</li>
  <li>아래는 kubernetes의 manifest의 구조입니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apiVersion: ...   <span class="c"># &lt;span style="color: green;"&gt;👉 리소스를 만드는데 사용할 Kubernetes API 버전&lt;/span&gt;</span>
kind: ...         <span class="c"># &lt;span style="color: green;"&gt;👉 만들고자 하는 리소스의 종류&lt;/span&gt;</span>
metadata:
    ...           <span class="c"># &lt;span style="color: green;"&gt;👉 리소스를 식별하는 고유 데이터와 상태와 관련없는 메타데이터&lt;/span&gt;</span>
spec:
    ...           <span class="c"># &lt;span style="color: green;"&gt;👉 리소스의 원하는 상태를 정의&lt;/span&gt;</span>
</code></pre></div>    </div>
  </li>
</ul>

<h5 id="deployment-배포-실습">Deployment 배포 실습</h5>

<ul>
  <li>
    <p>앞서 작성한 Jenkins Pipeline을 통해 빌드된 도커 이미지를 Kubernetes 클러스터에 응용프로그램을 배포해보겠습니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 디플로이먼트 오브젝트 배포 : 리플리카(파드 2개), 컨테이너 이미지 &gt;&gt; 아래 도커 계정 부분만 변경해서 배포해보자</span>
<span class="c">#$ DHUSER=&lt;도커 허브 계정명&gt;</span>
<span class="nv">$ DHUSER</span><span class="o">=</span>sweetlittlebird
  
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: timeserver
spec:
  replicas: 2
  selector:
    matchLabels:
      pod: timeserver-pod
  template:
    metadata:
      labels:
        pod: timeserver-pod
    spec:
      containers:
      - name: timeserver-container
        image: docker.io/</span><span class="nv">$DHUSER</span><span class="sh">/dev-app:0.0.1
</span><span class="no">EOF
</span><span class="c"># =&gt; deployment.apps/timeserver created</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> kubectl get deploy,pod <span class="nt">-o</span> wide
  
<span class="c"># 배포 상태 확인 : kube-ops-view 웹 확인</span>
<span class="nv">$ </span>kubectl get deploy,pod <span class="nt">-o</span> wide
<span class="c"># =&gt; NAME                         READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS             IMAGES                                    SELECTOR</span>
<span class="c">#    deployment.apps/timeserver   0/2     2            0           45s   timeserver-container   docker.io/sweetlittlebird/dev-app:0.0.1   pod=timeserver-pod</span>
<span class="c">#    </span>
<span class="c">#    NAME                              READY   STATUS             RESTARTS   AGE   IP           NODE            NOMINATED NODE   READINESS GATES</span>
<span class="c">#    pod/timeserver-5b5ff6d859-s282p   0/1     &lt;span style="color: red;"&gt;ImagePullBackOff&lt;/span&gt;   0          45s   10.244.2.2   myk8s-worker2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    pod/timeserver-5b5ff6d859-v7gs7   0/1     &lt;span style="color: red;"&gt;ImagePullBackOff&lt;/span&gt;   0          45s   10.244.1.2   myk8s-worker    &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 배포상태가 ImagePullBackOff로 배포가 되지 않았습니다.&lt;/span&gt;</span>
  
<span class="nv">$ </span>kubectl describe pod
<span class="c"># =&gt; Name:             timeserver-5b5ff6d859-s282p</span>
<span class="c">#    ...</span>
<span class="c">#    Events:</span>
<span class="c">#      Type     Reason     Age                    From               Message</span>
<span class="c">#      ----     ------     ----                   ----               -------</span>
<span class="c">#      Normal   Scheduled  5m38s                  default-scheduler  Successfully assigned default/timeserver-5b5ff6d859-s282p to myk8s-worker2</span>
<span class="c">#      Normal   Pulling    4m4s (x4 over 5m37s)   kubelet            Pulling image &amp;quot;docker.io/sweetlittlebird/dev-app:0.0.1&amp;quot;</span>
<span class="c">#      Warning  Failed     4m3s (x4 over 5m35s)   kubelet            Failed to pull image &amp;quot;docker.io/sweetlittlebird/dev-app:0.0.1&amp;quot;: failed to pull and unpack image &amp;quot;docker.io/sweetlittlebird/dev-app:0.0.1&amp;quot;: failed to resolve reference &amp;quot;docker.io/sweetlittlebird/dev-app:0.0.1&amp;quot;: pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed</span>
<span class="c">#      Warning  Failed     4m3s (x4 over 5m35s)   kubelet            Error: ErrImagePull</span>
<span class="c">#      Warning  Failed     3m48s (x6 over 5m35s)  kubelet            Error: ImagePullBackOff</span>
<span class="c">#      Normal   BackOff    22s (x20 over 5m35s)   kubelet            Back-off pulling image &amp;quot;docker.io/sweetlittlebird/dev-app:0.0.1&amp;quot;```</span>
</code></pre></div>    </div>
  </li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_14.png" alt="img.png" class="image-center" />
<em class="image-caption">Kube-Ops-View를 통해 살펴본 Kubernetes 클러스터에 timeserver 배포 실패</em></p>

<ul>
  <li>위와 같이 Image pull error가 나면서 배포가 실패했습니다.</li>
  <li><code class="language-plaintext highlighter-rouge">kubectl describe pod</code>를 통해 확인한 결과, <code class="language-plaintext highlighter-rouge">pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed</code>와 같은 메시지가 나타나고
이는 Kubernetes 클러스터에서 도커 이미지를 pull할 때 도커 허브에 인증 토큰이 되어있지 않아서 발생한 문제를 의미합니다.</li>
  <li>도커 허브의 인증토큰을 등록하고 다시 시도해보겠습니다.</li>
</ul>

<h4 id="k8s에-docker-hub-인증토큰-등록-후-다시-배포">K8S에 Docker Hub 인증토큰 등록 후 다시 배포</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># k8s secret : 도커 자격증명 설정</span>
 
<span class="nv">$ </span>kubectl get secret <span class="nt">-A</span>  <span class="c"># 기존 시크릿 확인</span>
<span class="c"># =&gt; NAMESPACE     NAME                                  TYPE                            DATA   AGE</span>
<span class="c">#    kube-system   bootstrap-token-abcdef                bootstrap.kubernetes.io/token   6      164m</span>
<span class="c">#    kube-system   sh.helm.release.v1.kube-ops-view.v1   helm.sh/release.v1              1      25m</span>

<span class="c">#$ DHUSER=&lt;도커 허브 계정&gt;</span>
<span class="c">#$ DHPASS=&lt;도커 허브 암호 혹은 토큰&gt;</span>

<span class="nv">$ DHUSER</span><span class="o">=</span>sweetlittlebird
<span class="nv">$ DHPASS</span><span class="o">=</span>dckr_<span class="k">****</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$DHUSER</span> <span class="nv">$DHPASS</span>
<span class="c"># =&gt; sweetlittlebird dckr_****</span>

<span class="c"># 도커 허브 시크릿 생성</span>
<span class="nv">$ </span>kubectl create secret docker-registry dockerhub-secret <span class="se">\</span>
  <span class="nt">--docker-server</span><span class="o">=</span>https://index.docker.io/v1/ <span class="se">\</span>
  <span class="nt">--docker-username</span><span class="o">=</span><span class="nv">$DHUSER</span> <span class="se">\</span>
  <span class="nt">--docker-password</span><span class="o">=</span><span class="nv">$DHPASS</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get secret
<span class="c"># =&gt; NAME               TYPE                             DATA   AGE</span>
<span class="c">#    dockerhub-secret   kubernetes.io/dockerconfigjson   1      8s</span>
<span class="nv">$ </span>kubectl describe secret
<span class="c"># =&gt; Name:         dockerhub-secret</span>
<span class="c">#    Namespace:    default</span>
<span class="c">#    Labels:       &amp;lt;none&amp;gt;</span>
<span class="c">#    Annotations:  &amp;lt;none&amp;gt;</span>
<span class="c">#    </span>
<span class="c">#    Type:  kubernetes.io/dockerconfigjson</span>
<span class="c">#    </span>
<span class="c">#    Data</span>
<span class="c">#    ====</span>
<span class="c">#    .dockerconfigjson:  205 bytes</span>
<span class="nv">$ </span>kubectl get secrets <span class="nt">-o</span> yaml | kubectl neat  <span class="c"># base64 인코딩 확인</span>
<span class="c"># =&gt; apiVersion: v1</span>
<span class="c">#    items:</span>
<span class="c">#    - apiVersion: v1</span>
<span class="c">#      data:</span>
<span class="c">#        .dockerconfigjson: eyJhdXRocyI6eyJodHRwczovL2luZGV4LmRvY2tlci5pby92MS8iOnsidXNlcm5hbWUiOiJzZWNyZXRsaXR0bGViaXJkIiwicGFzc3dvcmQiOiJkY2tyX3BhdF9QdWNpVTRIMFBPZVpYWGNvV1VNd1ozTVpZVEUiLCJhdXRoIjoiYzJWamNtVjBiR2wwZEd4bFltbHlaRHBrWTJ0eVgzQmhkRjlRZFdOcFZUUklNRkJQWlZwWVdHTnZWMVZOZDFvelRWcFpWRVU9In19fQ==</span>
<span class="c">#      kind: Secret</span>
<span class="c">#      metadata:</span>
<span class="c">#        name: dockerhub-secret</span>
<span class="c">#        namespace: default</span>
<span class="c">#      type: kubernetes.io/dockerconfigjson</span>
<span class="c">#    kind: List</span>
<span class="c">#    metadata: {}</span>

<span class="nv">$ SECRET</span><span class="o">=</span><span class="nv">eyJhdXRocyI6eyJodHRwczovL2luZGV4LmRvY2tlci5pby92MS8iOnsidXNlcm5hbWUiOiJzZWNyZXRsaXR0bGViaXJkIiwicGFzc3dvcmQiOiJkY2tyX3BhdF9QdWNpVTRIMFBPZVpYWGNvV1VNd1ozTVpZVEUiLCJhdXRoIjoiYzJWamNtVjBiR2wwZEd4bFltbHlaRHBrWTJ0eVgzQmhkRjlRZFdOcFZUUklNRkJQWlZwWVdHTnZWMVZOZDFvelRWcFpWRVU9In19fQ</span><span class="o">==</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"</span><span class="nv">$SECRET</span><span class="s2">"</span> | <span class="nb">base64</span> <span class="nt">-d</span> <span class="p">;</span> <span class="nb">echo</span>
<span class="c"># =&gt; {&amp;quot;auths&amp;quot;:{&amp;quot;https://index.docker.io/v1/&amp;quot;:{&amp;quot;username&amp;quot;:&amp;quot;sweetlittlebird&amp;quot;,&amp;quot;password&amp;quot;:&amp;quot;dckr_****&amp;quot;,&amp;quot;auth&amp;quot;:&amp;quot;c2VjcmV0bGl0dGxlYmlyZDpkY2tyX3BhdF9QdWNpVTRIMFBPZVpYWGNvV1VNd1ozTVpZVEU=&amp;quot;}}}</span>

<span class="c"># 도커허브 인증 토큰이 등록되었으니 다시 배포해보겠습니다.</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: timeserver
spec:
  replicas: 2
  selector:
    matchLabels:
      pod: timeserver-pod
  template:
    metadata:
      labels:
        pod: timeserver-pod
    spec:
      containers:
      - name: timeserver-container
        image: docker.io/</span><span class="nv">$DHUSER</span><span class="sh">/dev-app:0.0.1
      imagePullSecrets:
      - name: dockerhub-secret
</span><span class="no">EOF
</span><span class="nv">$ </span>watch <span class="nt">-d</span> kubectl get deploy,pod <span class="nt">-o</span> wide

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get deploy,pod
<span class="c"># =&gt; NAME                         READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/timeserver   2/2     2            2           39s</span>
<span class="c">#    </span>
<span class="c">#    NAME                              READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/timeserver-549cc9bc89-k6n6g   1/1     Running   0          39s</span>
<span class="c">#    pod/timeserver-549cc9bc89-kdmgx   1/1     Running   0          39s</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 배포가 잘 되었습니다!&lt;/span&gt;</span>

<span class="c"># 접속을 위한 curl 파드 생성</span>
<span class="nv">$ </span>kubectl run curl-pod <span class="nt">--image</span><span class="o">=</span>curlimages/curl:latest <span class="nt">--command</span> <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s2">"while true; do sleep 3600; done"</span>
<span class="c"># =&gt; pod/curl-pod created</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                          READY   STATUS    RESTARTS   AGE    IP           NODE            NOMINATED NODE   READINESS GATES</span>
<span class="c">#    curl-pod                      1/1     Running   0          22s    10.244.2.6   myk8s-worker2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    timeserver-549cc9bc89-k6n6g   1/1     Running   0          103s   10.244.2.5   myk8s-worker2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    timeserver-549cc9bc89-kdmgx   1/1     Running   0          103s   10.244.1.6   myk8s-worker    &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>

<span class="c"># timeserver 파드 IP 1개 확인 후 접속 확인</span>
<span class="c">#$ PODIP1=&lt;timeserver-Y 파드 IP&gt;</span>
<span class="nv">$ PODIP1</span><span class="o">=</span>10.244.2.5

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nv">$PODIP1</span>
<span class="c"># =&gt; The time is 2:51:54 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-k6n6g</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nv">$PODIP1</span>
<span class="c"># =&gt; The time is 2:52:03 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-k6n6g</span>

<span class="c"># 로그 확인</span>
<span class="nv">$ </span>kubectl logs deploy/timeserver
<span class="nv">$ </span>kubectl logs deploy/timeserver <span class="nt">-f</span>
<span class="nv">$ </span>kubectl stern deploy/timeserver
<span class="nv">$ </span>kubectl stern <span class="nt">-l</span> <span class="nv">pod</span><span class="o">=</span>timeserver-pod
</code></pre></div></div>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_15.png" alt="img.png" class="image-center" /></p>

<ul>
  <li>kube-ops-view를 통해서도 배포가 잘 되었음을 확인할 수 있습니다.</li>
  <li>파드 1개 삭제 후 동작을 확인해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="c">#$ POD1NAME=&lt;파드 1개 이름&gt;</span>
<span class="nv">$ POD1NAME</span><span class="o">=</span>timeserver-549cc9bc89-k6n6g

<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                          READY   STATUS    RESTARTS   AGE    IP           NODE            NOMINATED NODE   READINESS GATES</span>
<span class="c">#    curl-pod                      1/1     Running   0          22s    10.244.2.6   myk8s-worker2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    timeserver-549cc9bc89-k6n6g   1/1     Running   0          103s   10.244.2.5   myk8s-worker2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    timeserver-549cc9bc89-kdmgx   1/1     Running   0          103s   10.244.1.6   myk8s-worker    &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="nv">$ </span>kubectl delete pod <span class="nv">$POD1NAME</span> <span class="o">&amp;&amp;</span> kubectl get pod <span class="nt">-w</span>
<span class="c"># =&gt; pod &amp;quot;timeserver-549cc9bc89-k6n6g&amp;quot; deleted              # &lt;span style="color: green;"&gt;👉 분명히 timeserver 파드 1개를 삭제하였는데&lt;/span&gt;</span>
<span class="c">#    NAME                          READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    curl-pod                      1/1     Running   0          115s</span>
<span class="c">#    timeserver-549cc9bc89-kdmgx   1/1     Running   0          7m20s</span>
<span class="c">#    timeserver-549cc9bc89-pvm5k   1/1     Running   0          31s   # &lt;span style="color: green;"&gt;👉 다시 새로운 파드가 생성되었습니다.&lt;/span&gt;</span>

<span class="c"># 셀프 힐링 , 파드 IP 변경 -&gt; 고정 진입점(고정 IP/도메인네임) 필요 =&gt; Service</span>
<span class="nv">$ </span>kubectl get deploy,rs,pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                         READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS             IMAGES                                    SELECTOR</span>
<span class="c">#    deployment.apps/timeserver   2/2     2            2           10m   timeserver-container   docker.io/sweetlittlebird/dev-app:0.0.1   pod=timeserver-pod</span>
<span class="c">#    </span>
<span class="c">#    NAME                                    DESIRED   CURRENT   READY   AGE   CONTAINERS             IMAGES                                    SELECTOR</span>
<span class="c">#    replicaset.apps/timeserver-549cc9bc89   2         2         2       10m   timeserver-container   docker.io/sweetlittlebird/dev-app:0.0.1   pod=timeserver-pod,pod-template-hash=549cc9bc89</span>
<span class="c">#    </span>
<span class="c">#    NAME                              READY   STATUS    RESTARTS   AGE     IP           NODE            NOMINATED NODE   READINESS GATES</span>
<span class="c">#    pod/curl-pod                      1/1     Running   0          4m56s   10.244.2.7   myk8s-worker2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    pod/timeserver-549cc9bc89-kdmgx   1/1     Running   0          10m     10.244.1.6   myk8s-worker    &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    pod/timeserver-549cc9bc89-pvm5k   1/1     Running   0          3m32s   10.244.2.8   myk8s-worker2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
</code></pre></div></div>

<ul>
  <li>위와 같이 파드가 삭제되면 ReplicaSet에 의해 새로운 파드가 생성되는 것을 확인할 수 있습니다.</li>
  <li>이때 IP가 변경되어 새로운 파드가 생성되는데, 이렇게 되면 매번 파드가 생성될때 마다 IP가 변경되어 서비스를 제공하기 어렵습니다.</li>
  <li>이를 해결하기 위해 <strong>Service</strong>를 사용합니다.</li>
</ul>

<h5 id="service-소개">Service 소개</h5>

<ul>
  <li><strong>Service</strong>는 Pod의 집합에 대한 고정된 진입점을 제공합니다. 앞서 살펴본것과 같이 Pod는 생성/삭제되면 IP가 변경되는데, 이를 Service를 통해 고정된 IP로 접근할 수 있습니다.</li>
  <li>Deployment를 통해 Pod가 여러 개 생성되면, Service는 이들을 하나의 집합으로 묶어서 부하분산(Load Balancing)을 제공합니다.</li>
  <li>Service는 Deployment를 대상으로 하지않고, Pod를 대상으로 합니다. Pod의 Label Selector를 통해 Service는 Pod를 선택합니다. 
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_16.png" alt="img.png" class="image-center" />
<em class="image-caption">Service와 Deployment, Pod manifest의 관계</em></li>
  <li>Service는 다음과 같은 종류가 있습니다.
    <ul>
      <li><strong>ClusterIP</strong> : 클러스터 내부에서만 접근 가능합니다.</li>
      <li><strong>NodePort</strong> : 클러스터 내부에서는 물론 외부에서 접근 가능합니다. 이때 파드가 동작하는 노드 IP의 지정된 포트로 접근 가능합니다.</li>
      <li><strong>LoadBalancer</strong> : 클라우드 제공자의 로드밸런서를 사용하여 외부에서 접근 가능합니다.</li>
    </ul>
  </li>
</ul>

<h5 id="service-배포-실습">Service 배포 실습</h5>

<ul>
  <li>간단한 서비스를 배포해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 서비스 생성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Service
metadata:
  name: timeserver
spec:
  selector:
    pod: timeserver-pod
  ports:
  - port: 80
    targetPort: 80
    protocol: TCP
    nodePort: 30000
  type: NodePort
</span><span class="no">EOF
</span><span class="c"># =&gt; service/timeserver created</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get service,ep timeserver <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                 TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE   SELECTOR</span>
<span class="c">#    service/timeserver   NodePort   10.96.204.127   &amp;lt;none&amp;gt;        80:30000/TCP   13s   pod=timeserver-pod</span>
<span class="c">#    </span>
<span class="c">#    NAME                   ENDPOINTS                     AGE</span>
<span class="c">#    endpoints/timeserver   10.244.1.6:80,10.244.2.8:80   13s</span>

<span class="c"># Service(ClusterIP)로 접속 확인 : 도메인네임 방식</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl timeserver
<span class="c"># =&gt; The time is 3:29:30 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl timeserver.default.svc.cluster.local
<span class="c"># =&gt; The time is 3:29:33 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-pvm5k</span>

<span class="c"># Service(ClusterIP)로 접속 확인 : 클러스터 IP 방식</span>
<span class="nv">$ </span>kubectl get svc timeserver <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.spec.clusterIP<span class="o">}</span>
<span class="c"># =&gt; 10.96.204.127</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="si">$(</span>kubectl get svc timeserver <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.spec.clusterIP<span class="o">}</span><span class="si">)</span>
<span class="c"># =&gt; The time is 3:29:40 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-pvm5k</span>

<span class="c"># Service(NodePort)로 접속 확인 "노드IP:NodePort"</span>
<span class="nv">$ </span>curl http://127.0.0.1:30000
<span class="c"># =&gt; The time is 3:32:43 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-&lt;span style="color: red;"&gt;kdmgx&lt;/span&gt;</span>
<span class="nv">$ </span>curl http://127.0.0.1:30000
<span class="c"># =&gt; The time is 3:32:59 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-&lt;span style="color: red;"&gt;pvm5k&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 서비스가 2개의 Pod 사이를 Load balancing 하는것을 확인 할 수 있습니다.&lt;/span&gt;</span>

<span class="c"># 반복 접속 해두기 : 부하분산 확인</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 http://127.0.0.1:30000 | <span class="nb">grep </span>name <span class="p">;</span> <span class="nb">sleep </span>1 <span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; Server hostname: timeserver-549cc9bc89-kdmgx</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-kdmgx</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#    ...</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span>  <span class="k">do </span>curl <span class="nt">-s</span> http://127.0.0.1:30000 | <span class="nb">grep </span>name<span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;   54 Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#      46 Server hostname: timeserver-549cc9bc89-kdmgx</span>

<span class="c"># 파드 복제복 증가 : service endpoint 대상에 자동 추가</span>
<span class="nv">$ </span>kubectl scale deployment timeserver <span class="nt">--replicas</span> 4
<span class="c"># =&gt; deployment.apps/timeserver scaled</span>
<span class="nv">$ </span>kubectl get service,ep timeserver <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                 TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE   SELECTOR</span>
<span class="c">#    service/timeserver   NodePort   10.96.204.127   &amp;lt;none&amp;gt;        80:30000/TCP   37m   pod=timeserver-pod</span>
<span class="c">#    </span>
<span class="c">#    NAME                   ENDPOINTS                                               AGE</span>
<span class="c">#    endpoints/timeserver   10.244.1.6:80,10.244.1.7:80,10.244.2.8:80 + 1 more...   37m</span>

<span class="c"># 반복 접속 해두기 : 부하분산 확인</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 http://127.0.0.1:30000 | <span class="nb">grep </span>name <span class="p">;</span> <span class="nb">sleep </span>1 <span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-h9q6p</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-h9q6p</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-xlbck</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-kdmgx</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-xlbck</span>
<span class="c">#    ...</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span>  <span class="k">do </span>curl <span class="nt">-s</span> http://127.0.0.1:30000 | <span class="nb">grep </span>name<span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;   29 Server hostname: timeserver-549cc9bc89-xlbck</span>
<span class="c">#      27 Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#      22 Server hostname: timeserver-549cc9bc89-kdmgx</span>
<span class="c">#      22 Server hostname: timeserver-549cc9bc89-h9q6p</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 파드 수 만큼 자동으로 로드밸런싱 되는것을 확인 할 수 있습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<h5 id="앱-업데이트-후-재배포">앱 업데이트 후 재배포</h5>

<ul>
  <li>샘플 앱의 server.py와 VERSION 파일을 업데이트하고, Jenkins Pipeline을 통해 새로운 버전을 배포해보겠습니다.</li>
  <li>먼저 샘플 앱의 업데이트를 진행합니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 업데이트</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s1">'s/0.0.1/0.0.2/g'</span> server.py
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"0.0.2"</span> <span class="o">&gt;</span> VERSION
<span class="nv">$ </span>git add <span class="nb">.</span>
<span class="nv">$ </span>git commit <span class="nt">-m</span> <span class="s2">"Update to 0.0.2"</span>
<span class="c"># =&gt; main c17ce89] Update to 0.0.2</span>
<span class="c">#     2 files changed, 2 insertions(+), 2 deletions(-)</span>
<span class="nv">$ </span>git push origin main
<span class="c"># =&gt; Enumerating objects: 7, done.</span>
<span class="c">#    Counting objects: 100% (7/7), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (3/3), done.</span>
<span class="c">#    Writing objects: 100% (4/4), 332 bytes | 332.00 KiB/s, done.</span>
<span class="c">#    Total 4 (delta 2), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To http://10.0.4.3:3000/devops/dev-app.git</span>
<span class="c">#       3531233..c17ce89  main -&amp;gt; main</span>
</code></pre></div>    </div>
  </li>
  <li>Jenkins에서 Build Now를 클릭하여 통해 새로운 버전을 docker hub에 업로드 합니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_17.png" alt="img.png" /></p>

<ul>
  <li>새로운 버전이 docker hub에 업로드 되었으니, Kubernetes 클러스터에 배포해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 파드 복제복 증가</span>
<span class="nv">$ </span>kubectl scale deployment timeserver <span class="nt">--replicas</span> 4
<span class="c"># =&gt; deployment.apps/timeserver scaled</span>
<span class="nv">$ </span>kubectl get service,ep timeserver <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                 TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE   SELECTOR</span>
<span class="c">#    service/timeserver   NodePort   10.96.204.127   &amp;lt;none&amp;gt;        80:30000/TCP   45m   pod=timeserver-pod</span>
<span class="c">#    </span>
<span class="c">#    NAME                   ENDPOINTS                                               AGE</span>
<span class="c">#    endpoints/timeserver   10.244.1.6:80,10.244.1.7:80,10.244.2.8:80 + 1 more...   45m</span>

<span class="c"># 반복 접속 해두기 : 부하분산 확인</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 http://127.0.0.1:30000 | <span class="nb">grep </span>name <span class="p">;</span> <span class="nb">sleep </span>1 <span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; Server hostname: timeserver-549cc9bc89-kdmgx</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-h9q6p</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-kdmgx</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-xlbck</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#    ...</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span>  <span class="k">do </span>curl <span class="nt">-s</span> http://127.0.0.1:30000 | <span class="nb">grep </span>name<span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;   32 Server hostname: timeserver-549cc9bc89-xlbck</span>
<span class="c">#      27 Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#      25 Server hostname: timeserver-549cc9bc89-kdmgx</span>
<span class="c">#      16 Server hostname: timeserver-549cc9bc89-h9q6p</span>

<span class="c"># 업데이트를 배포하기 위해서 kubectl set image를 통해 컨테이너 이미지를 변경합니다.</span>
<span class="c"># $ kubectl set image deployment timeserver timeserver-container=$DHUSER/dev-app:0.0.Y &amp;&amp; watch -d "kubectl get deploy,ep timeserver; echo; kubectl get rs,pod"</span>
<span class="nv">$ </span>kubectl <span class="nb">set </span>image deployment timeserver timeserver-container<span class="o">=</span><span class="nv">$DHUSER</span>/dev-app:0.0.2 <span class="o">&amp;&amp;</span> watch <span class="nt">-d</span> <span class="s2">"kubectl get deploy,ep timeserver; echo; kubectl get rs,pod"</span>
<span class="c"># =&gt; Every 2.0s: kubectl get deploy,ep timeserver; echo; kubectl get rs,pod                                                                 Balthazar.local: Sun Oct 01 01:17:30 2024</span>
<span class="c">#    ...</span>
<span class="c">#    </span>
<span class="c">#    NAME                              READY   STATUS        RESTARTS   AGE</span>
<span class="c">#    pod/timeserver-549cc9bc89-h9q6p   1/1     Terminating   0          11m</span>
<span class="c">#    pod/timeserver-549cc9bc89-kdmgx   1/1     Terminating   0          88m</span>
<span class="c">#    pod/timeserver-549cc9bc89-pvm5k   1/1     Terminating   0          81m</span>
<span class="c">#    pod/timeserver-549cc9bc89-xlbck   1/1     Terminating   0          11m</span>
<span class="c">#    pod/timeserver-6f476fdbf-f8hw5    1/1     Running       0          9s</span>
<span class="c">#    pod/timeserver-6f476fdbf-k5fsn    1/1     Running       0          9s</span>
<span class="c">#    pod/timeserver-6f476fdbf-qq465    1/1     Running       0          4s</span>
<span class="c">#    pod/timeserver-6f476fdbf-tvrl5    1/1     Running       0          3s</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 기존 버전의 파드가 종료되고 새로운 파드가 replica 수 만큼 생성 되는 것을 확인 할 수 있습니다.&lt;/span&gt;</span>

<span class="c"># 롤링업데이트를 확인하기 위해 별도의 터미널에서 다음의 명령을 입력합니다.</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 http://127.0.0.1:30000<span class="p">;</span> <span class="nb">sleep </span>1 <span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    The time is 4:17:24 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#    The time is 4:17:25 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-xlbck</span>
<span class="c">#    The time is 4:17:26 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-xlbck</span>
<span class="c">#    The time is 4:17:27 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-pvm5k</span>
<span class="c">#    The time is 4:17:28 PM, VERSION 0.0.2</span>
<span class="c">#    Server hostname: timeserver-6f476fdbf-k5fsn</span>
<span class="c">#    The time is 4:17:29 PM, VERSION 0.0.2</span>
<span class="c">#    Server hostname: timeserver-6f476fdbf-qq465</span>
<span class="c">#    The time is 4:17:30 PM, VERSION 0.0.2</span>
<span class="c">#    Server hostname: timeserver-6f476fdbf-tvrl5</span>
<span class="c">#    The time is 4:17:31 PM, VERSION 0.0.2</span>
<span class="c">#    Server hostname: timeserver-6f476fdbf-f8hw5</span>
<span class="c">#    The time is 4:17:32 PM, VERSION 0.0.2</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 롤링업데이트를 통해 서비스 중단 없이 배포가 잘 됨을 확인 할 수 있습니다.&lt;/span&gt;</span>


<span class="c"># 롤링 업데이트 확인</span>
<span class="nv">$ </span>kubectl get deploy,rs,pod,svc,ep <span class="nt">-owide</span>

<span class="c"># kubectl get deploy $DEPLOYMENT_NAME</span>
<span class="nv">$ </span>kubectl get deploy timeserver
<span class="c"># =&gt; NAME         READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    timeserver   4/4     4            4           90m</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 READY는 전체 replica 중 몇 개의 파드가 서비스가 가능한지 알려줍니다.&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;    UP-TO-DATE는 몇 개의 파드가 현재의 버전(상태)인지 알려줍니다.&lt;/span&gt;</span>

<span class="nv">$ </span>kubectl get pods <span class="nt">-l</span> <span class="nv">pod</span><span class="o">=</span>timeserver-pod
<span class="c"># =&gt; NAME                         READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    timeserver-6f476fdbf-f8hw5   1/1     Running   0          3m3s</span>
<span class="c">#    timeserver-6f476fdbf-k5fsn   1/1     Running   0          3m3s</span>
<span class="c">#    timeserver-6f476fdbf-qq465   1/1     Running   0          2m58s</span>
<span class="c">#    timeserver-6f476fdbf-tvrl5   1/1     Running   0          2m57s</span>
</code></pre></div></div>

<h4 id="gogs-webhook을-통해-jenkins-pipeline-자동화">Gogs Webhook을 통해 Jenkins Pipeline 자동화</h4>

<ul>
  <li>Jenkins Pipeline을 통해 새로운 버전을 배포하는 과정을 자동화하기 위해 Gogs Webhook을 설정해보겠습니다.</li>
  <li>git push를 통해 새로운 버전을 업로드하면, Gogs Webhook을 통해 Jenkins Pipeline이 자동으로 실행되어 새로운 버전의 도커 이미지가 docker hub에 업로드되도록 합니다.</li>
</ul>

<h5 id="gogs-설정-수정-및-webhook-설정">Gogs 설정 수정 및 Webhook 설정</h5>

<ul>
  <li>
    <p>먼저 gogs 컨테이너의 app.ini 파일을 수정하여 jenkins가 gogs에 접근할 수 있도록 설정합니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># app.ini 파일 수정</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>gogs vi /data/gogs/conf/app.ini
</code></pre></div>    </div>

    <div class="language-ini highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># app.ini
</span><span class="err">...</span>
<span class="nn">[security]</span>
<span class="py">INSTALL_LOCK</span> <span class="p">=</span> <span class="s">true</span>
<span class="py">SECRET_KEY</span>   <span class="p">=</span> <span class="s">atxaUPQcbAEwpIu</span>
<span class="py">LOCAL_NETWORK_ALLOWLIST</span> <span class="p">=</span> <span class="s">10.0.4.3 # 각자 자신의 PC IP</span>
<span class="err">...</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>Gogs 컨테이너를 재기동합니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker compose restart gogs
</code></pre></div>    </div>
  </li>
  <li>
    <p>Gogs 에서 Webhook을 설정합니다.</p>
    <ol>
      <li>Repository를 선택후 우측의 Settings &gt; Webhooks &gt; Add a new webhook에서 Gogs를 선택합니다.
  <img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_18.png" alt="img.png" /></li>
      <li>Payload URL : <code class="language-plaintext highlighter-rouge">http://&lt;Jenkins의 IP = PC의 IP&gt;:8080/gogs-webhook/?job=SCM-Pipeline/</code></li>
      <li>Content Type : <code class="language-plaintext highlighter-rouge">application/json</code></li>
      <li>Secret : <code class="language-plaintext highlighter-rouge">qwe123</code></li>
      <li>When should this webhook be triggered? : Just the push event</li>
      <li>Active : 체크</li>
      <li>Add Webhook을 클릭하여 웹훅을 저장합니다.</li>
    </ol>
  </li>
</ul>

<h5 id="jenkins에서-gogs-webhook을-통한-pipeline-생성">Jenkins에서 Gogs Webhook을 통한 Pipeline 생성</h5>

<ul>
  <li>이번에는 Jenkins에서 앞서 생성한 Gogs Webhook을 통해 새로운 버전을 배포하는 Pipeline을 생성해보겠습니다.</li>
  <li>Dashboard &gt; New Item 을 선택합니다.
    <ul>
      <li>item name : SCM-Pipeline</li>
      <li>item type : Pipeline</li>
      <li>OK를 클릭합니다.</li>
    </ul>
  </li>
  <li>Pipeline 설정을 다음과 같이 설정합니다.
    <ul>
      <li>GitHub project : <code class="language-plaintext highlighter-rouge">http://&lt;PC의 IP&gt;:3000/&lt;Gogs 계정명&gt;/dev-app.git</code></li>
      <li>Use Gogs secret : <code class="language-plaintext highlighter-rouge">qwe123</code></li>
      <li>Build Triggers : Build when a change is pushed to Gogs 체크</li>
      <li>Pipeline script from SCM
        <ul>
          <li>SCM : Git
            <ul>
              <li>Repo URL : <code class="language-plaintext highlighter-rouge">http://&lt;PC의 IP&gt;:3000/&lt;Gogs 계정명&gt;/dev-app.git</code></li>
              <li>Credentials : <code class="language-plaintext highlighter-rouge">devops/*</code></li>
              <li>Branch : <code class="language-plaintext highlighter-rouge">*/main</code></li>
            </ul>
          </li>
          <li>Script Path : <code class="language-plaintext highlighter-rouge">Jenkinsfile</code> 
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_19.png" alt="img.png" /></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h5 id="jenkinsfile-작성-후-git-push">Jenkinsfile 작성 후 Git Push</h5>

<ul>
  <li>Jenkinsfile을 작성합니다.</li>
</ul>

<div class="language-groovy highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pipeline</span> <span class="o">{</span>
    <span class="n">agent</span> <span class="n">any</span>
    <span class="n">environment</span> <span class="o">{</span>
        <span class="n">DOCKER_IMAGE</span> <span class="o">=</span> <span class="s1">'&lt;자신의 도커 허브 계정&gt;/dev-app'</span> <span class="c1">// Docker 이미지 이름</span>
    <span class="o">}</span>
    <span class="n">stages</span> <span class="o">{</span>
        <span class="n">stage</span><span class="o">(</span><span class="s1">'Checkout'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                 <span class="n">git</span> <span class="nl">branch:</span> <span class="s1">'main'</span><span class="o">,</span>
                 <span class="nl">url:</span> <span class="s1">'http://&lt;PC의 IP&gt;:3000/devops/dev-app.git'</span><span class="o">,</span>  <span class="c1">// Git에서 코드 체크아웃</span>
                 <span class="nl">credentialsId:</span> <span class="s1">'gogs-crd'</span>  <span class="c1">// Credentials ID</span>
            <span class="o">}</span>
        <span class="o">}</span>
        <span class="n">stage</span><span class="o">(</span><span class="s1">'Read VERSION'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">script</span> <span class="o">{</span>
                    <span class="c1">// VERSION 파일 읽기</span>
                    <span class="kt">def</span> <span class="n">version</span> <span class="o">=</span> <span class="n">readFile</span><span class="o">(</span><span class="s1">'VERSION'</span><span class="o">).</span><span class="na">trim</span><span class="o">()</span>
                    <span class="n">echo</span> <span class="s2">"Version found: ${version}"</span>
                    <span class="c1">// 환경 변수 설정</span>
                    <span class="n">env</span><span class="o">.</span><span class="na">DOCKER_TAG</span> <span class="o">=</span> <span class="n">version</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
        <span class="n">stage</span><span class="o">(</span><span class="s1">'Docker Build and Push'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">script</span> <span class="o">{</span>
                    <span class="n">docker</span><span class="o">.</span><span class="na">withRegistry</span><span class="o">(</span><span class="s1">'https://index.docker.io/v1/'</span><span class="o">,</span> <span class="s1">'dockerhub-crd'</span><span class="o">)</span> <span class="o">{</span>
                        <span class="c1">// DOCKER_TAG 사용</span>
                        <span class="kt">def</span> <span class="n">appImage</span> <span class="o">=</span> <span class="n">docker</span><span class="o">.</span><span class="na">build</span><span class="o">(</span><span class="s2">"${DOCKER_IMAGE}:${DOCKER_TAG}"</span><span class="o">)</span>
                        <span class="n">appImage</span><span class="o">.</span><span class="na">push</span><span class="o">()</span>
                        <span class="n">appImage</span><span class="o">.</span><span class="na">push</span><span class="o">(</span><span class="s2">"latest"</span><span class="o">)</span>
                    <span class="o">}</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
    <span class="n">post</span> <span class="o">{</span>
        <span class="n">success</span> <span class="o">{</span>
            <span class="n">echo</span> <span class="s2">"Docker image ${DOCKER_IMAGE}:${DOCKER_TAG} has been built and pushed successfully!"</span>
        <span class="o">}</span>
        <span class="n">failure</span> <span class="o">{</span>
            <span class="n">echo</span> <span class="s2">"Pipeline failed. Please check the logs."</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<ul>
  <li>VERSION 파일과 server.py 파일을 0.0.2 =&gt; 0.0.3으로 수정합니다.</li>
  <li>작성된 파일 push</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"VERSION </span><span class="si">$(</span><span class="nb">cat </span>VERSION<span class="si">)</span><span class="s2"> Changed"</span> <span class="o">&amp;&amp;</span> git push <span class="nt">-u</span> origin main
</code></pre></div></div>

<ul>
  <li>Push와 거의 동시에 Jenkins에서 Build가 시작되고 성공적으로 빌드가 되었습니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_20.png" alt="img.png" /></p>

<ul>
  <li>Docker hub에도 0.0.3 버전이 업로드 잘 되었습니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_21.png" alt="img.png" /></p>

<ul>
  <li>Gogs에서 Repository &gt; Settings &gt; Webhooks &gt; 웹훅 클릭하면 웹훅 전달 로그를 확인할 수 있습니다.
Gogs =&gt; Jenkins의 방향으로 Webhook이 전달되었음을 확인할 수 있습니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_22.png" alt="img.png" /></p>

<ul>
  <li>마지막으로 Kubernetes 클러스터에서 새로운 버전을 배포하겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl <span class="nb">set </span>image deployment timeserver timeserver-container<span class="o">=</span><span class="nv">$DHUSER</span>/dev-app:0.0.3 <span class="o">&amp;&amp;</span> watch <span class="nt">-d</span> <span class="s2">"kubectl get deploy,ep timeserver; echo; kubectl get rs,pod"</span>
</code></pre></div></div>

<hr />

<h3 id="jenkins-cicd--k8s-kind">Jenkins CI/CD + K8S (Kind)</h3>

<ul>
  <li>이번에는 Jenkins에서 바로 Kubernetes 클러스터에 배포할 수 있도록 하는 실습을 진행해보겠습니다.</li>
  <li>Jenkins 컨테이너 내부에 필요한 툴(kubectl, helm)을 설치 하겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Install kubectl, helm</span>
<span class="nv">$ </span>docker compose <span class="nb">exec</span> <span class="nt">--privileged</span> <span class="nt">-u</span> root jenkins bash
<span class="nt">--------------------------------------------</span>
<span class="c">#curl -LO "https://dl.k8s.io/release/v1.31.0/bin/linux/amd64/kubectl" </span>
<span class="nv">$ </span>curl <span class="nt">-LO</span> <span class="s2">"https://dl.k8s.io/release/</span><span class="si">$(</span>curl <span class="nt">-L</span> <span class="nt">-s</span> https://dl.k8s.io/release/stable.txt<span class="si">)</span><span class="s2">/bin/linux/arm64/kubectl"</span>  <span class="c"># macOS</span>
<span class="c"># $ curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"  # WindowOS</span>

<span class="nv">$ </span><span class="nb">install</span> <span class="nt">-o</span> root <span class="nt">-g</span> root <span class="nt">-m</span> 0755 kubectl /usr/local/bin/kubectl
<span class="nv">$ </span>kubectl version <span class="nt">--client</span><span class="o">=</span><span class="nb">true</span>
<span class="c"># =&gt; Client Version: v1.32.0</span>
<span class="c">#    Kustomize Version: v5.5.0</span>

<span class="c">#</span>
<span class="nv">$ </span>curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
<span class="nv">$ </span>helm version
<span class="c"># =&gt; version.BuildInfo{Version:&amp;quot;v3.16.4&amp;quot;, GitCommit:&amp;quot;7877b45b63f95635153b29a42c0c2f4273ec45ca&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;, GoVersion:&amp;quot;go1.22.7&amp;quot;}</span>

<span class="nv">$ </span><span class="nb">exit</span>
<span class="nt">--------------------------------------------</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins kubectl version <span class="nt">--client</span><span class="o">=</span><span class="nb">true</span>
<span class="c"># =&gt; Client Version: v1.32.0</span>
<span class="c">#    Kustomize Version: v5.5.0</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins helm version
<span class="c"># =&gt; version.BuildInfo{Version:&amp;quot;v3.16.4&amp;quot;, GitCommit:&amp;quot;7877b45b63f95635153b29a42c0c2f4273ec45ca&amp;quot;, GitTreeState:&amp;quot;clean&amp;quot;, GoVersion:&amp;quot;go1.22.7&amp;quot;}</span>
</code></pre></div></div>

<ul>
  <li>Jenkins Item 생성(Pipeline) : item name(k8s-cmd)</li>
</ul>

<div class="language-gradle highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pipeline</span> <span class="o">{</span>
    <span class="n">agent</span> <span class="n">any</span>
    <span class="n">environment</span> <span class="o">{</span>
        <span class="n">KUBECONFIG</span> <span class="o">=</span> <span class="n">credentials</span><span class="o">(</span><span class="s1">'k8s-crd'</span><span class="o">)</span>
    <span class="o">}</span>
    <span class="n">stages</span> <span class="o">{</span>
        <span class="n">stage</span><span class="o">(</span><span class="s1">'List Pods'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">sh</span> <span class="s1">'''
                # Fetch and display Pods
                kubectl get pods -A --kubeconfig "$KUBECONFIG"
                '''</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_23.png" alt="img.png" /></p>

<h5 id="jenkins를-이용한-blue-green-배포-실습">Jenkins를 이용한 blue-green 배포 실습</h5>

<ul>
  <li>디플로이먼트 / 서비스 yaml 파일 작성 - http-echo 및 코드 push</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># </span>
<span class="nv">$ </span><span class="nb">cd </span>dev-app

<span class="c">#</span>
<span class="nv">$ </span><span class="nb">mkdir </span>deploy

<span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> deploy/echo-server-blue.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: apps/v1
kind: Deployment
metadata:
  name: echo-server-blue
spec:
  replicas: 2
  selector:
    matchLabels:
      app: echo-server
      version: blue
  template:
    metadata:
      labels:
        app: echo-server
        version: blue
    spec:
      containers:
      - name: echo-server
        image: hashicorp/http-echo
        args:
        - "-text=Hello from Blue"
        ports:
        - containerPort: 5678
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> deploy/echo-server-service.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: v1
kind: Service
metadata:
  name: echo-server-service
spec:
  selector:
    app: echo-server
    version: blue
  ports:
  - protocol: TCP
    port: 80
    targetPort: 5678
    nodePort: 30000
  type: NodePort
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> deploy/echo-server-green.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: apps/v1
kind: Deployment
metadata:
  name: echo-server-green
spec:
  replicas: 2
  selector:
    matchLabels:
      app: echo-server
      version: green
  template:
    metadata:
      labels:
        app: echo-server
        version: green
    spec:
      containers:
      - name: echo-server
        image: hashicorp/http-echo
        args:
        - "-text=Hello from Green"
        ports:
        - containerPort: 5678
</span><span class="no">EOF

</span><span class="c">#</span>
<span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"Add echo server yaml"</span> <span class="o">&amp;&amp;</span> git push <span class="nt">-u</span> origin main
<span class="c"># =&gt; main 76adc73] Add echo server yaml</span>
<span class="c">#     3 files changed, 60 insertions(+)</span>
<span class="c">#     create mode 100644 deploy/echo-server-blue.yaml</span>
<span class="c">#     create mode 100644 deploy/echo-server-green.yaml</span>
<span class="c">#     create mode 100644 deploy/echo-server-service.yaml</span>
<span class="c">#    Enumerating objects: 7, done.</span>
<span class="c">#    Counting objects: 100% (7/7), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (6/6), done.</span>
<span class="c">#    Writing objects: 100% (6/6), 789 bytes | 789.00 KiB/s, done.</span>
<span class="c">#    Total 6 (delta 2), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To http://10.0.4.3:3000/devops/dev-app.git</span>
<span class="c">#       60f336b..76adc73  main -&amp;gt; main</span>
<span class="c">#    branch 'main' set up to track 'origin/main'.</span>
</code></pre></div></div>

<ul>
  <li>Jenkins에서 Pipeline을 작성하여 배포해 보겠습니다.</li>
  <li>먼저, 이전 실습에서 배포한 deployment와 service를 삭제합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl delete deploy,svc timeserver
<span class="c"># =&gt; deployment.apps &amp;quot;timeserver&amp;quot; deleted</span>
<span class="c">#    service &amp;quot;timeserver&amp;quot; deleted</span>
</code></pre></div></div>

<ul>
  <li>반복접속을 미리 실행해둡니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 별도의 터미널에서 실행</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 http://127.0.0.1:30000 <span class="p">;</span> <span class="nb">echo</span> <span class="p">;</span> <span class="nb">sleep </span>1  <span class="p">;</span> kubectl get deploy <span class="nt">-owide</span> <span class="p">;</span> <span class="nb">echo</span> <span class="p">;</span> kubectl get svc,ep echo-server-service <span class="nt">-owide</span> <span class="p">;</span> <span class="nb">echo</span> <span class="s2">"------------"</span> <span class="p">;</span> <span class="k">done</span>
<span class="c"># 혹은 </span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 http://127.0.0.1:30000 <span class="p">;</span> <span class="nb">date</span> <span class="p">;</span> <span class="nb">echo</span> <span class="s2">"------------"</span> <span class="p">;</span> <span class="nb">sleep </span>1 <span class="p">;</span> <span class="k">done</span>
</code></pre></div></div>

<ul>
  <li>Jenkins에서 Pipeline 생성 : item name(k8s-bluegreen)</li>
</ul>

<div class="language-gradle highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pipeline</span> <span class="o">{</span>
    <span class="n">agent</span> <span class="n">any</span>

    <span class="n">environment</span> <span class="o">{</span>
        <span class="n">KUBECONFIG</span> <span class="o">=</span> <span class="n">credentials</span><span class="o">(</span><span class="s1">'k8s-crd'</span><span class="o">)</span>
    <span class="o">}</span>

    <span class="n">stages</span> <span class="o">{</span>
        <span class="n">stage</span><span class="o">(</span><span class="s1">'Checkout'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                 <span class="n">git</span> <span class="nl">branch:</span> <span class="s1">'main'</span><span class="o">,</span>
                 <span class="nl">url:</span> <span class="s1">'http://&lt;PC의 IP&gt;:3000/devops/dev-app.git'</span><span class="o">,</span>  <span class="c1">// Git에서 코드 체크아웃</span>
                 <span class="nl">credentialsId:</span> <span class="s1">'gogs-crd'</span>  <span class="c1">// Credentials ID</span>
            <span class="o">}</span>
        <span class="o">}</span>

        <span class="n">stage</span><span class="o">(</span><span class="s1">'container image build'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">echo</span> <span class="s2">"container image build"</span>
            <span class="o">}</span>
        <span class="o">}</span>

        <span class="n">stage</span><span class="o">(</span><span class="s1">'container image upload'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">echo</span> <span class="s2">"container image upload"</span>
            <span class="o">}</span>
        <span class="o">}</span>

        <span class="n">stage</span><span class="o">(</span><span class="s1">'k8s deployment blue version'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">sh</span> <span class="s2">"kubectl apply -f ./deploy/echo-server-blue.yaml --kubeconfig $KUBECONFIG"</span>
                <span class="n">sh</span> <span class="s2">"kubectl apply -f ./deploy/echo-server-service.yaml --kubeconfig $KUBECONFIG"</span>
            <span class="o">}</span>
        <span class="o">}</span>

        <span class="n">stage</span><span class="o">(</span><span class="s1">'approve green version'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">input</span> <span class="nl">message:</span> <span class="s1">'approve green version'</span><span class="o">,</span> <span class="nl">ok:</span> <span class="s2">"Yes"</span>
            <span class="o">}</span>
        <span class="o">}</span>

        <span class="n">stage</span><span class="o">(</span><span class="s1">'k8s deployment green version'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
	        	<span class="n">sh</span> <span class="s2">"kubectl apply -f ./deploy/echo-server-green.yaml --kubeconfig $KUBECONFIG"</span>
            <span class="o">}</span>
        <span class="o">}</span>

        <span class="n">stage</span><span class="o">(</span><span class="s1">'approve version switching'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">script</span> <span class="o">{</span>
                    <span class="n">returnValue</span> <span class="o">=</span> <span class="n">input</span> <span class="nl">message:</span> <span class="s1">'Green switching?'</span><span class="o">,</span> <span class="nl">ok:</span> <span class="s2">"Yes"</span><span class="o">,</span> <span class="nl">parameters:</span> <span class="o">[</span><span class="n">booleanParam</span><span class="o">(</span><span class="nl">defaultValue:</span> <span class="kc">true</span><span class="o">,</span> <span class="nl">name:</span> <span class="s1">'IS_SWITCHED'</span><span class="o">)]</span>
                    <span class="k">if</span> <span class="o">(</span><span class="n">returnValue</span><span class="o">)</span> <span class="o">{</span>
                        <span class="n">sh</span> <span class="s2">"kubectl patch svc echo-server-service -p '{\"spec\": {\"selector\": {\"version\": \"green\"}}}' --kubeconfig $KUBECONFIG"</span>
                    <span class="o">}</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>

        <span class="n">stage</span><span class="o">(</span><span class="s1">'Blue Rollback'</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">steps</span> <span class="o">{</span>
                <span class="n">script</span> <span class="o">{</span>
                    <span class="n">returnValue</span> <span class="o">=</span> <span class="n">input</span> <span class="nl">message:</span> <span class="s1">'Blue Rollback?'</span><span class="o">,</span> <span class="nl">parameters:</span> <span class="o">[</span><span class="n">choice</span><span class="o">(</span><span class="nl">choices:</span> <span class="o">[</span><span class="s1">'done'</span><span class="o">,</span> <span class="s1">'rollback'</span><span class="o">],</span> <span class="nl">name:</span> <span class="s1">'IS_ROLLBACk'</span><span class="o">)]</span>
                    <span class="k">if</span> <span class="o">(</span><span class="n">returnValue</span> <span class="o">==</span> <span class="s2">"done"</span><span class="o">)</span> <span class="o">{</span>
                        <span class="n">sh</span> <span class="s2">"kubectl delete -f ./deploy/echo-server-blue.yaml --kubeconfig $KUBECONFIG"</span>
                    <span class="o">}</span>
                    <span class="k">if</span> <span class="o">(</span><span class="n">returnValue</span> <span class="o">==</span> <span class="s2">"rollback"</span><span class="o">)</span> <span class="o">{</span>
                        <span class="n">sh</span> <span class="s2">"kubectl patch svc echo-server-service -p '{\"spec\": {\"selector\": {\"version\": \"blue\"}}}' --kubeconfig $KUBECONFIG"</span>
                    <span class="o">}</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<ul>
  <li>Build Now로 배포 후 동작을 확인합니다.
    <ul>
      <li>blue 버전이 배포된 다음 green 버전을 배포할지 승인 여부를 묻습니다.
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_24.png" alt="img.png" /></li>
      <li>승인하면 green 버전이 배포됩니다. 하지만 아직 트래픽은 Blue로만 흐릅니다.
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl get deploy <span class="nt">-owide</span> <span class="p">;</span> <span class="nb">echo</span> <span class="p">;</span> kubectl get svc,ep echo-server-service <span class="nt">-owide</span>
<span class="c"># =&gt; Hello from Blue</span>
<span class="c">#    </span>
<span class="c">#    NAME                READY   UP-TO-DATE   AVAILABLE   AGE     CONTAINERS    IMAGES                SELECTOR</span>
<span class="c">#    echo-server-blue    2/2     2            2           3m46s   echo-server   hashicorp/http-echo   app=echo-server,version=blue</span>
<span class="c">#    echo-server-green   2/2     2            2           31s     echo-server   hashicorp/http-echo   app=echo-server,version=green</span>
<span class="c">#    </span>
<span class="c">#    NAME                          TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE     SELECTOR</span>
<span class="c">#    service/echo-server-service   NodePort   10.96.40.148   &amp;lt;none&amp;gt;        80:30000/TCP   3m45s   app=echo-server,version=blue</span>
<span class="c">#    </span>
<span class="c">#    NAME                            ENDPOINTS                         AGE</span>
<span class="c">#    endpoints/echo-server-service   10.244.1.8:5678,10.244.2.8:5678   3m45s</span>
</code></pre></div>        </div>
      </li>
      <li>green으로 배포할지 승인하면 마침내 green으로 트래픽이 전달 됩니다. 
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_25.png" alt="img.png" />
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl get deploy <span class="nt">-owide</span> <span class="p">;</span> <span class="nb">echo</span> <span class="p">;</span> kubectl get svc,ep echo-server-service <span class="nt">-owide</span>
<span class="c"># =&gt; Hello from Green</span>
<span class="c">#    </span>
<span class="c">#    NAME                READY   UP-TO-DATE   AVAILABLE   AGE     CONTAINERS    IMAGES                SELECTOR</span>
<span class="c">#    echo-server-blue    2/2     2            2           6m14s   echo-server   hashicorp/http-echo   app=echo-server,version=blue</span>
<span class="c">#    echo-server-green   2/2     2            2           2m59s   echo-server   hashicorp/http-echo   app=echo-server,version=green</span>
<span class="c">#    </span>
<span class="c">#    NAME                          TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE     SELECTOR</span>
<span class="c">#    service/echo-server-service   NodePort   10.96.40.148   &amp;lt;none&amp;gt;        80:30000/TCP   6m13s   app=echo-server,version=green</span>
<span class="c">#    </span>
<span class="c">#    NAME                            ENDPOINTS                         AGE</span>
<span class="c">#    endpoints/echo-server-service   10.244.1.9:5678,10.244.2.9:5678   6m13s</span>
</code></pre></div>        </div>
      </li>
      <li>마지막으로 blue를 롤백할지 물으며, 승인하면 blue가 삭제 됩니다.
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># =&gt; Hello from Green</span>
<span class="c">#    </span>
<span class="c">#    NAME                READY   UP-TO-DATE   AVAILABLE   AGE     CONTAINERS    IMAGES                SELECTOR</span>
<span class="c">#    echo-server-green   2/2     2            2           4m55s   echo-server   hashicorp/http-echo   app=echo-server,version=green</span>
<span class="c">#    </span>
<span class="c">#    NAME                          TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE    SELECTOR</span>
<span class="c">#    service/echo-server-service   NodePort   10.96.40.148   &amp;lt;none&amp;gt;        80:30000/TCP   8m9s   app=echo-server,version=green</span>
<span class="c">#    </span>
<span class="c">#    NAME                            ENDPOINTS                         AGE</span>
<span class="c">#    endpoints/echo-server-service   10.244.1.9:5678,10.244.2.9:5678   8m9s</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li>실습 완료 후 삭제</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl delete deploy echo-server-blue echo-server-green
<span class="nv">$ </span>kubectl delete svc echo-server-service
</code></pre></div></div>

<h3 id="jenkins-ci--argocd--k8s-kind">Jenkins CI + ArgoCD + K8S (Kind)</h3>

<h4 id="argocd-소개">ArgoCD 소개</h4>

<ul>
  <li>ArgoCD는 GitOps를 지원하는 CD 도구로, Kubernetes 클러스터에 배포된 애플리케이션의 상태를 지속적으로 모니터링하고,
Git 저장소에 정의된 상태와 실제 상태가 일치하지 않을 경우 자동으로 동기화하여 애플리케이션을 원하는 상태로 유지하는 툴입니다.</li>
  <li>ArgoCD의 아키텍쳐
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_26.png" alt="img.png" /></li>
  <li>ArgoCD는 배포된 애플리케이션의 상태인 Kubernetes manifest를 다음의 방식들로 정의할 수 있습니다.
    <ul>
      <li><a href="https://kustomize.io/">Kustomize</a> 애플리케이션</li>
      <li><a href="https://helm.sh/">helm</a> chart</li>
      <li><a href="https://jsonnet.org/">jsonnet</a> 파일</li>
      <li>yaml/json manifest 파일이 있는 디렉터리</li>
      <li>기타 config management plugin에서 정의한 파일</li>
    </ul>
  </li>
  <li>자세한 사항은 <a href="https://argoproj.github.io/">공식 홈페이지</a>나 <a href="https://malwareanalysis.tistory.com/tag/ArgoCD">악분님 ArgoCD 정리 블로그</a>를 참고해주세요.</li>
</ul>

<h4 id="argocd-설치-및-기본설정">ArgoCD 설치 및 기본설정</h4>

<ul>
  <li>ArgoCD를 설치하고 기본 설정을 진행해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 네임스페이스 생성 및 파라미터 파일 작성</span>
<span class="nv">$ </span>kubectl create ns argocd
<span class="c"># =&gt; namespace/argocd created</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; argocd-values.yaml
dex:
  enabled: false

server:
  service:
    type: NodePort
    nodePortHttps: 30002
</span><span class="no">EOF

</span><span class="c"># 설치</span>
<span class="nv">$ </span>helm repo add argo https://argoproj.github.io/argo-helm
<span class="c"># =&gt; &amp;quot;argo&amp;quot; has been added to your repositories</span>
<span class="nv">$ </span>helm <span class="nb">install </span>argocd argo/argo-cd <span class="nt">--version</span> 7.7.10 <span class="nt">-f</span> argocd-values.yaml <span class="nt">--namespace</span> argocd
<span class="c"># =&gt; NAME: argocd</span>
<span class="c">#    LAST DEPLOYED: Sun Oct 01 16:53:42 2024</span>
<span class="c">#    NAMESPACE: argocd</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 1</span>
<span class="c">#    TEST SUITE: None</span>
<span class="c">#    NOTES:</span>
<span class="c">#    In order to access the server UI you have the following options:</span>
<span class="c">#    </span>
<span class="c">#    1. kubectl port-forward service/argocd-server -n argocd 8080:443</span>
<span class="c">#        and then open the browser on http://localhost:8080 and accept the certificate</span>
<span class="c">#    </span>
<span class="c">#    2. enable ingress in the values file `server.ingress.enabled` and either</span>
<span class="c">#          - Add the annotation for ssl passthrough: https://argo-cd.readthedocs.io/en/stable/operator-manual/ingress/#option-1-ssl-passthrough</span>
<span class="c">#          - Set the `configs.params.&amp;quot;server.insecure&amp;quot;` in the values file and terminate SSL at your ingress: https://argo-cd.readthedocs.io/en/stable/operator-manual/ingress/#option-2-multiple-ingress-objects-and-hosts</span>
<span class="c">#    </span>
<span class="c">#    After reaching the UI the first time you can login with username: admin and the random password generated during the installation. You can find the password by running:</span>
<span class="c">#    kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath=&amp;quot;{.data.password}&amp;quot; | base64 -d</span>
<span class="c">#    (You should delete the initial secret afterwards as suggested by the Getting Started Guide: https://argo-cd.readthedocs.io/en/stable/getting_started/#4-login-using-the-cli)</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get pod,svc,ep <span class="nt">-n</span> argocd
<span class="c"># =&gt; NAME                                                    READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/argocd-application-controller-0                     1/1     Running   0          4m55s</span>
<span class="c">#    pod/argocd-applicationset-controller-856f6bd788-zvtd2   1/1     Running   0          4m55s</span>
<span class="c">#    pod/argocd-notifications-controller-764b9d6597-z4mrx    1/1     Running   0          4m55s</span>
<span class="c">#    pod/argocd-redis-5c67786686-qwx8f                       1/1     Running   0          4m55s</span>
<span class="c">#    pod/argocd-repo-server-c9f8b6dbf-jpjcq                  1/1     Running   0          4m55s</span>
<span class="c">#    pod/argocd-server-7bff46b6bd-7n6vx                      1/1     Running   0          4m55s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                       TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE</span>
<span class="c">#    service/argocd-applicationset-controller   ClusterIP   10.96.166.245   &amp;lt;none&amp;gt;        7000/TCP                     4m55s</span>
<span class="c">#    service/argocd-redis                       ClusterIP   10.96.46.103    &amp;lt;none&amp;gt;        6379/TCP                     4m55s</span>
<span class="c">#    service/argocd-repo-server                 ClusterIP   10.96.117.132   &amp;lt;none&amp;gt;        8081/TCP                     4m55s</span>
<span class="c">#    service/argocd-server                      NodePort    10.96.75.70     &amp;lt;none&amp;gt;        80:30080/TCP,443:30002/TCP   4m55s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                         ENDPOINTS                           AGE</span>
<span class="c">#    endpoints/argocd-applicationset-controller   10.244.2.13:7000                    4m55s</span>
<span class="c">#    endpoints/argocd-redis                       10.244.2.12:6379                    4m55s</span>
<span class="c">#    endpoints/argocd-repo-server                 10.244.1.11:8081                    4m55s</span>
<span class="c">#    endpoints/argocd-server                      10.244.1.10:8080,10.244.1.10:8080   4m55s</span>
<span class="nv">$ </span>kubectl get crd | <span class="nb">grep </span>argo
<span class="c"># =&gt; applications.argoproj.io      2024-10-01T07:54:01Z</span>
<span class="c">#    applicationsets.argoproj.io   2024-10-01T07:54:01Z</span>
<span class="c">#    appprojects.argoproj.io       2024-10-01T07:54:01Z</span>

<span class="c"># 최초 접속 암호 확인</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> argocd get secret argocd-initial-admin-secret <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.data.password}"</span> | <span class="nb">base64</span> <span class="nt">-d</span> <span class="p">;</span><span class="nb">echo</span>
<span class="c"># =&gt; ZaQfvE9xrehyKxvl</span>

<span class="c"># Argo CD 웹 접속 주소 확인 : 초기 암호 입력 (admin 계정)</span>
<span class="nv">$ </span>open <span class="s2">"https://127.0.0.1:30002"</span> <span class="c"># macOS</span>
<span class="c">## Windows OS경우 직접 웹 브라우저에서 https://127.0.0.1:30002 접속</span>
</code></pre></div></div>

<ul>
  <li>Argo CD 웹 접속 확인 - 위에서 확인한 초기 비밀번호로 로그인합니다.
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_27.png" alt="img.png" class="image-center" />
<em class="image-caption">Argo CD 웹 초기 화면</em>
    <ul>
      <li>User Info &gt; Update password로 admin 계정 암호를 변경합니다. (qwe12345)</li>
    </ul>
  </li>
  <li>Settings &gt; Clusters, Projects, Accounts 등 기본정보를 확인해봅니다.</li>
  <li>실습을 위해 ops-deploy Repo를 등록해보겠습니다.
    <ul>
      <li>Settings &gt; Repositories &gt; Connect Repo 클릭
        <ul>
          <li>connection method : VIA HTTPS</li>
          <li>Type : git</li>
          <li>Project : default</li>
          <li>Repo URL : http://<PC의 IP="">:3000/devops/ops-deploy</PC의></li>
          <li>Username : devops</li>
          <li>Password : <Gogs 토큰=""></Gogs></li>
        </ul>

        <p>=&gt;  입력 후 CONNECT 클릭
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_28.png" alt="img.png" /></p>
      </li>
      <li>모든 정보가 정확하여 연결이 되면 연결상태가 Successful로 등록됩니다.</li>
    </ul>
  </li>
</ul>

<h4 id="helm-chart를-통한-배포-실습">Helm chart를 통한 배포 실습</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">mkdir </span>nginx-chart
<span class="nv">$ </span><span class="nb">cd </span>nginx-chart

<span class="nv">$ </span><span class="nb">mkdir </span>templates

<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> templates/configmap.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: v1
kind: ConfigMap
metadata:
  name: 
data:
  index.html: |
</span><span class="no">
EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> templates/deployment.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: apps/v1
kind: Deployment
metadata:
  name: 
spec:
  replicas: 
  selector:
    matchLabels:
      app: 
  template:
    metadata:
      labels:
        app: 
    spec:
      containers:
      - name: nginx
        image: :
        ports:
        - containerPort: 80
        volumeMounts:
        - name: index-html
          mountPath: /usr/share/nginx/html/index.html
          subPath: index.html
      volumes:
      - name: index-html
        configMap:
          name: 
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> templates/service.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: v1
kind: Service
metadata:
  name: 
spec:
  selector:
    app: 
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
    nodePort: 30000
  type: NodePort
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> values.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
indexHtml: |
  &lt;!DOCTYPE html&gt;
  &lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Welcome to Nginx!&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;h1&gt;Hello, Kubernetes!&lt;/h1&gt;
    &lt;p&gt;Nginx version 1.26.1&lt;/p&gt;
  &lt;/body&gt;
  &lt;/html&gt;

image:
  repository: nginx
  tag: 1.26.1

replicaCount: 1
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Chart.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: v2
name: nginx-chart
description: A Helm chart for deploying Nginx with custom index.html
type: application
version: 1.0.0
appVersion: "1.26.1"
</span><span class="no">EOF

</span><span class="c"># 이전 timeserver/service(nodeport) 삭제</span>
<span class="nv">$ </span>kubectl delete deploy,svc <span class="nt">--all</span>

<span class="c"># 직접 배포 해보기</span>
<span class="nv">$ </span>helm <span class="nb">install </span>dev-nginx <span class="nb">.</span> <span class="nt">-f</span> values.yaml
<span class="c"># =&gt; NAME: dev-nginx</span>
<span class="c">#    LAST DEPLOYED: Sun Oct 01 19:54:23 2024</span>
<span class="c">#    NAMESPACE: default</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 1</span>
<span class="c">#    TEST SUITE: None</span>
<span class="nv">$ </span>helm list
<span class="c"># =&gt; NAME       NAMESPACE REVISION  UPDATED                             STATUS    CHART             APP VERSION</span>
<span class="c">#    dev-nginx  default   1         2024-10-01 19:54:23.03644 +0900 KST deployed  nginx-chart-1.0.0 1.26.1     </span>
<span class="nv">$ </span>kubectl get deploy,svc,ep,cm dev-nginx <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                        READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES         SELECTOR</span>
<span class="c">#    deployment.apps/dev-nginx   1/1     1            1           4s    nginx        nginx:1.26.1   app=dev-nginx</span>
<span class="c">#    </span>
<span class="c">#    NAME                TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE   SELECTOR</span>
<span class="c">#    service/dev-nginx   NodePort   10.96.79.233   &amp;lt;none&amp;gt;        80:30000/TCP   4s    app=dev-nginx</span>
<span class="c">#    </span>
<span class="c">#    NAME                  ENDPOINTS        AGE</span>
<span class="c">#    endpoints/dev-nginx   10.244.1.16:80   4s</span>
<span class="c">#    </span>
<span class="c">#    NAME                  DATA   AGE</span>
<span class="c">#    configmap/dev-nginx   1      4s</span>

<span class="c">#</span>
<span class="nv">$ </span>curl http://127.0.0.1:30000
<span class="c"># =&gt; &lt;!DOCTYPE html&amp;gt;</span>
<span class="c">#    &amp;lt;html&amp;gt;</span>
<span class="c">#    &amp;lt;head&amp;gt;</span>
<span class="c">#      &amp;lt;title&amp;gt;Welcome to Nginx!&amp;lt;/title&amp;gt;</span>
<span class="c">#    &amp;lt;/head&amp;gt;</span>
<span class="c">#    &amp;lt;body&amp;gt;</span>
<span class="c">#      &amp;lt;h1&amp;gt;Hello, Kubernetes!&amp;lt;/h1&amp;gt;</span>
<span class="c">#      &amp;lt;p&amp;gt;Nginx version 1.26.1&amp;lt;/p&amp;gt;</span>
<span class="c">#    &amp;lt;/body&amp;gt;</span>
<span class="c">#    &amp;lt;/html&amp;gt;</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> http://127.0.0.1:30000 | <span class="nb">grep </span>version
<span class="c"># =&gt;   &amp;lt;p&amp;gt;Nginx version 1.26.1&amp;lt;/p&amp;gt;</span>
<span class="nv">$ </span>open http://127.0.0.1:30000

<span class="c"># value 값 변경 후 적용 해보기 : version/tag, replicaCount</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> values.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
indexHtml: |
  &lt;!DOCTYPE html&gt;
  &lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Welcome to Nginx!&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;h1&gt;Hello, Kubernetes!&lt;/h1&gt;
    &lt;p&gt;Nginx version 1.26.2&lt;/p&gt;
  &lt;/body&gt;
  &lt;/html&gt;

image:
  repository: nginx
  tag: 1.26.2

replicaCount: 2
</span><span class="no">EOF

</span><span class="c"># helm chart 업그레이드 적용</span>
<span class="nv">$ </span>helm upgrade dev-nginx <span class="nb">.</span> <span class="nt">-f</span> values.yaml
<span class="c"># =&gt; Release &amp;quot;dev-nginx&amp;quot; has been upgraded. Happy Helming!</span>
<span class="c">#    NAME: dev-nginx</span>
<span class="c">#    LAST DEPLOYED: Sun Oct 01 19:56:59 2024</span>
<span class="c">#    NAMESPACE: default</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 2</span>
<span class="c">#    TEST SUITE: None</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>helm list
<span class="c"># =&gt; NAME            NAMESPACE       REVISION        UPDATED                                 STATUS          CHART                   APP VERSION</span>
<span class="c">#    dev-nginx       default         2               2024-10-01 19:56:59.30731 +0900 KST     deployed        nginx-chart-1.0.0       1.26.1</span>
<span class="nv">$ </span>kubectl get deploy,svc,ep,cm dev-nginx <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                        READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES         SELECTOR</span>
<span class="c">#    deployment.apps/dev-nginx   &lt;span style="color: red;"&gt;2/2     2            2&lt;/span&gt;           38s   nginx        &lt;span style="color: red;"&gt;nginx:1.26.2&lt;/span&gt;   app=dev-nginx</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 Replica가 2개로 늘어나서 파드가 2개가 되었고 버전 1.26.2가 적용되었습니다.&lt;/span&gt;</span>
<span class="nv">$ </span>curl http://127.0.0.1:30000
<span class="c"># =&gt; &amp;lt;!DOCTYPE html&amp;gt;</span>
<span class="c">#    &amp;lt;html&amp;gt;</span>
<span class="c">#    &amp;lt;head&amp;gt;</span>
<span class="c">#      &amp;lt;title&amp;gt;Welcome to Nginx!&amp;lt;/title&amp;gt;</span>
<span class="c">#    &amp;lt;/head&amp;gt;</span>
<span class="c">#    &amp;lt;body&amp;gt;</span>
<span class="c">#      &amp;lt;h1&amp;gt;Hello, Kubernetes!&amp;lt;/h1&amp;gt;</span>
<span class="c">#      &amp;lt;p&amp;gt;Nginx version 1.26.2&amp;lt;/p&amp;gt;</span>
<span class="c">#    &amp;lt;/body&amp;gt;</span>
<span class="c">#    &amp;lt;/html&amp;gt;</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> http://127.0.0.1:30000 | <span class="nb">grep </span>version
<span class="c"># =&gt;   &amp;lt;p&amp;gt;Nginx version 1.26.2&amp;lt;/p&amp;gt;</span>
<span class="nv">$ </span>open http://127.0.0.1:30000

<span class="c"># 확인 후 삭제</span>
<span class="nv">$ </span>helm uninstall dev-nginx
</code></pre></div></div>

<h5 id="repoops-deploy-에-nginx-helm-chart-를-argo-cd를-통한-배포-1">Repo(ops-deploy) 에 nginx helm chart 를 Argo CD를 통한 배포 1</h5>

<ul>
  <li>git 작업</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">mkdir </span>cicd-labs
<span class="nv">$ </span><span class="nb">cd </span>cicd-labs
<span class="nv">$ </span>git clone http://10.0.4.3:3000/devops/ops-deploy.git
<span class="c"># =&gt; Cloning into 'ops-deploy'...</span>
<span class="c">#    remote: Enumerating objects: 3, done.</span>
<span class="c">#    remote: Counting objects: 100% (3/3), done.</span>
<span class="c">#    remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    Unpacking objects: 100% (3/3), 228 bytes | 114.00 KiB/s, done.</span>
<span class="nv">$ </span><span class="nb">cd </span>ops-deploy

<span class="c">#</span>
<span class="nv">$ </span>git config user.name <span class="s2">"devops"</span>
<span class="nv">$ </span>git config user.email <span class="s2">"a@a.com"</span>
<span class="nv">$ </span>git config init.defaultBranch main
<span class="nv">$ </span>git config credential.helper store

<span class="c">#</span>
<span class="nv">$ VERSION</span><span class="o">=</span>1.26.1
<span class="nv">$ </span><span class="nb">mkdir </span>nginx-chart
<span class="nv">$ </span><span class="nb">mkdir </span>nginx-chart/templates

<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> nginx-chart/VERSION <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
</span><span class="nv">$VERSION</span><span class="sh">
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> nginx-chart/templates/configmap.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: v1
kind: ConfigMap
metadata:
  name: 
data:
  index.html: |
</span><span class="no">
EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> nginx-chart/templates/deployment.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: apps/v1
kind: Deployment
metadata:
  name: 
spec:
  replicas: 
  selector:
    matchLabels:
      app: 
  template:
    metadata:
      labels:
        app: 
    spec:
      containers:
      - name: nginx
        image: :
        ports:
        - containerPort: 80
        volumeMounts:
        - name: index-html
          mountPath: /usr/share/nginx/html/index.html
          subPath: index.html
      volumes:
      - name: index-html
        configMap:
          name: 
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> nginx-chart/templates/service.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: v1
kind: Service
metadata:
  name: 
spec:
  selector:
    app: 
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
    nodePort: 30000
  type: NodePort
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> nginx-chart/values-dev.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
indexHtml: |
  &lt;!DOCTYPE html&gt;
  &lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Welcome to Nginx!&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;h1&gt;Hello, Kubernetes!&lt;/h1&gt;
    &lt;p&gt;DEV : Nginx version </span><span class="nv">$VERSION</span><span class="sh">&lt;/p&gt;
  &lt;/body&gt;
  &lt;/html&gt;

image:
  repository: nginx
  tag: </span><span class="nv">$VERSION</span><span class="sh">

replicaCount: 1
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> nginx-chart/values-prd.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
indexHtml: |
  &lt;!DOCTYPE html&gt;
  &lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Welcome to Nginx!&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;h1&gt;Hello, Kubernetes!&lt;/h1&gt;
    &lt;p&gt;PRD : Nginx version </span><span class="nv">$VERSION</span><span class="sh">&lt;/p&gt;
  &lt;/body&gt;
  &lt;/html&gt;

image:
  repository: nginx
  tag: </span><span class="nv">$VERSION</span><span class="sh">

replicaCount: 2
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> nginx-chart/Chart.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: v2
name: nginx-chart
description: A Helm chart for deploying Nginx with custom index.html
type: application
version: 1.0.0
appVersion: "</span><span class="nv">$VERSION</span><span class="sh">"
</span><span class="no">EOF

</span><span class="nv">$ </span>tree nginx-chart
<span class="c"># =&gt; nginx-chart</span>
<span class="c">#    ├── Chart.yaml</span>
<span class="c">#    ├── VERSION</span>
<span class="c">#    ├── templates</span>
<span class="c">#    │   ├── configmap.yaml</span>
<span class="c">#    │   ├── deployment.yaml</span>
<span class="c">#    │   └── service.yaml</span>
<span class="c">#    ├── values-dev.yaml</span>
<span class="c">#    └── values-prd.yaml</span>

<span class="c">#</span>
<span class="nv">$ </span>git status <span class="o">&amp;&amp;</span> git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"Add nginx helm chart"</span> <span class="o">&amp;&amp;</span> git push <span class="nt">-u</span> origin main
<span class="c"># =&gt; On branch main</span>
<span class="c">#    Your branch is up to date with 'origin/main'.</span>
<span class="c">#    </span>
<span class="c">#    Untracked files:</span>
<span class="c">#      (use &amp;quot;git add &amp;lt;file&amp;gt;...&amp;quot; to include in what will be committed)</span>
<span class="c">#            nginx-chart/</span>
<span class="c">#    </span>
<span class="c">#    nothing added to commit but untracked files present (use &amp;quot;git add&amp;quot; to track)</span>
<span class="c">#    [main 2bcfda2] Add nginx helm chart</span>
<span class="c">#     7 files changed, 88 insertions(+)</span>
<span class="c">#     create mode 100644 nginx-chart/Chart.yaml</span>
<span class="c">#     create mode 100644 nginx-chart/VERSION</span>
<span class="c">#     create mode 100644 nginx-chart/templates/configmap.yaml</span>
<span class="c">#     create mode 100644 nginx-chart/templates/deployment.yaml</span>
<span class="c">#     create mode 100644 nginx-chart/templates/service.yaml</span>
<span class="c">#     create mode 100644 nginx-chart/values-dev.yaml</span>
<span class="c">#     create mode 100644 nginx-chart/values-prd.yaml</span>
<span class="c">#    Enumerating objects: 12, done.</span>
<span class="c">#    Counting objects: 100% (12/12), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (10/10), done.</span>
<span class="c">#    Writing objects: 100% (11/11), 1.44 KiB | 1.44 MiB/s, done.</span>
<span class="c">#    Total 11 (delta 1), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To http://10.0.4.3:3000/devops/ops-deploy.git</span>
<span class="c">#       f7dc047..2bcfda2  main -&amp;gt; main</span>
<span class="c">#    branch 'main' set up to track 'origin/main'.</span>
</code></pre></div></div>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_29.png" alt="img.png" /></p>

<h5 id="argo-cd에-app-등록">Argo CD에 App 등록</h5>

<ul>
  <li>ArgoCD에서 Application &gt; New App을 클릭하여 애플리케이션을 등록합니다.
    <ul>
      <li>GENERAL
        <ul>
          <li>App Name : dev-nginx</li>
          <li>Project Name : default</li>
          <li>SYNC POLICY : Manual</li>
          <li>SYNC OPTIONS : AUTO-CREATE NAMESPACE(Check)</li>
        </ul>
      </li>
      <li>Source
        <ul>
          <li>Repo URL : <code class="language-plaintext highlighter-rouge">&lt;설정되어 있는 것 선택&gt;</code> (http://10.0.4.3:3000/devops/ops-deploy)</li>
          <li>Revision : HEAD</li>
          <li>PATH : nginx-chart</li>
        </ul>
      </li>
      <li>DESTINATION
        <ul>
          <li>Cluster URL : <code class="language-plaintext highlighter-rouge">&lt;기본값&gt;</code></li>
          <li>NAMESPACE : dev-nginx</li>
        </ul>
      </li>
      <li>HELM
        <ul>
          <li>Values files : values-dev.yaml 
=&gt; 작성 후 상단 CREATE 클릭</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_30.png" alt="img.png" class="image-center" />
<em class="image-caption">Argo CD Application 등록 직후</em></p>

<ul>
  <li>등록 직후에는 git에 등록된 manifest 파일의 내용과 현재 k8s의 상태가 다르기 때문에 <code class="language-plaintext highlighter-rouge">OutOfSync</code> 상태로 표시됩니다.</li>
  <li>dev-nginx를 클릭해서 보면 리소스의 배치와 어떤 리소스가 <code class="language-plaintext highlighter-rouge">OutOfSync</code>인지 표시가 됩니다.</li>
  <li>다음 명령을 입력해서 application의 배포상태를 확인해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>kubectl get applications <span class="nt">-n</span> argocd
<span class="c"># =&gt; NAME        SYNC STATUS   HEALTH STATUS</span>
<span class="c">#    dev-nginx   OutOfSync     Missing</span>

<span class="nv">$ </span>kubectl describe applications <span class="nt">-n</span> argocd dev-nginx
<span class="c"># =&gt; ...</span>
<span class="c">#    Events:</span>
<span class="c">#      Type    Reason           Age    From                           Message</span>
<span class="c">#      ----    ------           ----   ----                           -------</span>
<span class="c">#      Normal  ResourceCreated  7m38s  argocd-server                  admin created application</span>
<span class="c">#      Normal  ResourceUpdated  7m     argocd-application-controller  Updated sync status:  -&amp;gt; Unknown</span>
<span class="c">#      Normal  ResourceUpdated  6m58s  argocd-application-controller  Updated health status:  -&amp;gt; Healthy</span>
<span class="c">#      Normal  ResourceUpdated  3m35s  argocd-application-controller  Updated sync status: Unknown -&amp;gt; OutOfSync</span>
<span class="c">#      Normal  ResourceUpdated  3m35s  argocd-application-controller  Updated health status: Healthy -&amp;gt; Missing</span>

<span class="c"># 반복 접속 시도</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 http://127.0.0.1:30000 <span class="p">;</span> <span class="nb">date</span> <span class="p">;</span> <span class="nb">echo</span> <span class="s2">"------------"</span> <span class="p">;</span> <span class="nb">sleep </span>1 <span class="p">;</span> <span class="k">done</span>
</code></pre></div></div>

<ul>
  <li>ArgoCD에서 DIFF 버튼을 클릭하면 현재 상태와 git에 등록된 상태를 비교할 수 있습니다.
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_31.png" alt="img.png" class="image-center" />
<em class="image-caption">Argo CD Application DIFF 화면</em></li>
  <li>SYNC 버튼을 클릭하여 git의 manifest에 지정된 상태와 k8s의 상태를 동기화 해보겠습니다.
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_32.png" alt="img.png" /></li>
  <li>동기화가 완료되면 다음과 같이 노란색 화살표 아이콘 대신 녹색 체크표시가 나면서 <code class="language-plaintext highlighter-rouge">Synced</code> 상태로 변경됩니다. 
또한 동시에 Kubernetes에 NGINX가 배포가 잘 되었습니다.
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_33.png" alt="img.png" class="image-center" />
<em class="image-caption">Argo CD Application 동기화 완료</em></li>
</ul>

<h5 id="코드-수정-후-반영-확인">코드 수정 후 반영 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ VERSION</span><span class="o">=</span>1.26.2

<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> nginx-chart/VERSION <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
</span><span class="nv">$VERSION</span><span class="sh">
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> nginx-chart/values-dev.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
indexHtml: |
  &lt;!DOCTYPE html&gt;
  &lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Welcome to Nginx!&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;h1&gt;Hello, Kubernetes!&lt;/h1&gt;
    &lt;p&gt;DEV : Nginx version </span><span class="nv">$VERSION</span><span class="sh">&lt;/p&gt;
  &lt;/body&gt;
  &lt;/html&gt;

image:
  repository: nginx
  tag: </span><span class="nv">$VERSION</span><span class="sh">

replicaCount: 2
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> nginx-chart/values-prd.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
indexHtml: |
  &lt;!DOCTYPE html&gt;
  &lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Welcome to Nginx!&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;h1&gt;Hello, Kubernetes!&lt;/h1&gt;
    &lt;p&gt;PRD : Nginx version </span><span class="nv">$VERSION</span><span class="sh">&lt;/p&gt;
  &lt;/body&gt;
  &lt;/html&gt;

image:
  repository: nginx
  tag: </span><span class="nv">$VERSION</span><span class="sh">

replicaCount: 2
</span><span class="no">EOF

</span><span class="c">#</span>
<span class="nv">$ </span>git status <span class="o">&amp;&amp;</span> git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"Update nginx version </span><span class="si">$(</span><span class="nb">cat </span>nginx-chart/VERSION<span class="si">)</span><span class="s2">"</span> <span class="o">&amp;&amp;</span> git push <span class="nt">-u</span> origin main
<span class="c"># =&gt; On branch main</span>
<span class="c">#    Your branch is up to date with 'origin/main'.</span>
<span class="c">#    </span>
<span class="c">#    Changes not staged for commit:</span>
<span class="c">#      (use &amp;quot;git add &amp;lt;file&amp;gt;...&amp;quot; to update what will be committed)</span>
<span class="c">#      (use &amp;quot;git restore &amp;lt;file&amp;gt;...&amp;quot; to discard changes in working directory)</span>
<span class="c">#            modified:   nginx-chart/VERSION</span>
<span class="c">#            modified:   nginx-chart/values-dev.yaml</span>
<span class="c">#            modified:   nginx-chart/values-prd.yaml</span>
<span class="c">#    </span>
<span class="c">#    no changes added to commit (use &amp;quot;git add&amp;quot; and/or &amp;quot;git commit -a&amp;quot;)</span>
<span class="c">#    [main e1b02a2] Update nginx version 1.26.2</span>
<span class="c">#     3 files changed, 6 insertions(+), 6 deletions(-)</span>
<span class="c">#    Enumerating objects: 11, done.</span>
<span class="c">#    Counting objects: 100% (11/11), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (5/5), done.</span>
<span class="c">#    Writing objects: 100% (6/6), 589 bytes | 589.00 KiB/s, done.</span>
<span class="c">#    Total 6 (delta 2), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To http://10.0.4.3:3000/devops/ops-deploy.git</span>
<span class="c">#       2bcfda2..e1b02a2  main -&amp;gt; main</span>
<span class="c">#    branch 'main' set up to track 'origin/main'.</span>
</code></pre></div></div>

<ul>
  <li>Argo CD 웹 확인 =&gt; REFRESH 클릭
    <ul>
      <li>ArgoCD는 주기적으로 동기화 되나 바로 확인하려면 REFRESH 버튼을 클릭해야 합니다. (기본 주기는 3분)
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_34.png" alt="img.png" class="image-center" /></li>
      <li>DIFF로 확인하면 manifest 파일의 변경사항이 나타납니다.
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_35.png" alt="img.png" class="image-center" /></li>
    </ul>
  </li>
  <li>SYNC &gt; SYNCHRONIZE를 클릭하여 동기화 해보겠습니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 배포확인</span>
<span class="nv">$ </span>kubectl get all <span class="nt">-n</span> dev-nginx <span class="nt">-o</span> wide
<span class="c"># =&gt; NAME                             READY   STATUS    RESTARTS   AGE   IP           NODE            NOMINATED NODE   READINESS GATES</span>
<span class="c">#    pod/dev-nginx-5db658bd4f-nfldn   1/1     Running   0          8s    10.244.1.7   myk8s-worker    &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    pod/dev-nginx-5db658bd4f-rxmfz   1/1     Running   0          10s   10.244.2.6   myk8s-worker2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    </span>
<span class="c">#    NAME                TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE   SELECTOR</span>
<span class="c">#    service/dev-nginx   NodePort   10.96.233.99   &amp;lt;none&amp;gt;        80:30000/TCP   16m   app=dev-nginx</span>
<span class="c">#    </span>
<span class="c">#    NAME                        READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES         SELECTOR</span>
<span class="c">#    deployment.apps/dev-nginx   2/2     2            2           16m   nginx        &lt;span style="color: red;"&gt;nginx:1.26.2&lt;/span&gt;   app=dev-nginx</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 변경된 버전이 잘 배포되었습니다.&lt;/span&gt;</span>
<span class="c">#    </span>
<span class="c">#    NAME                                   DESIRED   CURRENT   READY   AGE   CONTAINERS   IMAGES         SELECTOR</span>
<span class="c">#    replicaset.apps/dev-nginx-5db658bd4f   2         2         2       11s   nginx        nginx:1.26.2   app=dev-nginx,pod-template-hash=5db658bd4f</span>
<span class="c">#    replicaset.apps/dev-nginx-77d44dfbf6   0         0         0       16m   nginx        nginx:1.26.1   app=dev-nginx,pod-template-hash=77d44dfbf6</span>
</code></pre></div>    </div>
  </li>
  <li>여기에서 replicaset은 기존 1.26.1이 남아있는데 그것은 ArgoCD가 Rollback을 지원하기 위해 기존 replicaset을 남겨서 관리하기 때문입니다.</li>
  <li>몇개의 history를 남길지는 설정에서 변경할 수 있습니다.</li>
  <li>ArgoCD웹 에서 APP 삭제하고 아래의 명령으로 삭제 진행상황을 확인합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>watch <span class="nt">-d</span> kubectl get all <span class="nt">-n</span> dev-nginx <span class="nt">-o</span> wide
</code></pre></div></div>

<h4 id="argocd-declarative-setup으로-배포-실습">ArgoCD Declarative Setup으로 배포 실습</h4>

<ul>
  <li>이번에는 ArgoCD 애플리케이션 자체를 yaml로 생성해보겠습니다.</li>
  <li>이를 통해 애플리케이션을 생성하고 배포하는 과정을 자동화할 수 있습니다.</li>
  <li>자세한 사항은 다음 공식 문서를 참고하세요. <a href="https://argo-cd.readthedocs.io/en/stable/operator-manual/declarative-setup/">ArgoCD Declarative Setup - Project, applications, ArgoCD Settings - Docs</a></li>
  <li>dev-nginx App 생성 및 Auto SYNC</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Declarative 방식으로 ArgoCD App 생성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: dev-nginx
  namespace: argocd
  finalizers:
  - resources-finalizer.argocd.argoproj.io
spec:
  project: default
  source:
    helm:
      valueFiles:
      - values-dev.yaml
    path: nginx-chart
    repoURL: http://10.0.4.3:3000/devops/ops-deploy
    targetRevision: HEAD
  syncPolicy:
    automated:
      prune: true
    syncOptions:
    - CreateNamespace=true
  destination:
    namespace: dev-nginx
    server: https://kubernetes.default.svc
</span><span class="no">EOF
</span><span class="c"># =&gt; application.argoproj.io/dev-nginx created</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get applications <span class="nt">-n</span> argocd dev-nginx
<span class="c"># =&gt; NAME        SYNC STATUS   HEALTH STATUS</span>
<span class="c">#    dev-nginx   Synced        Healthy</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 automated sync 정책이어서 배포 직후 동기화 된 상태가 됩니다.&lt;/span&gt;</span>
<span class="nv">$ </span>kubectl get applications <span class="nt">-n</span> argocd dev-nginx <span class="nt">-o</span> yaml | kubectl neat
<span class="nv">$ </span>kubectl describe applications <span class="nt">-n</span> argocd dev-nginx
<span class="c"># =&gt; ...</span>
<span class="c">#    Events:</span>
<span class="c">#      Type    Reason              Age   From                           Message</span>
<span class="c">#      ----    ------              ----  ----                           -------</span>
<span class="c">#      Normal  ResourceUpdated     80s   argocd-application-controller  Updated sync status:  -&amp;gt; Unknown</span>
<span class="c">#      Normal  ResourceUpdated     80s   argocd-application-controller  Updated health status:  -&amp;gt; Healthy</span>
<span class="c">#      Normal  OperationStarted    57s   argocd-application-controller  Initiated automated sync to 'e1b02a29e47a839ebcc93e46ee9da1f2d5320148'</span>
<span class="c">#      Normal  ResourceUpdated     57s   argocd-application-controller  Updated sync status: Unknown -&amp;gt; OutOfSync</span>
<span class="c">#      Normal  ResourceUpdated     57s   argocd-application-controller  Updated health status: Healthy -&amp;gt; Missing</span>
<span class="c">#      Normal  ResourceUpdated     57s   argocd-application-controller  Updated sync status: OutOfSync -&amp;gt; Synced</span>
<span class="c">#      Normal  ResourceUpdated     57s   argocd-application-controller  Updated health status: Missing -&amp;gt; Progressing</span>
<span class="c">#      Normal  OperationCompleted  57s   argocd-application-controller  Sync operation to e1b02a29e47a839ebcc93e46ee9da1f2d5320148 succeeded</span>
<span class="c">#      Normal  ResourceUpdated     55s   argocd-application-controller  Updated health status: Progressing -&amp;gt; Healthy</span>
<span class="nv">$ </span>kubectl get pod,svc,ep,cm <span class="nt">-n</span> dev-nginx
<span class="c"># =&gt; NAME                             READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/dev-nginx-5db658bd4f-blcr6   1/1     Running   0          74s</span>
<span class="c">#    pod/dev-nginx-5db658bd4f-k984k   1/1     Running   0          74s</span>
<span class="c">#    </span>
<span class="c">#    NAME                TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE</span>
<span class="c">#    service/dev-nginx   NodePort   10.96.176.134   &amp;lt;none&amp;gt;        80:30000/TCP   74s</span>
<span class="c">#    </span>
<span class="c">#    NAME                  ENDPOINTS                     AGE</span>
<span class="c">#    endpoints/dev-nginx   10.244.1.8:80,10.244.2.8:80   74s</span>
<span class="c">#    </span>
<span class="c">#    NAME                         DATA   AGE</span>
<span class="c">#    configmap/dev-nginx          1      74s</span>
<span class="c">#    configmap/kube-root-ca.crt   1      24m</span>

<span class="c">#</span>
<span class="nv">$ </span>curl http://127.0.0.1:30000
<span class="c"># =&gt; &amp;lt;!DOCTYPE html&amp;gt;</span>
<span class="c">#    &amp;lt;html&amp;gt;</span>
<span class="c">#    &amp;lt;head&amp;gt;</span>
<span class="c">#      &amp;lt;title&amp;gt;Welcome to Nginx!&amp;lt;/title&amp;gt;</span>
<span class="c">#    &amp;lt;/head&amp;gt;</span>
<span class="c">#    &amp;lt;body&amp;gt;</span>
<span class="c">#      &amp;lt;h1&amp;gt;Hello, Kubernetes!&amp;lt;/h1&amp;gt;</span>
<span class="c">#      &amp;lt;p&amp;gt;DEV : Nginx version 1.26.2&amp;lt;/p&amp;gt;</span>
<span class="c">#    &amp;lt;/body&amp;gt;</span>
<span class="c">#    &amp;lt;/html&amp;gt;</span>
<span class="nv">$ </span>open http://127.0.0.1:30000

<span class="c"># Argo CD App 삭제</span>
<span class="nv">$ </span>kubectl delete applications <span class="nt">-n</span> argocd dev-nginx
<span class="c"># =&gt; application.argoproj.io &amp;quot;dev-nginx&amp;quot; deleted</span>
</code></pre></div></div>

<ul>
  <li>prd-nginx App 생성 및 Auto SYNC</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: prd-nginx
  namespace: argocd
  finalizers:
  - resources-finalizer.argocd.argoproj.io
spec:
  destination:
    namespace: prd-nginx
    server: https://kubernetes.default.svc
  project: default
  source:
    helm:
      valueFiles:
      - values-prd.yaml
    path: nginx-chart
    repoURL: http://10.0.4.3:3000/devops/ops-deploy
    targetRevision: HEAD
  syncPolicy:
    automated:
      prune: true
    syncOptions:
    - CreateNamespace=true
</span><span class="no">EOF
</span><span class="c"># =&gt; application.argoproj.io/prd-nginx created</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get applications <span class="nt">-n</span> argocd prd-nginx
<span class="c"># =&gt; NAME        SYNC STATUS   HEALTH STATUS</span>
<span class="c">#    prd-nginx   Synced        Healthy</span>
<span class="nv">$ </span>kubectl describe applications <span class="nt">-n</span> argocd prd-nginx
<span class="c"># =&gt; ...</span>
<span class="c">#    Events:</span>
<span class="c">#      Type    Reason              Age   From                           Message</span>
<span class="c">#      ----    ------              ----  ----                           -------</span>
<span class="c">#      Normal  ResourceUpdated     28s   argocd-application-controller  Updated sync status:  -&amp;gt; Unknown</span>
<span class="c">#      Normal  ResourceUpdated     28s   argocd-application-controller  Updated health status:  -&amp;gt; Healthy</span>
<span class="c">#      Normal  OperationStarted    18s   argocd-application-controller  Initiated automated sync to 'e1b02a29e47a839ebcc93e46ee9da1f2d5320148'</span>
<span class="c">#      Normal  ResourceUpdated     18s   argocd-application-controller  Updated sync status: Unknown -&amp;gt; OutOfSync</span>
<span class="c">#      Normal  ResourceUpdated     18s   argocd-application-controller  Updated health status: Healthy -&amp;gt; Missing</span>
<span class="c">#      Normal  ResourceUpdated     15s   argocd-application-controller  Updated sync status: OutOfSync -&amp;gt; Synced</span>
<span class="c">#      Normal  ResourceUpdated     15s   argocd-application-controller  Updated health status: Missing -&amp;gt; Progressing</span>
<span class="c">#      Normal  OperationCompleted  15s   argocd-application-controller  Sync operation to e1b02a29e47a839ebcc93e46ee9da1f2d5320148 succeeded</span>
<span class="c">#      Normal  ResourceUpdated     13s   argocd-application-controller  Updated health status: Progressing -&amp;gt; Healthy</span>
<span class="nv">$ </span>kubectl get pod,svc,ep,cm <span class="nt">-n</span> prd-nginx
<span class="c"># =&gt; NAME                             READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/prd-nginx-645b5ffbbf-9jp6g   1/1     Running   0          45s</span>
<span class="c">#    pod/prd-nginx-645b5ffbbf-ch6q2   1/1     Running   0          45s</span>
<span class="c">#    </span>
<span class="c">#    NAME                TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE</span>
<span class="c">#    service/prd-nginx   NodePort   10.96.206.18   &amp;lt;none&amp;gt;        80:30000/TCP   45s</span>
<span class="c">#    </span>
<span class="c">#    NAME                  ENDPOINTS                     AGE</span>
<span class="c">#    endpoints/prd-nginx   10.244.1.9:80,10.244.2.9:80   45s</span>
<span class="c">#    </span>
<span class="c">#    NAME                         DATA   AGE</span>
<span class="c">#    configmap/kube-root-ca.crt   1      47s</span>
<span class="c">#    configmap/prd-nginx          1      45s</span>

<span class="c">#</span>
<span class="nv">$ </span>curl http://127.0.0.1:30000
<span class="c"># =&gt; &amp;lt;!DOCTYPE html&amp;gt;</span>
<span class="c">#    &amp;lt;html&amp;gt;</span>
<span class="c">#    &amp;lt;head&amp;gt;</span>
<span class="c">#      &amp;lt;title&amp;gt;Welcome to Nginx!&amp;lt;/title&amp;gt;</span>
<span class="c">#    &amp;lt;/head&amp;gt;</span>
<span class="c">#    &amp;lt;body&amp;gt;</span>
<span class="c">#      &amp;lt;h1&amp;gt;Hello, Kubernetes!&amp;lt;/h1&amp;gt;</span>
<span class="c">#      &amp;lt;p&amp;gt;PRD : Nginx version 1.26.2&amp;lt;/p&amp;gt;</span>
<span class="c">#    &amp;lt;/body&amp;gt;</span>
<span class="c">#    &amp;lt;/html&amp;gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 PRD nginx가 잘 배포되었습니다.&lt;/span&gt;</span>
<span class="nv">$ </span>open http://127.0.0.1:30000

<span class="c"># Argo CD App 삭제</span>
<span class="nv">$ </span>kubectl delete applications <span class="nt">-n</span> argocd prd-nginx
<span class="c"># =&gt; application.argoproj.io &amp;quot;prd-nginx&amp;quot; deleted</span>
</code></pre></div></div>

<h4 id="argocd를-이용한-full-cicd-구성">ArgoCD를 이용한 Full CI/CD 구성</h4>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_36.png" alt="img.png" /></p>

<ul>
  <li>최종적으로 위와 같이 CI/CD 파이프라인을 구성해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">cd </span>ops-deploy
<span class="nv">$ </span><span class="nb">mkdir </span>dev-app

<span class="c"># 도커 계정 정보</span>
<span class="c">#$ DHUSER=&lt;도커 허브 계정&gt;</span>
<span class="nv">$ DHUSER</span><span class="o">=</span>sweetlittlebird

<span class="c"># 버전 정보 </span>
<span class="nv">$ VERSION</span><span class="o">=</span>0.0.1

<span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> dev-app/VERSION <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
</span><span class="nv">$VERSION</span><span class="sh">
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> dev-app/timeserver.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: apps/v1
kind: Deployment
metadata:
  name: timeserver
spec:
  replicas: 2
  selector:
    matchLabels:
      pod: timeserver-pod
  template:
    metadata:
      labels:
        pod: timeserver-pod
    spec:
      containers:
      - name: timeserver-container
        image: docker.io/</span><span class="nv">$DHUSER</span><span class="sh">/dev-app:</span><span class="nv">$VERSION</span><span class="sh">
      imagePullSecrets:
      - name: dockerhub-secret
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> dev-app/service.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
apiVersion: v1
kind: Service
metadata:
  name: timeserver
spec:
  selector:
    pod: timeserver-pod
  ports:
  - port: 80
    targetPort: 80
    protocol: TCP
    nodePort: 30000
  type: NodePort
</span><span class="no">EOF

</span><span class="c">#</span>
<span class="nv">$ </span>git status <span class="o">&amp;&amp;</span> git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"Add dev-app deployment yaml"</span> <span class="o">&amp;&amp;</span> git push <span class="nt">-u</span> origin main
</code></pre></div></div>

<ul>
  <li>ArgoCD에 app 생성</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: timeserver
  namespace: argocd
  finalizers:
  - resources-finalizer.argocd.argoproj.io
spec:
  project: default
  source:
    path: dev-app
    repoURL: http://10.0.4.3:3000/devops/ops-deploy
    targetRevision: HEAD
  syncPolicy:
    automated:
      prune: true
    syncOptions:
    - CreateNamespace=true
  destination:
    namespace: default
    server: https://kubernetes.default.svc
</span><span class="no">EOF
</span><span class="c"># =&gt; application.argoproj.io/timeserver created</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get applications <span class="nt">-n</span> argocd timeserver
<span class="c"># =&gt; NAME         SYNC STATUS   HEALTH STATUS</span>
<span class="c">#    timeserver   Synced        Healthy</span>
<span class="nv">$ </span>kubectl get applications <span class="nt">-n</span> argocd timeserver <span class="nt">-o</span> yaml | kubectl neat
<span class="nv">$ </span>kubectl describe applications <span class="nt">-n</span> argocd timeserver
<span class="c"># =&gt; ...</span>
<span class="c">#    Events:</span>
<span class="c">#      Type    Reason              Age   From                           Message</span>
<span class="c">#      ----    ------              ----  ----                           -------</span>
<span class="c">#      Normal  OperationStarted    23s   argocd-application-controller  Initiated automated sync to 'd64cb772abc1646bd74abbd47b688eeb6d59d65a'</span>
<span class="c">#      Normal  ResourceUpdated     23s   argocd-application-controller  Updated sync status:  -&amp;gt; OutOfSync</span>
<span class="c">#      Normal  ResourceUpdated     23s   argocd-application-controller  Updated health status:  -&amp;gt; Missing</span>
<span class="c">#      Normal  ResourceUpdated     23s   argocd-application-controller  Updated sync status: OutOfSync -&amp;gt; Synced</span>
<span class="c">#      Normal  OperationCompleted  23s   argocd-application-controller  Sync operation to d64cb772abc1646bd74abbd47b688eeb6d59d65a succeeded</span>
<span class="c">#      Normal  ResourceUpdated     23s   argocd-application-controller  Updated health status: Missing -&amp;gt; Progressing</span>
<span class="c">#      Normal  ResourceUpdated     21s   argocd-application-controller  Updated health status: Progressing -&amp;gt; Healthy</span>
<span class="nv">$ </span>kubectl get deploy,rs,pod
<span class="c"># =&gt; NAME                         READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/timeserver   2/2     2            2           42s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                    DESIRED   CURRENT   READY   AGE</span>
<span class="c">#    replicaset.apps/timeserver-549cc9bc89   2         2         2       42s</span>
<span class="c">#    </span>
<span class="c">#    NAME                              READY   STATUS    RESTARTS      AGE</span>
<span class="c">#    pod/curl-pod                      1/1     Running   2 (51m ago)   21h</span>
<span class="c">#    pod/timeserver-549cc9bc89-5bsfm   1/1     Running   0             42s</span>
<span class="c">#    pod/timeserver-549cc9bc89-rwcsz   1/1     Running   0             42s</span>
<span class="nv">$ </span>kubectl get svc,ep timeserver
<span class="c"># =&gt; NAME                 TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE</span>
<span class="c">#    service/timeserver   NodePort   10.96.45.219   &amp;lt;none&amp;gt;        80:30000/TCP   50s</span>
<span class="c">#    </span>
<span class="c">#    NAME                   ENDPOINTS                       AGE</span>
<span class="c">#    endpoints/timeserver   10.244.1.10:80,10.244.2.10:80   50s</span>

<span class="c">#</span>
<span class="nv">$ </span>curl http://127.0.0.1:30000
<span class="c"># =&gt; The time is 12:16:57 PM, VERSION 0.0.1</span>
<span class="c">#    Server hostname: timeserver-549cc9bc89-5bsfm</span>
<span class="nv">$ </span>open http://127.0.0.1:30000
</code></pre></div></div>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_37.png" alt="img.png" /></p>

<h5 id="dev-app-repo-코드-작업">dev-app Repo 코드 작업</h5>

<ul>
  <li>dev-app Repo에 VERSION 업데이트 시 =&gt; ops-deploy Repo 에 dev-app 에 파일에 버전 정보 업데이트 작업 추가
    <ol>
      <li>기존 버전 정보는 VERSION 파일 내에 정보를 가져와서 변수 지정 : <code class="language-plaintext highlighter-rouge">OLDVER=$(cat dev-app/VERSION)</code></li>
      <li>신규 버전 정보는 environment 도커 태그 정보를 가져와서 변수 지정 : <code class="language-plaintext highlighter-rouge">NEWVER=$(echo ${DOCKER_TAG})</code></li>
      <li>이후 sed 로 ops-deploy Repo 에 dev-app/VERSION, timeserver.yaml 2개 파일에 ‘기존 버전’ → ‘신규 버전’으로 값 변경</li>
      <li>이후 ops-deploy Repo 에 git push ⇒ Argo CD app 가 최대 3분 사이에 변경 확인 후 AutoSync 로 신규 버전 업데이트 진행</li>
    </ol>
  </li>
  <li>아래는 dev-app 에 위치한 Jenkinsfile로 젠킨스에 SCM-Pipeline (SCM:git) 으로 사용되고 있는 파일을 수정해서 실습에 사용하겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Jenkinsfile</span>
pipeline <span class="o">{</span>
    agent any
    environment <span class="o">{</span>
        DOCKER_IMAGE <span class="o">=</span> <span class="s1">'sweetlittlebird/dev-app'</span> // Docker 이미지 이름
        GOGSCRD <span class="o">=</span> credentials<span class="o">(</span><span class="s1">'gogs-crd'</span><span class="o">)</span>
    <span class="o">}</span>
    stages <span class="o">{</span>
        stage<span class="o">(</span><span class="s1">'dev-app Checkout'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                 git branch: <span class="s1">'main'</span>,
                 url: <span class="s1">'http://10.0.4.3:3000/devops/dev-app.git'</span>,  // Git에서 코드 체크아웃
                 credentialsId: <span class="s1">'gogs-crd'</span>  // Credentials ID
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'Read VERSION'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                script <span class="o">{</span>
                    // VERSION 파일 읽기
                    def version <span class="o">=</span> readFile<span class="o">(</span><span class="s1">'VERSION'</span><span class="o">)</span>.trim<span class="o">()</span>
                    <span class="nb">echo</span> <span class="s2">"Version found: </span><span class="k">${</span><span class="nv">version</span><span class="k">}</span><span class="s2">"</span>
                    // 환경 변수 설정
                    env.DOCKER_TAG <span class="o">=</span> version
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'Docker Build and Push'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                script <span class="o">{</span>
                    docker.withRegistry<span class="o">(</span><span class="s1">'https://index.docker.io/v1/'</span>, <span class="s1">'dockerhub-crd'</span><span class="o">)</span> <span class="o">{</span>
                        // DOCKER_TAG 사용
                        def appImage <span class="o">=</span> docker.build<span class="o">(</span><span class="s2">"</span><span class="k">${</span><span class="nv">DOCKER_IMAGE</span><span class="k">}</span><span class="s2">:</span><span class="k">${</span><span class="nv">DOCKER_TAG</span><span class="k">}</span><span class="s2">"</span><span class="o">)</span>
                        appImage.push<span class="o">()</span>
                        appImage.push<span class="o">(</span><span class="s2">"latest"</span><span class="o">)</span>
                    <span class="o">}</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'ops-deploy Checkout'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                 git branch: <span class="s1">'main'</span>,
                 url: <span class="s1">'http://10.0.4.3:3000/devops/ops-deploy.git'</span>,  // Git에서 코드 체크아웃
                 credentialsId: <span class="s1">'gogs-crd'</span>  // Credentials ID
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'ops-deploy version update push'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                sh <span class="s1">'''
                OLDVER=$(cat dev-app/VERSION)
                NEWVER=$(echo ${DOCKER_TAG})
                sed -i -e "s/$OLDVER/$NEWVER/" dev-app/timeserver.yaml
                sed -i -e "s/$OLDVER/$NEWVER/" dev-app/VERSION
                git add ./dev-app
                git config user.name "devops"
                git config user.email "a@a.com"
                git commit -m "version update ${DOCKER_TAG}"
                git push http://${GOGSCRD_USR}:${GOGSCRD_PSW}@10.0.4.3:3000/devops/ops-deploy.git
                '''</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
    post <span class="o">{</span>
        success <span class="o">{</span>
            <span class="nb">echo</span> <span class="s2">"Docker image </span><span class="k">${</span><span class="nv">DOCKER_IMAGE</span><span class="k">}</span><span class="s2">:</span><span class="k">${</span><span class="nv">DOCKER_TAG</span><span class="k">}</span><span class="s2"> has been built and pushed successfully!"</span>
        <span class="o">}</span>
        failure <span class="o">{</span>
            <span class="nb">echo</span> <span class="s2">"Pipeline failed. Please check the logs."</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<ul>
  <li>아래는 dev-app (Repo) 에서 VERSION과 server.py 수정 후 git push를 진행합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># VERSION 파일 수정 : 0.0.4</span>
<span class="c"># server.py 파일 수정 : 0.0.4</span>

<span class="c"># git push : VERSION, server.py, Jenkinsfile</span>
git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"VERSION </span><span class="si">$(</span><span class="nb">cat </span>VERSION<span class="si">)</span><span class="s2"> Changed"</span> <span class="o">&amp;&amp;</span> git push <span class="nt">-u</span> origin main
</code></pre></div></div>
<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_38.png" alt="img.png" /></p>

<ul>
  <li>ArgoCD 웹에서 동작을 확인해보겠습니다.</li>
  <li>Jenkins Pipeline이 실행되면서 dev-app Repo의 버전 정보가 변경되고, ops-deploy Repo의 dev-app/VERSION 파일과 timeserver.yaml 파일이 
변경되어 ArgoCD가 변경사항을 감지하고 자동으로 배포를 진행합니다.</li>
  <li>REFRESH 버튼을 클릭하거나 ArgoCD WebHook 설정시 즉시 반영이 가능합니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_39.png" alt="img.png" /></p>

<ul>
  <li>dev-app Repo에서 몇번 더 버전을 업데이트 해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># VERSION 파일 수정 : 0.0.5</span>
<span class="c"># server.py 파일 수정 : 0.0.5</span>

<span class="c"># git push : VERSION, server.py, Jenkinsfile</span>
<span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"VERSION </span><span class="si">$(</span><span class="nb">cat </span>VERSION<span class="si">)</span><span class="s2"> Changed"</span> <span class="o">&amp;&amp;</span> git push <span class="nt">-u</span> origin main
<span class="c"># =&gt; [main 881d051] VERSION 0.0.5 Changed</span>
<span class="c">#     2 files changed, 2 insertions(+), 2 deletions(-)</span>
<span class="c">#    Enumerating objects: 7, done.</span>
<span class="c">#    Counting objects: 100% (7/7), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (3/3), done.</span>
<span class="c">#    Writing objects: 100% (4/4), 329 bytes | 329.00 KiB/s, done.</span>
<span class="c">#    Total 4 (delta 2), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To http://10.0.4.3:3000/devops/dev-app.git</span>
<span class="c">#       1d4cec2..881d051  main -&amp;gt; main</span>
<span class="c">#    branch 'main' set up to track 'origin/main'.</span>

<span class="c"># 배포 결과 확인</span>
<span class="nv">$ </span>curl http://127.0.0.1:30000
<span class="c"># =&gt; The time is 12:34:14 PM, VERSION 0.0.5</span>
<span class="c">#    Server hostname: timeserver-7546694df7-wds9r</span>
</code></pre></div></div>

<ul>
  <li>CI/CD가 잘 동작하여 최신버전이 배포됨을 확인 할 수 있습니다.</li>
</ul>

<hr />

<h3 id="argo-rollout--k8skind">Argo Rollout + K8S(Kind)</h3>

<ul>
  <li>Argo는 ArgoCD 뿐만 아니라 다양한 프로젝트를 제공하고 있으며, 그중의 하나가 Argo Rollout입니다.</li>
  <li>Argo Rollout은 Kubernetes의 Deployment, StatefulSet, DaemonSet, Job, CronJob 등의 리소스를 대체하여 롤아웃을 관리하는 컨트롤러입니다.</li>
  <li>다음과 같은 기능을 제공합니다. <a href="https://argoproj.github.io/argo-rollouts/concepts/">문서</a>
    <ul>
      <li>Blue-Green 업데이트 전략
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_40.png" alt="img.png" class="image-center" /></li>
      <li>Canary 업데이트 전략
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_41.png" alt="img_1.png" class="image-center" /></li>
      <li>세밀하고 가중치가 부여된 트래픽 전환</li>
      <li>자동화된 롤백 및 프로모션</li>
      <li>수동 판단</li>
      <li>사용자 정의 가능한 메트릭 쿼리 및 비즈니스 KPI 분석</li>
      <li>인그레스 컨트롤러 통합: NGINX, ALB, Apache APISIX</li>
      <li>서비스 메쉬 통합: Istio, Linkerd, SMI</li>
      <li>여러 제공자의 동시 사용: SMI + NGINX, Istio + ALB 등</li>
      <li>메트릭 제공자 통합: Prometheus, Wavefront, Kayenta, Web, Kubernetes Jobs, Datadog, New Relic, Graphite, InfluxDB</li>
    </ul>
  </li>
</ul>

<h5 id="argo-rollout-설치-및-실습">Argo Rollout 설치 및 실습</h5>

<ul>
  <li>Argo Rollout을 설치해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 네임스페이스 생성 및 파라미터 파일 작성</span>
<span class="nv">$ </span>kubectl create ns argo-rollouts
<span class="c"># =&gt; namespace/argo-rollouts created</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh"> &gt; argorollouts-values.yaml
dashboard:
  enabled: true
  service:
    type: NodePort
    nodePort: 30003
</span><span class="no">EOT

</span><span class="c"># 설치</span>
<span class="nv">$ </span>helm <span class="nb">install </span>argo-rollouts argo/argo-rollouts <span class="nt">--version</span> 2.35.1 <span class="nt">-f</span> argorollouts-values.yaml <span class="nt">--namespace</span> argo-rollouts
<span class="c"># =&gt; NAME: argo-rollouts</span>
<span class="c">#    LAST DEPLOYED: Sun Oct 01 23:05:23 2024</span>
<span class="c">#    NAMESPACE: argo-rollouts</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 1</span>
<span class="c">#    TEST SUITE: None</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get all <span class="nt">-n</span> argo-rollouts
<span class="c"># =&gt; NAME                                           READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/argo-rollouts-86469b5878-j6p5k             1/1     Running   0          42s</span>
<span class="c">#    pod/argo-rollouts-86469b5878-vlr6z             1/1     Running   0          43s</span>
<span class="c">#    pod/argo-rollouts-dashboard-7c88d965fc-l6lml   1/1     Running   0          43s</span>
<span class="c">#    </span>
<span class="c">#    NAME                              TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span>
<span class="c">#    service/argo-rollouts-dashboard   NodePort   10.96.195.148   &amp;lt;none&amp;gt;        3100:30003/TCP   43s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                      READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/argo-rollouts             2/2     2            2           43s</span>
<span class="c">#    deployment.apps/argo-rollouts-dashboard   1/1     1            1           43s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                                 DESIRED   CURRENT   READY   AGE</span>
<span class="c">#    replicaset.apps/argo-rollouts-86469b5878             2         2         2       43s</span>
<span class="c">#    replicaset.apps/argo-rollouts-dashboard-7c88d965fc   1         1         1       43s</span>
<span class="nv">$ </span>kubectl get crds
<span class="c"># =&gt; NAME                                   CREATED AT</span>
<span class="c">#    analysisruns.argoproj.io               2024-10-01T14:05:24Z</span>
<span class="c">#    analysistemplates.argoproj.io          2024-10-01T14:05:24Z</span>
<span class="c">#    applications.argoproj.io               2024-10-01T07:54:01Z</span>
<span class="c">#    applicationsets.argoproj.io            2024-10-01T07:54:01Z</span>
<span class="c">#    appprojects.argoproj.io                2024-10-01T07:54:01Z</span>
<span class="c">#    clusteranalysistemplates.argoproj.io   2024-10-01T14:05:24Z</span>
<span class="c">#    experiments.argoproj.io                2024-10-01T14:05:24Z</span>
<span class="c">#    rollouts.argoproj.io                   2024-10-01T14:05:24Z</span>

<span class="c"># Argo rollouts 대시보드 접속 주소 확인</span>
<span class="nv">$ </span>open <span class="s2">"http://127.0.0.1:30003"</span>
</code></pre></div></div>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_42.png" alt="img.png" /></p>

<ul>
  <li>Argo Rollout을 이용해서 배포를 진행해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Run the following command to deploy the initial Rollout and Service:</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/basic/rollout.yaml
<span class="c"># =&gt; rollout.argoproj.io/rollouts-demo created</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/basic/service.yaml
<span class="c"># =&gt; service/rollouts-demo created</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get rollout
<span class="c"># =&gt; NAME            DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    rollouts-demo   5         5         5            5           16s</span>
<span class="nv">$ </span>kubectl describe rollout
<span class="c"># =&gt; ...</span>
<span class="c">#    Events:</span>
<span class="c">#      Type    Reason                  Age   From                 Message</span>
<span class="c">#      ----    ------                  ----  ----                 -------</span>
<span class="c">#      Normal  RolloutAddedToInformer  25s   rollouts-controller  Rollout resource added to informer: default/rollouts-demo</span>
<span class="c">#      Normal  RolloutNotCompleted     25s   rollouts-controller  Rollout not completed, started update to revision 1 (687d76d795)</span>
<span class="c">#      Normal  RolloutUpdated          25s   rollouts-controller  Rollout updated to revision 1</span>
<span class="c">#      Normal  NewReplicaSetCreated    25s   rollouts-controller  Created ReplicaSet rollouts-demo-687d76d795 (revision 1)</span>
<span class="c">#      Normal  ScalingReplicaSet       25s   rollouts-controller  Scaled up ReplicaSet rollouts-demo-687d76d795 (revision 1) from 0 to 5</span>
<span class="c">#      Normal  RolloutCompleted        25s   rollouts-controller  Rollout completed update to revision 1 (687d76d795): Initial deploy</span>

<span class="nv">$ </span>kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>rollouts-demo
<span class="c"># =&gt; NAME                             READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    rollouts-demo-687d76d795-7pbl9   1/1     Running   0          46s</span>
<span class="c">#    rollouts-demo-687d76d795-bnl2c   1/1     Running   0          46s</span>
<span class="c">#    rollouts-demo-687d76d795-ggzsq   1/1     Running   0          46s</span>
<span class="c">#    rollouts-demo-687d76d795-vtnlj   1/1     Running   0          46s</span>
<span class="c">#    rollouts-demo-687d76d795-xmk2x   1/1     Running   0          46s</span>
<span class="nv">$ </span>kubectl get svc,ep rollouts-demo
<span class="c"># =&gt; NAME                    TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE</span>
<span class="c">#    service/rollouts-demo   ClusterIP   10.96.237.173   &amp;lt;none&amp;gt;        80/TCP    47s</span>
<span class="c">#    </span>
<span class="c">#    NAME                      ENDPOINTS                                                        AGE</span>
<span class="c">#    endpoints/rollouts-demo   10.244.1.14:8080,10.244.1.15:8080,10.244.1.16:8080 + 2 more...   47s</span>
<span class="nv">$ </span>kubectl get rollouts rollouts-demo <span class="nt">-o</span> yaml | kubectl neat
<span class="c"># =&gt; ...</span>
<span class="c">#    spec:</span>
<span class="c">#      replicas: 5</span>
<span class="c">#      revisionHistoryLimit: 2</span>
<span class="c">#      selector:</span>
<span class="c">#        matchLabels:</span>
<span class="c">#          app: rollouts-demo</span>
<span class="c">#      strategy:</span>
<span class="c">#        canary:</span>
<span class="c">#          steps:</span>
<span class="c">#          - setWeight: 20</span>
<span class="c">#          - setWeight: 40</span>
<span class="c">#          - pause:</span>
<span class="c">#              duration: 10</span>
<span class="c">#          - setWeight: 60</span>
<span class="c">#          - pause:</span>
<span class="c">#              duration: 10</span>
<span class="c">#          - setWeight: 80</span>
<span class="c">#          - pause:</span>
<span class="c">#              duration: 10</span>
<span class="c">#      ...</span>
</code></pre></div></div>

<ul>
  <li>
    <p>우측상단의 NAMESPACE를 default로 변경하고 rollout-demo를 클릭하면 다음의 rollout 화면이 나타납니다.
<img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_43.png" alt="img.png" /></p>
  </li>
  <li>
    <p>rollouts-demo:blue를 rollouts-demo:yellow로 변경해서 배포해보겠습니다.</p>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl edit rollouts rollouts-demo
...
     - image: argoproj/rollouts-demo:yellow
...
<span class="c"># =&gt; rollout.argoproj.io/rollouts-demo edited</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 위와 같이 rollouts-demo/blue를 rollouts-demo/yellow로 변경합니다.&lt;/span&gt;</span>

<span class="c"># 파드 label 정보 확인</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>rollouts-demo <span class="nt">-owide</span> <span class="nt">--show-labels</span>
</code></pre></div></div>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_44.png" alt="img.png" /></p>

<ul>
  <li>위와같이 yellow가 20% 만큼 canary 배포되고 정자 상태에 있습니다.</li>
  <li>Promote 버튼을 클릭하여 보겠습니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_45.png" alt="img.png" /></p>

<ul>
  <li>정해진 rollout rule에 따라 10초씩 대기 후 20%씩 canary 배포 비율을 높여서 최종적으로 전체가 yellow로 배포됩니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w3/20241221_cicd_lite_w3_46.png" alt="img.png" /></p>

<h2 id="마치며">마치며</h2>

<p>이번주에는 생각보다 실습량이 많아서 시간이 많이 걸렸습니다. 
하지만, K8S에 CI/CD 배포하는것과 ArgoCD와 Argo Rollout을 이용한 CI/CD 파이프라인 구성을 경험해볼 수 있어서 좋았습니다.
특히 ArgoCD와 Argo Rollout은 웹 UI는 조금 날것 느낌이 났지만,
기능이나 컨셉 자체는 좋은것 같고, 
선언적인 방식이나 CLI를 통해서 자동화할 수 있으니 다양하게 활용할 수 있을것 같습니다.</p>

<p>스터디 컨셉이 CI/CD 맛보기여서 가벼운 마음으로 시작했는데
실제 스터디는 가볍지 않았던것 같습니다.<br />
이 맛에 스터디합니다. 
:sweat_smile: 맛보기가 이 정도이니 본편은 얼마나 깊고 넓을지 기대가 됩니다.</p>

<p>연말에 어수선한 가운데 다들 스터디 참여하신 분들 모두 고생 많으셨고, 
진행해주신 가시다님께 감사드립니다.</p>

<p>긴 글 읽어주셔서 감사합니다. 
한 해 마무리 잘 하시고, 건강한 모습으로 내년에 또 뵙기를 기원합니다. :bow::bowing_woman:</p>]]></content><author><name></name></author><category term="kans" /><category term="cicd," /><category term="jenkins," /><category term="git," /><category term="linux" /><summary type="html"><![CDATA[이번 주에는 ArgoCD와 Jenkins를 사용하여 Kubernetes로의 배포를 하는 CI/CD를 구성해보겠습니다.]]></summary></entry><entry><title type="html">[CI/CD] GitHub Actions CI/CD</title><link href="https://sweetlittlebird.github.io/posts/2024-12-14-CICD-Lite-Week2/" rel="alternate" type="text/html" title="[CI/CD] GitHub Actions CI/CD" /><published>2024-12-14T23:01:18+09:00</published><updated>2024-12-14T23:01:18+09:00</updated><id>https://sweetlittlebird.github.io/posts/CICD%20Lite%20-%20Week2</id><content type="html" xml:base="https://sweetlittlebird.github.io/posts/2024-12-14-CICD-Lite-Week2/"><![CDATA[<h2 id="들어가며">들어가며</h2>

<p>이번 주에는 GitHub Actions를 이용한 CI/CD에 대해 알아보겠습니다.</p>

<h2 id="github-actions-cicd">GitHub Actions CI/CD</h2>

<h3 id="github-actions란">GitHub Actions란?</h3>

<ul>
  <li><a href="https://docs.github.com/ko/actions">공식문서</a> -
<a href="https://docs.github.com/ko/actions/about-github-actions/understanding-github-actions">개요</a> -
<a href="https://docs.github.com/ko/billing/managing-billing-for-your-products/managing-billing-for-github-actions">요금</a> -
<a href="https://blog.outsider.ne.kr/1744">GitHub Actions의 다양한 기능 활용하기</a></li>
  <li>GitHub Actions는 GitHub에서 호스팅되는 <strong>지속적 통합(CI) 및 지속적 배포(CD)</strong> 서비스입니다.</li>
  <li>푸시나 풀 리퀘스트와 같은 이벤트에 반응하여 <strong>사용자 지정된 워크플로</strong>를 실행할 수 있습니다. 이를 통해 CI/CD를 GitHub Actions로 구현할 수 있습니다.</li>
  <li>GitHub Actions는 <strong>GitHub Marketplace</strong>에서 기존에 작성된 워크플로를 가져와 사용할 수 있습니다. Slack 알림, AWS 배포 등 다양한 워크플로가 있습니다.</li>
  <li>GitHub Actions는 <strong>YAML</strong> 파일을 사용하여 워크플로를 정의합니다. 워크플로는 <strong>job</strong>으로 구성되며, 각 job은 <strong>step</strong>으로 구성됩니다.
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_1.png" alt="img.png" /></li>
  <li>
    <p>GitHub Actions의 요금은 아래와 같으며 500MB 스토리지와 매월 2000분을 무료로 사용할 수 있습니다.</p>

    <table>
      <thead>
        <tr>
          <th>계획</th>
          <th>스토리지</th>
          <th>분(월)</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>GitHub Free</td>
          <td>500 MB</td>
          <td>2,000</td>
        </tr>
        <tr>
          <td>GitHub Pro</td>
          <td>1GB</td>
          <td>3,000</td>
        </tr>
        <tr>
          <td>조직용 GitHub Free</td>
          <td>500 MB</td>
          <td>2,000</td>
        </tr>
        <tr>
          <td>GitHub Team</td>
          <td>2GB</td>
          <td>3,000</td>
        </tr>
        <tr>
          <td>GitHub Enterprise Cloud</td>
          <td>50GB</td>
          <td>50,000</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<h3 id="첫-github-actions-워크플로-만들기">첫 GitHub Actions 워크플로 만들기</h3>

<ul>
  <li>GitHub Actions는 repository 내의 <code class="language-plaintext highlighter-rouge">.github/workflows</code> 디렉터리에 저장된 워크플로우 정의 파일을 읽어서 실행합니다.</li>
  <li>간단한 GitHub Repository를 만들고 그 안에 워크플로우를 만들어서 테스트 해보겠습니다.
    <ol>
      <li>새로운 Repository 만들기 <a href="https://www.github.com/new">링크</a>
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_2.png" alt="img.png" /></li>
      <li>git clone으로 repository를 로컬로 가져옵니다.
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>git clone https://github.com/sweetlittlebird/2024-cicd-w2-1.git
<span class="nv">$ </span><span class="nb">cd </span>2024-cicd-w2-1
</code></pre></div>        </div>
      </li>
      <li><code class="language-plaintext highlighter-rouge">.github/workflows</code> 디렉터리를 만들고 그 안에 <code class="language-plaintext highlighter-rouge">main.yml</code> 파일을 만듭니다. (파일명은 자유롭게 지정 가능합니다.)
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">mkdir</span> <span class="nt">-p</span> .github/workflows
<span class="nv">$ </span><span class="nb">touch</span> .github/workflows/main.yml
</code></pre></div>        </div>
      </li>
      <li><code class="language-plaintext highlighter-rouge">main.yml</code> 파일에 워크플로우 작성합니다.
        <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># .github/workflows/main.yml</span>
<span class="na">name</span><span class="pi">:</span> <span class="s">Hello World</span>                 <span class="c1"># Github 웹 사이드바 이름</span>
<span class="na">on</span><span class="pi">:</span>
  <span class="na">workflow_dispatch</span><span class="pi">:</span>              <span class="c1"># 수동으로 실행할 수 있는 워크플로우</span>
  <span class="na">push</span><span class="pi">:</span>                           <span class="c1"># push 이벤트 발생 시 실행</span>
     
<span class="na">jobs</span><span class="pi">:</span>
  <span class="na">build</span><span class="pi">:</span>                          <span class="c1"># Jobs 이름</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>        <span class="c1"># 실행 환경</span>
    <span class="na">steps</span><span class="pi">:</span>                        <span class="c1"># Job 내부의 Step 들 </span>
      <span class="pi">-</span> <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/checkout@v3</span> <span class="c1"># actions/checkout 레포지토리의 v3 버전의 워크플로우 사용</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Hello World</span>         <span class="c1"># Step 이름</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">echo "Hello World"</span>     
</code></pre></div>        </div>
      </li>
      <li>GitHub에 push하여 워크플로우를 실행합니다.
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>git add <span class="nb">.</span>
<span class="nv">$ </span>git commit <span class="nt">-m</span> <span class="s2">"GitHub Actions 추가"</span>
<span class="nv">$ </span>git push origin main
</code></pre></div>        </div>
      </li>
      <li>GitHub Repository에서 Actions 탭을 클릭하여 워크플로우를 확인합니다. <a href="https://github.com/sweetlittlebird/2024-cicd-w2-1/actions">링크</a>
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_3.png" alt="img.png" />
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_4.png" alt="img.png" /></li>
    </ol>
  </li>
  <li>워크플로우가 잘 실행되어서 <code class="language-plaintext highlighter-rouge">Hello World</code>가 잘 출력되었습니다.</li>
</ul>

<h4 id="워크플로우를-수동으로-트리거-하기">워크플로우를 수동으로 트리거 하기</h4>

<ul>
  <li>앞서 작성한 워크플로우 처럼 on: workflow_dispatch를 사용하면 워크플로우를 수동으로 실행할 수 있습니다.</li>
  <li>GitHub Repository에서 Actions 탭을 클릭하고 <code class="language-plaintext highlighter-rouge">Run workflow</code> 버튼을 클릭하여 워크플로우를 수동으로 실행할 수 있습니다.
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_5.png" alt="img.png" /></li>
</ul>

<h3 id="직접-개발-후-실행">직접 개발 후 실행</h3>

<ul>
  <li>이번에는 가상머신을 만들고 그 안에서 간단한 웹 서버를 만들어서 GitHub Actions로 배포해보겠습니다.</li>
  <li>가상머신은 Vagrant를 사용하여 만들어 보겠습니다.
    <div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Vagrantfile</span>
<span class="no">Vagrant</span><span class="p">.</span><span class="nf">configure</span><span class="p">(</span><span class="s2">"2"</span><span class="p">)</span> <span class="k">do</span> <span class="o">|</span><span class="n">config</span><span class="o">|</span>
  <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="s2">"ubuntu/jammy64"</span>
  <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="mi">20022</span>
  <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">80</span><span class="p">,</span> <span class="ss">host: </span><span class="mi">20080</span>
  <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">inline: </span><span class="o">&lt;&lt;-</span><span class="no">SHELL</span><span class="sh">
    sudo apt-get update
    sudo apt install -y tree 
</span><span class="no">  SHELL</span>
<span class="k">end</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>위와 같이 Vagrantfile을 작성하고 <code class="language-plaintext highlighter-rouge">vagrant up</code>으로 가상머신을 만들어 줍니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>vagrant up
  
<span class="nv">$ </span>vargrant ssh 
<span class="c"># --------</span>
  
<span class="nv">$ </span>python3 <span class="nt">-V</span>
<span class="c"># =&gt; Python 3.10.12</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> server.py <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
from http.server import ThreadingHTTPServer, BaseHTTPRequestHandler
from datetime import datetime
  
class RequestHandler(BaseHTTPRequestHandler):
    def do_GET(self):
        self.send_response(200)
        self.send_header('Content-type', 'text/plain')
        self.end_headers()
        now = datetime.now()
        response_string = now.strftime("The time is %-I:%M:%S %p, CloudNeta Study.</span><span class="se">\n</span><span class="sh">")
        self.wfile.write(bytes(response_string, "utf-8")) 
  
def startServer():
    try:
        server = ThreadingHTTPServer(('', 80), RequestHandler)
        print("Listening on " + ":".join(map(str, server.server_address)))
        server.serve_forever()
    except KeyboardInterrupt:
        server.shutdown()
  
if __name__== "__main__":
    startServer()
</span><span class="no">EOF
  
</span><span class="nv">$ </span><span class="nb">sudo </span>python3 server.py
  
<span class="c"># 아래 확인 후</span>
<span class="c"># CTRL+C 로 실행 취소</span>
  
<span class="c"># (신규터미널) 서버1 SSH 접속</span>
<span class="nv">$ </span>curl localhost
<span class="c"># =&gt; The time is 2:50:56 PM, CloudNeta Study.</span>
<span class="nv">$ </span><span class="nb">sudo </span>ss <span class="nt">-tnlp</span>
<span class="c"># =&gt; State  Recv-Q Send-Q Local Address:Port Peer Address:PortProcess</span>
<span class="c">#    LISTEN 0      5            0.0.0.0:80        0.0.0.0:*    users:((&amp;quot;python3&amp;quot;,pid=2299,fd=3))</span>
<span class="c">#    LISTEN 0      128          0.0.0.0:22        0.0.0.0:*    users:((&amp;quot;sshd&amp;quot;,pid=1030,fd=3))</span>
  
<span class="c"># --------</span>
</code></pre></div>    </div>
  </li>
  <li>Git 작업
    <ul>
      <li>토큰 발급해두기 : scope (repo, workflow) 필요합니다. 
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_6.png" alt="img.png" /></li>
      <li>Private Repo 신규 생성
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_7.png" alt="img.png" /></li>
      <li>가상머신에서 Git 작업
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ GITUSER</span><span class="o">=</span><span class="s2">"sweetlittlebird"</span>
<span class="nv">$ </span>git config <span class="nt">--global</span> user.name <span class="nv">$GITUSER</span>
<span class="nv">$ </span>git config <span class="nt">--global</span> user.email <span class="s2">"sweetlittlebird@sweetlittlebird.com"</span>
<span class="nv">$ </span>git clone https://github.com/<span class="nv">$GITUSER</span>/2024-cicd-w2-2.git
<span class="c"># =&gt; Cloning into '2024-cicd-w2-2'...</span>
<span class="c">#    Username for 'https://github.com': git</span>
<span class="c">#    Password for 'https://git@github.com':</span>
<span class="c">#    remote: Enumerating objects: 3, done.</span>
<span class="c">#    remote: Counting objects: 100% (3/3), done.</span>
<span class="c">#    remote: Compressing objects: 100% (2/2), done.</span>
<span class="c">#    remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)</span>
<span class="c">#    Receiving objects: 100% (3/3), done.</span>
<span class="nv">$ </span><span class="nb">cp </span>server.py 2024-cicd-w2-2/
<span class="nv">$ </span><span class="nb">cd </span>2024-cicd-w2-2
    
<span class="nv">$ </span>git status
<span class="c"># =&gt; On branch main</span>
<span class="c">#    Your branch is up to date with 'origin/main'.</span>
<span class="c">#    </span>
<span class="c">#    Untracked files:</span>
<span class="c">#      (use &amp;quot;git add &amp;lt;file&amp;gt;...&amp;quot; to include in what will be committed)</span>
<span class="c">#            server.py</span>
<span class="c">#    </span>
<span class="c">#    nothing added to commit but untracked files present (use &amp;quot;git add&amp;quot; to track)</span>
<span class="nv">$ </span>git add <span class="nb">.</span>
<span class="nv">$ </span>git commit <span class="nt">-m</span> <span class="s2">"Initial commit"</span>
<span class="c"># =&gt; [main 30500ca] Initial commit</span>
<span class="c">#     1 file changed, 22 insertions(+)</span>
<span class="c">#     create mode 100644 server.py</span>
<span class="nv">$ </span>git push origin main 
<span class="c"># =&gt; Username for 'https://github.com': git</span>
<span class="c">#    Password for 'https://git@github.com': *** # &lt;span style="color: green;"&gt;👉 ghp로 시작하는 발급해둔 토큰을 사용합니다.&lt;/span&gt; </span>
<span class="c">#    Enumerating objects: 4, done.</span>
<span class="c">#    Counting objects: 100% (4/4), done.</span>
<span class="c">#    Delta compression using up to 2 threads</span>
<span class="c">#    Compressing objects: 100% (3/3), done.</span>
<span class="c">#    Writing objects: 100% (3/3), 665 bytes | 332.00 KiB/s, done.</span>
<span class="c">#    Total 3 (delta 0), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To https://github.com/sweetlittlebird/2024-cicd-w2-2.git</span>
<span class="c">#       ceaed76..30500ca  main -&amp;gt; main</span>
</code></pre></div>        </div>
        <p><img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_8.png" alt="img.png" /></p>
      </li>
    </ul>
  </li>
  <li>서버 실행
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">nohup sudo </span>python3 server.py <span class="o">&gt;</span> server.log 2&gt;&amp;1 &amp;
<span class="nv">$ </span><span class="nb">cat </span>server.log
<span class="c"># =&gt; nohup: ignoring input</span>
<span class="nv">$ </span>curl localhost
<span class="c"># =&gt; The time is 3:13:00 PM, CloudNeta Study.</span>
<span class="nv">$ </span><span class="nb">cat </span>server.log
<span class="c"># =&gt; nohup: ignoring input</span>
<span class="c">#    127.0.0.1 - - [14/Dec/2024 15:13:00] &amp;quot;GET / HTTP/1.1&amp;quot; 200 -</span>
  
<span class="c">#</span>
<span class="nv">$ </span><span class="nb">grep </span>log .gitignore
<span class="c"># =&gt; # Installer logs</span>
<span class="c">#    pip-log.txt</span>
<span class="c">#    *.log          # &lt;span style="color: green;"&gt;👉 로그 파일은 git에서 무시하도록 되어있습니다.&lt;/span&gt;</span>
  
<span class="c">#</span>
<span class="nv">$ </span>git add <span class="nb">.</span>
<span class="nv">$ </span>git commit <span class="nt">-m</span> <span class="s2">"add log file"</span>
<span class="c"># =&gt; nothing to commit, working tree clean  &lt;span style="color: green;"&gt;👉 로그 파일은 git에서 무시하도록 되어있어서 git add . 의 영향을 받지 않습니다.&lt;/span&gt;</span>
<span class="nv">$ </span>git status
<span class="c"># =&gt; nothing to commit, working tree clean</span>
</code></pre></div>    </div>
  </li>
  <li>코드 수정 후 재실행
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/CloudNeta/CICD/g"</span> server.py
  
<span class="c"># 프로세스 종료</span>
<span class="nv">$ </span><span class="nb">sudo </span>ss <span class="nt">-tnlp</span>
<span class="c"># =&gt; State  Recv-Q Send-Q Local Address:Port Peer Address:PortProcess</span>
<span class="c">#    LISTEN 0      128          0.0.0.0:22        0.0.0.0:*    users:(("sshd",pid=883,fd=3))</span>
<span class="c">#    LISTEN 0      5            0.0.0.0:80        0.0.0.0:*    users:((&amp;quot;python3&amp;quot;,pid=2287,fd=3))</span>
<span class="nv">$ </span><span class="nb">sudo </span>fuser <span class="nt">-k</span> <span class="nt">-n</span> tcp 80                 <span class="c"># &lt;span style="color: green;"&gt;👉 80번 포트를 사용하는 프로세스를 종료합니다.&lt;/span&gt;</span>
<span class="c"># =&gt; 80/tcp:               2287</span>
<span class="c">#    [1]+  Killed                  nohup sudo python3 server.py &amp;gt; server.log 2&amp;gt;&amp;amp;1  (wd: ~)</span>
<span class="c">#    (wd now: ~/2024-cicd-w2-2)</span>
<span class="nv">$ </span><span class="nb">sudo </span>ss <span class="nt">-tnlp</span>
<span class="c"># =&gt; State  Recv-Q Send-Q Local Address:Port Peer Address:PortProcess</span>
<span class="c">#    LISTEN 0      128          0.0.0.0:22        0.0.0.0:*    users:(("sshd",pid=883,fd=3))</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 80 포트를 사용하던 python3가 종료되어서 없어졌습니다.&lt;/span&gt;</span>
  
<span class="c"># 재실행</span>
<span class="nv">$ </span><span class="nb">nohup sudo </span>python3 server.py <span class="o">&gt;</span> server.log 2&gt;&amp;1 &amp;
<span class="nv">$ </span>curl localhost
<span class="c"># =&gt; The time is 3:24:23 PM, CICD Study.  # &lt;span style="color: green;"&gt;👉 수정사항이 반영되었습니다.&lt;/span&gt;</span>
</code></pre></div>    </div>
  </li>
  <li>코드 push
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 매번 사용자 인증을 요구하지 않도록 인증 정보를 저장하도록 설정하겠습니다.</span>
<span class="nv">$ </span>git config <span class="nt">--global</span> credential.helper store
  
<span class="c">#</span>
<span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"version update"</span> <span class="o">&amp;&amp;</span> git push origin main
<span class="c"># =&gt; [main 11f7a3d] version update</span>
<span class="c">#     1 file changed, 1 insertion(+), 1 deletion(-)</span>
<span class="c">#    Username for 'https://github.com': git</span>
<span class="c">#    Password for 'https://git@github.com':</span>
<span class="c">#    Enumerating objects: 5, done.</span>
<span class="c">#    Counting objects: 100% (5/5), done.</span>
<span class="c">#    Delta compression using up to 2 threads</span>
<span class="c">#    Compressing objects: 100% (3/3), done.</span>
<span class="c">#    Writing objects: 100% (3/3), 312 bytes | 156.00 KiB/s, done.</span>
<span class="c">#    Total 3 (delta 1), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    remote: Resolving deltas: 100% (1/1), completed with 1 local object.</span>
<span class="c">#    To https://github.com/sweetlittlebird/2024-cicd-w2-2.git</span>
<span class="c">#       30500ca..11f7a3d  main -&amp;gt; main</span>
  
<span class="nv">$ </span>git push origin main
<span class="c"># =&gt; Everything up-to-date</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 인증정보가 저장되어서 별도의 인증과정 없이 사용할 수 있습니다.&lt;/span&gt;</span>
</code></pre></div>    </div>
  </li>
</ul>

<h3 id="github-actions로-배포하기">GitHub Actions로 배포하기</h3>

<ul>
  <li>개인 PC에서 작업 후 Github에 push하면 GitHub Actions를 통해 VM에 배포가 되도록 CI/CD를 구성해보겠습니다.</li>
</ul>

<h5 id="ssh-키-생성">SSH 키 생성</h5>

<ul>
  <li>먼저 가상머신에 ssh 접속을 위해 ssh key를 생성하고 GitHub에 등록합니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cd</span> ~/.ssh
<span class="nv">$ </span>ssh-keygen <span class="nt">-t</span> ed25519
<span class="c"># =&gt; Enter file in which to save the key (/home/vagrant/.ssh/id_ed25519):</span>
<span class="c">#    Enter passphrase (empty for no passphrase): # &lt;span style="color: green;"&gt;👉 비밀번호 없이 엔터만 입력합니다.&lt;/span&gt;</span>
<span class="c">#    Enter same passphrase again:                # &lt;span style="color: green;"&gt;👉 엔터만 입력합니다.&lt;/span&gt;</span>
  
<span class="c"># 생성된 공개키를 로그인 허용 키 목록에 추가합니다</span>
<span class="nv">$ </span><span class="nb">cat </span>id_ed25519.pub  <span class="o">&gt;&gt;</span> authorized_keys     
<span class="nv">$ </span><span class="nb">cat </span>id_ed25519   <span class="c"># &lt;span style="color: green;"&gt;👉 개인키를 복사합니다. 복사한 키는 github secret에 추가할 것입니다.&lt;/span&gt;</span>
</code></pre></div>    </div>
  </li>
</ul>

<h5 id="github에-ssh-키와-가상머신-외부-ip-등록">GitHub에 SSH 키와 가상머신 외부 IP 등록</h5>

<ul>
  <li>GitHub의 Repository에서 <code class="language-plaintext highlighter-rouge">Settings</code> -&gt; <code class="language-plaintext highlighter-rouge">Secrets and variables</code> -&gt; <code class="language-plaintext highlighter-rouge">Actions</code> -&gt; <code class="language-plaintext highlighter-rouge">New repository secret</code>를 클릭하여 아래와 같이 추가합니다.
    <ul>
      <li><code class="language-plaintext highlighter-rouge">SSH_PRIVATE_KEY</code> : 앞에서 복사한 개인키를 추가합니다. 
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_9.png" alt="img.png" /></li>
      <li><code class="language-plaintext highlighter-rouge">EC2_PIP</code> : 가상머신의 외부 IP를 추가합니다. (인터넷에서 접속가능한 IP여야 합니다.)
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_10.png" alt="img.png" /></li>
    </ul>
  </li>
</ul>

<h5 id="내-pc에서-코드-작업">내 PC에서 코드 작업</h5>

<ul>
  <li>
    <p>내 PC에서 작업을 합니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>git clone https://github.com/sweetlittlebird/2024-cicd-w2-2.git
<span class="c"># =&gt; Cloning into '2024-cicd-w2-2'...</span>
<span class="c">#    remote: Enumerating objects: 9, done.</span>
<span class="c">#    remote: Counting objects: 100% (9/9), done.</span>
<span class="c">#    remote: Compressing objects: 100% (7/7), done.</span>
<span class="c">#    remote: Total 9 (delta 1), reused 6 (delta 1), pack-reused 0 (from 0)</span>
<span class="c">#    Receiving objects: 100% (9/9), done.</span>
<span class="c">#    Resolving deltas: 100% (1/1), done.</span>
<span class="nv">$ </span><span class="nb">cd </span>2024-cicd-w2-2
  
<span class="c"># 워크플로우 파일 생성</span>
<span class="nv">$ </span><span class="nb">mkdir</span> <span class="nt">-p</span> .github/workflows/
<span class="nv">$ </span><span class="nb">touch</span> .github/workflows/deploy.yaml
  
<span class="c"># 소스 수정</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s2">"s/CICD/CICD 2w/g"</span> server.py
</code></pre></div>    </div>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">.github/workflows/deploy.yaml</code> 파일을 작성합니다.</p>

    <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># .github/workflows/deploy.yaml</span>
<span class="na">name</span><span class="pi">:</span> <span class="s">CICD1</span>
<span class="na">on</span><span class="pi">:</span>
  <span class="na">workflow_dispatch</span><span class="pi">:</span>
  <span class="na">push</span><span class="pi">:</span>
    <span class="na">branches</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">main</span>
  
<span class="na">jobs</span><span class="pi">:</span>
  <span class="na">deploy</span><span class="pi">:</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Configure the SSH Private Key Secret</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">mkdir -p ~/.ssh/</span>
          <span class="s">echo "${{ secrets.SSH_PRIVATE_KEY }}" &gt; ~/.ssh/id_rsa</span>
          <span class="s">chmod 600 ~/.ssh/id_rsa</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Set Strict Host Key Checking</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">echo "StrictHostKeyChecking=no" &gt; ~/.ssh/config</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Git Pull</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">export MY_HOST="${{ secrets.EC2_PIP }}"</span>
          <span class="s">ssh vagrant@$MY_HOST &lt;&lt; EOF</span>
            <span class="s">cd /home/vagrant/2024-cicd-w2-2 || exit 1</span>
            <span class="s">git pull origin main || exit 1</span>
          <span class="s">EOF</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Run service</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">export MY_HOST="${{ secrets.EC2_PIP }}"</span>
          <span class="s">ssh vagrant@$MY_HOST sudo fuser -k -n tcp 80 || true</span>
          <span class="s">ssh vagrant@$MY_HOST "nohup sudo -E python3 /home/vagrant/2024-cicd-w2-2/server.py &gt; /home/vagrant/2024-cicd-w2-2/server.log 2&gt;&amp;1 &amp;"</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>코드를 push합니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"add workflow"</span> <span class="o">&amp;&amp;</span> git push origin main
</code></pre></div>    </div>
  </li>
  <li>GitHub Actions를 확인해보겠습니다.
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_11.png" alt="img.png" /></li>
  <li>가상머신에서 확인해보겠습니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>vagrant ssh
  
<span class="c">#-------</span>
<span class="nv">$ </span><span class="nb">cd </span>2024-cicd-w2-2/
<span class="nv">$ </span><span class="nb">grep</span> <span class="nt">-i</span> cicd server.py
<span class="c"># =&gt;         response_string = now.strftime(&amp;quot;The time is %-I:%M:%S %p, CICD 2w Study.\n&amp;quot;)</span>
<span class="nv">$ </span><span class="nb">sudo </span>ps <span class="nt">-ef</span> |grep server.py
<span class="c"># =&gt; root        2620       1  0 15:57 ?        00:00:00 sudo -E python3 /home/vagrant/2024-cicd-w2-2/server.py</span>
<span class="c">#    root        2621    2620  0 15:57 ?        00:00:00 python3 /home/vagrant/2024-cicd-w2-2/server.py</span>
<span class="nv">$ </span><span class="nb">tail</span> /home/vagrant/2024-cicd-w2-2/server.log
<span class="c"># =&gt; nohup: ignoring input</span>
<span class="c">#------- </span>
</code></pre></div>    </div>
  </li>
  <li>변경사항을 브라우저로 확인해보겠습니다.
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_12.png" alt="img.png" />
    <ul>
      <li>변경사항이 잘 반영되어서 CICD <code class="language-plaintext highlighter-rouge">2w</code>로 변경되었습니다.</li>
    </ul>
  </li>
</ul>

<h5 id="코드-수정-후-동작-확인">코드 수정 후 동작 확인</h5>

<ul>
  <li>개인 PC에서 코드와 워크플로우를 수정하고 GitHub에 push하여 배포가 잘 되는지 확인해보겠습니다.
    <ul>
      <li>코드 수정
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s2">"s/CICD 2w/CICD1 End/g"</span> server.py
</code></pre></div>        </div>
      </li>
      <li>
        <p>워크플로우 수정</p>

        <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># .github/workflows/deploy.yaml</span>
<span class="na">name</span><span class="pi">:</span> <span class="s">CICD1 End</span>
<span class="na">on</span><span class="pi">:</span>
  <span class="na">workflow_dispatch</span><span class="pi">:</span>
  <span class="na">push</span><span class="pi">:</span>
    <span class="na">branches</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">main</span>
    
<span class="na">jobs</span><span class="pi">:</span>
  <span class="na">deployfinal</span><span class="pi">:</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Configure the SSH Private Key Secret</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">mkdir -p ~/.ssh/</span>
          <span class="s">echo "${{ secrets.SSH_PRIVATE_KEY }}" &gt; ~/.ssh/id_rsa</span>
          <span class="s">chmod 600 ~/.ssh/id_rsa</span>
    
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Set Strict Host Key Checking</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">echo "StrictHostKeyChecking=no" &gt; ~/.ssh/config</span>
    
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Git Pull</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">export MY_HOST="${{ secrets.EC2_PIP }}"</span>
          <span class="s">ssh vagrant@$MY_HOST &lt;&lt; EOF</span>
            <span class="s">cd /home/vagrant/2024-cicd-w2-2 || exit 1</span>
            <span class="s">git pull origin main || exit 1</span>
          <span class="s">EOF</span>
    
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Run service</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">export MY_HOST="${{ secrets.EC2_PIP }}"</span>
          <span class="s">ssh vagrant@$MY_HOST sudo fuser -k -n tcp 80 || true</span>
          <span class="s">ssh vagrant@$MY_HOST "nohup sudo -E python3 /home/vagrant/2024-cicd-w2-2/server.py &gt; /home/vagrant/2024-cicd-w2-2/server.log 2&gt;&amp;1 &amp;"</span>
</code></pre></div>        </div>
      </li>
      <li>코드 push
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"edit workflow"</span> <span class="o">&amp;&amp;</span> git push origin main
    
<span class="c"># [가상머신]</span>
<span class="nv">$ </span><span class="nb">grep</span> <span class="nt">-i</span> cicd server.py
<span class="c"># =&gt;         response_string = now.strftime(&amp;quot;The time is %-I:%M:%S %p, CICD1 End Study.</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 변경된 소스가 서버에 반영되었습니다.&lt;/span&gt;</span>
    
<span class="nv">$ </span><span class="nb">sudo </span>ps <span class="nt">-ef</span> |grep server.py
<span class="c"># =&gt; root        3011       1  0 16:17 ?        00:00:00 sudo -E python3 /home/vagrant/2024-cicd-w2-2/server.py</span>
<span class="c">#    root        3012    3011  0 16:17 ?        00:00:00 python3 /home/vagrant/2024-cicd-w2-2/server.py</span>
<span class="c">#    vagrant     3035    2255  0 16:18 pts/0    00:00:00 grep --color=auto server.py</span>
<span class="nv">$ </span><span class="nb">tail</span> /home/vagrant/2024-cicd-w2-2/server.log
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li>변경사항을 브라우저로 확인해보겠습니다.
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_13.png" alt="img.png" />
    <ul>
      <li>변경사항이 잘 반영되어서 CICD1 End로 변경되었습니다.</li>
    </ul>
  </li>
</ul>

<h3 id="github-actions의-marketplace-활용하기">GitHub Actions의 Marketplace 활용하기</h3>

<ul>
  <li>이번에는 GitHub Actions의 Marketplace에서 다른 액션을 가져와서 사용해보겠습니다.</li>
  <li>Marketplace는 <a href="https://github.com/marketplace">https://github.com/marketplace</a>로 접속할 수 있습니다.</li>
  <li>이번 실습에서 사용할 액션은 ssh와 scp 입니다.</li>
</ul>

<h4 id="ssh-for-github-actions">SSH for GitHub Actions</h4>
<ul>
  <li>관련 주소 : <a href="https://github.com/appleboy/ssh-action">Github</a>, <a href="https://github.com/marketplace/actions/ssh-remote-commands">marketplace</a></li>
  <li>SSH for GitHub Actions는 원격 서버에 SSH로 접속하여 명령을 실행할 수 있습니다.</li>
  <li>앞의 실습처럼 쉘 명령으로 ssh 접속이 가능하지만 이 액션을 사용하면 더 간편하게 사용할 수 있습니다.</li>
  <li>사용 예
    <ol>
      <li>
        <p>아이디/비밀번호로 원격 서버에 접속하여 <code class="language-plaintext highlighter-rouge">whoami</code> 명령을 실행합니다.</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>name: remote ssh <span class="nb">command
</span>on: <span class="o">[</span>push]
<span class="nb">jobs</span>:
  build:
    name: Build
    runs-on: ubuntu-latest
    steps:
      - name: executing remote ssh commands using password
        uses: appleboy/ssh-action@v1.2.0
        with:
          host: <span class="k">${</span><span class="p">{ secrets.HOST </span><span class="k">}</span><span class="o">}</span>
          username: linuxserver.io
          password: <span class="k">${</span><span class="p">{ secrets.PASSWORD </span><span class="k">}</span><span class="o">}</span>
          port: <span class="k">${</span><span class="p">{ secrets.PORT </span><span class="k">}</span><span class="o">}</span>
          script: <span class="nb">whoami</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p>비밀번호 대신 private key를 사용하여 로그인 합니다.</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Using private key</span>
- name: executing remote ssh commands using ssh key
  uses: appleboy/ssh-action@v1.2.0
  with:
    host: <span class="k">${</span><span class="p">{ secrets.HOST </span><span class="k">}</span><span class="o">}</span>
    username: <span class="k">${</span><span class="p">{ secrets.USERNAME </span><span class="k">}</span><span class="o">}</span>
    key: <span class="k">${</span><span class="p">{ secrets.KEY </span><span class="k">}</span><span class="o">}</span>
    port: <span class="k">${</span><span class="p">{ secrets.PORT </span><span class="k">}</span><span class="o">}</span>
    script: <span class="nb">whoami</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p>여러 명령을 실행할 수 있습니다.</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Multiple Commands</span>
- name: multiple <span class="nb">command
  </span>uses: appleboy/ssh-action@v1.2.0
  with:
    host: <span class="k">${</span><span class="p">{ secrets.HOST </span><span class="k">}</span><span class="o">}</span>
    username: <span class="k">${</span><span class="p">{ secrets.USERNAME </span><span class="k">}</span><span class="o">}</span>
    key: <span class="k">${</span><span class="p">{ secrets.KEY </span><span class="k">}</span><span class="o">}</span>
    port: <span class="k">${</span><span class="p">{ secrets.PORT </span><span class="k">}</span><span class="o">}</span>
    script: |
      <span class="nb">whoami
      ls</span> <span class="nt">-al</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p>환경 변수를 쉘에 전달할 수 있습니다.</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Pass environment variable to shell script</span>
- name: pass environment
  uses: appleboy/ssh-action@v1.2.0
  <span class="nb">env</span>:
    FOO: <span class="s2">"BAR"</span>
    BAR: <span class="s2">"FOO"</span>
    SHA: <span class="k">${</span><span class="p">{ github.sha </span><span class="k">}</span><span class="o">}</span>
  with:
    host: <span class="k">${</span><span class="p">{ secrets.HOST </span><span class="k">}</span><span class="o">}</span>
    username: <span class="k">${</span><span class="p">{ secrets.USERNAME </span><span class="k">}</span><span class="o">}</span>
    key: <span class="k">${</span><span class="p">{ secrets.KEY </span><span class="k">}</span><span class="o">}</span>
    port: <span class="k">${</span><span class="p">{ secrets.PORT </span><span class="k">}</span><span class="o">}</span>
    envs: FOO,BAR,SHA
    script: |
      <span class="nb">echo</span> <span class="s2">"I am </span><span class="nv">$FOO</span><span class="s2">"</span>
      <span class="nb">echo</span> <span class="s2">"I am </span><span class="nv">$BAR</span><span class="s2">"</span>
      <span class="nb">echo</span> <span class="s2">"sha: </span><span class="nv">$SHA</span><span class="s2">"</span>
</code></pre></div>        </div>
      </li>
    </ol>
  </li>
  <li>
    <p>워크플로우 설정 후 테스트</p>

    <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># .github/workflows/ssh-deploy.yaml</span>
<span class="na">name</span><span class="pi">:</span> <span class="s">CICD2</span>
<span class="na">on</span><span class="pi">:</span>
  <span class="na">workflow_dispatch</span><span class="pi">:</span>
  <span class="na">push</span><span class="pi">:</span>
    <span class="na">branches</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">main</span>
  
<span class="na">jobs</span><span class="pi">:</span>
  <span class="na">ssh-deploy</span><span class="pi">:</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Github Repository Checkout</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/checkout@v4</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">executing remote ssh commands</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">appleboy/ssh-action@v1.2.0</span>
        <span class="na">env</span><span class="pi">:</span>
          <span class="na">AWS_KEYS</span><span class="pi">:</span> <span class="pi">|</span>
            <span class="s">ACCESSKEY : asdf1234end</span>
            <span class="s">SECRETKEY : qwer1234end</span>
        <span class="na">with</span><span class="pi">:</span>
          <span class="na">host</span><span class="pi">:</span> <span class="s">${{ secrets.EC2_PIP }}</span>
          <span class="na">port</span><span class="pi">:</span> <span class="m">22</span>
          <span class="na">username</span><span class="pi">:</span> <span class="s">vagrant</span>
          <span class="na">key</span><span class="pi">:</span> <span class="s">${{ secrets.SSH_PRIVATE_KEY }}</span>
          <span class="na">envs</span><span class="pi">:</span> <span class="s">AWS_KEYS</span>
          <span class="na">script_stop</span><span class="pi">:</span> <span class="kc">true</span>
          <span class="na">script</span><span class="pi">:</span> <span class="pi">|</span>
            <span class="s">cd /home/vagrant/2024-cicd-w2-2</span>
            <span class="s">echo "$AWS_KEYS" &gt; .env</span>
</code></pre></div>    </div>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"add ssh action test"</span> <span class="o">&amp;&amp;</span> git push origin main
</code></pre></div>    </div>
  </li>
  <li>
    <p>가상머신에서 확인</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-al</span> ~/2024-cicd-w2-2/
<span class="c"># =&gt; total 32</span>
<span class="c">#    drwxrwxr-x 4 vagrant vagrant 4096 Oct 01 16:46 .</span>
<span class="c">#    drwxr-x--- 5 vagrant vagrant 4096 Oct 01 16:46 ..</span>
<span class="c">#    -rw-rw-r-- 1 vagrant vagrant   49 Oct 01 16:46 .env  # &lt;span style="color: green;"&gt;👉 .env파일이 생성되었습니다.&lt;/span&gt;  </span>
<span class="c">#    drwxrwxr-x 8 vagrant vagrant 4096 Oct 01 16:46 .git</span>
<span class="c">#    drwxrwxr-x 3 vagrant vagrant 4096 Oct 01 15:57 .github</span>
<span class="c">#    -rw-rw-r-- 1 vagrant vagrant 3139 Oct 01 15:11 .gitignore</span>
<span class="c">#    -rw-rw-r-- 1 vagrant vagrant    0 Oct 01 16:46 server.log</span>
<span class="c">#    -rw-rw-r-- 1 vagrant vagrant  761 Oct 01 16:17 server.py</span>
<span class="c">#    -rw-rw-r-- 1 vagrant vagrant  759 Oct 01 16:17 server.py-e</span>
<span class="nv">$ </span><span class="nb">cat</span> ~/2024-cicd-w2-2/.env
<span class="c"># =&gt; ACCESSKEY : asdf1234end</span>
<span class="c">#    SECRETKEY : qwer1234end</span>
</code></pre></div>    </div>
  </li>
  <li>GitHub에서 .env가 있는지 확인해보겠습니다.
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_14.png" alt="img.png" />
.env 파일이 Git에는 없습니다! 하지만 가상머신 서버에 .env 파일이 있었던 것은 SSH for GitHub Actions를 통해 전달된 것입니다.</li>
</ul>

<h4 id="scp-for-github-actions">SCP for GitHub Actions</h4>

<ul>
  <li>관련 주소 : <a href="https://github.com/appleboy/scp-action">Github</a>, <a href="https://github.com/marketplace/actions/scp-files">marketplace</a></li>
  <li>SCP for GitHub Actions는 원격 서버로 파일을 전송해주는 액션입니다.</li>
  <li>실습을 통해 기능을 알아보겠습니다.</li>
  <li>server.py 수정하기
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s2">"s/CICD1 End Study/SCP Test/g"</span> server.py
</code></pre></div>    </div>
  </li>
  <li>
    <p>워크플로우 파일 수정하기</p>

    <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># .github/workflows/scp-ssh-deploy.yaml</span>
<span class="na">name</span><span class="pi">:</span> <span class="s">CICD2</span>
<span class="na">on</span><span class="pi">:</span>
  <span class="na">workflow_dispatch</span><span class="pi">:</span>
  <span class="na">push</span><span class="pi">:</span>
    <span class="na">branches</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">main</span>
  
<span class="na">jobs</span><span class="pi">:</span>
  <span class="na">scp-ssh-deploy</span><span class="pi">:</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Github Repository Checkout</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/checkout@v4</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">executing remote ssh commands</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">appleboy/ssh-action@v1.2.0</span>
        <span class="na">env</span><span class="pi">:</span>
          <span class="na">AWS_KEYS</span><span class="pi">:</span> <span class="s">${{ secrets.MYKEYS }}</span>
        <span class="na">with</span><span class="pi">:</span>
          <span class="na">host</span><span class="pi">:</span> <span class="s">${{ secrets.EC2_PIP }}</span>
          <span class="na">username</span><span class="pi">:</span> <span class="s">vagrant</span>
          <span class="na">port</span><span class="pi">:</span> <span class="m">22</span>
          <span class="na">key</span><span class="pi">:</span> <span class="s">${{ secrets.SSH_PRIVATE_KEY }}</span>
          <span class="na">envs</span><span class="pi">:</span> <span class="s">AWS_KEYS</span>
          <span class="na">script_stop</span><span class="pi">:</span> <span class="kc">true</span>
          <span class="na">script</span><span class="pi">:</span> <span class="pi">|</span>
             <span class="s">cd /home/vagrant/2024-cicd-w2-2</span>
             <span class="s">echo "$AWS_KEYS" &gt; .env</span>
             <span class="s">sudo fuser -k -n tcp 80 || true</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">copy file via scp</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">appleboy/scp-action@v0.1.7</span>
        <span class="na">with</span><span class="pi">:</span>
          <span class="na">host</span><span class="pi">:</span> <span class="s">${{ secrets.EC2_PIP }}</span>
          <span class="na">username</span><span class="pi">:</span> <span class="s">vagrant</span>
          <span class="na">port</span><span class="pi">:</span> <span class="m">22</span>
          <span class="na">key</span><span class="pi">:</span> <span class="s">${{ secrets.SSH_PRIVATE_KEY }}</span>
          <span class="na">source</span><span class="pi">:</span> <span class="s">server.py</span>
          <span class="na">target</span><span class="pi">:</span> <span class="s">/home/vagrant/2024-cicd-w2-2</span>
</code></pre></div>    </div>
  </li>
  <li>코드 push하기
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"using scp ssh action"</span> <span class="o">&amp;&amp;</span> git push origin main
</code></pre></div>    </div>
  </li>
  <li>가상서버에서 확인
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 서버 1</span>
<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-al</span> ~/2024-cicd-w2-2/
<span class="c"># =&gt; total 28</span>
<span class="c">#    drwxrwxr-x 4 vagrant vagrant 4096 Dec 14 17:04 .</span>
<span class="c">#    drwxr-x--- 5 vagrant vagrant 4096 Dec 14 17:04 ..</span>
<span class="c">#    -rw-rw-r-- 1 vagrant vagrant    1 Dec 14 17:03 .env</span>
<span class="c">#    drwxrwxr-x 8 vagrant vagrant 4096 Dec 14 17:02 .git</span>
<span class="c">#    drwxrwxr-x 3 vagrant vagrant 4096 Dec 14 15:57 .github</span>
<span class="c">#    -rw-rw-r-- 1 vagrant vagrant 3139 Dec 14 15:11 .gitignore</span>
<span class="c">#    -rw-rw-r-- 1 vagrant vagrant    0 Dec 14 17:02 server.log</span>
<span class="c">#    -rw-r--r-- 1 vagrant vagrant  754 Dec 14 17:03 server.py</span>
<span class="nv">$ </span><span class="nb">cat</span> ~/2024-cicd-w2-2/server.py | <span class="nb">grep </span>SCP
<span class="c"># =&gt;         response_string = now.strftime(&amp;quot;The time is %-I:%M:%S %p, SCP Test.\n&amp;quot;)  </span>
<span class="c"># &lt;span style="color: green;"&gt;👉 변경사항이 잘 반영되었습니다.&lt;/span&gt;</span>
</code></pre></div>    </div>
  </li>
</ul>

<h4 id="최종-실습">최종 실습</h4>

<ul>
  <li>앞서 쉘 명령으로 진행했던 작업을 GitHub Actions의 Marketplace에서 가져온 ssh, scp 액션을 사용하여 진행해보겠습니다.</li>
  <li>내 PC에서 소스 수정하기
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s2">"s/SCP Test/CICD2 End 🥳/g"</span> server.py
</code></pre></div>    </div>
  </li>
  <li>
    <p>워크플로우 수정하기</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># .github/workflows/deploy.yaml</span>
name: CICD2
on:
  workflow_dispatch:
  push:
    branches:
      - main
  
<span class="nb">jobs</span>:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Github Repository Checkout
        uses: actions/checkout@v4
  
      - name: copy file via ssh
        uses: appleboy/scp-action@v0.1.7
        with:
          host: <span class="k">${</span><span class="p">{ secrets.EC2_PIP </span><span class="k">}</span><span class="o">}</span>
          username: vagrant
          port: 22  
          key: <span class="k">${</span><span class="p">{ secrets.SSH_PRIVATE_KEY </span><span class="k">}</span><span class="o">}</span>
          <span class="nb">source</span>: server.py
          target: /home/vagrant
  
      - name: executing remote ssh commands 
        uses: appleboy/ssh-action@v1.2.0
        <span class="nb">env</span>:
          AWS_KEYS: <span class="k">${</span><span class="p">{ secrets.MYKEYS </span><span class="k">}</span><span class="o">}</span>
        with:
          host: <span class="k">${</span><span class="p">{ secrets.EC2_PIP </span><span class="k">}</span><span class="o">}</span>
          username: vagrant
          port: 22
          key: <span class="k">${</span><span class="p">{ secrets.SSH_PRIVATE_KEY </span><span class="k">}</span><span class="o">}</span>
          envs: AWS_KEYS
          script_stop: <span class="nb">true
          </span>script: |
             <span class="nb">cd</span> /home/vagrant/2024-cicd-w2-2
             <span class="nb">echo</span> <span class="s2">"</span><span class="nv">$AWS_KEYS</span><span class="s2">"</span> <span class="o">&gt;</span> .env
             <span class="nb">sudo </span>fuser <span class="nt">-k</span> <span class="nt">-n</span> tcp 80 <span class="o">||</span> <span class="nb">true
             rm </span>server.py
             <span class="nb">cp</span> /home/vagrant/server.py ./
             <span class="nb">nohup sudo</span> <span class="nt">-E</span> python3 /home/vagrant/2024-cicd-w2-2/server.py <span class="o">&gt;</span> /home/vagrant/2024-cicd-w2-2/server.log 2&gt;&amp;1 &amp;
             <span class="nb">echo</span> <span class="s2">"test"</span> <span class="o">&gt;&gt;</span> /home/vagrant/text.txt
</code></pre></div>    </div>
  </li>
  <li>코드 push하기
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"Deploy CICD2 Final"</span> <span class="o">&amp;&amp;</span> git push origin main
</code></pre></div>    </div>
  </li>
  <li>웹으로 접속해서 확인해보겠습니다.
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_15.png" alt="img.png" />
    <ul>
      <li>변경사항이 잘 반영되어서 CICD2 End 🥳로 변경되었습니다.</li>
    </ul>
  </li>
</ul>

<h3 id="github-actions-with-ansible">GitHub Actions with Ansible</h3>

<ul>
  <li>이번에는 GitHub Actions를 사용하여 Ansible을 실행해보겠습니다.</li>
  <li>상세한 Ansible 사용법은 <a href="https://docs.ansible.com/ansible/latest/index.html">Ansible 공식문서</a>를 참고하시고, 이번 실습에서는
간단하게 Ansible을 이용해서 Ping 테스트를 해보겠습니다. (여기에서의 ping은 ansible이 해당 호스트와 통신이 가능한지 확인하는 것이고 일반적인 ping과는 다릅니다.)</li>
  <li>
    <p>워크플로우 작성</p>

    <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># .github/workflows/ansible-deploy.yaml</span>
<span class="na">name</span><span class="pi">:</span> <span class="s">Run Ansible</span>
<span class="na">on</span><span class="pi">:</span>
  <span class="na">workflow_dispatch</span><span class="pi">:</span>
  <span class="na">push</span><span class="pi">:</span>
    <span class="na">branches</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">main</span>
  
<span class="na">jobs</span><span class="pi">:</span>
  <span class="na">run-playbooks</span><span class="pi">:</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Github Repository Checkout</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/checkout@v4</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Setup Python </span><span class="m">3</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/setup-python@v5</span>
        <span class="na">with</span><span class="pi">:</span>
          <span class="na">python-version</span><span class="pi">:</span> <span class="s2">"</span><span class="s">3.8"</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Upgrade Pip &amp; Install Ansible</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">python -m pip install --upgrade pip</span>
          <span class="s">python -m pip install ansible</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Implement the Private SSH Key</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">mkdir -p ~/.ssh/</span>
          <span class="s">echo "$" &gt; ~/.ssh/id_rsa</span>
          <span class="s">chmod 600 ~/.ssh/id_rsa</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Ansible Inventory File for Remote host</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">mkdir -p ./devops/ansible/</span>
          <span class="s">export INVENTORY_FILE=./devops/ansible/inventory.ini</span>
          <span class="s">echo "[my_host_group]" &gt; $INVENTORY_FILE</span>
          <span class="s">echo "$" &gt;&gt; $INVENTORY_FILE</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Ansible Default Configuration File</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">mkdir -p ./devops/ansible/</span>
          <span class="s">cat &lt;&lt;EOF &gt; ./devops/ansible/ansible.cfg</span>
          <span class="s">[defaults]</span>
          <span class="s">ansible_python_interpreter = '/usr/bin/python3'</span>
          <span class="s">ansible_ssh_private_key_file = ~/.ssh/id_rsa</span>
          <span class="s">remote_user = vagrant</span>
          <span class="s">inventory = ./inventory.ini</span>
          <span class="s">host_key_checking = False</span>
          <span class="s">EOF</span>
  
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Ping Ansible Hosts</span>
        <span class="na">working-directory</span><span class="pi">:</span> <span class="s">./devops/ansible/</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">ansible all -m ping</span>
  
      <span class="c1"># - name: Run Ansible Playbooks</span>
      <span class="c1">#   working-directory: ./devops/ansible/</span>
      <span class="c1">#   run: |</span>
      <span class="c1">#     ansible-playbook install-nginx.yaml</span>
  
      <span class="c1"># - name: Deploy Python via Ansible</span>
      <span class="c1">#   working-directory: ./devops/ansible/</span>
      <span class="c1">#   run: |</span>
      <span class="c1">#     ansible-playbook deploy-python.yaml</span>
</code></pre></div>    </div>
  </li>
  <li>워크플로우 push 하기
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"Deploy Ansible Test"</span> <span class="o">&amp;&amp;</span> git push origin main
</code></pre></div>    </div>
  </li>
  <li>GitHub Actions에서 ping 결과를 확인해보겠습니다.
<img src="/assets/2024/cicd-lite/w2/20241214_cicd_lite_w2_16.png" alt="img.png" />
    <ul>
      <li>정상적으로 ping이 가서 “pong”이라는 응답이 돌아왔습니다.</li>
    </ul>
  </li>
</ul>

<h2 id="마치며">마치며</h2>

<p>지금까지 GitHub Actions의 기본적인 사용하고, Marketplace에서 제공하는 액션 사용해보고, Ansible까지 맛보기로 사용해보았습니다.</p>

<p>GitHub Actions는 일부 제약이 있지만 무료로 편리하게 사용할 수 있고
Marketplace를 통해 다양한 추가기능을 손쉽게 사용할 수 있어서 매력적입니다.</p>

<p>하지만 매번 가상환경을 프로비저닝하고, 필요한 패키지를 설치하는 등의 작업이
시간이 의외로 많이 들어서, 실제 동작 시간이 예상보다 오래 걸릴 수 있다는 점이 있습니다.
또한 Jenkins나 다른 CI/CD 도구들은 실패한 상태의 쉘에 직접 로그인해서 트러블 슈팅을 할 수 있지만,
Github Actions는 그렇게 할 수 없는 점도 아쉽습니다.</p>

<p>그래도 GitHub를 사용하면서 저렴한 가격으로 간단하게 CI/CD를 구성할 수 있다는 점은 매력적인것 같습니다.</p>

<p>추운 날씨에도 애써주신 모든 분들 고생 많으셨습니다. 감사합니다! :bow:</p>]]></content><author><name></name></author><category term="kans" /><category term="cicd," /><category term="jenkins," /><category term="git," /><category term="linux" /><summary type="html"><![CDATA[이번 주에는 GitHub Actions를 이용한 CI/CD에 대해 알아보겠습니다.]]></summary></entry><entry><title type="html">[CI/CD] Jenkins CI/CD + Docker</title><link href="https://sweetlittlebird.github.io/posts/2024-12-08-CICD-Lite-Week1/" rel="alternate" type="text/html" title="[CI/CD] Jenkins CI/CD + Docker" /><published>2024-12-08T00:50:18+09:00</published><updated>2024-12-08T00:50:18+09:00</updated><id>https://sweetlittlebird.github.io/posts/CICD%20Lite%20-%20Week1</id><content type="html" xml:base="https://sweetlittlebird.github.io/posts/2024-12-08-CICD-Lite-Week1/"><![CDATA[<h2 id="들어가며">들어가며</h2>

<p>스터디 시간이 다시 돌아왔습니다. ^^ 이번 스터디는 3주차의 다소 짧은 스터디로 CI/CD에 관련해서 진행됩니다.
즐거운 연말 다시 한번 과제로 달려보겠습니다. :laughing:</p>

<p>이번 주에는 Jenkins와 Git, Docker를 이용하여 CI/CD 파이프라인을 구축해보겠습니다.</p>

<h2 id="jenkins-cicd--docker">Jenkins CI/CD + Docker</h2>

<h3 id="cicd란">CI/CD란?</h3>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_1.png" alt="img.png" class="image-center" />
<em class="image-caption">CI/CD 파이프라인 (출처:<a href="https://blog.devgenius.io/what-is-ci-cd-concept-375cb226cf3d">Dev Genius</a>)</em></p>

<ul>
  <li>CI/CD는 Continuous Integration(지속적 통합)과 Continuous Deployment(지속적 배포)의 약자로 소프트웨어 개발의 계획단계에서 부터 배포/운영까지 전 과정에 걸쳐
자동화된 프로세스를 통해 소프트웨어를 빠르게, 안정적으로 배포할 수 있도록 하는 방법론입니다.</li>
  <li>CI와 CD로 나눠서 살펴보겠습니다.
    <ul>
      <li>CI : 여러 개발자들이 작성한 코드를 하나로 통합하는 코드의 통합을 지속적으로 진행하는 것을 의미합니다.
        <ul>
          <li>CI의 단계 : 계획 -&gt; 코딩 -&gt; 빌드 -&gt; 테스트 -&gt; 패키징</li>
        </ul>
      </li>
      <li>CD : CI를 통해 빌드된 결과물을 배포하고 운영하고, 모니터링을 통해 개선할 점을 파악하는 과정을 지속적으로 진행하는 것을 의미합니다.
        <ul>
          <li>CD의 단계 : 배포 -&gt; 운영 -&gt; 모니터링 -&gt; 피드백</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>CI/CD는 위의 그림과 같이 다양한 툴들로 구성이 되며 이번주에는 Jenkins와 Git, Docker를 이용하여 CI/CD 파이프라인을 구축해보겠습니다.</li>
</ul>

<h3 id="컨테이너를-이용한-어플리케이션-개발">컨테이너를 이용한 어플리케이션 개발</h3>

<p>CI/CD 파이프라인을 구축하기 위해 Docker를 이용하여 어플리케이션을 컨테이너화하겠습니다.</p>

<h4 id="ruby로-특정-문자열-출력하는-간단한-어플리케이션-만들기">ruby로 특정 문자열 출력하는 간단한 어플리케이션 만들기</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nv">$ </span><span class="nb">mkdir </span>1.1 <span class="o">&amp;&amp;</span> <span class="nb">cd </span>1.1
  <span class="nv">$ </span><span class="nb">echo</span> <span class="s1">'puts "Hello Docker!"'</span> <span class="o">&gt;</span> hello.rb
  
  <span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Dockerfile <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
  FROM ruby:3.3
  COPY hello.rb /app/
  WORKDIR /app
  CMD ["ruby", "hello.rb"]
</span><span class="no">  EOF
  
</span>  <span class="c"># 이미지 빌드</span>
  <span class="nv">$ </span>docker build <span class="nt">-t</span> hello <span class="nb">.</span>
  <span class="c"># =&gt; [+] Building 36.6s (9/9) FINISHED</span>
  <span class="nv">$ </span>docker image <span class="nb">ls</span> <span class="nt">-f</span> <span class="nv">reference</span><span class="o">=</span>hello
  <span class="c"># =&gt; REPOSITORY   TAG       IMAGE ID       CREATED          SIZE</span>
  <span class="c">#    hello        latest    d0c55f1ebe18   35 seconds ago   1GB</span>
  
  <span class="c"># 실행</span>
  <span class="nv">$ </span>docker run hello
  <span class="c"># =&gt; Hello Docker!</span>
</code></pre></div></div>

<ul>
  <li>
    <p>코드 수정</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 코드 수정</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"puts 'Hello CloudNet@'"</span> <span class="o">&gt;</span> hello.rb
  
<span class="c"># 컨테이너 이미지 빌드</span>
<span class="nv">$ </span>docker build <span class="nb">.</span> <span class="nt">-t</span> hello:1
<span class="nv">$ </span>docker image <span class="nb">ls</span> <span class="nt">-f</span> <span class="nv">reference</span><span class="o">=</span>hello
<span class="c"># =&gt; REPOSITORY   TAG       IMAGE ID       CREATED         SIZE</span>
<span class="c">#    hello        1         7fe4f428d492   3 seconds ago   1GB</span>
<span class="c">#    hello        latest    d0c55f1ebe18   3 minutes ago   1GB  </span>
<span class="c"># &lt;span style="color: green;"&gt;👉 Latest 태그는 IMAGE ID를 통해 아직 이전의 이미지를 갖고 있는 것을 확인할 수 있습니다.&lt;/span&gt;</span>
  
<span class="c"># 1번 태그에 추가적으로 latest 태그를 붙여보겠습니다.</span>
<span class="nv">$ </span>docker tag hello:1 hello:latest
<span class="nv">$ </span>docker image <span class="nb">ls</span> <span class="nt">-f</span> <span class="nv">reference</span><span class="o">=</span>hello
<span class="c"># =&gt; REPOSITORY   TAG       IMAGE ID       CREATED          SIZE</span>
<span class="c">#    hello        1         7fe4f428d492   36 seconds ago   1GB</span>
<span class="c">#    hello        latest    7fe4f428d492   36 seconds ago   1GB</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 Latest 태그도 동일한 IMAGE ID를 갖게되었습니다.&lt;/span&gt;</span>
  
<span class="c"># 컨테이너 실행</span>
<span class="nv">$ </span>docker run <span class="nt">--rm</span> hello:1
<span class="c"># =&gt; Hello CloudNet@</span>
<span class="nv">$ </span>docker run <span class="nt">--rm</span> hello
<span class="c"># =&gt; Hello CloudNet@</span>
</code></pre></div>    </div>
  </li>
</ul>

<h4 id="compiling-code-in-docker">Compiling code in Docker</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c"># 코드 작성</span>
  <span class="nv">$ </span><span class="nb">mkdir </span>1.2 <span class="o">&amp;&amp;</span> <span class="nb">cd </span>1.2
  
  <span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Hello.java <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
  class Hello {
      public static void main(String[] args) {
          System.out.println("Hello Docker");
      }
  }
</span><span class="no">  EOF
  
</span>  <span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Dockerfile <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
  FROM openjdk
  COPY . /app
  WORKDIR /app
  RUN javac Hello.java    # 컴파일
  CMD java Hello
</span><span class="no">  EOF
  
</span>  <span class="c"># 컨테이너 이미지 빌드</span>
  <span class="nv">$ </span>docker pull openjdk
  <span class="nv">$ </span>docker build <span class="nb">.</span> <span class="nt">-t</span> hello:2 <span class="nt">-t</span> hello:latest
  <span class="c"># =&gt; [+] Building 0.8s (9/9) FINISHED</span>
  <span class="nv">$ </span>docker image <span class="nb">ls</span> <span class="nt">-f</span> <span class="nv">reference</span><span class="o">=</span>hello
  <span class="c"># =&gt; REPOSITORY   TAG       IMAGE ID       CREATED          SIZE</span>
  <span class="c">#    hello        2         ba37ddf45c26   10 seconds ago   487MB</span>
  <span class="c">#    hello        latest    ba37ddf45c26   10 seconds ago   487MB</span>
  <span class="c">#    hello        1         7fe4f428d492   9 minutes ago    1GB</span>
  
  <span class="c"># 컨테이너 실행</span>
  <span class="nv">$ </span>docker run <span class="nt">--rm</span> hello:2
  <span class="c"># =&gt; Hello Docker</span>
  <span class="nv">$ </span>docker run <span class="nt">--rm</span> hello
  <span class="c"># =&gt; Hello Docker</span>
  
  <span class="c"># 컨테이너 이미지 내부에 파일 목록을 보면 어떤가요? 꼭 필요한 파일만 있는가요? 보안적으로 어떨까요?</span>
  <span class="nv">$ </span>docker run <span class="nt">--rm</span> hello <span class="nb">ls</span> <span class="nt">-l</span>
  <span class="c"># =&gt; -rw-r--r-- 1 root root  89 Dec  5 15:04 Dockerfile</span>
  <span class="c">#    -rw-r--r-- 1 root root 416 Dec  5 15:05 Hello.class</span>
  <span class="c">#    -rw-r--r-- 1 root root 111 Dec  5 15:04 Hello.java</span>
  <span class="c"># &lt;span style="color: green;"&gt;👉 꼭 필요한 파일 외에도 Dockerfile, *.java 파일, java 컴파일러 등이 있습니다.&lt;/span&gt;</span>
  <span class="c"># &lt;span style="color: green;"&gt;   이 파일들은 정보 유출이나 공격 대상이 될 수 있기 때문에 컨테이너 이미지에 없어야 합니다.&lt;/span&gt;</span>
  
  <span class="c"># RUN 컴파일 시 소스코드와 java 컴파일러(javac)가 포함되어 있음. 실제 애플리케이션 실행에 필요 없음. </span>
  <span class="nv">$ </span>docker run <span class="nt">--rm</span> hello javac <span class="nt">--help</span>
  <span class="c"># =&gt; Usage: javac &amp;lt;options&amp;gt; &amp;lt;source files&amp;gt;</span>
  <span class="c">#    where possible options include:</span>
  <span class="c">#      @&amp;lt;filename&amp;gt;                  Read options and filenames from file</span>
  <span class="c">#    ...</span>
</code></pre></div></div>

<h4 id="멀티-스테이지-빌드">멀티 스테이지 빌드</h4>
<ul>
  <li>멀티 스테이지 빌드는 빌드를 여러 단계로 나누어서 진행하는 방법입니다.</li>
  <li>각 단계마다 필요한 환경을 구성하여 빌드를 진행하고, 최종적으로 필요한 파일만을 추출하여 불필요한 파일들이 제외된
가볍고 안전한 이미지를 생성할 수 있습니다.
  <img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_2.png" alt="img.png" class="image-center" />
  <em class="image-caption">멀티 스테이지 빌드 동작</em></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c"># 코드 작성</span>
  <span class="nv">$ </span><span class="nb">mkdir </span>1.3 <span class="o">&amp;&amp;</span> <span class="nb">cd </span>1.3
  
  <span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Hello.java <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
  class Hello {
      public static void main(String[] args) {
          System.out.println("Hello Multistage container build");
      }
  }
</span><span class="no">  EOF
  
</span>  <span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Dockerfile <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
  FROM openjdk:11 AS buildstage
  COPY . /app
  WORKDIR /app
  RUN javac Hello.java
  
  FROM openjdk:11-jre-slim
  COPY --from=buildstage /app/Hello.class /app/
  WORKDIR /app
  CMD java Hello
</span><span class="no">  EOF
  
</span>  <span class="c"># 컨테이너 이미지 빌드 : 용량 비교 해보자!</span>
  <span class="nv">$ </span>docker build <span class="nb">.</span> <span class="nt">-t</span> hello:3 <span class="nt">-t</span> hello:latest
  <span class="nv">$ </span>docker image <span class="nb">ls</span> <span class="nt">-f</span> <span class="nv">reference</span><span class="o">=</span>hello
  <span class="c"># =&gt; REPOSITORY   TAG       IMAGE ID       CREATED          SIZE</span>
  <span class="c">#    hello        3         4a058414ac44   11 seconds ago   216MB</span>
  <span class="c">#    hello        latest    4a058414ac44   11 seconds ago   216MB</span>
  <span class="c">#    hello        2         ba37ddf45c26   24 minutes ago   487MB</span>
  <span class="c">#    ...</span>
  <span class="c"># &lt;span style="color: green;"&gt;👉 Compiler가 없는 가벼운 jre 이미지를 사용하여 컨테이너 이미지 크기도 줄어든 것을 확인할 수 있습니다.&lt;/span&gt;</span>
  
  <span class="c"># 컨테이너 실행</span>
  <span class="nv">$ </span>docker run <span class="nt">--rm</span> hello:3
  <span class="c"># =&gt; Hello Multistage container build</span>
  <span class="nv">$ </span>docker run <span class="nt">--rm</span> hello
  <span class="c"># =&gt; Hello Multistage container build</span>
  
  <span class="c"># 컨테이너 이미지 내부에 파일 목록을 보면 어떤가요?</span>
  <span class="nv">$ </span>docker run <span class="nt">--rm</span> hello <span class="nb">ls</span> <span class="nt">-l</span>
  <span class="c"># =&gt; total 4</span>
  <span class="c">#    -rw-r--r-- 1 root root 436 Dec  5 15:26 Hello.class</span>
  <span class="nv">$ </span>docker run <span class="nt">--rm</span> hello javac <span class="nt">--help</span>
  <span class="c"># =&gt; docker: Error response from daemon: OCI runtime create failed: container_linux.go:380: starting container process caused: exec: &amp;quot;javac&amp;quot;: executable file not found in $PATH: unknown.</span>
  <span class="c"># &lt;span style="color: green;"&gt;👉 javac가 없어서 이전보다 안전한것을 알 수 있습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<h4 id="jib로-자바-컨테이너-빌드">Jib로 자바 컨테이너 빌드</h4>
<p><a href="https://cloud.google.com/java/getting-started/jib?hl=ko">문서</a>, 
  <a href="https://colevelup.tistory.com/53">관련 블로그1</a>,
  <a href="https://jh-labs.tistory.com/509">관련 블로그2</a></p>
<ul>
  <li>Jib는 Google에서 만든 오픈소스 도구로, Java 어플리케이션을 컨테이너 이미지로 빌드하는 도구입니다.</li>
  <li>Jib는 docker 없이 컨테이너 이미지를 빌드할 수 있으며, 빌드 속도가 빠르고, 이미지 크기가 작아서 배포가 용이합니다.</li>
  <li>Maven 또는 Gradle 플러그인으로 사용할 수 있습니다.</li>
  <li>기존의 Docker 이미지 빌드 흐름은 다음과 같습니다.
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_3.png" alt="img.png" /></li>
  <li>Jib는 다음과 같이 빌드 흐름이 간소화됩니다.
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_4.png" alt="img.png" />
    <ul>
      <li>빌드와 동시에 이미지가 만들어지고 저장소에 푸시까지 가능합니다.</li>
      <li>Jenkins 등의 CI 서버에 Docker가 없어도 컨테이너 이미지를 빌드할 수 있습니다.</li>
      <li>이미지 레이어 캐싱을 통해 빌드 속도가 빠릅니다.</li>
      <li>이미지 크기가 작아서 배포가 용이합니다.</li>
    </ul>
  </li>
</ul>

<h4 id="어플리케이션-서버-컨테이너화-하기">어플리케이션 서버 컨테이너화 하기</h4>

<ul>
  <li>데모를 위해 HTTP 웹 어플리케이션을 컨테이너화 해보겠습니다.</li>
  <li>다음은 ruby 언어로 작성한 기본적인 웹서버로, 현재 날짜와 시간을 표시합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">mkdir </span>1.4 <span class="o">&amp;&amp;</span> <span class="nb">cd </span>1.4

<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> app.rb <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
require 'sinatra'

get '/' do
  "Hello, World! The time is #{Time.now}"
end
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Dockerfile <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
FROM ruby:3.3
RUN gem install sinatra rackup puma
COPY app.rb /app/
WORKDIR /app
CMD ["ruby", "app.rb", "-o", "0.0.0.0"]
</span><span class="no">EOF

</span><span class="c"># 컨테이너 이미지 빌드</span>

<span class="nv">$ </span>docker build <span class="nb">.</span> <span class="nt">-t</span> timeserver:1 <span class="o">&amp;&amp;</span> docker tag timeserver:1 timeserver:latest
<span class="nv">$ </span>docker image <span class="nb">ls</span> <span class="nt">-f</span> <span class="nv">reference</span><span class="o">=</span>timeserver
<span class="c"># =&gt; REPOSITORY   TAG       IMAGE ID       CREATED          SIZE</span>
<span class="c">#    timeserver   1         6393669e5e68   12 seconds ago   1GB</span>
<span class="c">#    timeserver   latest    6393669e5e68   12 seconds ago   1GB</span>

<span class="c"># 컨테이너 실행</span>
<span class="nv">$ </span>docker run <span class="nt">-d</span> <span class="nt">-p</span> 8080:4567 <span class="nt">--name</span><span class="o">=</span>timeserver timeserver

<span class="c"># 컨테이너 접속 및 로그 확인</span>
<span class="nv">$ </span>curl http://localhost:8080
<span class="c"># =&gt; Hello, World! The time is 2024-10-01 15:28:18 +0000</span>
<span class="nv">$ </span>docker logs timeserver
<span class="c"># =&gt; Puma starting in single mode...</span>
<span class="c">#    * Puma version: 6.5.0 (&amp;quot;Sky's Version&amp;quot;)</span>
<span class="c">#    == Sinatra (v4.1.1) has taken the stage on 4567 for development with backup from Puma</span>
<span class="c">#    * Ruby version: ruby 3.3.6 (2024-10-01 revision 75015d4c1f) [aarch64-linux]</span>
<span class="c">#    *  Min threads: 0</span>
<span class="c">#    *  Max threads: 5</span>
<span class="c">#    *  Environment: development</span>
<span class="c">#    *          PID: 1</span>
<span class="c">#    * Listening on http://0.0.0.0:4567</span>
<span class="c">#    Use Ctrl-C to stop</span>
<span class="c">#    172.17.0.1 - - [01/Oct/2024:15:28:07 +0000] &amp;quot;GET / HTTP/1.1&amp;quot; 200 51 0.0048</span>

<span class="c"># 컨테이너 이미지 내부에 파일 확인</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> timeserver <span class="nb">ls</span> <span class="nt">-l</span>
<span class="c"># =&gt; total 4</span>
<span class="c">#    -rw-r--r-- 1 root root 76 Dec  6 15:20 app.rb</span>
</code></pre></div></div>

<ul>
  <li>도커 컨테이너 내부의 소스코드를 수정해서 반영되는지 확인해보겠습니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_5.png" alt="20241205_cicd_lite_w1_5.png" class="image-center" />
<em class="image-caption">vscode에 docker 확장 설치</em></p>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_6.png" alt="20241205_cicd_lite_w1_6.png" class="image-center" />
<em class="image-caption">timeserver 컨테이너 내부의 app.rb 파일 수정</em></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 컨테이너 이미지 내부에 app.rb 파일 수정 후 반영 확인 : VSCODE 경우 docker 확장프로그램 활용</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> timeserver <span class="nb">cat </span>app.rb
<span class="c"># =&gt; require 'sinatra'</span>
<span class="c">#    </span>
<span class="c">#    get '/' do</span>
<span class="c">#      &amp;quot;Hello, World! 😀 The time is #{Time.now}&amp;quot;</span>
<span class="c">#    end</span>

<span class="c"># 컨테이너 접속 후 확인 </span>
<span class="nv">$ </span>curl http://localhost:8080
<span class="c"># =&gt; Hello, World! The time is 2024-10-01 15:45:09 +0000%</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 수정 사항이 반영되지 않았습니다!&lt;/span&gt;</span>

<span class="c"># 컨테이너 삭제</span>
<span class="nv">$ </span>docker <span class="nb">rm</span> <span class="nt">-f</span> timeserver
</code></pre></div></div>

<ul>
  <li>어플리케이션 수정해서 테스트</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s1">'s#World!#World! 😀 Hello CloudNeta Study!#'</span> app.rb
<span class="nv">$ </span><span class="nb">cat </span>app.rb
<span class="c"># =&gt; require 'sinatra'</span>
<span class="c">#    </span>
<span class="c">#    get '/' do</span>
<span class="c">#      &amp;quot;Hello, World! 😀 Hello CloudNeta Study! The time is #{Time.now}&amp;quot;</span>
<span class="c">#    end</span>

<span class="c"># 컨테이너 이미지 빌드</span>
<span class="nv">$ </span>docker build <span class="nb">.</span> <span class="nt">-t</span> timeserver:2 <span class="nt">-t</span> timeserver:latest
<span class="nv">$ </span>docker image <span class="nb">ls</span> <span class="nt">-f</span> <span class="nv">reference</span><span class="o">=</span>timeserver
<span class="c"># =&gt; REPOSITORY   TAG       IMAGE ID       CREATED          SIZE</span>
<span class="c">#    timeserver   2         80f230757e3c   2 seconds ago    1.01GB</span>
<span class="c">#    timeserver   latest    80f230757e3c   2 seconds ago    1.01GB</span>
<span class="c">#    timeserver   1         c7055ab70155   27 minutes ago   1.01GB</span>

<span class="c"># 컨테이너 실행</span>
<span class="nv">$ </span>docker run <span class="nt">-d</span> <span class="nt">-p</span> 8080:4567 <span class="nt">--name</span><span class="o">=</span>timeserver timeserver
<span class="c"># =&gt; 278108d26b3998c8281add75b631d59a9d44abd4eb3e4f173b0b156d66e5da75</span>

<span class="c"># 컨테이너 접속 및 로그 확인</span>
<span class="nv">$ </span>curl http://localhost:8080
<span class="c"># =&gt; Hello, World! 😀 Hello CloudNeta Study! The time is 2024-10-01 15:55:19 +0000</span>

<span class="c"># 컨테이너 삭제</span>
<span class="nv">$ </span>docker <span class="nb">rm</span> <span class="nt">-f</span> timeserver
</code></pre></div></div>

<h4 id="로컬-개발을-위한-방안">로컬 개발을 위한 방안</h4>

<ul>
  <li>소스를 수정할 때마다 위와 같이 컨테이너 이미지를 빌드하고 실행하는 것은 번거롭습니다.</li>
  <li>이를 편리하게 하기 위해서 로컬 폴더와 컨테이너의 앱 소스를 매핑하고, 코드 내용을 동적으로 반영해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">mkdir </span>1.5 <span class="o">&amp;&amp;</span> <span class="nb">cd </span>1.5

<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> app.rb <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
require 'sinatra/base'

class App &lt; Sinatra::Base
  get '/' do
    "Hello, World! The time is #{Time.now}"
  end
end
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> config.ru <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
require 'rack/unreloader'
require 'sinatra'
Unreloader = Rack::Unreloader.new{App}
Unreloader.require './app.rb'

run Unreloader
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Dockerfile <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
FROM ruby:3.3
RUN gem install sinatra rackup puma </span><span class="se">\</span><span class="sh">
    rack-unreloader # 소스코드 변경시 자동으로 반영하기위한 툴
COPY app.rb config.ru /app/
WORKDIR /app
CMD ["rackup", "--host", "0.0.0.0"]
</span><span class="no">EOF

</span><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> docker-compose.yaml <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
services:
  frontend:
    build: .
    command: rackup --host 0.0.0.0
    volumes:
      - type: bind
        source: .
        target: /app
    ports:
      - "8080:9292"
</span><span class="no">EOF

</span><span class="c"># 도커 컴포즈로 컨테이너 빌드</span>
<span class="nv">$ </span>docker compose build 
<span class="c"># 도커 컴포즈로 컨테이너 실행 </span>
<span class="nv">$ </span>docker compose up <span class="nt">-d</span>
<span class="c"># =&gt; [+] Running 1/1</span>
<span class="c">#     ⠿ Container 15-frontend-1  Started 0.4s</span>

<span class="c"># 컴포즈로 실행 시 이미지와 컨테이너 네이밍 규칙을 알아보자!</span>
<span class="nv">$ </span>docker compose ps
<span class="c"># =&gt; NAME                COMMAND                  SERVICE             STATUS              PORTS</span>
<span class="c">#    15-frontend-1       &amp;quot;rackup --host 0.0.0…&amp;quot;   frontend            running             0.0.0.0:8080-&amp;gt;9292/tcp</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 컴포즈로 실행시 현재 디렉터리 이름에서 특수문자를 제외한 것에 컨테이너 이름에 "-1"를 붙이는듯 합니다.&lt;/span&gt;</span>

<span class="nv">$ </span>docker compose images
<span class="c"># =&gt; Container           Repository          Tag                 Image Id            Size</span>
<span class="c">#    15-frontend-1       15_frontend         latest              4aa2b680f319        1.01GB</span>

<span class="c">#</span>
<span class="nv">$ </span>curl http://localhost:8080
<span class="c"># =&gt; Hello, World! The time is 2024-10-01 05:55:18 +0000!!!!!%</span>
<span class="nv">$ </span>docker compose logs
<span class="c"># =&gt; 15-frontend-1  | Puma starting in single mode...</span>
<span class="c">#    15-frontend-1  | * Puma version: 6.5.0 (&amp;quot;Sky's Version&amp;quot;)</span>
<span class="c">#    15-frontend-1  | * Ruby version: ruby 3.3.6 (2024-10-01 revision 75015d4c1f) [aarch64-linux]</span>
<span class="c">#    15-frontend-1  | *  Min threads: 0</span>
<span class="c">#    15-frontend-1  | *  Max threads: 5</span>
<span class="c">#    15-frontend-1  | *  Environment: development</span>
<span class="c">#    15-frontend-1  | *          PID: 1</span>
<span class="c">#    15-frontend-1  | * Listening on http://0.0.0.0:9292</span>
<span class="c">#    15-frontend-1  | Use Ctrl-C to stop</span>
<span class="c">#    15-frontend-1  | 172.23.0.1 - - [01/Oct/2024:03:58:23 +0000] &amp;quot;GET / HTTP/1.1&amp;quot; 200 51 0.0153</span>
</code></pre></div></div>

<ul>
  <li>소스코드 수정 후 반영 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat </span>app.rb
<span class="c"># =&gt; require 'sinatra/base'</span>
<span class="c">#    </span>
<span class="c">#    class App &amp;lt; Sinatra::Base</span>
<span class="c">#      get '/' do</span>
<span class="c">#        &amp;quot;Hello, World! The time is #{Time.now}&amp;quot;</span>
<span class="c">#      end</span>
<span class="c">#    end</span>

<span class="c"># 소스코드 수정</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s1">'s#World!#World! 😀 Hello CloudNeta Study!#'</span> app.rb
<span class="nv">$ </span><span class="nb">cat </span>app.rb
<span class="c"># =&gt; require 'sinatra/base'</span>
<span class="c">#    </span>
<span class="c">#    class App &amp;lt; Sinatra::Base</span>
<span class="c">#      get '/' do</span>
<span class="c">#        &amp;quot;Hello, World! 😀 Hello CloudNeta Study! The time is #{Time.now}!!!!!&amp;quot;</span>
<span class="c">#      end</span>
<span class="c">#    end</span>

<span class="nv">$ </span>curl http://localhost:8080
<span class="c"># =&gt; Hello, World! 😀 Hello CloudNeta Study! The time is 2024-10-01 05:57:05 +0000!!!!!</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 변경사항이 잘 반영되었습니다. :)&lt;/span&gt;</span>

<span class="c"># 컨테이너 중지 및 삭제</span>
<span class="nv">$ </span>docker compose down
</code></pre></div></div>

<h3 id="cicd-실습환경-구성">CI/CD 실습환경 구성</h3>

<ul>
  <li>Jenkins와 Gitlab을 이용하여 CI/CD 파이프라인을 구축해보겠습니다.</li>
  <li>Jenkins는 Docker에 설치해서 사용하고 Gitlab은 <a href="https://www.gitlab.com">gitlab.com</a>를 사용하겠습니다.</li>
</ul>

<h4 id="jenkins-소개">Jenkins 소개</h4>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_7.png" alt="img.png" class="image-center" /></p>
<ul>
  <li>Jenkins는 오픈소스 CI/CD 도구로, 빌드, 테스트, 배포 등의 작업을 자동화할 수 있습니다.</li>
  <li>Jenkins는 CI/CD라는 용어가 있기 전부터 사용되던 도구로, CI/CD에 국한되지 않고 다양한 작업을 자동화할 수 있습니다.</li>
  <li>주요 기능은 다음과 같습니다.
    <ol>
      <li><strong>확장성</strong> : 다양한 플러그인 생태계를 가지고 있어 기능을 확장할 수 있습니다. Git, Docker, Kubernetes 등 다양한 도구 및 플랫폼과 통합할 수 있습니다.</li>
      <li><strong>분산 빌드</strong> : 분산 빌드를 지원하여 여러 머신에서 작업을 실행할 수 있습니다. 이를 통해 부하를 분산시키고 빌드 속도를 높일 수 있습니다.</li>
      <li><strong>자동화된 테스트</strong> : 테스트 실행을 자동화하여 코드 품질에 대한 즉각적인 피드백을 제공합니다. 다양한 테스트 프레임워크 및 도구를 지원합니다.</li>
      <li><strong>코드 파이프라인</strong> : Jenkinsfile을 사용하여 빌드, 테스트, 배포 파이프라인을 코드로 정의할 수 있습니다. 이를 통해 버전 관리와 협업이 용이합니다.</li>
      <li><strong>지속적 통합 및 지속적 배포 (CI/CD)</strong> : 코드 변경 사항을 통합하고, 애플리케이션을 빌드하고, 테스트를 실행하고, 배포하는 과정을 자동화합니다. 이를 통해 일관되고 신뢰할 수 있는 배포 프로세스를 보장합니다.</li>
    </ol>
  </li>
  <li>흔히 사용되는 CI/CD 워크플로우는 다음과 같습니다.
    <ol>
      <li><strong>최신 코드 가져오기</strong> : 개발을 위해 중앙 코드 리포지터리에서 로컬 시스템으로 애플리케이션의 최신 코드를 가져</li>
      <li><strong>단위 테스트 구현과 실행</strong> : 코드 작성 전 단위 테스트 케이스를 먼저 작성</li>
      <li><strong>코드 개발</strong> : 실패한 테스트 케이스를 성공으로 바꾸면서 코드 개발</li>
      <li><strong>단위 테스트 케이스 재실행</strong> : 단위 테스트 케이스 실행 시 통과(성공!)</li>
      <li><strong>코드 푸시와 병합</strong> : 개발 소스 코드를 중앙 리포지터리로 푸시하고, 코드 병합</li>
      <li><strong>코드 병합 후 컴파일</strong> : 변경 함수 코드가 병함되면 전체 애플리케이션이 컴파일된다</li>
      <li><strong>병합된 코드에서 테스트 실행</strong> : 개별 테스트뿐만 아니라 전체 통합 테스트를 실행하여 문제 없는지 확인</li>
      <li><strong>아티팩트 배포</strong> : 애플리케이션을 빌드하고, 애플리케이션 서버의 프로덕션 환경에 배포</li>
      <li><strong>배포 애플리케이션의 E-E 테스트 실행</strong> : 셀레늄 Selenium과 같은 User Interface 자동화 도구를 통해 애플리케이션의 전체 워크플로가 정상 동작하는지 확인하는 종단간 End-to-End 테스트를 실행.</li>
    </ol>
  </li>
  <li>이러한 워크플로우를 코드 커밋/푸시와 같은 이벤트가 발생할 때 자동으로 실행되도록 설정할 수 있습니다.</li>
</ul>

<h5 id="jenkins-컨테이너에서-호스트에-도커-데몬-사용-설정">Jenkins 컨테이너에서 호스트에 도커 데몬 사용 설정</h5>

<ul>
  <li>컨테이너에서 도커를 사용하기 위해서는 DinD(Docker in Docker)를 사용하여 컨테이너 안에서 도커를 실행하거나
DooD(Docker outside of Docker)를 사용하여 호스트의 도커 데몬을 사용할 수 있습니다.</li>
  <li>이번에는 Docker outside of Docker를 사용하여 호스트의 도커 데몬을 사용하겠습니다.
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_8.png" alt="img.png" class="image-center" />
<em class="image-caption">DinD와 DooD 구조 비교</em></li>
</ul>

<h4 id="jenkins-컨테이너-실행-및-설정">Jenkins 컨테이너 실행 및 설정</h4>

<ul>
  <li>먼저 Jenkins 컨테이너를 실행하겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 작업 디렉토리 생성 후 이동</span>
<span class="nv">$ </span><span class="nb">mkdir </span>cicd-labs <span class="o">&amp;&amp;</span> <span class="nb">cd </span>cicd-labs

<span class="c"># </span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh"> &gt; docker-compose.yaml
services:
  jenkins:
    container_name: jenkins
    image: jenkins/jenkins
    restart: unless-stopped
    networks:
      - cicd-network
    ports:
      - "8080:8080"
      - "50000:50000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - jenkins_home:/var/jenkins_home
volumes:
  jenkins_home:
networks:
  cicd-network:
    driver: bridge
</span><span class="no">EOT

</span><span class="c"># 배포</span>
<span class="nv">$ </span>docker compose up <span class="nt">-d</span>
<span class="c"># =&gt; [+] Running 13/13</span>
<span class="c">#     ⠿ jenkins Pulled                                                                                                                                                      13.7s</span>
<span class="c">#    [+] Running 3/3</span>
<span class="c">#     ⠿ Network cicd-labs_cicd-network   Created                                                                                                                             0.0s</span>
<span class="c">#     ⠿ Volume &amp;quot;cicd-labs_jenkins_home&amp;quot;  Created                                                                                                                             0.0s</span>
<span class="c">#     ⠿ Container jenkins                Started</span>
<span class="nv">$ </span>docker compose ps
<span class="c"># =&gt; NAME                COMMAND                  SERVICE             STATUS              PORTS</span>
<span class="c">#    jenkins             &amp;quot;/usr/bin/tini -- /u…&amp;quot;   jenkins             running             0.0.0.0:8080-&amp;gt;8080/tcp, 0.0.0.0:50000-&amp;gt;50000/tcp</span>

<span class="c"># 기본 정보 확인</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>jenkins <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; container : </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker compose <span class="nb">exec</span> <span class="nv">$i</span> sh <span class="nt">-c</span> <span class="s2">"whoami &amp;&amp; pwd"</span><span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; container : jenkins &amp;lt;&amp;lt;</span>
<span class="c">#    jenkins</span>
<span class="c">#    /</span>

<span class="c"># 도커를 이용하여 컨테이너로 접속</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins bash
<span class="nv">$ </span><span class="nb">exit</span>
</code></pre></div></div>

<ul>
  <li>Jenkins 초기 설정을 진행하겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 초기 비밀번호 확인</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins <span class="nb">cat</span> /var/jenkins_home/secrets/initialAdminPassword
<span class="c"># =&gt; dcc757c8c4f14fc09795ed0440baf157</span>

<span class="c"># 브라우저에서 접속하여 초기 비밀번호 입력후 설정 진행 : 계정 / 암호 입력 &gt;&gt; admin / qwe123</span>
<span class="nv">$ </span>open http://localhost:8080
</code></pre></div></div>

<ul>
  <li>jenkins 컨테이너에서 호스트의 도커 데몬을 사용하기 위해 설정을 진행하겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># jenkins 컨테이너에서 호스트의 도커 데몬을 사용하기 위한 설정</span>
<span class="nv">$ </span>docker compose <span class="nb">exec</span> <span class="nt">--privileged</span> <span class="nt">-u</span> root jenkins bash
<span class="nt">-----------------------------------------------------</span>
<span class="nv">$ </span><span class="nb">id</span>
<span class="c"># =&gt; uid=0(root) gid=0(root) groups=0(root)</span>

<span class="nv">$ </span>curl <span class="nt">-fsSL</span> https://download.docker.com/linux/debian/gpg <span class="nt">-o</span> /etc/apt/keyrings/docker.asc
<span class="nv">$ </span><span class="nb">chmod </span>a+r /etc/apt/keyrings/docker.asc
<span class="nv">$ </span><span class="nb">echo</span> <span class="se">\</span>
  <span class="s2">"deb [arch=</span><span class="si">$(</span>dpkg <span class="nt">--print-architecture</span><span class="si">)</span><span class="s2"> signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/debian </span><span class="se">\</span><span class="s2">
  </span><span class="si">$(</span><span class="nb">.</span> /etc/os-release <span class="o">&amp;&amp;</span> <span class="nb">echo</span> <span class="s2">"</span><span class="nv">$VERSION_CODENAME</span><span class="s2">"</span><span class="si">)</span><span class="s2"> stable"</span> | <span class="se">\</span>
  <span class="nb">tee</span> /etc/apt/sources.list.d/docker.list <span class="o">&gt;</span> /dev/null
<span class="nv">$ </span>apt-get update <span class="o">&amp;&amp;</span> apt <span class="nb">install </span>docker-ce-cli curl tree jq <span class="nt">-y</span>

<span class="nv">$ </span>docker info
<span class="c"># =&gt; Client: Docker Engine - Community</span>
<span class="c">#     Version:    27.3.1</span>
<span class="c">#     Context:    default</span>
<span class="c">#     Debug Mode: false</span>
<span class="c">#     Plugins:</span>
<span class="c">#      buildx: Docker Buildx (Docker Inc.)</span>
<span class="c">#        Version:  v0.17.1</span>
<span class="c">#        Path:     /usr/libexec/docker/cli-plugins/docker-buildx</span>
<span class="c">#      compose: Docker Compose (Docker Inc.)</span>
<span class="c">#        Version:  v2.29.7</span>
<span class="c">#        Path:     /usr/libexec/docker/cli-plugins/docker-compose</span>
<span class="c">#    </span>
<span class="c">#    Server:</span>
<span class="c">#     Containers: 27</span>
<span class="c">#      Running: 3</span>
<span class="c">#      Paused: 0</span>
<span class="c">#      Stopped: 24</span>
<span class="c">#     Images: 37</span>
<span class="c">#     Server Version: 20.10.12</span>
<span class="c">#     Storage Driver: overlay2</span>
<span class="c">#      Backing Filesystem: extfs</span>
<span class="c">#      Supports d_type: true</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE                  COMMAND                  CREATED          STATUS          PORTS                                              NAMES</span>
<span class="c">#    06409fe2219f   jenkins/jenkins        &amp;quot;/usr/bin/tini -- /u…&amp;quot;   25 minutes ago   Up 25 minutes   0.0.0.0:8080-&amp;gt;8080/tcp, 0.0.0.0:50000-&amp;gt;50000/tcp   jenkins</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 Docker-out-of-Docker 이기 때문에 호스트 도커 데몬에서 운영되는 컨테이너를 볼 수 있습니다!&lt;/span&gt;</span>
<span class="nv">$ </span>which docker
<span class="c"># =&gt; /usr/bin/docker</span>

<span class="c"># Jenkins 컨테이너 내부에서 root가 아닌 jenkins 유저도 docker를 실행할 수 있도록 권한을 부여</span>
<span class="nv">$ </span>groupadd <span class="nt">-g</span> 2000 <span class="nt">-f</span> docker
<span class="nv">$ </span><span class="nb">chgrp </span>docker /var/run/docker.sock
<span class="nv">$ </span><span class="nb">chmod </span>770 /var/run/docker.sock
<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-l</span> /var/run/docker.sock
<span class="c"># =&gt; srwxr-xr-x 1 root docker 0 Dec  7 03:12 /var/run/docker.sock</span>
<span class="nv">$ </span>usermod <span class="nt">-aG</span> docker jenkins
<span class="nv">$ </span><span class="nb">cat</span> /etc/group | <span class="nb">grep </span>docker
<span class="c"># =&gt; docker:x:2000:jenkins</span>

<span class="nv">$ </span><span class="nb">exit</span>
<span class="nt">--------------------------------------------</span>

<span class="c"># jenkins item 실행 시 docker 명령 실행 권한 에러 발생 : Jenkins 컨테이너 재기동으로 위 설정 내용을 Jenkins app 에도 적용 필요</span>
<span class="nv">$ </span>docker compose restart jenkins
<span class="c"># $ sudo docker compose restart jenkins  # Windows 경우 이후부터 sudo 붙여서 실행</span>

<span class="c"># jenkins user로 docker 명령 실행 확인</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins <span class="nb">id</span>
<span class="c"># =&gt; uid=1000(jenkins) gid=1000(jenkins) groups=1000(jenkins),2000(docker)</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins docker info
<span class="c"># =&gt; Client: Docker Engine - Community</span>
<span class="c">#     Version:    27.3.1</span>
<span class="c">#     Context:    default</span>
<span class="c">#     ...</span>
<span class="c">#    </span>
<span class="c">#    Server:</span>
<span class="c">#     Containers: 27</span>
<span class="c">#      Running: 3</span>
<span class="c">#      Paused: 0</span>
<span class="c">#      Stopped: 24</span>
<span class="c">#     Images: 37</span>
<span class="c">#     Server Version: 20.10.12</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE                  COMMAND                  CREATED          STATUS         PORTS                                              NAMES</span>
<span class="c">#    06409fe2219f   jenkins/jenkins        &amp;quot;/usr/bin/tini -- /u…&amp;quot;   30 minutes ago   Up 2 minutes   0.0.0.0:8080-&amp;gt;8080/tcp, 0.0.0.0:50000-&amp;gt;50000/tcp   jenkins</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<h4 id="gitlab-소개">Gitlab 소개</h4>

<ul>
  <li>Gitlab은 Github와 유사한 Git 기반의 코드 저장소 서비스로, 코드 저장소, 이슈 트래커, CI/CD 파이프라인, 코드 검토 등의 기능을 제공합니다.
<a href="https://www.gitlab.com">Gitlab.com</a></li>
  <li>이번 실습에서는 코드 저장소 기능만 사용하고 Jenkins의 CI/CD 파이프라인을 사용하겠습니다.</li>
  <li>주요 기능
    <ul>
      <li><strong>소스 코드 관리</strong> : GitLab은 Git 기반의 소스 코드 저장소를 제공하여 버전 관리를 쉽게 할 수 있습니다.</li>
      <li><strong>CI/CD 파이프라인</strong> : GitLab은 CI/CD 파이프라인을 통해 코드의 빌드, 테스트, 배포를 자동화할 수 있습니다.</li>
      <li><strong>이슈 트래킹</strong> : 프로젝트의 버그, 기능 요청 등을 관리할 수 있는 이슈 트래킹 시스템을 제공합니다.</li>
      <li><strong>코드 리뷰</strong> : 병합 요청(Merge Request)을 통해 코드 리뷰를 쉽게 진행할 수 있습니다.</li>
      <li><strong>위키</strong> : 프로젝트 관련 문서를 작성하고 관리할 수 있는 위키 기능을 제공합니다.</li>
      <li><strong>프로젝트 관리</strong> : 마일스톤, 보드, 라벨 등을 통해 프로젝트를 체계적으로 관리할 수 있습니다.</li>
      <li><strong>통합 및 확장성</strong> : 다양한 외부 도구와의 통합 및 확장을 지원하여 유연한 개발 환경을 구축할 수 있습니다.</li>
      <li><strong>셀프 호스트 가능</strong> : GitLab은 오픈소스로 제공되어 무료로 자체 서버에 설치하여 사용할 수 있습니다. (일부 기능 차이가 있음)</li>
    </ul>
  </li>
</ul>

<h4 id="gitlab-프로젝트-생성-및-설정">Gitlab 프로젝트 생성 및 설정</h4>

<ul>
  <li>
    <p>Gitlab.com에서 새로운 프로젝트를 생성하겠습니다.
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_9.png" alt="img.png" class="image-center" />
<em class="image-caption">Gitlab 프로젝트 생성</em></p>
  </li>
  <li>
    <p>프로젝트 생성시 프로젝트 이름과 가시성을 설정하고 생성합니다.</p>
    <ul>
      <li><strong>프로젝트 이름</strong> : 2024-cicd-lite-w1</li>
      <li><strong>가시성</strong> : Private</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_10.png" alt="img_1.png" class="image-center" />
<em class="image-caption">Jenkins와 연동을 위해 토큰 발급</em></p>

<ul>
  <li>프로젝트 생성 후 프로젝트 설정에서 CI/CD 파이프라인을 위한 토큰을 발급받습니다.</li>
  <li>프로필 아이콘 클릭 &gt; Preferences &gt; Access Tokens &gt; Add new token을 클릭하여 토큰을 발급받습니다.
    <ul>
      <li><strong>토큰 이름</strong> : jenkins</li>
      <li><strong>권한</strong> : read_repository, write_repository</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_11.png" alt="img_2.png" class="image-center" />
<em class="image-caption">토큰 발급 완료</em></p>

<ul>
  <li>토큰이 완료되면 복사할 수 있습니다. 이후에는 다시 확인할 수 없으므로 잘 기록해두어야 합니다.</li>
</ul>

<h5 id="gitlab에서-소스-받기">Gitlab에서 소스 받기</h5>

<ul>
  <li>소스를 받기 위해 git 주소를 복사합니다.
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_12.png" alt="img.png" class="image-center" />
<em class="image-caption">Gitlab 프로젝트 주소 복사</em></li>
  <li>프로젝트 페이지에 접속 후 Code 버튼을 클릭하고 클립보드 아이콘을 클릭하여 주소를 복사할 수 있습니다.</li>
  <li>복사한 주소로 소스를 받아서 필요한 파일들을 생성해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># &lt;span style="color: green;"&gt;👉 아이디와 비밀번호를 물으면 토큰이름과 발급받은 토큰을 입력하시면 됩니다.&lt;/span&gt;</span>
<span class="nv">$ </span>git clone https://gitlab.com/littlebird/2024-cicd-lite-w1.git
<span class="c"># =&gt; Cloning into '2024-cicd-lite-w1'...</span>
<span class="c">#    Username for 'https://gitlab.com': jenkins</span>
<span class="c">#    Password for 'https://jenkins@gitlab.com': glpat-ABCD1234</span>
<span class="c">#    remote: Enumerating objects: 3, done.</span>
<span class="c">#    remote: Counting objects: 100% (3/3), done.</span>
<span class="c">#    remote: Compressing objects: 100% (2/2), done.</span>
<span class="c">#    remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)</span>
<span class="c">#    Receiving objects: 100% (3/3), done.</span>
<span class="nv">$ </span><span class="nb">cd </span>2024-cicd-lite-w1/

<span class="c"># 소스코드 작성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> app.rb <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
require 'sinatra'

get '/' do
  "Hello, World! The time is #{Time.now}"
end
</span><span class="no">EOF

</span><span class="c"># Dockerfile 작성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Dockerfile <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
FROM ruby:3.3
RUN gem install sinatra rackup puma
COPY app.rb /app/
WORKDIR /app
CMD ["ruby", "app.rb", "-o", "0.0.0.0"]
</span><span class="no">EOF

</span><span class="c"># VERSION 파일 생성</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"0.0.1"</span> <span class="o">&gt;</span> VERSION

<span class="c">#</span>
<span class="nv">$ </span>git add <span class="nb">.</span>
<span class="nv">$ </span>git commit <span class="nt">-m</span> <span class="s2">"Initial commit"</span>
<span class="c"># =&gt; [main 569ce3c] Initial commit</span>
<span class="c">#     3 files changed, 11 insertions(+)</span>
<span class="c">#     create mode 100644 Dockerfile</span>
<span class="c">#     create mode 100644 VERSION</span>
<span class="c">#     create mode 100644 app.rb</span>
<span class="nv">$ </span>git push <span class="nt">-u</span> origin main
<span class="c"># =&gt; Enumerating objects: 6, done.</span>
<span class="c">#    Counting objects: 100% (6/6), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (4/4), done.</span>
<span class="c">#    Writing objects: 100% (5/5), 536 bytes | 536.00 KiB/s, done.</span>
<span class="c">#    Total 5 (delta 0), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To https://gitlab.com/littlebird/2024-cicd-lite-w1.git</span>
<span class="c">#       fe2fb73..569ce3c  main -&amp;gt; main</span>
<span class="c">#    branch 'main' set up to track 'origin/main'.</span>
</code></pre></div></div>

<ul>
  <li>Gitlab 리파지토리에서 확인해보겠습니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_13.png" alt="img.png" /></p>

<ul>
  <li>Gitlab 프로젝트에 소스가 정상적으로 업로드 되었습니다.</li>
</ul>

<h4 id="docker-hub-소개">Docker Hub 소개</h4>

<ul>
  <li><a href="https://hub.docker.com">도커허브(Docker Hub)</a>는 도커 이미지를 저장하고 공유할 수 있는 클라우드 서비스입니다.</li>
  <li>여러 사용자가 자신이 만든 도커 이미지를 서로 자유롭게 공유할 수 있습니다.</li>
  <li>유의 사항
    <ul>
      <li>Docker Hub는 무료로 누구나 업로드 할 수 있기 때문에, 공식(Official) 라벨이 없는 이미지는 보안에 취약할 수 있고, 사용법을 알 수 없거나, 제대로 작동하지 않을 수 있습니다.</li>
      <li>도커 악성 이미지를 통한 취약점 공격 기사 모음
        <ul>
          <li>도커도 이제 공격 통로! 악성 이미지 늘어나고 있다 - <a href="https://www.boannews.com/media/view.asp?idx=93080&amp;page=1&amp;kind=1">링크</a></li>
          <li>도커 환경 공격하는 해커들, 전략을 또 변경했다 - <a href="https://www.boannews.com/media/view.asp?idx=89841&amp;page=1&amp;kind=1">링크</a></li>
          <li>암호화폐 채굴 공격자들, 잘못 설정된 도커 집중 공략 - <a href="https://www.boannews.com/media/view.asp?idx=87427&amp;page=1&amp;kind=1">링크</a></li>
          <li>리눅스 노리던 봇넷 멀웨어 둘, 최근 들어 도커 서버도 노리기 시작 - <a href="https://www.boannews.com/media/view.asp?idx=89205&amp;page=1&amp;kind=1">링크</a></li>
          <li>도커 호스트 감염시켜가며 암호화폐 채굴하는 웜 발견 - <a href="https://www.boannews.com/media/view.asp?idx=83854&amp;page=1&amp;kind=1">링크</a>  *</li>
        </ul>
      </li>
      <li>사용자당 1개의 Private Repository만 무료로 사용할 수 있습니다.</li>
    </ul>
  </li>
  <li>주요 기능
    <ul>
      <li><strong>도커 이미지 저장소</strong> : 도커 이미지를 저장하고 공유할 수 있습니다.</li>
      <li><strong>자동 빌드</strong> : Github, Gitlab과 연동하여 코드가 업데이트 될 때마다 자동으로 이미지를 빌드할 수 있습니다.</li>
      <li><strong>웹훅</strong> : 타 서비스와 연동하여 이벤트가 발생할 때마다 특정 URL로 요청을 보낼 수 있습니다.</li>
      <li><strong>Docker Hub CLI 도구</strong> : 도커 이미지를 커맨드라인으로 관리할 수 있는 도구를 제공합니다.</li>
    </ul>
  </li>
</ul>

<h4 id="docker-hub에-dev-app-private-repo-생성">Docker Hub에 dev-app (private) repo 생성</h4>

<ul>
  <li>Docker Hub에 dev-app이라는 private 리포지토리를 생성하겠습니다.</li>
  <li>Docker Hub에 로그인 후 Repositories &gt; Create Repository를 클릭하여 리포지토리를 생성합니다.
    <ul>
      <li><strong>Repository Name</strong> : dev-app</li>
      <li><strong>Visibility</strong> : Private</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_14.png" alt="img.png" /></p>

<h3 id="jenkins-기본-사용">Jenkins 기본 사용</h3>

<ul>
  <li>Jenkins를 사용하여 CI/CD 파이프라인을 구축해보겠습니다.</li>
  <li>작업 소개
    <ol>
      <li><strong>Trigger</strong> : 작업을 수행하는 시점을 지정합니다.
        <ul>
          <li>작업 수행 태스크 task가 언제 시작될지를 지시할 수 있습니다.</li>
        </ul>
      </li>
      <li><strong>Built step</strong> : 작업을 구성하는 단계별 태스크를 지정합니다.
        <ul>
          <li>특정 목표를 수행하기 위한 태스크를 단계별 step로 구성할 수 있습니다.</li>
          <li>이것을 젠킨스에서는 빌드 스텝 build step이라고 부릅니다.</li>
        </ul>
      </li>
      <li><strong>Post-build action</strong> : 태스크가 완료 후 수행할 명령을 지정합니다.
        <ul>
          <li>예를 들어 작업의 결과(성공 or 실패)를 사용자에게 알려주는 후속 동작이나, 자바 코드를 컴파일한 후 생성된 클래스 파일을 특정 위치로 복사 등의 작업을 수행할 수 있습니다.
     - (참고) 젠킨스의 <strong>빌드</strong> : 젠킨스 작업의 특정 실행 버전
       - 사용자는 젠킨스 작업을 여러번 실행할 수 있는데, 실행될 때마다 <strong>고유 빌드 번호</strong>가 부여됩니다.
       - 작업 실행 중에 생성된 <strong>아티팩트</strong>, <strong>콘솔 로드</strong> 등 특정 실행 버전과 관련된 모든 세부 정보가 해당 빌드 번호로 저장됩니다.</li>
        </ul>
      </li>
    </ol>
  </li>
  <li>첫번째 작업 생성
    <ul>
      <li>name : first</li>
      <li>item type : freestyle project</li>
      <li>Build Steps : Execute shell
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">echo</span> <span class="s2">"docker check"</span> | <span class="nb">tee </span>test.txt
docker ps
</code></pre></div>        </div>
        <p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_15.png" alt="img.png" class="image-center" />
<em class="image-caption">Jenkins 첫번째 작업 생성</em></p>
      </li>
    </ul>
  </li>
  <li>
    <p>“Build Now”(지금 실행) 메뉴를 클릭하여 작업을 실행합니다.
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_16.png" alt="img.png" class="image-center" />
<em class="image-caption">빌드 결과 (Console Output)</em></p>
  </li>
  <li>작업 공간 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins <span class="nb">ls</span> /var/jenkins_home/workspace
<span class="c"># =&gt; first</span>

<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins <span class="nb">ls</span> /var/jenkins_home/workspace/first
<span class="c"># =&gt; test.txt</span>

<span class="c"># 작업 결과 확인</span>
<span class="nv">$ </span>docker compose <span class="nb">exec </span>jenkins <span class="nb">cat</span> /var/jenkins_home/workspace/first/test.txt
<span class="c"># =&gt; docker check</span>
</code></pre></div></div>

<h4 id="jenkins-플러그인-설치">Jenkins 플러그인 설치</h4>

<ul>
  <li>Jenkins 플러그인을 설치하여 더 다양한 기능을 사용할 수 있습니다.</li>
  <li>Dashboard &gt; Manage Jenkins 메뉴를 클릭하고, 플러그인 관리를 클릭합니다.</li>
  <li>Available plugins 를 클릭하여 다양한 플러그인을 설치할 수 있습니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_17.png" alt="img.png" class="image-center" />
<em class="image-caption">Jenkins 플러그인 설치 화면</em></p>

<ul>
  <li>다음의 plugin 을 설치합니다.
    <ul>
      <li><strong>Pipeline Stage View</strong> : 파이프라인 스테이지를 시각적으로 보여주는 플러그인 <a href="https://plugins.jenkins.io/pipeline-stage-view/">링크</a></li>
      <li><strong>Docker Pipeline</strong> : 파이프라인에서 도커를 사용할 수 있도록 지원하는 플러그인 <a href="https://plugins.jenkins.io/docker-workflow/">링크</a></li>
      <li><strong>Gitlab</strong> : Gitlab과 Jenkins를 연동할 수 있도록 지원하는 플러그인 <a href="https://plugins.jenkins.io/gitlab-plugin/">링크</a></li>
    </ul>
  </li>
  <li>Dashboard &gt; Manage Jenkins &gt; Credentials &gt; System &gt; Global credentials (unrestricted) &gt; Add Credentials 를 클릭하여 자격증명을 추가합니다.
    <ul>
      <li>Docker hub 크레덴셜
        <ul>
          <li>Kind : Username with password</li>
          <li>Username : <code class="language-plaintext highlighter-rouge">&lt;docker hub 계정&gt;</code></li>
          <li>Password : <code class="language-plaintext highlighter-rouge">&lt;docker hub 비밀번호 혹은 토큰&gt;</code></li>
          <li>ID : <code class="language-plaintext highlighter-rouge">dockerhub-credentials</code> =&gt; 자격증명 이름으로 pipeline에서 사용됩니다.</li>
        </ul>
      </li>
      <li>Gitlab 저장소 크레덴셜
        <ul>
          <li>Kind : Username with password</li>
          <li>Username : <code class="language-plaintext highlighter-rouge">&lt;gitlab 토큰 이름&gt;</code></li>
          <li>Password : <code class="language-plaintext highlighter-rouge">&lt;gitlab 토큰&gt;</code></li>
          <li>ID : <code class="language-plaintext highlighter-rouge">gitlab-credentials</code> =&gt; 자격증명 이름으로 pipeline에서 사용됩니다.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="파이프라인">파이프라인</h4>

<ul>
  <li>pipeline은 CI/CD 파이프라인을 코드로 정의하는 플러그인 스크립트입니다. <a href="https://www.jenkins.io/doc/book/pipeline/">docs</a></li>
</ul>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_18.png" alt="img.png" /></p>

<ul>
  <li>파이프라인의 <strong>장점</strong>
    <ul>
      <li><strong>코드</strong> : 애플리케이션 CI/CD 프로세스를 코드 형식으로 작성할 수 있고, 해당 코드를 중앙 리포지터리에 저장하여 팀원과 공유 및 작업 가능합니다.</li>
      <li><strong>내구성</strong> : 젠킨스 서비스가 의도적으로 또는 우발적으로 재시작되더라도 문제없이 유지됩니다.</li>
      <li><strong>일시 중지 가능</strong> : 파이프라인을 실행하는 도중 사람의 승인이나 입력을 기다리기 위해 중단하거나 기다리는 것이 가능합니다.</li>
      <li><strong>다양성</strong> : 분기나 반복, 병렬 처리와 같은 다양한 CI/CD 요구 사항을 지원합니다.</li>
    </ul>
  </li>
  <li>파이프라인 용어
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_19.png" alt="img.png" class="image-center" />
    <ul>
      <li><strong>Pipeline(파이프라인)</strong> : 전체 빌드 프로세스를 정의하는 코드</li>
      <li><strong>Node(노드) = Agent</strong> : 파이프라인을 실행하는 시스템</li>
      <li><strong>Stages</strong> : 순차 작업 명세인 stage 들의 묶음</li>
      <li><strong>Stage</strong> : 특정 단계에서 수행되는 작업들의 정의</li>
      <li><strong>Steps</strong> : 파이프라인의 특정 단계에서 수행되는 단일 작업을 의미.</li>
      <li><strong>Post</strong> : 빌드 후 조치, 일반적으로 stages 작업이 끝난 후 추가적인 steps/step</li>
      <li><strong>Directive</strong> - <a href="https://www.jenkins.io/doc/book/pipeline/syntax/#declarative-directives">Docs</a>
        <ul>
          <li><strong>Environment</strong> (key=value) : 파이프라인 내부에서 사용할 환경변수</li>
          <li><strong>Parameters</strong> : 입력 받아야할 변수를 정의 - Type(string, text, choice, password …)</li>
          <li><strong>Triggers</strong> : 파이프라인을 실행하는 조건 설정</li>
          <li><strong>Input</strong> : 파이프라인 실행 중 사용자 입력을 받을 수 있도록 설정</li>
          <li><strong>When</strong> : stage 를 실행 할 조건 설정</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>파이프라인 구성 형태 3가지
    <ol>
      <li><strong>Pipeline Script</strong> : 일반적인 방식으로 Jenkins 파이프라인을 생성하여 Shell Script 형태로 작성 <a href="https://www.jenkins.io/doc/book/pipeline/getting-started/#through-the-classic-ui">링크</a></li>
      <li><strong>Pipeline Script from SCM</strong> : Jenkinsfile을 git 등의 SCM(Source Code Management)에 저장하고, 빌드 시작 시 해당 파일을 읽어 파이프라인을 실행 <a href="https://www.jenkins.io/doc/book/pipeline/getting-started/#defining-a-pipeline-in-scm">링크</a></li>
      <li><strong>Blue Ocean 기반</strong> : Blue Ocean 플러그인을 설치하여 UI로 파이프라인을 구성하면 Jenkinsfile이 자동으로 생성됨 <a href="https://www.jenkins.io/doc/book/pipeline/getting-started/#through-blue-ocean">링크</a></li>
    </ol>
  </li>
  <li>파이프라인 구문 형태 2가지
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_20.png" alt="img.png" class="image-center w-80" />
<em class="image-caption">파이프라인 구문 형태별 구조</em>
    <ol>
      <li><strong>Declarative Pipeline</strong> : 간결하고 가독성이 좋으며, 최근 문법이고, 권장하는 방법. step은 필수로 사용
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pipeline <span class="o">{</span>
   agent any     <span class="c"># Execute this Pipeline or any of its stages, on any available agent.</span>
   stages <span class="o">{</span>
     stage<span class="o">(</span><span class="s1">'Build'</span><span class="o">)</span> <span class="o">{</span>   <span class="c"># Defines the "Build" stage.</span>
         steps <span class="o">{</span>
             //         <span class="c"># Perform some steps related to the "Build" stage.</span>
         <span class="o">}</span>
     <span class="o">}</span>
     stage<span class="o">(</span><span class="s1">'Test'</span><span class="o">)</span> <span class="o">{</span> 
         steps <span class="o">{</span>
             // 
         <span class="o">}</span>
     <span class="o">}</span>
     stage<span class="o">(</span><span class="s1">'Deploy'</span><span class="o">)</span> <span class="o">{</span> 
         steps <span class="o">{</span>
             // 
         <span class="o">}</span>
     <span class="o">}</span>
   <span class="o">}</span>
<span class="o">}</span>
</code></pre></div>        </div>
      </li>
      <li><strong>Scripted Pipeline</strong> : 커스텀이 용이하나 복잡도가 높고, step은 필수가 아님
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>node <span class="o">{</span>             <span class="c"># Execute this Pipeline or any of its stages, on any available agent.</span>
  stage<span class="o">(</span><span class="s1">'Build'</span><span class="o">)</span> <span class="o">{</span> <span class="c"># Defines the "Build" stage. stage blocks are optional in Scripted Pipeline syntax. However, implementing stage blocks in a Scripted Pipeline provides clearer visualization of each stage's subset of tasks/steps in the Jenkins UI.</span>
   //              <span class="c"># Perform some steps related to the "Build" stage.</span>
  <span class="o">}</span>
  stage<span class="o">(</span><span class="s1">'Test'</span><span class="o">)</span> <span class="o">{</span> 
   // 
  <span class="o">}</span>
  stage<span class="o">(</span><span class="s1">'Deploy'</span><span class="o">)</span> <span class="o">{</span> 
   // 
  <span class="o">}</span>
<span class="o">}</span>
</code></pre></div>        </div>
      </li>
    </ol>
  </li>
</ul>

<h5 id="jenkins-pipeline-실습">Jenkins Pipeline 실습</h5>

<ul>
  <li>New Item &gt; Pipeline 으로 파이프라인을 생성합니다.
    <ul>
      <li><strong>Name</strong> : First-Pipeline</li>
      <li><strong>Definition</strong> : Pipeline script</li>
      <li><strong>Script</strong> : 아래의 파이프라인 스크립트를 입력합니다.</li>
    </ul>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pipeline <span class="o">{</span>
    agent any

    stages <span class="o">{</span>
        stage<span class="o">(</span><span class="s1">'Hello'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                <span class="nb">echo</span> <span class="s1">'Hello World'</span>
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'Deploy'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                <span class="nb">echo</span> <span class="s2">"Deployed successfully!"</span><span class="p">;</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<ul>
  <li>
    <p>Save 하여 저장후 “Build Now”를 클릭하여 파이프라인을 실행합니다.
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_21.png" alt="img.png" class="image-center" />
<em class="image-caption">파이프라인 실행 결과</em></p>
  </li>
  <li>
    <p>아래 처럼 수정 후 확인: 환경변수 사용, 문자열 보간 → Console Output 확인</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pipeline <span class="o">{</span>
    agent any
    environment <span class="o">{</span> 
        CC <span class="o">=</span> <span class="s1">'clang'</span>
    <span class="o">}</span>
      
    stages <span class="o">{</span>
        stage<span class="o">(</span><span class="s1">'Example'</span><span class="o">)</span> <span class="o">{</span>
            environment <span class="o">{</span> 
                AN_ACCESS_KEY <span class="o">=</span> <span class="s1">'abcdefg'</span>
            <span class="o">}</span>
            steps <span class="o">{</span>
                <span class="nb">echo</span> <span class="s2">"</span><span class="k">${</span><span class="nv">CC</span><span class="k">}</span><span class="s2">"</span><span class="p">;</span>
                sh <span class="s1">'echo ${AN_ACCESS_KEY}'</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div>    </div>

    <p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_22.png" alt="img.png" class="image-center" />
<em class="image-caption">Console Output</em></p>
  </li>
  <li>
    <p>아래 처럼 수정 후 확인: 파이프라인 빌드 시작(트리거) → Console Output 확인</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pipeline <span class="o">{</span>
    agent any
    triggers <span class="o">{</span>
        cron<span class="o">(</span><span class="s1">'H */4 * * 1-5'</span><span class="o">)</span>
    <span class="o">}</span>
    stages <span class="o">{</span>
        stage<span class="o">(</span><span class="s1">'Example'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                <span class="nb">echo</span> <span class="s1">'Hello World'</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div>    </div>

    <p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_23.png" alt="img.png" class="image-center" />
<em class="image-caption">Console Output</em></p>
  </li>
  <li>
    <p>아래 처럼 수정 후 확인: 파라미터와 함께 빌드 → Console Output 확인 ⇒ 다시 한번 더 빌드 클릭 (변수 입력 칸 확인)</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pipeline <span class="o">{</span>
    agent any
    parameters <span class="o">{</span>
        string<span class="o">(</span>name: <span class="s1">'PERSON'</span>, defaultValue: <span class="s1">'Mr Jenkins'</span>, description: <span class="s1">'Who should I say hello to?'</span><span class="o">)</span>
        text<span class="o">(</span>name: <span class="s1">'BIOGRAPHY'</span>, defaultValue: <span class="s1">''</span>, description: <span class="s1">'Enter some information about the person'</span><span class="o">)</span>
        booleanParam<span class="o">(</span>name: <span class="s1">'TOGGLE'</span>, defaultValue: <span class="nb">true</span>, description: <span class="s1">'Toggle this value'</span><span class="o">)</span>
        choice<span class="o">(</span>name: <span class="s1">'CHOICE'</span>, choices: <span class="o">[</span><span class="s1">'One'</span>, <span class="s1">'Two'</span>, <span class="s1">'Three'</span><span class="o">]</span>, description: <span class="s1">'Pick something'</span><span class="o">)</span>
        password<span class="o">(</span>name: <span class="s1">'PASSWORD'</span>, defaultValue: <span class="s1">'SECRET'</span>, description: <span class="s1">'Enter a password'</span><span class="o">)</span>
    <span class="o">}</span>
    stages <span class="o">{</span>
        stage<span class="o">(</span><span class="s1">'Example'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                <span class="nb">echo</span> <span class="s2">"Hello </span><span class="k">${</span><span class="nv">params</span><span class="p">.PERSON</span><span class="k">}</span><span class="s2">"</span>
                <span class="nb">echo</span> <span class="s2">"Biography: </span><span class="k">${</span><span class="nv">params</span><span class="p">.BIOGRAPHY</span><span class="k">}</span><span class="s2">"</span>
                <span class="nb">echo</span> <span class="s2">"Toggle: </span><span class="k">${</span><span class="nv">params</span><span class="p">.TOGGLE</span><span class="k">}</span><span class="s2">"</span>
                <span class="nb">echo</span> <span class="s2">"Choice: </span><span class="k">${</span><span class="nv">params</span><span class="p">.CHOICE</span><span class="k">}</span><span class="s2">"</span>
                <span class="nb">echo</span> <span class="s2">"Password: </span><span class="k">${</span><span class="nv">params</span><span class="p">.PASSWORD</span><span class="k">}</span><span class="s2">"</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>파이프라인 스크립트를 수정하고 저장 후 “Build with Parameters”를 클릭하여 파라미터를 입력하고 빌드를 실행하면
아래와 같이 지정된 파라미터로 빌드를 실행할 수 있습니다.</p>
  </li>
</ul>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_24.png" alt="img.png" class="image-center" />
<em class="image-caption">Build with Parameters 화면</em></p>

<ul>
  <li>
    <p>아래처럼 post (빌드 후 조치) 블록을 추가하여 빌드 후 조치를 설정할 수 있습니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pipeline <span class="o">{</span>
    agent any
    stages <span class="o">{</span>
        stage<span class="o">(</span><span class="s1">'Compile'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                <span class="nb">echo</span> <span class="s2">"Compiled successfully!"</span><span class="p">;</span>
            <span class="o">}</span>
        <span class="o">}</span>
  
        stage<span class="o">(</span><span class="s1">'JUnit'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                <span class="nb">echo</span> <span class="s2">"JUnit passed successfully!"</span><span class="p">;</span>
            <span class="o">}</span>
        <span class="o">}</span>
  
        stage<span class="o">(</span><span class="s1">'Code Analysis'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                <span class="nb">echo</span> <span class="s2">"Code Analysis completed successfully!"</span><span class="p">;</span>
            <span class="o">}</span>
        <span class="o">}</span>
  
        stage<span class="o">(</span><span class="s1">'Deploy'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                <span class="nb">echo</span> <span class="s2">"Deployed successfully!"</span><span class="p">;</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
    post <span class="o">{</span> 
        always <span class="o">{</span> 
            <span class="nb">echo</span> <span class="s1">'I will always say Hello again!'</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div>    </div>

    <p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_25.png" alt="img.png" class="image-center w-80" />
<em class="image-caption">step 별 메시지와 post 메시지</em></p>

    <ul>
      <li>post에는 always 외에도 다음과 같은 옵션을 사용할 수 있습니다.
        <ul>
          <li><strong>always</strong> : 항상 실행</li>
          <li><strong>changed</strong> : 성공 또는 실패가 변경되었을 때 실행</li>
          <li><strong>success</strong> : 성공했을 때 실행</li>
          <li><strong>failure</strong> : 실패했을 때 실행</li>
          <li><strong>unstable</strong> : 불안정한 상태일 때 실행</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>Pipeline Syntax -&gt; Snippet Generator 를 사용하여 파이프라인 스크립트를 생성할 수 있습니다.
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_26.png" alt="img.png" class="image-center w-80" /></p>
  </li>
</ul>

<h5 id="gitlab과-jenkins-pipeline-연동-실습">Gitlab과 Jenkins pipeline 연동 실습</h5>

<ul>
  <li>Gitlab에서 소스를 받아 빌드 후 Docker Hub에 이미지를 업로드하는 파이프라인을 구성해보겠습니다.</li>
  <li>Pipeline script</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pipeline <span class="o">{</span>
    agent any
    environment <span class="o">{</span>
        DOCKER_IMAGE <span class="o">=</span> <span class="s1">'sweetlittlebird/dev-app'</span> // Docker 이미지 이름
    <span class="o">}</span>
    stages <span class="o">{</span>
        stage<span class="o">(</span><span class="s1">'Checkout'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                 git branch: <span class="s1">'main'</span>,
                 url: <span class="s1">'https://gitlab.com/littlebird/2024-cicd-lite-w1.git'</span>,  // Git에서 코드 체크아웃
                 credentialsId: <span class="s1">'gitlab-credentials'</span>  // Credentials ID
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'Read VERSION'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                script <span class="o">{</span>
                    // VERSION 파일 읽기
                    def version <span class="o">=</span> readFile<span class="o">(</span><span class="s1">'VERSION'</span><span class="o">)</span>.trim<span class="o">()</span>
                    <span class="nb">echo</span> <span class="s2">"Version found: </span><span class="k">${</span><span class="nv">version</span><span class="k">}</span><span class="s2">"</span>
                    // 환경 변수 설정
                    env.DOCKER_TAG <span class="o">=</span> version
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'Docker Build and Push'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                script <span class="o">{</span>
                    docker.withRegistry<span class="o">(</span><span class="s1">'https://index.docker.io/v1/'</span>, <span class="s1">'dockerhub-credentials'</span><span class="o">)</span> <span class="o">{</span>
                        // DOCKER_TAG 사용
                        def appImage <span class="o">=</span> docker.build<span class="o">(</span><span class="s2">"</span><span class="k">${</span><span class="nv">DOCKER_IMAGE</span><span class="k">}</span><span class="s2">:</span><span class="k">${</span><span class="nv">DOCKER_TAG</span><span class="k">}</span><span class="s2">"</span><span class="o">)</span>
                        appImage.push<span class="o">()</span>
                    <span class="o">}</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
    <span class="o">}</span>
    post <span class="o">{</span>
        success <span class="o">{</span>
            <span class="nb">echo</span> <span class="s2">"Docker image </span><span class="k">${</span><span class="nv">DOCKER_IMAGE</span><span class="k">}</span><span class="s2">:</span><span class="k">${</span><span class="nv">DOCKER_TAG</span><span class="k">}</span><span class="s2"> has been built and pushed successfully!"</span>
        <span class="o">}</span>
        failure <span class="o">{</span>
            <span class="nb">echo</span> <span class="s2">"Pipeline failed. Please check the logs."</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div>

<ul>
  <li>
    <p>Build Now -&gt; Console Output 확인</p>

    <p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_27.png" alt="img.png" class="image-center w-80" /></p>
  </li>
  <li>
    <p>Docker Hub에서 이미지 확인</p>

    <p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_28.png" alt="img.png" class="image-center" /></p>
  </li>
</ul>

<h4 id="도커-기반-어플리케이션의-cicd-구성">도커 기반 어플리케이션의 CI/CD 구성</h4>

<ul>
  <li>Jenkins와 Gitlab을 사용하여 다음 그림과 같은 형태의 도커 기반 어플리케이션의 CI/CD 파이프라인을 구성해보겠습니다.</li>
</ul>

<p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_29.png" alt="img.png" class="image-center w-80" />
<em class="image-caption">목표 CI/CD 파이프라인</em></p>

<h5 id="gitlab에서-jenkins-연동-설정">Gitlab에서 Jenkins 연동 설정</h5>

<ul>
  <li>gitlab 프로젝트 페이지 &gt; Settings &gt; Integrations &gt; Jenkins 연결후 아래의 정보를 입력 합니다.
    <ul>
      <li><strong>Enable integration</strong> : Active 체크</li>
      <li><strong>Trigger</strong> : Push, Merge request 체크</li>
      <li><strong>URL</strong> : <code class="language-plaintext highlighter-rouge">http://&lt;Jenkins접속주소&gt;:&lt;Jenkins포트&gt;</code></li>
      <li><strong>Project name</strong> : <code class="language-plaintext highlighter-rouge">SCM-Pipeline</code> (Jenkins 프로젝트 이름)</li>
      <li><strong>Username</strong> : <code class="language-plaintext highlighter-rouge">&lt;Jenkins 아이디&gt;</code></li>
      <li><strong>Password</strong> : <code class="language-plaintext highlighter-rouge">&lt;Jenkins 비밀번호&gt;</code></li>
    </ul>

    <p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_30.png" alt="img.png" class="image-center" /></p>
  </li>
</ul>

<h5 id="jenkins에서-gitlab-연동-설정">Jenkins에서 Gitlab 연동 설정</h5>

<ul>
  <li>Jenkins Item 생성
    <ul>
      <li>Dashboard &gt; New Item &gt; Pipeline (item name : <code class="language-plaintext highlighter-rouge">SCM-Pipeline</code>)</li>
    </ul>
  </li>
  <li>Build Triggers 설정
    <ul>
      <li>Configuration &gt; Build Triggers
        <ul>
          <li><strong>Build when a change is pushed to GitLab</strong> 체크</li>
          <li><strong>Push Events</strong> 체크</li>
          <li><strong>Accepted Merge Request Events</strong> 체크
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_31.png" alt="img.png" /></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>Jenkins 파일 생성 후 push</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&gt;</span> Jenkinsfile <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh">
pipeline {
    agent any
    environment {
        DOCKER_IMAGE = 'sweetlittlebird/dev-app' // Docker 이미지 이름
    }
    stages {
        stage('Checkout') {
            steps {
                 git branch: 'main',
                 url: 'https://gitlab.com/littlebird/2024-cicd-lite-w1.git',  // Git에서 코드 체크아웃
                 credentialsId: 'gitlab-credentials'  // Credentials ID
            }
        }
        stage('Read VERSION') {
            steps {
                script {
                    // VERSION 파일 읽기
                    def version = readFile('VERSION').trim()
                    echo "Version found: </span><span class="se">\$</span><span class="sh">{version}"
                    // 환경 변수 설정
                    env.DOCKER_TAG = version
                }
            }
        }
        stage('Docker Build and Push') {
            steps {
                script {
                    docker.withRegistry('https://index.docker.io/v1/', 'dockerhub-credentials') {
                        // DOCKER_TAG 사용
                        def appImage = docker.build("</span><span class="se">\$</span><span class="sh">{DOCKER_IMAGE}:</span><span class="se">\$</span><span class="sh">{DOCKER_TAG}")
                        appImage.push()
                    }
                }
            }
        }
    }
    post {
        success {
            echo "Docker image </span><span class="se">\$</span><span class="sh">{DOCKER_IMAGE}:</span><span class="se">\$</span><span class="sh">{DOCKER_TAG} has been built and pushed successfully!"
        }
        failure {
            echo "Pipeline failed. Please check the logs."
        }
    }
}
</span><span class="no">EOF
  
</span><span class="c"># 버전 업데이트</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; VERSION
0.0.2
</span><span class="no">EOF
  
</span><span class="nv">$ </span>git add <span class="nb">.</span>
<span class="nv">$ </span>git commit <span class="nt">-m</span> <span class="s2">"Add Jenkinsfile"</span>
<span class="c"># =&gt; [main e5671f2] Add Jenkinsfile</span>
<span class="c">#     1 file changed, 45 insertions(+)</span>
<span class="c">#     create mode 100644 Jenkinsfile</span>
<span class="nv">$ </span>git push <span class="nt">-u</span> origin main
<span class="c"># =&gt; Enumerating objects: 4, done.</span>
<span class="c">#    Counting objects: 100% (4/4), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (3/3), done.</span>
<span class="c">#    Writing objects: 100% (3/3), 859 bytes | 859.00 KiB/s, done.</span>
<span class="c">#    Total 3 (delta 1), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To https://gitlab.com/littlebird/2024-cicd-lite-w1.git</span>
<span class="c">#       41a6efc..e5671f2  main -&amp;gt; main</span>
<span class="c">#    branch 'main' set up to track 'origin/main'.</span>
</code></pre></div>    </div>
  </li>
  <li>Jenkins 트리거 빌드 확인
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_32.png" alt="img.png" />
    <ul>
      <li>git push에 의해 자동으로 빌드가 잘 되었습니다.</li>
    </ul>
  </li>
  <li>Docker 저장소 확인
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_33.png" alt="img.png" />
    <ul>
      <li>Docker Hub에 수정된 0.0.2 버전의 이미지가 업로드 되었습니다.</li>
    </ul>
  </li>
  <li>
    <p>Gitlab Webhook 기록 확인
<img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_34.png" alt="img.png" class="image-center" /></p>
  </li>
  <li>
    <p>app.rb 소스와 VERSION 변경 후 Jenkins 트리거 작업 한번 더 확인</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># app.rb 수정</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s1">'s/Hello, World!/Hello, Jenkins! 😀/'</span> app.rb
  
<span class="c"># VERSION 수정</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"0.0.3"</span> <span class="o">&gt;</span> VERSION
  
<span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"Update app.rb and VERSION </span><span class="si">$(</span><span class="nb">cat </span>VERSION<span class="si">)</span><span class="s2">"</span> <span class="o">&amp;&amp;</span> git push <span class="nt">-u</span> origin main
<span class="c"># =&gt; [main a100e97] Update app.rb and VERSION 0.0.3</span>
<span class="c">#     3 files changed, 7 insertions(+), 2 deletions(-)</span>
<span class="c">#     create mode 100644 app.rb-e</span>
<span class="c">#    Enumerating objects: 7, done.</span>
<span class="c">#    Counting objects: 100% (7/7), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (3/3), done.</span>
<span class="c">#    Writing objects: 100% (4/4), 509 bytes | 509.00 KiB/s, done.</span>
<span class="c">#    Total 4 (delta 0), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To https://gitlab.com/littlebird/2024-cicd-lite-w1.git</span>
<span class="c">#       1bd4fcb..a100e97  main -&amp;gt; main</span>
<span class="c">#    branch 'main' set up to track 'origin/main'.</span>
</code></pre></div>    </div>

    <p><img src="/assets/2024/cicd-lite/w1/20241205_cicd_lite_w1_35.png" alt="img.png" /></p>
    <ul>
      <li>빌드가 잘 되고 Docker Hub에 이미지가 업로드 되었습니다.</li>
    </ul>
  </li>
</ul>

<h5 id="jenkins-빌드-후-컨테이너-실행">Jenkins 빌드 후 컨테이너 실행</h5>

<ul>
  <li>Jenkins pipline 빌드 후 Docker 컨테이너를 실행하는 파이프라인을 구성해보겠습니다.</li>
  <li>
    <p>Jenkinsfile 수정</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pipeline <span class="o">{</span>
    agent any
    environment <span class="o">{</span>
        DOCKER_IMAGE <span class="o">=</span> <span class="s1">'sweetlittlebird/dev-app'</span> // Docker 이미지 이름
        CONTAINER_NAME <span class="o">=</span> <span class="s1">'dev-app'</span>  // Docker 컨테이너 이름
    <span class="o">}</span>
    stages <span class="o">{</span>
        stage<span class="o">(</span><span class="s1">'Checkout'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                git branch: <span class="s1">'main'</span>,
                url: <span class="s1">'https://gitlab.com/littlebird/2024-cicd-lite-w1.git'</span>,  // Git에서 코드 체크아웃
                credentialsId: <span class="s1">'gitlab-credentials'</span>  // Credentials ID
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'Read VERSION'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                script <span class="o">{</span>
                    // VERSION 파일 읽기
                    def version <span class="o">=</span> readFile<span class="o">(</span><span class="s1">'VERSION'</span><span class="o">)</span>.trim<span class="o">()</span>
                    <span class="nb">echo</span> <span class="s2">"Version found: </span><span class="k">${</span><span class="nv">version</span><span class="k">}</span><span class="s2">"</span>
                    // 환경 변수 설정
                    env.DOCKER_TAG <span class="o">=</span> version
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'Docker Build and Push'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                script <span class="o">{</span>
                    docker.withRegistry<span class="o">(</span><span class="s1">'https://index.docker.io/v1/'</span>, <span class="s1">'dockerhub-credentials'</span><span class="o">)</span> <span class="o">{</span>
                        // DOCKER_TAG 사용
                        def appImage <span class="o">=</span> docker.build<span class="o">(</span><span class="s2">"</span><span class="k">${</span><span class="nv">DOCKER_IMAGE</span><span class="k">}</span><span class="s2">:</span><span class="k">${</span><span class="nv">DOCKER_TAG</span><span class="k">}</span><span class="s2">"</span><span class="o">)</span>
                        appImage.push<span class="o">()</span>
                    <span class="o">}</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>
        stage<span class="o">(</span><span class="s1">'Check, Stop and Run Docker Container'</span><span class="o">)</span> <span class="o">{</span>
            steps <span class="o">{</span>
                script <span class="o">{</span>
                    // 실행 중인 컨테이너 확인
                    def isRunning <span class="o">=</span> sh<span class="o">(</span>
                        script: <span class="s2">"docker ps -q -f name=</span><span class="k">${</span><span class="nv">CONTAINER_NAME</span><span class="k">}</span><span class="s2">"</span>,
                        returnStdout: <span class="nb">true</span>
                    <span class="o">)</span>.trim<span class="o">()</span>
                      
                    <span class="k">if</span> <span class="o">(</span>isRunning<span class="o">)</span> <span class="o">{</span>
                        <span class="nb">echo</span> <span class="s2">"Container '</span><span class="k">${</span><span class="nv">CONTAINER_NAME</span><span class="k">}</span><span class="s2">' is already running. Stopping it..."</span>
                        // 실행 중인 컨테이너 중지
                        sh <span class="s2">"docker stop </span><span class="k">${</span><span class="nv">CONTAINER_NAME</span><span class="k">}</span><span class="s2">"</span>
                        // 컨테이너 제거
                        sh <span class="s2">"docker rm </span><span class="k">${</span><span class="nv">CONTAINER_NAME</span><span class="k">}</span><span class="s2">"</span>
                        <span class="nb">echo</span> <span class="s2">"Container '</span><span class="k">${</span><span class="nv">CONTAINER_NAME</span><span class="k">}</span><span class="s2">' stopped and removed."</span>
                    <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
                        <span class="nb">echo</span> <span class="s2">"Container '</span><span class="k">${</span><span class="nv">CONTAINER_NAME</span><span class="k">}</span><span class="s2">' is not running."</span>
                    <span class="o">}</span>
                      
                    // 5초 대기
                    <span class="nb">echo</span> <span class="s2">"Waiting for 5 seconds before starting the new container..."</span>
                    <span class="nb">sleep</span><span class="o">(</span>5<span class="o">)</span>
                      
                    // 신규 컨테이너 실행
                    <span class="nb">echo</span> <span class="s2">"Starting a new container '</span><span class="k">${</span><span class="nv">CONTAINER_NAME</span><span class="k">}</span><span class="s2">'..."</span>
                    sh <span class="s2">"""
                    docker run -d --name </span><span class="k">${</span><span class="nv">CONTAINER_NAME</span><span class="k">}</span><span class="s2"> -p 4000:4567 </span><span class="k">${</span><span class="nv">DOCKER_IMAGE</span><span class="k">}</span><span class="s2">:</span><span class="k">${</span><span class="nv">DOCKER_TAG</span><span class="k">}</span><span class="s2">
                    """</span>
                <span class="o">}</span>
            <span class="o">}</span>
        <span class="o">}</span>        
    <span class="o">}</span>
    post <span class="o">{</span>
        success <span class="o">{</span>
            <span class="nb">echo</span> <span class="s2">"Docker image </span><span class="k">${</span><span class="nv">DOCKER_IMAGE</span><span class="k">}</span><span class="s2">:</span><span class="k">${</span><span class="nv">DOCKER_TAG</span><span class="k">}</span><span class="s2"> has been built and pushed successfully!"</span>
        <span class="o">}</span>
        failure <span class="o">{</span>
            <span class="nb">echo</span> <span class="s2">"Pipeline failed. Please check the logs."</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>git commit 후 push</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">echo </span>0.0.4 <span class="o">&gt;</span> VERSION
  
<span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"Update Jenkinsfile </span><span class="si">$(</span><span class="nb">cat </span>VERSION<span class="si">)</span><span class="s2">"</span> <span class="o">&amp;&amp;</span> git push <span class="nt">-u</span> origin main
<span class="c"># =&gt; [main 25e5c95] Update Jenkinsfile 0.0.4</span>
<span class="c">#     2 files changed, 2 insertions(+), 1 deletion(-)</span>
<span class="c">#    Enumerating objects: 7, done.</span>
<span class="c">#    Counting objects: 100% (7/7), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (3/3), done.</span>
<span class="c">#    Writing objects: 100% (4/4), 385 bytes | 385.00 KiB/s, done.</span>
<span class="c">#    Total 4 (delta 2), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To https://gitlab.com/littlebird/2024-cicd-lite-w1.git</span>
<span class="c">#       26c809d..25e5c95  main -&amp;gt; main</span>
<span class="c">#    branch 'main' set up to track 'origin/main'.</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>생성된 컨테이너 접속 확인</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>docker image <span class="nb">ls</span>
<span class="c"># =&gt; REPOSITORY                                                                   TAG           IMAGE ID       CREATED             SIZE</span>
<span class="c">#    sweetlittlebird/dev-app                                                      0.0.4         2f5f42fa7dd6   9 minutes ago       1.01GB</span>
<span class="c">#    ... </span>
<span class="nv">$ </span>docker ps <span class="nt">--filter</span> <span class="nv">name</span><span class="o">=</span>dev-app
<span class="c"># =&gt; CONTAINER ID   IMAGE                           COMMAND                  CREATED         STATUS         PORTS                  NAMES</span>
<span class="c">#    e5d4760ea725   sweetlittlebird/dev-app:0.0.4   &amp;quot;ruby app.rb -o 0.0.…&amp;quot;   2 minutes ago   Up 2 minutes   0.0.0.0:4000-&amp;gt;80/tcp   dev-app</span>
<span class="nv">$ </span>curl http://localhost:4000
<span class="c"># =&gt; Hello, Jenkins! 😀 The time is 2024-10-01 15:49:44 +0000!!</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>app.rb와 VERSION 수정 후 push 후 컨테이너 접속 후 반영 확인</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># app.rb 수정</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="nt">-e</span> <span class="s1">'s/Hello, Jenkins! 😀/Hello, Jenkins again!!! 😎/'</span> app.rb
  
<span class="c"># VERSION 수정</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"0.0.5"</span> <span class="o">&gt;</span> VERSION
  
<span class="nv">$ </span>git add <span class="nb">.</span> <span class="o">&amp;&amp;</span> git commit <span class="nt">-m</span> <span class="s2">"Update app.rb and VERSION </span><span class="si">$(</span><span class="nb">cat </span>VERSION<span class="si">)</span><span class="s2">"</span> <span class="o">&amp;&amp;</span> git push <span class="nt">-u</span> origin main
<span class="c"># =&gt; [main 70eaa32] Update app.rb and VERSION 0.0.5</span>
<span class="c">#     3 files changed, 3 insertions(+), 3 deletions(-)</span>
<span class="c">#    Enumerating objects: 7, done.</span>
<span class="c">#    Counting objects: 100% (7/7), done.</span>
<span class="c">#    Delta compression using up to 8 threads</span>
<span class="c">#    Compressing objects: 100% (3/3), done.</span>
<span class="c">#    Writing objects: 100% (4/4), 519 bytes | 519.00 KiB/s, done.</span>
<span class="c">#    Total 4 (delta 0), reused 0 (delta 0), pack-reused 0</span>
<span class="c">#    To https://gitlab.com/littlebird/2024-cicd-lite-w1.git</span>
<span class="c">#       cc87e97..70eaa32  main -&amp;gt; main</span>
<span class="c">#    branch 'main' set up to track 'origin/main'.</span>
  
<span class="c"># 호스트 PC에서 반복 접속 실행 : 서비스 중단 시간 체크!</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 http://127.0.0.1:4000 <span class="p">;</span> <span class="nb">date</span><span class="p">;</span> <span class="nb">sleep </span>1 <span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; Hello, Jenkins again!!! 😎 The time is 2024-10-01 15:52:25 +0000!!Sun Oct  1 00:52:25 KST 2024</span>
<span class="c">#    Hello, Jenkins again!!! 😎 The time is 2024-10-01 15:52:26 +0000!!Sun Oct  1 00:52:26 KST 2024</span>
<span class="c">#    Sun Oct  1 00:52:27 KST 2024</span>
<span class="c">#    Sun Oct  1 00:52:28 KST 2024</span>
<span class="c">#    Sun Oct  1 00:52:29 KST 2024</span>
<span class="c">#    Sun Oct  1 00:52:30 KST 2024</span>
<span class="c">#    Sun Oct  1 00:52:31 KST 2024</span>
<span class="c">#    Sun Oct  1 00:52:32 KST 2024</span>
<span class="c">#    Hello, Jenkins again!!! 😎 The time is 2024-10-01 15:52:33 +0000!!Sun Oct  1 00:52:33 KST 2024</span>
<span class="c">#    Hello, Jenkins again!!! 😎 The time is 2024-10-01 15:52:34 +0000!!Sun Oct  1 00:52:34 KST 2024</span>
<span class="c">#    Hello, Jenkins again!!! 😎 The time is 2024-10-01 15:52:35 +0000!!Sun Oct  1 00:52:35 KST 2024</span>
</code></pre></div>    </div>
  </li>
  <li>수정사항이 적용은 잘 되었지만 6~7초 가량 서비스가 중단되는 것을 확인할 수 있습니다. 이는 컨테이너 중지 및 재시작 시간이 소요되기 때문입니다.</li>
  <li>이러한 문제를 해결하기 위해 docker swarm이나 kubernetes 등의 컨테이너 오케스트레이션 툴을 사용하여 서비스 중단 없이 배포할 수 있습니다.
이 부분은 다음에 다루도록 하겠습니다.</li>
</ul>

<h2 id="마치며">마치며</h2>

<p>이번 시간에는 Jenkins, Gitlab 등을 사용하여 CI/CD 파이프라인을 구성하는 방법을 알아보았습니다.
다양하게 테스트해보고 싶었는데 생각보다 정리하는데 시간이 많이 소요되어 다양한 예제를 다루지 못한 점이 아쉽습니다.</p>

<p>Jenkins는 예전에 써보고 Teamcity나 Github action을 주로 사용해왔는데, 
다시 사용해보니 Jenkins도 Jenkinsfile과 Pipeline도 지원하고 예전에 비해서 훨씬 좋아진 것 같습니다.
이번 스터디를 통해 Jenkins를 재발견한것 같습니다.
준비해주신 Gasida 님께 감사드립니다.</p>]]></content><author><name></name></author><category term="kans" /><category term="cicd," /><category term="jenkins," /><category term="git," /><category term="linux" /><summary type="html"><![CDATA[Jenkins와 Git, Docker를 이용하여 CI/CD 파이프라인을 구축해보겠습니다.]]></summary></entry><entry><title type="html">[KANS 3기] AWS EKS : VPC CNI</title><link href="https://sweetlittlebird.github.io/posts/2024-11-03-KANS-Study-Week9/" rel="alternate" type="text/html" title="[KANS 3기] AWS EKS : VPC CNI" /><published>2024-11-03T00:00:18+09:00</published><updated>2024-11-03T00:00:18+09:00</updated><id>https://sweetlittlebird.github.io/posts/KANS%20Study%20-%20Week9</id><content type="html" xml:base="https://sweetlittlebird.github.io/posts/2024-11-03-KANS-Study-Week9/"><![CDATA[<h2 id="들어가며">들어가며</h2>

<p>안녕하세요. 이번 주에는 AWS EKS의 VPC CNI에 대해 알아보겠습니다.
KANS 3기 9주차 스터디를 시작하겠습니다.</p>

<hr />

<h2 id="aws-eks--vpc-cni">AWS EKS : VPC CNI</h2>

<h3 id="aws-vpc-cni-소개">AWS VPC CNI 소개</h3>

<ul>
  <li>AWS VPC CNI는 AWS에서 제공하는 CNI(Container Network Interface) 플러그인으로, AWS VPC(Virtual Private Cloud)의 네트워크를 사용하여 파드 간 통신을 지원하는 CNI 플러그인입니다.</li>
  <li>AWS VPC CNI의 특징
    <ul>
      <li>가장 큰 특징은 파드의 IP 네트워크 대역과 노드(인스턴스)의 IP 네트워크 대역이 같아서 직접 통신이 가능하다는 것입니다. - 
<a href="https://github.com/aws/amazon-vpc-cni-k8s">Github</a>, <a href="https://github.com/aws/amazon-vpc-cni-k8s/blob/master/docs/cni-proposal.md">Proposal</a></li>
      <li>또한 VPC와 통합되어 VPC Flow logs나 VPC 라우팅 정책, 보안 그룹(Security Group) 등을 활용할 수 있습니다.</li>
      <li>아래에서 설명할 Warm Pool을 통해 노드의 IP 주소를 재사용하여 파드의 생성과 삭제를 빠르게 할 수 있습니다.</li>
    </ul>
  </li>
  <li>Amazon VPC CNI는 크게 두가지 구성요소로  이루어집니다.
    <ul>
      <li>CNI 바이너리 : 파드간 통신을 활성화 하도록 파드 네트워크를 설정합니다. CNI 바이너리는 노드의 루트 파일 시스템에서 실행되며,
새로운 파드가 추가되거나, 기존 파드가 제거 될때 kubelet에 의해 호출됩니다.</li>
      <li>ipamd : IP 주소를 할당하고 관리하는 데몬으로 다음을 담당 합니다.
        <ul>
          <li>노드에서 ENI(<code class="language-plaintext highlighter-rouge">Elastic Network Interface</code> - EC2에서 사용하는 일종의 가상 랜카드) 관리</li>
          <li>사용가능한 IP 주소들의 웜풀 유지</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>인스턴스가 생성되면 EC2는 기본 서브넷과 연결된 기본 ENI를 생성하고 연결합니다.
호스트 네트워크 모드에서 실행되는 포드는 노드 기본 ENI에 할당된 기본 IP 주소를 
사용하며 호스트와 동일한 네트워크 네임스페이스를 공유합니다.</li>
</ul>

<blockquote>
  <p><strong>웜풀(warm pool)</strong>은
  노드가 프로비저닝 될 때 미리 할당된 IP 주소들의 집합입니다. 
  이것은 노드가 프로비저닝 될 때마다 새로운 IP 주소를 할당하는 것을 방지하고, 노드가 삭제되어도 IP 주소를 재사용할 수 있도록 하여
  조금 더 빠른 파드의 생성과 삭제를 가능하게 합니다.</p>
</blockquote>

<ul>
  <li>EC2 인스턴스별 최대 사용가능한 ENI 갯수는 인스턴스 타입에 따라 다르며, 
인스턴스 타입별 ENI 갯수는 <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html#network-cards">여기</a>에서 확인할 수 있습니다. 
이 ENI 갯수에 따라 할당 가능한 IP 주소의 갯수가 결정되며, 이에 따라 파드의 갯수가 제한될 수 있습니다.</li>
  <li>
    <p>각 ENI는 할당할 수 있는 IP수가 제한되어 있으며, 이 수는 EC2 인스턴스 타입에 따라 다릅니다.
인스턴스 타입별 ENI 당 IP 할당 수는 <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AvailableIpPerENI.html">여기</a>에서 확인할 수 있습니다.
ENI 당 할당할 수 있는 IP 를 slot 이라고 하며, 이 slot은 VPC CNI를 통해 파드에 할당됩니다.</p>

    <p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_1.png" alt="img.png" class="image-center" />
<em class="image-caption">파드에 IP를 할당하기 위한 절차</em></p>
  </li>
</ul>

<h4 id="calico-cni와의-차이점">Calico CNI와의 차이점</h4>

<ul>
  <li>노드와 파드의 네트워크 대역을 동일하게 설정함으로써 NAT(Network Address Translation)을 사용하지 않아도 되기 때문에
성능이 향상되고 지연이 최소화 됩니다.</li>
</ul>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_2.png" alt="img.png" class="image-center w-80" /></p>

<ul>
  <li>파드간 통신시 Calico CNI 등의 일반적인 CNI는 오버레이(VXLAN, IP-in-IP)를 사용하여 통신하지만,
AWS VPC CNI는 VPC의 네트워크를 사용하여 직접 통신합니다.</li>
</ul>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_3.png" alt="img_1.png" class="image-center w-90" /></p>

<h4 id="ipv4-prefix-위임-delegation">IPv4 Prefix 위임 (Delegation)</h4>

<ul>
  <li>앞서 알아 본것 처럼 각 파드는 노드의 ENI에 할당된 IP 주소를 사용하고, ENI당 IP (slot) 수와 ENI 갯수는
인스턴스별로 제한이 있고, 이 값이 큰 편이 아닙니다. 이를 해결하기위해 IPv4 Prefix 위임이 도입되었습니다.</li>
  <li>IPv4 Prefix는 ENI 별로 IP를 할당하지 않고, /28의 접두사 길이 CIDR 블록을 노드에 할당하여 파드에 할당할 IP 주소를 관리합니다.
이렇게 하면 각 슬랏당 16개의 IP주소를 할당할 수 있어서 다음과 같은 갯수의 최대 IP 또는 파드를 사용할 수 있습니다.</li>
  <li>최대 사용가능한 IP 수 계산 : 
<code class="language-plaintext highlighter-rouge">사용가능한 파드 IP 수 = (최대 네트워크 인터페이스(ENI) 갯수 * (네트워크 인터페이스 당 slot 수 - 1) * 16)</code>
    <ul>
      <li>단, 실제로는 인스턴스 유형별로 권장되는 최대 갯수로 선정됩니다.</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_4.png" alt="img.png" class="image-center" /></p>

<ul>
  <li>참고 링크 : <a href="https://trans.yonghochoi.com/translations/aws_vpc_cni_increase_pods_per_node_limits.ko">Amazon VPC CNI 플러그인으로 노드당 파드수 제한 늘리기</a></li>
</ul>

<hr />

<h3 id="실습-준비">실습 준비</h3>

<h4 id="구성-환경">구성 환경</h4>

<ul>
  <li>사전 준비물 : AWS 계정, SSH 키 페어, IAM 계정 생성 후 키</li>
  <li>전체 구성도 : VPC 1개(퍼블릭 서브넷 3개, 프라이빗 서브넷 3개), EKS 클러스터(Control Plane), 관리형 노드 그룹(EC2 3대), Add-on
<img src="/assets/2024/kans-3th/w9/20241102_kans_w9_28.png" alt="img.png" class="image-center" />
    <ul>
      <li>CloudFormation 스택 실행 시 <strong>파라미터</strong>를 기입하면, 해당 정보가 반영되어 배포됩니다.</li>
      <li>실습 환경을 위한 <strong>VPC</strong> 1개가 생성되고, <strong>퍼블릭</strong> 서브넷 3개와 <strong>프라이빗</strong> 서브넷 3개가 생성됩니다.</li>
      <li>CloudFormation 에 EC2의 <strong>UserData</strong> 부분(<strong>Script</strong> 실행)으로 Amazon EKS <strong>설치(with OIDC, Endpoint Public)</strong>를 진행합니다.</li>
      <li><strong>관리형 노드 그룹</strong>(워커 노드)는 AZ1~AZ3를 사용하여, 기본 <strong>3</strong>대로 구성됩니다</li>
      <li><strong>Add-on</strong> 같이 설치 됨 : 최신 버전 - kube-proxy, coredns, aws vpc cni - <a href="https://docs.aws.amazon.com/eks/latest/userguide/eks-add-ons.html">링크</a></li>
      <li><strong>노드</strong>에 <strong>EC2 IAM Profile</strong> 권한 추가 : external-dns-access, full-ecr-access, alb-ingress-access, awsLoadBalancerController</li>
    </ul>
  </li>
</ul>

<h4 id="배포-및-테스트">배포 및 테스트</h4>

<ul>
  <li>배포
    <ul>
      <li>aws cli를 설치하고, aws configure로 자격증명을 설정 후 아래의 명령을 실행합니다.</li>
      <li>다음의 파라미터가 있고, :point_right: 표시가 있는 부분은 필수로 설정해주어야 합니다.
        <ul>
          <li><strong>Deploy EC2</strong>
            <ol>
              <li>:point_right: <strong>KeyName</strong> : 작업용 bastion ec2에 SSH 접속을 위한 <strong>SSH 키페어</strong> 선택 <em>← 미리 SSH 키 생성 해두자!</em></li>
              <li>:point_right: <strong>MyIamUserAccessKeyID</strong> : <strong>관리자</strong> 수준의 권한을 가진 IAM User의 액세스 키ID 입력</li>
              <li>:point_right: <strong>MyIamUserSecretAccessKey</strong> : <strong>관리자</strong> 수준의 권한을 가진 IAM User의 <strong>시크릿 키ID</strong> 입력 <strong>← 노출되지 않게 보안 주의</strong></li>
              <li>:point_right: <strong>SgIngressSshCidr</strong> : 작업용 bastion ec2에 <strong>SSH 접속 가능한 IP</strong> 입력 (<strong>집 공인IP</strong>/32 입력), 보안그룹 인바운드 규칙에 반영됨</li>
              <li>MyInstanceType: 작업용 bastion EC2 인스턴스의 타입 (기본 <strong>t3.medium</strong>) ⇒ 변경 가능</li>
              <li>LatestAmiId : 작업용 bastion EC2에 사용할 AMI는 아마존리눅스2 최신 버전 사용</li>
            </ol>
          </li>
          <li><strong>EKS Config</strong>
            <ol>
              <li><strong>ClusterBaseName</strong> : EKS <strong>클러스터 이름</strong>이며, <strong>myeks</strong> 기본값 사용을 권장 → 이유: 실습 리소스 태그명과 실습 커멘드에서 사용</li>
              <li><strong>KubernetesVersion</strong> : EKS 호환, 쿠버네티스 버전 (기본 v1.30, 실습은 <strong>1.30</strong> 버전 사용)</li>
              <li><strong>WorkerNodeInstanceType</strong>: 워커 노드 EC2 인스턴스의 타입 (기본 <strong>t3.medium</strong>) ⇒ 변경 가능</li>
              <li><strong>WorkerNodeCount</strong> : 워커노드의 갯수를 입력 (기본 3대) ⇒ 변경 가능</li>
              <li><strong>WorkerNodeVolumesize</strong> : 워커노드의 EBS 볼륨 크기 (기본 80GiB) ⇒ 변경 가능</li>
            </ol>
          </li>
          <li><strong>Region AZ</strong> : 리전과 가용영역을 지정, 기본값 그대로 사용</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># YAML 파일 다운로드</span>
<span class="nv">$ </span>curl <span class="nt">-O</span> https://s3.ap-northeast-2.amazonaws.com/cloudformation.cloudneta.net/kans/eks-oneclick.yaml

<span class="c"># CloudFormation 스택 배포</span>
<span class="c"># aws cloudformation deploy --template-file eks-oneclick.yaml --stack-name myeks --parameter-overrides KeyName=&lt;My SSH Keyname&gt; SgIngressSshCidr=&lt;My Home Public IP Address&gt;/32 MyIamUserAccessKeyID=&lt;IAM User의 액세스키&gt; MyIamUserSecretAccessKey=&lt;IAM User의 시크릿 키&gt; ClusterBaseName='&lt;eks 이름&gt;' --region ap-northeast-2</span>
<span class="c"># 예시) aws cloudformation deploy --template-file eks-oneclick.yaml --stack-name myeks --parameter-overrides KeyName=aws-ec2 SgIngressSshCidr=$(curl -s ipinfo.io/ip)/32  MyIamUserAccessKeyID=AKIA5... MyIamUserSecretAccessKey='CVNa2...' ClusterBaseName=myeks --region ap-northeast-2</span>

<span class="c">## Tip. 워커노드 인스턴스 타입 변경 : WorkerNodeInstanceType=t3.xlarge</span>
<span class="c"># 예시) aws cloudformation deploy --template-file eks-oneclick.yaml --stack-name myeks --parameter-overrides KeyName=aws-ec2 SgIngressSshCidr=$(curl -s ipinfo.io/ip)/32  MyIamUserAccessKeyID=AKIA5... MyIamUserSecretAccessKey='CVNa2...' ClusterBaseName=myeks --region ap-northeast-2 WorkerNodeInstanceType=t3.xlarge </span>

<span class="nv">$ </span>aws cloudformation deploy <span class="nt">--template-file</span> eks-oneclick.yaml <span class="nt">--stack-name</span> myeks <span class="se">\</span>
  <span class="nt">--parameter-overrides</span> <span class="nv">KeyName</span><span class="o">=</span>aws-ec2 <span class="se">\</span>
  <span class="nv">SgIngressSshCidr</span><span class="o">=</span><span class="si">$(</span>curl <span class="nt">-s</span> ipinfo.io/ip<span class="si">)</span>/32 <span class="se">\</span>
  <span class="nv">MyIamUserAccessKeyID</span><span class="o">=</span>AKIA5... <span class="se">\</span>
  <span class="nv">MyIamUserSecretAccessKey</span><span class="o">=</span><span class="s1">'CVNa2...'</span> <span class="se">\ </span> 
  <span class="nv">ClusterBaseName</span><span class="o">=</span>myeks <span class="se">\ </span>
  <span class="nt">--region</span> ap-northeast-2
<span class="c"># =&gt; Waiting for changeset to be created..</span>
<span class="c">#    Waiting for stack create/update to complete</span>
<span class="c">#    Successfully created/updated stack - myeks</span>

<span class="c"># CloudFormation 스택 배포 완료 후 작업용 EC2 IP 출력</span>
<span class="nv">$ </span>aws cloudformation describe-stacks <span class="nt">--stack-name</span> myeks <span class="nt">--query</span> <span class="s1">'Stacks[*].Outputs[0].OutputValue'</span> <span class="nt">--output</span> text
<span class="c"># =&gt; 3.35.140.75</span>

<span class="c"># 작업용 EC2 SSH 접속</span>
<span class="nv">$ </span>ssh <span class="nt">-i</span> ~/.ssh/aws-ec2-key.cer ec2-user@<span class="si">$(</span>aws cloudformation describe-stacks <span class="nt">--stack-name</span> myeks <span class="nt">--query</span> <span class="s1">'Stacks[*].Outputs[0].OutputValue'</span> <span class="nt">--output</span> text<span class="si">)</span>
<span class="c"># =&gt;    ,     #_</span>
<span class="c">#       ~\_  ####_        Amazon Linux 2</span>
<span class="c">#      ~~  \_#####\</span>
<span class="c">#      ~~     \###|       AL2 End of Life is 2025-06-30.</span>
<span class="c">#      ~~       \#/ ___</span>
<span class="c">#       ~~       V~' '-&amp;gt;</span>
<span class="c">#        ~~~         /    A newer version of Amazon Linux is available!</span>
<span class="c">#          ~~._.   _/</span>
<span class="c">#             _/ _/       Amazon Linux 2023, GA and supported until 2028-03-15.</span>
<span class="c">#           _/m/'           https://aws.amazon.com/linux/amazon-linux-2023/</span>
<span class="c">#    </span>
<span class="c">#    10 package(s) needed for security, out of 13 available</span>
<span class="c">#    Run &amp;quot;sudo yum update&amp;quot; to apply all updates.</span>
<span class="c">#    [root@myeks-bastion ~]#</span>
</code></pre></div></div>

<ul>
  <li>작업용 EC2에 SSH 키 파일 사용하여 SSH 접속 후 확인해보겠습니다.</li>
  <li>쿠버네티스 정상 설치 확인은 스택 생성 시작 후 20분 후 접속하는 것이 좋습니다.</li>
  <li>접속 후 기본 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># SSH 접속</span>
<span class="nv">$ </span>ssh <span class="nt">-i</span> ~/.ssh/aws-ec2-key.cer ec2-user@<span class="si">$(</span>aws cloudformation describe-stacks <span class="nt">--stack-name</span> myeks <span class="nt">--query</span> <span class="s1">'Stacks[*].Outputs[0].OutputValue'</span> <span class="nt">--output</span> text<span class="si">)</span>

<span class="c"># cloud-init 실행 과정 로그 확인</span>
<span class="nv">$ </span><span class="nb">tail</span> <span class="nt">-f</span> /var/log/cloud-init-output.log
<span class="c"># =&gt;  ...</span>
<span class="c">#     69  dnsmasq                  available    [ =stable ]</span>
<span class="c">#     70  unbound1.17              available    [ =stable ]</span>
<span class="c">#     72  collectd-python3         available    [ =stable ]</span>
<span class="c">#    † Note on end-of-support. Use 'info' subcommand.</span>
<span class="c">#    Created symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /usr/lib/systemd/system/docker.service.</span>
<span class="c">#    cloudinit End!</span>
<span class="c">#    Cloud-init v. 19.3-46.amzn2.0.2 finished at Sat, 01 Nov 2024 07:27:24 +0000. Datasource DataSourceEc2.  Up 84.79 seconds</span>

<span class="c"># cloud-init 정상 완료 후 eksctl 실행 과정 로그 확인</span>
<span class="nv">$ </span><span class="nb">tail</span> <span class="nt">-f</span> /root/create-eks.log
<span class="c"># =&gt; ...</span>
<span class="c">#    2024-10-01 16:26:46 [ℹ]  deploying stack &amp;quot;eksctl-myeks-cluster&amp;quot;</span>
<span class="c">#    2024-10-01 16:27:16 [ℹ]  waiting for CloudFormation stack &amp;quot;eksctl-myeks-cluster&amp;quot;</span>
<span class="c">#    ...</span>
<span class="c">#    2024-10-01 16:40:31 [✔]  EKS cluster &amp;quot;myeks&amp;quot; in &amp;quot;ap-northeast-2&amp;quot; region is ready</span>

<span class="c"># default 네임스페이스 적용</span>
<span class="nv">$ </span>kubectl ns default
<span class="c"># =&gt; Context &amp;quot;anonym@myeks.ap-northeast-2.eksctl.io&amp;quot; modified.</span>
<span class="c">#    Active namespace is &amp;quot;default&amp;quot;.</span>

<span class="c"># 설치 확인</span>
<span class="nv">$ </span>kubectl cluster-info
<span class="c"># =&gt; Kubernetes control plane is running at https://CF0FD5E1EEB937DD6FF881B7EBADDFD4.yl4.ap-northeast-2.eks.amazonaws.com</span>
<span class="c">#    CoreDNS is running at https://CF0FD5E1EEB937DD6FF881B7EBADDFD4.yl4.ap-northeast-2.eks.amazonaws.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</span>
<span class="nv">$ </span>eksctl get cluster
<span class="c"># =&gt; NAME REGION    EKSCTL CREATED</span>
<span class="c">#    myeks  ap-northeast-2  True</span>
<span class="nv">$ </span>eksctl get nodegroup <span class="nt">--cluster</span> <span class="nv">$CLUSTER_NAME</span>
<span class="c"># =&gt; CLUSTER  NODEGROUP STATUS  CREATED               MIN SIZE  MAX SIZE  DESIRED CAPACITY  INSTANCE TYPE  IMAGE ID    ASG NAME                                      TYPE</span>
<span class="c">#    myeks    ng1       ACTIVE  2024-10-01T07:37:58Z  3         3         3                 t3.medium      AL2_x86_64  eks-ng1-4ec975e7-9584-1403-37c4-fc55cc2ec860  managed</span>

<span class="c"># 환경변수 정보 확인</span>
<span class="nv">$ </span><span class="nb">export</span> | egrep <span class="s1">'ACCOUNT|AWS_|CLUSTER|KUBERNETES|VPC|Subnet'</span>
<span class="nv">$ </span><span class="nb">export</span> | egrep <span class="s1">'ACCOUNT|AWS_|CLUSTER|KUBERNETES|VPC|Subnet'</span> | egrep <span class="nt">-v</span> <span class="s1">'SECRET|KEY'</span>
<span class="c"># =&gt; declare -x ACCOUNT_ID=&amp;quot;123456789012&amp;quot;</span>
<span class="c">#    declare -x AWS_DEFAULT_REGION=&amp;quot;ap-northeast-2&amp;quot;</span>
<span class="c">#    declare -x AWS_PAGER=&amp;quot;&amp;quot;</span>
<span class="c">#    declare -x AWS_REGION=&amp;quot;ap-northeast-2&amp;quot;</span>
<span class="c">#    declare -x CLUSTER_NAME=&amp;quot;myeks&amp;quot;</span>
<span class="c">#    declare -x KUBERNETES_VERSION=&amp;quot;1.30&amp;quot;</span>
<span class="c">#    declare -x PrivateSubnet1=&amp;quot;subnet-02550e25cd3a9d814&amp;quot;</span>
<span class="c">#    declare -x PrivateSubnet2=&amp;quot;subnet-0c2adfcc3d586e58d&amp;quot;</span>
<span class="c">#    declare -x PrivateSubnet3=&amp;quot;subnet-04dd8e21b159de4cb&amp;quot;</span>
<span class="c">#    declare -x PubSubnet1=&amp;quot;subnet-0a06ed52d587bd707&amp;quot;</span>
<span class="c">#    declare -x PubSubnet2=&amp;quot;subnet-00b4dacf7eef35d33&amp;quot;</span>
<span class="c">#    declare -x PubSubnet3=&amp;quot;subnet-03c911c48452b41b2&amp;quot;</span>
<span class="c">#    declare -x VPCID=&amp;quot;vpc-0837921f515624150&amp;quot;</span>

<span class="c"># 인증 정보 확인</span>
<span class="nv">$ </span><span class="nb">cat</span> /root/.kube/config
<span class="nv">$ </span>kubectl config view
<span class="nv">$ </span>kubectl ctx
<span class="c"># =&gt; anonym@myeks.ap-northeast-2.eksctl.io</span>

<span class="c"># 노드 정보 확인</span>
<span class="nv">$ </span>kubectl get node <span class="nt">--label-columns</span><span class="o">=</span>node.kubernetes.io/instance-type,eks.amazonaws.com/capacityType,topology.kubernetes.io/zone
<span class="c"># =&gt; NAME                                               STATUS   ROLES    AGE     VERSION               INSTANCE-TYPE   CAPACITYTYPE   ZONE</span>
<span class="c">#    ip-192-168-1-186.ap-northeast-2.compute.internal   Ready    &amp;lt;none&amp;gt;   7m26s   v1.30.4-eks-a737599   t3.medium       ON_DEMAND      ap-northeast-2a</span>
<span class="c">#    ip-192-168-2-92.ap-northeast-2.compute.internal    Ready    &amp;lt;none&amp;gt;   7m22s   v1.30.4-eks-a737599   t3.medium       ON_DEMAND      ap-northeast-2b</span>
<span class="c">#    ip-192-168-3-235.ap-northeast-2.compute.internal   Ready    &amp;lt;none&amp;gt;   7m22s   v1.30.4-eks-a737599   t3.medium       ON_DEMAND      ap-northeast-2c</span>
<span class="nv">$ </span>eksctl get iamidentitymapping <span class="nt">--cluster</span> myeks
<span class="c"># =&gt; ARN                      USERNAME        GROUPS          ACCOUNT</span>
<span class="c">#    arn:aws:iam::123456789012:role/eksctl-myeks-nodegroup-ng1-NodeInstanceRole-kPdCWLD1sAsU  system:node: system:bootstrappers,system:nodes</span>

<span class="c"># krew 플러그인 확인</span>
<span class="nv">$ </span>kubectl krew list
<span class="c"># =&gt; PLUGIN   VERSION</span>
<span class="c">#    ctx      v0.9.5</span>
<span class="c">#    get-all  v1.3.8</span>
<span class="c">#    krew     v0.4.4</span>
<span class="c">#    neat     v2.0.4</span>
<span class="c">#    ns       v0.9.5</span>
<span class="c">#    stern    v1.31.0</span>

<span class="c"># 모든 네임스페이스에서 모든 리소스 확인</span>
<span class="nv">$ </span>kubectl get-all
</code></pre></div></div>

<ul>
  <li>노드 접속 확인 및 SSH 접속</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 노드 IP 확인 및 PrivateIP 변수 지정</span>
<span class="nv">$ </span>aws ec2 describe-instances <span class="nt">--query</span> <span class="s2">"Reservations[*].Instances[*].{PublicIPAdd:PublicIpAddress,PrivateIPAdd:PrivateIpAddress,InstanceName:Tags[?Key=='Name']|[0].Value,Status:State.Name}"</span> <span class="nt">--filters</span> <span class="nv">Name</span><span class="o">=</span>instance-state-name,Values<span class="o">=</span>running <span class="nt">--output</span> table
<span class="c"># =&gt; ------------------------------------------------------------------</span>
<span class="c">#    |                        DescribeInstances                       |</span>
<span class="c">#    +----------------+-----------------+------------------+----------+</span>
<span class="c">#    |  InstanceName  |  PrivateIPAdd   |   PublicIPAdd    | Status   |</span>
<span class="c">#    +----------------+-----------------+------------------+----------+</span>
<span class="c">#    |  myeks-ng1-Node|  192.168.2.92   |  43.203.143.233  |  running |</span>
<span class="c">#    |  myeks-ng1-Node|  192.168.3.235  |  15.164.95.12    |  running |</span>
<span class="c">#    |  myeks-bastion |  192.168.1.100  |  3.35.140.75     |  running |</span>
<span class="c">#    |  myeks-ng1-Node|  192.168.1.186  |  3.38.183.82     |  running |</span>
<span class="c">#    +----------------+-----------------+------------------+----------+</span>
<span class="nv">$ N1</span><span class="o">=</span><span class="si">$(</span>kubectl get node <span class="nt">--label-columns</span><span class="o">=</span>topology.kubernetes.io/zone <span class="nt">--selector</span><span class="o">=</span>topology.kubernetes.io/zone<span class="o">=</span>ap-northeast-2a <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.items[0].status.addresses[0].address<span class="o">}</span><span class="si">)</span>
<span class="nv">$ N2</span><span class="o">=</span><span class="si">$(</span>kubectl get node <span class="nt">--label-columns</span><span class="o">=</span>topology.kubernetes.io/zone <span class="nt">--selector</span><span class="o">=</span>topology.kubernetes.io/zone<span class="o">=</span>ap-northeast-2b <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.items[0].status.addresses[0].address<span class="o">}</span><span class="si">)</span>
<span class="nv">$ N3</span><span class="o">=</span><span class="si">$(</span>kubectl get node <span class="nt">--label-columns</span><span class="o">=</span>topology.kubernetes.io/zone <span class="nt">--selector</span><span class="o">=</span>topology.kubernetes.io/zone<span class="o">=</span>ap-northeast-2c <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.items[0].status.addresses[0].address<span class="o">}</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"export N1=</span><span class="nv">$N1</span><span class="s2">"</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"export N2=</span><span class="nv">$N2</span><span class="s2">"</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"export N3=</span><span class="nv">$N3</span><span class="s2">"</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$N1</span>, <span class="nv">$N2</span>, <span class="nv">$N3</span>
<span class="c"># =&gt; 192.168.1.186, 192.168.2.92, 192.168.3.235</span>

<span class="c"># 보안그룹 ID와 보안그룹 이름(Name아님을 주의!) 확인</span>
<span class="nv">$ </span>aws ec2 describe-security-groups <span class="nt">--query</span> <span class="s1">'SecurityGroups[*].[GroupId, GroupName]'</span> <span class="nt">--output</span> text
<span class="c"># =&gt; sg-07b8900660cb85dff default</span>
<span class="c">#    sg-0ece66fedd1fb4abe myeks-EKSEC2SG-1GNaTdbIbBNG</span>
<span class="c">#    sg-07663468a536ba88b eksctl-myeks-cluster-ControlPlaneSecurityGroup-S7dWa32uw1S7</span>
<span class="c">#    sg-0edc706b941f0aef7 eksctl-myeks-cluster-ClusterSharedNodeSecurityGroup-sO3DEJP4xewT</span>
<span class="c">#    sg-02c614a038ec1f7e7 eks-cluster-sg-myeks-104368993</span>
<span class="c">#    sg-036e220bf3d8aaf20 eksctl-myeks-nodegroup-ng1-remoteAccess</span>
<span class="c">#    sg-035e2b98b5ac89231 default</span>

<span class="c"># 노드 보안그룹 ID 확인</span>
<span class="nv">$ </span>aws ec2 describe-security-groups <span class="nt">--filters</span> <span class="nv">Name</span><span class="o">=</span>group-name,Values<span class="o">=</span><span class="k">*</span>ng1<span class="k">*</span> <span class="nt">--query</span> <span class="s2">"SecurityGroups[*].[GroupId]"</span> <span class="nt">--output</span> text
<span class="c"># =&gt; sg-036e220bf3d8aaf20</span>
<span class="nv">$ NGSGID</span><span class="o">=</span><span class="si">$(</span>aws ec2 describe-security-groups <span class="nt">--filters</span> <span class="nv">Name</span><span class="o">=</span>group-name,Values<span class="o">=</span><span class="k">*</span>ng1<span class="k">*</span> <span class="nt">--query</span> <span class="s2">"SecurityGroups[*].[GroupId]"</span> <span class="nt">--output</span> text<span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$NGSGID</span>
<span class="c"># =&gt; sg-036e220bf3d8aaf20</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"export NGSGID=</span><span class="nv">$NGSGID</span><span class="s2">"</span> <span class="o">&gt;&gt;</span> /etc/profile

<span class="c"># 노드 보안그룹에 eksctl-host 에서 노드(파드)에 접속 가능하게 룰(Rule) 추가 설정</span>
<span class="nv">$ </span>aws ec2 authorize-security-group-ingress <span class="nt">--group-id</span> <span class="nv">$NGSGID</span> <span class="nt">--protocol</span> <span class="s1">'-1'</span> <span class="nt">--cidr</span> 192.168.1.100/32

<span class="c"># eksctl-host 에서 노드의IP나 coredns 파드IP로 ping 테스트</span>
<span class="nv">$ </span>ping <span class="nt">-c</span> 1 <span class="nv">$N1</span>
<span class="c"># =&gt; PING 192.168.1.186 (192.168.1.186) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 192.168.1.186: icmp_seq=1 ttl=255 time=0.492 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 192.168.1.186 ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 0.492/0.492/0.492/0.000 ms</span>
<span class="nv">$ </span>ping <span class="nt">-c</span> 1 <span class="nv">$N2</span>
<span class="nv">$ </span>ping <span class="nt">-c</span> 1 <span class="nv">$N3</span>

<span class="c"># 워커 노드 SSH 접속 : '-i ~/.ssh/id_rsa' 생략 가능</span>
<span class="nv">$ </span><span class="k">for </span>node <span class="k">in</span> <span class="nv">$N1</span> <span class="nv">$N2</span> <span class="nv">$N3</span><span class="p">;</span> <span class="k">do </span>ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no ec2-user@<span class="nv">$node</span> <span class="nb">hostname</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span>ssh ec2-user@<span class="nv">$N1</span>
<span class="nv">$ </span><span class="nb">exit</span>
<span class="nv">$ </span>ssh ec2-user@<span class="nv">$N2</span>
<span class="nv">$ </span><span class="nb">exit</span>
<span class="nv">$ </span>ssh ec2-user@<span class="nv">$N3</span>
<span class="nv">$ </span><span class="nb">exit</span>
</code></pre></div></div>

<ul>
  <li>Add-on 정보확인 : 최신 버전 - kube-proxy, coredns, aws vpc cni - 링크 mgmt</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 모든 파드의 컨테이너 이미지 정보 확인</span>
<span class="nv">$ </span>kubectl get pods <span class="nt">--all-namespaces</span> <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.items[*].spec.containers[*].image}"</span> | <span class="nb">tr</span> <span class="nt">-s</span> <span class="s1">'[[:space:]]'</span> <span class="s1">'\n'</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span>
<span class="c"># =&gt;       3 602401143452.dkr.ecr.ap-northeast-2.amazonaws.com/amazon/aws-network-policy-agent:v1.1.4-eksbuild.1</span>
<span class="c">#          3 602401143452.dkr.ecr.ap-northeast-2.amazonaws.com/amazon-k8s-cni:v1.18.6-eksbuild.1</span>
<span class="c">#          2 602401143452.dkr.ecr.ap-northeast-2.amazonaws.com/eks/coredns:v1.11.3-eksbuild.2</span>
<span class="c">#          3 602401143452.dkr.ecr.ap-northeast-2.amazonaws.com/eks/kube-proxy:v1.30.5-minimal-eksbuild.2</span>
<span class="c"># 위 버전은 Add-on 으로 최신 버전 설치</span>
<span class="nv">$ </span>kubectl get pods <span class="nt">-A</span>
<span class="nv">$ </span>kubectl get pods <span class="nt">--all-namespaces</span> <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.items[*].spec.containers[*].image}"</span> | <span class="nb">tr</span> <span class="nt">-s</span> <span class="s1">'[[:space:]]'</span> <span class="s1">'\n'</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span>
<span class="c"># =&gt;       3 602401143452.dkr.ecr.ap-northeast-2.amazonaws.com/amazon/aws-network-policy-agent:v1.1.4-eksbuild.1</span>
<span class="c">#          3 602401143452.dkr.ecr.ap-northeast-2.amazonaws.com/amazon-k8s-cni:v1.18.6-eksbuild.1</span>
<span class="c">#          2 602401143452.dkr.ecr.ap-northeast-2.amazonaws.com/eks/coredns:v1.11.3-eksbuild.2</span>
<span class="c">#          3 602401143452.dkr.ecr.ap-northeast-2.amazonaws.com/eks/kube-proxy:v1.30.5-minimal-eksbuild.2</span>

<span class="c"># eksctl 설치/업데이트 addon 확인</span>
<span class="nv">$ </span>eksctl get addon <span class="nt">--cluster</span> <span class="nv">$CLUSTER_NAME</span>
<span class="c"># =&gt; NAME        VERSION             STATUS  ISSUES      IAMROLE                                                                       UPDATE                AVAILABLE  CONFIGURATION  VALUES  POD      IDENTITY  ASSOCIATION  ROLES</span>
<span class="c">#    coredns     v1.11.3-eksbuild.2  ACTIVE  0</span>
<span class="c">#    kube-proxy  v1.30.5-eksbuild.2  ACTIVE  0</span>
<span class="c">#    vpc-cni     v1.18.6-eksbuild.1  ACTIVE  0           arn:aws:iam::123456789012:role/eksctl-myeks-addon-vpc-cni-Role1-QUy8qUBqFjcx  enableNetworkPolicy:  &amp;quot;true&amp;quot;</span>

<span class="c"># (참고) eks 설치 yaml 중 addon 내용</span>
<span class="nv">$ </span><span class="nb">tail</span> <span class="nt">-n11</span> myeks.yaml
<span class="c"># =&gt; addons:</span>
<span class="c">#      - name: vpc-cni # no version is specified so it deploys the default version</span>
<span class="c">#        version: latest # auto discovers the latest available</span>
<span class="c">#        attachPolicyARNs:</span>
<span class="c">#          - arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy</span>
<span class="c">#        configurationValues: |-</span>
<span class="c">#          enableNetworkPolicy: &amp;quot;true&amp;quot;</span>
<span class="c">#      - name: kube-proxy</span>
<span class="c">#        version: latest</span>
<span class="c">#      - name: coredns</span>
<span class="c">#        version: latest</span>
</code></pre></div></div>

<hr />

<h3 id="노드에서-기본-네트워크-정보-확인">노드에서 기본 네트워크 정보 확인</h3>

<h4 id="워커-노드-기본-네트워크-구성">워커 노드 기본 네트워크 구성</h4>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_5.png" alt="img.png" class="image-center w-60" /></p>

<ul>
  <li>네트워크 네임스페이스는 호스트(Root)와 파드별(Per Pod)로 구분됩니다.</li>
  <li>특정한 파드 (kube-proxy, aws-node)는 호스트의 IP를 그대로 사용합니다. =&gt; 파드의 Host Network 옵션 - <a href="https://xn--vj5b11biyw.kr/306">참고</a></li>
  <li>t3.medium 의 경우 ENI 마다 최대 6개의 IP를 가질 수 있습니다. (ENI 당 5개의 보조 IP)</li>
  <li>ENI0, ENI1 으로 2개의 ENI는 자신의 IP 이외에 추가적으로 5개의 보조 프라이빗 IP를 가질 수 있습니다.</li>
  <li>coredns 파드는 veth으로 호스트에는 eniY@ifN 인터페이스와 파드에 eth0과 연결되어 있습니다.</li>
</ul>

<h4 id="실습-보조-ipv4-주소를-파드가-사용하는지-확인">[실습] 보조 IPv4 주소를 파드가 사용하는지 확인</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># coredns 파드 IP 정보 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>kube-dns <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                       READY   STATUS    RESTARTS   AGE   IP             NODE                                               NOMINATED NODE   READINESS GATES</span>
<span class="c">#    coredns-699d8c5988-bvxtz   1/1     Running   0          18m   192.168.1.30   ip-192-168-1-186.ap-northeast-2.compute.internal   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    coredns-699d8c5988-vt68k   1/1     Running   0          18m   192.168.3.82   ip-192-168-3-235.ap-northeast-2.compute.internal   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>

<span class="c"># 노드의 라우팅 정보 확인 &gt;&gt; EC2 네트워크 정보의 '보조 프라이빗 IPv4 주소'와 비교해보자</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="nv">$N1</span> <span class="nv">$N2</span> <span class="nv">$N3</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> ssh ec2-user@<span class="nv">$i</span> <span class="nb">sudo </span>ip <span class="nt">-c</span> route<span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; node 192.168.1.186 &amp;lt;&amp;lt;</span>
<span class="c">#    default via 192.168.1.1 dev eth0</span>
<span class="c">#    169.254.169.254 dev eth0</span>
<span class="c">#    192.168.1.0/24 dev eth0 proto kernel scope link src 192.168.1.186</span>
<span class="c">#    192.168.1.30 dev eni319ad74733c scope link</span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; node 192.168.2.92 &amp;lt;&amp;lt;</span>
<span class="c">#    default via 192.168.2.1 dev eth0</span>
<span class="c">#    169.254.169.254 dev eth0</span>
<span class="c">#    192.168.2.0/24 dev eth0 proto kernel scope link src 192.168.2.92</span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; node 192.168.3.235 &amp;lt;&amp;lt;</span>
<span class="c">#    default via 192.168.3.1 dev eth0</span>
<span class="c">#    169.254.169.254 dev eth0</span>
<span class="c">#    192.168.3.0/24 dev eth0 proto kernel scope link src 192.168.3.235</span>
<span class="c">#    192.168.3.82 dev enid438418b082 scope link</span>

<span class="c"># &lt;span style="color: green;"&gt;👉 노드의 IP와 파드의 IP가 같은 대역임을 확인 할 수 있습니다.&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;    예를 들어서 노드 IP가 192.168.1.186인 경우 파드는 192.168.1.30으로&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;    동일한 IP 대역으로, 보조 IPv4가 사용됨을 확인 할 수 있습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<h4 id="실습-테스트용-파드-생성---nicolakanetshoot">[실습] 테스트용 파드 생성 - <a href="https://github.com/nicolaka/netshoot">nicolaka/netshoot</a></h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># [터미널1~3] 노드 모니터링</span>
<span class="nv">$ </span>ssh ec2-user@<span class="nv">$N1</span>
<span class="c"># =&gt; [ec2-user@ip-192-168-1-186 ~]$</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> <span class="s2">"ip link | egrep 'eth|eni' ;echo;echo "</span><span class="o">[</span>ROUTE TABLE]<span class="s2">"; route -n | grep eni"</span>
<span class="c"># =&gt; 2: eth0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc</span>
<span class="c">#     mq state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 02:35:26:fe:f6:2f brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    3: eni319ad74733c@if3: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt;</span>
<span class="c">#    mtu 9001 qdisc noqueue state UP mode DEFAULT group defaul</span>
<span class="c">#    t</span>
<span class="c">#        link/ether 16:69:60:63:cf:f7 brd ff:ff:ff:ff:ff:ff li</span>
<span class="c">#    nk-netns cni-a953612e-ef39-78ca-660c-2a1ecde16b39</span>
<span class="c">#    4: eth1: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc</span>
<span class="c">#     mq state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 02:86:42:43:71:d1 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    </span>
<span class="c">#    [ROUTE TABLE]</span>
<span class="c">#    192.168.1.30    0.0.0.0         255.255.255.255 UH    0</span>
<span class="c">#        0        0 eni319ad74733c</span>

<span class="nv">$ </span>ssh ec2-user@<span class="nv">$N2</span>
<span class="c"># =&gt; [ec2-user@ip-192-168-2-92 ~]$</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> <span class="s2">"ip link | egrep 'eth|eni' ;echo;echo "</span><span class="o">[</span>ROUTE TABLE]<span class="s2">"; route -n | grep eni"</span>
<span class="c"># =&gt; 2: eth0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc</span>
<span class="c">#     mq state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 06:bc:36:ed:7c:d3 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    </span>
<span class="c">#    [ROUTE TABLE]</span>

<span class="nv">$ </span>ssh ec2-user@<span class="nv">$N3</span>
<span class="c"># =&gt; [ec2-user@ip-192-168-3-235 ~]$</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> <span class="s2">"ip link | egrep 'eth|eni' ;echo;echo "</span><span class="o">[</span>ROUTE TABLE]<span class="s2">"; route -n | grep eni"</span>
<span class="c"># =&gt; 2: eth0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc</span>
<span class="c">#     mq state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 0a:3e:a1:00:00:05 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    3: enid438418b082@if3: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt;</span>
<span class="c">#    mtu 9001 qdisc noqueue state UP mode DEFAULT group defaul</span>
<span class="c">#    t</span>
<span class="c">#        link/ether 02:50:3a:92:0e:1b brd ff:ff:ff:ff:ff:ff li</span>
<span class="c">#    nk-netns cni-23569158-d846-4981-4105-ec08005e9b95</span>
<span class="c">#    4: eth1: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc</span>
<span class="c">#     mq state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 0a:e8:ac:41:8c:ab brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    </span>
<span class="c">#    [ROUTE TABLE]</span>
<span class="c">#    192.168.3.82    0.0.0.0         255.255.255.255 UH    0</span>
<span class="c">#        0        0 enid438418b082</span>

<span class="c"># 테스트용 파드 netshoot-pod 생성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: netshoot-pod
spec:
  replicas: 3
  selector:
    matchLabels:
      app: netshoot-pod
  template:
    metadata:
      labels:
        app: netshoot-pod
    spec:
      containers:
      - name: netshoot-pod
        image: nicolaka/netshoot
        command: ["tail"]
        args: ["-f", "/dev/null"]
      terminationGracePeriodSeconds: 0
</span><span class="no">EOF
</span><span class="c"># =&gt; deployment.apps/netshoot-pod created</span>

<span class="c"># 파드 이름 변수 지정</span>
<span class="nv">$ PODNAME1</span><span class="o">=</span><span class="si">$(</span>kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>netshoot-pod <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.items[0].metadata.name<span class="o">}</span><span class="si">)</span>
<span class="nv">$ PODNAME2</span><span class="o">=</span><span class="si">$(</span>kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>netshoot-pod <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.items[1].metadata.name<span class="o">}</span><span class="si">)</span>
<span class="nv">$ PODNAME3</span><span class="o">=</span><span class="si">$(</span>kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>netshoot-pod <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.items[2].metadata.name<span class="o">}</span><span class="si">)</span>

<span class="c"># 파드 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-o</span> wide
<span class="c"># =&gt; NAME                            READY   STATUS    RESTARTS   AGE   IP              NODE                                               NOMINATED NODE   READINESS GATES</span>
<span class="c">#    netshoot-pod-74b7555dc7-6qsvf   1/1     Running   0          29s   192.168.1.112   ip-192-168-1-186.ap-northeast-2.compute.internal   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    netshoot-pod-74b7555dc7-x6lxb   1/1     Running   0          29s   192.168.2.172   ip-192-168-2-92.ap-northeast-2.compute.internal    &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    netshoot-pod-74b7555dc7-x7r96   1/1     Running   0          29s   192.168.3.246   ip-192-168-3-235.ap-northeast-2.compute.internal   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-o</span><span class="o">=</span>custom-columns<span class="o">=</span>NAME:.metadata.name,IP:.status.podIP
<span class="c"># =&gt; NAME                            IP</span>
<span class="c">#    netshoot-pod-74b7555dc7-6qsvf   192.168.1.112</span>
<span class="c">#    netshoot-pod-74b7555dc7-x6lxb   192.168.2.172</span>
<span class="c">#    netshoot-pod-74b7555dc7-x7r96   192.168.3.246</span>

<span class="c"># 노드에 라우팅 정보 확인</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="nv">$N1</span> <span class="nv">$N2</span> <span class="nv">$N3</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> ssh ec2-user@<span class="nv">$i</span> <span class="nb">sudo </span>ip <span class="nt">-c</span> route<span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt; node 192.168.1.186 &amp;lt;&amp;lt;</span>
<span class="c">#    default via 192.168.1.1 dev eth0</span>
<span class="c">#    169.254.169.254 dev eth0</span>
<span class="c">#    192.168.1.0/24 dev eth0 proto kernel scope link src 192.168.1.186</span>
<span class="c">#    192.168.1.30 dev eni319ad74733c scope link</span>
<span class="c">#    192.168.1.112 dev eni7ecb7efa346 scope link  # &lt;span style="color: green;"&gt;👉 추가된 신규 파드의 IPv4 보조 IP&lt;/span&gt;</span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; node 192.168.2.92 &amp;lt;&amp;lt;</span>
<span class="c">#    default via 192.168.2.1 dev eth0</span>
<span class="c">#    169.254.169.254 dev eth0</span>
<span class="c">#    192.168.2.0/24 dev eth0 proto kernel scope link src 192.168.2.92</span>
<span class="c">#    192.168.2.172 dev enif06a5cbfaaa scope link  # &lt;span style="color: green;"&gt;👉 추가된 신규 파드의 IPv4 보조 IP&lt;/span&gt;</span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; node 192.168.3.235 &amp;lt;&amp;lt;</span>
<span class="c">#    default via 192.168.3.1 dev eth0</span>
<span class="c">#    169.254.169.254 dev eth0</span>
<span class="c">#    192.168.3.0/24 dev eth0 proto kernel scope link src 192.168.3.235</span>
<span class="c">#    192.168.3.82 dev enid438418b082 scope link</span>
<span class="c">#    192.168.3.246 dev eniea7f0ec96dd scope link  # &lt;span style="color: green;"&gt;👉 추가된 신규 파드의 IPv4 보조 IP&lt;/span&gt;</span>
</code></pre></div></div>

<ul>
  <li>파드가 생성되면, 워커 노드에 eniY@ifN 추가되고 라우팅 테이블에도 정보가 추가된것을 확인 할 수 있습니다.</li>
  <li>테스트용 파드 eniY 정보 확인 - 워커 노드 EC2</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 노드3에서 네트워크 인터페이스 정보 확인</span>
<span class="nv">$ </span>ssh ec2-user@<span class="nv">$N3</span>
<span class="nt">----------------</span>
<span class="nv">$ </span>ip <span class="nt">-br</span> <span class="nt">-c</span> addr show
<span class="c"># =&gt; lo               UNKNOWN        127.0.0.1/8 ::1/128</span>
<span class="c">#    eth0             UP             192.168.3.235/24 fe80::83e:a1ff:fe00:5/64</span>
<span class="c">#    enid438418b082@if3 UP             fe80::50:3aff:fe92:e1b/64</span>
<span class="c">#    eth1             UP             192.168.3.236/24 fe80::8e8:acff:fe41:8cab/64</span>
<span class="c">#    eniea7f0ec96dd@if3 UP             fe80::8cd8:57ff:fee7:29c/64</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> <span class="nb">link</span>
<span class="c"># =&gt; 1: lo: &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span>
<span class="c">#    2: eth0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc mq state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 0a:3e:a1:00:00:05 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    3: enid438418b082@if3: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc noqueue state UP mode DEFAULT group default</span>
<span class="c">#        link/ether 02:50:3a:92:0e:1b brd ff:ff:ff:ff:ff:ff link-netns cni-23569158-d846-4981-4105-ec08005e9b95</span>
<span class="c">#    4: eth1: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc mq state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 0a:e8:ac:41:8c:ab brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    5: eniea7f0ec96dd@if3: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc noqueue state UP mode DEFAULT group default</span>
<span class="c">#        link/ether 8e:d8:57:e7:02:9c brd ff:ff:ff:ff:ff:ff link-netns cni-508d7216-7484-4497-a023-c6236435d535</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> addr
<span class="c"># =&gt; ...</span>
<span class="c">#    2: eth0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc mq state UP group default qlen 1000</span>
<span class="c">#        link/ether 0a:3e:a1:00:00:05 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet 192.168.3.235/24 brd 192.168.3.255 scope global dynamic eth0</span>
<span class="c">#           valid_lft 2166sec preferred_lft 2166sec</span>
<span class="c">#        inet6 fe80::83e:a1ff:fe00:5/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    3: enid438418b082@if3: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc noqueue state UP group default</span>
<span class="c">#        link/ether 02:50:3a:92:0e:1b brd ff:ff:ff:ff:ff:ff link-netns cni-23569158-d846-4981-4105-ec08005e9b95</span>
<span class="c">#        inet6 fe80::50:3aff:fe92:e1b/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    4: eth1: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc mq state UP group default qlen 1000</span>
<span class="c">#        link/ether 0a:e8:ac:41:8c:ab brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet 192.168.3.236/24 brd 192.168.3.255 scope global eth1</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#        inet6 fe80::8e8:acff:fe41:8cab/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    5: eniea7f0ec96dd@if3: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc noqueue state UP group default</span>
<span class="c">#        link/ether 8e:d8:57:e7:02:9c brd ff:ff:ff:ff:ff:ff link-netns cni-508d7216-7484-4497-a023-c6236435d535</span>
<span class="c">#        inet6 fe80::8cd8:57ff:fee7:29c/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="nv">$ </span>ip route <span class="c"># 혹은 route -n</span>
<span class="c"># =&gt; default via 192.168.3.1 dev eth0</span>
<span class="c">#    169.254.169.254 dev eth0</span>
<span class="c">#    192.168.3.0/24 dev eth0 proto kernel scope link src 192.168.3.235</span>
<span class="c">#    192.168.3.82 dev enid438418b082 scope link</span>
<span class="c">#    192.168.3.246 dev eniea7f0ec96dd scope link</span>
  
<span class="c"># 마지막 생성된 네임스페이스 정보 출력 -t net(네트워크 타입)</span>
<span class="nv">$ </span><span class="nb">sudo </span>lsns <span class="nt">-o</span> PID,COMMAND <span class="nt">-t</span> net | <span class="nb">awk</span> <span class="s1">'NR&gt;2 {print $1}'</span> | <span class="nb">tail</span> <span class="nt">-n</span> 1
<span class="c"># =&gt; 9774</span>
  
<span class="c"># 마지막 생성된 네임스페이스 net PID 정보 출력 -t net(네트워크 타입)를 변수 지정</span>
<span class="nv">$ MyPID</span><span class="o">=</span><span class="si">$(</span><span class="nb">sudo </span>lsns <span class="nt">-o</span> PID,COMMAND <span class="nt">-t</span> net | <span class="nb">awk</span> <span class="s1">'NR&gt;2 {print $1}'</span> | <span class="nb">tail</span> <span class="nt">-n</span> 1<span class="si">)</span>
  
<span class="c"># PID 정보로 파드 정보 확인</span>
<span class="nv">$ </span><span class="nb">sudo </span>nsenter <span class="nt">-t</span> <span class="nv">$MyPID</span> <span class="nt">-n</span> ip <span class="nt">-c</span> addr
<span class="c"># =&gt; ...</span>
<span class="c">#    3: eth0@if5: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc noqueue state UP group default</span>
<span class="c">#        link/ether 6a:d5:4d:a7:45:7e brd ff:ff:ff:ff:ff:ff link-netnsid 0</span>
<span class="c">#        inet 192.168.3.246/32 scope global eth0</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#        inet6 fe80::68d5:4dff:fea7:457e/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="nv">$ </span><span class="nb">sudo </span>nsenter <span class="nt">-t</span> <span class="nv">$MyPID</span> <span class="nt">-n</span> ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 169.254.1.1 dev eth0</span>
<span class="c">#    169.254.1.1 dev eth0 scope link</span>
  
<span class="nv">$ </span><span class="nb">exit</span>
<span class="nt">----------------</span>
</code></pre></div></div>

<ul>
  <li>테스트용 파드 접속(exec) 후 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 테스트용 파드 접속(exec) 후 Shell 실행</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$PODNAME1</span> <span class="nt">--</span> zsh
<span class="c"># =&gt;  netshoot-pod-74b7555dc7-6qsvf  ~ </span>
  
<span class="c"># 아래부터는 pod-1 Shell 에서 실행 : 네트워크 정보 확인</span>
<span class="nt">----------------------------</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> addr
<span class="c"># =&gt; ...</span>
<span class="c">#    3: eth0@if5: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc noqueue state UP group default</span>
<span class="c">#        link/ether c6:cb:41:a0:85:57 brd ff:ff:ff:ff:ff:ff link-netnsid 0</span>
<span class="c">#        inet 192.168.1.112/32 scope global eth0</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#        inet6 fe80::c4cb:41ff:fea0:8557/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 169.254.1.1 dev eth0</span>
<span class="c">#    169.254.1.1 dev eth0 scope link</span>
<span class="nv">$ </span>route <span class="nt">-n</span>
<span class="c"># =&gt; Kernel IP routing table</span>
<span class="c">#    Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span>
<span class="c">#    0.0.0.0         169.254.1.1     0.0.0.0         UG    0      0        0 eth0</span>
<span class="c">#    169.254.1.1     0.0.0.0         255.255.255.255 UH    0      0        0 eth0</span>
<span class="c">#$ ping -c 1 &lt;pod-2 IP&gt;</span>
<span class="nv">$ </span>ping <span class="nt">-c</span> 1 192.168.2.172
<span class="c"># =&gt; PING 192.168.2.172 (192.168.2.172) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 192.168.2.172: icmp_seq=1 ttl=125 time=1.25 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 192.168.2.172 ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 1.249/1.249/1.249/0.000 ms</span>
<span class="nv">$ </span>ps
<span class="c"># =&gt; PID   USER     TIME  COMMAND</span>
<span class="c">#        1 root      0:00 tail -f /dev/null</span>
<span class="c">#      109 root      0:00 zsh</span>
<span class="c">#      186 root      0:00 ps</span>
<span class="nv">$ </span><span class="nb">cat</span> /etc/resolv.conf
<span class="c"># =&gt; search default.svc.cluster.local svc.cluster.local cluster.local ap-northeast-2.compute.internal</span>
<span class="c">#    nameserver 10.100.0.10</span>
<span class="c">#    options ndots:5</span>
<span class="nv">$ </span><span class="nb">exit</span>
<span class="nt">----------------------------</span>
  
<span class="c"># 파드2 Shell 실행</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$PODNAME2</span> <span class="nt">--</span> ip <span class="nt">-c</span> addr
<span class="c"># =&gt; ...</span>
<span class="c">#    3: eth0@if3: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 9001 qdisc noqueue state UP group default</span>
<span class="c">#        link/ether 02:ea:11:63:f6:9f brd ff:ff:ff:ff:ff:ff link-netnsid 0</span>
<span class="c">#        inet 192.168.2.172/32 scope global eth0</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#        inet6 fe80::ea:11ff:fe63:f69f/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
  
<span class="c"># 파드3 Shell 실행</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$PODNAME3</span> <span class="nt">--</span> ip <span class="nt">-br</span> <span class="nt">-c</span> addr
<span class="c"># =&gt; lo               UNKNOWN        127.0.0.1/8 ::1/128</span>
<span class="c">#    eth0@if5         UP             192.168.3.246/32 fe80::68d5:4dff:fea7:457e/64</span>
</code></pre></div></div>

<hr />

<h3 id="노드간-파드-통신">노드간 파드 통신</h3>

<ul>
  <li><strong>파드간 통신 흐름</strong> : AWS VPC CNI의 경우 별도의 오버레이(Overlay) 통신 기술없이, VPC에서 Native하게 파드간 직접 통신이 가능합니다.</li>
</ul>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_6.png" alt="img.png" class="image-center" /></p>

<ul>
  <li>파드간 통신 과정 참고</li>
</ul>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_7.png" alt="img.png" class="image-center" />
<em class="image-caption"><a href="https://github.com/aws/amazon-vpc-cni-k8s/blob/master/docs/cni-proposal.md">https://github.com/aws/amazon-vpc-cni-k8s/blob/master/docs/cni-proposal.md</a></em></p>

<h4 id="실습-파드간-통신-테스트-및-확인--별도의-nat-동작-없이-통신-가능">[실습] 파드간 통신 테스트 및 확인 : 별도의 NAT 동작 없이 통신 가능!</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 파드 IP 변수 지정</span>
<span class="nv">$ PODIP1</span><span class="o">=</span><span class="si">$(</span>kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>netshoot-pod <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.items[0].status.podIP<span class="o">}</span><span class="si">)</span>
<span class="nv">$ PODIP2</span><span class="o">=</span><span class="si">$(</span>kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>netshoot-pod <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.items[1].status.podIP<span class="o">}</span><span class="si">)</span>
<span class="nv">$ PODIP3</span><span class="o">=</span><span class="si">$(</span>kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>netshoot-pod <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.items[2].status.podIP<span class="o">}</span><span class="si">)</span>

<span class="c"># 파드1 Shell 에서 파드2로 ping 테스트</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$PODNAME1</span> <span class="nt">--</span> ping <span class="nt">-c</span> 2 <span class="nv">$PODIP2</span>
<span class="c"># =&gt; PING 192.168.2.172 (192.168.2.172) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 192.168.2.172: icmp_seq=1 ttl=125 time=0.915 ms</span>
<span class="c">#    64 bytes from 192.168.2.172: icmp_seq=2 ttl=125 time=0.870 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 192.168.2.172 ping statistics ---</span>
<span class="c">#    2 packets transmitted, 2 received, 0% packet loss, time 1001ms</span>
<span class="c">#    rtt min/avg/max/mdev = 0.870/0.892/0.915/0.022 ms</span>

<span class="c"># 파드2 Shell 에서 파드3로 ping 테스트</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$PODNAME2</span> <span class="nt">--</span> ping <span class="nt">-c</span> 2 <span class="nv">$PODIP3</span>
<span class="c"># =&gt; PING 192.168.3.246 (192.168.3.246) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 192.168.3.246: icmp_seq=1 ttl=125 time=1.79 ms</span>
<span class="c">#    64 bytes from 192.168.3.246: icmp_seq=2 ttl=125 time=1.25 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 192.168.3.246 ping statistics ---</span>
<span class="c">#    2 packets transmitted, 2 received, 0% packet loss, time 1002ms</span>
<span class="c">#    rtt min/avg/max/mdev = 1.245/1.516/1.788/0.271 ms</span>

<span class="c"># 파드3 Shell 에서 파드1로 ping 테스트</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$PODNAME3</span> <span class="nt">--</span> ping <span class="nt">-c</span> 2 <span class="nv">$PODIP1</span>
<span class="c"># =&gt; PING 192.168.1.112 (192.168.1.112) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 192.168.1.112: icmp_seq=1 ttl=125 time=1.08 ms</span>
<span class="c">#    64 bytes from 192.168.1.112: icmp_seq=2 ttl=125 time=1.23 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 192.168.1.112 ping statistics ---</span>
<span class="c">#    2 packets transmitted, 2 received, 0% packet loss, time 1001ms</span>
<span class="c">#    rtt min/avg/max/mdev = 1.084/1.155/1.227/0.071 ms</span>

<span class="c"># 워커 노드 EC2 : TCPDUMP 확인</span>
<span class="c">## For Pod to external (outside VPC) traffic, we will program iptables to SNAT using Primary IP address on the Primary ENI.</span>
<span class="nv">$ </span><span class="nb">sudo </span>tcpdump <span class="nt">-i</span> any <span class="nt">-nn</span> icmp
<span class="c"># =&gt; 08:11:33.865634 IP 192.168.2.172 &amp;gt; 192.168.3.246: ICMP echo request, id 19, seq 1, length 64</span>
<span class="c">#    08:11:33.865684 IP 192.168.2.172 &amp;gt; 192.168.3.246: ICMP echo request, id 19, seq 1, length 64</span>
<span class="c">#    08:11:33.867117 IP 192.168.3.246 &amp;gt; 192.168.2.172: ICMP echo reply, id 19, seq 1, length 64</span>
<span class="c">#    08:11:33.867195 IP 192.168.3.246 &amp;gt; 192.168.2.172: ICMP echo reply, id 19, seq 1, length 64</span>
<span class="c">#    08:11:34.866610 IP 192.168.2.172 &amp;gt; 192.168.3.246: ICMP echo request, id 19, seq 2, length 64</span>
<span class="c">#    08:11:34.866654 IP 192.168.2.172 &amp;gt; 192.168.3.246: ICMP echo request, id 19, seq 2, length 64</span>
<span class="c">#    08:11:34.867865 IP 192.168.3.246 &amp;gt; 192.168.2.172: ICMP echo reply, id 19, seq 2, length 64</span>
<span class="c">#    08:11:34.867891 IP 192.168.3.246 &amp;gt; 192.168.2.172: ICMP echo reply, id 19, seq 2, length 64</span>
<span class="nv">$ </span><span class="nb">sudo </span>tcpdump <span class="nt">-i</span> eth1 <span class="nt">-nn</span> icmp
<span class="c"># &lt;span style="color: green;"&gt;👉 캡쳐된 패킷이 없습니다.&lt;/span&gt;</span>
<span class="nv">$ </span><span class="nb">sudo </span>tcpdump <span class="nt">-i</span> eth0 <span class="nt">-nn</span> icmp
<span class="c"># =&gt; 08:11:33.865689 IP 192.168.2.172 &amp;gt; 192.168.3.246: ICMP echo request, id 19, seq 1, length 64</span>
<span class="c">#    08:11:33.867117 IP 192.168.3.246 &amp;gt; 192.168.2.172: ICMP echo reply, id 19, seq 1, length 64</span>
<span class="c">#    08:11:34.866654 IP 192.168.2.172 &amp;gt; 192.168.3.246: ICMP echo request, id 19, seq 2, length 64</span>
<span class="c">#    08:11:34.867865 IP 192.168.3.246 &amp;gt; 192.168.2.172: ICMP echo reply, id 19, seq 2, length 64</span>
<span class="nv">$ </span><span class="nb">sudo </span>tcpdump <span class="nt">-i</span> eniYYYYYYYY <span class="nt">-nn</span> icmp
<span class="c"># =&gt; 08:11:33.865643 IP 192.168.2.172 &amp;gt; 192.168.3.246: ICMP echo request, id 19, seq 1, length 64</span>
<span class="c">#    08:11:33.867195 IP 192.168.3.246 &amp;gt; 192.168.2.172: ICMP echo reply, id 19, seq 1, length 64</span>
<span class="c">#    08:11:34.866610 IP 192.168.2.172 &amp;gt; 192.168.3.246: ICMP echo request, id 19, seq 2, length 64</span>
<span class="c">#    08:11:34.867891 IP 192.168.3.246 &amp;gt; 192.168.2.172: ICMP echo reply, id 19, seq 2, length 64</span>

<span class="c"># [워커 노드1]</span>
<span class="c"># routing policy database management 확인</span>
<span class="nv">$ </span>ip rule
<span class="c"># =&gt; 0: from all lookup local</span>
<span class="c">#    512: from all to 192.168.1.30 lookup main</span>
<span class="c">#    512: from all to 192.168.1.112 lookup main</span>
<span class="c">#    1024:  from all fwmark 0x80/0x80 lookup main</span>
<span class="c">#    32766: from all lookup main</span>
<span class="c">#    32767: from all lookup default</span>

<span class="c"># routing table management 확인</span>
<span class="nv">$ </span>ip route show table <span class="nb">local</span>
<span class="c"># =&gt; broadcast 127.0.0.0 dev lo proto kernel scope link src 127.0.0.1</span>
<span class="c">#    local 127.0.0.0/8 dev lo proto kernel scope host src 127.0.0.1</span>
<span class="c">#    local 127.0.0.1 dev lo proto kernel scope host src 127.0.0.1</span>
<span class="c">#    broadcast 127.255.255.255 dev lo proto kernel scope link src 127.0.0.1</span>
<span class="c">#    broadcast 192.168.1.0 dev eth0 proto kernel scope link src 192.168.1.186</span>
<span class="c">#    broadcast 192.168.1.0 dev eth1 proto kernel scope link src 192.168.1.9</span>
<span class="c">#    local 192.168.1.9 dev eth1 proto kernel scope host src 192.168.1.9</span>
<span class="c">#    local 192.168.1.186 dev eth0 proto kernel scope host src 192.168.1.186</span>
<span class="c">#    broadcast 192.168.1.255 dev eth0 proto kernel scope link src 192.168.1.186</span>
<span class="c">#    broadcast 192.168.1.255 dev eth1 proto kernel scope link src 192.168.1.9</span>

<span class="c"># 디폴트 네트워크 정보를 eth0 을 통해서 빠져나간다</span>
<span class="nv">$ </span>ip route show table main
<span class="c"># =&gt; default via 192.168.1.1 dev eth0</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<hr />

<h3 id="파드에서-외부-통신">파드에서 외부 통신</h3>

<ul>
  <li>파드에서 외부 통신 흐름 : iptable 에 SNAT 을 통하여 노드의 eth0 IP로 변경되어서 외부와 통신합니다.</li>
</ul>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_8.png" alt="img.png" class="image-center" />
<em class="image-caption"><a href="https://github.com/aws/amazon-vpc-cni-k8s/blob/master/docs/cni-proposal.md">https://github.com/aws/amazon-vpc-cni-k8s/blob/master/docs/cni-proposal.md</a></em></p>

<ul>
  <li>VPC CNI 의 External source network address translation (<code class="language-plaintext highlighter-rouge">SNAT</code>) 설정에 따라, 외부(인터넷) 통신 시 <strong>SNAT</strong> 하거나 혹은 <strong>SNAT 없이</strong> 통신을 할 수 있다 - <a href="https://docs.aws.amazon.com/eks/latest/userguide/external-snat.html">링크</a></li>
</ul>

<h4 id="실습-파드에서-외부-통신-테스트-및-확인"><strong>[실습] 파드에서 외부 통신</strong> 테스트 및 확인</h4>

<ul>
  <li>파드 shell 실행 후 외부로 ping 테스트 &amp; 워커 노드에서 tcpdump 및 iptables 정보 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 작업용 EC2 : pod-1 Shell 에서 외부로 ping</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$PODNAME1</span> <span class="nt">--</span> ping <span class="nt">-c</span> 1 www.google.com
<span class="c"># =&gt; PING www.google.com (172.217.25.164) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from kix06s19-in-f4.1e100.net (172.217.25.164): icmp_seq=1 ttl=104 time=39.0 ms</span>
<span class="c">#    </span>
<span class="c">#    --- www.google.com ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 38.967/38.967/38.967/0.000 ms</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$PODNAME1</span> <span class="nt">--</span> ping <span class="nt">-i</span> 0.1 www.google.com
  
<span class="c"># 워커 노드 EC2 : TCPDUMP 확인</span>
<span class="nv">$ </span><span class="nb">sudo </span>tcpdump <span class="nt">-i</span> any <span class="nt">-nn</span> icmp
<span class="nv">$ </span><span class="nb">sudo </span>tcpdump <span class="nt">-i</span> eth0 <span class="nt">-nn</span> icmp
  
<span class="c"># 작업용 EC2 : 퍼블릭IP 확인</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="nv">$N1</span> <span class="nv">$N2</span> <span class="nv">$N3</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> ssh ec2-user@<span class="nv">$i</span> curl <span class="nt">-s</span> ipinfo.io/ip<span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
  
<span class="c"># 작업용 EC2 : pod-1 Shell 에서 외부 접속 확인 - 공인IP는 어떤 주소인가?</span>
<span class="c">## The right way to check the weather - [링크](https://github.com/chubin/wttr.in)</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="nv">$PODNAME1</span> <span class="nv">$PODNAME2</span> <span class="nv">$PODNAME3</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; Pod : </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$i</span> <span class="nt">--</span> curl <span class="nt">-s</span> ipinfo.io/ip<span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$PODNAME1</span> <span class="nt">--</span> curl <span class="nt">-s</span> wttr.in/seoul
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$PODNAME1</span> <span class="nt">--</span> curl <span class="nt">-s</span> wttr.in/seoul?format<span class="o">=</span>3
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$PODNAME1</span> <span class="nt">--</span> curl <span class="nt">-s</span> wttr.in/Moon
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nv">$PODNAME1</span> <span class="nt">--</span> curl <span class="nt">-s</span> wttr.in/:help
  
<span class="c"># 워커 노드 EC2</span>
<span class="nv">$ </span>ip rule
<span class="nv">$ </span>ip route show table main
<span class="nv">$ </span><span class="nb">sudo </span>iptables <span class="nt">-L</span> <span class="nt">-n</span> <span class="nt">-v</span> <span class="nt">-t</span> nat
<span class="nv">$ </span><span class="nb">sudo </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span>
  
<span class="c"># 파드가 외부와 통신시에는 아래 처럼 'AWS-SNAT-CHAIN-0' 룰(rule)에 의해서 SNAT 되어서 외부와 통신!</span>
<span class="c"># 참고로 뒤 IP는 eth0(ENI 첫번째)의 IP 주소입니다.</span>
<span class="c"># --random-fully 동작 - [링크1](https://ssup2.github.io/issue/Linux_TCP_SYN_Packet_Drop_SNAT_Port_Race_Condition/)  [링크2](https://ssup2.github.io/issue/Kubernetes_TCP_Connection_Delay_VXLAN_CNI_Plugin/)</span>
<span class="nv">$ </span><span class="nb">sudo </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span> | <span class="nb">grep</span> <span class="s1">'A AWS-SNAT-CHAIN'</span>
<span class="c"># =&gt; -A AWS-SNAT-CHAIN-0 -d 192.168.0.0/16 -m comment --comment &amp;quot;AWS SNAT CHAIN&amp;quot; -j RETURN</span>
<span class="c">#    -A AWS-SNAT-CHAIN-0 ! -o vlan+ -m comment --comment &amp;quot;AWS, SNAT&amp;quot; -m addrtype ! --dst-type LOCAL -j SNAT --to-source 192.168.2.92 --random-fully</span>
  
<span class="c">## 아래 'mark 0x4000/0x4000' 매칭되지 않아서 RETURN 됨!</span>
<span class="c"># =&gt; -A KUBE-POSTROUTING -m mark ! --mark 0x4000/0x4000 -j RETURN</span>
<span class="c">#    -A KUBE-POSTROUTING -j MARK --set-xmark 0x4000/0x0</span>
<span class="c">#    -A KUBE-POSTROUTING -m comment --comment &amp;quot;kubernetes service traffic requiring SNAT&amp;quot; -j MASQUERADE --random-fully</span>
<span class="c">#    ...</span>
  
<span class="c"># 카운트 확인 시 AWS-SNAT-CHAIN-0에 매칭되어, 목적지가 192.168.0.0/16 아니고 외부 빠져나갈때 SNAT 192.168.1.251(EC2 노드1 IP) 변경되어 나갑니다.</span>
<span class="nv">$ </span><span class="nb">sudo </span>iptables <span class="nt">-t</span> filter <span class="nt">--zero</span><span class="p">;</span> <span class="nb">sudo </span>iptables <span class="nt">-t</span> nat <span class="nt">--zero</span><span class="p">;</span> <span class="nb">sudo </span>iptables <span class="nt">-t</span> mangle <span class="nt">--zero</span><span class="p">;</span> <span class="nb">sudo </span>iptables <span class="nt">-t</span> raw <span class="nt">--zero</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> <span class="s1">'sudo iptables -v --numeric --table nat --list AWS-SNAT-CHAIN-0; echo ; sudo iptables -v --numeric --table nat --list KUBE-POSTROUTING; echo ; sudo iptables -v --numeric --table nat --list POSTROUTING'</span>
<span class="c"># =&gt; Chain AWS-SNAT-CHAIN-0 (1 references)</span>
<span class="c">#     pkts bytes target     prot opt in     out     source               destination</span>
<span class="c">#       12  1106 RETURN     all  --  *      *       0.0.0.0/0            192.168.0.0/16  /* AWS SNAT CHAIN */</span>
<span class="c">#       31  1924 SNAT       all  --  *      !vlan+  0.0.0.0/0            0.0.0.0/0            /* AWS, SNAT */ ADDRTYPE match dst-type !LOCAL to:192.168.2.92 random-fully</span>
<span class="c">#    </span>
<span class="c">#    Chain KUBE-POSTROUTING (1 references)</span>
<span class="c">#     pkts bytes target     prot opt in     out     source               destination</span>
<span class="c">#       53  3630 RETURN     all  --  *      *       0.0.0.0/0            0.0.0.0/0            mark match ! 0x4000/0x4000</span>
<span class="c">#        0     0 MARK       all  --  *      *       0.0.0.0/0            0.0.0.0/0            MARK xor 0x4000</span>
<span class="c">#        0     0 MASQUERADE  all  --  * * 0.0.0.0/0            0.0.0.0/0            /* kubernetes service traffic requiring SNAT */ random-fully</span>
<span class="c">#    </span>
<span class="c">#    Chain POSTROUTING (policy ACCEPT 22 packets, 1706 bytes)</span>
<span class="c">#     pkts bytes target     prot opt in     out     source               destination</span>
<span class="c">#       53  3630 KUBE-POSTROUTING  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes postrouting rules */</span>
<span class="c">#       53  3630 AWS-SNAT-CHAIN-0  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* AWS SNAT CHAIN */</span>
  
<span class="c"># conntrack 확인</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="nv">$N1</span> <span class="nv">$N2</span> <span class="nv">$N3</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> ssh ec2-user@<span class="nv">$i</span> <span class="nb">sudo </span>conntrack <span class="nt">-L</span> <span class="nt">-n</span> |grep <span class="nt">-v</span> <span class="s1">'169.254.169'</span><span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; node 192.168.1.186 &amp;lt;&amp;lt;</span>
<span class="c">#    udp      17 29 src=192.168.1.186 dst=146.56.40.151 sport=50772 dport=123 src=146.56.40.151 dst=192.168.1.186 sport=123 dport=47629 mark=128 use=1</span>
<span class="c">#    tcp      6 86395 ESTABLISHED src=192.168.1.186 dst=52.95.197.175 sport=45832 dport=443 src=52.95.197.175 dst=192.168.1.186 sport=443 dport=30346 [ASSURED] mark=128 use=1</span>
<span class="c">#    tcp      6 86395 ESTABLISHED src=192.168.1.186 dst=52.95.195.121 sport=48862 dport=443 src=52.95.195.121 dst=192.168.1.186 sport=443 dport=41664 [ASSURED] mark=128 use=1</span>
<span class="c">#    conntrack v1.4.4 (conntrack-tools): 59 flow entries have been shown.</span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; node 192.168.2.92 &amp;lt;&amp;lt;</span>
<span class="c">#    conntrack v1.4.4 (conntrack-tools): 50 flow entries have been shown.</span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; node 192.168.3.235 &amp;lt;&amp;lt;</span>
<span class="c">#    conntrack v1.4.4 (conntrack-tools): 51 flow entries have been shown.</span>
<span class="c">#    udp      17 23 src=192.168.3.235 dst=146.56.40.151 sport=51849 dport=123 src=146.56.40.151 dst=192.168.3.235 sport=123 dport=29777 mark=128 use=1</span>
</code></pre></div></div>

<ul>
  <li>다음 실습을 위해서 파드 삭제</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl delete deploy netshoot-pod
<span class="c"># =&gt; deployment.apps &amp;quot;netshoot-pod&amp;quot; deleted</span>
</code></pre></div></div>

<hr />

<h3 id="노드의-파드-생성-갯수-제한">노드의 파드 생성 갯수 제한</h3>

<h4 id="사전-준비--kube-ops-view-설치">사전 준비 : kube-ops-view 설치</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># kube-ops-view</span>
<span class="nv">$ </span>helm repo add geek-cookbook https://geek-cookbook.github.io/charts/
<span class="c"># =&gt; &amp;quot;geek-cookbook&amp;quot; has been added to your repositories</span>
<span class="nv">$ </span>helm <span class="nb">install </span>kube-ops-view geek-cookbook/kube-ops-view <span class="nt">--version</span> 1.2.2 <span class="nt">--set</span> service.main.type<span class="o">=</span>LoadBalancer <span class="nt">--set</span> env.TZ<span class="o">=</span><span class="s2">"Asia/Seoul"</span> <span class="nt">--namespace</span> kube-system
<span class="c"># =&gt; NAME: kube-ops-view</span>
<span class="c">#    LAST DEPLOYED: Sat Oct  1 17:30:33 2024</span>
<span class="c">#    NAMESPACE: kube-system</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 1</span>
<span class="c">#    TEST SUITE: None</span>
<span class="c">#    NOTES:</span>
<span class="c">#    1. Get the application URL by running these commands:</span>
<span class="c">#         NOTE: It may take a few minutes for the LoadBalancer IP to be available.</span>
<span class="c">#               You can watch the status of by running 'kubectl get svc -w kube-ops-view'</span>
<span class="c">#      export SERVICE_IP=$(kubectl get svc --namespace kube-system kube-ops-view -o jsonpath='{.status.loadBalancer.ingress[0].ip}')</span>
<span class="c">#      echo http://$SERVICE_IP:8080</span>

<span class="c"># kube-ops-view 접속 URL 확인 (1.5 배율)</span>
<span class="nv">$ </span>kubectl get svc <span class="nt">-n</span> kube-system kube-ops-view <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.status.loadBalancer.ingress[0].hostname<span class="o">}</span> | <span class="nb">awk</span> <span class="s1">'{ print "KUBE-OPS-VIEW URL = http://"$1":8080/#scale=1.5"}'</span>
<span class="c"># =&gt; KUBE-OPS-VIEW URL = http://ae19b387d6fee48239f44d3f9f121378-262130081.ap-northeast-2.elb.amazonaws.com:8080/#scale=1.5</span>
</code></pre></div></div>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_29.png" alt="img.png" class="image-center" /></p>

<ul>
  <li><strong>Secondary IPv4 addresses</strong> (기본값) : 인스턴스 유형에 최대 ENI 갯수와 할당 가능 IP 수를 조합하여 선정</li>
</ul>

<h4 id="워커-노드의-인스턴스-타입-별-파드-생성-갯수-제한">워커 노드의 인스턴스 타입 별 파드 생성 갯수 제한</h4>

<ul>
  <li><strong>인스턴스 타입</strong> 별 ENI 최대 갯수와 할당 가능한 최대 IP 갯수에 따라서 파드 배치 갯수가 결정됨</li>
  <li>단, aws-node 와 kube-proxy 파드는 호스트의 IP를 사용함으로 최대 갯수에서 제외함</li>
</ul>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_9.png" alt="img.png" class="image-center w-90" /></p>

<blockquote>
  <p>👉 최대 파드 생성 갯수 : <code class="language-plaintext highlighter-rouge">(Number of network interfaces for the instance type × (the number of IP addressess per network interface - 1)) + 2</code></p>
</blockquote>

<h4 id="워커-노드의-인스턴스-정보-확인--t3medium-사용-시">워커 노드의 인스턴스 정보 확인 : t3.medium 사용 시</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># t3 타입의 정보(필터) 확인</span>
<span class="nv">$ </span>aws ec2 describe-instance-types <span class="nt">--filters</span> <span class="nv">Name</span><span class="o">=</span>instance-type,Values<span class="o">=</span>t3.<span class="k">*</span> <span class="se">\</span>
  <span class="nt">--query</span> <span class="s2">"InstanceTypes[].{Type: InstanceType, MaxENI: NetworkInfo.MaximumNetworkInterfaces, IPv4addr: NetworkInfo.Ipv4AddressesPerInterface}"</span> <span class="se">\</span>
  <span class="nt">--output</span> table
<span class="c"># =&gt; --------------------------------------</span>
<span class="c">#    |        DescribeInstanceTypes       |</span>
<span class="c">#    +----------+----------+--------------+</span>
<span class="c">#    | IPv4addr | MaxENI   |    Type      |</span>
<span class="c">#    +----------+----------+--------------+</span>
<span class="c">#    |  12      |  3       |  t3.large    |</span>
<span class="c">#    |  6       |  3       |  t3.medium   |</span>
<span class="c">#    |  15      |  4       |  t3.2xlarge  |</span>
<span class="c">#    |  15      |  4       |  t3.xlarge   |</span>
<span class="c">#    |  2       |  2       |  t3.micro    |</span>
<span class="c">#    |  2       |  2       |  t3.nano     |</span>
<span class="c">#    |  4       |  3       |  t3.small    |</span>
<span class="c">#    +----------+----------+--------------+</span>

<span class="c"># c5 타입의 정보(필터) 확인</span>
<span class="nv">$ </span>aws ec2 describe-instance-types <span class="nt">--filters</span> <span class="nv">Name</span><span class="o">=</span>instance-type,Values<span class="o">=</span>c5<span class="k">*</span>.<span class="k">*</span> <span class="se">\</span>
  <span class="nt">--query</span> <span class="s2">"InstanceTypes[].{Type: InstanceType, MaxENI: NetworkInfo.MaximumNetworkInterfaces, IPv4addr: NetworkInfo.Ipv4AddressesPerInterface}"</span> <span class="se">\</span>
  <span class="nt">--output</span> table
<span class="c"># =&gt; ----------------------------------------</span>
<span class="c">#    |         DescribeInstanceTypes        |</span>
<span class="c">#    +----------+----------+----------------+</span>
<span class="c">#    | IPv4addr | MaxENI   |     Type       |</span>
<span class="c">#    +----------+----------+----------------+</span>
<span class="c">#    |  30      |  8       |  c5d.12xlarge  |</span>
<span class="c">#    |  10      |  3       |  c5d.large     |</span>
<span class="c">#    |  10      |  3       |  c5n.large     |</span>
<span class="c">#    |  15      |  4       |  c5n.2xlarge   |</span>
<span class="c">#    |  30      |  8       |  c5.4xlarge    |</span>
<span class="c">#    |  15      |  4       |  c5a.xlarge    |</span>
<span class="c">#    |  30      |  8       |  c5a.4xlarge   |</span>
<span class="c">#    |  15      |  4       |  c5d.2xlarge   |</span>
<span class="c">#    |  50      |  15      |  c5d.24xlarge  |</span>
<span class="c">#    |  30      |  8       |  c5.12xlarge   |</span>
<span class="c">#    |  30      |  8       |  c5n.9xlarge   |</span>
<span class="c">#    |  30      |  8       |  c5a.12xlarge  |</span>
<span class="c">#    |  15      |  4       |  c5.xlarge     |</span>
<span class="c">#    |  30      |  8       |  c5n.4xlarge   |</span>
<span class="c">#    |  50      |  15      |  c5n.18xlarge  |</span>
<span class="c">#    |  50      |  15      |  c5.24xlarge   |</span>
<span class="c">#    |  30      |  8       |  c5d.4xlarge   |</span>
<span class="c">#    |  30      |  8       |  c5.9xlarge    |</span>
<span class="c">#    |  15      |  4       |  c5a.2xlarge   |</span>
<span class="c">#    |  50      |  15      |  c5.metal      |</span>
<span class="c">#    |  50      |  15      |  c5a.24xlarge  |</span>
<span class="c">#    |  50      |  15      |  c5d.18xlarge  |</span>
<span class="c">#    |  50      |  15      |  c5a.16xlarge  |</span>
<span class="c">#    |  30      |  8       |  c5a.8xlarge   |</span>
<span class="c">#    |  50      |  15      |  c5n.metal     |</span>
<span class="c">#    |  50      |  15      |  c5d.metal     |</span>
<span class="c">#    |  10      |  3       |  c5.large      |</span>
<span class="c">#    |  15      |  4       |  c5.2xlarge    |</span>
<span class="c">#    |  15      |  4       |  c5d.xlarge    |</span>
<span class="c">#    |  10      |  3       |  c5a.large     |</span>
<span class="c">#    |  50      |  15      |  c5.18xlarge   |</span>
<span class="c">#    |  30      |  8       |  c5d.9xlarge   |</span>
<span class="c">#    |  15      |  4       |  c5n.xlarge    |</span>
<span class="c">#    +----------+----------+----------------+  </span>

<span class="c"># 파드 사용 가능 계산 예시 : aws-node 와 kube-proxy 파드는 host-networking 사용으로 IP 2개 남음</span>
<span class="c"># ((MaxENI * (IPv4addr-1)) + 2)</span>
<span class="c"># t3.medium 경우 : ((3 * (6 - 1) + 2 ) = 17개 &gt;&gt; aws-node 와 kube-proxy 2개 제외하면 15개</span>

<span class="c"># 워커노드 상세 정보 확인 : 노드 상세 정보의 Allocatable 에 pods 에 17개 정보 확인</span>
<span class="nv">$ </span>kubectl describe node | <span class="nb">grep </span>Allocatable: <span class="nt">-A6</span>
<span class="c"># =&gt; Allocatable:</span>
<span class="c">#      cpu:                1930m</span>
<span class="c">#      ephemeral-storage:  27905944324</span>
<span class="c">#      hugepages-1Gi:      0</span>
<span class="c">#      hugepages-2Mi:      0</span>
<span class="c">#      memory:             3388304Ki</span>
<span class="c">#      pods:               17</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<h4 id="최대-파드-생성-및-확인">최대 파드 생성 및 확인</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 워커 노드 EC2 - 모니터링</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>ip <span class="nt">-br</span> <span class="nt">-c</span> addr show <span class="o">&amp;&amp;</span> <span class="nb">echo</span> <span class="s2">"--------------"</span> <span class="p">;</span> <span class="nb">date</span> <span class="s2">"+%Y-%m-%d %H:%M:%S"</span> <span class="p">;</span> <span class="nb">sleep </span>1<span class="p">;</span> <span class="k">done</span>

<span class="c"># 작업용 EC2 - 터미널1</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> <span class="s1">'kubectl get pods -o wide'</span>

<span class="c"># 작업용 EC2 - 터미널2</span>
<span class="c"># 디플로이먼트 생성</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nt">-O</span> https://raw.githubusercontent.com/gasida/PKOS/main/2/nginx-dp.yaml
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> nginx-dp.yaml
<span class="c"># =&gt; deployment.apps/nginx-deployment created</span>

<span class="c"># 파드 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-o</span> wide
<span class="nv">$ </span>kubectl get pod <span class="nt">-o</span><span class="o">=</span>custom-columns<span class="o">=</span>NAME:.metadata.name,IP:.status.podIP
<span class="c"># =&gt; NAME                                IP</span>
<span class="c">#    nginx-deployment-6f999cfffb-44rw7   192.168.1.230</span>
<span class="c">#    nginx-deployment-6f999cfffb-xk4nh   192.168.3.246</span>

<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="nv">$N1</span> <span class="nv">$N2</span> <span class="nv">$N3</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> ssh ec2-user@<span class="nv">$i</span> <span class="nb">sudo </span>ip <span class="nt">-brief</span> addr | <span class="nb">wc</span> <span class="nt">-l</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; node 192.168.1.186 &amp;lt;&amp;lt;</span>
<span class="c">#    5</span>
<span class="c">#    &amp;gt;&amp;gt; node 192.168.2.92 &amp;lt;&amp;lt;</span>
<span class="c">#    4</span>
<span class="c">#    &amp;gt;&amp;gt; node 192.168.3.235 &amp;lt;&amp;lt;</span>
<span class="c">#    5</span>

<span class="c"># 파드 증가 테스트 &gt;&gt; 파드 정상 생성 확인, 워커 노드에서 eth, eni 갯수 확인</span>
<span class="nv">$ </span>kubectl scale deployment nginx-deployment <span class="nt">--replicas</span><span class="o">=</span>8
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="nv">$N1</span> <span class="nv">$N2</span> <span class="nv">$N3</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> ssh ec2-user@<span class="nv">$i</span> <span class="nb">sudo </span>ip <span class="nt">-brief</span> addr | <span class="nb">wc</span> <span class="nt">-l</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; node 192.168.1.186 &amp;lt;&amp;lt;</span>
<span class="c">#    7</span>
<span class="c">#    &amp;gt;&amp;gt; node 192.168.2.92 &amp;lt;&amp;lt;</span>
<span class="c">#    6</span>
<span class="c">#    &amp;gt;&amp;gt; node 192.168.3.235 &amp;lt;&amp;lt;</span>
<span class="c">#    7</span>

<span class="c"># 파드 증가 테스트 &gt;&gt; 파드 정상 생성 확인, 워커 노드에서 eth, eni 갯수 확인 &gt;&gt; 어떤일이 벌어졌는가?</span>
<span class="nv">$ </span>kubectl scale deployment nginx-deployment <span class="nt">--replicas</span><span class="o">=</span>15
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="nv">$N1</span> <span class="nv">$N2</span> <span class="nv">$N3</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> ssh ec2-user@<span class="nv">$i</span> <span class="nb">sudo </span>ip <span class="nt">-brief</span> addr | <span class="nb">wc</span> <span class="nt">-l</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; node 192.168.1.186 &amp;lt;&amp;lt;</span>
<span class="c">#    9</span>
<span class="c">#    &amp;gt;&amp;gt; node 192.168.2.92 &amp;lt;&amp;lt;</span>
<span class="c">#    9</span>
<span class="c">#    &amp;gt;&amp;gt; node 192.168.3.235 &amp;lt;&amp;lt;</span>
<span class="c">#    10</span>

<span class="c"># 파드 증가 테스트 &gt;&gt; 파드 정상 생성 확인, 워커 노드에서 eth, eni 갯수 확인 &gt;&gt; 어떤일이 벌어졌는가?</span>
<span class="nv">$ </span>kubectl scale deployment nginx-deployment <span class="nt">--replicas</span><span class="o">=</span>30
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="nv">$N1</span> <span class="nv">$N2</span> <span class="nv">$N3</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> ssh ec2-user@<span class="nv">$i</span> <span class="nb">sudo </span>ip <span class="nt">-brief</span> addr | <span class="nb">wc</span> <span class="nt">-l</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; node 192.168.1.186 &amp;lt;&amp;lt;</span>
<span class="c">#    15</span>
<span class="c">#    &amp;gt;&amp;gt; node 192.168.2.92 &amp;lt;&amp;lt;</span>
<span class="c">#    15</span>
<span class="c">#    &amp;gt;&amp;gt; node 192.168.3.235 &amp;lt;&amp;lt;</span>
<span class="c">#    15</span>

<span class="c"># 파드 증가 테스트 &gt;&gt; 파드 정상 생성 확인, 워커 노드에서 eth, eni 갯수 확인 &gt;&gt; 어떤일이 벌어졌는가?</span>
<span class="nv">$ </span>kubectl scale deployment nginx-deployment <span class="nt">--replicas</span><span class="o">=</span>50
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="nv">$N1</span> <span class="nv">$N2</span> <span class="nv">$N3</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> ssh ec2-user@<span class="nv">$i</span> <span class="nb">sudo </span>ip <span class="nt">-brief</span> addr | <span class="nb">wc</span> <span class="nt">-l</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; node 192.168.1.186 &amp;lt;&amp;lt;</span>
<span class="c">#    19</span>
<span class="c">#    &amp;gt;&amp;gt; node 192.168.2.92 &amp;lt;&amp;lt;</span>
<span class="c">#    19</span>
<span class="c">#    &amp;gt;&amp;gt; node 192.168.3.235 &amp;lt;&amp;lt;</span>
<span class="c">#    19</span>

<span class="c"># 파드 생성 실패!</span>
<span class="nv">$ </span>kubectl get pods | <span class="nb">grep </span>Pending
<span class="c"># =&gt; nginx-deployment-6f999cfffb-59cj6   0/1     Pending   0          69s</span>
<span class="c">#    nginx-deployment-6f999cfffb-5z5qg   0/1     Pending   0          69s</span>
<span class="c">#    nginx-deployment-6f999cfffb-6gk4m   0/1     Pending   0          69s</span>
<span class="c">#    nginx-deployment-6f999cfffb-bhzc8   0/1     Pending   0          69s</span>
<span class="c">#    nginx-deployment-6f999cfffb-hlns8   0/1     Pending   0          69s</span>
<span class="c">#    nginx-deployment-6f999cfffb-n64nc   0/1     Pending   0          69s</span>
<span class="c">#    nginx-deployment-6f999cfffb-w8x7g   0/1     Pending   0          69s</span>
<span class="c">#    nginx-deployment-6f999cfffb-zb2pk   0/1     Pending   0          69s</span>

<span class="c">#$ kubectl describe pod &lt;Pending 파드&gt; | grep Events: -A5</span>
<span class="nv">$ </span>kubectl describe pod nginx-deployment-6f999cfffb-59cj6 | <span class="nb">grep </span>Events: <span class="nt">-A5</span>
<span class="c"># =&gt; Events:</span>
<span class="c">#      Type     Reason            Age   From               Message</span>
<span class="c">#      ----     ------            ----  ----               -------</span>
<span class="c">#      Warning  FailedScheduling  101s  default-scheduler  0/3 nodes are available: 3 Too many pods. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod.</span>
</code></pre></div></div>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_30.png" alt="img.png" class="image-center" /></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 디플로이먼트 삭제</span>
<span class="nv">$ </span>kubectl delete deploy nginx-deployment
<span class="c"># =&gt; deployment.apps &amp;quot;nginx-deployment&amp;quot; deleted</span>
</code></pre></div></div>

<ul>
  <li>👉 해결 방안 : IPv4 Prefix Delegation, WARM &amp; MIN IP/Prefix Targets, Custom Network</li>
</ul>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_10.png" alt="img.png" class="image-center w-80" />
<em class="image-caption">IPv4 Prefix Delegation을 통한 IP 갯수 제한 해소</em></p>

<hr />

<h3 id="service--aws-loadbalancer-controller">Service &amp; AWS LoadBalancer Controller</h3>

<h4 id="서비스-종류">서비스 종류</h4>

<ul>
  <li>ClusterIP 타입</li>
</ul>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_16.png" alt="img.png" class="image-center w-90" /></p>

<ul>
  <li>NodePort 타입</li>
</ul>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_17.png" alt="img_1.png" class="image-center w-90" /></p>

<ul>
  <li>LoadBalancer 타입 (기본 모드) : NLB 인스턴스 유형</li>
</ul>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_18.png" alt="img_2.png" class="image-center w-90" /></p>

<ul>
  <li>Service (LoadBalancer Controller) : AWS Load Balancer Controller + NLB IP 모드 동작 with AWS VPC CNI</li>
</ul>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_19.png" alt="img_3.png" class="image-center w-90" /></p>

<h4 id="nlb-모드-전체-정리">NLB 모드 전체 정리</h4>

<h5 id="instance-mode">Instance mode</h5>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_20.png" alt="img_4.png" class="image-center w-90" />
<em class="image-caption"><a href="https://aws.amazon.com/blogs/networking-and-content-delivery/deploying-aws-load-balancer-controller-on-amazon-eks/">https://aws.amazon.com/blogs/networking-and-content-delivery/deploying-aws-load-balancer-controller-on-amazon-eks/</a></em></p>

<ul>
  <li><strong>externalTrafficPolicy</strong>에 따른 동작은 다음과 같습니다.
    <ul>
      <li><code class="language-plaintext highlighter-rouge">externalTrafficPolicy: ClusterIP</code> : 2번 분산 및 SNAT으로 Client IP 확인 불가능합니다. &lt;- LoadBalancer 타입 (기본 모드) 동작</li>
      <li><code class="language-plaintext highlighter-rouge">externalTrafficPolicy: Local</code> : 1번 분산 및 ClientIP가 유지되고, 워커 노드의 iptables을 사용합니다.
        <ul>
          <li>
            <p><strong>통신 흐름</strong> : 외부 클라이언트가 ‘로드밸런서’ 접속 시 부하분산 되어 노드 도달 후 iptables 룰로 목적지 파드와 통신됩니다.</p>

            <p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_21.png" alt="img_5.png" class="image-center w-90" />
<em class="image-caption"><code class="language-plaintext highlighter-rouge">externalTrafficPolicy: Local</code>일때의 통신흐름의 예</em></p>

            <p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_22.png" alt="img_6.png" class="image-center w-90" /></p>

            <ul>
              <li>노드는 외부에 공개되지 않고 로드밸런서만 외부에 공개되며, 외부 클라이언트는 로드밸랜서에 접속을 할 뿐 내부 노드의 정보를 알 수 없습니다.</li>
              <li>로드밸런서가 부하분산하여 파드가 존재하는 노드들에게 전달합니다. iptables 룰에서는 자신의 노드에 있는 파드만 연결합니다. (<code class="language-plaintext highlighter-rouge">externalTrafficPolicy: local</code>)</li>
              <li>DNAT가 2번 동작합니다. (1) 로드밸런서 접속 후 빠져 나갈때, (2) 노드의 iptables 룰에서 파드IP 전달 시</li>
              <li>외부 클라이언트의 IP가 보존됩니다. AWS NLB 는 <strong>타켓</strong>이 <strong>인스턴스</strong>일 경우 클라이언트 IP를 유지, iptables 룰 경우도 <code class="language-plaintext highlighter-rouge">externalTrafficPolicy: local</code> 로 클라이언트 IP를 보존합니다.</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>부하분산 최적화</strong> : 노드에 파드가 없을 경우 ‘로드밸런서’에서 노드에 헬스 체크(상태 검사)가 실패하여 해당 노드로는 외부 요청 트래픽을 전달하지 않습니다.</p>

    <p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_23.png" alt="img_7.png" class="image-center w-90" />
<img src="/assets/2024/kans-3th/w9/20241102_kans_w9_26.png" alt="img.png" /></p>

    <p>위의 이미지 처럼 3번째 인스턴스(Node3)은 상태 확인이 실패한 경우, 해당 노드로는 외부 요청 트래픽 전달하지 않습니다.</p>
  </li>
</ul>

<h5 id="ip-mode">IP mode</h5>

<ul>
  <li>
    <p>IP 모드는 반드시 AWS LoadBalancer 컨트롤러 파드 및 정책 설정이 필요합니다.</p>

    <p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_24.png" alt="img_8.png" class="image-center w-90" />
<em class="image-caption"><a href="https://aws.amazon.com/blogs/networking-and-content-delivery/deploying-aws-load-balancer-controller-on-amazon-eks/">https://aws.amazon.com/blogs/networking-and-content-delivery/deploying-aws-load-balancer-controller-on-amazon-eks/</a></em></p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">Proxy Protocol v2 비활성화</code> ⇒ NLB에서 바로 파드로 인입되며, 단 ClientIP가 NLB로 SNAT 되어 Client IP 확인 불가능합니다.</li>
      <li><code class="language-plaintext highlighter-rouge">Proxy Protocol v2 활성화</code> ⇒ NLB에서 바로 파드로 인입 및 ClientIP 확인 가능합니다. 단, PPv2를 애플리케이션이 인지할 수 있게 설정이 필요합니다.</li>
    </ul>
  </li>
  <li>
    <p><strong>AWS LoadBalancer Controller 배포</strong> - <a href="https://kubernetes-sigs.github.io/aws-load-balancer-controller/latest/deploy/installation/"><strong>Link</strong></a></p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Helm Chart 설치</span>
<span class="nv">$ </span>helm repo add eks https://aws.github.io/eks-charts
<span class="c"># =&gt; &amp;quot;eks&amp;quot; has been added to your repositories</span>
<span class="nv">$ </span>helm repo update
<span class="c"># =&gt; Hang tight while we grab the latest from your chart repositories...</span>
<span class="c">#    ...Successfully got an update from the &amp;quot;eks&amp;quot; chart repository</span>
<span class="c">#    ...Successfully got an update from the &amp;quot;geek-cookbook&amp;quot; chart repository</span>
<span class="c">#    Update Complete. ⎈Happy Helming!⎈</span>
<span class="nv">$ </span>helm <span class="nb">install </span>aws-load-balancer-controller eks/aws-load-balancer-controller <span class="nt">-n</span> kube-system <span class="nt">--set</span> <span class="nv">clusterName</span><span class="o">=</span><span class="nv">$CLUSTER_NAME</span>
<span class="c"># =&gt; NAME: aws-load-balancer-controller</span>
<span class="c">#    LAST DEPLOYED: Sat Oct  1 17:45:09 2024</span>
<span class="c">#    NAMESPACE: kube-system</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 1</span>
<span class="c">#    TEST SUITE: None</span>
<span class="c">#    NOTES:</span>
<span class="c">#    AWS Load Balancer controller installed!</span>
  
<span class="c">## 설치 확인</span>
<span class="nv">$ </span>kubectl get crd
<span class="c"># =&gt; NAME                                         CREATED AT</span>
<span class="c">#    ...</span>
<span class="c">#    ingressclassparams.elbv2.k8s.aws             2024-10-01T08:45:08Z</span>
<span class="c">#    ...</span>
<span class="c">#    targetgroupbindings.elbv2.k8s.aws            2024-10-01T08:45:08Z</span>
<span class="nv">$ </span>kubectl get deployment <span class="nt">-n</span> kube-system aws-load-balancer-controller
<span class="c"># =&gt; NAME                           READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    aws-load-balancer-controller   2/2     2            2           58s</span>
<span class="nv">$ </span>kubectl describe deploy <span class="nt">-n</span> kube-system aws-load-balancer-controller
<span class="nv">$ </span>kubectl describe deploy <span class="nt">-n</span> kube-system aws-load-balancer-controller | <span class="nb">grep</span> <span class="s1">'Service Account'</span>
<span class="c"># =&gt;   Service Account:  aws-load-balancer-controller</span>
  
<span class="c"># 클러스터롤, 롤 확인</span>
<span class="nv">$ </span>kubectl describe clusterrolebindings.rbac.authorization.k8s.io aws-load-balancer-controller-rolebinding
<span class="nv">$ </span>kubectl describe clusterroles.rbac.authorization.k8s.io aws-load-balancer-controller-role
<span class="c"># =&gt; ...</span>
<span class="c">#    PolicyRule:</span>
<span class="c">#      Resources                                     Non-Resource URLs  Resource Names  Verbs</span>
<span class="c">#      ---------                                     -----------------  --------------  -----</span>
<span class="c">#      targetgroupbindings.elbv2.k8s.aws             []                 []              [create delete get list patch update watch]</span>
<span class="c">#      events                                        []                 []              [create patch]</span>
<span class="c">#      configmaps                                    []                 []              [get delete create update]</span>
<span class="c">#      ingresses                                     []                 []              [get list patch update watch]</span>
<span class="c">#      services                                      []                 []              [get list patch update watch]</span>
<span class="c">#      ingresses.extensions                          []                 []              [get list patch update watch]</span>
<span class="c">#      services.extensions                           []                 []              [get list patch update watch]</span>
<span class="c">#      ingresses.networking.k8s.io                   []                 []              [get list patch update watch]</span>
<span class="c">#      services.networking.k8s.io                    []                 []              [get list patch update watch]</span>
<span class="c">#      endpoints                                     []                 []              [get list watch]</span>
<span class="c">#      namespaces                                    []                 []              [get list watch]</span>
<span class="c">#      nodes                                         []                 []              [get list watch]</span>
<span class="c">#      pods                                          []                 []              [get list watch]</span>
<span class="c">#      endpointslices.discovery.k8s.io               []                 []              [get list watch]</span>
<span class="c">#      ingressclassparams.elbv2.k8s.aws              []                 []              [get list watch]</span>
<span class="c">#      ingressclasses.networking.k8s.io              []                 []              [get list watch]</span>
<span class="c">#      ingresses/status                              []                 []              [update patch]</span>
<span class="c">#      pods/status                                   []                 []              [update patch]</span>
<span class="c">#      services/status                               []                 []              [update patch]</span>
<span class="c">#      targetgroupbindings/status                    []                 []              [update patch]</span>
<span class="c">#      ingresses.elbv2.k8s.aws/status                []                 []              [update patch]</span>
<span class="c">#      pods.elbv2.k8s.aws/status                     []                 []              [update patch]</span>
<span class="c">#      services.elbv2.k8s.aws/status                 []                 []              [update patch]</span>
<span class="c">#      targetgroupbindings.elbv2.k8s.aws/status      []                 []              [update patch]</span>
<span class="c">#      ingresses.extensions/status                   []                 []              [update patch]</span>
<span class="c">#      pods.extensions/status                        []                 []              [update patch]</span>
<span class="c">#      services.extensions/status                    []                 []              [update patch]</span>
<span class="c">#      targetgroupbindings.extensions/status         []                 []              [update patch]</span>
<span class="c">#      ingresses.networking.k8s.io/status            []                 []              [update patch]</span>
<span class="c">#      pods.networking.k8s.io/status                 []                 []              [update patch]</span>
<span class="c">#      services.networking.k8s.io/status             []                 []              [update patch]</span>
<span class="c">#      targetgroupbindings.networking.k8s.io/status  []                 []              [update patch]</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>서비스/파드 배포 테스트 with NLB - <a href="https://kubernetes-sigs.github.io/aws-load-balancer-controller/v2.4/guide/service/nlb/">링크</a> <a href="https://docs.aws.amazon.com/eks/latest/userguide/network-load-balancing.html">NLB</a></p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 모니터링</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> kubectl get pod,svc,ep
  
<span class="c"># 작업용 EC2 - 디플로이먼트 &amp; 서비스 생성</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nt">-O</span> https://raw.githubusercontent.com/gasida/PKOS/main/2/echo-service-nlb.yaml
<span class="nv">$ </span><span class="nb">cat </span>echo-service-nlb.yaml
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> echo-service-nlb.yaml
<span class="c"># =&gt; deployment.apps/deploy-echo created</span>
<span class="c">#    service/svc-nlb-ip-type created</span>
  
<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get deploy,pod
<span class="c"># =&gt; NAME                          READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/deploy-echo   2/2     2            2           10s</span>
<span class="c">#    </span>
<span class="c">#    NAME                               READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/deploy-echo-857b6cfb88-452cd   1/1     Running   0          10s</span>
<span class="c">#    pod/deploy-echo-857b6cfb88-5xz5j   1/1     Running   0          10s</span>
<span class="nv">$ </span>kubectl get svc,ep,ingressclassparams,targetgroupbindings
<span class="c"># =&gt; NAME                      TYPE           CLUSTER-IP      EXTERNAL-IP                                                                         PORT(S)        AGE</span>
<span class="c">#    service/kubernetes        ClusterIP      10.100.0.1      &amp;lt;none&amp;gt;                                                                              443/TCP        76m</span>
<span class="c">#    service/svc-nlb-ip-type   LoadBalancer   10.100.83.184   k8s-default-svcnlbip-50f5d03f41-f28c6aa861a2e815.elb.ap-northeast-2.amazonaws.com   80:30771/TCP   21s</span>
<span class="c">#    </span>
<span class="c">#    NAME                        ENDPOINTS                              AGE</span>
<span class="c">#    endpoints/kubernetes        192.168.1.65:443,192.168.3.189:443     76m</span>
<span class="c">#    endpoints/svc-nlb-ip-type   192.168.1.112:8080,192.168.2.24:8080   21s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                   GROUP-NAME   SCHEME   IP-ADDRESS-TYPE   AGE</span>
<span class="c">#    ingressclassparams.elbv2.k8s.aws/alb                                           3m9s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                                               SERVICE-NAME      SERVICE-PORT   TARGET-TYPE   AGE</span>
<span class="c">#    targetgroupbinding.elbv2.k8s.aws/k8s-default-svcnlbip-f58255c318   svc-nlb-ip-type   80             ip            16s</span>
<span class="nv">$ </span>kubectl get targetgroupbindings <span class="nt">-o</span> json | jq
<span class="c"># =&gt; {</span>
<span class="c">#      &amp;quot;apiVersion&amp;quot;: &amp;quot;v1&amp;quot;,</span>
<span class="c">#      &amp;quot;items&amp;quot;: [</span>
<span class="c">#        {</span>
<span class="c">#          &amp;quot;apiVersion&amp;quot;: &amp;quot;elbv2.k8s.aws/v1beta1&amp;quot;,</span>
<span class="c">#          &amp;quot;kind&amp;quot;: &amp;quot;TargetGroupBinding&amp;quot;,</span>
<span class="c">#          &amp;quot;metadata&amp;quot;: {</span>
<span class="c">#            &amp;quot;annotations&amp;quot;: {</span>
<span class="c">#              &amp;quot;elbv2.k8s.aws/checkpoint&amp;quot;: &amp;quot;gs98wrXMlQMdFGryEbrFbVngcODAXK0Yk4czpOdn9bg/biShKK1OQPD05qA040YQHH29qU6aPNq6J-fRu4M-dKY&amp;quot;,</span>
<span class="c">#              &amp;quot;elbv2.k8s.aws/checkpoint-timestamp&amp;quot;: &amp;quot;1730537287&amp;quot;</span>
<span class="c">#            },</span>
<span class="c">#            &amp;quot;creationTimestamp&amp;quot;: &amp;quot;2024-10-01T08:48:04Z&amp;quot;,</span>
<span class="c">#            &amp;quot;finalizers&amp;quot;: [</span>
<span class="c">#              &amp;quot;elbv2.k8s.aws/resources&amp;quot;</span>
<span class="c">#            ],</span>
<span class="c">#            &amp;quot;generation&amp;quot;: 1,</span>
<span class="c">#            &amp;quot;labels&amp;quot;: {</span>
<span class="c">#              &amp;quot;service.k8s.aws/stack-name&amp;quot;: &amp;quot;svc-nlb-ip-type&amp;quot;,</span>
<span class="c">#              &amp;quot;service.k8s.aws/stack-namespace&amp;quot;: &amp;quot;default&amp;quot;</span>
<span class="c">#            },</span>
<span class="c">#            &amp;quot;name&amp;quot;: &amp;quot;k8s-default-svcnlbip-f58255c318&amp;quot;,</span>
<span class="c">#            &amp;quot;namespace&amp;quot;: &amp;quot;default&amp;quot;,</span>
<span class="c">#            &amp;quot;resourceVersion&amp;quot;: &amp;quot;17369&amp;quot;,</span>
<span class="c">#            &amp;quot;uid&amp;quot;: &amp;quot;bdf37bcf-7fab-47ad-8b73-fb97c0239c9a&amp;quot;</span>
<span class="c">#          },</span>
<span class="c">#          &amp;quot;spec&amp;quot;: {</span>
<span class="c">#            &amp;quot;ipAddressType&amp;quot;: &amp;quot;ipv4&amp;quot;,</span>
<span class="c">#            &amp;quot;networking&amp;quot;: {</span>
<span class="c">#              &amp;quot;ingress&amp;quot;: [</span>
<span class="c">#                {</span>
<span class="c">#                  &amp;quot;from&amp;quot;: [</span>
<span class="c">#                    {</span>
<span class="c">#                      &amp;quot;securityGroup&amp;quot;: {</span>
<span class="c">#                        &amp;quot;groupID&amp;quot;: &amp;quot;sg-0a7a0dcdcda95c9fc&amp;quot;</span>
<span class="c">#                      }</span>
<span class="c">#                    }</span>
<span class="c">#                  ],</span>
<span class="c">#                  &amp;quot;ports&amp;quot;: [</span>
<span class="c">#                    {</span>
<span class="c">#                      &amp;quot;port&amp;quot;: 8080,</span>
<span class="c">#                      &amp;quot;protocol&amp;quot;: &amp;quot;TCP&amp;quot;</span>
<span class="c">#                    }</span>
<span class="c">#                  ]</span>
<span class="c">#                }</span>
<span class="c">#              ]</span>
<span class="c">#            },</span>
<span class="c">#            &amp;quot;serviceRef&amp;quot;: {</span>
<span class="c">#              &amp;quot;name&amp;quot;: &amp;quot;svc-nlb-ip-type&amp;quot;,</span>
<span class="c">#              &amp;quot;port&amp;quot;: 80</span>
<span class="c">#            },</span>
<span class="c">#            &amp;quot;targetGroupARN&amp;quot;: &amp;quot;arn:aws:elasticloadbalancing:ap-northeast-2:123456789012:targetgroup/k8s-default-svcnlbip-f58255c318/0cfa12d6c579f11b&amp;quot;,</span>
<span class="c">#            &amp;quot;targetType&amp;quot;: &amp;quot;ip&amp;quot;,</span>
<span class="c">#            &amp;quot;vpcID&amp;quot;: &amp;quot;vpc-0837921f515624150&amp;quot;</span>
<span class="c">#          },</span>
<span class="c">#          &amp;quot;status&amp;quot;: {</span>
<span class="c">#            &amp;quot;observedGeneration&amp;quot;: 1</span>
<span class="c">#          }</span>
<span class="c">#        }</span>
<span class="c">#      ],</span>
<span class="c">#      &amp;quot;kind&amp;quot;: &amp;quot;List&amp;quot;,</span>
<span class="c">#      &amp;quot;metadata&amp;quot;: {</span>
<span class="c">#        &amp;quot;resourceVersion&amp;quot;: &amp;quot;&amp;quot;</span>
<span class="c">#      }</span>
<span class="c">#    }</span>
  
<span class="c"># (옵션) 빠른 실습을 위해서 등록 취소 지연(드레이닝 간격) 수정 : 기본값 300초</span>
<span class="nv">$ </span>vi echo-service-nlb.yaml
<span class="nt">---</span>
..
apiVersion: v1
kind: Service
metadata:
  name: svc-nlb-ip-type
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: ip
    service.beta.kubernetes.io/aws-load-balancer-scheme: internet-facing
    service.beta.kubernetes.io/aws-load-balancer-healthcheck-port: <span class="s2">"8080"</span>
    service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: <span class="s2">"true"</span>
    service.beta.kubernetes.io/aws-load-balancer-target-group-attributes: deregistration_delay.timeout_seconds<span class="o">=</span>60
...
:wq!
<span class="nt">---</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> echo-service-nlb.yaml
<span class="c"># =&gt; deployment.apps/deploy-echo unchanged</span>
<span class="c">#    service/svc-nlb-ip-type configured</span>
  
<span class="c"># AWS ELB(NLB) 정보 확인</span>
<span class="nv">$ </span>aws elbv2 describe-load-balancers | jq
<span class="c"># =&gt; {</span>
<span class="c">#      &amp;quot;LoadBalancers&amp;quot;: [</span>
<span class="c">#        {</span>
<span class="c">#          &amp;quot;LoadBalancerArn&amp;quot;: &amp;quot;arn:aws:elasticloadbalancing:ap-northeast-2:123456789012:loadbalancer/net/k8s-default-svcnlbip-50f5d03f41/f28c6aa861a2e815&amp;quot;,</span>
<span class="c">#          &amp;quot;DNSName&amp;quot;: &amp;quot;k8s-default-svcnlbip-50f5d03f41-f28c6aa861a2e815.elb.ap-northeast-2.amazonaws.com&amp;quot;,</span>
<span class="c">#          &amp;quot;CanonicalHostedZoneId&amp;quot;: &amp;quot;ZIBE1TIR4HY56&amp;quot;,</span>
<span class="c">#          &amp;quot;CreatedTime&amp;quot;: &amp;quot;2024-10-01T08:48:03.532000+00:00&amp;quot;,</span>
<span class="c">#          &amp;quot;LoadBalancerName&amp;quot;: &amp;quot;k8s-default-svcnlbip-50f5d03f41&amp;quot;,</span>
<span class="c">#          &amp;quot;Scheme&amp;quot;: &amp;quot;internet-facing&amp;quot;,</span>
<span class="c">#          &amp;quot;VpcId&amp;quot;: &amp;quot;vpc-0837921f515624150&amp;quot;,</span>
<span class="c">#          &amp;quot;State&amp;quot;: {</span>
<span class="c">#            &amp;quot;Code&amp;quot;: &amp;quot;provisioning&amp;quot;</span>
<span class="c">#          },</span>
<span class="c">#          &amp;quot;Type&amp;quot;: &amp;quot;network&amp;quot;,</span>
<span class="c">#          &amp;quot;AvailabilityZones&amp;quot;: [</span>
<span class="c">#            {</span>
<span class="c">#              &amp;quot;ZoneName&amp;quot;: &amp;quot;ap-northeast-2a&amp;quot;,</span>
<span class="c">#              &amp;quot;SubnetId&amp;quot;: &amp;quot;subnet-0a06ed52d587bd707&amp;quot;,</span>
<span class="c">#              &amp;quot;LoadBalancerAddresses&amp;quot;: []</span>
<span class="c">#            },</span>
<span class="c">#            {</span>
<span class="c">#              &amp;quot;ZoneName&amp;quot;: &amp;quot;ap-northeast-2c&amp;quot;,</span>
<span class="c">#              &amp;quot;SubnetId&amp;quot;: &amp;quot;subnet-03c911c48452b41b2&amp;quot;,</span>
<span class="c">#              &amp;quot;LoadBalancerAddresses&amp;quot;: []</span>
<span class="c">#            },</span>
<span class="c">#            {</span>
<span class="c">#              &amp;quot;ZoneName&amp;quot;: &amp;quot;ap-northeast-2b&amp;quot;,</span>
<span class="c">#              &amp;quot;SubnetId&amp;quot;: &amp;quot;subnet-00b4dacf7eef35d33&amp;quot;,</span>
<span class="c">#              &amp;quot;LoadBalancerAddresses&amp;quot;: []</span>
<span class="c">#            }</span>
<span class="c">#          ],</span>
<span class="c">#          &amp;quot;SecurityGroups&amp;quot;: [</span>
<span class="c">#            &amp;quot;sg-0a7a0dcdcda95c9fc&amp;quot;,</span>
<span class="c">#            &amp;quot;sg-0e325a379a10ced56&amp;quot;</span>
<span class="c">#          ],</span>
<span class="c">#          &amp;quot;IpAddressType&amp;quot;: &amp;quot;ipv4&amp;quot;,</span>
<span class="c">#          &amp;quot;EnablePrefixForIpv6SourceNat&amp;quot;: &amp;quot;off&amp;quot;</span>
<span class="c">#        }</span>
<span class="c">#      ]</span>
<span class="c">#    }</span>
<span class="nv">$ </span>aws elbv2 describe-load-balancers <span class="nt">--query</span> <span class="s1">'LoadBalancers[*].State.Code'</span> <span class="nt">--output</span> text
<span class="c"># =&gt; provisioning</span>
<span class="nv">$ ALB_ARN</span><span class="o">=</span><span class="si">$(</span>aws elbv2 describe-load-balancers <span class="nt">--query</span> <span class="s1">'LoadBalancers[?contains(LoadBalancerName, `k8s-default-svcnlbip`) == `true`].LoadBalancerArn'</span> | jq <span class="nt">-r</span> <span class="s1">'.[0]'</span><span class="si">)</span>
<span class="nv">$ </span>aws elbv2 describe-target-groups <span class="nt">--load-balancer-arn</span> <span class="nv">$ALB_ARN</span> | jq
<span class="c"># =&gt; {</span>
<span class="c">#      &amp;quot;TargetGroups&amp;quot;: [</span>
<span class="c">#        {</span>
<span class="c">#          &amp;quot;TargetGroupArn&amp;quot;: &amp;quot;arn:aws:elasticloadbalancing:ap-northeast-2:123456789012:targetgroup/k8s-default-svcnlbip-f58255c318/0cfa12d6c579f11b&amp;quot;,</span>
<span class="c">#          &amp;quot;TargetGroupName&amp;quot;: &amp;quot;k8s-default-svcnlbip-f58255c318&amp;quot;,</span>
<span class="c">#          &amp;quot;Protocol&amp;quot;: &amp;quot;TCP&amp;quot;,</span>
<span class="c">#          &amp;quot;Port&amp;quot;: 8080,</span>
<span class="c">#          &amp;quot;VpcId&amp;quot;: &amp;quot;vpc-0837921f515624150&amp;quot;,</span>
<span class="c">#          &amp;quot;HealthCheckProtocol&amp;quot;: &amp;quot;TCP&amp;quot;,</span>
<span class="c">#          &amp;quot;HealthCheckPort&amp;quot;: &amp;quot;8080&amp;quot;,</span>
<span class="c">#          &amp;quot;HealthCheckEnabled&amp;quot;: true,</span>
<span class="c">#          &amp;quot;HealthCheckIntervalSeconds&amp;quot;: 10,</span>
<span class="c">#          &amp;quot;HealthCheckTimeoutSeconds&amp;quot;: 10,</span>
<span class="c">#          &amp;quot;HealthyThresholdCount&amp;quot;: 3,</span>
<span class="c">#          &amp;quot;UnhealthyThresholdCount&amp;quot;: 3,</span>
<span class="c">#          &amp;quot;LoadBalancerArns&amp;quot;: [</span>
<span class="c">#            &amp;quot;arn:aws:elasticloadbalancing:ap-northeast-2:123456789012:loadbalancer/net/k8s-default-svcnlbip-50f5d03f41/f28c6aa861a2e815&amp;quot;</span>
<span class="c">#          ],</span>
<span class="c">#          &amp;quot;TargetType&amp;quot;: &amp;quot;ip&amp;quot;,</span>
<span class="c">#          &amp;quot;IpAddressType&amp;quot;: &amp;quot;ipv4&amp;quot;</span>
<span class="c">#        }</span>
<span class="c">#      ]</span>
<span class="c">#    }</span>
<span class="nv">$ TARGET_GROUP_ARN</span><span class="o">=</span><span class="si">$(</span>aws elbv2 describe-target-groups <span class="nt">--load-balancer-arn</span> <span class="nv">$ALB_ARN</span> | jq <span class="nt">-r</span> <span class="s1">'.TargetGroups[0].TargetGroupArn'</span><span class="si">)</span>
<span class="nv">$ </span>aws elbv2 describe-target-health <span class="nt">--target-group-arn</span> <span class="nv">$TARGET_GROUP_ARN</span> | jq
<span class="c"># =&gt; {</span>
<span class="c">#      &amp;quot;TargetHealthDescriptions&amp;quot;: [</span>
<span class="c">#        {</span>
<span class="c">#          &amp;quot;Target&amp;quot;: {</span>
<span class="c">#            &amp;quot;Id&amp;quot;: &amp;quot;192.168.2.24&amp;quot;,</span>
<span class="c">#            &amp;quot;Port&amp;quot;: 8080,</span>
<span class="c">#            &amp;quot;AvailabilityZone&amp;quot;: &amp;quot;ap-northeast-2b&amp;quot;</span>
<span class="c">#          },</span>
<span class="c">#          &amp;quot;HealthCheckPort&amp;quot;: &amp;quot;8080&amp;quot;,</span>
<span class="c">#          &amp;quot;TargetHealth&amp;quot;: {</span>
<span class="c">#            &amp;quot;State&amp;quot;: &amp;quot;healthy&amp;quot;</span>
<span class="c">#          },</span>
<span class="c">#          &amp;quot;AdministrativeOverride&amp;quot;: {</span>
<span class="c">#            &amp;quot;State&amp;quot;: &amp;quot;no_override&amp;quot;,</span>
<span class="c">#            &amp;quot;Reason&amp;quot;: &amp;quot;AdministrativeOverride.NoOverride&amp;quot;,</span>
<span class="c">#            &amp;quot;Description&amp;quot;: &amp;quot;No override is currently active on target&amp;quot;</span>
<span class="c">#          }</span>
<span class="c">#        },</span>
<span class="c">#        {</span>
<span class="c">#          &amp;quot;Target&amp;quot;: {</span>
<span class="c">#            &amp;quot;Id&amp;quot;: &amp;quot;192.168.1.112&amp;quot;,</span>
<span class="c">#            &amp;quot;Port&amp;quot;: 8080,</span>
<span class="c">#            &amp;quot;AvailabilityZone&amp;quot;: &amp;quot;ap-northeast-2a&amp;quot;</span>
<span class="c">#          },</span>
<span class="c">#          &amp;quot;HealthCheckPort&amp;quot;: &amp;quot;8080&amp;quot;,</span>
<span class="c">#          &amp;quot;TargetHealth&amp;quot;: {</span>
<span class="c">#            &amp;quot;State&amp;quot;: &amp;quot;initial&amp;quot;,</span>
<span class="c">#            &amp;quot;Reason&amp;quot;: &amp;quot;Elb.InitialHealthChecking&amp;quot;,</span>
<span class="c">#            &amp;quot;Description&amp;quot;: &amp;quot;Initial health checks in progress&amp;quot;</span>
<span class="c">#          },</span>
<span class="c">#          &amp;quot;AdministrativeOverride&amp;quot;: {</span>
<span class="c">#            &amp;quot;State&amp;quot;: &amp;quot;no_override&amp;quot;,</span>
<span class="c">#            &amp;quot;Reason&amp;quot;: &amp;quot;AdministrativeOverride.NoOverride&amp;quot;,</span>
<span class="c">#            &amp;quot;Description&amp;quot;: &amp;quot;No override is currently active on target&amp;quot;</span>
<span class="c">#          }</span>
<span class="c">#        }</span>
<span class="c">#      ]</span>
<span class="c">#    }</span>
  
<span class="c"># 웹 접속 주소 확인</span>
<span class="nv">$ </span>kubectl get svc svc-nlb-ip-type <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.status.loadBalancer.ingress[0].hostname<span class="o">}</span> | <span class="nb">awk</span> <span class="s1">'{ print "Pod Web URL = http://"$1 }'</span>
<span class="c"># =&gt; Pod Web URL = http://k8s-default-svcnlbip-50f5d03f41-f28c6aa861a2e815.elb.ap-northeast-2.amazonaws.com</span>
  
<span class="c"># 파드 로깅 모니터링</span>
<span class="nv">$ </span>kubectl logs <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>deploy-websrv <span class="nt">-f</span>
  
<span class="c"># 분산 접속 확인</span>
<span class="nv">$ NLB</span><span class="o">=</span><span class="si">$(</span>kubectl get svc svc-nlb-ip-type <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.status.loadBalancer.ingress[0].hostname<span class="o">}</span><span class="si">)</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$NLB</span>
<span class="c"># =&gt; Hostname: deploy-echo-857b6cfb88-5xz5j</span>
<span class="c">#    </span>
<span class="c">#    Pod Information:</span>
<span class="c">#     -no pod information available-</span>
<span class="c">#    </span>
<span class="c">#    Server values:</span>
<span class="c">#     server_version=nginx: 1.13.0 - lua: 10008</span>
<span class="c">#    </span>
<span class="c">#    Request Information:</span>
<span class="c">#     client_address=192.168.3.171</span>
<span class="c">#     method=GET</span>
<span class="c">#     real path=/</span>
<span class="c">#     query=</span>
<span class="c">#     request_version=1.1</span>
<span class="c">#     request_uri=http://k8s-default-svcnlbip-50f5d03f41-f28c6aa861a2e815.elb.ap-northeast-2.amazonaws.com:8080/</span>
<span class="c">#    </span>
<span class="c">#    Request Headers:</span>
<span class="c">#     accept=*/*</span>
<span class="c">#     host=k8s-default-svcnlbip-50f5d03f41-f28c6aa861a2e815.elb.ap-northeast-2.amazonaws.com</span>
<span class="c">#     user-agent=curl/8.3.0</span>
<span class="c">#    </span>
<span class="c">#    Request Body:</span>
<span class="c">#     -no body in request-</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$NLB</span> | <span class="nb">grep </span>Hostname <span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt; 52 Hostname: deploy-echo-857b6cfb88-452cd</span>
<span class="c">#    48 Hostname: deploy-echo-857b6cfb88-5xz5j</span>
  
<span class="c"># 지속적인 접속 시도 : 아래 상세 동작 확인 시 유용(패킷 덤프 등)</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 <span class="nv">$NLB</span> | egrep <span class="s1">'Hostname|client_address'</span><span class="p">;</span> <span class="nb">echo</span> <span class="s2">"----------"</span> <span class="p">;</span> <span class="nb">date</span> <span class="s2">"+%Y-%m-%d %H:%M:%S"</span> <span class="p">;</span> <span class="nb">sleep </span>1<span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; Hostname: deploy-echo-857b6cfb88-5xz5j</span>
<span class="c">#     client_address=192.168.1.39</span>
<span class="c">#    ----------</span>
<span class="c">#    2024-10-01 17:52:08</span>
<span class="c">#    Hostname: deploy-echo-857b6cfb88-452cd</span>
<span class="c">#     client_address=192.168.3.171</span>
<span class="c">#    ----------</span>
<span class="c">#    2024-10-01 17:52:09</span>
<span class="c">#    Hostname: deploy-echo-857b6cfb88-5xz5j</span>
<span class="c">#     client_address=192.168.1.39</span>
<span class="c">#    ----------</span>
<span class="c">#    2024-10-01 17:52:10</span>
<span class="c">#    Hostname: deploy-echo-857b6cfb88-452cd</span>
<span class="c">#     client_address=192.168.3.171</span>
<span class="c">#    ...</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>파드 2개 → 1개 → 3개 설정 시 동작을 확인해보겠습니다. 파드의 IP가 auto discovery되는데 이것은 service에 엔드포인트 정보를 사용한 것입니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># (신규 터미널) 모니터링</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>aws elbv2 describe-target-health <span class="nt">--target-group-arn</span> <span class="nv">$TARGET_GROUP_ARN</span> <span class="nt">--output</span> text<span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; TARGETHEALTHDESCRIPTIONS 8080</span>
<span class="c">#    ADMINISTRATIVEOVERRIDE No override is currently active on target AdministrativeOverride.NoOverride no_override</span>
<span class="c">#    TARGET ap-northeast-2b 192.168.2.24  8080</span>
<span class="c">#    TARGETHEALTH healthy</span>
<span class="c">#    TARGETHEALTHDESCRIPTIONS 8080</span>
<span class="c">#    ADMINISTRATIVEOVERRIDE No override is currently active on target AdministrativeOverride.NoOverride no_override</span>
<span class="c">#    TARGET ap-northeast-2a 192.168.1.112 8080</span>
<span class="c">#    TARGETHEALTH healthy</span>
<span class="c">#    ...</span>
    
<span class="c"># 작업용 EC2 - 파드 1개 설정 </span>
<span class="nv">$ </span>kubectl scale deployment deploy-echo <span class="nt">--replicas</span><span class="o">=</span>1
    
<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get deploy,pod,svc,ep
<span class="c"># =&gt; NAME                          READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/deploy-echo   1/1     1            1           6m34s</span>
<span class="c">#    </span>
<span class="c">#    NAME                               READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/deploy-echo-857b6cfb88-452cd   1/1     Running   0          6m34s</span>
<span class="c">#    </span>
<span class="c">#    NAME                      TYPE           CLUSTER-IP      EXTERNAL-IP                                                                         PORT(S)        AGE</span>
<span class="c">#    service/kubernetes        ClusterIP      10.100.0.1      &amp;lt;none&amp;gt;                                                                              443/TCP        82m</span>
<span class="c">#    service/svc-nlb-ip-type   LoadBalancer   10.100.83.184   k8s-default-svcnlbip-50f5d03f41-f28c6aa861a2e815.elb.ap-northeast-2.amazonaws.com   80:30771/TCP   6m34s</span>
<span class="c">#    </span>
<span class="c">#    NAME                        ENDPOINTS                            AGE</span>
<span class="c">#    endpoints/kubernetes        192.168.1.65:443,192.168.3.189:443   82m</span>
<span class="c">#    endpoints/svc-nlb-ip-type   192.168.2.24:8080                    6m34s</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$NLB</span>
<span class="c"># =&gt; Hostname: deploy-echo-857b6cfb88-452cd</span>
<span class="c">#    </span>
<span class="c">#    Pod Information:</span>
<span class="c">#     -no pod information available-</span>
<span class="c">#    </span>
<span class="c">#    Server values:</span>
<span class="c">#     server_version=nginx: 1.13.0 - lua: 10008</span>
<span class="c">#    </span>
<span class="c">#    Request Information:</span>
<span class="c">#     client_address=192.168.3.171</span>
<span class="c">#     method=GET</span>
<span class="c">#     real path=/</span>
<span class="c">#     query=</span>
<span class="c">#     request_version=1.1</span>
<span class="c">#     request_uri=http://k8s-default-svcnlbip-50f5d03f41-f28c6aa861a2e815.elb.ap-northeast-2.amazonaws.com:8080/</span>
<span class="c">#    </span>
<span class="c">#    Request Headers:</span>
<span class="c">#     accept=*/*</span>
<span class="c">#     host=k8s-default-svcnlbip-50f5d03f41-f28c6aa861a2e815.elb.ap-northeast-2.amazonaws.com</span>
<span class="c">#     user-agent=curl/8.3.0</span>
<span class="c">#    </span>
<span class="c">#    Request Body:</span>
<span class="c">#     -no body in request-</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 <span class="nv">$NLB</span> | <span class="nb">grep </span>Hostname <span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;     100 Hostname: deploy-echo-857b6cfb88-452cd</span>
    
<span class="c"># 작업용 EC2 - 파드 3개 설정 </span>
<span class="nv">$ </span>kubectl scale deployment deploy-echo <span class="nt">--replicas</span><span class="o">=</span>3
<span class="c"># =&gt; deployment.apps/deploy-echo scaled</span>
    
<span class="c"># 확인 : NLB 대상 타켓이 아직 initial 일 때 100번 반복 접속 시 어떻게 되는지 확인해보자!</span>
<span class="nv">$ </span>kubectl get deploy,pod,svc,ep
<span class="c"># =&gt; NAME                          READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/deploy-echo   3/3     3            3           7m41s</span>
<span class="c">#    </span>
<span class="c">#    NAME                               READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    ...</span>
<span class="c">#    pod/deploy-echo-857b6cfb88-8wn7b   1/1     Running   0          10s</span>
<span class="c">#    pod/deploy-echo-857b6cfb88-qhqbt   1/1     Running   0          10s</span>
<span class="c">#    </span>
<span class="c">#    ...</span>
<span class="c">#    </span>
<span class="c">#    NAME                        ENDPOINTS                                                 AGE</span>
<span class="c">#    ...</span>
<span class="c">#    endpoints/svc-nlb-ip-type   192.168.1.161:8080,192.168.2.24:8080,192.168.3.241:8080   7m41s</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$NLB</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 <span class="nv">$NLB</span> | <span class="nb">grep </span>Hostname <span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;      37 Hostname: deploy-echo-857b6cfb88-452cd</span>
<span class="c">#         33 Hostname: deploy-echo-857b6cfb88-8wn7b</span>
<span class="c">#         30 Hostname: deploy-echo-857b6cfb88-qhqbt</span>
    
<span class="c"># </span>
<span class="nv">$ </span>kubectl describe deploy <span class="nt">-n</span> kube-system aws-load-balancer-controller | <span class="nb">grep</span> <span class="nt">-i</span> <span class="s1">'Service Account'</span>
<span class="c"># =&gt;   Service Account:  aws-load-balancer-controller</span>
    
<span class="c"># [AWS LB Ctrl] 클러스터 롤 바인딩 정보 확인</span>
<span class="nv">$ </span>kubectl describe clusterrolebindings.rbac.authorization.k8s.io aws-load-balancer-controller-rolebinding
    
<span class="c"># [AWS LB Ctrl] 클러스터롤 확인 </span>
<span class="nv">$ </span>kubectl describe clusterroles.rbac.authorization.k8s.io aws-load-balancer-controller-role
</code></pre></div>    </div>

    <ul>
      <li>실습 리소스 삭제:  <code class="language-plaintext highlighter-rouge">kubectl delete deploy deploy-echo; kubectl delete svc svc-nlb-ip-type</code></li>
    </ul>
  </li>
  <li><strong>(심화) Pod readiness gate</strong> : ALB/NLB 대상(ip mode)이 ALB/NLB의 헬스체크에 의해 정상일 경우 해당 파드로 전달할 수 있는 기능입니다. - <a href="https://kubernetes-sigs.github.io/aws-load-balancer-controller/v2.7/deploy/pod_readiness_gate/">Link</a> <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#pod-readiness-gate">K8S</a>
    <ul>
      <li>
        <p>사전 준비</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 바로 위에서 실습 리소스 삭제했다면, 다시 생성 : deregistration_delay.timeout_seconds=60 확인</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> echo-service-nlb.yaml
<span class="c"># =&gt; deployment.apps/deploy-echo created</span>
<span class="c">#    service/svc-nlb-ip-type created</span>
<span class="nv">$ </span>kubectl scale deployment deploy-echo <span class="nt">--replicas</span><span class="o">=</span>1
<span class="c"># =&gt; deployment.apps/deploy-echo scaled</span>
    
<span class="c">#</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                           READY   STATUS    RESTARTS   AGE   IP              NODE                                               NOMINATED NODE   READINESS GATES</span>
<span class="c">#    deploy-echo-857b6cfb88-sx8lg   1/1     Running   0          14m   192.168.3.124   ip-192-168-3-235.ap-northeast-2.compute.internal   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
    
<span class="c"># mutatingwebhookconfigurations 확인 : mutating 대상(네임스페이스에 아래 매칭 시)</span>
<span class="nv">$ </span>kubectl get mutatingwebhookconfigurations
<span class="c"># =&gt; NAME                            WEBHOOKS   AGE</span>
<span class="c">#    aws-load-balancer-webhook       3          28m</span>
<span class="c">#    pod-identity-webhook            1          102m</span>
<span class="c">#    vpc-resource-mutating-webhook   1          102m</span>
<span class="nv">$ </span>kubectl get mutatingwebhookconfigurations aws-load-balancer-webhook <span class="nt">-o</span> yaml | kubectl neat
<span class="c"># =&gt; ...</span>
<span class="c">#      name: mpod.elbv2.k8s.aws</span>
<span class="c">#      namespaceSelector:</span>
<span class="c">#        matchExpressions:</span>
<span class="c">#        - key: elbv2.k8s.aws/pod-readiness-gate-inject</span>
<span class="c">#          operator: In</span>
<span class="c">#          values:</span>
<span class="c">#          - enabled</span>
<span class="c">#      objectSelector:</span>
<span class="c">#        matchExpressions:</span>
<span class="c">#        - key: app.kubernetes.io/name</span>
<span class="c">#          operator: NotIn</span>
<span class="c">#          values:</span>
<span class="c">#          - aws-load-balancer-controller</span>
<span class="c">#    ...</span>
    
<span class="c"># 현재 확인</span>
<span class="nv">$ </span>kubectl get ns <span class="nt">--show-labels</span>
<span class="c"># =&gt; NAME              STATUS   AGE    LABELS</span>
<span class="c">#    default           Active   103m   kubernetes.io/metadata.name=default</span>
<span class="c">#    kube-node-lease   Active   103m   kubernetes.io/metadata.name=kube-node-lease</span>
<span class="c">#    kube-public       Active   103m   kubernetes.io/metadata.name=kube-public</span>
<span class="c">#    kube-system       Active   103m   kubernetes.io/metadata.name=kube-system</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p>설정 및 확인</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># (터미널 각각 2개) 모니터링</span>
<span class="nv">$ ALB_ARN</span><span class="o">=</span><span class="si">$(</span>aws elbv2 describe-load-balancers <span class="nt">--query</span> <span class="s1">'LoadBalancers[?contains(LoadBalancerName, `k8s-default-svcnlbip`) == `true`].LoadBalancerArn'</span> | jq <span class="nt">-r</span> <span class="s1">'.[0]'</span><span class="si">)</span>
<span class="nv">$ TARGET_GROUP_ARN</span><span class="o">=</span><span class="si">$(</span>aws elbv2 describe-target-groups <span class="nt">--load-balancer-arn</span> <span class="nv">$ALB_ARN</span> | jq <span class="nt">-r</span> <span class="s1">'.TargetGroups[0].TargetGroupArn'</span><span class="si">)</span>
    
<span class="nv">$ </span>watch <span class="nt">-d</span> kubectl get pod,svc,ep <span class="nt">-owide</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>aws elbv2 describe-target-health <span class="nt">--target-group-arn</span> <span class="nv">$TARGET_GROUP_ARN</span> <span class="nt">--output</span> text<span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
    
<span class="c">#</span>
<span class="nv">$ </span>kubectl label namespace default elbv2.k8s.aws/pod-readiness-gate-inject<span class="o">=</span>enabled
<span class="c"># =&gt; namespace/default labeled</span>
<span class="nv">$ </span>kubectl get ns <span class="nt">--show-labels</span>
<span class="c"># =&gt; NAME              STATUS   AGE    LABELS</span>
<span class="c">#    default           Active   108m   elbv2.k8s.aws/pod-readiness-gate-inject=enabled,kubernetes.io/metadata.name=default</span>
<span class="c">#    kube-node-lease   Active   108m   kubernetes.io/metadata.name=kube-node-lease</span>
<span class="c">#    kube-public       Active   108m   kubernetes.io/metadata.name=kube-public</span>
<span class="c">#    kube-system       Active   108m   kubernetes.io/metadata.name=kube-system</span>
    
<span class="c"># READINESS GATES 항목 추가 확인</span>
<span class="nv">$ </span>kubectl describe pod
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                           READY   STATUS    RESTARTS   AGE   IP              NODE                                               NOMINATED NODE   READINESS GATES</span>
<span class="c">#    deploy-echo-857b6cfb88-sx8lg   1/1     Running   0          20m   192.168.3.124   ip-192-168-3-235.ap-northeast-2.compute.internal   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
    
<span class="c">#</span>
<span class="nv">$ </span>kubectl delete pod <span class="nt">--all</span>
<span class="c"># =&gt; pod &amp;quot;deploy-echo-857b6cfb88-sx8lg&amp;quot; deleted</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                           READY   STATUS    RESTARTS   AGE   IP             NODE                                              NOMINATED NODE   READINESS GATES</span>
<span class="c">#    deploy-echo-857b6cfb88-njwdj   1/1     Running   0          54s   192.168.2.18   ip-192-168-2-92.ap-northeast-2.compute.internal   &amp;lt;none&amp;gt;           1/1</span>
    
<span class="nv">$ </span>kubectl describe pod
<span class="c"># =&gt; ...</span>
<span class="c">#    Readiness Gates:</span>
<span class="c">#      Type                                                          Status</span>
<span class="c">#      target-health.elbv2.k8s.aws/k8s-default-svcnlbip-2e5acb9719   True</span>
<span class="c">#    Conditions:</span>
<span class="c">#      Type                                                          Status</span>
<span class="c">#      target-health.elbv2.k8s.aws/k8s-default-svcnlbip-2e5acb9719   True</span>
<span class="c">#      PodReadyToStartContainers                                     True</span>
<span class="c">#      Initialized                                                   True</span>
<span class="c">#      Ready                                                         True</span>
<span class="c">#      ContainersReady                                               True</span>
<span class="c">#      PodScheduled                                                  True</span>
<span class="c">#      ...</span>
    
<span class="nv">$ </span>kubectl get pod <span class="nt">-o</span> yaml | yh
<span class="c"># =&gt; ...</span>
<span class="c">#        readinessGates:</span>
<span class="c">#        - conditionType: target-health.elbv2.k8s.aws/k8s-default-svcnlbip-2e5acb9719</span>
<span class="c">#    ...</span>
<span class="c">#      status:</span>
<span class="c">#        conditions:</span>
<span class="c">#        - lastProbeTime: null</span>
<span class="c">#          lastTransitionTime: &amp;quot;2024-10-01T09:21:28Z&amp;quot;</span>
<span class="c">#          status: &amp;quot;True&amp;quot;</span>
<span class="c">#          type: target-health.elbv2.k8s.aws/k8s-default-svcnlbip-2e5acb9719</span>
<span class="c">#    ...</span>
    
<span class="c"># 분산 접속 확인</span>
<span class="nv">$ NLB</span><span class="o">=</span><span class="si">$(</span>kubectl get svc svc-nlb-ip-type <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.status.loadBalancer.ingress[0].hostname<span class="o">}</span><span class="si">)</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$NLB</span>
<span class="c"># =&gt; Hostname: deploy-echo-857b6cfb88-njwdj</span>
<span class="c">#    </span>
<span class="c">#    Pod Information:</span>
<span class="c">#     -no pod information available-</span>
<span class="c">#    </span>
<span class="c">#    Server values:</span>
<span class="c">#     server_version=nginx: 1.13.0 - lua: 10008</span>
<span class="c">#    </span>
<span class="c">#    Request Information:</span>
<span class="c">#     client_address=192.168.3.71</span>
<span class="c">#     method=GET</span>
<span class="c">#     real path=/</span>
<span class="c">#     query=</span>
<span class="c">#     request_version=1.1</span>
<span class="c">#     request_uri=http://k8s-default-svcnlbip-f4c21d9697-0d3512de2bf74357.elb.ap-northeast-2.amazonaws.com:8080/</span>
<span class="c">#    </span>
<span class="c">#    Request Headers:</span>
<span class="c">#     accept=*/*</span>
<span class="c">#     host=k8s-default-svcnlbip-f4c21d9697-0d3512de2bf74357.elb.ap-northeast-2.amazonaws.com</span>
<span class="c">#     user-agent=curl/8.3.0</span>
<span class="c">#    </span>
<span class="c">#    Request Body:</span>
<span class="c">#     -no body in request-</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$NLB</span> | <span class="nb">grep </span>Hostname <span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;     100 Hostname: deploy-echo-857b6cfb88-njwdj</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p>실습 리소스 삭제:  <code class="language-plaintext highlighter-rouge">kubectl delete deploy deploy-echo; kubectl delete svc svc-nlb-ip-type</code></p>
      </li>
    </ul>
  </li>
  <li>NLB 대상 타켓을 <strong>Instance mode</strong> 로 설정해보기
    <ul>
      <li>다음 링크에서 확인해볼 수 있습니다.
<a href="https://www.notion.so/AWS-NLB-Client-IP-Proxy-protocol-57827e2c83fc474992b37e65db81f669?pvs=21">AWS NLB - Client IP 확인 &amp; Proxy protocol</a></li>
    </ul>
  </li>
  <li>
    <p>NLB IP Target &amp; <strong>Proxy Protocol v2</strong> 활성화 : NLB에서 바로 파드로 인입 및 ClientIP 확인 설정 - <a href="https://www.notion.so/AWS-NLB-Client-IP-Proxy-protocol-57827e2c83fc474992b37e65db81f669?pvs=21">링크</a> <a href="https://hub.docker.com/r/gasida/httpd/tags">image</a> <a href="https://canaryrelease.tistory.com/42">참고</a></p>

    <p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_25.png" alt="img_9.png" class="image-center w-90" /></p>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 생성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: gasida-web
spec:
  replicas: 1
  selector:
    matchLabels:
      app: gasida-web
  template:
    metadata:
      labels:
        app: gasida-web
    spec:
      terminationGracePeriodSeconds: 0
      containers:
      - name: gasida-web
        image: sweetlittlebird/httpd:pp
        ports:
        - containerPort: 8080
---
apiVersion: v1
kind: Service
metadata:
  name: svc-nlb-ip-type-pp
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: ip
    service.beta.kubernetes.io/aws-load-balancer-scheme: internet-facing
    service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: "true"
    service.beta.kubernetes.io/aws-load-balancer-proxy-protocol: "*"
spec:
  ports:
    - port: 80
      targetPort: 80
      protocol: TCP
  type: LoadBalancer
  loadBalancerClass: service.k8s.aws/nlb
  selector:
    app: gasida-web
</span><span class="no">EOF
</span><span class="c"># =&gt; deployment.apps/gasida-web created</span>
<span class="c">#    service/svc-nlb-ip-type-pp created</span>

<span class="c"># apache에 proxy protocol 활성화 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>deploy/gasida-web <span class="nt">--</span> apachectl <span class="nt">-t</span> <span class="nt">-D</span> DUMP_MODULES
<span class="c"># =&gt; Loaded Modules:</span>
<span class="c">#     ...</span>
<span class="c">#     remoteip_module (shared)</span>
<span class="c">#     ...</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>deploy/gasida-web <span class="nt">--</span> <span class="nb">cat</span> /usr/local/apache2/conf/httpd.conf
<span class="c"># =&gt; ...</span>
<span class="c">#    RemoteIPProxyProtocol On</span>
<span class="c">#    ...</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get svc,ep
<span class="c"># =&gt; NAME                         TYPE           CLUSTER-IP       EXTERNAL-IP                                                                         PORT(S)        AGE</span>
<span class="c">#    service/kubernetes           ClusterIP      10.100.0.1       &amp;lt;none&amp;gt;                                                                              443/TCP        5h52m</span>
<span class="c">#    service/svc-nlb-ip-type-pp   LoadBalancer   10.100.160.172   k8s-default-svcnlbip-c11e4bd02e-ec82d8f688f176d3.elb.ap-northeast-2.amazonaws.com   80:31348/TCP   36m</span>
<span class="c">#    </span>
<span class="c">#    NAME                           ENDPOINTS                            AGE</span>
<span class="c">#    endpoints/kubernetes           192.168.1.65:443,192.168.3.189:443   5h52m</span>
<span class="c">#    endpoints/svc-nlb-ip-type-pp   192.168.2.51:80                      36m</span>
<span class="nv">$ </span>kubectl describe svc svc-nlb-ip-type-pp
<span class="nv">$ </span>kubectl describe svc svc-nlb-ip-type-pp | <span class="nb">grep </span>Annotations: <span class="nt">-A5</span>
<span class="c"># =&gt; Annotations: service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: true</span>
<span class="c">#                 service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: ip   # &lt;span style="color: green;"&gt;👉 NLB Target Type이 IP입니다.&lt;/span&gt;</span>
<span class="c">#                 service.beta.kubernetes.io/aws-load-balancer-proxy-protocol: *</span>
<span class="c">#                 service.beta.kubernetes.io/aws-load-balancer-scheme: internet-facing</span>
<span class="c">#    Selector:    app=gasida-web</span>
<span class="c">#    Type:        LoadBalancer</span>

<span class="c"># 접속 확인</span>
<span class="nv">$ NLB</span><span class="o">=</span><span class="si">$(</span>kubectl get svc svc-nlb-ip-type-pp <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.status.loadBalancer.ingress[0].hostname<span class="o">}</span><span class="si">)</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$NLB</span>
<span class="c"># =&gt; &amp;lt;html&amp;gt;&amp;lt;body&amp;gt;&amp;lt;h1&amp;gt;It works!&amp;lt;/h1&amp;gt;&amp;lt;/body&amp;gt;&amp;lt;/html&amp;gt;</span>

<span class="c"># 지속적인 접속 시도 : 아래 상세 동작 확인 시 유용(패킷 덤프 등)</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 <span class="nv">$NLB</span><span class="p">;</span> <span class="nb">echo</span> <span class="s2">"----------"</span> <span class="p">;</span> <span class="nb">date</span> <span class="s2">"+%Y-%m-%d %H:%M:%S"</span> <span class="p">;</span> <span class="nb">sleep </span>1<span class="p">;</span> <span class="k">done</span>

<span class="c"># 베스쳔 호스트 IP 확인</span>
<span class="nv">$ </span>curl ipinfo.io/ip
<span class="c"># =&gt; 3.35.140.75</span>

<span class="c"># 로그 확인</span>
<span class="nv">$ </span>kubectl logs <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>gasida-web <span class="nt">-f</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    3.35.140.75 - - [01/Oct/2024:13:46:35 +0000] &amp;quot;GET / HTTP/1.1&amp;quot; 200 45</span>
<span class="c">#    3.35.140.75 - - [01/Oct/2024:13:46:36 +0000] &amp;quot;GET / HTTP/1.1&amp;quot; 200 45</span>
<span class="c">#    3.35.140.75 - - [01/Oct/2024:13:46:37 +0000] &amp;quot;GET / HTTP/1.1&amp;quot; 200 45</span>
<span class="c">#    3.35.140.75 - - [01/Oct/2024:13:46:38 +0000] &amp;quot;GET / HTTP/1.1&amp;quot; 200 45</span>

<span class="c"># &lt;span style="color: green;"&gt;👉 proxy protocol을 통해 외부 클라이언트의 IP가 전달되어 로그에 남는것을 확인할 수 있었습니다.&lt;/span&gt;</span>

<span class="c"># 삭제</span>
<span class="nv">$ </span>kubectl delete deploy gasida-web<span class="p">;</span> kubectl delete svc svc-nlb-ip-type-pp
</code></pre></div></div>

<hr />

<h3 id="ingress">Ingress</h3>

<ul>
  <li>Ingress는 클러스터 내부의 서비스(ClusterIP, NodePort, Loadbalancer)를 외부로 노출(<strong>HTTP/HTTPS</strong>)시키는 일종의 Web Proxy 역할을 수행합니다.</li>
</ul>

<h4 id="aws-load-balancer-controller--ingress-alb-ip-모드-동작-with-aws-vpc-cni"><strong>AWS Load Balancer Controller</strong> + <strong>Ingress (ALB) IP 모드</strong> 동작 with <strong>AWS VPC CNI</strong></h4>

<p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_11.png" alt="img.png" class="image-center w-90" /></p>

<ul>
  <li>
    <p>서비스/파드 배포 테스트 with Ingress(ALB) - <a href="https://docs.aws.amazon.com/eks/latest/userguide/alb-ingress.html">ALB</a></p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 게임 파드와 Service, Ingress 배포</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nt">-O</span> https://raw.githubusercontent.com/gasida/PKOS/main/3/ingress1.yaml
<span class="nv">$ </span><span class="nb">cat </span>ingress1.yaml
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> ingress1.yaml
<span class="c"># =&gt; namespace/game-2048 created</span>
<span class="c">#    deployment.apps/deployment-2048 created</span>
<span class="c">#    service/service-2048 created</span>
<span class="c">#    ingress.networking.k8s.io/ingress-2048 created</span>
  
<span class="c"># 모니터링</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> kubectl get pod,ingress,svc,ep <span class="nt">-n</span> game-2048
  
<span class="c"># 생성 확인</span>
<span class="nv">$ </span>kubectl get-all <span class="nt">-n</span> game-2048
<span class="c"># =&gt; NAME                                                               NAMESPACE  AGE</span>
<span class="c">#    configmap/kube-root-ca.crt                                         game-2048  38s</span>
<span class="c">#    endpoints/service-2048                                             game-2048  38s</span>
<span class="c">#    pod/deployment-2048-85f8c7d69-gz295                                game-2048  38s</span>
<span class="c">#    pod/deployment-2048-85f8c7d69-t2blb                                game-2048  38s</span>
<span class="c">#    serviceaccount/default                                             game-2048  38s</span>
<span class="c">#    service/service-2048                                               game-2048  38s</span>
<span class="c">#    deployment.apps/deployment-2048                                    game-2048  38s</span>
<span class="c">#    replicaset.apps/deployment-2048-85f8c7d69                          game-2048  38s</span>
<span class="c">#    endpointslice.discovery.k8s.io/service-2048-s58q4                  game-2048  38s</span>
<span class="c">#    targetgroupbinding.elbv2.k8s.aws/k8s-game2048-service2-00c3b27023  game-2048  34s</span>
<span class="c">#    ingress.networking.k8s.io/ingress-2048                             game-2048  38s</span>
<span class="nv">$ </span>kubectl get ingress,svc,ep,pod <span class="nt">-n</span> game-2048
<span class="c"># =&gt; NAME                                     CLASS   HOSTS   ADDRESS                                                                       PORTS   AGE</span>
<span class="c">#    ingress.networking.k8s.io/ingress-2048   alb     *       k8s-game2048-ingress2-70d50ce3fd-333540411.ap-northeast-2.elb.amazonaws.com   80      49s</span>
<span class="c">#    </span>
<span class="c">#    NAME                   TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE</span>
<span class="c">#    service/service-2048   NodePort   10.100.41.151   &amp;lt;none&amp;gt;        80:32522/TCP   49s</span>
<span class="c">#    </span>
<span class="c">#    NAME                     ENDPOINTS                          AGE</span>
<span class="c">#    endpoints/service-2048   192.168.1.112:80,192.168.2.18:80   49s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                  READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/deployment-2048-85f8c7d69-gz295   1/1     Running   0          49s</span>
<span class="c">#    pod/deployment-2048-85f8c7d69-t2blb   1/1     Running   0          49s</span>
<span class="nv">$ </span>kubectl get targetgroupbindings <span class="nt">-n</span> game-2048
<span class="c"># =&gt; NAME                               SERVICE-NAME   SERVICE-PORT   TARGET-TYPE   AGE</span>
<span class="c">#    k8s-game2048-service2-00c3b27023   service-2048   80             ip            56s</span>
  
<span class="c"># ALB 생성 확인</span>
<span class="nv">$ </span>aws elbv2 describe-load-balancers <span class="nt">--query</span> <span class="s1">'LoadBalancers[?contains(LoadBalancerName, `k8s-game2048`) == `true`]'</span> | jq
<span class="nv">$ ALB_ARN</span><span class="o">=</span><span class="si">$(</span>aws elbv2 describe-load-balancers <span class="nt">--query</span> <span class="s1">'LoadBalancers[?contains(LoadBalancerName, `k8s-game2048`) == `true`].LoadBalancerArn'</span> | jq <span class="nt">-r</span> <span class="s1">'.[0]'</span><span class="si">)</span>
<span class="nv">$ </span>aws elbv2 describe-target-groups <span class="nt">--load-balancer-arn</span> <span class="nv">$ALB_ARN</span>
<span class="nv">$ TARGET_GROUP_ARN</span><span class="o">=</span><span class="si">$(</span>aws elbv2 describe-target-groups <span class="nt">--load-balancer-arn</span> <span class="nv">$ALB_ARN</span> | jq <span class="nt">-r</span> <span class="s1">'.TargetGroups[0].TargetGroupArn'</span><span class="si">)</span>
<span class="nv">$ </span>aws elbv2 describe-target-health <span class="nt">--target-group-arn</span> <span class="nv">$TARGET_GROUP_ARN</span> | jq
<span class="c"># =&gt; {</span>
<span class="c">#      &amp;quot;TargetHealthDescriptions&amp;quot;: [</span>
<span class="c">#        {</span>
<span class="c">#          &amp;quot;Target&amp;quot;: {</span>
<span class="c">#            &amp;quot;Id&amp;quot;: &amp;quot;192.168.1.112&amp;quot;,</span>
<span class="c">#            &amp;quot;Port&amp;quot;: 80,</span>
<span class="c">#            &amp;quot;AvailabilityZone&amp;quot;: &amp;quot;ap-northeast-2a&amp;quot;</span>
<span class="c">#          },</span>
<span class="c">#          &amp;quot;HealthCheckPort&amp;quot;: &amp;quot;80&amp;quot;,</span>
<span class="c">#          &amp;quot;TargetHealth&amp;quot;: {</span>
<span class="c">#            &amp;quot;State&amp;quot;: &amp;quot;healthy&amp;quot;</span>
<span class="c">#          }</span>
<span class="c">#        },</span>
<span class="c">#        {</span>
<span class="c">#          &amp;quot;Target&amp;quot;: {</span>
<span class="c">#            &amp;quot;Id&amp;quot;: &amp;quot;192.168.2.18&amp;quot;,</span>
<span class="c">#            &amp;quot;Port&amp;quot;: 80,</span>
<span class="c">#            &amp;quot;AvailabilityZone&amp;quot;: &amp;quot;ap-northeast-2b&amp;quot;</span>
<span class="c">#          },</span>
<span class="c">#          &amp;quot;HealthCheckPort&amp;quot;: &amp;quot;80&amp;quot;,</span>
<span class="c">#          &amp;quot;TargetHealth&amp;quot;: {</span>
<span class="c">#            &amp;quot;State&amp;quot;: &amp;quot;healthy&amp;quot;</span>
<span class="c">#          }</span>
<span class="c">#        }</span>
<span class="c">#      ]</span>
<span class="c">#    }</span>
  
<span class="c"># Ingress 확인</span>
<span class="nv">$ </span>kubectl describe ingress <span class="nt">-n</span> game-2048 ingress-2048
<span class="nv">$ </span>kubectl get ingress <span class="nt">-n</span> game-2048 ingress-2048 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.status.loadBalancer.ingress[*].hostname}{'</span><span class="se">\n</span><span class="s2">'}"</span>
<span class="c"># =&gt; k8s-game2048-ingress2-70d50ce3fd-333540411.ap-northeast-2.elb.amazonaws.com</span>
  
<span class="c"># 게임 접속 : ALB 주소로 웹 접속</span>
<span class="nv">$ </span>kubectl get ingress <span class="nt">-n</span> game-2048 ingress-2048 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.status.loadBalancer.ingress[0].hostname<span class="o">}</span> | <span class="nb">awk</span> <span class="s1">'{ print "Game URL = http://"$1 }'</span>
<span class="c"># =&gt; Game URL = http://k8s-game2048-ingress2-70d50ce3fd-333540411.ap-northeast-2.elb.amazonaws.com</span>
  
<span class="c"># 파드 IP 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-n</span> game-2048 <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                              READY   STATUS    RESTARTS   AGE     IP              NODE                                               NOMINATED NODE   READINESS GATES</span>
<span class="c">#    deployment-2048-85f8c7d69-gz295   1/1     Running   0          3m42s   192.168.2.18    ip-192-168-2-92.ap-northeast-2.compute.internal    &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    deployment-2048-85f8c7d69-t2blb   1/1     Running   0          3m42s   192.168.1.112   ip-192-168-1-186.ap-northeast-2.compute.internal   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
</code></pre></div>    </div>
    <p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_31.png" alt="img.png" /></p>

    <ul>
      <li>
        <p><strong>ALB 대상 그룹</strong>에 등록된 대상 확인 : ALB에서 파드 IP로 직접 전달</p>

        <p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_32.png" alt="img.png" class="image-center" />
<em class="image-caption">파드 IP로 바로 직접 연결된 ALB 대상 그룹</em></p>
      </li>
      <li>
        <p>파드 3개로 증가</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 터미널1</span>
<span class="nv">$ </span>watch kubectl get pod <span class="nt">-n</span> game-2048
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>aws elbv2 describe-target-health <span class="nt">--target-group-arn</span> <span class="nv">$TARGET_GROUP_ARN</span> <span class="nt">--output</span> text<span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
    
<span class="c"># 터미널2 : 파드 3개로 증가</span>
<span class="nv">$ </span>kubectl scale deployment <span class="nt">-n</span> game-2048 deployment-2048 <span class="nt">--replicas</span> 3
<span class="c"># =&gt; deployment.apps/deployment-2048 scaled</span>
</code></pre></div>        </div>
        <p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_33.png" alt="img.png" class="image-center" />
<em class="image-caption">추가된 파드 IP가 연결됨</em></p>
      </li>
      <li>
        <p>파드 1개로 감소</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 터미널2 : 파드 1개로 감소</span>
<span class="nv">$ </span>kubectl scale deployment <span class="nt">-n</span> game-2048 deployment-2048 <span class="nt">--replicas</span> 1
<span class="c"># =&gt; deployment.apps/deployment-2048 scaled</span>
</code></pre></div>        </div>

        <p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_34.png" alt="img.png" class="image-center" />
<em class="image-caption">삭제되는 2개의 파드가 삭제 중임을 확인</em></p>
      </li>
      <li>
        <p>실습 리소스  삭제</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl delete ingress ingress-2048 <span class="nt">-n</span> game-2048
<span class="nv">$ </span>kubectl delete svc service-2048 <span class="nt">-n</span> game-2048 <span class="o">&amp;&amp;</span> kubectl delete deploy deployment-2048 <span class="nt">-n</span> game-2048 <span class="o">&amp;&amp;</span> kubectl delete ns game-2048
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
</ul>

<h4 id="kubernetes-응용프로그램을-외부로-노출-시키는-방법들-비교">Kubernetes 응용프로그램을 외부로 노출 시키는 방법들 비교</h4>

<ul>
  <li>간략하게 Kubernetes 응용프로그램을 외부로 노출 시기는 방법들을 비교해보겠습니다.</li>
  <li>자세한 내용은 다음 블로그에서 살펴 볼 수 있습니다. <a href="https://aws.amazon.com/blogs/containers/exposing-kubernetes-applications-part-1-service-and-ingress-resources/">Exposing Kubernetes Applications, Part 1: Service and Ingress Resources </a>
    <ol>
      <li>Exposing a <strong>Service</strong> : In-tree Service Controller
  <img src="/assets/2024/kans-3th/w9/20241102_kans_w9_12.png" alt="img.png" class="image-center" />
        <ul>
          <li>AWS CLB(Classic Load Balancer)나 AWS NLB(Network Load Balancer)를 사용하여 서비스를 직접 외부로 노출합니다.
 하지만 서비스 수가 많아지면 Load Balancer의 수도 많아지게 되어 관리가 어려워집니다.</li>
        </ul>
      </li>
      <li><strong>Ingress Implementations : External Load Balancer</strong>
  <img src="/assets/2024/kans-3th/w9/20241102_kans_w9_13.png" alt="img.png" class="image-center" />
        <ul>
          <li>외부에 ALB(Application Load Balancer)를 생성하고 라우팅합니다. 이때 외부의 ALB가 Ingress rule을 ALB rule로 변환하여 
 외부 ALB가 직접 파드와 통신합니다. 앞에서 본 서비스를 직접 외부로 노출하는것 보다, CSP(Cloud Service Provider)에서 제공하는
 확장성이나, DDOS 방어기능 등을 활용 할 수 있습니다.</li>
        </ul>
      </li>
      <li><strong>Ingress Implementations : Internal Reverse Proxy</strong>
  <img src="/assets/2024/kans-3th/w9/20241102_kans_w9_14.png" alt="img.png" class="image-center" />
        <ul>
          <li>외부의 ALB에 더해 nginx 등의 Layer 7 리버스 프록시를 두는 방식입니다. 이 방식은 외부 ALB가 직접 파드와 통신하는 것이 아니라,
 리버스 프록시를 통해 통신하게 됩니다. 성능상으로는 불이익이 있지만 L7 리버스 프록시에서 제공하는 추가 기능들을 활용 할 수 있습니다.</li>
          <li>하지만 관리요소가 추가되는 것이기 때문에 이를 고려하여 사용해야 합니다.</li>
        </ul>
      </li>
      <li><strong>Kubernetes Gateway API</strong>
  <img src="/assets/2024/kans-3th/w9/20241102_kans_w9_15.png" alt="img.png" class="image-center" />
        <ul>
          <li>Kubernetes Gateway API는 Ingress Controller를 대체하는 새로운 API로 현시점에서 Beta 상태로, 정식 지원하지는 않는듯하며,
 외부 Loadbalancer나 Internal reverse proxy 방식처럼 사용할 수 있습니다.</li>
        </ul>
      </li>
    </ol>
  </li>
</ul>

<h3 id="externaldns">ExternalDNS</h3>

<ul>
  <li>
    <p>K8S 서비스/인그레스 생성 시 도메인을 설정하면, AWS(Route 53), Azure(DNS), GCP(Cloud DNS)에 A 레코드(TXT 레코드)가 자동으로 생성/삭제됩니다.
<img src="/assets/2024/kans-3th/w9/20241102_kans_w9_27.png" alt="img.png" class="image-center" />
<em class="image-caption"><a href="https://edgehog.blog/a-self-hosted-external-dns-resolver-for-kubernetes-111a27d6fc2c">https://edgehog.blog/a-self-hosted-external-dns-resolver-for-kubernetes-111a27d6fc2c</a></em></p>
  </li>
  <li>
    <p>AWS Route 53 정보 확인 &amp; 변수 지정 : Public 도메인 소유를 하고 있어야 합니다</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 자신의 도메인 변수 지정 : 소유하고 있는 자신의 도메인을 입력하시면 됩니다</span>
<span class="c">#$ MyDomain=&lt;자신의 도메인&gt;</span>
<span class="nv">$ MyDomain</span><span class="o">=</span>kans.loremipsum.sweetlittlebird.io
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"export MyDomain=kans.loremipsum.sweetlittlebird.io"</span> <span class="o">&gt;&gt;</span> /etc/profile
  
<span class="c"># 자신의 Route 53 도메인 ID 조회 및 변수 지정</span>
<span class="nv">$ </span>aws route53 list-hosted-zones-by-name <span class="nt">--dns-name</span> <span class="s2">"</span><span class="k">${</span><span class="nv">MyDomain</span><span class="k">}</span><span class="s2">."</span> | jq
<span class="c"># =&gt; {</span>
<span class="c">#      &amp;quot;HostedZones&amp;quot;: [</span>
<span class="c">#        {</span>
<span class="c">#          &amp;quot;Id&amp;quot;: &amp;quot;/hostedzone/Z0416620XQJAGAPWXO31&amp;quot;,</span>
<span class="c">#          &amp;quot;Name&amp;quot;: &amp;quot;kans.loremipsum.sweetlittlebird.io.&amp;quot;,</span>
<span class="c">#          &amp;quot;CallerReference&amp;quot;: &amp;quot;3aba3324-d6a0-44a4-82b5-004044e06dd6&amp;quot;,</span>
<span class="c">#          &amp;quot;Config&amp;quot;: {</span>
<span class="c">#            &amp;quot;Comment&amp;quot;: &amp;quot;&amp;quot;,</span>
<span class="c">#            &amp;quot;PrivateZone&amp;quot;: false</span>
<span class="c">#          },</span>
<span class="c">#          &amp;quot;ResourceRecordSetCount&amp;quot;: 3</span>
<span class="c">#        }</span>
<span class="c">#      ],</span>
<span class="c">#      &amp;quot;DNSName&amp;quot;: &amp;quot;kans.loremipsum.sweetlittlebird.io.&amp;quot;,</span>
<span class="c">#      &amp;quot;IsTruncated&amp;quot;: false,</span>
<span class="c">#      &amp;quot;MaxItems&amp;quot;: &amp;quot;100&amp;quot;</span>
<span class="c">#    }</span>
<span class="nv">$ </span>aws route53 list-hosted-zones-by-name <span class="nt">--dns-name</span> <span class="s2">"</span><span class="k">${</span><span class="nv">MyDomain</span><span class="k">}</span><span class="s2">."</span> <span class="nt">--query</span> <span class="s2">"HostedZones[0].Name"</span>
<span class="c"># =&gt; &amp;quot;kans.loremipsum.sweetlittlebird.io.&amp;quot;</span>
<span class="nv">$ </span>aws route53 list-hosted-zones-by-name <span class="nt">--dns-name</span> <span class="s2">"</span><span class="k">${</span><span class="nv">MyDomain</span><span class="k">}</span><span class="s2">."</span> <span class="nt">--query</span> <span class="s2">"HostedZones[0].Id"</span> <span class="nt">--output</span> text
<span class="c"># =&gt; /hostedzone/Z0416620XQJAGAPWXO31</span>
<span class="nv">$ MyDnzHostedZoneId</span><span class="o">=</span><span class="sb">`</span>aws route53 list-hosted-zones-by-name <span class="nt">--dns-name</span> <span class="s2">"</span><span class="k">${</span><span class="nv">MyDomain</span><span class="k">}</span><span class="s2">."</span> <span class="nt">--query</span> <span class="s2">"HostedZones[0].Id"</span> <span class="nt">--output</span> text<span class="sb">`</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$MyDnzHostedZoneId</span>
<span class="c"># =&gt; /hostedzone/Z0416620XQJAGAPWXO31</span>
  
<span class="c"># (옵션) NS 레코드 타입 첫번째 조회</span>
<span class="nv">$ </span>aws route53 list-resource-record-sets <span class="nt">--output</span> json <span class="nt">--hosted-zone-id</span> <span class="s2">"</span><span class="k">${</span><span class="nv">MyDnzHostedZoneId</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--query</span> <span class="s2">"ResourceRecordSets[?Type == 'NS']"</span> | jq <span class="nt">-r</span> <span class="s1">'.[0].ResourceRecords[].Value'</span>
<span class="c"># =&gt; ns-979.awsdns-58.net.</span>
<span class="c">#    ns-1489.awsdns-58.org.</span>
<span class="c">#    ns-355.awsdns-44.com.</span>
<span class="c">#    ns-1760.awsdns-28.co.uk.</span>
<span class="c"># (옵션) A 레코드 타입 모두 조회</span>
<span class="nv">$ </span>aws route53 list-resource-record-sets <span class="nt">--output</span> json <span class="nt">--hosted-zone-id</span> <span class="s2">"</span><span class="k">${</span><span class="nv">MyDnzHostedZoneId</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--query</span> <span class="s2">"ResourceRecordSets[?Type == 'A']"</span>
<span class="c"># =&gt; []</span>
  
<span class="c"># A 레코드 타입 조회</span>
<span class="nv">$ </span>aws route53 list-resource-record-sets <span class="nt">--hosted-zone-id</span> <span class="s2">"</span><span class="k">${</span><span class="nv">MyDnzHostedZoneId</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--query</span> <span class="s2">"ResourceRecordSets[?Type == 'A']"</span> | jq
<span class="nv">$ </span>aws route53 list-resource-record-sets <span class="nt">--hosted-zone-id</span> <span class="s2">"</span><span class="k">${</span><span class="nv">MyDnzHostedZoneId</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--query</span> <span class="s2">"ResourceRecordSets[?Type == 'A'].Name"</span> | jq
<span class="nv">$ </span>aws route53 list-resource-record-sets <span class="nt">--hosted-zone-id</span> <span class="s2">"</span><span class="k">${</span><span class="nv">MyDnzHostedZoneId</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--query</span> <span class="s2">"ResourceRecordSets[?Type == 'A'].Name"</span> <span class="nt">--output</span> text
  
<span class="c"># A 레코드 값 반복 조회</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>aws route53 list-resource-record-sets <span class="nt">--hosted-zone-id</span> <span class="s2">"</span><span class="k">${</span><span class="nv">MyDnzHostedZoneId</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--query</span> <span class="s2">"ResourceRecordSets[?Type == 'A']"</span> | jq <span class="p">;</span> <span class="nb">date</span> <span class="p">;</span> <span class="nb">echo</span> <span class="p">;</span> <span class="nb">sleep </span>1<span class="p">;</span> <span class="k">done</span>
</code></pre></div>    </div>
  </li>
  <li>ExternalDNS 설치 - <a href="https://github.com/kubernetes-sigs/external-dns/blob/master/docs/tutorials/aws.md">링크</a>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># EKS 배포 시 Node IAM Role 설정되어 있음</span>
<span class="c"># eksctl create cluster ... --external-dns-access ...</span>
  
<span class="c"># </span>
<span class="c">#$ MyDomain=&lt;자신의 도메인&gt;</span>
<span class="nv">$ MyDomain</span><span class="o">=</span>kans.loremipsum.sweetlittlebird.io
  
<span class="c"># 자신의 Route 53 도메인 ID 조회 및 변수 지정</span>
<span class="nv">$ MyDnzHostedZoneId</span><span class="o">=</span><span class="si">$(</span>aws route53 list-hosted-zones-by-name <span class="nt">--dns-name</span> <span class="s2">"</span><span class="k">${</span><span class="nv">MyDomain</span><span class="k">}</span><span class="s2">."</span> <span class="nt">--query</span> <span class="s2">"HostedZones[0].Id"</span> <span class="nt">--output</span> text<span class="si">)</span>
  
<span class="c"># 변수 확인</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$MyDomain</span>, <span class="nv">$MyDnzHostedZoneId</span>
<span class="c"># =&gt; kans.loremipsum.sweetlittlebird.io, /hostedzone/Z0416620XQJAGAPWXO31</span>
  
<span class="c"># ExternalDNS 배포</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nt">-O</span> https://raw.githubusercontent.com/gasida/PKOS/main/aews/externaldns.yaml
<span class="nv">$ </span><span class="nb">cat </span>externaldns.yaml
<span class="nv">$ MyDomain</span><span class="o">=</span><span class="nv">$MyDomain</span> <span class="nv">MyDnzHostedZoneId</span><span class="o">=</span><span class="nv">$MyDnzHostedZoneId</span> envsubst &lt; externaldns.yaml | kubectl apply <span class="nt">-f</span> -
<span class="c"># =&gt; serviceaccount/external-dns created</span>
<span class="c">#    clusterrole.rbac.authorization.k8s.io/external-dns created</span>
<span class="c">#    clusterrolebinding.rbac.authorization.k8s.io/external-dns-viewer created</span>
<span class="c">#    deployment.apps/external-dns created</span>
  
<span class="c"># 확인 및 로그 모니터링</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-l</span> app.kubernetes.io/name<span class="o">=</span>external-dns <span class="nt">-n</span> kube-system
<span class="c"># =&gt; NAME                            READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    external-dns-648996678b-7r4mz   1/1     Running   0          12s</span>
<span class="nv">$ </span>kubectl logs deploy/external-dns <span class="nt">-n</span> kube-system <span class="nt">-f</span>
</code></pre></div>    </div>

    <ul>
      <li>
        <p>(참고) 기존에 ExternalDNS를 통해 사용한 A/TXT 레코드가 있는 존의 경우에 policy 정책을 upsert-only 로 설정 후 사용 하자 - <a href="https://github.com/kubernetes-sigs/external-dns/blob/master/docs/tutorials/aws.md#deploy-externaldns">Link</a></p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- <span class="c">#--policy=upsert-only # would prevent ExternalDNS from deleting any records, omit to enable full synchronization</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li>Service(<strong>NLB</strong>) + 도메인 연동(<strong>ExternalDNS</strong>) - <a href="https://www.whatsmydns.net/">도메인체크</a>
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 터미널1 (모니터링)</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> <span class="s1">'kubectl get pod,svc'</span>
<span class="nv">$ </span>kubectl logs deploy/external-dns <span class="nt">-n</span> kube-system <span class="nt">-f</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    time=&amp;quot;2024-10-01T14:18:10Z&amp;quot; level=info msg=&amp;quot;Instantiating new Kubernetes client&amp;quot;</span>
<span class="c">#    time=&amp;quot;2024-10-01T14:18:10Z&amp;quot; level=info msg=&amp;quot;Using inCluster-config based on serviceaccount-token&amp;quot;</span>
<span class="c">#    time=&amp;quot;2024-10-01T14:18:10Z&amp;quot; level=info msg=&amp;quot;Created Kubernetes client https://10.100.0.1:443&amp;quot;</span>
<span class="c">#    time=&amp;quot;2024-10-01T14:18:11Z&amp;quot; level=info msg=&amp;quot;Applying provider record filter for domains: [kans.loremipsum.sweetlittlebird.io. .kans.loremipsum.sweetlittlebird.io.]&amp;quot;</span>
<span class="c">#    time=&amp;quot;2024-10-01T14:18:11Z&amp;quot; level=info msg=&amp;quot;All records are already up to date&amp;quot;</span>
<span class="c">#    ... (deployment 배포 후) ...</span>
<span class="c">#    time=&amp;quot;2024-10-01T14:20:11Z&amp;quot; level=info msg=&amp;quot;Applying provider record filter for domains: [kans.loremipsum.sweetlittlebird.io. .kans.loremipsum.sweetlittlebird.io.]&amp;quot;</span>
<span class="c">#    time=&amp;quot;2024-10-01T14:20:12Z&amp;quot; level=info msg=&amp;quot;Desired change: CREATE cname-tetris.kans.loremipsum.sweetlittlebird.io TXT&amp;quot; profile=default zoneID=/hostedzone/Z0416620XQJAGAPWXO31 zoneName=kans.loremipsum.sweetlittlebird.io.</span>
<span class="c">#    time=&amp;quot;2024-10-01T14:20:12Z&amp;quot; level=info msg=&amp;quot;Desired change: CREATE tetris.kans.loremipsum.sweetlittlebird.io A&amp;quot; profile=default zoneID=/hostedzone/Z0416620XQJAGAPWXO31 zoneName=kans.loremipsum.sweetlittlebird.io.</span>
<span class="c">#    time=&amp;quot;2024-10-01T14:20:12Z&amp;quot; level=info msg=&amp;quot;Desired change: CREATE tetris.kans.loremipsum.sweetlittlebird.io TXT&amp;quot; profile=default zoneID=/hostedzone/Z0416620XQJAGAPWXO31 zoneName=kans.loremipsum.sweetlittlebird.io.</span>
<span class="c">#    time=&amp;quot;2024-10-01T14:20:12Z&amp;quot; level=info msg=&amp;quot;3 record(s) were successfully updated&amp;quot; profile=default zoneID=/hostedzone/Z0416620XQJAGAPWXO31 zoneName=kans.loremipsum.sweetlittlebird.io.</span>
  
<span class="c"># 테트리스 디플로이먼트 배포</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: tetris
  labels:
    app: tetris
spec:
  replicas: 1
  selector:
    matchLabels:
      app: tetris
  template:
    metadata:
      labels:
        app: tetris
    spec:
      containers:
      - name: tetris
        image: bsord/tetris
---
apiVersion: v1
kind: Service
metadata:
  name: tetris
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: ip
    service.beta.kubernetes.io/aws-load-balancer-scheme: internet-facing
    service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: "true"
    service.beta.kubernetes.io/aws-load-balancer-backend-protocol: "http"
    #service.beta.kubernetes.io/aws-load-balancer-healthcheck-port: "80"
spec:
  selector:
    app: tetris
  ports:
  - port: 80
    protocol: TCP
    targetPort: 80
  type: LoadBalancer
  loadBalancerClass: service.k8s.aws/nlb
</span><span class="no">EOF
  
</span><span class="c"># 배포 확인</span>
<span class="nv">$ </span>kubectl get deploy,svc,ep tetris
<span class="c"># =&gt; NAME                     READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/tetris   0/1     1            0           5s</span>
<span class="c">#    </span>
<span class="c">#    NAME             TYPE           CLUSTER-IP      EXTERNAL-IP                                                                       PORT(S)        AGE</span>
<span class="c">#    service/tetris   LoadBalancer   10.100.39.204   k8s-default-tetris-4d2a39458c-e91cd840ce214644.elb.ap-northeast-2.amazonaws.com   80:32310/TCP   5s</span>
<span class="c">#    </span>
<span class="c">#    NAME               ENDPOINTS   AGE</span>
<span class="c">#    endpoints/tetris   &amp;lt;none&amp;gt;      5s</span>
  
<span class="c"># NLB에 ExternanDNS 로 도메인 연결</span>
<span class="nv">$ </span>kubectl annotate service tetris <span class="s2">"external-dns.alpha.kubernetes.io/hostname=tetris.</span><span class="nv">$MyDomain</span><span class="s2">"</span>
<span class="c"># =&gt; service/tetris annotated</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>aws route53 list-resource-record-sets <span class="nt">--hosted-zone-id</span> <span class="s2">"</span><span class="k">${</span><span class="nv">MyDnzHostedZoneId</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--query</span> <span class="s2">"ResourceRecordSets[?Type == 'A']"</span> | jq <span class="p">;</span> <span class="nb">date</span> <span class="p">;</span> <span class="nb">echo</span> <span class="p">;</span> <span class="nb">sleep </span>1<span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; [</span>
<span class="c">#      {</span>
<span class="c">#        &amp;quot;Name&amp;quot;: &amp;quot;tetris.kans.loremipsum.sweetlittlebird.io.&amp;quot;,</span>
<span class="c">#        &amp;quot;Type&amp;quot;: &amp;quot;A&amp;quot;,</span>
<span class="c">#        &amp;quot;AliasTarget&amp;quot;: {</span>
<span class="c">#          &amp;quot;HostedZoneId&amp;quot;: &amp;quot;ZIBE1TIR4HY56&amp;quot;,</span>
<span class="c">#          &amp;quot;DNSName&amp;quot;: &amp;quot;k8s-default-tetris-4d2a39458c-e91cd840ce214644.elb.ap-northeast-2.amazonaws.com.&amp;quot;,</span>
<span class="c">#          &amp;quot;EvaluateTargetHealth&amp;quot;: true</span>
<span class="c">#        }</span>
<span class="c">#      }</span>
<span class="c">#    ]</span>
<span class="c">#    Sat Oct  1 23:21:27 KST 2024</span>
<span class="c">#    ...</span>
  
<span class="c"># Route53에 A레코드 확인</span>
<span class="nv">$ </span>aws route53 list-resource-record-sets <span class="nt">--hosted-zone-id</span> <span class="s2">"</span><span class="k">${</span><span class="nv">MyDnzHostedZoneId</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--query</span> <span class="s2">"ResourceRecordSets[?Type == 'A']"</span> | jq
<span class="c"># =&gt; [</span>
<span class="c">#      {</span>
<span class="c">#        &amp;quot;Name&amp;quot;: &amp;quot;tetris.kans.loremipsum.sweetlittlebird.io.&amp;quot;,</span>
<span class="c">#        &amp;quot;Type&amp;quot;: &amp;quot;A&amp;quot;,</span>
<span class="c">#        &amp;quot;AliasTarget&amp;quot;: {</span>
<span class="c">#          &amp;quot;HostedZoneId&amp;quot;: &amp;quot;ZIBE1TIR4HY56&amp;quot;,</span>
<span class="c">#          &amp;quot;DNSName&amp;quot;: &amp;quot;k8s-default-tetris-4d2a39458c-e91cd840ce214644.elb.ap-northeast-2.amazonaws.com.&amp;quot;,</span>
<span class="c">#          &amp;quot;EvaluateTargetHealth&amp;quot;: true</span>
<span class="c">#        }</span>
<span class="c">#      }</span>
<span class="c">#    ]</span>
<span class="nv">$ </span>aws route53 list-resource-record-sets <span class="nt">--hosted-zone-id</span> <span class="s2">"</span><span class="k">${</span><span class="nv">MyDnzHostedZoneId</span><span class="k">}</span><span class="s2">"</span> <span class="nt">--query</span> <span class="s2">"ResourceRecordSets[?Type == 'A'].Name"</span> | jq .[]
<span class="c"># =&gt; &amp;quot;tetris.kans.loremipsum.sweetlittlebird.io.&amp;quot;</span>
  
<span class="c"># 확인</span>
<span class="nv">$ </span>dig +short tetris.<span class="nv">$MyDomain</span> @8.8.8.8
<span class="c"># =&gt; 3.38.82.70</span>
<span class="c">#    3.36.187.152</span>
<span class="c">#    3.35.184.161</span>
<span class="nv">$ </span>dig +short tetris.<span class="nv">$MyDomain</span>
<span class="c"># =&gt; 3.38.82.70</span>
  
<span class="c"># 도메인 체크</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"My Domain Checker = https://www.whatsmydns.net/#A/tetris.</span><span class="nv">$MyDomain</span><span class="s2">"</span>
<span class="c"># =&gt; My Domain Checker = https://www.whatsmydns.net/#A/tetris.kans.loremipsum.sweetlittlebird.io</span>
  
<span class="c"># 웹 접속 주소 확인 및 접속</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"Tetris Game URL = http://tetris.</span><span class="nv">$MyDomain</span><span class="s2">"</span>
<span class="c"># =&gt; Tetris Game URL = http://tetris.kans.loremipsum.sweetlittlebird.io</span>
</code></pre></div>    </div>

    <ul>
      <li>
        <p>웹 접속(http) → 화살표키, 일시중지(space bar)</p>

        <p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_35.png" alt="img.png" class="image-center" /></p>
      </li>
    </ul>
  </li>
  <li>
    <p>Ingress(ALB + HTTPS) + 도메인 연동(ExternalDNS)</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 테트리스 디플로이먼트 배포</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: tetris
  labels:
    app: tetris
spec:
  replicas: 1
  selector:
    matchLabels:
      app: tetris
  template:
    metadata:
      labels:
        app: tetris
    spec:
      containers:
      - name: tetris
        image: bsord/tetris
---
apiVersion: v1
kind: Service
metadata:
  name: tetris
  labels:
    app: tetris
spec:
  selector:
    app: tetris
  ports:
  - port: 80
    protocol: TCP
    targetPort: 80
  type: LoadBalancer
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: tetris-ingress
  annotations:
    kubernetes.io/ingress.class: alb
    alb.ingress.kubernetes.io/scheme: internet-facing
    alb.ingress.kubernetes.io/certificate-arn: arn:aws:acm:ap-northeast-2:123456789012:certificate/256538f4-6c5d-4109-9d4d-9aa6af41adaa
    alb.ingress.kubernetes.io/listen-ports: '[{"HTTP": 80}, {"HTTPS":443}]'
    alb.ingress.kubernetes.io/actions.ssl-redirect: '{"Type": "redirect", "RedirectConfig": { "Protocol": "HTTPS", "Port": "443", "StatusCode": "HTTP_301"}}'
spec:
  ingressClassName: alb
  rules:
    - http:
        paths:
        - path: /
          pathType: Prefix
          backend:
            service:
              name: tetris
              port:
                number: 80  
</span><span class="no">EOF
</span><span class="c"># =&gt; deployment.apps/tetris created</span>
<span class="c">#    service/tetris created</span>
<span class="c">#    ingress.networking.k8s.io/tetris-ingress created</span>
  
<span class="c"># ingress에 도메인 부여</span>
<span class="nv">$ </span>kubectl annotate ingress tetris-ingress <span class="s2">"external-dns.alpha.kubernetes.io/hostname=tetris2.</span><span class="nv">$MyDomain</span><span class="s2">"</span>
<span class="c"># =&gt; ingress.networking.k8s.io/tetris-ingress annotated</span>
  
<span class="c"># &lt;span style="color: green;"&gt;👉 기존에 사용했던 도메인(tetris.$MyDomain)을 사용하면 DNS 레코드가 전파되는데 시간이 더 걸리기 때문에&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   다른 도메인 (tetris2.$MyDomain)을 사용하였습니다.&lt;/span&gt;</span>
</code></pre></div>    </div>

    <p><img src="/assets/2024/kans-3th/w9/20241102_kans_w9_36.png" alt="img.png" class="image-center" />
<em class="image-caption">dns 적용 확인 (<a href="https://www.whatsmydns.net/">확인 사이트 링크</a>)</em></p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">https://tetris2.kans.loremipsum.sweetlittlebird.io</code> 로 접속하여 https 통신 확인
<img src="/assets/2024/kans-3th/w9/20241102_kans_w9_37.png" alt="img.png" class="image-center" />
<em class="image-caption">https 적용 확인</em></li>
    </ul>
  </li>
  <li><strong>리소스 삭제</strong> : <code class="language-plaintext highlighter-rouge">kubectl delete deploy,svc tetris</code> ← 삭제 시 externaldns 에 의해서 A레코드도 같이 삭제됩니다.</li>
</ul>

<ul>
  <li>
    <p>(참고) ACM 퍼블릭 인증서 요청 및 해당 인증서에 대한 Route53 도메인 검증 설정 with AWS CLI</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 각자 자신의 도메인 변수 지정</span>
<span class="c">#$ MyDomain=&lt;각자 자신의 도메인&gt;</span>
<span class="nv">$ MyDomain</span><span class="o">=</span>kans.loremipsum.sweetlittlebird.io
  
<span class="c"># ACM 퍼블릭 인증서 요청</span>
<span class="nv">$ CERT_ARN</span><span class="o">=</span><span class="si">$(</span>aws acm request-certificate <span class="se">\</span>
  <span class="nt">--domain-name</span> <span class="nv">$MyDomain</span> <span class="se">\</span>
  <span class="nt">--validation-method</span> <span class="s1">'DNS'</span> <span class="se">\</span>
  <span class="nt">--key-algorithm</span> <span class="s1">'RSA_2048'</span> <span class="se">\</span>
  | jq <span class="nt">--raw-output</span> <span class="s1">'.CertificateArn'</span><span class="si">)</span>
  
<span class="c"># 생성한 인증서 CNAME 이름 가져오기</span>
<span class="nv">$ CnameName</span><span class="o">=</span><span class="si">$(</span>aws acm describe-certificate <span class="se">\</span>
  <span class="nt">--certificate-arn</span> <span class="nv">$CERT_ARN</span> <span class="se">\</span>
  <span class="nt">--query</span> <span class="s1">'Certificate.DomainValidationOptions[*].ResourceRecord.Name'</span> <span class="se">\</span>
  <span class="nt">--output</span> text<span class="si">)</span>
  
<span class="c"># 생성한 인증서 CNAME 값 가져오기</span>
<span class="nv">$ CnameValue</span><span class="o">=</span><span class="si">$(</span>aws acm describe-certificate <span class="se">\</span>
  <span class="nt">--certificate-arn</span> <span class="nv">$CERT_ARN</span> <span class="se">\</span>
  <span class="nt">--query</span> <span class="s1">'Certificate.DomainValidationOptions[*].ResourceRecord.Value'</span> <span class="se">\</span>
  <span class="nt">--output</span> text<span class="si">)</span>
  
<span class="c"># 정상 출력 확인하기</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$CERT_ARN</span>, <span class="nv">$CnameName</span>, <span class="nv">$CnameValue</span>
<span class="c"># =&gt; arn:aws:acm:ap-northeast-2:123456789012:certificate/256538f4-6c5d-4109-9d4d-9aa6af41adaa, _e784949706a5e6eee7f350436cc9d501.kans.loremipsum.sweetlittlebird.io., _e62ee6e59a48ea2f3d1ab952d289bcea.djqtsrsxkq.acm-validations.aws.</span>
  
<span class="c"># 레코드 파일</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh"> &gt; cname.json
{
  "Comment": "create a acm's CNAME record",
  "Changes": [
    {
      "Action": "CREATE",
      "ResourceRecordSet": {
        "Name": "CnameName",
        "Type": "CNAME",
        "TTL": 300,
        "ResourceRecords": [
          {
            "Value": "CnameValue"
          }
        ]
      }
    }
  ]
}
</span><span class="no">EOT
  
</span><span class="c"># CNAME 이름, 값 치환하기</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/CnameName/</span><span class="nv">$CnameName</span><span class="s2">/g"</span> cname.json
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/CnameValue/</span><span class="nv">$CnameValue</span><span class="s2">/g"</span> cname.json
<span class="nv">$ </span><span class="nb">cat </span>cname.json
<span class="c"># =&gt; {</span>
<span class="c">#      &amp;quot;Comment&amp;quot;: &amp;quot;create a acm's CNAME record&amp;quot;,</span>
<span class="c">#      &amp;quot;Changes&amp;quot;: [</span>
<span class="c">#        {</span>
<span class="c">#          &amp;quot;Action&amp;quot;: &amp;quot;CREATE&amp;quot;,</span>
<span class="c">#          &amp;quot;ResourceRecordSet&amp;quot;: {</span>
<span class="c">#            &amp;quot;Name&amp;quot;: &amp;quot;_e784949706a5e6eee7f350436cc9d501.kans.loremipsum.sweetlittlebird.io.&amp;quot;,</span>
<span class="c">#            &amp;quot;Type&amp;quot;: &amp;quot;CNAME&amp;quot;,</span>
<span class="c">#            &amp;quot;TTL&amp;quot;: 300,</span>
<span class="c">#            &amp;quot;ResourceRecords&amp;quot;: [</span>
<span class="c">#              {</span>
<span class="c">#                &amp;quot;Value&amp;quot;: &amp;quot;_e62ee6e59a48ea2f3d1ab952d289bcea.djqtsrsxkq.acm-validations.aws.&amp;quot;</span>
<span class="c">#              }</span>
<span class="c">#            ]</span>
<span class="c">#          }</span>
<span class="c">#        }</span>
<span class="c">#      ]</span>
<span class="c">#    }</span>
  
<span class="c"># 해당 인증서에 대한 Route53 도메인 검증 설정을 위한 Route53 레코드 생성</span>
<span class="nv">$ </span>aws route53 change-resource-record-sets <span class="nt">--hosted-zone-id</span> <span class="nv">$MyDnzHostedZoneId</span> <span class="nt">--change-batch</span> file://cname.json
</code></pre></div>    </div>
  </li>
</ul>

<h3 id="실습-완료-후-자원-삭제">실습 완료 후 자원 삭제</h3>

<ul>
  <li>삭제 : 장점(1줄 명령어로 완전 삭제), 단점(삭제 실행과 완료까지 SSH 세션 유지 필요)
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>eksctl delete cluster <span class="nt">--name</span> <span class="nv">$CLUSTER_NAME</span> <span class="o">&amp;&amp;</span> aws cloudformation delete-stack <span class="nt">--stack-name</span> <span class="nv">$CLUSTER_NAME</span>
</code></pre></div>    </div>
  </li>
</ul>

<hr />

<h2 id="마치며">마치며</h2>

<p>와.. 드디어 마지막 주차인 9주차 과제를 완료하였습니다.
마지막 주차인 만큼 과제를 빨리 마치고 싶었지만, 생각보다 시간이 많이 걸려서 결국 오늘도 자정을 넘긴 일요일입니다. :cry:
매과제마다 저도 시간을 많이 쏟지만, 가시다 님을 비롯하여 스터디 조력자분들이 이 스터디를 위해 지금까지 얼마나 많은 시간을 투자하셨을지
생각하면 스스로가 머쓱하면서도, 감사함과 존경심을 느낍니다.</p>

<p>이번 스터디를 통해 많은 것을 배웠고, 블로그를 작성하는데 있어서도 많은 도움이 되었습니다.
회사에서 필요한 글만 쓰다가, 정말 오랜만에 개인을 위한 글도 이렇게 꾸준히 쓴것도 참 오랜만입니다. 
지난 테라폼 스터디부터 하면 5개월 정도는 거의 매주 글을 썼던 것 같습니다. 
—물론 실습 위주여서 “글”을 쓴게 맞냐는 문제가 있긴합니다.— 
예전에는 정말 시덥잖은 블로그 글도 많이 썼었는데, 나이도 들고, 사회적 지위도 (아직은 낮지만 예전보다) 높아지다보니
글을 쓰는데 있어서도 조금은 부담이 되었었는데, 이번 스터디를 통해 다시 글을 쓰는 재미와 글을 쓸 수 있다는 자신감을 느끼게 되었습니다.
앞으로도 스터디가 아니더라도 꾸준히 글을 쓰고 싶습니다.</p>

<p>약 3개월 간 스터디를 잘 이끌어주신 가시다 님과 조력자 분들께 큰 감사를 드립니다. :bow:</p>

<p>스터디에 참여하신 모든 분들도 고생 많으셨습니다. 다음에 또 뵐 수 있기를 기대합니다. :smile:</p>]]></content><author><name></name></author><category term="kans" /><category term="kubernetes," /><category term="network," /><category term="linux" /><summary type="html"><![CDATA[이번 주에는 AWS EKS의 VPC CNI에 대해 알아보겠습니다.]]></summary></entry><entry><title type="html">[KANS 3기] Cilium CNI</title><link href="https://sweetlittlebird.github.io/posts/2024-10-26-KANS-Study-Week8/" rel="alternate" type="text/html" title="[KANS 3기] Cilium CNI" /><published>2024-10-26T01:00:18+09:00</published><updated>2024-10-26T01:00:18+09:00</updated><id>https://sweetlittlebird.github.io/posts/KANS%20Study%20-%20Week8</id><content type="html" xml:base="https://sweetlittlebird.github.io/posts/2024-10-26-KANS-Study-Week8/"><![CDATA[<h2 id="들어가며">들어가며</h2>

<p>이번주에는 드디어 CNI의 끝판 왕(제가 아는 한에서)인 Cilium에 대해 알아보겠습니다.
어떤 것들이 가능할지 궁금합니다. 
KANS 3기 8주차 스터디를 시작하겠습니다.</p>

<hr />

<h2 id="cilium">Cilium</h2>

<p>Cilium은 eBPF(Berkeley Packet Filter)를 사용하여 네트워크 보안 및 라우팅을 제공하는 CNI(Container Network Interface) 플러그인입니다.
먼저 Cilium의 근간이 되는 eBPF에 대해 간단히 소개하고, Cilium에 대한 소개와 실습을 진행하겠습니다.</p>

<h3 id="bpfebpf-소개">BPF/eBPF 소개</h3>

<ul>
  <li>소개글 : <a href="https://hyeyoo.com/133">링크</a></li>
</ul>

<p><img src="/assets/2024/kans-3th/w8/20241026_kans_w8_1.png" alt="img.png" class="image-center" />
<em class="image-caption">기존 리눅스 Netfilter 기반 네트워크 스택</em></p>

<p>기존의 네트워크 스택은 Netfilter 기반으로 동작하며, 복잡한 네트워크 레이어를 거쳐야하고 이 레이어를 건너뛰기 어렵습니다.
또한 kube-proxy와 같은 userland 프로세스를 통해 네트워크 패킷을 처리합니다. 
그러다보니 오버헤드가 커져서 성능이 떨어지고, 룰이 복잡해질 경우 수 많은 룰을 관리해야하는 문제가 있습니다.</p>

<p><img src="/assets/2024/kans-3th/w8/20241026_kans_w8_2.png" alt="img_1.png" class="image-center" />
<em class="image-caption">eBPF 기반 네트워크 스택</em></p>

<p>eBPF는 커널 내부에서 동작하는 프로그램을 실행할 수 있으며, 이를 통해 네트워크 스택을 확장할 수 있습니다.
특히 샌드박스 방식을 통해 eBPF 프로그램이 커널에 영향을 미치지 않도록 보호할 수 있습니다. 
즉, eBPF 프로그램이 잘못된 동작을 하더라도 커널 패닉등의 발생이 거의 없습니다.</p>

<p>또한 XDP(eXpress Data Path)를 통해 네트워크 패킷을 처리할 수 있으며, 
이 XDP는 네트워크 카드(Offloaded mode), 네트워크 드라이버(Native mode), 커널 스페이스(Generic Mode)에서
동작하여 훨씬 빠르게 패킷을 처리할 수 있습니다.</p>

<p><img src="/assets/2024/kans-3th/w8/20241026_kans_w8_3.png" alt="img.png" class="image-center w-80" />
<em class="image-caption">iptables와 eBPF 성능 비교</em></p>

<ul>
  <li>eBPF 활용처
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_4.png" alt="img.png" class="image-center w-80" />
    <ul>
      <li><strong>Security</strong> (보안) : eBPF는 하드웨어 레벨에서 부터 모든 시스템 콜을 이해하고 처리할 수 있기 때문에 보다 더 세밀하고 강력한 보안 정책을 적용할 수 있습니다.</li>
      <li><strong>Tracing &amp; Profiling</strong> (추적 및 프로파일링) : eBPF는 커널 내부의 모든 이벤트를 추적하고 프로파일링 할 수 있습니다. 기존에 해결하기 어려웠던 성능 문제들도 eBPF를 통해 해결할 수 있습니다.</li>
      <li><strong>Networking</strong> (네트워킹) : eBPF는 커널 스페이스를 떠나지 않고 새로운 프로토콜을 만든다던지, 라우팅을 구현하는 등의 다양한 네트워크 기능을 만들 수 있습니다.</li>
      <li><strong>Observability</strong> (가시성) : 커널내부에서 다양한 소스에서 메트릭을 수집하고, 처리할 수 있고, 일부 데이터만 샘플링하는 것이 아닌 모든 데이터를 수집할 수 있습니다.</li>
    </ul>
  </li>
</ul>

<h3 id="cilium-소개">Cilium 소개</h3>

<ul>
  <li><strong>Cilium</strong>은 기존의 복잡한 네트워크 스택을 <strong>eBPF</strong>를 통해 <strong>간소화</strong>하고, <strong>빠르게 처리</strong>할 수 있도록 하는 CNI 플러그인입니다.</li>
</ul>

<p><img src="/assets/2024/kans-3th/w8/20241026_kans_w8_5.png" alt="img.png" class="image-center w-80" />
<em class="image-caption"><a href="https://isovalent.com/blog/post/migrating-from-metallb-to-cilium/">https://isovalent.com/blog/post/migrating-from-metallb-to-cilium/</a></em></p>

<ul>
  <li>Cilium eBPF는 추가적인 코드 수정이나 설정 변경없이, 리눅스 커널에서 동작하는 Bytecode를 자유롭게 프로그래밍하여 커널에 로딩시켜 동작이 가능합니다. <a href="https://www.youtube.com/watch?v=qsnR-s4XuGo&amp;t=1059s">링크</a></li>
  <li>또한 eBPF는 모든 패킷을 가로채기 위해서 수신 NIC의 ingress TC(<a href="https://netbeez.net/blog/how-to-use-the-linux-traffic-control/">Traffic Control</a>) hooks를 사용할 수 있습니다.
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_6.png" alt="img.png" class="image-center w-60" />
<em class="image-caption">NIC의 TC Hooks에 eBPF 프로그램이 attach 된 예</em></li>
  <li>Cilium은 터널모드(VXLAN, GENEVE), 네이티브 라우팅 모드의 2가지 네트워크 모드를 제공합니다.
    <ul>
      <li><strong>터널모드</strong> : Cilium이 VXLAN(UDP 8472), GENEVE(UDP 6081) 인터페이스를 만들어서 이들을 통해 트래픽을 전달합니다. Encapsulation 모드라고도 합니다.</li>
      <li><strong>네이티브 라우팅 모드</strong> : Cilium가 패킷 전달을 위해 구성을 변경하지 않고, 외부에서 제공되는 패킷 전달 방법(클라우드 또는 BGP 라우팅등)을 사용합니다. Direct Routing 모드라고도 합니다.
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_7.png" alt="img.png" class="image-center w-80" />
<em class="image-caption">Cilium 네트워크 모드 - <a href="https://docs.cilium.io/en/stable/network/concepts/routing/">링크</a></em></li>
    </ul>
  </li>
  <li>2021년 10월 Cilium은 CNCF에 채택되었습니다. <a href="https://cilium.io/blog/2021/10/13/cilium-joins-cncf/">링크</a></li>
  <li>Googke GKE dataplane과 AWS EKS Anywhere에서 기본 CNI로 Cilium을 사용하고 있습니다. <a href="https://isovalent.com/blog/post/2021-09-aws-eks-anywhere-chooses-cilium/">링크</a></li>
  <li>Cilium은 Kube-Proxy를 100% 대체 가능합니다.
    <ul>
      <li>iptables를 거의 사용하지 않고도 동작하며, 이를 통해 성능을 향상시킬 수 있습니다.</li>
      <li>하지만 istio, FHRP, VRRP 등과 같이 iptables 기능을 활용하는 동작들은 이슈가 발생할 수 있으며, 차츰 해결해 나가고 있습니다.</li>
    </ul>
  </li>
</ul>

<h4 id="cilium-아키텍쳐">Cilium 아키텍쳐</h4>

<ul>
  <li>구성요소 - <a href="https://ssup2.github.io/blog-software/docs/theory-analysis/kubernetes-cilium-plugin/">링크</a>
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_8.png" alt="img.png" class="image-center w-80" />
<em class="image-caption">Cilium 아키텍쳐 - <a href="https://github.com/cilium/cilium">출처</a></em>
    <ul>
      <li>Cilium <strong>Agent</strong> : 데몬셋으로 실행, K8S API 설정으로 부터 ‘네트워크 설정, 네트워크 정책, 서비스 부하분산, 모니터링’ 등을 수행하며, eBPF 프로그램을 관리합니다.</li>
      <li>Cilium <strong>Client</strong> (CLI) : Cilium 커멘드툴로 eBPF maps 에 직접 접속하여 상태를 확인할 수 있습니다.</li>
      <li>Cilium <strong>Operator</strong> : K8S 클러스터에 대한 한 번씩 처리해야 하는 작업을 관리합니다.</li>
      <li><strong>Hubble</strong> : 네트워크와 보안 모니터링 플랫폼 역할을 하여, Server, Relay, Client, Graphical UI 로 구성되어 있습니다.</li>
      <li><strong>Data Store</strong> : Cilium Agent 간의 상태를 저장하고 전파하는 데이터 저장소, 2가지 종류 중 선택(K8S CRDs, Key-Value Store)할 수 있습니다.</li>
    </ul>
  </li>
</ul>

<h3 id="cilium-실습">Cilium 실습</h3>

<p>실습을 통해 Cilium CNI에 대해서 알아보겠습니다. 먼저 Cilium을 설치하고, 기본적인 설정을 확인하고, 네트워크 정책을 설정해보겠습니다.</p>

<h4 id="cilium-설치">Cilium 설치</h4>

<h5 id="helm을-통한-설치-및-확인">Helm을 통한 설치 및 확인</h5>

<ul>
  <li>helm 옵션 : <a href="https://docs.cilium.io/en/stable/helm-reference/">https://docs.cilium.io/en/stable/helm-reference/</a></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 모니터링</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> kubectl get node,pod <span class="nt">-A</span> <span class="nt">-owide</span>

<span class="c">#</span>
<span class="nv">$ </span>helm repo add cilium https://helm.cilium.io/
<span class="c"># =&gt; &amp;quot;cilium&amp;quot; has been added to your repositories</span>
<span class="nv">$ </span>helm repo update
<span class="c"># =&gt; ...Successfully got an update from the &amp;quot;cilium&amp;quot; chart repository</span>
<span class="c">#    Update Complete. ⎈Happy Helming!⎈</span>

<span class="c">#</span>
<span class="nv">$ </span>helm <span class="nb">install </span>cilium cilium/cilium <span class="nt">--version</span> 1.16.3 <span class="nt">--namespace</span> kube-system <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">k8sServiceHost</span><span class="o">=</span>192.168.10.10 <span class="nt">--set</span> <span class="nv">k8sServicePort</span><span class="o">=</span>6443 <span class="nt">--set</span> debug.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">rollOutCiliumPods</span><span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> <span class="nv">routingMode</span><span class="o">=</span>native <span class="nt">--set</span> <span class="nv">autoDirectNodeRoutes</span><span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> bpf.masquerade<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> bpf.hostRouting<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> endpointRoutes.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> ipam.mode<span class="o">=</span>kubernetes <span class="nt">--set</span> k8s.requireIPv4PodCIDR<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> <span class="nv">kubeProxyReplacement</span><span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">ipv4NativeRoutingCIDR</span><span class="o">=</span>192.168.0.0/16 <span class="nt">--set</span> <span class="nv">installNoConntrackIptablesRules</span><span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> hubble.ui.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> hubble.relay.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> prometheus.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> operator.prometheus.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> hubble.metrics.enableOpenMetrics<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> hubble.metrics.enabled<span class="o">=</span><span class="s2">"{dns:query;ignoreAAAA,drop,tcp,flow,port-distribution,icmp,httpV2:exemplars=true;labelsContext=source_ip</span><span class="se">\,</span><span class="s2">source_namespace</span><span class="se">\,</span><span class="s2">source_workload</span><span class="se">\,</span><span class="s2">destination_ip</span><span class="se">\,</span><span class="s2">destination_namespace</span><span class="se">\,</span><span class="s2">destination_workload</span><span class="se">\,</span><span class="s2">traffic_direction}"</span> <span class="se">\</span>
  <span class="nt">--set</span> operator.replicas<span class="o">=</span>1
<span class="c"># =&gt; NAME: cilium</span>
<span class="c">#    LAST DEPLOYED: Sat Oct 01 07:23:34 2024</span>
<span class="c">#    NAMESPACE: kube-system</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 1</span>
<span class="c">#    TEST SUITE: None</span>
<span class="c">#    NOTES:</span>
<span class="c">#    You have successfully installed Cilium with Hubble Relay and Hubble UI.</span>
<span class="c">#    </span>
<span class="c">#    Your release version is 1.16.3.</span>
<span class="c">#    </span>
<span class="c">#    For any further help, visit https://docs.cilium.io/en/v1.16/gettinghelp</span>

<span class="c">## 주요 파라미터 설명</span>
<span class="c"># --set debug.enabled=true # cilium 파드에 로그 레벨을 debug 설정</span>
<span class="c"># --set autoDirectNodeRoutes=true # 동일 대역 내의 노드들 끼리는 상대 노드의 podCIDR 대역의 라우팅이 자동으로 설정</span>
<span class="c"># --set endpointRoutes.enabled=true # 호스트에 endpoint(파드)별 개별 라우팅 설정</span>
<span class="c"># --set hubble.relay.enabled=true --set hubble.ui.enabled=true # hubble 활성화</span>
<span class="c"># --set ipam.mode=kubernetes --set k8s.requireIPv4PodCIDR=true # k8s IPAM 활용</span>
<span class="c"># --set kubeProxyReplacement=true # kube-proxy 없이 (최대한) 대처할수 있수 있게</span>
<span class="c"># --set ipv4NativeRoutingCIDR=192.168.0.0/16 # 해당 대역과 통신 시 IP Masq 하지 않음, 보통 사내망 대역을 지정</span>
<span class="c"># --set operator.replicas=1 # cilium-operator 파드 기본 1개</span>
<span class="c"># --set enableIPv4Masquerade=true --set bpf.masquerade=true # 파드를 위한 Masquerade , 추가로 Masquerade 을 BPF 로 처리 &gt;&gt; enableIPv4Masquerade=true 인 상태에서 추가로 bpf.masquerade=true 적용이 가능</span>

<span class="c"># 설정 및 확인</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> addr
<span class="c"># =&gt; ...</span>
<span class="c">#    4: cilium_net@cilium_host: &amp;lt;BROADCAST,MULTICAST,NOARP,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span>
<span class="c">#        link/ether 3a:03:2f:7e:cc:72 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet6 fe80::3803:2fff:fe7e:cc72/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    5: cilium_host@cilium_net: &amp;lt;BROADCAST,MULTICAST,NOARP,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span>
<span class="c">#        link/ether ca:73:d2:a6:00:b4 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet 172.16.0.227/32 scope global cilium_host</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#        inet6 fe80::c873:d2ff:fea6:b4/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>kubectl get node,pod,svc <span class="nt">-A</span> <span class="nt">-owide</span>
<span class="c"># =&gt; NAME          STATUS   ROLES                  AGE     VERSION        INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION       CONTAINER-RUNTIME</span>
<span class="c">#    node/k3s-m    Ready    control-plane,master   3h58m   v1.30.5+k3s1   192.168.10.10    &amp;lt;none&amp;gt;        Ubuntu 22.04.5 LTS   5.15.0-119-generic   containerd://1.7.21-k3s2</span>
<span class="c">#    node/k3s-w1   Ready    &amp;lt;none&amp;gt;                 3h57m   v1.30.5+k3s1   192.168.10.101   &amp;lt;none&amp;gt;        Ubuntu 22.04.5 LTS   5.15.0-119-generic   containerd://1.7.21-k3s2</span>
<span class="c">#    node/k3s-w2   Ready    &amp;lt;none&amp;gt;                 3h55m   v1.30.5+k3s1   192.168.10.102   &amp;lt;none&amp;gt;        Ubuntu 22.04.5 LTS   5.15.0-119-generic   containerd://1.7.21-k3s2</span>
<span class="c">#    </span>
<span class="c">#    NAMESPACE     NAME                                          READY   STATUS    RESTARTS         AGE     IP               NODE     NOMINATED NODE   READINESS GATES</span>
<span class="c">#    kube-system   pod/cilium-envoy-9q7c6                        1/1     Running   0                5m19s   192.168.10.102   k3s-w2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system   pod/cilium-ljv9t                              1/1     Running   0                5m19s   192.168.10.101   k3s-w1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system   pod/cilium-operator-76bb588dbc-gxrqx          1/1     Running   0                5m19s   192.168.10.101   k3s-w1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system   pod/cilium-q96l4                              1/1     Running   0                5m19s   192.168.10.102   k3s-w2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system   pod/coredns-7b98449c4-x5756                   1/1     Running   0                2m59s   172.16.1.21      k3s-w1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system   pod/hubble-relay-88f7f89d4-fcq2s              1/1     Running   0                5m19s   172.16.1.99      k3s-w1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system   pod/hubble-ui-59bb4cb67b-r48tz                2/2     Running   0                5m19s   172.16.0.238     k3s-m    &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system   pod/local-path-provisioner-6795b5f9d8-84m96   1/1     Running   11 (5m28s ago)   3h58m   172.16.2.184     k3s-w2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system   pod/metrics-server-cdcc87586-g5m2d            1/1     Running   11 (5m10s ago)   3h58m   172.16.2.223     k3s-w2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    ...</span>
<span class="c">#    </span>
<span class="c">#    NAMESPACE     NAME                     TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                  AGE     SELECTOR</span>
<span class="c">#    default       service/kubernetes       ClusterIP   10.10.200.1     &amp;lt;none&amp;gt;        443/TCP                  3h58m   &amp;lt;none&amp;gt;</span>
<span class="c">#    kube-system   service/cilium-envoy     ClusterIP   None            &amp;lt;none&amp;gt;        9964/TCP                 5m19s   k8s-app=cilium-envoy</span>
<span class="c">#    kube-system   service/hubble-metrics   ClusterIP   None            &amp;lt;none&amp;gt;        9965/TCP                 5m19s   k8s-app=cilium</span>
<span class="c">#    kube-system   service/hubble-peer      ClusterIP   10.10.200.203   &amp;lt;none&amp;gt;        443/TCP                  5m19s   k8s-app=cilium</span>
<span class="c">#    kube-system   service/hubble-relay     ClusterIP   10.10.200.175   &amp;lt;none&amp;gt;        80/TCP                   5m19s   k8s-app=hubble-relay</span>
<span class="c">#    kube-system   service/hubble-ui        ClusterIP   10.10.200.125   &amp;lt;none&amp;gt;        80/TCP                   5m19s   k8s-app=hubble-ui</span>
<span class="c">#    kube-system   service/kube-dns         ClusterIP   10.10.200.10    &amp;lt;none&amp;gt;        53/UDP,53/TCP,9153/TCP   3h58m   k8s-app=kube-dns</span>
<span class="c">#    kube-system   service/metrics-server   ClusterIP   10.10.200.180   &amp;lt;none&amp;gt;        443/TCP                  3h58m   k8s-app=metrics-server</span>

<span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> filter <span class="nt">-S</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> raw <span class="nt">-S</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> mangle <span class="nt">-S</span>
<span class="nv">$ </span>conntrack <span class="nt">-L</span>

<span class="nv">$ </span>kubectl get crd | <span class="nb">grep </span>cilium
<span class="c"># =&gt; ciliumcidrgroups.cilium.io                   2024-10-01T11:10:57Z</span>
<span class="c">#    ciliumclusterwidenetworkpolicies.cilium.io   2024-10-01T11:10:58Z</span>
<span class="c">#    ciliumendpoints.cilium.io                    2024-10-01T11:10:57Z</span>
<span class="c">#    ciliumexternalworkloads.cilium.io            2024-10-01T11:10:57Z</span>
<span class="c">#    ciliumidentities.cilium.io                   2024-10-01T11:10:58Z</span>
<span class="c">#    ciliuml2announcementpolicies.cilium.io       2024-10-01T11:10:57Z</span>
<span class="c">#    ciliumloadbalancerippools.cilium.io          2024-10-01T11:10:57Z</span>
<span class="c">#    ciliumnetworkpolicies.cilium.io              2024-10-01T11:10:58Z</span>
<span class="c">#    ciliumnodeconfigs.cilium.io                  2024-10-01T11:10:57Z</span>
<span class="c">#    ciliumnodes.cilium.io                        2024-10-01T11:10:57Z</span>
<span class="c">#    ciliumpodippools.cilium.io                   2024-10-01T11:10:57Z</span>
<span class="nv">$ </span>kubectl get ciliumnodes <span class="c"># cilium_host 인터페이스의 IP 확인 : CILIUMINTERNALIP</span>
<span class="c"># =&gt; NAME     CILIUMINTERNALIP   INTERNALIP       AGE</span>
<span class="c">#    k3s-m    172.16.0.227       192.168.10.10    21m</span>
<span class="c">#    k3s-w1   172.16.1.82        192.168.10.101   21m</span>
<span class="c">#    k3s-w2   172.16.2.25        192.168.10.102   21m</span>
<span class="nv">$ </span>kubectl get ciliumendpoints <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE     NAME                                      SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    kube-system   coredns-7b98449c4-x5756                   11970               ready            172.16.1.21</span>
<span class="c">#    kube-system   hubble-relay-88f7f89d4-fcq2s              4124                ready            172.16.1.99</span>
<span class="c">#    kube-system   hubble-ui-59bb4cb67b-r48tz                37523               ready            172.16.0.238</span>
<span class="c">#    kube-system   local-path-provisioner-6795b5f9d8-84m96   11088               ready            172.16.2.184</span>
<span class="c">#    kube-system   metrics-server-cdcc87586-g5m2d            27624               ready            172.16.2.223</span>

<span class="nv">$ </span>kubectl get cm <span class="nt">-n</span> kube-system cilium-config <span class="nt">-o</span> json | jq

<span class="nv">$ </span>kubetail <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium <span class="nt">--since</span> 1h
<span class="nv">$ </span>kubetail <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium-envoy <span class="nt">--since</span> 1h

<span class="c"># Native XDP 지원 NIC 확인 : https://docs.cilium.io/en/stable/bpf/progtypes/#xdp-drivers</span>
<span class="nv">$ </span>ethtool <span class="nt">-i</span> enp0s8
<span class="c"># =&gt; driver: virtio_net   # &gt;= XDP 4.10 부터 지원되는듯 합니다.</span>
<span class="c">#    version: 1.0.0</span>
<span class="c">#    ...</span>

<span class="c"># https://docs.cilium.io/en/stable/operations/performance/tuning/#bypass-iptables-connection-tracking</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> kubectl get pod <span class="nt">-A</span> <span class="c"># 모니터링</span>
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--namespace</span> kube-system <span class="nt">--reuse-values</span> <span class="nt">--set</span> <span class="nv">installNoConntrackIptablesRules</span><span class="o">=</span><span class="nb">true</span>
<span class="c"># =&gt; Release &amp;quot;cilium&amp;quot; has been upgraded. Happy Helming!</span>
<span class="c">#    NAME: cilium</span>
<span class="c">#    LAST DEPLOYED: Sat Oct 01 11:42:10 2024</span>
<span class="c">#    NAMESPACE: kube-system</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 2</span>
<span class="c">#    TEST SUITE: None</span>
<span class="c">#    NOTES:</span>
<span class="c">#    You have successfully installed Cilium with Hubble Relay and Hubble UI.</span>
<span class="c">#    </span>
<span class="c">#    Your release version is 1.16.3.</span>
<span class="c">#    </span>
<span class="c">#    For any further help, visit https://docs.cilium.io/en/v1.16/gettinghelp</span>

<span class="c"># 확인: 기존 raw 에 아래 rule 추가 확인</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> raw <span class="nt">-S</span> | <span class="nb">grep </span>notrack
<span class="c"># =&gt; -A CILIUM_OUTPUT_raw -d 192.168.0.0/16 -m comment --comment "cilium: NOTRACK for pod traffic" -j CT --notrack</span>
<span class="c">#    -A CILIUM_OUTPUT_raw -s 192.168.0.0/16 -m comment --comment "cilium: NOTRACK for pod traffic" -j CT --notrack</span>
<span class="c">#    ...</span>

<span class="nv">$ </span>conntrack <span class="nt">-F</span>
<span class="nv">$ </span>conntrack <span class="nt">-L</span>
<span class="nv">$ </span>conntrack <span class="nt">-L</span> |grep <span class="nt">-v</span> 2379
</code></pre></div></div>

<h5 id="cilium-cli를-통한-확인">Cilium CLI를 통한 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># cilium CLI 설치</span>
<span class="nv">$ CILIUM_CLI_VERSION</span><span class="o">=</span><span class="si">$(</span>curl <span class="nt">-s</span> https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt<span class="si">)</span>
<span class="nv">$ CLI_ARCH</span><span class="o">=</span>amd64
<span class="nv">$ </span><span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span><span class="si">)</span><span class="s2">"</span> <span class="o">=</span> <span class="s2">"aarch64"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then </span><span class="nv">CLI_ARCH</span><span class="o">=</span>arm64<span class="p">;</span> <span class="k">fi</span>
<span class="nv">$ </span>curl <span class="nt">-L</span> <span class="nt">--fail</span> <span class="nt">--remote-name-all</span> https://github.com/cilium/cilium-cli/releases/download/<span class="k">${</span><span class="nv">CILIUM_CLI_VERSION</span><span class="k">}</span>/cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz<span class="o">{</span>,.sha256sum<span class="o">}</span>
<span class="nv">$ </span><span class="nb">sha256sum</span> <span class="nt">--check</span> cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz.sha256sum
<span class="nv">$ </span><span class="nb">sudo tar </span>xzvfC cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz /usr/local/bin
<span class="nv">$ </span><span class="nb">rm </span>cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz<span class="o">{</span>,.sha256sum<span class="o">}</span>

<span class="c"># 테스트</span>
<span class="nv">$ </span>cilium status <span class="nt">--wait</span>
<span class="c"># =&gt;     /¯¯\</span>
<span class="c">#     /¯¯\__/¯¯\    Cilium:             OK</span>
<span class="c">#     \__/¯¯\__/    Operator:           OK</span>
<span class="c">#     /¯¯\__/¯¯\    Envoy DaemonSet:    OK</span>
<span class="c">#     \__/¯¯\__/    Hubble Relay:       OK</span>
<span class="c">#        \__/       ClusterMesh:        disabled</span>
<span class="c">#    </span>
<span class="c">#    DaemonSet              cilium             Desired: 3, Ready: 3/3, Available: 3/3</span>
<span class="c">#    DaemonSet              cilium-envoy       Desired: 3, Ready: 3/3, Available: 3/3</span>
<span class="c">#    Deployment             cilium-operator    Desired: 1, Ready: 1/1, Available: 1/1</span>
<span class="c">#    Deployment             hubble-relay       Desired: 1, Ready: 1/1, Available: 1/1</span>
<span class="c">#    Deployment             hubble-ui          Desired: 1, Ready: 1/1, Available: 1/1</span>
<span class="c">#    Containers:            cilium             Running: 3</span>
<span class="c">#                           cilium-envoy       Running: 3</span>
<span class="c">#                           cilium-operator    Running: 1</span>
<span class="c">#                           hubble-relay       Running: 1</span>
<span class="c">#                           hubble-ui          Running: 1</span>
<span class="c">#    Cluster Pods:          5/5 managed by Cilium</span>
<span class="c">#    Helm chart version:    1.16.3</span>
<span class="c">#    Image versions         cilium             quay.io/cilium/cilium:v1.16.3@sha256:62d2a09bbef840a46099ac4c69421c90f84f28d018d479749049011329aa7f28: 3</span>
<span class="c">#                           cilium-envoy       quay.io/cilium/cilium-envoy:v1.29.9-1728346947-0d05e48bfbb8c4737ec40d5781d970a550ed2bbd@sha256:42614a44e508f70d03a04470df5f61e3cffd22462471a0be0544cf116f2c50ba: 3</span>
<span class="c">#                           cilium-operator    quay.io/cilium/operator-generic:v1.16.3@sha256:6e2925ef47a1c76e183c48f95d4ce0d34a1e5e848252f910476c3e11ce1ec94b: 1</span>
<span class="c">#                           hubble-relay       quay.io/cilium/hubble-relay:v1.16.3@sha256:feb60efd767e0e7863a94689f4a8db56a0acc7c1d2b307dee66422e3dc25a089: 1</span>
<span class="c">#                           hubble-ui          quay.io/cilium/hubble-ui-backend:v0.13.1@sha256:0e0eed917653441fded4e7cdb096b7be6a3bddded5a2dd10812a27b1fc6ed95b: 1</span>
<span class="c">#                           hubble-ui          quay.io/cilium/hubble-ui:v0.13.1@sha256:e2e9313eb7caf64b0061d9da0efbdad59c6c461f6ca1752768942bfeda0796c6: 1</span>

<span class="nv">$ </span>cilium connectivity <span class="nb">test</span>

<span class="nv">$ </span>cilium config view
<span class="c"># =&gt; agent-not-ready-taint-key                         node.cilium.io/agent-not-ready</span>
<span class="c">#    arping-refresh-period                             30s</span>
<span class="c">#    auto-direct-node-routes                           true</span>
<span class="c">#    bpf-events-drop-enabled                           true</span>
<span class="c">#    bpf-events-policy-verdict-enabled                 true</span>
<span class="c">#    bpf-events-trace-enabled                          true</span>
<span class="c">#    bpf-lb-acceleration                               disabled</span>
<span class="c">#    bpf-lb-external-clusterip                         false</span>
<span class="c">#    bpf-lb-map-max                                    65536</span>
<span class="c">#    bpf-lb-sock                                       false</span>
<span class="c">#    bpf-lb-sock-terminate-pod-connections             false</span>
<span class="c">#    bpf-map-dynamic-size-ratio                        0.0025</span>
<span class="c">#    bpf-policy-map-max                                16384</span>
<span class="c">#    bpf-root                                          /sys/fs/bpf</span>
<span class="c">#    ...</span>
<span class="c">#    ipv4-native-routing-cidr                          192.168.0.0/16</span>
<span class="c">#    ...</span>
<span class="c">#    kube-proxy-replacement                            true</span>
<span class="c">#    kube-proxy-replacement-healthz-bind-address</span>
<span class="c">#    max-connected-clusters                            255</span>
<span class="c">#    mesh-auth-enabled                                 true</span>
<span class="c">#    ...</span>

<span class="c"># cilium 데몬셋 파드 내에서 cilium 명령어로 상태 확인</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD0</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k3s-m  <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c0</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD0</span><span class="s2"> -n kube-system -c cilium-agent -- cilium"</span>
<span class="nv">$ </span>c0 status <span class="nt">--verbose</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    KubeProxyReplacement:   True   [enp0s3   10.0.2.15 fe80::6d:daff:feb3:d4d3, enp0s8   192.168.10.10 fe80::27ff:fe8a:de00 (Direct Routing)]</span>
<span class="c">#    ...</span>
<span class="c">#    IPAM:                   IPv4: 4/254 allocated from 172.16.0.0/24, </span>
<span class="c">#    Allocated addresses:</span>
<span class="c">#      172.16.0.223 (kube-system/hubble-ui-59bb4cb67b-r48tz)</span>
<span class="c">#      172.16.0.227 (router)</span>
<span class="c">#      172.16.0.26 (health)</span>
<span class="c">#      172.16.0.44 (cilium-test-1/client3-67f959dd9b-ptl65)</span>
<span class="c">#    ...</span>
<span class="c">#    Routing:                Network: Native   Host: BPF</span>
<span class="c">#    ...</span>
<span class="c">#    Device Mode:            veth</span>
<span class="c">#    Masquerading:           BPF   [ens5]   192.168.0.0/16 [IPv4: Enabled, IPv6: Disabled]</span>
<span class="c">#    ...  </span>
<span class="c">#    Proxy Status:            OK, ip 172.16.0.227, 0 redirects active on ports 10000-20000, Envoy: external</span>
<span class="c">#    ...</span>
<span class="c">#    KubeProxyReplacement Details:</span>
<span class="c">#      Status:                 True</span>
<span class="c">#      Socket LB:              Enabled</span>
<span class="c">#      Socket LB Tracing:      Enabled</span>
<span class="c">#      Socket LB Coverage:     Full</span>
<span class="c">#      Devices:                enp0s3   10.0.2.15 fe80::6d:daff:feb3:d4d3, enp0s8   192.168.10.10 fe80::27ff:fe8a:de00 (Direct Routing)</span>
<span class="c">#      Mode:                   SNAT</span>
<span class="c">#      Backend Selection:      Random</span>
<span class="c">#      Session Affinity:       Enabled</span>
<span class="c">#      Graceful Termination:   Enabled</span>
<span class="c">#      NAT46/64 Support:       Disabled</span>
<span class="c">#      XDP Acceleration:       Disabled</span>
<span class="c">#      Services:</span>
<span class="c">#      - ClusterIP:      Enabled</span>
<span class="c">#      - NodePort:       Enabled (Range: 30000-32767) </span>
<span class="c">#      - LoadBalancer:   Enabled </span>
<span class="c">#      - externalIPs:    Enabled </span>
<span class="c">#      - HostPort:       Enabled</span>
<span class="c">#    BPF Maps:   dynamic sizing: on (ratio: 0.002500)</span>
<span class="c">#    ...</span>

<span class="c"># Native Routing 확인 : # 192.168.0.0/16 대역은 IP Masq 없이 라우팅</span>
<span class="nv">$ </span>c0 status | <span class="nb">grep </span>KubeProxyReplacement
<span class="c"># =&gt; KubeProxyReplacement:    True   [enp0s3   10.0.2.15 fe80::6d:daff:feb3:d4d3, enp0s8   192.168.10.10 fe80::27ff:fe8a:de00 (Direct Routing)]</span>

<span class="c"># enableIPv4Masquerade=true(기본값) , bpf.masquerade=true 확인</span>
<span class="nv">$ </span>cilium config view | egrep <span class="s1">'enable-ipv4-masquerade|enable-bpf-masquerade'</span>
<span class="c"># =&gt; enable-bpf-masquerade                             true</span>
<span class="c">#    enable-ipv4-masquerade                            true</span>

<span class="nv">$ </span>c0 status <span class="nt">--verbose</span> | <span class="nb">grep </span>Masquerading
<span class="c"># =&gt; Masquerading:           BPF   [enp0s3, enp0s8]   192.168.0.0/16 [IPv4: Enabled, IPv6: Disabled]</span>

<span class="c"># Configure the eBPF-based ip-masq-agent</span>
<span class="c"># https://docs.cilium.io/en/stable/network/concepts/masquerading/</span>
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--namespace</span> kube-system <span class="nt">--reuse-values</span> <span class="nt">--set</span> ipMasqAgent.enabled<span class="o">=</span><span class="nb">true</span>
<span class="c"># =&gt; Release &amp;quot;cilium&amp;quot; has been upgraded. Happy Helming!</span>
<span class="c">#    ...</span>

<span class="c">#</span>
<span class="nv">$ </span>cilium config view | <span class="nb">grep</span> <span class="nt">-i</span> masq
<span class="c"># =&gt; enable-bpf-masquerade                             true</span>
<span class="c">#    enable-ip-masq-agent                              true</span>
<span class="c">#    ...</span>

<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD0</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k3s-m  <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c0</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD0</span><span class="s2"> -n kube-system -c cilium-agent -- cilium"</span>
<span class="nv">$ </span>c0 status <span class="nt">--verbose</span> | <span class="nb">grep </span>Masquerading
<span class="c"># =&gt; Masquerading:           BPF (ip-masq-agent)   [enp0s3, enp0s8]   192.168.0.0/16 [IPv4: Enabled, IPv6: Disabled]</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 BPF가 BPF (ip-masq-agent)로 변경되었습니다.&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   ip-masq-agent는 k8s 클러스터 내부에서 IP 마스커레이딩을 관리하는 컴포넌트로,&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;   마스커레이딩 여부를 결정하여 네트워크 자원 사용을 최적화 해줍니다.&lt;/span&gt;</span>

<span class="nv">$ </span>kubectl get cm <span class="nt">-n</span> kube-system cilium-config <span class="nt">-o</span> yaml  | <span class="nb">grep </span>ip-masq
<span class="c"># =&gt;   enable-ip-masq-agent: &amp;quot;true&amp;quot;</span>
</code></pre></div></div>

<h4 id="cilium-기본정보-확인">Cilium 기본정보 확인</h4>

<h5 id="변수--단축키">변수 &amp; 단축키</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># cilium 파드 이름</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD0</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k3s-m  <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD1</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k3s-w1 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD2</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k3s-w2 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>

<span class="c"># 단축키(alias) 지정</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c0</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD0</span><span class="s2"> -n kube-system -c cilium-agent -- cilium"</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c1</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD1</span><span class="s2"> -n kube-system -c cilium-agent -- cilium"</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c2</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD2</span><span class="s2"> -n kube-system -c cilium-agent -- cilium"</span>

<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c0bpf</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD0</span><span class="s2"> -n kube-system -c cilium-agent -- bpftool"</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c1bpf</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD1</span><span class="s2"> -n kube-system -c cilium-agent -- bpftool"</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c2bpf</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD2</span><span class="s2"> -n kube-system -c cilium-agent -- bpftool"</span>

<span class="c"># Hubble UI 웹 접속</span>
<span class="nv">$ </span>kubectl patch <span class="nt">-n</span> kube-system svc hubble-ui <span class="nt">-p</span> <span class="s1">'{"spec": {"type": "NodePort"}}'</span>
<span class="c"># =&gt; service/hubble-ui patched</span>
<span class="nv">$ HubbleUiNodePort</span><span class="o">=</span><span class="si">$(</span>kubectl get svc <span class="nt">-n</span> kube-system hubble-ui <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.spec.ports[0].nodePort<span class="o">}</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"Hubble UI URL = http://</span><span class="si">$(</span>curl <span class="nt">-s</span> ipinfo.io/ip<span class="si">)</span><span class="s2">:</span><span class="nv">$HubbleUiNodePort</span><span class="s2">"</span>
<span class="c"># =&gt; Hubble UI URL = http://54.180.146.116:30732</span>
</code></pre></div></div>

<h5 id="자주-쓰는-cilium-cli-명령어">자주 쓰는 Cilium CLI 명령어</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># cilium 파드 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium <span class="nt">-owide</span>
<span class="c"># =&gt; NAME           READY   STATUS    RESTARTS   AGE     IP               NODE     NOMINATED NODE   READINESS GATES</span>
<span class="c">#    cilium-5gx8w   1/1     Running   0          9m12s   192.168.10.102   k3s-w2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    cilium-92k6s   1/1     Running   0          8m53s   192.168.10.101   k3s-w1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    cilium-zv22g   1/1     Running   0          9m12s   192.168.10.10    k3s-m    &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>

<span class="c"># cilium 파드 재시작</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system rollout restart ds/cilium
<span class="c"># =&gt; daemonset.apps/cilium restarted</span>
<span class="c"># 혹은</span>
<span class="nv">$ </span>kubectl delete pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium
<span class="c"># =&gt; pod &amp;quot;cilium-5p4q4&amp;quot; deleted</span>
<span class="c">#    pod &amp;quot;cilium-bc7jz&amp;quot; deleted</span>
<span class="c">#    pod &amp;quot;cilium-zqs9l&amp;quot; deleted</span>

<span class="c"># cilium 설정 정보 확인</span>
<span class="nv">$ </span>cilium config view

<span class="c"># cilium 파드의 cilium 상태 확인</span>
<span class="nv">$ </span>c0 status <span class="nt">--verbose</span>

<span class="c"># cilium 엔드포인트 확인</span>
<span class="nv">$ </span>kubectl get ciliumendpoints <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE       NAME                                      SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    kube-system     coredns-7b98449c4-x5756                   11970               ready            172.16.1.21</span>
<span class="c">#    kube-system     hubble-relay-88f7f89d4-fcq2s              4124                ready            172.16.1.99</span>
<span class="c">#    kube-system     hubble-ui-59bb4cb67b-r48tz                37523               ready            172.16.0.223</span>
<span class="c">#    kube-system     local-path-provisioner-6795b5f9d8-84m96   11088               ready            172.16.2.184</span>
<span class="c">#    kube-system     metrics-server-cdcc87586-g5m2d            27624               ready            172.16.2.223</span>
<span class="nv">$ </span>c0 endpoint list
<span class="c"># =&gt; ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])                                                  IPv6   IPv4           STATUS</span>
<span class="c">#               ENFORCEMENT        ENFORCEMENT</span>
<span class="c">#    640        Disabled           Disabled          37523      k8s:app.kubernetes.io/name=hubble-ui                                                172.16.0.223   ready</span>
<span class="c">#                                                               k8s:app.kubernetes.io/part-of=cilium</span>
<span class="c">#                                                               k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=kube-system</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.cluster=default</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.serviceaccount=hubble-ui</span>
<span class="c">#                                                               k8s:io.kubernetes.pod.namespace=kube-system</span>
<span class="c">#                                                               k8s:k8s-app=hubble-ui</span>
<span class="c">#    1196       Disabled           Disabled          1          k8s:node-role.kubernetes.io/control-plane=true                                                     ready</span>
<span class="c">#                                                               k8s:node-role.kubernetes.io/master=true</span>
<span class="c">#                                                               k8s:node.kubernetes.io/instance-type=k3s</span>
<span class="c">#                                                               reserved:host</span>
<span class="c">#    1598       Disabled           Disabled          4          reserved:health                                                                     172.16.0.26    ready</span>
<span class="nv">$ </span>c0 bpf endpoint list
<span class="c"># =&gt; IP ADDRESS        LOCAL ENDPOINT INFO</span>
<span class="c">#    172.16.0.26:0     id=1598  sec_id=4     flags=0x0000 ifindex=17  mac=CE:24:50:27:35:B9 nodemac=FE:57:C1:AD:A6:28</span>
<span class="c">#    172.16.0.223:0    id=640   sec_id=37523 flags=0x0000 ifindex=9   mac=AE:B8:81:A6:B1:28 nodemac=C2:21:B8:92:DA:FD</span>
<span class="c">#    172.16.0.227:0    (localhost)</span>
<span class="c">#    192.168.10.10:0   (localhost)</span>
<span class="c">#    10.0.2.15:0       (localhost)</span>
<span class="nv">$ </span>c0 map get cilium_lxc
<span class="c"># =&gt; Key              Value                                                                                            State   Error</span>
<span class="c">#    172.16.0.223:0   id=640   sec_id=37523 flags=0x0000 ifindex=9   mac=AE:B8:81:A6:B1:28 nodemac=C2:21:B8:92:DA:FD   sync</span>
<span class="c">#    172.16.0.26:0    id=1598  sec_id=4     flags=0x0000 ifindex=17  mac=CE:24:50:27:35:B9 nodemac=FE:57:C1:AD:A6:28   sync</span>
<span class="nv">$ </span>c0 ip list

<span class="c"># Manage the IPCache mappings for IP/CIDR &lt;-&gt; Identity</span>
<span class="nv">$ </span>c0 bpf ipcache list

<span class="c"># Service/NAT List 확인</span>
<span class="nv">$ </span>c0 service list
<span class="c"># =&gt; ID   Frontend              Service Type   Backend</span>
<span class="c">#    1    10.10.200.1:443       ClusterIP      1 =&amp;gt; 192.168.10.10:6443 (active)</span>
<span class="c">#    ...</span>
<span class="c">#    6    10.10.200.10:9153     ClusterIP      1 =&amp;gt; 172.16.1.21:9153 (active)</span>
<span class="c">#    7    10.10.200.180:443     ClusterIP      1 =&amp;gt; 172.16.2.223:10250 (active)</span>
<span class="c">#    16   0.0.0.0:30732         NodePort       1 =&amp;gt; 172.16.0.223:8081 (active)</span>
<span class="c">#    17   10.0.2.15:30732       NodePort       1 =&amp;gt; 172.16.0.223:8081 (active)</span>
<span class="c">#    18   192.168.10.10:30732   NodePort       1 =&amp;gt; 172.16.0.223:8081 (active)</span>
<span class="nv">$ </span>c0 bpf lb list
<span class="c"># =&gt; SERVICE ADDRESS           BACKEND ADDRESS (REVNAT_ID) (SLOT)</span>
<span class="c">#    10.10.200.1:443 (0)       0.0.0.0:0 (1) (0) [ClusterIP, non-routable]</span>
<span class="c">#    ...</span>
<span class="c">#    10.10.200.10:9153 (0)     0.0.0.0:0 (6) (0) [ClusterIP, non-routable]</span>
<span class="c">#    10.10.200.180:443 (1)     172.16.2.223:10250 (7) (1)</span>
<span class="c">#    0.0.0.0:30732 (0)         0.0.0.0:0 (16) (0) [NodePort, non-routable]</span>
<span class="c">#    192.168.10.10:30732 (0)   0.0.0.0:0 (18) (0) [NodePort]</span>
<span class="c">#    10.0.2.15:30732 (0)       0.0.0.0:0 (17) (0) [NodePort]</span>
<span class="nv">$ </span>c0 bpf lb list <span class="nt">--revnat</span>
<span class="c"># =&gt; ID   BACKEND ADDRESS (REVNAT_ID) (SLOT)</span>
<span class="c">#    7    10.10.200.180:443</span>
<span class="c">#    6    10.10.200.10:9153</span>
<span class="c">#    ...</span>
<span class="c">#    1    10.10.200.1:443</span>
<span class="c">#    17   10.0.2.15:30732</span>
<span class="c">#    16   0.0.0.0:30732</span>
<span class="c">#    18   192.168.10.10:30732</span>
<span class="nv">$ </span>c0 bpf nat list
<span class="c"># =&gt; TCP OUT 192.168.10.10:34576 -&amp;gt; 192.168.10.101:4240 XLATE_SRC 192.168.10.10:34576 Created=409sec ago NeedsCT=1</span>
<span class="c">#    TCP IN 192.168.10.101:4240 -&amp;gt; 192.168.10.10:34576 XLATE_DST 192.168.10.10:34576 Created=409sec ago NeedsCT=1</span>
<span class="c">#    ICMP OUT 192.168.10.10:35656 -&amp;gt; 172.16.1.224:0 XLATE_SRC 192.168.10.10:35656 Created=169sec ago NeedsCT=1</span>
<span class="c">#    ICMP OUT 192.168.10.10:35656 -&amp;gt; 192.168.10.102:0 XLATE_SRC 192.168.10.10:35656 Created=169sec ago NeedsCT=1</span>
<span class="c">#    ...</span>

<span class="c"># List all open BPF maps</span>
<span class="nv">$ </span>c0 map list
<span class="c"># =&gt; Name                       Num entries   Num errors   Cache enabled</span>
<span class="c">#    cilium_lb4_backends_v3     2             0            true</span>
<span class="c">#    cilium_lb4_source_range    0             0            true</span>
<span class="c">#    cilium_policy_01196        2             0            true</span>
<span class="c">#    cilium_policy_01598        3             0            true</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>c0 map list <span class="nt">--verbose</span>

<span class="c"># List contents of a policy BPF map : Dump all policy maps</span>
<span class="nv">$ </span>c0 bpf policy get <span class="nt">--all</span>
<span class="nv">$ </span>c0 bpf policy get <span class="nt">--all</span> <span class="nt">-n</span>

<span class="c"># cilium monitor</span>
<span class="nv">$ </span>c0 monitor <span class="nt">-v</span>
<span class="c"># =&gt; Listening for events on 4 CPUs with 64x4096 of shared memory</span>
<span class="c">#    Press Ctrl-C to quit</span>
<span class="c">#    time=&amp;quot;2024-10-01T12:11:28Z&amp;quot; level=info msg=&amp;quot;Initializing dissection cache...&amp;quot; subsys=monitor</span>
<span class="c">#    -&amp;gt; network flow 0x206747a1 , identity health-&amp;gt;remote-node state reply ifindex enp0s8 orig-ip 0.0.0.0: 172.16.0.26:4240 -&amp;gt; 192.168.10.102:39142 tcp ACK</span>
<span class="c">#    -&amp;gt; endpoint 1598 flow 0x0 , identity remote-node-&amp;gt;health state established ifindex lxc_health orig-ip 192.168.10.102: 192.168.10.102:39142 -&amp;gt; 172.16.0.26:4240 tcp ACK</span>
<span class="c">#    -&amp;gt; endpoint 640 flow 0x665dd157 , identity host-&amp;gt;37523 state new ifindex lxcdd00fea91485 orig-ip 10.0.2.15: 10.0.2.15:37040 -&amp;gt; 172.16.0.223:8081 tcp SYN</span>
<span class="c">#    -&amp;gt; stack flow 0xf0f2648f , identity 37523-&amp;gt;host state reply ifindex 0 orig-ip 0.0.0.0: 172.16.0.223:8081 -&amp;gt; 10.0.2.15:37040 tcp SYN, ACK</span>
<span class="c">#    -&amp;gt; endpoint 640 flow 0x665dd157 , identity host-&amp;gt;37523 state established ifindex lxcdd00fea91485 orig-ip 10.0.2.15: 10.0.2.15:37040 -&amp;gt; 172.16.0.223:8081 tcp ACK</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 cilium monitor는 자체적으로 마치 tcpdump처럼 패킷의 이동을 모니터링 할 수 있습니다.&lt;/span&gt;</span>
<span class="nv">$ </span>c0 monitor <span class="nt">-v</span> <span class="nt">--type</span> l7   <span class="c"># Layer 7 (Application layer) 만을 모니터링할 수도 있습니다.</span>
<span class="c"># =&gt; CPU 01: [pre-xlate-rev] cgroup_id: 5161 sock_cookie: 14187, dst [10.0.2.15]:43070 tcp</span>
<span class="c">#    CPU 01: [pre-xlate-rev] cgroup_id: 2800 sock_cookie: 14188, dst [172.16.0.223]:8081 tcp</span>
<span class="c">#    CPU 01: [pre-xlate-rev] cgroup_id: 5161 sock_cookie: 14189, dst [10.0.2.15]:43080 tcp</span>
<span class="c">#    CPU 01: [pre-xlate-rev] cgroup_id: 2800 sock_cookie: 10103, dst [172.16.0.223]:8081 tcp</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<h5 id="네트워크-기본-정보-확인--k3s-w1w2-에-ssh-접속-후-ip--c-linkroute-정보-확인">네트워크 기본 정보 확인 : k3s-w1/w2 에 SSH 접속 후 ip -c link/route 정보 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 네트워크 인터페이스 정보 확인</span>
<span class="nv">$ </span>ip <span class="nt">-br</span> <span class="nt">-c</span> <span class="nb">link</span>
<span class="c"># =&gt; lo               UNKNOWN        00:00:00:00:00:00 &amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt;</span>
<span class="c">#    enp0s3           UP             02:6d:da:b3:d4:d3 &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt;</span>
<span class="c">#    enp0s8           UP             08:00:27:35:1b:07 &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt;</span>
<span class="c">#    cilium_net@cilium_host UP             16:9d:bb:67:fc:a0 &amp;lt;BROADCAST,MULTICAST,NOARP,UP,LOWER_UP&amp;gt;</span>
<span class="c">#    cilium_host@cilium_net UP             7e:ea:43:69:1e:4b &amp;lt;BROADCAST,MULTICAST,NOARP,UP,LOWER_UP&amp;gt;</span>
<span class="c">#    lxcb0b60514c056@if10 UP             be:61:78:59:9a:b9 &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt;</span>
<span class="c">#    lxcb6d4cfe53c6a@if12 UP             b6:62:74:02:2f:32 &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt;</span>
<span class="c">#    lxc_health@if18  UP             aa:7e:99:a8:fd:c3 &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt;</span>
<span class="nv">$ </span>ip <span class="nt">-br</span> <span class="nt">-c</span> addr
<span class="c"># =&gt; lo               UNKNOWN        127.0.0.1/8 ::1/128</span>
<span class="c">#    enp0s3           UP             10.0.2.15/24 metric 100 fe80::6d:daff:feb3:d4d3/64</span>
<span class="c">#    enp0s8           UP             192.168.10.101/24 fe80::a00:27ff:fe35:1b07/64</span>
<span class="c">#    cilium_net@cilium_host UP             fe80::149d:bbff:fe67:fca0/64</span>
<span class="c">#    cilium_host@cilium_net UP             172.16.1.82/32 fe80::7cea:43ff:fe69:1e4b/64</span>
<span class="c">#    lxcb0b60514c056@if10 UP             fe80::bc61:78ff:fe59:9ab9/64</span>
<span class="c">#    lxcb6d4cfe53c6a@if12 UP             fe80::b462:74ff:fe02:2f32/64</span>
<span class="c">#    lxc_health@if18  UP             fe80::a87e:99ff:fea8:fdc3/64</span>

<span class="nt">--------------------------------------------</span>
<span class="c"># cilium_net 과 cilium_host 는 veth peer 관계이며, cilium_host 는 파드의 GW IP 주소로 지정되며 32bit 이다</span>
<span class="c"># =&gt; 4: cilium_net@cilium_host: &amp;lt;BROADCAST,MULTICAST,NOARP,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span>
<span class="c">#        link/ether 16:9d:bb:67:fc:a0 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet6 fe80::149d:bbff:fe67:fca0/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    5: cilium_host@cilium_net: &amp;lt;BROADCAST,MULTICAST,NOARP,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span>
<span class="c">#        link/ether 7e:ea:43:69:1e:4b brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet 172.16.1.82/32 scope global cilium_host</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#        inet6 fe80::7cea:43ff:fe69:1e4b/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>

<span class="c"># proxy arp 는 disable(0) 상태이며, 파드와 연결된 lxc 도 모두 0 이다</span>
<span class="c"># 파드의 32bit ip의 gw 가 각각 연결된 veth 인터페이스의 mac 으로 cilium_host 의 IP/MAC 응답을 처리한다, 어떻게 동작이 되는걸까요? &gt;&gt; eBPF program!!!</span>
<span class="nv">$ </span><span class="nb">cat</span> /proc/sys/net/ipv4/conf/cilium_net/proxy_arp
<span class="c"># =&gt; 0</span>
<span class="nv">$ </span><span class="nb">cat</span> /proc/sys/net/ipv4/conf/cilium_host/proxy_arp
<span class="c"># =&gt; 0</span>

<span class="c"># lxc_health 인터페이스는 veth 로 cilium(NET NS 0, 호스트와 다름)과 veth pair 이다 - 링크</span>
<span class="c"># cilium 인터페이스에 파드 IP가 할당되어 있으며, cilium-health-responder 로 동작한다</span>
<span class="nv">$ </span>lsns <span class="nt">-t</span> net
<span class="c"># =&gt;         NS TYPE NPROCS   PID USER     NETNSID NSFS                                                COMMAND</span>
<span class="c">#    4026531840 net     133     1 root  unassigned                                                     /sbin/init</span>
<span class="c">#    4026532195 net       2  8433 65535          1 /run/netns/cni-0943b57a-e695-904e-87f6-7edb4fb0cd92 /pause</span>
<span class="c">#    4026532350 net       1 18060 root           0                                                     cilium-health-responder --listen 4240 --pidfile /var/run/cilium/state/health-endp</span>
<span class="c">#    4026532359 net       2 10652 65535          2 /run/netns/cni-1b359731-9a53-2db0-eee1-63b0c5643c27 /pause</span>
</code></pre></div></div>

<h4 id="hubble">Hubble</h4>

<p>Cillium은 Hubble을 통해 통신 및 서비스와 네트워킹 인프라의 동작에 대한 심층적인 가시성을 완전히 투명한 방식으로 관찰성을 제공합니다. - <a href="https://cilium.io/blog/2019/11/19/announcing-hubble/">참고</a></p>
<ul>
  <li>Hubble은 <strong>완전히 분산된 네트워킹 및 보안 모니터링</strong> 플랫폼입니다</li>
  <li>Cilium 과 eBPF 기반으로 동작하며, <strong>어플리케이션 수정없이도</strong> 보다 심도있는 가시성을 제공합니다.</li>
  <li>Hubble은 컨테이너 기반 워크로드 뿐만 아니라 전통적인 <strong>표준 리눅스 프로세스나 VM 기반 워크로드에 대해서도 가시성을 제공</strong>합니다.</li>
  <li>eBPF를 사용함으로써 전통적인 IP 기반이 아닌 <strong>서비스/파드/컨테이너 수준의 네트워크 트래픽</strong>에 대해서 보안 가시성 및 통제를 제공할 수 있습니다.
또한 <strong>어플리케이션 레이어(L7)에서 필터링 할 수 도</strong> 있습니다.</li>
  <li>기본적으로 Hubble API는 Cilium 에이전트가 실행되는 개별 노드의 범위 내에서 작동합니다. 
이는 네트워크 통찰력을 로컬 Cilium 에이전트가 관찰한 트래픽으로 제한합니다.<br />
Hubble <strong>CLI</strong>(<code class="language-plaintext highlighter-rouge">hubble</code>)를 사용하여 <strong>로컬 Unix Domain Socket</strong>을 통해 제공된 <strong>Hubble API를 쿼리</strong>할 수 있습니다. Hubble CLI 바이너리는 기본적으로 Cilium 에이전트 포드에 설치됩니다.</li>
  <li><strong>Hubble Relay</strong>를 배포하면 전체 클러스터 또는 ClusterMesh 시나리오의 여러 <strong>클러스터에 대한 네트워크 가시성</strong>이 제공됩니다. 이 모드에서 Hubble 데이터는 Hubble CLI(<code class="language-plaintext highlighter-rouge">hubble</code>)를 Hubble Relay 서비스로 지정하거나 Hubble UI를 통해 액세스할 수 있습니다. Hubble UI는 L3/L4 및 L7 계층에서 서비스 종속성 그래프를 자동으로 검색할 수 있는 웹 인터페이스로, 사용자 친화적인 시각화 및 서비스 맵으로서의 데이터 흐름 필터링을 허용합니다.
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_10.png" alt="img.png" class="image-center w-80" />
<em class="image-caption">Hubble Relay를 통한 전체 클러스터 모니터링 <a href="https://cilium.io/blog/2020/06/22/cilium-18/">링크</a></em></li>
  <li>메트릭은 <strong>Prometheus</strong>로 수집되며, <strong>Grafana</strong>를 통해 시각화할 수도 있어서 기존의 대시보드와 통합도 가능합니다.
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_9.png" alt="img.png" class="image-center w-80" />
<em class="image-caption"><a href="https://cilium.io/blog/2019/11/19/announcing-hubble/">https://cilium.io/blog/2019/11/19/announcing-hubble/</a></em></li>
  <li>Hubble UI 화면
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_11.png" alt="img.png" class="image-center w-100" />
<em class="image-caption">서비스 종속성 그래프</em></li>
  <li>통제 예시
    <ul>
      <li><code class="language-plaintext highlighter-rouge">/public/.*</code> 경로에 대한 <code class="language-plaintext highlighter-rouge">GET</code> 요청만 허용하고, 다른 모든 요청은 거부</li>
      <li><code class="language-plaintext highlighter-rouge">service1</code>이 <code class="language-plaintext highlighter-rouge">topic1</code>이라는 토픽을 생산하고, <code class="language-plaintext highlighter-rouge">service2</code>가 <code class="language-plaintext highlighter-rouge">topic1</code>을 소비하도록 허용하고, 그 외의 모든 카프카 메시지는 거부</li>
      <li>HTTP 헤더에 <code class="language-plaintext highlighter-rouge">X-Token: [0-9]+</code>가 포함된 모든 요청을 허용하고, 그렇지 않은 요청은 거부</li>
    </ul>
  </li>
</ul>

<h5 id="hubble-uicli-접근-및-확인">Hubble UI/CLI 접근 및 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 확인</span>
<span class="nv">$ </span>cilium status
<span class="c"># =&gt;     /¯¯\</span>
<span class="c">#     /¯¯\__/¯¯\    Cilium:             OK</span>
<span class="c">#     \__/¯¯\__/    Operator:           OK</span>
<span class="c">#     /¯¯\__/¯¯\    Envoy DaemonSet:    OK</span>
<span class="c">#     \__/¯¯\__/    Hubble Relay:       OK</span>
<span class="c">#        \__/       ClusterMesh:        disabled</span>
<span class="c">#    </span>
<span class="c">#    DaemonSet              cilium             Desired: 3, Ready: 3/3, Available: 3/3</span>
<span class="c">#    ...</span>

<span class="c"># UI 파드 정보 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>hubble-ui <span class="nt">-o</span> wide
<span class="c"># =&gt; NAME                         READY   STATUS    RESTARTS      AGE    IP             NODE    NOMINATED NODE   READINESS GATES</span>
<span class="c">#    hubble-ui-59bb4cb67b-r48tz   2/2     Running   2 (87m ago)   101m   172.16.0.223   k3s-m   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>

<span class="c"># Hubble UI 웹 접속</span>
<span class="nv">$ </span>kubectl patch <span class="nt">-n</span> kube-system svc hubble-ui <span class="nt">-p</span> <span class="s1">'{"spec": {"type": "NodePort"}}'</span>
<span class="c"># =&gt; service/hubble-ui patched</span>
<span class="nv">$ HubbleUiNodePort</span><span class="o">=</span><span class="si">$(</span>kubectl get svc <span class="nt">-n</span> kube-system hubble-ui <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.spec.ports[0].nodePort<span class="o">}</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"Hubble UI URL = http://</span><span class="si">$(</span>curl <span class="nt">-s</span> ipinfo.io/ip<span class="si">)</span><span class="s2">:</span><span class="nv">$HubbleUiNodePort</span><span class="s2">"</span>
<span class="c"># =&gt; Hubble UI URL = http://54.180.146.116:30732</span>

<span class="c">## Service NodePort 생성 후 아래 정보 확인!</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span>
<span class="c"># =&gt; -P PREROUTING ACCEPT</span>
<span class="c">#    -P INPUT ACCEPT</span>
<span class="c">#    -P OUTPUT ACCEPT</span>
<span class="c">#    -P POSTROUTING ACCEPT</span>
<span class="c">#    ...</span>
<span class="c">#    -N KUBE-EXT-ZGWW2L4XLRSDZ3EF</span>
<span class="c">#    -N KUBE-MARK-MASQ</span>
<span class="c">#    -N KUBE-NODEPORTS</span>
<span class="c">#    ...</span>
<span class="c">#    -N KUBE-SEP-UOFUVE4S3JB7NP6T</span>
<span class="c">#    -N KUBE-SERVICES</span>
<span class="c">#    ...</span>
<span class="c">#    # &lt;span style="color: green;"&gt;👉 (1)&lt;/span&gt;-A PREROUTING -m comment --comment &amp;quot;kubernetes service portals&amp;quot; -j KUBE-SERVICES</span>
<span class="c">#    ...</span>
<span class="c">#    # &lt;span style="color: green;"&gt;👉 (4)&lt;/span&gt;-A KUBE-EXT-ZGWW2L4XLRSDZ3EF -m comment --comment &amp;quot;masquerade traffic for kube-system/hubble-ui:http external destinations&amp;quot; -j KUBE-MARK-MASQ</span>
<span class="c">#    # &lt;span style="color: green;"&gt;👉 (5)&lt;/span&gt;-A KUBE-EXT-ZGWW2L4XLRSDZ3EF -j KUBE-SVC-ZGWW2L4XLRSDZ3EF</span>
<span class="c">#    -A KUBE-MARK-MASQ -j MARK --set-xmark 0x4000/0x4000</span>
<span class="c">#    # &lt;span style="color: green;"&gt;👉 (3)&lt;/span&gt;-A KUBE-NODEPORTS -p tcp -m comment --comment &amp;quot;kube-system/hubble-ui:http&amp;quot; -m tcp --dport 30732 -j KUBE-EXT-ZGWW2L4XLRSDZ3EF</span>
<span class="c">#    ...</span>
<span class="c">#    # &lt;span style="color: green;"&gt;👉 (8)&lt;/span&gt;-A KUBE-SEP-UOFUVE4S3JB7NP6T -s 172.16.0.223/32 -m comment --comment &amp;quot;kube-system/hubble-ui:http&amp;quot; -j KUBE-MARK-MASQ</span>
<span class="c">#    # &lt;span style="color: green;"&gt;👉 (9)&lt;/span&gt;-A KUBE-SEP-UOFUVE4S3JB7NP6T -p tcp -m comment --comment &amp;quot;kube-system/hubble-ui:http&amp;quot; -m tcp -j DNAT --to-destination 172.16.0.223:8081</span>
<span class="c">#    ...</span>
<span class="c">#    # &lt;span style="color: green;"&gt;👉 (2)&lt;/span&gt;-A KUBE-SERVICES -m comment --comment &amp;quot;kubernetes service nodeports; NOTE: this must be the last rule in this chain&amp;quot; -m addrtype --dst-type LOCAL -j KUBE-NODEPORTS</span>
<span class="c">#    ...</span>
<span class="c">#    # &lt;span style="color: green;"&gt;👉 (6)&lt;/span&gt;-A KUBE-SVC-ZGWW2L4XLRSDZ3EF ! -s 172.16.0.0/16 -d 10.10.200.125/32 -p tcp -m comment --comment &amp;quot;kube-system/hubble-ui:http cluster IP&amp;quot; -m tcp --dport 80 -j KUBE-MARK-MASQ</span>
<span class="c">#    # &lt;span style="color: green;"&gt;👉 (7)&lt;/span&gt;-A KUBE-SVC-ZGWW2L4XLRSDZ3EF -m comment --comment &amp;quot;kube-system/hubble-ui:http -&amp;gt; 172.16.0.223:8081&amp;quot; -j KUBE-SEP-UOFUVE4S3JB7NP6T</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 (1) PREROUTING =&gt; (2) KUBE-SERVICES =&gt; (3) KUBE-NODEPORTS &lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;    if 노드 포트인 30732로 접속:&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;        =&gt; (4,5) KUBE-EXT-ZGWW2L4XLRSDZ3EF&lt;/span&gt; </span>
<span class="c"># &lt;span style="color: green;"&gt;        =&gt; (6,7) KUBE-SVC-ZGWW2L4XLRSDZ3EF =&gt; (8,9) KUBE-SEP-UOFUVE4S3JB7NP6T =&gt; 172.16.0.223:8081&lt;/span&gt;</span>

<span class="nv">$ </span>conntrack <span class="nt">-L</span>
<span class="nv">$ </span>conntrack <span class="nt">-L</span> |grep <span class="nt">-v</span> 2379

<span class="c"># Install Hubble Client</span>
<span class="nv">$ HUBBLE_VERSION</span><span class="o">=</span><span class="si">$(</span>curl <span class="nt">-s</span> https://raw.githubusercontent.com/cilium/hubble/master/stable.txt<span class="si">)</span>
<span class="nv">$ HUBBLE_ARCH</span><span class="o">=</span>amd64
<span class="nv">$ </span><span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span><span class="si">)</span><span class="s2">"</span> <span class="o">=</span> <span class="s2">"aarch64"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then </span><span class="nv">HUBBLE_ARCH</span><span class="o">=</span>arm64<span class="p">;</span> <span class="k">fi</span>
<span class="nv">$ </span>curl <span class="nt">-L</span> <span class="nt">--fail</span> <span class="nt">--remote-name-all</span> https://github.com/cilium/hubble/releases/download/<span class="nv">$HUBBLE_VERSION</span>/hubble-linux-<span class="k">${</span><span class="nv">HUBBLE_ARCH</span><span class="k">}</span>.tar.gz<span class="o">{</span>,.sha256sum<span class="o">}</span>
<span class="nv">$ </span><span class="nb">sha256sum</span> <span class="nt">--check</span> hubble-linux-<span class="k">${</span><span class="nv">HUBBLE_ARCH</span><span class="k">}</span>.tar.gz.sha256sum
<span class="nv">$ </span><span class="nb">sudo tar </span>xzvfC hubble-linux-<span class="k">${</span><span class="nv">HUBBLE_ARCH</span><span class="k">}</span>.tar.gz /usr/local/bin
<span class="c"># =&gt; hubble</span>
<span class="nv">$ </span><span class="nb">rm </span>hubble-linux-<span class="k">${</span><span class="nv">HUBBLE_ARCH</span><span class="k">}</span>.tar.gz<span class="o">{</span>,.sha256sum<span class="o">}</span>

<span class="c"># Hubble API Access : localhost TCP 4245 Relay 를 통해 접근, observe 를 통해서 flow 쿼리 확인 가능!</span>
<span class="nv">$ </span>cilium hubble port-forward &amp;
<span class="c"># =&gt; [1] 16534</span>

<span class="c"># CLI 로 Hubble API 상태 확인</span>
<span class="nv">$ </span>hubble status
<span class="c"># =&gt; Healthcheck (via localhost:4245): Ok</span>
<span class="c">#    Current/Max Flows: 12,285/12,285 (100.00%)</span>
<span class="c">#    Flows/s: 24.50</span>
<span class="c">#    Connected Nodes: 3/3</span>

<span class="c"># query the flow API and look for flows</span>
<span class="nv">$ </span>hubble observe
<span class="c"># =&gt; Oct 01 13:26:17.501: kube-system/local-path-provisioner-6795b5f9d8-84m96:60994 (ID:11088) -&amp;gt; 192.168.10.10:6443 (kube-apiserver) to-network FORWARDED (TCP Flags: ACK)</span>
<span class="c">#    Oct 01 13:26:17.660: kube-system/hubble-ui-59bb4cb67b-r48tz:47372 (ID:37523) -&amp;gt; kube-system/hubble-relay-88f7f89d4-fcq2s:4245 (ID:4124) to-network FORWARDED (TCP Flags: ACK)</span>
<span class="c">#    Oct 01 13:26:17.797: 127.0.0.1:36150 (world) &amp;lt;&amp;gt; kube-system/hubble-ui-59bb4cb67b-r48tz (ID:37523) pre-xlate-rev TRACED (TCP)</span>
<span class="c">#    Oct 01 13:26:17.914: 192.168.10.102:38716 (host) -&amp;gt; 192.168.10.10:6443 (kube-apiserver) to-network FORWARDED (TCP Flags: ACK)</span>
<span class="c">#    Oct 01 13:26:18.011: 127.0.0.1:36160 (world) &amp;lt;&amp;gt; kube-system/hubble-ui-59bb4cb67b-r48tz (ID:37523) pre-xlate-rev TRACED (TCP)</span>
<span class="c">#    Oct 01 13:26:18.067: 10.0.2.15:59486 (host) -&amp;gt; kube-system/metrics-server-cdcc87586-g5m2d:10250 (ID:27624) to-endpoint FORWARDED (TCP Flags: SYN)</span>
<span class="c">#    Oct 01 13:26:18.067: 10.0.2.15:59486 (host) &amp;lt;- kube-system/metrics-server-cdcc87586-g5m2d:10250 (ID:27624) to-stack FORWARDED (TCP Flags: SYN, ACK)</span>
<span class="c">#    ...</span>
<span class="c"># hubble observe --pod netpod</span>
<span class="c"># hubble observe --namespace galaxy --http-method POST --http-path /v1/request-landing</span>
<span class="c"># hubble observe --pod deathstar --protocol http</span>
<span class="c"># hubble observe --pod deathstar --verdict DROPPED</span>
</code></pre></div></div>

<h4 id="노드간-파드-통신">노드간 파드 통신</h4>

<ul>
  <li>
    <p>Endpoint to Endpoint 통신 패킷 흐름도
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_12.png" alt="img.png" class="image-center w-100" /></p>
  </li>
  <li>
    <p>Egress to Endpoint 통신 패킷 흐름도
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_13.png" alt="img_1.png" class="image-center w-100" /></p>
  </li>
  <li>
    <p>Ingress to Endpoint 통신 패킷 흐름도
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_14.png" alt="img_2.png" class="image-center w-100" /></p>
  </li>
  <li>
    <p>파드 생성 및 확인</p>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl create -f -
apiVersion: v1
kind: Pod
metadata:
  name: netpod
  labels:
    app: netpod
spec:
  nodeName: k3s-m
  containers:
  - name: netshoot-pod
    image: nicolaka/netshoot
    command: ["tail"]
    args: ["-f", "/dev/null"]
  terminationGracePeriodSeconds: 0
---
apiVersion: v1
kind: Pod
metadata:
  name: webpod1
  labels:
    app: webpod
spec:
  nodeName: k3s-w1
  containers:
  - name: container
    image: traefik/whoami
  terminationGracePeriodSeconds: 0
---
apiVersion: v1
kind: Pod
metadata:
  name: webpod2
  labels:
    app: webpod
spec:
  nodeName: k3s-w2
  containers:
  - name: container
    image: traefik/whoami
  terminationGracePeriodSeconds: 0
</span><span class="no">EOF
</span><span class="c"># =&gt; pod/netpod created</span>
<span class="c">#    pod/webpod1 created</span>
<span class="c">#    pod/webpod2 created</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-o</span> wide
<span class="c"># =&gt; NAME      READY   STATUS    RESTARTS   AGE   IP             NODE     NOMINATED NODE   READINESS GATES</span>
<span class="c">#    netpod    1/1     Running   0          36s   172.16.0.147   k3s-m    &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    webpod1   1/1     Running   0          36s   172.16.1.247   k3s-w1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    webpod2   1/1     Running   0          36s   172.16.2.84    k3s-w2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="nv">$ </span>c0 status <span class="nt">--verbose</span> | <span class="nb">grep </span>Allocated <span class="nt">-A5</span>
<span class="c"># =&gt; Allocated addresses:</span>
<span class="c">#      172.16.0.147 (default/netpod)</span>
<span class="c">#      172.16.0.223 (kube-system/hubble-ui-59bb4cb67b-r48tz [restored])</span>
<span class="c">#      172.16.0.227 (router)</span>
<span class="c">#      172.16.0.26 (health)</span>
<span class="c">#    IPv4 BIG TCP:           Disabled</span>
<span class="nv">$ </span>c1 status <span class="nt">--verbose</span> | <span class="nb">grep </span>Allocated <span class="nt">-A5</span>
<span class="c"># =&gt; Allocated addresses:</span>
<span class="c">#      172.16.1.21 (kube-system/coredns-7b98449c4-x5756 [restored])</span>
<span class="c">#      172.16.1.224 (health)</span>
<span class="c">#      172.16.1.247 (default/webpod1)</span>
<span class="c">#      172.16.1.82 (router)</span>
<span class="c">#      172.16.1.99 (kube-system/hubble-relay-88f7f89d4-fcq2s [restored])</span>
<span class="nv">$ </span>c2 status <span class="nt">--verbose</span> | <span class="nb">grep </span>Allocated <span class="nt">-A5</span>
<span class="c"># =&gt; Allocated addresses:</span>
<span class="c">#      172.16.2.184 (kube-system/local-path-provisioner-6795b5f9d8-84m96 [restored])</span>
<span class="c">#      172.16.2.223 (kube-system/metrics-server-cdcc87586-g5m2d [restored])</span>
<span class="c">#      172.16.2.25 (router)</span>
<span class="c">#      172.16.2.8 (health)</span>
<span class="c">#      172.16.2.84 (default/webpod2)</span>

<span class="nv">$ </span>kubectl get ciliumendpoints
<span class="c"># =&gt; NAME      SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    netpod    27629               ready            172.16.0.147</span>
<span class="c">#    webpod1   64309               ready            172.16.1.247</span>
<span class="c">#    webpod2   64309               ready            172.16.2.84</span>
<span class="nv">$ </span>kubectl get ciliumendpoints <span class="nt">-A</span>
<span class="c"># =&gt; root@k3s-m:~# kubectl get ciliumendpoints -A</span>
<span class="c">#    NAMESPACE     NAME                                      SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    default       netpod                                    27629               ready            172.16.0.147</span>
<span class="c">#    default       webpod1                                   64309               ready            172.16.1.247</span>
<span class="c">#    default       webpod2                                   64309               ready            172.16.2.84</span>
<span class="c">#    kube-system   coredns-7b98449c4-x5756                   11970               ready            172.16.1.21</span>
<span class="c">#    kube-system   hubble-relay-88f7f89d4-fcq2s              4124                ready            172.16.1.99</span>
<span class="c">#    kube-system   hubble-ui-59bb4cb67b-r48tz                37523               ready            172.16.0.223</span>
<span class="c">#    kube-system   local-path-provisioner-6795b5f9d8-84m96   11088               ready            172.16.2.184</span>
<span class="c">#    kube-system   metrics-server-cdcc87586-g5m2d            27624               ready            172.16.2.223</span>
<span class="nv">$ </span>c0 endpoint list
<span class="c"># =&gt; ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])                                                  IPv6   IPv4           STATUS</span>
<span class="c">#               ENFORCEMENT        ENFORCEMENT</span>
<span class="c">#    640        Disabled           Disabled          37523      k8s:app.kubernetes.io/name=hubble-ui                                                172.16.0.223   ready</span>
<span class="c">#                                                               k8s:app.kubernetes.io/part-of=cilium</span>
<span class="c">#                                                               k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=kube-system</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.cluster=default</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.serviceaccount=hubble-ui</span>
<span class="c">#                                                               k8s:io.kubernetes.pod.namespace=kube-system</span>
<span class="c">#                                                               k8s:k8s-app=hubble-ui</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>c0 bpf endpoint list
<span class="c"># =&gt; IP ADDRESS        LOCAL ENDPOINT INFO</span>
<span class="c">#    192.168.10.10:0   (localhost)</span>
<span class="c">#    10.0.2.15:0       (localhost)</span>
<span class="c">#    172.16.0.147:0    id=2724  sec_id=27629 flags=0x0000 ifindex=19  mac=52:59:78:2F:C0:BE nodemac=7E:77:FA:0A:D3:CC</span>
<span class="c">#    172.16.0.26:0     id=1598  sec_id=4     flags=0x0000 ifindex=17  mac=CE:24:50:27:35:B9 nodemac=FE:57:C1:AD:A6:28</span>
<span class="c">#    172.16.0.223:0    id=640   sec_id=37523 flags=0x0000 ifindex=9   mac=AE:B8:81:A6:B1:28 nodemac=C2:21:B8:92:DA:FD</span>
<span class="c">#    172.16.0.227:0    (localhost)</span>
<span class="nv">$ </span>c0 map get cilium_lxc
<span class="c"># =&gt; Key              Value                                                                                            State   Error</span>
<span class="c">#    172.16.0.147:0   id=2724  sec_id=27629 flags=0x0000 ifindex=19  mac=52:59:78:2F:C0:BE nodemac=7E:77:FA:0A:D3:CC   sync</span>
<span class="c">#    172.16.0.223:0   id=640   sec_id=37523 flags=0x0000 ifindex=9   mac=AE:B8:81:A6:B1:28 nodemac=C2:21:B8:92:DA:FD   sync</span>
<span class="c">#    172.16.0.26:0    id=1598  sec_id=4     flags=0x0000 ifindex=17  mac=CE:24:50:27:35:B9 nodemac=FE:57:C1:AD:A6:28   sync</span>
<span class="nv">$ </span>c0 ip list
<span class="c"># =&gt; IP                  IDENTITY                                                                         SOURCE</span>
<span class="c">#    0.0.0.0/0           reserved:world</span>
<span class="c">#    10.0.2.15/32        reserved:host</span>
<span class="c">#                        reserved:kube-apiserver</span>
<span class="c">#    172.16.0.26/32      reserved:health</span>
<span class="c">#    172.16.0.147/32     k8s:app=netpod                                                                   custom-resource</span>
<span class="c">#                        k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<ul>
  <li>파드 변수 지정</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 테스트 파드들 IP</span>
<span class="nv">$ NETPODIP</span><span class="o">=</span><span class="si">$(</span>kubectl get pods netpod <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.podIP}'</span><span class="si">)</span>
<span class="nv">$ WEBPOD1IP</span><span class="o">=</span><span class="si">$(</span>kubectl get pods webpod1 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.podIP}'</span><span class="si">)</span>
<span class="nv">$ WEBPOD2IP</span><span class="o">=</span><span class="si">$(</span>kubectl get pods webpod2 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.podIP}'</span><span class="si">)</span>

<span class="c"># 단축키(alias) 지정</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">p0</span><span class="o">=</span><span class="s2">"kubectl exec -it netpod  -- "</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">p1</span><span class="o">=</span><span class="s2">"kubectl exec -it webpod1 -- "</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">p2</span><span class="o">=</span><span class="s2">"kubectl exec -it webpod2 -- "</span>
</code></pre></div></div>

<ul>
  <li>파드의 ARP 동작 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># netpod 네트워크 정보 확인</span>
<span class="nv">$ </span>p0 ip <span class="nt">-c</span> <span class="nt">-4</span> addr
<span class="c"># =&gt; ...</span>
<span class="c">#    18: eth0@if19: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UP group default qlen 1000 link-netnsid 0</span>
<span class="c">#        inet 172.16.0.147/32 scope global eth0</span>
<span class="nv">$ </span>p0 route <span class="nt">-n</span>
<span class="c"># =&gt; Kernel IP routing table</span>
<span class="c">#    Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span>
<span class="c">#    0.0.0.0         172.16.0.227    0.0.0.0         UG    0      0        0 eth0</span>
<span class="c">#    172.16.0.227    0.0.0.0         255.255.255.255 UH    0      0        0 eth0</span>
<span class="nv">$ </span>p0 ping <span class="nt">-c</span> 1 <span class="nv">$WEBPOD1IP</span> <span class="o">&amp;&amp;</span> p0 ping <span class="nt">-c</span> 1 <span class="nv">$WEBPOD2IP</span>
<span class="c"># =&gt; PING 172.16.1.247 (172.16.1.247) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 172.16.1.247: icmp_seq=1 ttl=62 time=0.642 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 172.16.1.247 ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 0.642/0.642/0.642/0.000 ms</span>
<span class="c">#    PING 172.16.2.84 (172.16.2.84) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 172.16.2.84: icmp_seq=1 ttl=62 time=0.716 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 172.16.2.84 ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 0.716/0.716/0.716/0.000 ms</span>
</code></pre></div></div>

<p><img src="/assets/2024/kans-3th/w8/20241026_kans_w8_15.png" alt="img.png" /></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>p0 curl <span class="nt">-s</span> <span class="nv">$WEBPOD1IP</span> <span class="o">&amp;&amp;</span> p0 curl <span class="nt">-s</span> <span class="nv">$WEBPOD2IP</span>
<span class="c"># =&gt; Hostname: webpod1</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: 172.16.1.247</span>
<span class="c">#    RemoteAddr: 172.16.0.147:51692</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: 172.16.1.247</span>
<span class="c">#    User-Agent: curl/8.7.1</span>
<span class="c">#    Accept: */*</span>
<span class="c">#    </span>
<span class="c">#    Hostname: webpod2</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: 172.16.2.84</span>
<span class="c">#    RemoteAddr: 172.16.0.147:32796</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: 172.16.2.84</span>
<span class="c">#    User-Agent: curl/8.7.1</span>
<span class="c">#    Accept: */*</span>
<span class="nv">$ </span>p0 curl <span class="nt">-s</span> <span class="nv">$WEBPOD1IP</span>:8080 <span class="p">;</span> p0 curl <span class="nt">-s</span> <span class="nv">$WEBPOD2IP</span>:8080
<span class="c"># =&gt; command terminated with exit code 7</span>
<span class="c">#    command terminated with exit code 7</span>
<span class="nv">$ </span>p0 ping <span class="nt">-c</span> 1 8.8.8.8 <span class="o">&amp;&amp;</span> p0 curl <span class="nt">-s</span> wttr.in/seoul
<span class="c"># =&gt; PING 8.8.8.8 (8.8.8.8) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 8.8.8.8: icmp_seq=1 ttl=61 time=39.1 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 8.8.8.8 ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 39.095/39.095/39.095/0.000 ms</span>
<span class="c">#    Weather report: seoul</span>
<span class="c">#    </span>
<span class="c">#         \  /       Partly cloudy</span>
<span class="c">#       _ /&amp;quot;&amp;quot;.-.     16 °C</span>
<span class="c">#         \_(   ).   ← 4 km/h</span>
<span class="c">#         /(___(__)  10 km</span>
<span class="c">#                    0.0 mm</span>
<span class="c">#                                                           ┌─────────────┐</span>
<span class="c">#    ┌──────────────────────────────┬───────────────────────┤  Sat 26 Oct ├───────────────────────┬──────────────────────────────┐</span>
<span class="c">#    │            Morning           │             Noon      └──────┬──────┘     Evening           │             Night            │</span>
<span class="c">#    ├──────────────────────────────┼──────────────────────────────┼──────────────────────────────┼──────────────────────────────┤</span>
<span class="c">#    │     \   /     Sunny          │     \   /     Sunny          │               Overcast       │    \  /       Partly Cloudy  │</span>
<span class="c">#    │      .-.      16 °C          │      .-.      21 °C          │      .--.     20 °C          │  _ /&amp;quot;&amp;quot;.-.     19 °C          │</span>
<span class="c">#    │   ― (   ) ―   ↙ 5-7 km/h     │   ― (   ) ―   ↙ 5-6 km/h     │   .-(    ).   ← 4-6 km/h     │    \_(   ).   ↙ 4-7 km/h     │</span>
<span class="c">#    │      `-’      10 km          │      `-’      10 km          │  (___.__)__)  10 km          │    /(___(__)  10 km          │</span>
<span class="c">#    │     /   \     0.0 mm | 0%    │     /   \     0.0 mm | 0%    │               0.0 mm | 0%    │               0.0 mm | 0%    │</span>
<span class="c">#    └──────────────────────────────┴──────────────────────────────┴──────────────────────────────┴──────────────────────────────┘</span>
<span class="c">#                                                           ┌─────────────┐</span>
<span class="c">#    ┌──────────────────────────────┬───────────────────────┤  Sun 27 Oct ├───────────────────────┬──────────────────────────────┐</span>
<span class="c">#    │            Morning           │             Noon      └──────┬──────┘     Evening           │             Night            │</span>
<span class="c">#    ├──────────────────────────────┼──────────────────────────────┼──────────────────────────────┼──────────────────────────────┤</span>
<span class="c">#    │               Overcast       │               Cloudy         │     \   /     Clear          │     \   /     Clear          │</span>
<span class="c">#    │      .--.     16 °C          │      .--.     19 °C          │      .-.      19 °C          │      .-.      17 °C          │</span>
<span class="c">#    │   .-(    ).   ← 1 km/h       │   .-(    ).   ↓ 4-5 km/h     │   ― (   ) ―   ↘ 9-13 km/h    │   ― (   ) ―   ↘ 5-7 km/h     │</span>
<span class="c">#    │  (___.__)__)  10 km          │  (___.__)__)  10 km          │      `-’      10 km          │      `-’      10 km          │</span>
<span class="c">#    │               0.0 mm | 0%    │               0.0 mm | 0%    │     /   \     0.0 mm | 0%    │     /   \     0.0 mm | 0%    │</span>
<span class="c">#    └──────────────────────────────┴──────────────────────────────┴──────────────────────────────┴──────────────────────────────┘</span>
<span class="c">#                                                           ┌─────────────┐</span>
<span class="c">#    ┌──────────────────────────────┬───────────────────────┤  Mon 28 Oct ├───────────────────────┬──────────────────────────────┐</span>
<span class="c">#    │            Morning           │             Noon      └──────┬──────┘     Evening           │             Night            │</span>
<span class="c">#    ├──────────────────────────────┼──────────────────────────────┼──────────────────────────────┼──────────────────────────────┤</span>
<span class="c">#    │     \   /     Sunny          │    \  /       Partly Cloudy  │               Cloudy         │  _`/&amp;quot;&amp;quot;.-.     Patchy rain ne…│</span>
<span class="c">#    │      .-.      16 °C          │  _ /&amp;quot;&amp;quot;.-.     20 °C          │      .--.     20 °C          │   ,\_(   ).   19 °C          │</span>
<span class="c">#    │   ― (   ) ―   ← 5-6 km/h     │    \_(   ).   ← 6-7 km/h     │   .-(    ).   ↙ 6-9 km/h     │    /(___(__)  ← 8-10 km/h    │</span>
<span class="c">#    │      `-’      10 km          │    /(___(__)  10 km          │  (___.__)__)  10 km          │      ‘ ‘ ‘ ‘  10 km          │</span>
<span class="c">#    │     /   \     0.0 mm | 0%    │               0.0 mm | 0%    │               0.0 mm | 0%    │     ‘ ‘ ‘ ‘   0.0 mm | 67%   │</span>
<span class="c">#    └──────────────────────────────┴──────────────────────────────┴──────────────────────────────┴──────────────────────────────┘</span>
<span class="c">#    Location: 서울특별시, 대한민국 [37.5666791,126.9782914]</span>
<span class="c">#    </span>
<span class="c">#    Follow @igor_chubin for wttr.in updates</span>

<span class="nv">$ </span>p0 ip <span class="nt">-c</span> neigh
<span class="c"># =&gt; 172.16.0.227 dev eth0 lladdr 7e:77:fa:0a:d3:cc STALE</span>

<span class="c"># hubble cli 확인</span>
<span class="nv">$ </span>hubble observe <span class="nt">--pod</span> netpod
<span class="c"># =&gt; Oct 01 14:29:21.248: kube-system/coredns-7b98449c4-7kqtg:53 (ID:11970) &amp;lt;&amp;gt; default/netpod (ID:27629) pre-xlate-rev TRACED (UDP)</span>
<span class="c">#    Oct 01 14:29:21.248: kube-system/kube-dns:53 (world) &amp;lt;&amp;gt; default/netpod (ID:27629) post-xlate-rev TRANSLATED (UDP)</span>
<span class="c">#    Oct 01 14:29:21.248: default/netpod:34162 (ID:27629) -&amp;gt; 5.9.243.187:80 (world) to-network FORWARDED (TCP Flags: SYN)</span>
<span class="c">#    Oct 01 14:29:21.481: default/netpod:34162 (ID:27629) -&amp;gt; 5.9.243.187:80 (world) to-network FORWARDED (TCP Flags: ACK, PSH)</span>
<span class="c">#    Oct 01 14:29:21.481: default/netpod:34162 (ID:27629) &amp;lt;- 5.9.243.187:80 (world) to-endpoint FORWARDED (TCP Flags: SYN, ACK)</span>
<span class="c">#    Oct 01 14:29:21.481: default/netpod:34162 (ID:27629) -&amp;gt; 5.9.243.187:80 (world) to-network FORWARDED (TCP Flags: ACK)</span>
<span class="c">#    Oct 01 14:29:21.816: default/netpod:34162 (ID:27629) &amp;lt;- 5.9.243.187:80 (world) to-endpoint FORWARDED (TCP Flags: ACK, PSH)</span>
<span class="c">#    Oct 01 14:29:21.819: default/netpod:34162 (ID:27629) -&amp;gt; 5.9.243.187:80 (world) to-network FORWARDED (TCP Flags: ACK, FIN)</span>
<span class="c">#    Oct 01 14:29:22.052: default/netpod:34162 (ID:27629) &amp;lt;- 5.9.243.187:80 (world) to-endpoint FORWARDED (TCP Flags: ACK, FIN)</span>
<span class="c">#    Oct 01 14:29:22.052: default/netpod:34162 (ID:27629) -&amp;gt; 5.9.243.187:80 (world) to-network FORWARDED (TCP Flags: ACK)</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>hubble observe <span class="nt">--pod</span> webpod1
<span class="c"># =&gt; Oct 01 14:33:40.392: default/netpod:60282 (ID:27629) -&amp;gt; default/webpod1:80 (ID:64309) to-endpoint FORWARDED (TCP Flags: SYN)</span>
<span class="c">#    Oct 01 14:33:40.392: default/netpod:60282 (ID:27629) &amp;lt;- default/webpod1:80 (ID:64309) to-network FORWARDED (TCP Flags: SYN, ACK)</span>
<span class="c">#    Oct 01 14:33:40.392: default/netpod:60282 (ID:27629) &amp;lt;&amp;gt; default/webpod1 (ID:64309) pre-xlate-rev TRACED (TCP)</span>
<span class="c">#    Oct 01 14:33:40.392: default/netpod:60282 (ID:27629) -&amp;gt; default/webpod1:80 (ID:64309) to-endpoint FORWARDED (TCP Flags: ACK)</span>
<span class="c">#    Oct 01 14:33:40.392: default/netpod:60282 (ID:27629) -&amp;gt; default/webpod1:80 (ID:64309) to-endpoint FORWARDED (TCP Flags: ACK, PSH)</span>
<span class="c">#    Oct 01 14:33:40.393: default/netpod:60282 (ID:27629) &amp;lt;- default/webpod1:80 (ID:64309) to-network FORWARDED (TCP Flags: ACK, PSH)</span>
<span class="c">#    Oct 01 14:33:40.393: default/netpod:60282 (ID:27629) -&amp;gt; default/webpod1:80 (ID:64309) to-endpoint FORWARDED (TCP Flags: ACK, FIN)</span>
<span class="c">#    Oct 01 14:33:40.393: default/netpod:60282 (ID:27629) &amp;lt;- default/webpod1:80 (ID:64309) to-network FORWARDED (TCP Flags: ACK, FIN)</span>
<span class="c">#    Oct 01 14:33:40.394: default/netpod:60282 (ID:27629) -&amp;gt; default/webpod1:80 (ID:64309) to-endpoint FORWARDED (TCP Flags: ACK)</span>
<span class="c">#    Oct 01 14:33:40.405: default/netpod:60282 (ID:27629) -&amp;gt; default/webpod1:80 (ID:64309) to-network FORWARDED (TCP Flags: SYN)</span>
<span class="c">#    Oct 01 14:33:40.406: default/netpod:60282 (ID:27629) &amp;lt;- default/webpod1:80 (ID:64309) to-endpoint FORWARDED (TCP Flags: SYN, ACK)</span>
<span class="c">#    Oct 01 14:33:40.406: default/netpod:60282 (ID:27629) -&amp;gt; default/webpod1:80 (ID:64309) to-network FORWARDED (TCP Flags: ACK)</span>
<span class="c">#    Oct 01 14:33:40.406: default/netpod:60282 (ID:27629) -&amp;gt; default/webpod1:80 (ID:64309) to-network FORWARDED (TCP Flags: ACK, PSH)</span>
<span class="c">#    Oct 01 14:33:40.407: default/netpod:60282 (ID:27629) &amp;lt;- default/webpod1:80 (ID:64309) to-endpoint FORWARDED (TCP Flags: ACK, PSH)</span>
<span class="c">#    Oct 01 14:33:40.407: default/netpod:60282 (ID:27629) -&amp;gt; default/webpod1:80 (ID:64309) to-network FORWARDED (TCP Flags: ACK, FIN)</span>
<span class="c">#    Oct 01 14:33:40.408: default/netpod:60282 (ID:27629) &amp;lt;- default/webpod1:80 (ID:64309) to-endpoint FORWARDED (TCP Flags: ACK, FIN)</span>
<span class="c">#    Oct 01 14:33:40.408: default/netpod:60282 (ID:27629) -&amp;gt; default/webpod1:80 (ID:64309) to-network FORWARDED (TCP Flags: ACK)</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 80포트로 접속했을때 정상적인 응답 패킷들&lt;/span&gt;</span>

<span class="c">#    Oct 01 14:33:43.956: default/netpod:34488 (ID:27629) -&amp;gt; default/webpod1:8080 (ID:64309) to-endpoint FORWARDED (TCP Flags: SYN)</span>
<span class="c">#    Oct 01 14:33:43.956: default/netpod:34488 (ID:27629) &amp;lt;- default/webpod1:8080 (ID:64309) to-network FORWARDED (TCP Flags: ACK, RST)</span>
<span class="c">#    Oct 01 14:33:43.970: default/netpod:34488 (ID:27629) -&amp;gt; default/webpod1:8080 (ID:64309) to-network FORWARDED (TCP Flags: SYN)</span>
<span class="c">#    Oct 01 14:33:43.970: default/netpod:34488 (ID:27629) &amp;lt;- default/webpod1:8080 (ID:64309) to-endpoint FORWARDED (TCP Flags: ACK, RST)</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 열려있지 않은 8080포트로 접속했을때 오류가 발생한 패킷들&lt;/span&gt;</span>

<span class="nv">$ </span>hubble observe <span class="nt">--pod</span> webpod2

<span class="c"># BPF maps : 목적지 파드와 통신 시 어느곳으로 보내야 될지 확인할 수 있다</span>
<span class="nv">$ </span>c0 map get cilium_ipcache
<span class="c"># =&gt; Key                 Value                                                                     State   Error</span>
<span class="c">#    172.16.2.182/32     identity=27624 encryptkey=0 tunnelendpoint=192.168.10.102, flags=&amp;lt;none&amp;gt;   sync</span>
<span class="c">#    172.16.2.8/32       identity=4 encryptkey=0 tunnelendpoint=192.168.10.102, flags=&amp;lt;none&amp;gt;       sync</span>
<span class="c">#    172.16.0.147/32     identity=27629 encryptkey=0 tunnelendpoint=0.0.0.0, flags=&amp;lt;none&amp;gt;          sync</span>
<span class="c">#    172.16.0.223/32     identity=37523 encryptkey=0 tunnelendpoint=0.0.0.0, flags=&amp;lt;none&amp;gt;          sync</span>
<span class="c">#    192.168.10.10/32    identity=1 encryptkey=0 tunnelendpoint=0.0.0.0, flags=&amp;lt;none&amp;gt;              sync</span>
<span class="c">#    172.16.0.26/32      identity=4 encryptkey=0 tunnelendpoint=0.0.0.0, flags=&amp;lt;none&amp;gt;              sync</span>
<span class="c">#    10.0.2.15/32        identity=1 encryptkey=0 tunnelendpoint=0.0.0.0, flags=&amp;lt;none&amp;gt;              sync</span>
<span class="c">#    192.168.10.102/32   identity=6 encryptkey=0 tunnelendpoint=0.0.0.0, flags=&amp;lt;none&amp;gt;              sync</span>
<span class="c">#    172.16.1.82/32      identity=6 encryptkey=0 tunnelendpoint=192.168.10.101, flags=&amp;lt;none&amp;gt;       sync</span>
<span class="c">#    172.16.2.237/32     identity=11970 encryptkey=0 tunnelendpoint=192.168.10.102, flags=&amp;lt;none&amp;gt;   sync</span>
<span class="c">#    172.16.2.216/32     identity=64309 encryptkey=0 tunnelendpoint=192.168.10.102, flags=&amp;lt;none&amp;gt;   sync</span>
<span class="c">#    0.0.0.0/0           identity=2 encryptkey=0 tunnelendpoint=0.0.0.0, flags=&amp;lt;none&amp;gt;              sync</span>
<span class="c">#    172.16.2.111/32     identity=11088 encryptkey=0 tunnelendpoint=192.168.10.102, flags=&amp;lt;none&amp;gt;   sync</span>
<span class="c">#    172.16.1.224/32     identity=4 encryptkey=0 tunnelendpoint=192.168.10.101, flags=&amp;lt;none&amp;gt;       sync</span>
<span class="c">#    172.16.2.25/32      identity=6 encryptkey=0 tunnelendpoint=192.168.10.102, flags=&amp;lt;none&amp;gt;       sync</span>
<span class="c">#    192.168.10.101/32   identity=6 encryptkey=0 tunnelendpoint=0.0.0.0, flags=&amp;lt;none&amp;gt;              sync</span>
<span class="c">#    172.16.0.148/32     identity=4124 encryptkey=0 tunnelendpoint=0.0.0.0, flags=&amp;lt;none&amp;gt;           sync</span>
<span class="c">#    172.16.1.247/32     identity=64309 encryptkey=0 tunnelendpoint=192.168.10.101, flags=&amp;lt;none&amp;gt;   sync</span>
<span class="c">#    172.16.0.227/32     identity=1 encryptkey=0 tunnelendpoint=0.0.0.0, flags=&amp;lt;none&amp;gt;              sync</span>
<span class="nv">$ </span>c0 map get cilium_ipcache | <span class="nb">grep</span> <span class="nv">$WEBPOD1IP</span>
<span class="c"># =&gt; 172.16.1.247/32     identity=64309 encryptkey=0 tunnelendpoint=192.168.10.101, flags=&amp;lt;none&amp;gt;   sync</span>

<span class="c"># netpod 의 LXC 변수 지정</span>
<span class="c">#$ LXC=&lt;k3s-m의 가장 나중에 lxc 이름&gt;</span>
<span class="nv">$ LXC</span><span class="o">=</span>lxcd551b3b4058f

<span class="c"># 파드와 veth pair 에 IP가 없습니다! proxy_arp 도 없습니다! 하지만 GW MAC 요청 시 lxc(veth)의 MAC 으로 응답이 옵니다! &gt;&gt; eBPF Magic!</span>
<span class="c"># Cilium hijacks ARP table of POD1, forces the next hop to be the peer end (host side) of the veth pair.</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> addr show dev <span class="nv">$LXC</span>
<span class="c"># =&gt; 23: lxcd551b3b4058f@if22: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span>
<span class="c">#        link/ether fa:32:54:4b:16:d7 brd ff:ff:ff:ff:ff:ff link-netns cni-8634ff07-8cb9-608a-1baf-dc929d510a84</span>
<span class="c">#        inet6 fe80::f832:54ff:fe4b:16d7/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
</code></pre></div></div>

<p><img src="/assets/2024/kans-3th/w8/20241026_kans_w8_16.png" alt="img.png" class="image-center" />
<em class="image-caption">webpod1,2와 wttr.in 접속 테스트 후 Hubble UI</em></p>

<h4 id="서비스-통신-확인">서비스 통신 확인</h4>

<h5 id="소켓-기반-로드밸런싱-소개">소켓 기반 로드밸런싱 소개</h5>

<ul>
  <li>참고 : <a href="https://velog.io/@haruband/K8SCilium-Socket-Based-LoadBalancing-%EA%B8%B0%EB%B2%95">https://velog.io/@haruband/K8SCilium-Socket-Based-LoadBalancing-%EA%B8%B0%EB%B2%95</a></li>
  <li>네트워크 기반 로드밸런싱(왼쪽) vs 소켓 기반 로드밸런싱(오른쪽) 비교
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_17.png" alt="img.png" />
위의 그림에서 처럼 네트워크 기반 로드밸런싱은 서비스를 통해 DNAT 되는 과정을 거치는데, <strong>소켓기반 로드밸런싱은 DNAT하는 과정이 필요가 없습</strong>니다.
    <ul>
      <li>위의 그림을 풀어서 설명하자면 위의 예에서 Pod1에서 동작하는 앱이 <code class="language-plaintext highlighter-rouge">connect()</code> 시스템 콜을 이용해서 소켓을 연결할때 목적지 주소가
서비스 주소 (192.168.0.1)이면 소켓의 목적지 주소를 바로 백엔드 주소(10.0.0.2)으로 설정합니다. 이후 데이터 전송은 
<strong>바로 백엔드 주소(10.0.0.2)로 전송되기 때문</strong>에 <strong>DNAT 변환 및 역변환 과정이 필요없어</strong>집니다.</li>
      <li><em>이는 cilium이 L7에서 파드/서비스의 의미를 이해하고 처리하기 때문입니다!</em></li>
      <li>심지어 서비스 주소를 백엔드 주소로 변경하는 것은 <strong>시스템콜 레벨에서 이루어지며</strong>, 커널에서 패킷이 생성되기도 전입니다.</li>
    </ul>
  </li>
  <li>Socket Operations : BPF Socket Operations program은 root cgroup에 연결되며 TCP event(ESTABLISHED)에서 실행합니다.</li>
  <li>Socket send/recv : Socket send/recv 훅은 TCP socket의 모든 송수신 작업에서 실행되며, hook에서 검사/삭제/리다이렉션 할 수 있습니다.</li>
  <li><code class="language-plaintext highlighter-rouge">connect()</code>와 <code class="language-plaintext highlighter-rouge">sendto()</code> 소켓 함수에 연결된 프로그램(<code class="language-plaintext highlighter-rouge">connect4</code>, <code class="language-plaintext highlighter-rouge">sendmsg4</code>)에서는 소켓의 목적지 주소를 백엔드 주소와 포트로 변환하고, 
cilium_lb4_backends 맵에 백엔드 주소와 포트를 등록해놓습니다. 이후 <code class="language-plaintext highlighter-rouge">recvmsg()</code> 소켓 함수에 연결된 프로그램(<code class="language-plaintext highlighter-rouge">recvmsg4</code>)에서는
ilium_lb4_reverse_nat 맵을 이용해서 목적지 주소와 포트를 다시 서비스 주소와 포트로 변환합니다.
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_18.png" alt="img.png" class="image-center" />
<em class="image-caption">cilium의 소켓 기반 로드밸런싱 동작 방식 - <a href="https://k8s.networkop.co.uk/services/clusterip/dataplane/ebpf/">링크</a></em></li>
</ul>

<h5 id="서비스-생성-및-접속-확인">서비스 생성 및 접속 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 서비스 생성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl create -f -
apiVersion: v1
kind: Service
metadata:
  name: svc
spec:
  ports:
    - name: svc-webport
      port: 80
      targetPort: 80
  selector:
    app: webpod
  type: ClusterIP
</span><span class="no">EOF
</span><span class="c"># =&gt; service/svc created</span>

<span class="c"># 서비스 생성 확인</span>
<span class="nv">$ </span>kubectl get svc,ep svc
<span class="c"># =&gt; NAME          TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE</span>
<span class="c">#    service/svc   ClusterIP   10.10.200.121   &amp;lt;none&amp;gt;        80/TCP    13s</span>
<span class="c">#    </span>
<span class="c">#    NAME            ENDPOINTS                         AGE</span>
<span class="c">#    endpoints/svc   172.16.1.247:80,172.16.2.216:80   13s</span>

<span class="c"># 노드에 iptables 더이상 KUBE-SVC rule 이 생성되지 않는다!</span>
<span class="nv">$ </span>iptables-save | <span class="nb">grep </span>KUBE-SVC
<span class="nv">$ </span>iptables-save | <span class="nb">grep </span>CILIUM

<span class="c"># 서비스IP를 변수에 지정</span>
<span class="nv">$ SVCIP</span><span class="o">=</span><span class="si">$(</span>kubectl get svc svc <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.spec.clusterIP}'</span><span class="si">)</span>

<span class="c"># Pod1 에서 Service(ClusterIP) 접속 트래픽 발생</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>netpod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nv">$SVCIP</span>
<span class="c"># =&gt; Hostname: webpod2</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: ::1</span>
<span class="c">#    IP: 172.16.2.216</span>
<span class="c">#    IP: fe80::844e:b2ff:fed0:7d5</span>
<span class="c">#    RemoteAddr: 172.16.0.147:36844</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: 10.10.200.121</span>
<span class="c">#    User-Agent: curl/8.7.1</span>
<span class="c">#    Accept: */*</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>netpod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nv">$SVCIP</span> | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod1</span>

<span class="c"># 지속적으로 접속 트래픽 발생</span>
<span class="nv">$ SVCIP</span><span class="o">=</span><span class="si">$(</span>kubectl get svc svc <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.spec.clusterIP}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>kubectl <span class="nb">exec </span>netpod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nv">$SVCIP</span> | <span class="nb">grep </span>Hostname<span class="p">;</span><span class="nb">echo</span> <span class="s2">"-----"</span><span class="p">;</span><span class="nb">sleep </span>1<span class="p">;</span><span class="k">done</span>

<span class="nv">$ </span>kubectl <span class="nb">exec </span>netpod <span class="nt">--</span> tcpdump <span class="nt">-enni</span> any <span class="nt">-q</span>
<span class="c"># =&gt; 15:01:03.468433 eth0  Out ifindex 18 52:59:78:2f:c0:be 172.16.0.147.57744 &amp;gt; 172.16.1.247.80: tcp 0</span>
<span class="c">#    15:01:03.468761 eth0  In  ifindex 18 7e:77:fa:0a:d3:cc 172.16.1.247.80 &amp;gt; 172.16.0.147.57744: tcp 0</span>
<span class="c">#    15:01:03.468801 eth0  Out ifindex 18 52:59:78:2f:c0:be 172.16.0.147.57744 &amp;gt; 172.16.1.247.80: tcp 0</span>
<span class="c">#    15:01:03.469249 eth0  Out ifindex 18 52:59:78:2f:c0:be 172.16.0.147.57744 &amp;gt; 172.16.1.247.80: tcp 76</span>
<span class="c">#    15:01:03.469852 eth0  In  ifindex 18 7e:77:fa:0a:d3:cc 172.16.1.247.80 &amp;gt; 172.16.0.147.57744: tcp 0</span>
<span class="c">#    15:01:03.469852 eth0  In  ifindex 18 7e:77:fa:0a:d3:cc 172.16.1.247.80 &amp;gt; 172.16.0.147.57744: tcp 312</span>
<span class="c">#    15:01:03.469888 eth0  Out ifindex 18 52:59:78:2f:c0:be 172.16.0.147.57744 &amp;gt; 172.16.1.247.80: tcp 0</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 파드에서 SVC(ClusterIP) 접속 시 tcpdump 로 확인 &gt;&gt; 파드 내부 캡쳐인데,&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;    SVC(10.10.200.121)는 보이지 않고, DNAT 된 web-pod 의 IP가 확인됩니다! It's Magic!&lt;/span&gt;</span>

<span class="nv">$ </span>kubectl <span class="nb">exec </span>netpod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s2">"ngrep -tW byline -d eth0 '' 'tcp port 80'"</span>
<span class="c"># =&gt; T 2024/10/01 15:02:58.406586 172.16.0.147:48018 -&amp;gt; 172.16.2.216:80 [AP] #4</span>
<span class="c">#    GET / HTTP/1.1.</span>
<span class="c">#    Host: 10.10.200.121.</span>
<span class="c">#    User-Agent: curl/8.7.1.</span>
<span class="c">#    Accept: */*.</span>
<span class="c">#    ...</span>

<span class="c"># 서비스 정보 확인</span>
<span class="nv">$ </span>c0 service list
<span class="c"># =&gt; ID   Frontend              Service Type   Backend</span>
<span class="c">#    ...</span>
<span class="c">#    11   10.10.200.121:80      ClusterIP      1 =&amp;gt; 172.16.1.247:80 (active)</span>
<span class="c">#                                              2 =&amp;gt; 172.16.2.216:80 (active)</span>
<span class="nv">$ </span>c0 bpf lb list
<span class="c"># =&gt; SERVICE ADDRESS           BACKEND ADDRESS (REVNAT_ID) (SLOT)</span>
<span class="c">#    0.0.0.0:30405 (0)         0.0.0.0:0 (8) (0) [NodePort, non-routable]</span>
<span class="c">#    ...</span>
<span class="c">#    10.10.200.121:80 (1)      172.16.1.247:80 (11) (1)</span>
<span class="c">#    10.10.200.121:80 (2)      172.16.2.216:80 (11) (2)</span>
<span class="c">#    ...</span>

<span class="c"># BPF maps</span>
<span class="nv">$ </span>c0 map list <span class="nt">--verbose</span>
<span class="nv">$ </span>c0 map list <span class="nt">--verbose</span> | <span class="nb">grep </span>lb
<span class="c"># =&gt; ## Map: cilium_lb4_backends_v3</span>
<span class="c">#    ## Map: cilium_lb_affinity_match</span>
<span class="c">#    ## Map: cilium_lb4_source_range</span>
<span class="c">#    ## Map: cilium_lb4_affinity</span>
<span class="c">#    ## Map: cilium_lb4_services_v2</span>
<span class="c">#    ## Map: cilium_lb4_reverse_nat</span>
<span class="c">#    ## Map: cilium_lb4_reverse_sk</span>
<span class="c">#    ## Map: cilium_skip_lb4</span>
<span class="nv">$ </span>c0 map get cilium_lb4_services_v2
<span class="c"># =&gt; Key                       Value                 State   Error</span>
<span class="c">#    ...</span>
<span class="c">#    10.10.200.121:80 (1)      20 0 (11) [0x0 0x0]   sync</span>
<span class="c">#    10.10.200.121:80 (0)      0 2 (11) [0x0 0x0]    sync</span>
<span class="c">#    10.10.200.121:80 (2)      21 0 (11) [0x0 0x0]   sync</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>c0 map get cilium_lb4_backends_v3
<span class="c"># =&gt; Key                       Value                 State   Error</span>
<span class="c">#    ...</span>
<span class="c">#    21    ANY://172.16.2.216    sync</span>
<span class="c">#    20    ANY://172.16.1.247    sync</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>c0 map get cilium_lb4_reverse_nat
<span class="c"># =&gt; Key                       Value                 State   Error</span>
<span class="c">#    ...</span>
<span class="c">#    11    10.10.200.121:80      sync</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>c0 map get cilium_lb4_reverse_sk
<span class="c"># =&gt; Key                       Value                 State   Error</span>
<span class="c">#    ...</span>
<span class="c">#    [172.16.2.216]:20480, 22906     [10.10.200.121]:20480, 2816</span>
<span class="c">#    [172.16.1.247]:20480, 19024     [10.10.200.121]:20480, 2816</span>
<span class="c">#    [172.16.2.216]:20480, 30734     [10.10.200.121]:20480, 2816</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>c0 map get cilium_lxc
<span class="c"># =&gt; Key              Value                                                                                            State   Error</span>
<span class="c">#    172.16.0.147:0   id=2724  sec_id=27629 flags=0x0000 ifindex=19  mac=52:59:78:2F:C0:BE nodemac=7E:77:FA:0A:D3:CC   sync</span>
<span class="c">#    172.16.0.223:0   id=640   sec_id=37523 flags=0x0000 ifindex=9   mac=AE:B8:81:A6:B1:28 nodemac=C2:21:B8:92:DA:FD   sync</span>
<span class="c">#    172.16.0.26:0    id=1606  sec_id=4     flags=0x0000 ifindex=21  mac=A2:52:92:B7:C0:D9 nodemac=C2:C0:3A:67:BE:B2   sync</span>
<span class="c">#    172.16.0.148:0   id=655   sec_id=4124  flags=0x0000 ifindex=23  mac=2E:AF:13:F1:DD:88 nodemac=FA:32:54:4B:16:D7   sync</span>
<span class="nv">$ </span>c0 map get cilium_ipcache
<span class="c"># =&gt; 172.16.2.216/32     identity=64309 encryptkey=0 tunnelendpoint=192.168.10.102, flags=&amp;lt;none&amp;gt;   sync</span>
<span class="c">#    172.16.1.247/32     identity=64309 encryptkey=0 tunnelendpoint=192.168.10.101, flags=&amp;lt;none&amp;gt;   sync</span>
</code></pre></div></div>

<h4 id="prometheus와-grafana를-통한-cilium-모니터링">Prometheus와 Grafana를 통한 Cilium 모니터링</h4>

<h5 id="설정">설정</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 배포</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/cilium/cilium/1.16.3/examples/kubernetes/addons/prometheus/monitoring-example.yaml
<span class="c"># =&gt; namespace/cilium-monitoring created</span>
<span class="c">#    serviceaccount/prometheus-k8s created</span>
<span class="c">#    configmap/grafana-config created</span>
<span class="c">#    configmap/grafana-cilium-dashboard created</span>
<span class="c">#    configmap/grafana-cilium-operator-dashboard created</span>
<span class="c">#    configmap/grafana-hubble-dashboard created</span>
<span class="c">#    configmap/grafana-hubble-l7-http-metrics-by-workload created</span>
<span class="c">#    configmap/prometheus created</span>
<span class="c">#    clusterrole.rbac.authorization.k8s.io/prometheus created</span>
<span class="c">#    clusterrolebinding.rbac.authorization.k8s.io/prometheus created</span>
<span class="c">#    service/grafana created</span>
<span class="c">#    service/prometheus created</span>
<span class="c">#    deployment.apps/grafana created</span>
<span class="c">#    deployment.apps/prometheus created</span>
<span class="nv">$ </span>kubectl get all <span class="nt">-n</span> cilium-monitoring
<span class="c"># =&gt; NAME                              READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/grafana-65d4578dc4-zcmgz      1/1     Running   0          36s</span>
<span class="c">#    pod/prometheus-7cc8784659-bqchf   1/1     Running   0          36s</span>
<span class="c">#    </span>
<span class="c">#    NAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE</span>
<span class="c">#    service/grafana      ClusterIP   10.10.200.223   &amp;lt;none&amp;gt;        3000/TCP   36s</span>
<span class="c">#    service/prometheus   ClusterIP   10.10.200.90    &amp;lt;none&amp;gt;        9090/TCP   36s</span>
<span class="c">#    </span>
<span class="c">#    NAME                         READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/grafana      1/1     1            1           36s</span>
<span class="c">#    deployment.apps/prometheus   1/1     1            1           36s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                    DESIRED   CURRENT   READY   AGE</span>
<span class="c">#    replicaset.apps/grafana-65d4578dc4      1         1         1       36s</span>
<span class="c">#    replicaset.apps/prometheus-7cc8784659   1         1         1       36s</span>

<span class="c"># 파드와 서비스 확인</span>
<span class="nv">$ </span>kubectl get pod,svc,ep <span class="nt">-o</span> wide <span class="nt">-n</span> cilium-monitoring
<span class="c"># =&gt; NAME                              READY   STATUS    RESTARTS   AGE   IP             NODE     NOMINATED NODE   READINESS GATES</span>
<span class="c">#    pod/grafana-65d4578dc4-zcmgz      1/1     Running   0          49s   172.16.1.208   k3s-w1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    pod/prometheus-7cc8784659-bqchf   1/1     Running   0          49s   172.16.1.248   k3s-w1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    </span>
<span class="c">#    NAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE   SELECTOR</span>
<span class="c">#    service/grafana      ClusterIP   10.10.200.223   &amp;lt;none&amp;gt;        3000/TCP   49s   app=grafana</span>
<span class="c">#    service/prometheus   ClusterIP   10.10.200.90    &amp;lt;none&amp;gt;        9090/TCP   49s   app=prometheus</span>
<span class="c">#    </span>
<span class="c">#    NAME                   ENDPOINTS           AGE</span>
<span class="c">#    endpoints/grafana      172.16.1.208:3000   49s</span>
<span class="c">#    endpoints/prometheus   172.16.1.248:9090   49s</span>

<span class="c"># NodePort 설정</span>
<span class="nv">$ </span>kubectl patch svc grafana <span class="nt">-n</span> cilium-monitoring <span class="nt">-p</span> <span class="s1">'{"spec": {"type": "NodePort"}}'</span>
<span class="nv">$ </span>kubectl patch svc prometheus <span class="nt">-n</span> cilium-monitoring <span class="nt">-p</span> <span class="s1">'{"spec": {"type": "NodePort"}}'</span>

<span class="c"># Grafana 웹 접속</span>
<span class="nv">$ GPT</span><span class="o">=</span><span class="si">$(</span>kubectl get svc <span class="nt">-n</span> cilium-monitoring grafana <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.spec.ports[0].nodePort<span class="o">}</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"Grafana URL = http://</span><span class="si">$(</span>curl <span class="nt">-s</span> ipinfo.io/ip<span class="si">)</span><span class="s2">:</span><span class="nv">$GPT</span><span class="s2">"</span>
<span class="c"># =&gt; Grafana URL = http://54.180.146.116:32172</span>

<span class="c"># Prometheus 웹 접속 정보 확인</span>
<span class="nv">$ PPT</span><span class="o">=</span><span class="si">$(</span>kubectl get svc <span class="nt">-n</span> cilium-monitoring prometheus <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.spec.ports[0].nodePort<span class="o">}</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"Prometheus URL = http://</span><span class="si">$(</span>curl <span class="nt">-s</span> ipinfo.io/ip<span class="si">)</span><span class="s2">:</span><span class="nv">$PPT</span><span class="s2">"</span>
<span class="c"># =&gt; Prometheus URL = http://54.180.146.116:30426</span>
</code></pre></div></div>

<h5 id="grafana--prometheus-nodeport-로-웹-접속-후-확인">grafana , prometheus NodePort 로 웹 접속 후 확인</h5>

<p><img src="/assets/2024/kans-3th/w8/20241026_kans_w8_19.png" alt="img.png" class="image-center" />
<em class="image-caption">Prometheus 모니터링 화면</em></p>

<p><img src="/assets/2024/kans-3th/w8/20241026_kans_w8_21.png" alt="img_1.png" class="image-center" />
<em class="image-caption">Grafana 모니터링 화면</em></p>

<h4 id="network-policy-l3-l4-l7">Network Policy (L3, L4, L7)</h4>

<h5 id="cilium-보안-소개">Cilium 보안 소개</h5>

<p>Cilium은 여러 레벨의 보안 기능을 제공합니다. <a href="https://docs.cilium.io/en/stable/security/network/intro/">문서</a>
그 중에서 다음 3가지를 알아보겠습니다.</p>

<ul>
  <li>ID 기반 (L3) : 엔드포인트 간의 연결 정책을 정의할 때, 엔드포인트의 ID를 사용합니다. 이 ID는 엔드포인트의 네트워크 주소와 무관하게 유지되며, 
k8s의 label을 통해 만들어집니다. 즉, 파드간에 공유할 수 있으며, 네트워크 주소가 변경되어도 유지됩니다.
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_22.png" alt="img.png" class="image-center w-80" />
<em class="image-caption"><a href="https://docs.cilium.io/en/stable/security/network/identity/">https://docs.cilium.io/en/stable/security/network/identity/</a></em></li>
  <li>포트기반 (L4) : 엔드포인트 간의 연결 정책을 정의할 때, 포트를 사용합니다. 이는 L3 정책과 함께 사용될 수 있어서,
<code class="language-plaintext highlighter-rouge">role=frontend</code>라는 레이블을 가진 엔드포인트는 443 포트로 outgoing 연결을 허용하고, <code class="language-plaintext highlighter-rouge">role=backend</code>라는 레이블을 가진 엔드포인트는 
443 포트로 incoming 연결을 허용하는 등의 정책을 정의할 수 있습니다.</li>
  <li>어플리케이션 (http) 기반 (L7) : HTTP통신과 RPC 프로토콜의 보안을 위해서 어플리케이션 레벨에서 정밀하게 정책을 정의할 수 있습니다.
이는 HTTP 헤더, 메소드, 경로, 쿼리 파라미터 등을 사용하여 정책을 정의할 수 있습니다.
    <ul>
      <li>프록시 주입 : Envoy - <a href="https://docs.cilium.io/en/stable/security/network/proxy/">Docs</a>, <a href="https://docs.cilium.io/en/stable/security/network/proxy/envoy/">Envoy</a>
        <ul>
          <li>Cilium은 모든 네트워크 연결에 대해 Layer 4 프록시(예) Envoy)를 주입시킬 수 있습니다.
이는 고차원의 네트워크 정책을 강제할 수 있는 기반이 됩니다.
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_23.png" alt="img.png" class="image-center" />
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_24.png" alt="img.png" class="image-center" /></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h5 id="network-policy-관련-ebpf-datapath">Network Policy 관련 eBPF Datapath</h5>

<p><img src="/assets/2024/kans-3th/w8/20241026_kans_w8_25.png" alt="img.png" class="image-center w-80" /></p>

<ul>
  <li>Prefilter : Prefilter는 XDP 프로그램을 통해 수행되며, 최고의 성능을 위해 네트워크 패킷을 필터링하는 prefilter 규칙들을 제공합니다.
특히 CIDR map들을 사용해 IP 주소를 필터링하는 등의 동작을 할 수 있습니다.</li>
  <li>Endpoint policy : 정책에 따라 패킷을 차단/전달하거나, 서비스로 전달하거나, L7로 정책 전달을 할 수 있습니다.
    <ul>
      <li>Cilium datapath는 L3와 L4 정책을 강제하거나, 패킷과 ID를 매핑하는 역할을 수행합니다.</li>
    </ul>
  </li>
  <li>L7 policy : L7 정책은 프록시 트래픽을 Cilium의 userspace proxy instance, 즉 Envoy로 전달합니다. Envoy 는 트래픽을 전달하거나
L7 정책에 의해 차단할 수 있습니다.
    <ul>
      <li>👉 L7 정책은 hook과 Userspace Proxy(envoy)를 사용하기 때문에 성능이 조금 떨어질 수 있습니다.</li>
    </ul>
  </li>
</ul>

<h5 id="실습">실습</h5>

<ul>
  <li>스타워즈에서 영감받은 예제를 통해 Network Policy를 적용해보겠습니다.
    <ul>
      <li>디플로이먼트(웹 서버, deathstar, replicas 2), 파드(xwing, tiefighter), 서비스(ClusterIP, service/deathstar)</li>
    </ul>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 배포</span>
<span class="nv">$ </span>kubectl create <span class="nt">-f</span> https://raw.githubusercontent.com/cilium/cilium/1.16.3/examples/minikube/http-sw-app.yaml
<span class="c"># =&gt; service/deathstar created</span>
<span class="c">#    deployment.apps/deathstar created</span>
<span class="c">#    pod/tiefighter created</span>
<span class="c">#    pod/xwing created</span>
<span class="nv">$ </span>kubectl get all
<span class="c"># =&gt; NAME                             READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/deathstar-689f66b57d-mm72v   1/1     Running   0          15s</span>
<span class="c">#    pod/deathstar-689f66b57d-pz56p   1/1     Running   0          15s</span>
<span class="c">#    pod/tiefighter                   1/1     Running   0          15s</span>
<span class="c">#    pod/xwing                        1/1     Running   0          15s</span>
<span class="c">#    </span>
<span class="c">#    NAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE</span>
<span class="c">#    service/deathstar    ClusterIP   10.10.200.162   &amp;lt;none&amp;gt;        80/TCP    15s</span>
<span class="c">#    service/kubernetes   ClusterIP   10.10.200.1     &amp;lt;none&amp;gt;        443/TCP   8h</span>
<span class="c">#    </span>
<span class="c">#    NAME                        READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/deathstar   2/2     2            2           15s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                   DESIRED   CURRENT   READY   AGE</span>
<span class="c">#    replicaset.apps/deathstar-689f66b57d   2         2         2       15s</span>

<span class="c"># 파드 라벨 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">--show-labels</span>
<span class="c"># =&gt; NAME                         READY   STATUS    RESTARTS   AGE   LABELS</span>
<span class="c">#    deathstar-689f66b57d-mm72v   1/1     Running   0          24s   app.kubernetes.io/name=deathstar,class=deathstar,org=empire,pod-template-hash=689f66b57d</span>
<span class="c">#    deathstar-689f66b57d-pz56p   1/1     Running   0          24s   app.kubernetes.io/name=deathstar,class=deathstar,org=empire,pod-template-hash=689f66b57d</span>
<span class="c">#    tiefighter                   1/1     Running   0          24s   app.kubernetes.io/name=tiefighter,class=tiefighter,org=empire</span>
<span class="c">#    xwing                        1/1     Running   0          24s   app.kubernetes.io/name=xwing,class=xwing,org=alliance</span>

<span class="c"># cilium endpoint 확인</span>
<span class="nv">$ </span>kubectl get ciliumendpoints
<span class="c"># =&gt; NAME                         SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    deathstar-689f66b57d-mm72v   391                 ready            172.16.2.35</span>
<span class="c">#    deathstar-689f66b57d-pz56p   391                 ready            172.16.1.232</span>
<span class="c">#    tiefighter                   9002                ready            172.16.0.5</span>
<span class="c">#    xwing                        10812               ready            172.16.2.31</span>

<span class="nv">$ </span>c0 endpoint list
<span class="c"># =&gt; ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])                                                  IPv6   IPv4           STATUS</span>
<span class="c">#               ENFORCEMENT        ENFORCEMENT</span>
<span class="c">#    ...</span>
<span class="c">#    2481       Disabled           Disabled          9002       k8s:app.kubernetes.io/name=tiefighter                                               172.16.0.5     ready</span>
<span class="c">#                                                               k8s:class=tiefighter</span>
<span class="c">#                                                               k8s:org=empire</span>
<span class="nv">$ </span>c1 endpoint list
<span class="c"># =&gt; ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])                                                        IPv6   IPv4           STATUS</span>
<span class="c">#               ENFORCEMENT        ENFORCEMENT</span>
<span class="c">#    ...</span>
<span class="c">#    1063       Disabled           Disabled          391        k8s:app.kubernetes.io/name=deathstar                                                      172.16.1.232   ready</span>
<span class="c">#                                                               k8s:class=deathstar</span>
<span class="c">#                                                               k8s:org=empire</span>
<span class="nv">$ </span>c2 endpoint list
<span class="c"># =&gt; ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])                                                      IPv6   IPv4           STATUS</span>
<span class="c">#               ENFORCEMENT        ENFORCEMENT</span>
<span class="c">#    ...</span>
<span class="c">#    1695       Disabled           Disabled          391        k8s:app.kubernetes.io/name=deathstar                                                    172.16.2.35    ready</span>
<span class="c">#                                                               k8s:class=deathstar</span>
<span class="c">#                                                               k8s:org=empire</span>
<span class="c">#    2810       Disabled           Disabled          10812      k8s:app.kubernetes.io/name=xwing                                                        172.16.2.31    ready</span>
<span class="c">#                                                               k8s:class=xwing</span>
<span class="c">#                                                               k8s:org=alliance</span>

<span class="c"># 데스스타 SVC(ClusterIP) 접속하여 웹 파드 연결 확인 &gt;&gt; Hubble UI 에서 실시간 확인해보자!</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>xwing <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPOST</span> deathstar.default.svc.cluster.local/v1/request-landing
<span class="c"># =&gt; Ship landed</span>

<span class="nv">$ </span>kubectl <span class="nb">exec </span>tiefighter <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPOST</span> deathstar.default.svc.cluster.local/v1/request-landing
<span class="c"># =&gt; Ship landed</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>hubble observe
</code></pre></div></div>

<p><img src="/assets/2024/kans-3th/w8/20241026_kans_w8_26.png" alt="img.png" /></p>

<ul>
  <li>Identity-Aware and HTTP-Aware Policy Enforcement <code class="language-plaintext highlighter-rouge">Apply an L3/L4 Policy</code> - <a href="https://docs.cilium.io/en/stable/gettingstarted/demo/#apply-an-l3-l4-policy">Link</a> &amp; Hubble CLI - <a href="https://docs.cilium.io/en/stable/gettingstarted/hubble_cli/">링크</a>
    <ul>
      <li>Cilium 에서는 Endpoint IP 대신, <strong>파드</strong>의 <strong>Labels(라벨)</strong>을 사용(기준)하여 <strong>보안 정책을 적용</strong>합니다.</li>
      <li><strong>IP/Port</strong> 필터링을 <strong>L3/L4 네트워크 정책</strong>이라고 합니다.</li>
      <li>아래 처럼 ‘org=empire’ Labels(라벨) 부착된 파드만 허용해보겠습니다.</li>
      <li>Cilium 은 <strong>stateful connection tracking</strong>을 지원하므로 리턴 트래픽은 자동으로 허용됩니다.</li>
    </ul>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># L3/L4 정책 생성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f - 
apiVersion: "cilium.io/v2"
kind: CiliumNetworkPolicy
metadata:
  name: "rule1"
spec:
  description: "L3-L4 policy to restrict deathstar access to empire ships only"
  endpointSelector:
    matchLabels:
      org: empire
      class: deathstar
  ingress:
  - fromEndpoints:
    - matchLabels:
        org: empire
    toPorts:
    - ports:
      - port: "80"
        protocol: TCP
</span><span class="no">EOF
</span><span class="c"># =&gt; ciliumnetworkpolicy.cilium.io/rule1 created</span>

<span class="c"># 정책 확인</span>
<span class="nv">$ </span>kubectl get cnp
<span class="c"># =&gt; NAME    AGE</span>
<span class="c">#    rule1   9s</span>
<span class="nv">$ </span>kubectl describe cnp rule1
<span class="nv">$ </span>c0 policy get
<span class="c"># =&gt; [</span>
<span class="c">#      {</span>
<span class="c">#        &amp;quot;endpointSelector&amp;quot;: {</span>
<span class="c">#          &amp;quot;matchLabels&amp;quot;: {</span>
<span class="c">#            &amp;quot;any:class&amp;quot;: &amp;quot;deathstar&amp;quot;,</span>
<span class="c">#            &amp;quot;any:org&amp;quot;: &amp;quot;empire&amp;quot;,</span>
<span class="c">#            &amp;quot;k8s:io.kubernetes.pod.namespace&amp;quot;: &amp;quot;default&amp;quot;</span>
<span class="c">#          }</span>
<span class="c">#        },</span>
<span class="c">#        &amp;quot;ingress&amp;quot;: [</span>
<span class="c">#          {</span>
<span class="c">#            &amp;quot;fromEndpoints&amp;quot;: [</span>
<span class="c">#              {</span>
<span class="c">#                &amp;quot;matchLabels&amp;quot;: {</span>
<span class="c">#                  &amp;quot;any:org&amp;quot;: &amp;quot;empire&amp;quot;,</span>
<span class="c">#                  &amp;quot;k8s:io.kubernetes.pod.namespace&amp;quot;: &amp;quot;default&amp;quot;</span>
<span class="c">#                }</span>
<span class="c">#              }</span>
<span class="c">#            ],</span>
<span class="c">#            &amp;quot;toPorts&amp;quot;: [</span>
<span class="c">#              {</span>
<span class="c">#                &amp;quot;ports&amp;quot;: [</span>
<span class="c">#                  {</span>
<span class="c">#                    &amp;quot;port&amp;quot;: &amp;quot;80&amp;quot;,</span>
<span class="c">#                    &amp;quot;protocol&amp;quot;: &amp;quot;TCP&amp;quot;</span>
<span class="c">#                  }</span>
<span class="c">#                ]</span>
<span class="c">#              }</span>
<span class="c">#            ]</span>
<span class="c">#          }</span>
<span class="c">#        ],</span>
<span class="c">#        ...</span>
<span class="c">#        &amp;quot;enableDefaultDeny&amp;quot;: {</span>
<span class="c">#          &amp;quot;ingress&amp;quot;: true,</span>
<span class="c">#          &amp;quot;egress&amp;quot;: false</span>
<span class="c">#        },</span>
<span class="c">#        ...</span>
<span class="c">#      }</span>
<span class="c">#    ]</span>

<span class="c"># 파드 curl 접속 시도 시 파드 sh 접속 후 curl 시도하자!</span>
<span class="c"># 데스스타 SVC(ClusterIP) 접속하여 웹 파드 연결 확인 &gt;&gt; Hubble UI 에서 drop 확인!</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>tiefighter <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPOST</span> deathstar.default.svc.cluster.local/v1/request-landing
<span class="c"># =&gt; Ship landed</span>

<span class="nv">$ </span>kubectl <span class="nb">exec </span>xwing <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPOST</span> deathstar.default.svc.cluster.local/v1/request-landing
<span class="c"># =&gt; (없음)</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 접속이 drop 됩니다. xwing은 허용되는 `org=empire`인 엔드포인트가 아닌 `org=alliance`인 엔드포인트이기 때문입니다.&lt;/span&gt;</span>

<span class="c"># hubble cli 모니터링 </span>
<span class="nv">$ </span>hubble observe <span class="nt">--pod</span> xwing
<span class="nv">$ </span>hubble observe <span class="nt">--pod</span> tiefighter
<span class="nv">$ </span>hubble observe <span class="nt">--pod</span> deathstar
<span class="c"># =&gt; Oct 01 16:28:28.825: default/xwing:39224 (ID:10812) &amp;lt;&amp;gt; default/deathstar-689f66b57d-mm72v:80 (ID:391) policy-verdict:none INGRESS DENIED (TCP Flags: SYN)</span>
<span class="c">#    Oct 01 16:28:28.825: default/xwing:39224 (ID:10812) &amp;lt;&amp;gt; default/deathstar-689f66b57d-mm72v:80 (ID:391) Policy denied DROPPED (TCP Flags: SYN)</span>

<span class="nv">$ </span>hubble observe <span class="nt">--pod</span> deathstar <span class="nt">--verdict</span> DROPPED
<span class="c"># =&gt; Oct 01 16:27:50.894: default/xwing:43148 (ID:10812) &amp;lt;&amp;gt; default/deathstar-689f66b57d-pz56p:80 (ID:391) policy-verdict:none INGRESS DENIED (TCP Flags: SYN)</span>
<span class="c">#    Oct 01 16:27:50.894: default/xwing:43148 (ID:10812) &amp;lt;&amp;gt; default/deathstar-689f66b57d-pz56p:80 (ID:391) Policy denied DROPPED (TCP Flags: SYN)</span>
<span class="c">#    Oct 01 16:28:24.676: default/xwing:43148 (ID:10812) &amp;lt;&amp;gt; default/deathstar-689f66b57d-pz56p:80 (ID:391) policy-verdict:none INGRESS DENIED (TCP Flags: SYN)</span>
<span class="c">#    Oct 01 16:28:24.676: default/xwing:43148 (ID:10812) &amp;lt;&amp;gt; default/deathstar-689f66b57d-pz56p:80 (ID:391) Policy denied DROPPED (TCP Flags: SYN)</span>

<span class="c"># Inspecting the Policy</span>
<span class="c"># If we run cilium endpoint list again we will see that the pods with the label org=empire and class=deathstar</span>
<span class="c"># now have ingress policy enforcement enabled as per the policy above.</span>

<span class="c"># endpoint list 에서 정책 적용 확인</span>
<span class="nv">$ </span>c0 endpoint list
<span class="c"># =&gt; ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])                                                  IPv6   IPv4           STATUS</span>
<span class="c">#               ENFORCEMENT        ENFORCEMENT</span>
<span class="c">#    2481       Disabled           Disabled          9002       k8s:app.kubernetes.io/name=tiefighter                                               172.16.0.5     ready</span>
<span class="c">#                                                               k8s:class=tiefighter</span>
<span class="c">#                                                               k8s:org=empire </span>
<span class="nv">$ </span>c1 endpoint list | <span class="nb">grep </span>deathstar
<span class="c"># =&gt; 1063       Enabled            Disabled          391        k8s:app.kubernetes.io/name=deathstar                                                      172.16.1.232   ready</span>
<span class="c">#                                                               k8s:class=deathstar</span>
<span class="nv">$ </span>c2 endpoint list
<span class="c"># =&gt; ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])                                                      IPv6   IPv4           STATUS</span>
<span class="c">#               ENFORCEMENT        ENFORCEMENT</span>
<span class="c">#    1695       Enabled            Disabled          391        k8s:app.kubernetes.io/name=deathstar                                                    172.16.2.35    ready</span>
<span class="c">#                                                               k8s:class=deathstar</span>
<span class="c">#                                                               k8s:org=empire</span>
<span class="c">#    2810       Disabled           Disabled          10812      k8s:app.kubernetes.io/name=xwing                                                        172.16.2.31    ready</span>
<span class="c">#                                                               k8s:class=xwing</span>
<span class="c">#                                                               k8s:org=alliance</span>
</code></pre></div></div>

<ul>
  <li>Identity-Aware and HTTP-Aware Policy Enforcement Apply and Test HTTP-aware L7 Policy - <a href="https://docs.cilium.io/en/stable/gettingstarted/demo/#apply-and-test-http-aware-l7-policy">Docs</a>
    <ul>
      <li>HTTP L7 필터링을 적용 : PUT /v1/exhaust-port 요청을 차단해보겠습니다.</li>
    </ul>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 데스스타 SVC(ClusterIP) 접속</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>tiefighter <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPUT</span> deathstar.default.svc.cluster.local/v1/exhaust-port
<span class="c"># =&gt; Panic: deathstar exploded</span>
<span class="c">#    ...</span>

<span class="c"># POST /v1/request-landing API 호출만 허용 정책으로 기존 정책 내용을 업데이트(configured)!</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f - 
apiVersion: "cilium.io/v2"
kind: CiliumNetworkPolicy
metadata:
  name: "rule1"
spec:
  description: "L7 policy to restrict access to specific HTTP call"
  endpointSelector:
    matchLabels:
      org: empire
      class: deathstar
  ingress:
  - fromEndpoints:
    - matchLabels:
        org: empire
    toPorts:
    - ports:
      - port: "80"
        protocol: TCP
      rules:
        http:
        - method: "POST"
          path: "/v1/request-landing"
</span><span class="no">EOF

</span><span class="c"># 정책 확인</span>
<span class="nv">$ </span>kubectl describe ciliumnetworkpolicies
<span class="c"># =&gt; Name:         rule1</span>
<span class="c">#    Namespace:    default</span>
<span class="c">#    Labels:       &amp;lt;none&amp;gt;</span>
<span class="c">#    Annotations:  &amp;lt;none&amp;gt;</span>
<span class="c">#    API Version:  cilium.io/v2</span>
<span class="c">#    Kind:         CiliumNetworkPolicy</span>
<span class="c">#    Metadata:</span>
<span class="c">#      Creation Timestamp:  2024-10-01T16:24:53Z</span>
<span class="c">#      Generation:          2</span>
<span class="c">#      Resource Version:    32642</span>
<span class="c">#      UID:                 d3527eec-5832-4273-b805-c006c728a8af</span>
<span class="c">#    Spec:</span>
<span class="c">#      Description:  L7 policy to restrict access to specific HTTP call</span>
<span class="c">#      Endpoint Selector:</span>
<span class="c">#        Match Labels:</span>
<span class="c">#          Class:  deathstar</span>
<span class="c">#          Org:    empire</span>
<span class="c">#      Ingress:</span>
<span class="c">#        From Endpoints:</span>
<span class="c">#          Match Labels:</span>
<span class="c">#            Org:  empire</span>
<span class="c">#        To Ports:</span>
<span class="c">#          Ports:</span>
<span class="c">#            Port:      80</span>
<span class="c">#            Protocol:  TCP</span>
<span class="c">#          Rules:</span>
<span class="c">#            Http:</span>
<span class="c">#              Method:  POST</span>
<span class="c">#              Path:    /v1/request-landing</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>c0 policy get

<span class="c"># 모니터링</span>
<span class="nv">$ </span>c1 monitor <span class="nt">-v</span> <span class="nt">--type</span> l7
<span class="nv">$ </span>c2 monitor <span class="nt">-v</span> <span class="nt">--type</span> l7
<span class="c"># =&gt; &amp;lt;- Request http from 0 ([k8s:app.kubernetes.io/name=tiefighter k8s:class=tiefighter k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default k8s:io.cilium.k8s.policy.cluster=default k8s:io.cilium.k8s.policy.serviceaccount=default k8s:io.kubernetes.pod.namespace=default k8s:org=empire]) to 1695 ([k8s:app.kubernetes.io/name=deathstar k8s:class=deathstar k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default k8s:io.cilium.k8s.policy.cluster=default k8s:io.cilium.k8s.policy.serviceaccount=default k8s:io.kubernetes.pod.namespace=default k8s:org=empire]), identity 9002-&amp;gt;391, verdict Forwarded POST http://deathstar.default.svc.cluster.local/v1/request-landing =&amp;gt; 0</span>
<span class="c">#    &amp;lt;- Response http to 0 ([k8s:app.kubernetes.io/name=tiefighter k8s:class=tiefighter k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default k8s:io.cilium.k8s.policy.cluster=default k8s:io.cilium.k8s.policy.serviceaccount=default k8s:io.kubernetes.pod.namespace=default k8s:org=empire]) from 1695 ([k8s:app.kubernetes.io/name=deathstar k8s:class=deathstar k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default k8s:io.cilium.k8s.policy.cluster=default k8s:io.cilium.k8s.policy.serviceaccount=default k8s:io.kubernetes.pod.namespace=default k8s:org=empire]), identity 391-&amp;gt;9002, verdict Forwarded POST http://deathstar.default.svc.cluster.local/v1/request-landing =&amp;gt; 200</span>
<span class="nv">$ </span>hubble observe <span class="nt">--pod</span> deathstar
<span class="nv">$ </span>hubble observe <span class="nt">--pod</span> deathstar <span class="nt">--verdict</span> DROPPED

<span class="c"># 접근 테스트</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>tiefighter <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPOST</span> deathstar.default.svc.cluster.local/v1/request-landing
<span class="c"># =&gt; Ship landed</span>

<span class="nv">$ </span>kubectl <span class="nb">exec </span>tiefighter <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">-XPUT</span> deathstar.default.svc.cluster.local/v1/exhaust-port
<span class="c"># =&gt; Access denied</span>

<span class="c">## hubble cli 에 차단 로그 확인</span>
<span class="nv">$ </span>hubble observe <span class="nt">--pod</span> deathstar <span class="nt">--verdict</span> DROPPED
<span class="c"># =&gt; Oct 01 16:41:48.094: default/tiefighter:51860 (ID:9002) -&amp;gt; default/deathstar-689f66b57d-mm72v:80 (ID:391) http-request DROPPED (HTTP/1.1 PUT http://deathstar.default.svc.cluster.local/v1/exhaust-port)</span>
<span class="c">#    Oct 01 16:41:48.094: default/tiefighter:51860 (ID:9002) &amp;lt;- default/deathstar-689f66b57d-mm72v:80 (ID:391) http-response FORWARDED (HTTP/1.1 403 0ms (PUT http://deathstar.default.svc.cluster.local/v1/exhaust-port))</span>

<span class="nv">$ </span>hubble observe <span class="nt">--pod</span> deathstar <span class="nt">--protocol</span> http
<span class="c"># =&gt; Oct 01 16:39:57.041: default/tiefighter:57616 (ID:9002) &amp;lt;- default/deathstar-689f66b57d-mm72v:80 (ID:391) http-response FORWARDED (HTTP/1.1 200 2ms (POST http://deathstar.default.svc.cluster.local/v1/request-landing))</span>

<span class="c"># 삭제</span>
<span class="nv">$ </span>kubectl delete <span class="nt">-f</span> https://raw.githubusercontent.com/cilium/cilium/1.16.3/examples/minikube/http-sw-app.yaml
<span class="c"># =&gt; service &amp;quot;deathstar&amp;quot; deleted</span>
<span class="c">#    deployment.apps &amp;quot;deathstar&amp;quot; deleted</span>
<span class="c">#    pod &amp;quot;tiefighter&amp;quot; deleted</span>
<span class="c">#    pod &amp;quot;xwing&amp;quot; deleted</span>
<span class="nv">$ </span>kubectl delete cnp rule1
<span class="c"># =&gt; ciliumnetworkpolicy.cilium.io &amp;quot;rule1&amp;quot; deleted</span>
</code></pre></div></div>

<h4 id="bandwidth-manager">Bandwidth Manager</h4>

<h5 id="bandwidth-manager-소개">Bandwidth Manager 소개</h5>

<ul>
  <li>Cilium은 Bandwidth(네트워크 대역폭)과 Latency optimization(지연 시간 최적화)를 지원합니다. - <a href="https://docs.cilium.io/en/stable/network/kubernetes/bandwidth-manager/">Link</a> , <a href="https://cilium.io/use-cases/bandwidth-optimization/">Home</a> , <a href="https://www.youtube.com/watch?v=QTSS6ktK8hY">Youtube</a>
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_27.png" alt="img.png" class="image-center w-80" />
<em class="image-caption"><a href="https://cilium.io/use-cases/bandwidth-optimization/">https://cilium.io/use-cases/bandwidth-optimization/</a></em>
    <ul>
      <li>bandwidth manager는 TCP와 UDP 부하를 최적화 하고, 효율적으로 개별 파드의 접속률을 제한할 수 있습니다. - <strong>EDT</strong>(Earliest Departure Time) 와 <strong>eBPF</strong> 사용</li>
      <li><code class="language-plaintext highlighter-rouge">kubernetes.io/egress-bandwidth</code> Pod <strong>annotation</strong> 은 egress 트래픽에 대해 호스트 네트워크 장치의 대역폭 제한을 설정합니다.</li>
      <li><del><code class="language-plaintext highlighter-rouge">kubernetes.io/ingress-bandwidth</code></del> <strong>annotation</strong> 은 지원되지 않습니다.</li>
      <li>direct routing mode, tunneling mode 둘 다 지원합니다.</li>
      <li>Limitations : L7 정책과 함께 사용할 수 없습니다.
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_28.png" alt="img.png" class="image-center w-80" /></li>
    </ul>
  </li>
</ul>

<h5 id="설정-및-확인">설정 및 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 인터페이스 tc qdisc 확인</span>
<span class="nv">$ </span>tc qdisc show dev enp0s8
<span class="c"># =&gt; qdisc fq_codel 0: root refcnt 2 limit 10240p flows 1024 quantum 1514 target 5ms interval 100ms memory_limit 32Mb ecn drop_batch 64</span>
<span class="c">#    qdisc clsact ffff: parent ffff:fff1</span>

<span class="c"># 설정</span>
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--namespace</span> kube-system <span class="nt">--reuse-values</span> <span class="nt">--set</span> bandwidthManager.enabled<span class="o">=</span><span class="nb">true</span>
<span class="c"># =&gt; Release &amp;quot;cilium&amp;quot; has been upgraded. Happy Helming!</span>
<span class="c">#    ...</span>

<span class="c"># 적용 확인</span>
<span class="nv">$ </span>cilium config view | <span class="nb">grep </span>bandwidth
<span class="c"># =&gt; enable-bandwidth-manager                          true</span>

<span class="c"># egress bandwidth limitation 동작하는 인터페이스 확인</span>
<span class="nv">$ </span>c0 status | <span class="nb">grep  </span>BandwidthManager
<span class="c"># =&gt; BandwidthManager:        EDT with BPF [CUBIC] [enp0s3, enp0s8]</span>

<span class="c"># 인터페이스 tc qdisc 확인 : 설정 전후 옵션값들이 상당히 추가된다</span>
<span class="nv">$ </span>tc qdisc
<span class="nv">$ </span>tc qdisc show dev enp0s8
<span class="c"># =&gt; qdisc fq 8006: root refcnt 2 limit 10000p flow_limit 100p buckets 32768 orphan_mask 1023 quantum 3028b initial_quantum 15140b low_rate_threshold 550Kbit refill_delay 40ms timer_slack 10us horizon 2s horizon_cap</span>
<span class="c">#    qdisc clsact ffff: parent ffff:fff1</span>
</code></pre></div></div>

<h5 id="동작-및-확인">동작 및 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 테스트를 위한 트래픽 발생 서버/클라이언트 파드 생성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
---
apiVersion: v1
kind: Pod
metadata:
  annotations:
    # Limits egress bandwidth to 10Mbit/s.
    kubernetes.io/egress-bandwidth: "10M"
  labels:
    # This pod will act as server.
    app.kubernetes.io/name: netperf-server
  name: netperf-server
spec:
  containers:
  - name: netperf
    image: cilium/netperf
    ports:
    - containerPort: 12865
---
apiVersion: v1
kind: Pod
metadata:
  # This Pod will act as client.
  name: netperf-client
spec:
  affinity:
    # Prevents the client from being scheduled to the
    # same node as the server.
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: app.kubernetes.io/name
            operator: In
            values:
            - netperf-server
        topologyKey: kubernetes.io/hostname
  containers:
  - name: netperf
    args:
    - sleep
    - infinity
    image: cilium/netperf
</span><span class="no">EOF
</span><span class="c"># =&gt; pod/netperf-server created</span>
<span class="c">#    pod/netperf-client created</span>

<span class="c"># egress BW 제한 정보 확인</span>
<span class="nv">$ </span>kubectl describe pod netperf-server | <span class="nb">grep </span>Annotations:
<span class="c"># =&gt; Annotations:      kubernetes.io/egress-bandwidth: 10M</span>

<span class="c"># egress BW 제한이 설정된 파드가 있는 cilium pod 에서 제한 정보 확인</span>
<span class="nv">$ </span>c0 bpf bandwidth list
<span class="nv">$ </span>c1 bpf bandwidth list
<span class="nv">$ </span>c2 bpf bandwidth list
<span class="c"># =&gt; IDENTITY   EGRESS BANDWIDTH (BitsPerSec)</span>
<span class="c">#    1391       10M</span>

<span class="nv">$ </span>c0 endpoint list
<span class="nv">$ </span>c1 endpoint list
<span class="nv">$ </span>c2 endpoint list
<span class="c"># =&gt; ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])                                                      IPv6   IPv4           STATUS</span>
<span class="c">#               ENFORCEMENT        ENFORCEMENT</span>
<span class="c">#    1391       Disabled           Disabled          8191       k8s:app.kubernetes.io/name=netperf-server                                               172.16.2.106   ready</span>
<span class="c">#    ...</span>

<span class="c"># 트래픽 발생 &gt;&gt; Hubble UI 에서 확인</span>
<span class="c"># egress traffic of the netperf-server Pod has been limited to 10Mbit per second. </span>
<span class="nv">$ NETPERF_SERVER_IP</span><span class="o">=</span><span class="si">$(</span>kubectl get pod netperf-server <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.podIP}'</span><span class="si">)</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>netperf-client <span class="nt">--</span> netperf <span class="nt">-t</span> TCP_MAERTS <span class="nt">-H</span> <span class="s2">"</span><span class="k">${</span><span class="nv">NETPERF_SERVER_IP</span><span class="k">}</span><span class="s2">"</span>
<span class="c"># =&gt; Recv   Send    Send</span>
<span class="c">#    Socket Socket  Message  Elapsed</span>
<span class="c">#    Size   Size    Size     Time     Throughput</span>
<span class="c">#    bytes  bytes   bytes    secs.    10^6bits/sec</span>
<span class="c">#    131072  16384  16384    10.01       9.13</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 10Mbps 제한 확인!&lt;/span&gt;</span>

<span class="c"># 5M 제한 설정 후 테스트</span>
<span class="nv">$ </span>kubectl get pod netperf-server <span class="nt">-o</span> json | <span class="nb">sed</span> <span class="nt">-e</span> <span class="s1">'s|10M|5M|g'</span> | kubectl apply <span class="nt">-f</span> -
<span class="c"># =&gt; pod/netperf-server configured</span>
<span class="nv">$ </span>c0 bpf bandwidth list
<span class="nv">$ </span>c1 bpf bandwidth list
<span class="nv">$ </span>c2 bpf bandwidth list
<span class="c"># =&gt; IDENTITY   EGRESS BANDWIDTH (BitsPerSec)</span>
<span class="c">#    1391       5M</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>netperf-client <span class="nt">--</span> netperf <span class="nt">-t</span> TCP_MAERTS <span class="nt">-H</span> <span class="s2">"</span><span class="k">${</span><span class="nv">NETPERF_SERVER_IP</span><span class="k">}</span><span class="s2">"</span>
<span class="c"># =&gt; Recv   Send    Send</span>
<span class="c">#    Socket Socket  Message  Elapsed</span>
<span class="c">#    Size   Size    Size     Time     Throughput</span>
<span class="c">#    bytes  bytes   bytes    secs.    10^6bits/sec</span>
<span class="c">#    </span>
<span class="c">#    131072  16384  16384    10.01       4.59</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 4.5Mbps 제한 확인!&lt;/span&gt;</span>

<span class="c"># 20M 제한 설정 후 테스트</span>
<span class="nv">$ </span>kubectl get pod netperf-server <span class="nt">-o</span> json | <span class="nb">sed</span> <span class="nt">-e</span> <span class="s1">'s|5M|20M|g'</span> | kubectl apply <span class="nt">-f</span> -
<span class="c"># =&gt; pod/netperf-server configured</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>netperf-client <span class="nt">--</span> netperf <span class="nt">-t</span> TCP_MAERTS <span class="nt">-H</span> <span class="s2">"</span><span class="k">${</span><span class="nv">NETPERF_SERVER_IP</span><span class="k">}</span><span class="s2">"</span>
<span class="c"># =&gt; Recv   Send    Send</span>
<span class="c">#    Socket Socket  Message  Elapsed</span>
<span class="c">#    Size   Size    Size     Time     Throughput</span>
<span class="c">#    bytes  bytes   bytes    secs.    10^6bits/sec</span>
<span class="c">#    131072  16384  16384    10.00      18.40</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 19Mbps 제한 확인!&lt;/span&gt;</span>

<span class="nv">$ </span>tc qdisc show dev enp0s8
<span class="c"># =&gt; qdisc fq 8006: root refcnt 2 limit 10000p flow_limit 100p buckets 32768 orphan_mask 1023 quantum 3028b initial_quantum 15140b low_rate_threshold 550Kbit refill_delay 40ms timer_slack 10us horizon 2s horizon_cap</span>
<span class="c">#    qdisc clsact ffff: parent ffff:fff1</span>

<span class="c"># 삭제</span>
<span class="nv">$ </span>kubectl delete pod netperf-client netperf-server
</code></pre></div></div>

<h4 id="l2-announcements--l2-aware-lb-beta">L2 Announcements / L2 Aware LB (Beta)</h4>

<ul>
  <li>참고 링크 : <a href="https://docs.cilium.io/en/stable/network/l2-announcements/">Link</a> , <a href="https://isovalent.com/blog/post/migrating-from-metallb-to-cilium/">Blog</a></li>
  <li>L2 Announcements는 로컬 영역 네트워크에서 서비스를 표시하고 도달 가능하게 만드는 기능입니다. 
이 기능은 주로 사무실 또는 캠퍼스 네트워크와 같이 BGP 기반 라우팅이 없는 네트워크 내에서 온프레미스 배포를 위해 고안되었습니다.</li>
  <li>이 기능을 사용하면 ExternalIP 및 LoadBalancer IP에 대한 ARP 쿼리에 응답합니다. 
이러한 IP는 여러 노드의 가상 IP(네트워크 장치에 설치되지 않음)이므로 각 서비스에 대해 한 번에 한 노드가 
ARP 쿼리에 응답하고 MAC 주소로 응답합니다.
이 노드는 서비스 로드 밸런싱 기능으로 로드 밸런싱을 수행하여 북쪽/남쪽 로드 밸런서 역할을 합니다.</li>
  <li>NodePort 서비스에 비해 이 기능의 장점은 각 서비스가 고유한 IP를 사용할 수 있으므로 여러 서비스가 동일한 포트 번호를
사용할 수 있다는 것입니다. 
NodePort를 사용할 때 트래픽을 보낼 호스트를 결정하는 것은 클라이언트에게 달려 있으며 노드가 다운되면
IP+Port 콤보를 사용할 수 없게 됩니다. L2 공지를 사용하면 서비스 VIP가 다른 노드로 간단히 마이그레이션되고 계속 작동합니다.</li>
  <li>이를 통해 MetalLB와 같은 외부 로드 밸런서를 Cilium으로 대체할 수 있습니다.</li>
</ul>

<p><img src="/assets/2024/kans-3th/w8/20241026_kans_w8_29.png" alt="img.png" class="image-center w-80" />
<em class="image-caption"><a href="https://isovalent.com/blog/post/migrating-from-metallb-to-cilium/">https://isovalent.com/blog/post/migrating-from-metallb-to-cilium/</a></em></p>

<h5 id="설정-및-확인-1">설정 및 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--namespace</span> kube-system <span class="nt">--reuse-values</span> <span class="se">\</span>
  <span class="nt">--set</span> l2announcements.enabled<span class="o">=</span><span class="nb">true</span> <span class="nt">--set</span> externalIPs.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> l2announcements.leaseDuration<span class="o">=</span>3s <span class="nt">--set</span> l2announcements.leaseRenewDeadline<span class="o">=</span>1s <span class="nt">--set</span> l2announcements.leaseRetryPeriod<span class="o">=</span>200ms
<span class="c"># =&gt; Release &amp;quot;cilium&amp;quot; has been upgraded. Happy Helming!</span>
<span class="c">#    ...</span>
 
<span class="c">#</span>
<span class="nv">$ </span>c0 config <span class="nt">--all</span> | <span class="nb">grep </span>L2
<span class="c"># =&gt; EnableL2Announcements             : true</span>
<span class="c">#    EnableL2NeighDiscovery            : true</span>

<span class="c"># CiliumL2AnnouncementPolicy 생성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f - 
apiVersion: "cilium.io/v2alpha1"
kind: CiliumL2AnnouncementPolicy
metadata:
  name: policy1
spec:
  serviceSelector:
    matchLabels:
      color: blue
  nodeSelector:
    matchExpressions:
      - key: node-role.kubernetes.io/control-plane
        operator: DoesNotExist
  interfaces:
  - ^enp0s[0-9]+
  externalIPs: true
  loadBalancerIPs: true
</span><span class="no">EOF
</span><span class="c"># =&gt; ciliuml2announcementpolicy.cilium.io/policy1 created</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get ciliuml2announcementpolicy
<span class="c"># =&gt; NAME      AGE</span>
<span class="c">#    policy1   7s</span>
<span class="nv">$ </span>kubectl describe l2announcement

<span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f - 
apiVersion: "cilium.io/v2alpha1"
kind: CiliumLoadBalancerIPPool
metadata:
  name: "cilium-pool"
spec:
  allowFirstLastIPs: "No"
  blocks:
  - cidr: "10.10.200.0/29"
</span><span class="no">EOF
</span><span class="c"># =&gt; ciliumloadbalancerippool.cilium.io/cilium-pool created</span>

<span class="c"># cilium ip pool 조회</span>
<span class="nv">$ </span>kubectl get CiliumLoadBalancerIPPool
<span class="c"># =&gt; NAME          DISABLED   CONFLICTING   IPS AVAILABLE   AGE</span>
<span class="c">#    cilium-pool   false      False         6               9s</span>
</code></pre></div></div>

<h5 id="테스트용-파드-서비스-생성">테스트용 파드, 서비스 생성</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: webpod1
  labels:
    app: webpod
spec:
  nodeName: k3s-w1
  containers:
  - name: container
    image: traefik/whoami
  terminationGracePeriodSeconds: 0
---
apiVersion: v1
kind: Pod
metadata:
  name: webpod2
  labels:
    app: webpod
spec:
  nodeName: k3s-w2
  containers:
  - name: container
    image: traefik/whoami
  terminationGracePeriodSeconds: 0
---
apiVersion: v1
kind: Service
metadata:
  name: svc1
spec:
  ports:
    - name: svc1-webport
      port: 80
      targetPort: 80
  selector:
    app: webpod
  type: LoadBalancer  # 👉 서비스 타입이 LoadBalancer
---
apiVersion: v1
kind: Service
metadata:
  name: svc2
spec:
  ports:
    - name: svc2-webport
      port: 80
      targetPort: 80
  selector:
    app: webpod
  type: LoadBalancer  # 👉 서비스 타입이 LoadBalancer
---
apiVersion: v1
kind: Service
metadata:
  name: svc3
spec:
  ports:
    - name: svc3-webport
      port: 80
      targetPort: 80
  selector:
    app: webpod
  type: LoadBalancer  # 👉 서비스 타입이 LoadBalancer
</span><span class="no">EOF
</span><span class="c"># =&gt; pod/webpod1 created</span>
<span class="c">#    pod/webpod2 created</span>
<span class="c">#    service/svc1 created</span>
<span class="c">#    service/svc2 created</span>
<span class="c">#    service/svc3 created</span>
</code></pre></div></div>

<h5 id="접속-확인">접속 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>kubectl get svc,ep
<span class="c"># =&gt; NAME                 TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE</span>
<span class="c">#    service/kubernetes   ClusterIP      10.10.200.1     &amp;lt;none&amp;gt;        443/TCP        10h</span>
<span class="c">#    service/svc1         LoadBalancer   10.10.200.214   10.10.200.1   80:30456/TCP   98s</span>
<span class="c">#    service/svc2         LoadBalancer   10.10.200.240   10.10.200.2   80:30367/TCP   98s</span>
<span class="c">#    service/svc3         LoadBalancer   10.10.200.155   10.10.200.3   80:31800/TCP   98s</span>
<span class="c">#    </span>
<span class="c">#    NAME                   ENDPOINTS                        AGE</span>
<span class="c">#    endpoints/kubernetes   192.168.10.10:6443               10h</span>
<span class="c">#    endpoints/svc1         172.16.1.32:80,172.16.2.115:80   98s</span>
<span class="c">#    endpoints/svc2         172.16.1.32:80,172.16.2.115:80   98s</span>
<span class="c">#    endpoints/svc3         172.16.1.32:80,172.16.2.115:80   98s</span>

<span class="c">#</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> 10.10.200.1
<span class="c"># =&gt; Hostname: webpod1</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: 172.16.1.32</span>
<span class="c">#    RemoteAddr: 192.168.10.10:58036</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: 10.10.200.1</span>
<span class="c">#    User-Agent: curl/7.81.0</span>
<span class="c">#    Accept: */*</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> 10.10.200.2
<span class="c"># =&gt; Hostname: webpod2</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: 172.16.2.115</span>
<span class="c">#    RemoteAddr: 192.168.10.10:53496</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: 10.10.200.2</span>
<span class="c">#    User-Agent: curl/7.81.0</span>
<span class="c">#    Accept: */*</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> 10.10.200.3
<span class="c"># =&gt; Hostname: webpod1</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: 172.16.1.32</span>
<span class="c">#    RemoteAddr: 192.168.10.10:54098</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: 10.10.200.3</span>
<span class="c">#    User-Agent: curl/7.81.0</span>
<span class="c">#    Accept: */*</span>
</code></pre></div></div>

<p>이상과 같이 Cilium 만으로 Loadbalancer유형의 Service를 구성할 수 있었습니다.</p>

<hr />

<h2 id="마치며">마치며</h2>

<p>이번 글에서는 Cilium CNI의 다양한 기능들을 살펴보았습니다.
Cilium CNI은 알면 알수록 “끝판왕”, “It’s magic!”이라는 말이 계속 떠올랐습니다.
아래의 말과 참 맞닿는것 같습니다.</p>

<blockquote>
  <p>“충분히 발달한 과학 기술은 마법과 구별할 수 없다” - 아서 클라크</p>
</blockquote>

<p>스터디 중에도 가시다 님이 “됩니다”를 연발하셔서 “다 되는 페이” KB 페이 광고가 생각났습니다. 
정말 다 되는 CNI인것 같습니다.
물론 eBPF나 Envoy와 같은 기술들이 있었기에 Cilium이 가능한 것이지만, 참 대단합니다.
이번에 실습한것 외에도 더 다양한 기능들이 있어서, 더욱더 공부해야겠다는 생각이 듭니다.</p>

<p>어느덧 다음주가 마지막 주차입니다. 이런 저런 일들로 스터디 포기할까 하는 때도 있었는데 어찌저찌 잘 버텼습니다. 
다음주에는 좀 더 일찍 과제를 제출할 수 있기를 바라며
이만 포스팅을 마치겠습니다.</p>]]></content><author><name></name></author><category term="kans" /><category term="kubernetes," /><category term="network," /><category term="linux" /><summary type="html"><![CDATA[이번주에는 드디어 CNI의 끝판 왕(제가 아는 한에서)인 Cilium에 대해 알아보겠습니다.]]></summary></entry><entry><title type="html">[KANS 3기] Service Mesh : Istio - Mode (Sidecar, Ambient)</title><link href="https://sweetlittlebird.github.io/posts/2024-10-19-KANS-Study-Week7/" rel="alternate" type="text/html" title="[KANS 3기] Service Mesh : Istio - Mode (Sidecar, Ambient)" /><published>2024-10-19T01:00:18+09:00</published><updated>2024-10-19T01:00:18+09:00</updated><id>https://sweetlittlebird.github.io/posts/KANS%20Study%20-%20Week7</id><content type="html" xml:base="https://sweetlittlebird.github.io/posts/2024-10-19-KANS-Study-Week7/"><![CDATA[<h2 id="들어가며">들어가며</h2>

<p>이번주에는 Service Mesh와 대표적인 오픈소스 프로젝트인 Istio에 대해 알아 보겠습니다.
KANS 3기 7주차 스터디를 시작하겠습니다.</p>

<hr />

<h2 id="istio-소개">Istio 소개</h2>

<p>Istio는 서비스 메시를 구축하고 관리하기 위한 오픈소스 플랫폼입니다. Istio를 알아보기에 앞서 서비스 메시에 대해 알아보겠습니다.</p>

<h3 id="서비스-메시-service-mesh란">서비스 메시 (Service Mesh)란?</h3>

<ul>
  <li><strong>서비스 메시</strong>는 서비스 간 <strong>통신을 제어</strong>하고 <strong>모니터링</strong>하는 레이어를 제공하는 인프라스트럭처 계층입니다.</li>
  <li><strong>등장배경</strong> : MSA 환경에서 서비스가 많아지다 보니 서비스 간 통신이 복잡해지고, 이로 인해 서비스 간 통신을 관리하고 모니터링하는 것이 어려워졌습니다.
이로인해 장애가 발생하거나 병목 현상이 발생했을때 원인과 발생하는 구간을 찾기가 어려워졌습니다. 이것을 해결 하기 위해 등장한 것이 서비스 메시입니다.
<img src="/assets/2024/kans-3th/w7/20241019_kans_w7_1.png" alt="img.png" class="image-center w-80" /></li>
  <li><strong>개념</strong> : 마이크로 서비스 간에 통신이나 경로를 제어 - 예) istio, linkerd, consul, envoy, …</li>
  <li><strong>기본 동작</strong> : 파드간 통신경로에 프록시를 두고 트래픽을 모니터링하거나 컨트롤 합니다. 따라서 기존 어플리케이션을 수정하지 않고도 적용할 수 있습니다.
<img src="/assets/2024/kans-3th/w7/20241019_kans_w7_2.png" alt="img.png" class="image-center w-80" />
위의 그림 처럼 서비스 메시는 각 파드에 프록시를 두고 프록시를 통해 통신을 하도록한 다음 프록시를 통해 트래픽을 모니터링하거나 컨트롤 합니다.
    <ul>
      <li>이때 프록시는 <strong>Sidecar</strong> 모드로 동작하거나 <strong>Ambient</strong> 모드로 동작하며 대표적인 프록시로는 Envoys가 있습니다.</li>
      <li>Envoy는 구글, IBM, Lyft가 중심이 되어 개발하고 있는 오픈소스 프록시입니다.</li>
      <li>네트워크 투명성을 목표로 다양한 필터 체인 지원(L3, L4, L7), 동적 Configuration API를 제공하고, hot reload를 지원합니다.</li>
    </ul>
  </li>
  <li><strong>주요기능</strong>
    <ul>
      <li><strong>트래픽 모니터링</strong> : 요청의 에러율, 지연시간, 컨넥션 개수, 요청개수 등의 메트릭을 수집하여 모니터링하고, 서비스간 혹은 특정 요청 경로를 필터링 할 수 있습니다.
=&gt; 원인 파악 용이</li>
      <li><strong>트래픽 컨트롤</strong>
        <ul>
          <li>트래픽 시프팅(traffic shifting) : 트래픽을 서비스간에 분산시키는 기능으로, 특정 단말/사용자는 신규 어플리케이션에 연결하도록 하는 카나리 배포등에 활용할 수도 있습니다.</li>
          <li>서킷 브레이커(circuit breaker) : 특정 서비스에 문제가 있을때 접속을 차단하고, 출발지 서비스에 에러를 반환하도록 하는 기능입니다. (연쇄장애, 시스템 전체 장애 방지)</li>
          <li>플트 인젝션(fault injection) : 의도적으로 요청을 지연시키거나 실패하도록 할 수 있습니다. (비정상 상황 테스트)</li>
          <li>속도 제한(rate limiting) : 특정 서비스에 대한 요청 개수를 제한하는 기능입니다.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="envoy">Envoy</h3>

<ul>
  <li>지난주에 살짝 언급되었던 내용인데 이번 주에 좀 더 자세히 알아보겠습니다.</li>
  <li>Envoy는 구글, IBM, Lyft가 중심이 되어 개발하고 있는 오픈소스 프록시입니다.</li>
  <li>Istio의 핵심 기능들은 Envoy를 감싼 istio proxy를 통해 이루어지므로 Envoy에 대한 이해가 필요합니다.</li>
</ul>

<p><img src="/assets/2024/kans-3th/w7/20241019_kans_w7_4.svg" alt="20241019_kans_w7_4.svg" class="image-center w-80" /></p>

<ul>
  <li>Envoy에서 사용하는 용어 들을 정리해 보았습니다.</li>
</ul>

<table>
  <thead>
    <tr>
      <th>용어</th>
      <th>설명</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Cluster</td>
      <td>envoy가 트래픽을 포워딩할 수 있는 논리적 서비스 (엔드포인트 셋트)</td>
    </tr>
    <tr>
      <td>Endpoint</td>
      <td>IP 주소와 포트 번호로 구성된 서비스의 실제 인스턴스. 엔드포인트가 모여서 하나의 Cluster를 이룸</td>
    </tr>
    <tr>
      <td>Listener</td>
      <td>클라이언트가 접속하는 포트, 유닉스 도메인 소켓 등을 노출하고, 다운스트림으로 부터 받은 요청을 처리</td>
    </tr>
    <tr>
      <td>Route</td>
      <td>Listener로 들어온 요청을 어떤 클러스터로 보낼지 정의</td>
    </tr>
    <tr>
      <td>Filter</td>
      <td>Listener로 부터 서비스에 트래픽 전달하기 전에 트래픽을 가공하거나 차단하는 역할을 하는 컴포넌트</td>
    </tr>
    <tr>
      <td>UpStream</td>
      <td>envoy 요청을 포워딩해서 연결하는 백엔드 네트워크 노드 - 사이드카일때는 application app, 아닐때는 원격 백엔드</td>
    </tr>
    <tr>
      <td>DownStream</td>
      <td>envoy로 연결하여 요청을 보내는 개체. 사이드카가 아닐때는 원격지의 클라이언트</td>
    </tr>
    <tr>
      <td>Host</td>
      <td>네트워크 통신이 가능한 개체 (PC, 서버, 휴대폰, 네트워크 어플리케이션 등)</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>많은 Service Mesh 솔루션이나, Gateway API 구현체들이 내부적으로 Envoy를 사용하고 있으며, Envoy가 제공하는 동적 구성을 위한 API(xDS Sync API)를 
이용하여 다양한 네트워크 정책을 구성하게 됩니다.</li>
  <li>Envoy의 xDS Sync API는 아래와 같은 레이어에서 동작합니다.
    <ul>
      <li>LDS - Listener Discovery Service</li>
      <li>RDS - Route Discovery Service</li>
      <li>CDS - Cluster Discovery Service</li>
      <li>EDS - Endpoint Discovery Service</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/2024/kans-3th/w7/20241019_kans_w7_5.png" alt="img.png" class="image-center w-80" /></p>

<p><img src="/assets/2024/kans-3th/w7/20241019_kans_w7_6.png" alt="img.png" class="image-center w-80" /></p>

<h4 id="envoy-실습">Envoy 실습</h4>

<ul>
  <li>test pc에 Envoy 설치</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 설치</span>
<span class="c"># echo "deb [signed-by=/etc/apt/keyrings/envoy-keyring.gpg] https://apt.envoyproxy.io focal main" | sudo tee /etc/apt/sources.list.d/envoy.list</span>
<span class="nv">$ </span>wget <span class="nt">-O-</span> https://apt.envoyproxy.io/signing.key | <span class="nb">sudo </span>gpg <span class="nt">--dearmor</span> <span class="nt">-o</span> /etc/apt/keyrings/envoy-keyring.gpg
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"deb [signed-by=/etc/apt/keyrings/envoy-keyring.gpg] https://apt.envoyproxy.io jammy main"</span> | <span class="nb">sudo tee</span> /etc/apt/sources.list.d/envoy.list
<span class="nv">$ </span><span class="nb">sudo </span>apt-get update <span class="o">&amp;&amp;</span> <span class="nb">sudo </span>apt-get <span class="nb">install </span>envoy <span class="nt">-y</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>envoy <span class="nt">--version</span>
<span class="c"># =&gt; envoy  version: e3b4a6e9570da15ac1caffdded17a8bebdc7dfc9/1.32.0/Clean/RELEASE/BoringSSL</span>

<span class="c"># 도움말</span>
<span class="nv">$ </span>envoy <span class="nt">--help</span>
</code></pre></div></div>

<ul>
  <li>Envoy proxy 실습 - <a href="https://www.envoyproxy.io/docs/envoy/latest/start/quick-start/">Link</a>
    <ul>
      <li>envoy-demo.yml 작성
        <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># envoy-demo.yml</span>
<span class="na">static_resources</span><span class="pi">:</span>
    
  <span class="na">listeners</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">listener_0</span>
    <span class="na">address</span><span class="pi">:</span>
      <span class="na">socket_address</span><span class="pi">:</span>
        <span class="na">address</span><span class="pi">:</span> <span class="s">0.0.0.0</span>
        <span class="na">port_value</span><span class="pi">:</span> <span class="m">10000</span>
    <span class="na">filter_chains</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">filters</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">envoy.filters.network.http_connection_manager</span>
        <span class="na">typed_config</span><span class="pi">:</span>
          <span class="s2">"</span><span class="s">@type"</span><span class="err">:</span> <span class="s">type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager</span>
          <span class="s">stat_prefix</span><span class="err">:</span> <span class="s">ingress_http</span>
          <span class="s">access_log</span><span class="err">:</span>
          <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">envoy.access_loggers.stdout</span>
            <span class="na">typed_config</span><span class="pi">:</span>
              <span class="s2">"</span><span class="s">@type"</span><span class="err">:</span> <span class="s">type.googleapis.com/envoy.extensions.access_loggers.stream.v3.StdoutAccessLog</span>
          <span class="na">http_filters</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">envoy.filters.http.router</span>
          <span class="na">route_config</span><span class="pi">:</span>
            <span class="na">name</span><span class="pi">:</span> <span class="s">local_route</span>
            <span class="na">virtual_hosts</span><span class="pi">:</span>
            <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">local_service</span>
              <span class="na">domains</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">*"</span><span class="pi">]</span>
              <span class="na">routes</span><span class="pi">:</span>
              <span class="pi">-</span> <span class="na">match</span><span class="pi">:</span>
                  <span class="na">prefix</span><span class="pi">:</span> <span class="s2">"</span><span class="s">/"</span>
                <span class="na">route</span><span class="pi">:</span>
                  <span class="na">host_rewrite_literal</span><span class="pi">:</span> <span class="s">www.envoyproxy.io</span>
                  <span class="na">cluster</span><span class="pi">:</span> <span class="s">service_envoyproxy_io</span>
    
  <span class="na">clusters</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">service_envoyproxy_io</span>
    <span class="na">type</span><span class="pi">:</span> <span class="s">LOGICAL_DNS</span>
    <span class="c1"># Comment out the following line to test on v6 networks</span>
    <span class="na">dns_lookup_family</span><span class="pi">:</span> <span class="s">V4_ONLY</span>
    <span class="na">connect_timeout</span><span class="pi">:</span> <span class="s">5s</span>
    <span class="na">load_assignment</span><span class="pi">:</span>
      <span class="na">cluster_name</span><span class="pi">:</span> <span class="s">service_envoyproxy_io</span>
      <span class="na">endpoints</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">lb_endpoints</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">endpoint</span><span class="pi">:</span>
            <span class="na">address</span><span class="pi">:</span>
              <span class="na">socket_address</span><span class="pi">:</span>
                <span class="na">address</span><span class="pi">:</span> <span class="s">www.envoyproxy.io</span>
                <span class="na">port_value</span><span class="pi">:</span> <span class="m">443</span>
    <span class="na">transport_socket</span><span class="pi">:</span>
      <span class="na">name</span><span class="pi">:</span> <span class="s">envoy.transport_sockets.tls</span>
      <span class="na">typed_config</span><span class="pi">:</span>
        <span class="s2">"</span><span class="s">@type"</span><span class="err">:</span> <span class="s">type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext</span>
        <span class="s">sni</span><span class="err">:</span> <span class="s">www.envoyproxy.io</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p>실행</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c"># (터미널1) 데모 config 적용하여 실행</span>
  <span class="nv">$ </span>curl <span class="nt">-O</span> https://www.envoyproxy.io/docs/envoy/latest/_downloads/92dcb9714fb6bc288d042029b34c0de4/envoy-demo.yaml
  <span class="nv">$ </span>envoy <span class="nt">-c</span> envoy-demo.yaml
  <span class="c"># =&gt; [2024-10-01 16:41:51.547][4479][info][main] [source/server/server.cc:426] initializing epoch 0 (base id=0, hot restart version=11.104)</span>
  <span class="c">#    ...</span>
    
  <span class="c"># (터미널2) 정보 확인</span>
  <span class="nv">$ </span>ss <span class="nt">-tnlp</span>
  <span class="c"># =&gt; State           Recv-Q           Send-Q                     Local Address:Port                      Peer Address:Port          Process</span>
  <span class="c">#    LISTEN          0                4096                             0.0.0.0:10000                          0.0.0.0:*              users:((&amp;quot;envoy&amp;quot;,pid=4479,fd=35))</span>
  <span class="c">#    LISTEN          0                4096                             0.0.0.0:10000                          0.0.0.0:*              users:((&amp;quot;envoy&amp;quot;,pid=4479,fd=34))</span>
  <span class="c">#    LISTEN          0                4096                             0.0.0.0:10000                          0.0.0.0:*              users:((&amp;quot;envoy&amp;quot;,pid=4479,fd=33))</span>
  <span class="c">#    LISTEN          0                4096                             0.0.0.0:10000                          0.0.0.0:*              users:((&amp;quot;envoy&amp;quot;,pid=4479,fd=32))</span>
  <span class="c">#    ...</span>
    
  <span class="c"># 접속 테스트</span>
  <span class="nv">$ </span>curl <span class="nt">-s</span> http://127.0.0.1:10000 | <span class="nb">grep</span> <span class="nt">-o</span> <span class="s2">"&lt;title&gt;.*&lt;/title&gt;"</span>
  <span class="c"># =&gt; &amp;lt;title&amp;gt;Envoy proxy - home&amp;lt;/title&amp;gt;</span>
    
  <span class="c"># 외부 접속 정보 출력</span>
  <span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"http://</span><span class="si">$(</span>curl <span class="nt">-s</span> ipinfo.io/ip<span class="si">)</span><span class="s2">:10000"</span>
  <span class="c"># =&gt; http://54.123.42.212:10000</span>
    
  <span class="nt">--------------------</span>
  <span class="c"># 자신의 PC 웹브라우저에서 외부 접속 정보 접속 확인!</span>
    
  <span class="c"># k3s-m 에서 접속 테스트</span>
  <span class="nv">$ </span>curl <span class="nt">-s</span> http://192.168.56.104:10000 | <span class="nb">grep</span> <span class="nt">-o</span> <span class="s2">"&lt;title&gt;.*&lt;/title&gt;"</span>
  <span class="c"># =&gt; &amp;lt;title&amp;gt;Envoy proxy - home&amp;lt;/title&amp;gt; </span>
  <span class="nt">--------------------</span>
    
  <span class="c"># 연결 정보 확인</span>
  <span class="nv">$ </span>ss <span class="nt">-tnp</span>
    
  <span class="c"># (터미널1) envoy 실행 취소(CTRL+C) 후 (관리자페이지) 설정 덮어쓰기 - 링크</span>
  <span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh">&gt; envoy-override.yaml
  admin:
    address:
      socket_address:
        address: 0.0.0.0
        port_value: 9902
</span><span class="no">  EOT
</span>  <span class="nv">$ </span>envoy <span class="nt">-c</span> envoy-demo.yaml <span class="nt">--config-yaml</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">cat </span>envoy-override.yaml<span class="si">)</span><span class="s2">"</span>
    
  <span class="c"># envoy 관리페이지 외부 접속 정보 출력</span>
  <span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"http://</span><span class="si">$(</span>curl <span class="nt">-s</span> ipinfo.io/ip<span class="si">)</span><span class="s2">:9902"</span>
  <span class="c"># =&gt; http://54.123.42.212:9902</span>
    
  <span class="nt">--------------------</span>
  <span class="c"># 자신의 PC 웹브라우저에서 관리 페이지 외부 접속 정보 접속 확인!</span>
</code></pre></div>        </div>

        <p><img src="/assets/2024/kans-3th/w7/20241019_kans_w7_7.png" alt="img.png" class="image-center" />
  <em class="image-caption">PC에서 접속한 화면</em></p>
      </li>
    </ul>
  </li>
</ul>

<h3 id="istio-소개-1">Istio 소개</h3>

<ul>
  <li><strong>Istio</strong>는 서비스 메시를 구축하고 관리하기 위한 오픈소스 플랫폼입니다.</li>
  <li><strong>Istio의 구성</strong>
<img src="/assets/2024/kans-3th/w7/20241019_kans_w7_3.svg" alt="20241019_kans_w7_3.svg" class="image-center w-80" />
    <ul>
      <li>파일럿(Pilot) : 모든 Envoy 사이드카에서 프록시 라우팅 규칙을 관리하며, 서비스 디스커버리, 로드밸런싱 설정을 제공합니다.</li>
      <li>겔리(Galley) : Istio와 쿠버네티스를 연결하는 역할을 합니다. 서비스 메시 구성 데이터를 검증하고 변환합니다.</li>
      <li>시타델(Citadel) : 서비스 간의 인증과 보안을 관리합니다. 서비스 간의 TLS 통신을 제공하고, 서비스 간의 인증을 관리합니다.</li>
    </ul>
  </li>
  <li>Istio의 구성요소
    <ul>
      <li>istiod : Istio의 중앙 제어 플레인으로, Pilot, Citadel, Galley를 포함합니다.</li>
      <li>istio proxy : Envoy 기반의 프록시로, istiod와 통신하며, 서비스 트래픽을 통제하고 옵저빌리티를 위한 메트릭을 제공합니다.</li>
    </ul>
  </li>
  <li>특징
    <ul>
      <li>Istio는 각 파드안에서 사이드카로 동작하는 Envoy가 트래픽을 제어하고 모니터링합니다.</li>
      <li>모든 마이크로 서비스간 통신은 Envoy를 통해 이루어지며, 이를 통해 메트릭을 수집하거나 컨트롤 할 수 있습니다.</li>
      <li>트래픽을 컨트롤 하기 위해서 Envoy 프록시에 전송룰을 정의 합니다.</li>
      <li>마이크로 서비스간의 통신을 mutual TLS 인증(mTLS)을 통해 보안합니다.</li>
      <li>각 어플리케이션은 파드 내의 엔보이 프록시에 접속하기 위해 localhost에 TCP 접속을 합니다.</li>
    </ul>
  </li>
</ul>

<h3 id="istio-설치-sidecar-모드">Istio 설치 (Sidecar 모드)</h3>

<ul>
  <li>Istio 공식 문서 : <a href="https://istio.io/latest/docs/">Link</a>
    <ul>
      <li>Istio Sidecar mode 설치 : v1.23.2 - 
<a href="https://istio.io/latest/docs/releases/supported-releases/#support-status-of-istio-releases">버전</a>
<a href="https://istio.io/latest/docs/setup/getting-started/">설치</a>,</li>
      <li>without GwApi - <a href="https://istio.io/latest/docs/setup/additional-setup/getting-started-istio-apis/">Docs</a></li>
      <li>Operator 방식 설치 : https://istio.io/latest/docs/setup/install/operator/ (Istio Operator는 <strong>Deprecated</strong> 되었습니다.)</li>
    </ul>
  </li>
  <li>Istio 설치
```bash</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># istioctl 설치</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">ISTIOV</span><span class="o">=</span>1.23.2
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"export ISTIOV=1.23.2"</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nt">-L</span> https://istio.io/downloadIstio | <span class="nv">ISTIO_VERSION</span><span class="o">=</span><span class="nv">$ISTIOV</span> <span class="nv">TARGET_ARCH</span><span class="o">=</span>x86_64 sh -
<span class="nv">$ </span>tree istio-<span class="nv">$ISTIOV</span> <span class="nt">-L</span> 2 <span class="c"># sample yaml 포함</span>
<span class="c"># =&gt; istio-1.23.2</span>
<span class="c">#    ├── LICENSE</span>
<span class="c">#    ├── README.md</span>
<span class="c">#    ├── bin</span>
<span class="c">#    │   └── istioctl</span>
<span class="c">#    ├── manifest.yaml</span>
<span class="c">#    ├── manifests</span>
<span class="c">#    │   ├── charts</span>
<span class="c">#    │   └── profiles</span>
<span class="c">#    ├── samples</span>
<span class="c">#    │   ...</span>
<span class="c">#    └── tools</span>
<span class="c">#        ├── _istioctl</span>
<span class="c">#        ├── certs</span>
<span class="c">#        └── istioctl.bash</span>
<span class="nv">$ </span><span class="nb">cp </span>istio-<span class="nv">$ISTIOV</span>/bin/istioctl /usr/local/bin/istioctl
<span class="nv">$ </span>istioctl version <span class="nt">--remote</span><span class="o">=</span><span class="nb">false</span>
<span class="c"># =&gt; client version: 1.23.2</span>

<span class="c"># (demo 프로파일) 컨트롤 플레인 배포 - 링크 Customizing</span>
<span class="c"># The istioctl command supports the full IstioOperator API via command-line options for individual settings or for passing a yaml file containing an IstioOperator custom resource (CR).</span>
<span class="nv">$ </span>istioctl profile list
<span class="c"># =&gt; Istio configuration profiles:</span>
<span class="c">#        ambient</span>
<span class="c">#        default</span>
<span class="c">#        demo</span>
<span class="c">#        empty</span>
<span class="c">#        minimal</span>
<span class="c">#        openshift</span>
<span class="c">#        openshift-ambient</span>
<span class="c">#        preview</span>
<span class="c">#        remote</span>
<span class="c">#        stable</span>
<span class="nv">$ </span>istioctl profile dump default
<span class="nv">$ </span>istioctl profile dump <span class="nt">--config-path</span> components.ingressGateways
<span class="c"># =&gt; - enabled: true</span>
<span class="c">#      name: istio-ingressgateway</span>
<span class="nv">$ </span>istioctl profile dump <span class="nt">--config-path</span> values.gateways.istio-ingressgateway
<span class="c"># =&gt; {}</span>
<span class="nv">$ </span>istioctl profile dump demo
<span class="c"># =&gt; apiVersion: install.istio.io/v1alpha1</span>
<span class="c">#    kind: IstioOperator</span>
<span class="c">#    spec:</span>
<span class="c">#      components:</span>
<span class="c">#        base:</span>
<span class="c">#          enabled: true</span>
<span class="c">#        egressGateways:</span>
<span class="c">#        - enabled: true</span>
<span class="c">#          name: istio-egressgateway</span>
<span class="c">#        ingressGateways:</span>
<span class="c">#        - enabled: true</span>
<span class="c">#          name: istio-ingressgateway</span>
<span class="c">#        pilot:</span>
<span class="c">#          enabled: true</span>
<span class="c">#      hub: docker.io/istio</span>
<span class="c">#      profile: demo</span>
<span class="c">#      tag: 1.23.2</span>
<span class="c">#      values:</span>
<span class="c">#        defaultRevision: &amp;quot;&amp;quot;</span>
<span class="c">#        gateways:</span>
<span class="c">#          istio-egressgateway: {}</span>
<span class="c">#          istio-ingressgateway: {}</span>
<span class="c">#        global:</span>
<span class="c">#          configValidation: true</span>
<span class="c">#          istioNamespace: istio-system</span>
<span class="c">#        profile: demo</span>

<span class="nv">$ </span>istioctl profile dump demo <span class="o">&gt;</span> demo-profile.yaml
<span class="nv">$ </span>vi demo-profile.yaml <span class="c"># 복잡성을 줄이게 실습 시나리오 환경 맞춤</span>
<span class="nt">--------------------</span>
    egressGateways:
    - enabled: <span class="nb">false</span>
<span class="nt">--------------------</span>    

<span class="nv">$ </span>istioctl <span class="nb">install</span> <span class="nt">-f</span> demo-profile.yaml <span class="nt">-y</span>
<span class="c"># =&gt; ✔ Istio core installed ⛵️</span>
<span class="c">#    ✔ Istiod installed 🧠</span>
<span class="c">#    ✔ Ingress gateways installed 🛬</span>
<span class="c">#    ✔ Installation complete</span>
<span class="c">#    Made this installation the default for cluster-wide operations.</span>

<span class="c"># 설치 확인 : istiod, istio-ingressgateway</span>
<span class="nv">$ </span>kubectl get all,svc,ep,sa,cm,secret,pdb <span class="nt">-n</span> istio-system
<span class="c"># =&gt; NAME                                        READY   STATUS    RESTARTS      AGE</span>
<span class="c">#    pod/istio-ingressgateway-5f9f654d46-l7mqp   1/1     Running   0             14m</span>
<span class="c">#    pod/istiod-7f8b586864-8mc4c                 1/1     Running   1 (82s ago)   14m</span>
<span class="c">#    </span>
<span class="c">#    NAME                           TYPE           CLUSTER-IP      EXTERNAL-IP                                    PORT(S)                                                                      AGE</span>
<span class="c">#    service/istio-ingressgateway   LoadBalancer   10.10.200.171   192.168.10.101,192.168.10.102,192.168.10.103   15021:30953/TCP,80:31677/TCP,443:30737/TCP,31400:30617/TCP,15443:31668/TCP   14m</span>
<span class="c">#    service/istiod                 ClusterIP      10.10.200.215   &amp;lt;none&amp;gt;                                         15010/TCP,15012/TCP,443/TCP,15014/TCP                                        14m</span>
<span class="c">#    </span>
<span class="c">#    NAME                                   READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/istio-ingressgateway   1/1     1            1           14m</span>
<span class="c">#    deployment.apps/istiod                 1/1     1            1           14m</span>
<span class="c">#    </span>
<span class="c">#    NAME                                              DESIRED   CURRENT   READY   AGE</span>
<span class="c">#    replicaset.apps/istio-ingressgateway-5f9f654d46   1         1         1       14m</span>
<span class="c">#    replicaset.apps/istiod-7f8b586864                 1         1         1       14m</span>
<span class="c">#    </span>
<span class="c">#    NAME                             ENDPOINTS                                                           AGE</span>
<span class="c">#    endpoints/istio-ingressgateway   172.16.2.14:15443,172.16.2.14:15021,172.16.2.14:31400 + 2 more...   14m</span>
<span class="c">#    endpoints/istiod                 172.16.3.16:15012,172.16.3.16:15010,172.16.3.16:15017 + 1 more...   14m</span>
<span class="c">#    </span>
<span class="c">#    NAME                                                  SECRETS   AGE</span>
<span class="c">#    serviceaccount/istio-ingressgateway-service-account   0         14m</span>
<span class="c">#    serviceaccount/istio-reader-service-account           0         14m</span>
<span class="c">#    serviceaccount/istiod                                 0         14m</span>
<span class="c">#    ...</span>
<span class="c">#    </span>
<span class="c">#    NAME                                            DATA   AGE</span>
<span class="c">#    configmap/istio                                 2      14m</span>
<span class="c">#    configmap/istio-sidecar-injector                2      14m</span>
<span class="c">#    ...</span>
<span class="c">#    </span>
<span class="c">#    NAME                     TYPE               DATA   AGE</span>
<span class="c">#    secret/istio-ca-secret   istio.io/ca-root   5      14m</span>
<span class="c">#    </span>
<span class="c">#    NAME                                              MIN AVAILABLE   MAX UNAVAILABLE   ALLOWED DISRUPTIONS   AGE</span>
<span class="c">#    poddisruptionbudget.policy/istio-ingressgateway   1               N/A               0                     14m</span>
<span class="c">#    poddisruptionbudget.policy/istiod                 1               N/A               0                     14m</span>
<span class="nv">$ </span>kubectl get crd | <span class="nb">grep </span>istio.io | <span class="nb">sort</span>
<span class="c"># =&gt; authorizationpolicies.security.istio.io      2024-10-01T05:26:47Z</span>
<span class="c">#    destinationrules.networking.istio.io         2024-10-01T05:26:47Z</span>
<span class="c">#    envoyfilters.networking.istio.io             2024-10-01T05:26:47Z</span>
<span class="c">#    gateways.networking.istio.io                 2024-10-01T05:26:47Z</span>
<span class="c">#    peerauthentications.security.istio.io        2024-10-01T05:26:47Z</span>
<span class="c">#    proxyconfigs.networking.istio.io             2024-10-01T05:26:47Z</span>
<span class="c">#    requestauthentications.security.istio.io     2024-10-01T05:26:47Z</span>
<span class="c">#    serviceentries.networking.istio.io           2024-10-01T05:26:47Z</span>
<span class="c">#    sidecars.networking.istio.io                 2024-10-01T05:26:47Z</span>
<span class="c">#    telemetries.telemetry.istio.io               2024-10-01T05:26:48Z</span>
<span class="c">#    virtualservices.networking.istio.io          2024-10-01T05:26:48Z</span>
<span class="c">#    wasmplugins.extensions.istio.io              2024-10-01T05:26:48Z</span>
<span class="c">#    workloadentries.networking.istio.io          2024-10-01T05:26:48Z</span>
<span class="c">#    workloadgroups.networking.istio.io           2024-10-01T05:26:48Z</span>

<span class="c"># istio-ingressgateway 의 envoy 버전 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> deploy/istio-ingressgateway <span class="nt">-n</span> istio-system <span class="nt">-c</span> istio-proxy <span class="nt">--</span> envoy <span class="nt">--version</span>
<span class="c"># =&gt; envoy  version: 6c72b2179f5a58988b920a55b0be8346de3f7b35/1.31.2-dev/Clean/RELEASE/BoringSSL</span>

<span class="c"># istio-ingressgateway 서비스 NodePort로 변경</span>
<span class="nv">$ </span>kubectl patch svc <span class="nt">-n</span> istio-system istio-ingressgateway <span class="nt">-p</span> <span class="s1">'{"spec":{"type":"NodePort"}}'</span>
<span class="c"># =&gt; service/istio-ingressgateway patched</span>

<span class="c"># istio-ingressgateway 서비스 확인</span>
<span class="nv">$ </span>kubectl get svc,ep <span class="nt">-n</span> istio-system istio-ingressgateway
<span class="c"># =&gt; NAME                           TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)                                                                      AGE</span>
<span class="c">#    service/istio-ingressgateway   NodePort   10.10.200.171   &amp;lt;none&amp;gt;        15021:30953/TCP,80:31677/TCP,443:30737/TCP,31400:30617/TCP,15443:31668/TCP   16m</span>
<span class="c">#    </span>
<span class="c">#    NAME                             ENDPOINTS                                                           AGE</span>
<span class="c">#    endpoints/istio-ingressgateway   172.16.2.14:15443,172.16.2.14:15021,172.16.2.14:31400 + 2 more...   16m</span>

<span class="c">## istio-ingressgateway 서비스 포트 정보 확인</span>
<span class="nv">$ </span>kubectl get svc <span class="nt">-n</span> istio-system istio-ingressgateway <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.spec.ports[<span class="k">*</span><span class="o">]}</span> | jq
<span class="c"># =&gt; {</span>
<span class="c">#      &amp;quot;name&amp;quot;: &amp;quot;https&amp;quot;,</span>
<span class="c">#      &amp;quot;nodePort&amp;quot;: 30737,</span>
<span class="c">#      &amp;quot;port&amp;quot;: 443,</span>
<span class="c">#      &amp;quot;protocol&amp;quot;: &amp;quot;TCP&amp;quot;,</span>
<span class="c">#      &amp;quot;targetPort&amp;quot;: 8443</span>
<span class="c">#    }</span>
<span class="c">#    {</span>
<span class="c">#      &amp;quot;name&amp;quot;: &amp;quot;tcp&amp;quot;,</span>
<span class="c">#      &amp;quot;nodePort&amp;quot;: 30617,</span>
<span class="c">#      &amp;quot;port&amp;quot;: 31400,</span>
<span class="c">#      &amp;quot;protocol&amp;quot;: &amp;quot;TCP&amp;quot;,</span>
<span class="c">#      &amp;quot;targetPort&amp;quot;: 31400</span>
<span class="c">#    }</span>
<span class="c">#    ...</span>

<span class="c">## istio-ingressgateway 디플로이먼트 파드의 포트 정보 확인 </span>
<span class="nv">$ </span>kubectl get deploy/istio-ingressgateway <span class="nt">-n</span> istio-system <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.spec.template.spec.containers[0].ports[<span class="k">*</span><span class="o">]}</span> | jq
<span class="c"># =&gt; ...</span>
<span class="c">#    {</span>
<span class="c">#      &amp;quot;containerPort&amp;quot;: 8443,</span>
<span class="c">#      &amp;quot;protocol&amp;quot;: &amp;quot;TCP&amp;quot;</span>
<span class="c">#    }</span>
<span class="c">#    {</span>
<span class="c">#      &amp;quot;containerPort&amp;quot;: 31400,</span>
<span class="c">#      &amp;quot;protocol&amp;quot;: &amp;quot;TCP&amp;quot;</span>
<span class="c">#    }</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>kubectl get deploy/istio-ingressgateway <span class="nt">-n</span> istio-system <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.spec.template.spec.containers[0].readinessProbe<span class="o">}</span> | jq
<span class="c"># =&gt; {</span>
<span class="c">#      &amp;quot;failureThreshold&amp;quot;: 30,</span>
<span class="c">#      &amp;quot;httpGet&amp;quot;: {</span>
<span class="c">#        &amp;quot;path&amp;quot;: &amp;quot;/healthz/ready&amp;quot;,</span>
<span class="c">#        &amp;quot;port&amp;quot;: 15021,</span>
<span class="c">#        &amp;quot;scheme&amp;quot;: &amp;quot;HTTP&amp;quot;</span>
<span class="c">#      },</span>
<span class="c">#      &amp;quot;initialDelaySeconds&amp;quot;: 1,</span>
<span class="c">#      &amp;quot;periodSeconds&amp;quot;: 2,</span>
<span class="c">#      &amp;quot;successThreshold&amp;quot;: 1,</span>
<span class="c">#      &amp;quot;timeoutSeconds&amp;quot;: 1</span>
<span class="c">#    }</span>

<span class="c"># istiod(컨트롤플레인) 디플로이먼트 정보 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> deployment.apps/istiod <span class="nt">-n</span> istio-system <span class="nt">--</span> ss <span class="nt">-tnlp</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> deployment.apps/istiod <span class="nt">-n</span> istio-system <span class="nt">--</span> ss <span class="nt">-tnp</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> deployment.apps/istiod <span class="nt">-n</span> istio-system <span class="nt">--</span> ps <span class="nt">-ef</span>
<span class="c"># =&gt; UID          PID    PPID  C STIME TTY          TIME CMD</span>
<span class="c">#    istio-p+       1       0  0 05:39 ?        00:00:01 /usr/local/bin/pilot-discovery discovery --monitoringAddr=:15014 --log_output_level=default:info --domain cluster.local --ke</span>

<span class="c"># istio-ingressgateway 디플로이먼트 정보 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> deployment.apps/istio-ingressgateway <span class="nt">-n</span> istio-system <span class="nt">--</span> ss <span class="nt">-tnlp</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> deployment.apps/istio-ingressgateway <span class="nt">-n</span> istio-system <span class="nt">--</span> ss <span class="nt">-tnp</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> deployment.apps/istio-ingressgateway <span class="nt">-n</span> istio-system <span class="nt">--</span> ps <span class="nt">-ef</span>
<span class="c"># =&gt; UID          PID    PPID  C STIME TTY          TIME CMD</span>
<span class="c">#    istio-p+       1       0  0 05:27 ?        00:00:08 /usr/local/bin/pilot-agent proxy router --domain istio-system.svc.cluster.local</span>
<span class="c">#    istio-p+      16       1  0 05:27 ?        00:00:04 /usr/local/bin/envoy -c etc/istio/proxy/envoy-rev.json --drain-time-s 45 --drai</span>
<span class="c"># # &lt;span style="color: green;"&gt;👉 pilot-agent와 envoy가 동작 중입니다.&lt;/span&gt;</span>

<span class="c"># envoy 설정 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> deployment.apps/istio-ingressgateway <span class="nt">-n</span> istio-system <span class="nt">--</span> <span class="nb">cat</span> /etc/istio/proxy/envoy-rev.json
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> deployment.apps/istio-ingressgateway <span class="nt">-n</span> istio-system <span class="nt">--</span> ss <span class="nt">-xnlp</span>
<span class="c"># =&gt; Netid      State       Recv-Q      Send-Q                                          Local Address:Port              Peer Address:Port      Process</span>
<span class="c">#    u_str      LISTEN      0           4096               var/run/secrets/workload-spiffe-uds/socket 32430                        * 0          users:((&amp;quot;pilot-agent&amp;quot;,pid=1,fd=9))</span>
<span class="c">#    u_str      LISTEN      0           4096                                      etc/istio/proxy/XDS 32431                        * 0          users:((&amp;quot;pilot-agent&amp;quot;,pid=1,fd=10))</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> deployment.apps/istio-ingressgateway <span class="nt">-n</span> istio-system <span class="nt">--</span> ss <span class="nt">-xnp</span>
<span class="c"># =&gt; Netid State Recv-Q Send-Q                              Local Address:Port  Peer Address:Port Process</span>
<span class="c">#    u_str ESTAB 0      0                                               * 39978            * 37977 users:((&amp;quot;envoy&amp;quot;,pid=16,fd=19))</span>
<span class="c">#    u_str ESTAB 0      0                                               * 37501            * 37981 users:((&amp;quot;envoy&amp;quot;,pid=16,fd=32))</span>
<span class="c">#    u_str ESTAB 0      0                             etc/istio/proxy/XDS 37977            * 39978 users:((&amp;quot;pilot-agent&amp;quot;,pid=1,fd=11))</span>
<span class="c">#    u_str ESTAB 0      0      var/run/secrets/workload-spiffe-uds/socket 37981            * 37501 users:((&amp;quot;pilot-agent&amp;quot;,pid=1,fd=15))</span>
</code></pre></div></div>

<ul>
  <li>Auto Injection with namespace label</li>
  <li>
    <p>해당 네임스페이스에 생성되는 모든 파드들은 istio 사이드카가 자동으로 injection 됩니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># mutating Webhook admisstion controller 사용</span>
<span class="nv">$ </span>kubectl label namespace default istio-injection<span class="o">=</span>enabled
<span class="c"># =&gt; namespace/default labeled</span>
<span class="nv">$ </span>kubectl get ns <span class="nt">-L</span> istio-injection
<span class="c"># =&gt; NAME              STATUS   AGE     ISTIO-INJECTION</span>
<span class="c">#    default           Active   7d      enabled</span>
<span class="c">#    ...</span>
</code></pre></div>    </div>

    <p><img src="/assets/2024/kans-3th/w7/20241019_kans_w7_8.png" alt="img.png" class="image-center" /></p>
  </li>
  <li>Istio 접속 테스트를 위한 변수 지정 및 k3s-m에서 접속 테스트</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># k3s-m)</span>
<span class="c"># istio ingress gw NodePort(HTTP 접속용) 변수 지정 </span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">IGWHTTP</span><span class="o">=</span><span class="si">$(</span>kubectl get service <span class="nt">-n</span> istio-system istio-ingressgateway <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.spec.ports[1].nodePort}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$IGWHTTP</span>
<span class="c"># =&gt; 31677</span>

<span class="c"># /etc/hosts 파일 수정</span>
<span class="c"># $ MYDOMAIN=&lt;각자 자신의 www 도메인&gt; # 단, 사용하고 있지 않는 공인 도메인을 사용 할 것</span>
<span class="c"># $ echo "&lt;istio-ingressgateway 파드가 있는 워커 노드&gt; $MYDOMAIN" &gt;&gt; /etc/hosts</span>

<span class="nv">$ </span><span class="nb">export </span><span class="nv">MYDOMAIN</span><span class="o">=</span>sweetlittlebird.com
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"192.168.10.10 </span><span class="nv">$MYDOMAIN</span><span class="s2">"</span> <span class="o">&gt;&gt;</span> /etc/hosts
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"export MYDOMAIN=</span><span class="nv">$MYDOMAIN</span><span class="s2">"</span> <span class="o">&gt;&gt;</span> /etc/profile

<span class="c"># istio ingress gw 접속 테스트 : 아직은 설정이 없어서 접속 실패가 됩니다.</span>
<span class="nv">$ </span>curl <span class="nt">-v</span> <span class="nt">-s</span> <span class="nv">$MYDOMAIN</span>:<span class="nv">$IGWHTTP</span>
<span class="c"># =&gt; *   Trying 192.168.10.10:31677...</span>
<span class="c">#    * connect to 192.168.10.10 port 31677 failed: Connection refused</span>
<span class="c">#    * Failed to connect to sweetlittlebird.com port 31677 after 3 ms: Connection refused</span>
<span class="c">#    * Closing connection 0</span>
</code></pre></div></div>

<ul>
  <li>testpc에서 접속 테스트</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 아래 변수는 각자 자신의 값을 직접 입력 할 것</span>
<span class="c"># $ IGWHTTP=&lt;각자 출력된 NodePort&gt;</span>
<span class="nv">$ IGWHTTP</span><span class="o">=</span>31677
<span class="nv">$ </span><span class="nb">export </span><span class="nv">MYDOMAIN</span><span class="o">=</span>sweetlittlebird.com
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"192.168.10.10 </span><span class="nv">$MYDOMAIN</span><span class="s2">"</span> <span class="o">&gt;&gt;</span> /etc/hosts
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"export MYDOMAIN=</span><span class="nv">$MYDOMAIN</span><span class="s2">"</span> <span class="o">&gt;&gt;</span> /etc/profile

<span class="c"># istio ingress gw 접속 테스트 : 아직은 설정이 없어서 접속 실패가 된다</span>
<span class="nv">$ </span>curl <span class="nt">-v</span> <span class="nt">-s</span> <span class="nv">$MYDOMAIN</span>:<span class="nv">$IGWHTTP</span>
<span class="c"># =&gt; * Host sweetlittlebird.com:31677 was resolved.</span>
<span class="c">#    * ...</span>
<span class="c">#    * Failed to connect to sweetlittlebird.com port 31677 after 2 ms: Couldn't connect to server</span>
<span class="c">#    * ...</span>
</code></pre></div></div>

<ul>
  <li>자신의 pc에서 접속 테스트</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 아래 변수는 각자 자신의 값을 직접 입력 할 것</span>
<span class="c"># $ IGWHTTP=&lt;각자 출력된 NodePort&gt;</span>
<span class="nv">$ IGWHTTP</span><span class="o">=</span>31677
<span class="c"># $ ISTIONODEIP=&lt;k3s-m 의 유동 공인 IP&gt;</span>
<span class="nv">$ ISTIONODEIP</span><span class="o">=</span>54.123.42.212

<span class="nv">$ </span><span class="nb">export </span><span class="nv">MYDOMAIN</span><span class="o">=</span>sweetlittlebird.com
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"192.168.10.10 </span><span class="nv">$MYDOMAIN</span><span class="s2">"</span> <span class="o">&gt;&gt;</span> /etc/hosts
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"export MYDOMAIN=</span><span class="nv">$MYDOMAIN</span><span class="s2">"</span> <span class="o">&gt;&gt;</span> /etc/profile

<span class="c"># istio ingress gw 접속 테스트 : 아직은 설정이 없어서 접속 실패가 된다</span>
<span class="nv">$ </span>curl <span class="nt">-v</span> <span class="nt">-s</span> <span class="nv">$MYDOMAIN</span>:<span class="nv">$IGWHTTP</span>
<span class="c"># =&gt; * Host sweetlittlebird.com:31677 was resolved.</span>
<span class="c">#    * ...</span>
<span class="c">#    * Failed to connect to sweetlittlebird.com port 31677 after 2 ms: Couldn't connect to server</span>
<span class="c">#    * ...</span>
</code></pre></div></div>

<h3 id="istio를-통한-외부-노출">Istio를 통한 외부 노출</h3>

<ul>
  <li>Nginx 디플로이먼트와 서비스 배포</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 로그 모니터링</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-n</span> istio-system <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>istiod
<span class="c"># =&gt; NAME                      READY   STATUS    RESTARTS      AGE</span>
<span class="c">#    istiod-7f8b586864-8mc4c   1/1     Running   1 (60m ago)   73m</span>
<span class="nv">$ </span>kubetail <span class="nt">-n</span> istio-system <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>istiod <span class="nt">-f</span>

<span class="nv">$ </span>kubectl get pod <span class="nt">-n</span> istio-system <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>istio-ingressgateway
<span class="c"># =&gt; NAME                                    READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    istio-ingressgateway-5f9f654d46-l7mqp   1/1     Running   0          74m</span>
<span class="nv">$ </span>kubetail <span class="nt">-n</span> istio-system <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>istio-ingressgateway <span class="nt">-f</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl create -f -
apiVersion: v1
kind: ServiceAccount
metadata:
  name: kans-nginx
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: deploy-websrv
spec:
  replicas: 1
  selector:
    matchLabels:
      app: deploy-websrv
  template:
    metadata:
      labels:
        app: deploy-websrv
    spec:
      serviceAccountName: kans-nginx
      terminationGracePeriodSeconds: 0
      containers:
      - name: deploy-websrv
        image: nginx:alpine
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: svc-clusterip
spec:
  ports:
    - name: svc-webport
      port: 80
      targetPort: 80
  selector:
    app: deploy-websrv
  type: ClusterIP
</span><span class="no">EOF
</span><span class="c"># =&gt; serviceaccount/kans-nginx created</span>
<span class="c">#    deployment.apps/deploy-websrv created</span>
<span class="c">#    service/svc-clusterip created</span>

<span class="c"># 사이드카 컨테이너 배포 확인</span>
<span class="nv">$ </span>kubectl get pod,svc,ep,sa <span class="nt">-o</span> wide
<span class="c"># =&gt; NAME                                 READY   STATUS    RESTARTS   AGE   IP            NODE     NOMINATED NODE   READINESS GATES</span>
<span class="c">#    pod/deploy-websrv-778ffd6947-cxf5k   2/2     Running   0          50s   172.16.1.13   k3s-w2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    </span>
<span class="c">#    NAME                    TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE     SELECTOR</span>
<span class="c">#    service/kubernetes      ClusterIP   10.10.200.1     &amp;lt;none&amp;gt;        443/TCP   6d16h   &amp;lt;none&amp;gt;</span>
<span class="c">#    service/svc-clusterip   ClusterIP   10.10.200.243   &amp;lt;none&amp;gt;        80/TCP    50s     app=deploy-websrv</span>
<span class="c">#    </span>
<span class="c">#    NAME                      ENDPOINTS            AGE</span>
<span class="c">#    endpoints/kubernetes      192.168.10.10:6443   6d16h</span>
<span class="c">#    endpoints/svc-clusterip   172.16.1.13:80       50s</span>
<span class="c">#    </span>
<span class="c">#    NAME                        SECRETS   AGE</span>
<span class="c">#    serviceaccount/default      0         7d1h</span>
<span class="c">#    serviceaccount/kans-nginx   0         50s</span>

<span class="nv">$ </span>kubectl describe pod
<span class="c"># =&gt; Name:             deploy-websrv-778ffd6947-cxf5k</span>
<span class="c">#    Namespace:        default</span>
<span class="c">#    Priority:         0</span>
<span class="c">#    Service Account:  kans-nginx</span>
<span class="c">#    Node:             k3s-w2/192.168.10.102</span>
<span class="c">#    Labels:           app=deploy-websrv</span>
<span class="c">#                      security.istio.io/tlsMode=istio</span>
<span class="c">#                      ...</span>
<span class="c">#    Annotations:      istio.io/rev: default</span>
<span class="c">#                      sidecar.istio.io/status:</span>
<span class="c">#                        {&amp;quot;initContainers&amp;quot;:[&amp;quot;istio-init&amp;quot;],&amp;quot;containers&amp;quot;:[&amp;quot;istio-proxy&amp;quot;],&amp;quot;volumes&amp;quot;:[&amp;quot;workload-socket&amp;quot;,&amp;quot;credential-socket&amp;quot;,&amp;quot;workload-certs&amp;quot;,&amp;quot;istio-env...</span>
<span class="c">#    Status:           Running</span>
<span class="c">#    ...</span>
<span class="c">#    Controlled By:  ReplicaSet/deploy-websrv-778ffd6947</span>
<span class="c">#    &lt;span style="color: red;"&gt;Init Containers:&lt;/span&gt;  # &lt;span style="color: green;"&gt;👉 init container가 파드내 iptables 셋팅&lt;/span&gt;</span>
<span class="c">#      istio-init:</span>
<span class="c">#        Container ID:  containerd://2a114fe0624581b35bda9ca257c6d3c831138e8a44900a6130e988bb51eb05da</span>
<span class="c">#        Image:         docker.io/istio/proxyv2:1.23.2</span>
<span class="c">#        Image ID:      docker.io/istio/proxyv2@sha256:2876cfc2fdf47e4b9665390ccc9ccf2bf913b71379325b8438135c9f35578e1a</span>
<span class="c">#        Port:          &amp;lt;none&amp;gt;</span>
<span class="c">#        Host Port:     &amp;lt;none&amp;gt;</span>
<span class="c">#        Args:</span>
<span class="c">#          &lt;span style="color: red;"&gt;istio-iptables&lt;/span&gt;</span>
<span class="c">#          -p</span>
<span class="c">#          15001</span>
<span class="c">#          -z</span>
<span class="c">#          15006</span>
<span class="c">#          -u</span>
<span class="c">#          1337</span>
<span class="c">#          -m</span>
<span class="c">#          REDIRECT</span>
<span class="c">#          -i</span>
<span class="c">#          *</span>
<span class="c">#          -x</span>
<span class="c">#    </span>
<span class="c">#          -b</span>
<span class="c">#          *</span>
<span class="c">#          -d</span>
<span class="c">#          15090,15021,15020</span>
<span class="c">#          --log_output_level=default:info</span>
<span class="c">#        State:          Terminated</span>
<span class="c">#          Reason:       Completed</span>
<span class="c">#        ...</span>
<span class="c">#    Containers:</span>
<span class="c">#      deploy-websrv:</span>
<span class="c">#        Container ID:   containerd://8918e0bb760bce8d090e84818bc189ae3ababdf9e74eb7dd3fb9709b356891f9</span>
<span class="c">#        Image:          nginx:alpine</span>
<span class="c">#        ...</span>
<span class="c">#      &lt;span style="color: red;"&gt;istio-proxy:&lt;/span&gt;  # &lt;span style="color: green;"&gt;👉 istio-proxy라는 컨테이너가 sidecar로 동작 중&lt;/span&gt;</span>
<span class="c">#        Container ID:  containerd://71d9e07a530dfce2ec34810d60a28dc3f9445b8eab714c2a7e204c459c59bcd3</span>
<span class="c">#        Image:         docker.io/istio/proxyv2:1.23.2</span>
<span class="c">#        Image ID:      docker.io/istio/proxyv2@sha256:2876cfc2fdf47e4b9665390ccc9ccf2bf913b71379325b8438135c9f35578e1a</span>
<span class="c">#        Port:          15090/TCP</span>
<span class="c">#        Host Port:     0/TCP</span>
<span class="c">#        Args:</span>
<span class="c">#          proxy</span>
<span class="c">#          sidecar</span>
<span class="c">#          --domain</span>
<span class="c">#          $(POD_NAMESPACE).svc.cluster.local</span>
<span class="c">#          --proxyLogLevel=warning</span>
<span class="c">#          --proxyComponentLogLevel=misc:error</span>
<span class="c">#          --log_output_level=default:info</span>
<span class="c">#        State:          Running</span>
<span class="c">#        ...</span>
</code></pre></div></div>

<ul>
  <li>Istio Gateway/VirtualService 설정 - Host 기반 트래픽 라우팅 설정 <a href="https://istio.io/latest/docs/setup/additional-setup/gateway/">링크</a>
<img src="/assets/2024/kans-3th/w7/20241019_kans_w7_9.png" alt="img.png" class="image-center w-80" />
    <ul>
      <li>클라이언트 PC → (Service:NodePort) Istio ingressgateway 파드 → (Gateway, VirtualService, Service 는 Bypass) → Endpoint(파드 : 사이드카 - Application 컨테이너)</li>
      <li>Gateway : 지정한 인그레스 게이트웨이로부터 트래픽이 인입, 프로토콜 및 포트, HOSTS, Proxy 등 설정 가능 <a href="https://istio.io/latest/docs/setup/additional-setup/gateway/">링크</a></li>
      <li>VirtualService : 인입 처리할 hosts 설정, L7 PATH 별 라우팅, 목적지에 대한 정책 설정 가능 (envoy route config)</li>
      <li>(참고) Introducing Istio v1 APIs - <a href="https://istio.io/latest/blog/2024/v1-apis/">Blog</a></li>
    </ul>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl create -f -
apiVersion: networking.istio.io/v1
kind: Gateway
metadata:
  name: test-gateway
spec:
  selector:
    istio: ingressgateway
  servers:
  - port:
      number: 80
      name: http
      protocol: HTTP
    hosts:
    - "*"
---
apiVersion: networking.istio.io/v1
kind: VirtualService
metadata:
  name: nginx-service
spec:
  hosts:
  - "</span><span class="nv">$MYDOMAIN</span><span class="sh">"
  gateways:
  - test-gateway
  http:
  - route:
    - destination:
        host: svc-clusterip
        port:
          number: 80
</span><span class="no">EOF
</span><span class="c"># =&gt; gateway.networking.istio.io/test-gateway created</span>
<span class="c">#    virtualservice.networking.istio.io/nginx-service created</span>

<span class="c"># Istio Gateway(=gw)/VirtualService(=vs) 설정 정보를 확인</span>
<span class="nv">$ </span>kubectl explain gateways.networking.istio.io
<span class="nv">$ </span>kubectl explain virtualservices.networking.istio.io
<span class="nv">$ </span>kubectl api-resources  | <span class="nb">grep </span>istio
<span class="c"># =&gt; wasmplugins                                      extensions.istio.io/v1alpha1      true         WasmPlugin</span>
<span class="c">#    destinationrules                    dr           networking.istio.io/v1            true         DestinationRule</span>
<span class="c">#    envoyfilters                                     networking.istio.io/v1alpha3      true         EnvoyFilter</span>
<span class="c">#    gateways                            gw           networking.istio.io/v1            true         Gateway</span>
<span class="c">#    proxyconfigs                                     networking.istio.io/v1beta1       true         ProxyConfig</span>
<span class="c">#    serviceentries                      se           networking.istio.io/v1            true         ServiceEntry</span>
<span class="c">#    sidecars                                         networking.istio.io/v1            true         Sidecar</span>
<span class="c">#    virtualservices                     vs           networking.istio.io/v1            true         VirtualService</span>
<span class="c">#    workloadentries                     we           networking.istio.io/v1            true         WorkloadEntry</span>
<span class="c">#    workloadgroups                      wg           networking.istio.io/v1            true         WorkloadGroup</span>
<span class="c">#    authorizationpolicies               ap           security.istio.io/v1              true         AuthorizationPolicy</span>
<span class="c">#    peerauthentications                 pa           security.istio.io/v1              true         PeerAuthentication</span>
<span class="c">#    requestauthentications              ra           security.istio.io/v1              true         RequestAuthentication</span>
<span class="c">#    telemetries                         telemetry    telemetry.istio.io/v1             true         Telemetry</span>

<span class="c"># virtual service 는 다른 네임스페이스의 서비스(ex. svc-nn.&lt;ns&gt;)도 참조할 수 있다</span>
<span class="nv">$ </span>kubectl get gw,vs
<span class="c"># =&gt; NAME                                       AGE</span>
<span class="c">#    gateway.networking.istio.io/test-gateway   105s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                               GATEWAYS           HOSTS                     AGE</span>
<span class="c">#    virtualservice.networking.istio.io/nginx-service   [&amp;quot;test-gateway&amp;quot;]   [&amp;quot;sweetlittlebird.com&amp;quot;]   105s</span>

<span class="c"># Retrieves last sent and last acknowledged xDS sync from Istiod to each Envoy in the mesh</span>
<span class="c"># istioctl proxy-status command was improved to include the time since last change, and more relevant status values.</span>
<span class="nv">$ </span>istioctl proxy-status <span class="c"># 단축어 ps</span>
<span class="nv">$ </span>istioctl ps
<span class="c"># =&gt; NAME                                                   CLUSTER        CDS                LDS                EDS              RDS                ECDS        ISTIOD                      VERSION</span>
<span class="c">#    deploy-websrv-778ffd6947-cxf5k.default                 Kubernetes     SYNCED (22m)       SYNCED (22m)       SYNCED (22m)     SYNCED (22m)       IGNORED     istiod-7f8b586864-8mc4c     1.23.2</span>
<span class="c">#    istio-ingressgateway-5f9f654d46-l7mqp.istio-system     Kubernetes     SYNCED (2m14s)     SYNCED (2m14s)     SYNCED (22m)     SYNCED (2m14s)     IGNORED     istiod-7f8b586864-8mc4c     1.23.2</span>
</code></pre></div></div>

<ul>
  <li>Istio를 통한 Nginx 파드 접속 테스트
    <ul>
      <li>외부 (자신의 PC, test pc)에서 접속 테스트</li>
    </ul>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># istio ingress gw 를 통한 접속 테스트</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$MYDOMAIN</span>:<span class="nv">$IGWHTTP</span> | <span class="nb">grep</span> <span class="nt">-o</span> <span class="s2">"&lt;title&gt;.*&lt;/title&gt;"</span>
<span class="c"># =&gt; &lt;title&gt;Welcome to nginx!&lt;/title&gt;</span>
<span class="nv">$ </span>curl <span class="nt">-v</span> <span class="nt">-s</span> <span class="nv">$MYDOMAIN</span>:<span class="nv">$IGWHTTP</span>
<span class="c"># =&gt; * Host sweetlittlebird.com:31677 was resolved.</span>
<span class="c">#    * IPv6: (none)</span>
<span class="c">#    * IPv4: 192.168.10.10, 192.168.10.10</span>
<span class="c">#    *   Trying 192.168.10.10:31677...</span>
<span class="c">#    * Connected to sweetlittlebird.com (192.168.10.10) port 31677</span>
<span class="c">#    &amp;gt; GET / HTTP/1.1</span>
<span class="c">#    &amp;gt; Host: sweetlittlebird.com:31677</span>
<span class="c">#    &amp;gt; User-Agent: curl/8.5.0</span>
<span class="c">#    &amp;gt; Accept: */*</span>
<span class="c">#    &amp;gt;</span>
<span class="c">#    &amp;lt; HTTP/1.1 200 OK</span>
<span class="c">#    &amp;lt; server: istio-envoy</span>
<span class="c">#    &amp;lt; date: Sat, 19 Oct 2024 07:14:25 GMT</span>
<span class="c">#    &amp;lt; content-type: text/html</span>
<span class="c">#    &amp;lt; content-length: 615</span>
<span class="c">#    &amp;lt; last-modified: Wed, 02 Oct 2024 16:07:39 GMT</span>
<span class="c">#    &amp;lt; etag: &amp;quot;66fd6fcb-267&amp;quot;</span>
<span class="c">#    &amp;lt; accept-ranges: bytes</span>
<span class="c">#    &amp;lt; x-envoy-upstream-service-time: 1</span>
<span class="c">#    ...</span>
<span class="c"># $ curl -v -s &lt;유동공인이IP&gt;:$IGWHTTP</span>
<span class="nv">$ </span>curl <span class="nt">-v</span> <span class="nt">-s</span> 54.123.42.212:<span class="nv">$IGWHTTP</span>
</code></pre></div></div>

<ul>
  <li>출력 로그 정보 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubetail <span class="nt">-n</span> istio-system <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>istio-ingressgateway <span class="nt">-f</span>
<span class="c"># =&gt; [istio-ingressgateway-5f9f654d46-l7mqp] [2024-10-01T07:49:20.833Z] &amp;quot;GET / HTTP/1.1&amp;quot; 200 - via_upstream - &amp;quot;-&amp;quot; 0 615 6 5 &amp;quot;172.16.0.0&amp;quot; &amp;quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.6 Safari/605.1.15&amp;quot; &amp;quot;6f246b4e-d675-971e-9a9d-dd809f560c6f&amp;quot; &amp;quot;sweetlittlebird.com:31677&amp;quot; &amp;quot;172.16.1.13:80&amp;quot; </span>
<span class="c">#    &lt;span style="color: red;"&gt;outbound|80||svc-clusterip.default.svc.cluster.local&lt;/span&gt; 172.16.2.14:60786 172.16.2.14:8080 172.16.0.0:8773 - -</span>
<span class="nv">$ </span>kubetail <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>deploy-websrv
<span class="c"># =&gt; [deploy-websrv-778ffd6947-cxf5k istio-proxy] [2024-10-01T07:49:20.866Z] &amp;quot;GET / HTTP/1.1&amp;quot; 200 - via_upstream - &amp;quot;-&amp;quot; 0 615 2 1 &amp;quot;172.16.0.0&amp;quot; &amp;quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.6 Safari/605.1.15&amp;quot; &amp;quot;6f246b4e-d675-971e-9a9d-dd809f560c6f&amp;quot; &amp;quot;sweetlittlebird.com:31677&amp;quot; &amp;quot;172.16.1.13:80&amp;quot; </span>
<span class="c">#    &lt;span style="color: red;"&gt;inbound|80||&lt;/span&gt; 127.0.0.6:40337 172.16.1.13:80 172.16.0.0:0 invalid:outbound_.80_._.svc-clusterip.default.svc.cluster.local default</span>
</code></pre></div></div>

<p><img src="/assets/2024/kans-3th/w7/20241019_kans_w7_10.png" alt="img.png" class="image-center" /></p>

<ul>
  <li>istioctl 정보 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>istioctl proxy-status
<span class="c"># =&gt; NAME                                                   CLUSTER        CDS              LDS              EDS              RDS              ECDS        ISTIOD                      VERSION</span>
<span class="c">#    deploy-websrv-778ffd6947-cxf5k.default                 Kubernetes     SYNCED (19m)     SYNCED (19m)     SYNCED (19m)     SYNCED (19m)     IGNORED     istiod-7f8b586864-8mc4c     1.23.2</span>
<span class="c">#    istio-ingressgateway-5f9f654d46-l7mqp.istio-system     Kubernetes     SYNCED (24m)     SYNCED (24m)     SYNCED (24m)     SYNCED (24m)     IGNORED     istiod-7f8b586864-8mc4c     1.23.2</span>

<span class="c"># Envoy config dump : all, cluster, endpoint, listener 등</span>
<span class="nv">$ </span>istioctl proxy-config <span class="nt">--help</span> 
<span class="nv">$ </span>istioctl proxy-config all deploy-websrv-778ffd6947-cxf5k
<span class="nv">$ </span>istioctl proxy-config all deploy-websrv-778ffd6947-cxf5k <span class="nt">-o</span> json | jq
<span class="nv">$ </span>istioctl proxy-config route deploy-websrv-778ffd6947-cxf5k <span class="nt">-o</span> json | jq
</code></pre></div></div>

<ul>
  <li>pilot : istio-proxy내 uds로 envoy와 grpc통신, istiod에서 받아온 dynamic config를 envoy에 전달</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># istio-proxy 사용자 정보 확인 : uid(1337):gid(1337) 확인 -&gt; iptables rule 에서 사용됨</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> deploy/deploy-websrv <span class="nt">-c</span> istio-proxy <span class="nt">--</span> <span class="nb">tail</span> <span class="nt">-n</span> 3 /etc/passwd
<span class="c"># =&gt; ubuntu:x:1000:1000:Ubuntu:/home/ubuntu:/bin/bash</span>
<span class="c">#    tcpdump:x:100:102::/nonexistent:/usr/sbin/nologin</span>
<span class="c">#    istio-proxy:x:1337:1337::/home/istio-proxy:/bin/sh</span>

<span class="c"># envoy 설정 정보 확인 : dynamic_resources , static_resources - listeners  </span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> deploy/deploy-websrv <span class="nt">-c</span> istio-proxy <span class="nt">--</span> <span class="nb">cat</span> /etc/istio/proxy/envoy-rev.json
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> deploy/deploy-websrv <span class="nt">-c</span> istio-proxy <span class="nt">--</span> ss <span class="nt">-nlp</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> deploy/deploy-websrv <span class="nt">-c</span> istio-proxy <span class="nt">--</span> ss <span class="nt">-np</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> deploy/deploy-websrv <span class="nt">-c</span> istio-proxy <span class="nt">--</span> netstat <span class="nt">-np</span>
<span class="c"># =&gt; Active Internet connections (w/o servers)</span>
<span class="c">#    Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name</span>
<span class="c">#    tcp        0      0 127.0.0.1:33168         127.0.0.1:15020         ESTABLISHED 13/envoy</span>
<span class="c">#    tcp        0      0 127.0.0.1:33156         127.0.0.1:15020         ESTABLISHED 13/envoy</span>
<span class="c">#    tcp        0      0 172.16.1.13:15006       172.16.2.14:33006       ESTABLISHED 13/envoy</span>
<span class="c">#    tcp        0      0 172.16.1.13:59774       10.10.200.215:15012     ESTABLISHED 1/pilot-agent</span>
<span class="c">#    tcp        0      0 172.16.1.13:15006       172.16.2.14:60786       ESTABLISHED 13/envoy</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 172.16.1.13 : deploy-websrv 파드 ip&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;    172.16.2.14 : istio-ingressgateway 파드 ip&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;    10.10.200.215 : istiod 서비스의 Cluster-IP&lt;/span&gt;</span>
<span class="c">#    ...</span>
<span class="c">#    Active UNIX domain sockets (w/o servers)</span>
<span class="c">#    Proto RefCnt Flags       Type       State         I-Node   PID/Program name     Path</span>
<span class="c">#    unix  3      [ ]         STREAM     CONNECTED     54162    13/envoy</span>
<span class="c">#    unix  3      [ ]         STREAM     CONNECTED     54709    1/pilot-agent        var/run/secrets/workload-spiffe-uds/socket</span>
<span class="c">#    unix  3      [ ]         STREAM     CONNECTED     71034    1/pilot-agent        etc/istio/proxy/XDS</span>
<span class="c">#    unix  3      [ ]         STREAM     CONNECTED     72979    13/envoy</span>
<span class="c">#    ...</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> deploy/deploy-websrv <span class="nt">-c</span> istio-proxy <span class="nt">--</span> ps <span class="nt">-ef</span>
<span class="c"># =&gt; UID          PID    PPID  C STIME TTY          TIME CMD</span>
<span class="c">#    istio-p+       1       0  0 06:43 ?        00:00:01 /usr/local/bin/pilot-agent proxy sidecar --domain default.svc.cluster.local --proxyLogLevel=warning --proxyComponentLogLevel=mi</span>
<span class="c">#    istio-p+      13       1  0 06:43 ?        00:00:34 /usr/local/bin/envoy -c etc/istio/proxy/envoy-rev.json --drain-time-s 45 --drain-strategy immediate --local-address-ip-version</span>

<span class="c"># </span>
<span class="nv">$ </span>kubectl get pod,svc <span class="nt">-A</span> <span class="nt">-owide</span>
<span class="c"># =&gt; NAMESPACE      NAME                                            READY   STATUS    RESTARTS        AGE     IP            NODE     NOMINATED NODE   READINESS GATES</span>
<span class="c">#    default        pod/deploy-websrv-778ffd6947-cxf5k              2/2     Running   0               91m     172.16.1.13   k3s-w2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    istio-system   pod/istio-ingressgateway-5f9f654d46-l7mqp       1/1     Running   0               167m    172.16.2.14   k3s-w3   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    istio-system   pod/istiod-7f8b586864-8mc4c                     1/1     Running   1 (154m ago)    167m    172.16.3.16   k3s-w1   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    ...</span>
<span class="c">#    </span>
<span class="c">#    NAMESPACE      NAME                                         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                                                                      AGE     SELECTOR</span>
<span class="c">#    default        service/kubernetes                           ClusterIP   10.10.200.1     &amp;lt;none&amp;gt;        443/TCP                                                                      6d17h   &amp;lt;none&amp;gt;</span>
<span class="c">#    default        service/svc-clusterip                        ClusterIP   10.10.200.243   &amp;lt;none&amp;gt;        80/TCP                                                                       91m     app=deploy-websrv</span>
<span class="c">#    istio-system   service/istio-ingressgateway                 NodePort    10.10.200.171   &amp;lt;none&amp;gt;        15021:30953/TCP,80:31677/TCP,443:30737/TCP,31400:30617/TCP,15443:31668/TCP   167m    app=istio-ingressgateway,istio=ingressgateway</span>
<span class="c">#    istio-system   service/istiod                               ClusterIP   10.10.200.215   &amp;lt;none&amp;gt;        15010/TCP,15012/TCP,443/TCP,15014/TCP                                        167m    app=istiod,istio=pilot</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> deploy/deploy-websrv <span class="nt">-c</span> istio-proxy <span class="nt">--</span> netstat <span class="nt">-antp</span>
<span class="c"># =&gt; Active Internet connections (servers and established)</span>
<span class="c">#    Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name</span>
<span class="c">#    tcp        0      0 0.0.0.0:80              0.0.0.0:*               LISTEN      -</span>
<span class="c">#    ...</span>
<span class="c">#    tcp        0      0 127.0.0.1:33168         127.0.0.1:15020         ESTABLISHED 13/envoy</span>
<span class="c">#    tcp        0      0 127.0.0.1:33156         127.0.0.1:15020         ESTABLISHED 13/envoy</span>
<span class="c">#    tcp        0      0 172.16.1.13:15006       172.16.2.14:33006       ESTABLISHED 13/envoy</span>
<span class="c">#    tcp        0      0 172.16.1.13:59774       10.10.200.215:15012     ESTABLISHED 1/pilot-agent</span>
<span class="c">#    tcp        0      0 172.16.1.13:15006       172.16.2.14:60786       ESTABLISHED 13/envoy</span>
<span class="c">#    tcp6       0      0 127.0.0.1:15020         127.0.0.1:33168         ESTABLISHED 1/pilot-agent</span>
<span class="c">#    tcp6       0      0 127.0.0.1:15020         127.0.0.1:33156         ESTABLISHED 1/pilot-agent</span>

<span class="c"># istiod 정보 같이 확인 : 출력되는 IP가 누구인지 확인 해보자</span>
<span class="nv">$ </span>kubectl get pod,svc <span class="nt">-A</span> <span class="nt">-owide</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> deploy/istiod <span class="nt">-n</span> istio-system <span class="nt">--</span> ps <span class="nt">-ef</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> deploy/istiod <span class="nt">-n</span> istio-system <span class="nt">--</span> netstat <span class="nt">-antp</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> deploy/istiod <span class="nt">-n</span> istio-system <span class="nt">--</span> ss <span class="nt">-nlp</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> deploy/istiod <span class="nt">-n</span> istio-system <span class="nt">--</span> ss <span class="nt">-np</span>
<span class="c"># =&gt; Netid  State  Recv-Q  Send-Q         Local Address:Port           Peer Address:Port   Process</span>
<span class="c">#    tcp    ESTAB  0       0                172.16.3.16:33552           10.10.200.1:443     users:((&amp;quot;pilot-discovery&amp;quot;,pid=1,fd=7))</span>
<span class="c">#    tcp    ESTAB  0       0       [::ffff:172.16.3.16]:15012  [::ffff:172.16.2.14]:37102   users:((&amp;quot;pilot-discovery&amp;quot;,pid=1,fd=13))</span>
<span class="c">#    tcp    ESTAB  0       0       [::ffff:172.16.3.16]:15012  [::ffff:172.16.1.13]:56560   users:((&amp;quot;pilot-discovery&amp;quot;,pid=1,fd=14))</span>
</code></pre></div></div>

<ul>
  <li>istio-proxy, istiod가 각각 사용하는 포트 정보 <a href="https://istio.io/latest/docs/ops/deployment/application-requirements/">링크</a>
    <ul>
      <li>
        <p>istio-proxy</p>

        <table>
          <thead>
            <tr>
              <th>Port</th>
              <th>Protocol</th>
              <th>Description</th>
              <th>Pod-internal only</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>15000</td>
              <td>TCP</td>
              <td>Envoy admin port (commands/diagnostics)</td>
              <td>Yes</td>
            </tr>
            <tr>
              <td>15001</td>
              <td>TCP</td>
              <td>Envoy outbound</td>
              <td>No</td>
            </tr>
            <tr>
              <td>15004</td>
              <td>HTTP</td>
              <td>Debug port</td>
              <td>Yes</td>
            </tr>
            <tr>
              <td>15006</td>
              <td>TCP</td>
              <td>Envoy inbound</td>
              <td>No</td>
            </tr>
            <tr>
              <td>15008</td>
              <td>HTTP2</td>
              <td>HBONE mTLS tunnel port</td>
              <td>No</td>
            </tr>
            <tr>
              <td>15020</td>
              <td>HTTP</td>
              <td>Merged Prometheus telemetry from Istio agent, Envoy, and application No</td>
              <td>No</td>
            </tr>
            <tr>
              <td>15021</td>
              <td>HTTP</td>
              <td>Health checks</td>
              <td>No</td>
            </tr>
            <tr>
              <td>15053</td>
              <td>DNS</td>
              <td>DNS port, if capture is enabled</td>
              <td>Yes</td>
            </tr>
            <tr>
              <td>15090</td>
              <td>HTTP</td>
              <td>Envoy Prometheus telemetry</td>
              <td>No</td>
            </tr>
          </tbody>
        </table>
      </li>
      <li>
        <p>istiod (컨트롤플레인)</p>

        <table>
          <thead>
            <tr>
              <th>Port</th>
              <th>Protocol</th>
              <th>Description</th>
              <th>Pod-internal only</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>443</td>
              <td>HTTPS</td>
              <td>Webhooks service port</td>
              <td>No</td>
            </tr>
            <tr>
              <td>8080</td>
              <td>HTTP</td>
              <td>Debug interface (deprecated, container port only)</td>
              <td>No</td>
            </tr>
            <tr>
              <td>15010</td>
              <td>GRPC</td>
              <td>XDS and CA services (Plaintext, only for secure networks)</td>
              <td>No</td>
            </tr>
            <tr>
              <td>15012</td>
              <td>GRPC</td>
              <td>XDS and CA services (TLS and mTLS, recommended for production use)</td>
              <td>No</td>
            </tr>
            <tr>
              <td>15014</td>
              <td>HTTP</td>
              <td>Control plane monitoring</td>
              <td>No</td>
            </tr>
            <tr>
              <td>15017</td>
              <td>HTTPS</td>
              <td>Webhook container port, forwarded from 443</td>
              <td>No</td>
            </tr>
          </tbody>
        </table>
      </li>
    </ul>
  </li>
  <li>Istio - Istio proxy와 Envoy 프로세스간 유닉스 도메인 소켓 통신 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 파드 확인</span>
<span class="nv">$ </span>kubectl get pod
<span class="c"># =&gt; NAME                             READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    deploy-websrv-778ffd6947-cxf5k   2/2     Running   0          106m</span>

<span class="c"># istio 컨테이너 접속</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> deploy/deploy-websrv <span class="nt">-c</span> istio-proxy <span class="nt">--</span> bash
<span class="nt">---------------------------------------------------------------</span>
<span class="c"># SDS, XDS 는 소켓 타입</span>
<span class="nv">$ </span><span class="nb">ls</span> <span class="nt">-al</span> /etc/istio/proxy
<span class="c"># =&gt; total 24</span>
<span class="c">#    drwxrwxrwt 2 root        root          100 Oct 19 06:43 .</span>
<span class="c">#    drwxr-xr-x 4 root        root         4096 Oct 19 06:43 ..</span>
<span class="c">#    srw-rw-rw- 1 istio-proxy istio-proxy     0 Oct 19 06:43 XDS</span>
<span class="c">#    -rw-r--r-- 1 istio-proxy istio-proxy 13644 Oct 19 06:43 envoy-rev.json</span>
<span class="c">#    -rw-r--r-- 1 istio-proxy istio-proxy  2747 Oct 19 06:43 grpc-bootstrap.json</span>

<span class="c"># .json 파일 확인</span>
<span class="nv">$ </span>more /etc/istio/proxy/envoy-rev.json
<span class="c"># =&gt; {</span>
<span class="c">#      &amp;quot;node&amp;quot;: {</span>
<span class="c">#        &amp;quot;id&amp;quot;: &amp;quot;sidecar~172.16.1.13~deploy-websrv-778ffd6947-cxf5k.default~default.svc.cluster.local&amp;quot;,</span>
<span class="c">#        &amp;quot;cluster&amp;quot;: &amp;quot;deploy-websrv.default&amp;quot;,</span>
<span class="c">#    ...</span>
<span class="c">#      &amp;quot;admin&amp;quot;: {</span>
<span class="c">#        &amp;quot;access_log&amp;quot;: [</span>
<span class="c">#          {</span>
<span class="c">#            &amp;quot;name&amp;quot;: &amp;quot;envoy.access_loggers.file&amp;quot;,</span>
<span class="c">#            &amp;quot;typed_config&amp;quot;: {</span>
<span class="c">#              &amp;quot;@type&amp;quot;: &amp;quot;type.googleapis.com/envoy.extensions.access_loggers.file.v3.FileAccessLog&amp;quot;,</span>
<span class="c">#              &amp;quot;path&amp;quot;: &amp;quot;/dev/null&amp;quot;</span>
<span class="c">#            }</span>
<span class="c">#          }</span>
<span class="c">#        ],</span>
<span class="c">#        &amp;quot;profile_path&amp;quot;: &amp;quot;/var/lib/istio/data/envoy.prof&amp;quot;,</span>
<span class="c">#        &amp;quot;address&amp;quot;: {</span>
<span class="c">#          &amp;quot;socket_address&amp;quot;: {</span>
<span class="c">#            &amp;quot;address&amp;quot;: &amp;quot;127.0.0.1&amp;quot;,</span>
<span class="c">#            &amp;quot;port_value&amp;quot;: 15000</span>
<span class="c">#          }</span>
<span class="c">#        }</span>
<span class="c">#      },</span>
<span class="c">#    ...</span>
<span class="c">#    &amp;quot;dynamic_resources&amp;quot;: {</span>
<span class="c">#        &amp;quot;lds_config&amp;quot;: {</span>
<span class="c">#          &amp;quot;ads&amp;quot;: {},</span>
<span class="c">#          &amp;quot;initial_fetch_timeout&amp;quot;: &amp;quot;0s&amp;quot;,</span>
<span class="c">#          &amp;quot;resource_api_version&amp;quot;: &amp;quot;V3&amp;quot;</span>
<span class="c">#        },</span>
<span class="c">#        &amp;quot;cds_config&amp;quot;: {</span>
<span class="c">#          &amp;quot;ads&amp;quot;: {},</span>
<span class="c">#          &amp;quot;initial_fetch_timeout&amp;quot;: &amp;quot;0s&amp;quot;,</span>
<span class="c">#          &amp;quot;resource_api_version&amp;quot;: &amp;quot;V3&amp;quot;</span>
<span class="c">#        },</span>
<span class="c">#        &amp;quot;ads_config&amp;quot;: {</span>
<span class="c">#          &amp;quot;api_type&amp;quot;: &amp;quot;GRPC&amp;quot;,</span>
<span class="c">#          &amp;quot;set_node_on_first_message_only&amp;quot;: true,</span>
<span class="c">#          &amp;quot;transport_api_version&amp;quot;: &amp;quot;V3&amp;quot;,</span>
<span class="c">#          &amp;quot;grpc_services&amp;quot;: [</span>
<span class="c">#            {</span>
<span class="c">#              &amp;quot;envoy_grpc&amp;quot;: {</span>
<span class="c">#                &amp;quot;cluster_name&amp;quot;: &amp;quot;xds-grpc&amp;quot;</span>
<span class="c">#    ...</span>
<span class="c">#    &amp;quot;static_resources&amp;quot;: {</span>
<span class="c">#        &amp;quot;clusters&amp;quot;: [</span>
<span class="c">#          {</span>
<span class="c">#            ...</span>
<span class="c">#            &amp;quot;name&amp;quot;: &amp;quot;xds-grpc&amp;quot;,</span>
<span class="c">#            &amp;quot;alt_stat_name&amp;quot;: &amp;quot;xds-grpc;&amp;quot;,</span>
<span class="c">#            &amp;quot;type&amp;quot; : &amp;quot;STATIC&amp;quot;,</span>
<span class="c">#            &amp;quot;connect_timeout&amp;quot;: &amp;quot;1s&amp;quot;,</span>
<span class="c">#            &amp;quot;lb_policy&amp;quot;: &amp;quot;ROUND_ROBIN&amp;quot;,</span>
<span class="c">#            &amp;quot;load_assignment&amp;quot;: {</span>
<span class="c">#              &amp;quot;cluster_name&amp;quot;: &amp;quot;xds-grpc&amp;quot;,</span>
<span class="c">#              &amp;quot;endpoints&amp;quot;: [{</span>
<span class="c">#                &amp;quot;lb_endpoints&amp;quot;: [{</span>
<span class="c">#                  &amp;quot;endpoint&amp;quot;: {</span>
<span class="c">#                    &amp;quot;address&amp;quot;:{</span>
<span class="c">#                      &amp;quot;pipe&amp;quot;: {</span>
<span class="c">#                        &amp;quot;path&amp;quot;: &amp;quot;./etc/istio/proxy/XDS&amp;quot;</span>
<span class="c">#                      }</span>
<span class="c">#    ...</span>
<span class="c">#    &amp;quot;listeners&amp;quot;:[</span>
<span class="c">#      ...</span>
<span class="c">#      &amp;quot;address&amp;quot;: {</span>
<span class="c">#        &amp;quot;socket_address&amp;quot;: {</span>
<span class="c">#          &amp;quot;protocol&amp;quot;: &amp;quot;TCP&amp;quot;,</span>
<span class="c">#          &amp;quot;address&amp;quot;: &amp;quot;0.0.0.0&amp;quot;,</span>
<span class="c">#          &amp;quot;port_value&amp;quot;: 15090</span>
<span class="c">#        }</span>
<span class="c">#      },</span>
<span class="c">#     &amp;quot;filter_chains&amp;quot;: [</span>
<span class="c">#                &amp;quot;filters&amp;quot;: [</span>
<span class="c">#                  {</span>
<span class="c">#                    &amp;quot;name&amp;quot;: &amp;quot;envoy.filters.network.http_connection_manager&amp;quot;,</span>
<span class="c">#                    &amp;quot;typed_config&amp;quot;: {</span>
<span class="c">#                      &amp;quot;@type&amp;quot;: &amp;quot;type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager&amp;quot;,</span>
<span class="c">#                      &amp;quot;codec_type&amp;quot;: &amp;quot;AUTO&amp;quot;,</span>
<span class="c">#                      &amp;quot;stat_prefix&amp;quot;: &amp;quot;agent&amp;quot;,</span>
<span class="c">#                      &amp;quot;route_config&amp;quot;: {</span>
<span class="c">#                        &amp;quot;virtual_hosts&amp;quot;: [</span>
<span class="c">#                          {</span>
<span class="c">#                            &amp;quot;name&amp;quot;: &amp;quot;backend&amp;quot;,</span>
<span class="c">#                            &amp;quot;domains&amp;quot;: [</span>
<span class="c">#                              &amp;quot;*&amp;quot;</span>
<span class="c">#                            ],</span>
<span class="c">#                            &amp;quot;routes&amp;quot;: [</span>
<span class="c">#                              {</span>
<span class="c">#                                &amp;quot;match&amp;quot;: {</span>
<span class="c">#                                  &amp;quot;prefix&amp;quot;: &amp;quot;/healthz/ready&amp;quot;</span>
<span class="c">#                                },</span>
<span class="c">#                                &amp;quot;route&amp;quot;: {</span>
<span class="c">#                                  &amp;quot;cluster&amp;quot;: &amp;quot;agent&amp;quot;</span>
<span class="c">#    ...</span>

<span class="nv">$ </span>more /etc/istio/proxy/grpc-bootstrap.json
<span class="c"># =&gt; {</span>
<span class="c">#      &amp;quot;xds_servers&amp;quot;: [</span>
<span class="c">#        {</span>
<span class="c">#          &amp;quot;server_uri&amp;quot;: &lt;span style="color: red;"&gt;&amp;quot;unix:///etc/istio/proxy/XDS&amp;quot;,&lt;/span&gt;</span>
<span class="c">#          ...</span>
<span class="c">#        }</span>
<span class="c">#      ],</span>
<span class="c">#      &amp;quot;node&amp;quot;: {</span>
<span class="c">#        &amp;quot;id&amp;quot;: &amp;quot;sidecar~172.16.1.13~deploy-websrv-778ffd6947-cxf5k.default~default.svc.cluster.local&amp;quot;,</span>
<span class="c">#        &amp;quot;metadata&amp;quot;: {</span>
<span class="c">#          &amp;quot;ANNOTATIONS&amp;quot;: {</span>
<span class="c">#            &amp;quot;istio.io/rev&amp;quot;: &amp;quot;default&amp;quot;,</span>
<span class="c">#            &amp;quot;kubectl.kubernetes.io/default-container&amp;quot;: &amp;quot;deploy-websrv&amp;quot;,</span>
<span class="c">#            &amp;quot;kubectl.kubernetes.io/default-logs-container&amp;quot;: &amp;quot;deploy-websrv&amp;quot;,</span>
<span class="c">#            ...</span>
<span class="c">#            &amp;quot;sidecar.istio.io/status&amp;quot;: &amp;quot;{\&amp;quot;initContainers\&amp;quot;:[\&amp;quot;istio-init\&amp;quot;],\&amp;quot;containers\&amp;quot;:[\&amp;quot;istio-proxy\&amp;quot;],\&amp;quot;volumes\&amp;quot;:[\&amp;quot;workload-socket\&amp;quot;,\&amp;quot;credential-socket\&amp;quot;,\&amp;quot;workload-certs\&amp;quot;</span>
<span class="c">#    ,\&amp;quot;istio-envoy\&amp;quot;,\&amp;quot;istio-data\&amp;quot;,\&amp;quot;istio-podinfo\&amp;quot;,\&amp;quot;istio-token\&amp;quot;,\&amp;quot;istiod-ca-cert\&amp;quot;],\&amp;quot;imagePullSecrets\&amp;quot;:null,\&amp;quot;revision\&amp;quot;:\&amp;quot;default\&amp;quot;}&amp;quot;</span>
<span class="c">#          },</span>
<span class="c">#          ...</span>
<span class="c">#          &amp;quot;SERVICE_ACCOUNT&amp;quot;: &amp;quot;kans-nginx&amp;quot;,</span>
<span class="c">#          &amp;quot;WORKLOAD_NAME&amp;quot;: &amp;quot;deploy-websrv&amp;quot;</span>
<span class="c">#        },</span>
<span class="c">#        &amp;quot;locality&amp;quot;: {},</span>
<span class="c">#        &amp;quot;UserAgentVersionType&amp;quot;: null</span>
<span class="c">#      },</span>
<span class="c">#      &amp;quot;server_listener_resource_name_template&amp;quot;: &amp;quot;xds.istio.io/grpc/lds/inbound/%s&amp;quot;</span>
<span class="c">#    }</span>

<span class="c"># display only Unix domain sockets : Listener 과 ESTAB 상태 정보 확인</span>
<span class="nv">$ </span>ss <span class="nt">-xpl</span>
<span class="c"># =&gt; Netid State  Recv-Q Send-Q                              Local Address:Port  Peer Address:PortProcess</span>
<span class="c">#    u_str LISTEN 0      4096                          etc/istio/proxy/XDS 54694            * 0    users:((&amp;quot;pilot-agent&amp;quot;,pid=1,fd=11))</span>
<span class="c">#    u_str LISTEN 0      4096   var/run/secrets/workload-spiffe-uds/socket 54693            * 0    users:((&amp;quot;pilot-agent&amp;quot;,pid=1,fd=9))</span>
<span class="nv">$ </span>ss <span class="nt">-xp</span>
<span class="c"># =&gt; Netid State Recv-Q Send-Q                              Local Address:Port  Peer Address:Port Process</span>
<span class="c">#    u_str ESTAB 0      0                             etc/istio/proxy/XDS 79304            * 82228 users:((&amp;quot;pilot-agent&amp;quot;,pid=1,fd=10))</span>
<span class="c">#    u_str ESTAB 0      0      var/run/secrets/workload-spiffe-uds/socket 54709            * 54162 users:((&amp;quot;pilot-agent&amp;quot;,pid=1,fd=16))</span>
<span class="c">#    u_str ESTAB 0      0                                               * 82228            * 79304 users:((&amp;quot;envoy&amp;quot;,pid=13,fd=19))</span>
<span class="c">#    u_str ESTAB 0      0                                               * 54162            * 54709 users:((&amp;quot;envoy&amp;quot;,pid=13,fd=32))</span>

<span class="c"># display only TCP sockets and display only IP version 4 sockets : TCP 상태 정보 확인</span>
<span class="nv">$ </span>ss <span class="nt">-4tpl</span>
<span class="c"># =&gt; LISTEN 0      4096         0.0.0.0:15090      0.0.0.0:*    users:((&amp;quot;envoy&amp;quot;,pid=13,fd=21))</span>
<span class="c">#    LISTEN 0      4096         0.0.0.0:15090      0.0.0.0:*    users:((&amp;quot;envoy&amp;quot;,pid=13,fd=20))</span>
<span class="c">#    LISTEN 0      4096         0.0.0.0:15021      0.0.0.0:*    users:((&amp;quot;envoy&amp;quot;,pid=13,fd=23))</span>
<span class="c">#    LISTEN 0      4096         0.0.0.0:15021      0.0.0.0:*    users:((&amp;quot;envoy&amp;quot;,pid=13,fd=22))</span>
<span class="c">#    LISTEN 0      4096         0.0.0.0:15001      0.0.0.0:*    users:((&amp;quot;envoy&amp;quot;,pid=13,fd=35))</span>
<span class="c">#    LISTEN 0      4096         0.0.0.0:15001      0.0.0.0:*    users:((&amp;quot;envoy&amp;quot;,pid=13,fd=34))</span>
<span class="c">#    LISTEN 0      4096         0.0.0.0:15006      0.0.0.0:*    users:((&amp;quot;envoy&amp;quot;,pid=13,fd=37))</span>
<span class="c">#    LISTEN 0      4096         0.0.0.0:15006      0.0.0.0:*    users:((&amp;quot;envoy&amp;quot;,pid=13,fd=36))</span>
<span class="c">#    LISTEN 0      4096       127.0.0.1:15000      0.0.0.0:*    users:((&amp;quot;envoy&amp;quot;,pid=13,fd=18))</span>
<span class="c">#    LISTEN 0      4096       127.0.0.1:15004      0.0.0.0:*    users:((&amp;quot;pilot-agent&amp;quot;,pid=1,fd=13))</span>
<span class="c">#    LISTEN 0      511          0.0.0.0:http       0.0.0.0:*</span>
</code></pre></div></div>

<h3 id="bookinfo-실습-및-istio-기능-확인">Bookinfo 실습 및 Istio 기능 확인</h3>

<h4 id="bookinfo">Bookinfo</h4>

<ul>
  <li>Bookinfo는 istio의 기능을 설명하기위한 MSA(Microservices Architecture)  기반의 예제 어플리케이션입니다.
<img src="/assets/2024/kans-3th/w7/20241019_kans_w7_11.png" alt="img.png" class="image-center" />
<em class="image-caption">Bookinfo 어플리케이션 구성</em>
    <ul>
      <li>productpage, details, reviews, ratings 서비스로 구성됩니다. <a href="https://istio.io/latest/docs/examples/bookinfo/">소개 링크</a></li>
      <li><strong>ProductPage</strong> 페이지에서 요청을 받으면, 도서 리뷰를 보여주는 <strong>Reviews</strong> 서비스와 도서 상세 정보를 보여주는 <strong>Details</strong> 서비스에 접속하고,</li>
      <li>ProductPage 는 <strong>Reviews</strong> 와 <strong>Details</strong> 결과를 사용자에게 응답합니다.</li>
      <li><strong>Reviews</strong> 서비스는 v1, v2, v3 세 개의 버전이 있고 v2, v3 버전의 경우 <strong>Ratings</strong> 서비스에 접소갛여 도서에 대한 5단계 평가를 가져옵니다.</li>
      <li>Reviews 서비스의 차이는, v1은 Rating 이 <strong>없고</strong>, v2는 <strong>검은색</strong> 별로 Ratings 가 표시되며, v3는 <strong>색깔이</strong> 있는 별로 Ratings 가 표시됩니다.</li>
    </ul>
  </li>
  <li>설치 및 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 모니터링</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> <span class="s1">'kubectl get pod -owide;echo;kubectl get svc'</span>

<span class="c"># Bookinfo 애플리케이션 배포</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$ISTIOV</span>
<span class="c"># =&gt; 1.23.2</span>
<span class="nv">$ </span><span class="nb">cat</span> ~/istio-<span class="nv">$ISTIOV</span>/samples/bookinfo/platform/kube/bookinfo.yaml
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> ~/istio-<span class="nv">$ISTIOV</span>/samples/bookinfo/platform/kube/bookinfo.yaml
<span class="c"># =&gt; service/details created</span>
<span class="c">#    serviceaccount/bookinfo-details created</span>
<span class="c">#    deployment.apps/details-v1 created</span>
<span class="c">#    service/ratings created</span>
<span class="c">#    serviceaccount/bookinfo-ratings created</span>
<span class="c">#    deployment.apps/ratings-v1 created</span>
<span class="c">#    service/reviews created</span>
<span class="c">#    serviceaccount/bookinfo-reviews created</span>
<span class="c">#    deployment.apps/reviews-v1 created</span>
<span class="c">#    deployment.apps/reviews-v2 created</span>
<span class="c">#    deployment.apps/reviews-v3 created</span>
<span class="c">#    service/productpage created</span>
<span class="c">#    serviceaccount/bookinfo-productpage created</span>
<span class="c">#    deployment.apps/productpage-v1 created</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get all,sa
<span class="c"># =&gt; NAME                                 READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/details-v1-65cfcf56f9-8465x      2/2     Running   0          87s</span>
<span class="c">#    pod/productpage-v1-d5789fdfb-f8gdf   2/2     Running   0          86s</span>
<span class="c">#    pod/ratings-v1-7c9bd4b87f-s9gxs      2/2     Running   0          87s</span>
<span class="c">#    pod/reviews-v1-6584ddcf65-gnc9j      2/2     Running   0          87s</span>
<span class="c">#    pod/reviews-v2-6f85cb9b7c-cfc68      2/2     Running   0          87s</span>
<span class="c">#    pod/reviews-v3-6f5b775685-cw7tc      2/2     Running   0          87s</span>
<span class="c">#    </span>
<span class="c">#    NAME                    TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE</span>
<span class="c">#    service/details         ClusterIP   10.10.200.54    &amp;lt;none&amp;gt;        9080/TCP   87s</span>
<span class="c">#    service/productpage     ClusterIP   10.10.200.184   &amp;lt;none&amp;gt;        9080/TCP   87s</span>
<span class="c">#    service/ratings         ClusterIP   10.10.200.163   &amp;lt;none&amp;gt;        9080/TCP   87s</span>
<span class="c">#    service/reviews         ClusterIP   10.10.200.214   &amp;lt;none&amp;gt;        9080/TCP   87s</span>
<span class="c">#    </span>
<span class="c">#    NAME                             READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/details-v1       1/1     1            1           87s</span>
<span class="c">#    deployment.apps/productpage-v1   1/1     1            1           86s</span>
<span class="c">#    deployment.apps/ratings-v1       1/1     1            1           87s</span>
<span class="c">#    deployment.apps/reviews-v1       1/1     1            1           87s</span>
<span class="c">#    deployment.apps/reviews-v2       1/1     1            1           87s</span>
<span class="c">#    deployment.apps/reviews-v3       1/1     1            1           87s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                       DESIRED   CURRENT   READY   AGE</span>
<span class="c">#    replicaset.apps/details-v1-65cfcf56f9      1         1         1       87s</span>
<span class="c">#    replicaset.apps/productpage-v1-d5789fdfb   1         1         1       86s</span>
<span class="c">#    replicaset.apps/ratings-v1-7c9bd4b87f      1         1         1       87s</span>
<span class="c">#    replicaset.apps/reviews-v1-6584ddcf65      1         1         1       87s</span>
<span class="c">#    replicaset.apps/reviews-v2-6f85cb9b7c      1         1         1       87s</span>
<span class="c">#    replicaset.apps/reviews-v3-6f5b775685      1         1         1       87s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                  SECRETS   AGE</span>
<span class="c">#    serviceaccount/bookinfo-details       0         87s</span>
<span class="c">#    serviceaccount/bookinfo-productpage   0         86s</span>
<span class="c">#    serviceaccount/bookinfo-ratings       0         87s</span>
<span class="c">#    serviceaccount/bookinfo-reviews       0         87s</span>

<span class="c"># product 웹 접속 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="s2">"</span><span class="si">$(</span>kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>ratings <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span><span class="s2">"</span> <span class="nt">-c</span> ratings <span class="nt">--</span> curl <span class="nt">-sS</span> productpage:9080/productpage | <span class="nb">grep</span> <span class="nt">-o</span> <span class="s2">"&lt;title&gt;.*&lt;/title&gt;"</span>
<span class="c"># =&gt; &amp;lt;title&amp;gt;Simple Bookstore App&amp;lt;/title&amp;gt;</span>

<span class="c"># 로그</span>
<span class="nv">$ </span>kubetail <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>productpage <span class="nt">-f</span>
</code></pre></div></div>

<h4 id="istio를-통한-인입-기본-설정">Istio를 통한 인입 기본 설정</h4>

<h5 id="istio-gatewayvirtualservice-설정">Istio Gateway/VirtualService 설정</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Istio Gateway/VirtualService 설정</span>
<span class="nv">$ </span><span class="nb">cat</span> ~/istio-<span class="nv">$ISTIOV</span>/samples/bookinfo/networking/bookinfo-gateway.yaml
<span class="c"># =&gt; apiVersion: networking.istio.io/v1alpha3</span>
<span class="c">#    kind: Gateway</span>
<span class="c">#    metadata:</span>
<span class="c">#      name: bookinfo-gateway</span>
<span class="c">#    spec:</span>
<span class="c">#      # The selector matches the ingress gateway pod labels.</span>
<span class="c">#      # If you installed Istio using Helm following the standard documentation, this would be &amp;quot;istio=ingress&amp;quot;</span>
<span class="c">#      selector:</span>
<span class="c">#        istio: ingressgateway # use istio default controller</span>
<span class="c">#      servers:</span>
<span class="c">#      - port:</span>
<span class="c">#          number: 8080</span>
<span class="c">#          name: http</span>
<span class="c">#          protocol: HTTP</span>
<span class="c">#        hosts:</span>
<span class="c">#        - &amp;quot;*&amp;quot;</span>
<span class="c">#    ---</span>
<span class="c">#    apiVersion: networking.istio.io/v1alpha3</span>
<span class="c">#    kind: VirtualService</span>
<span class="c">#    metadata:</span>
<span class="c">#      name: bookinfo</span>
<span class="c">#    spec:</span>
<span class="c">#      hosts:</span>
<span class="c">#      - &amp;quot;*&amp;quot;</span>
<span class="c">#      gateways:</span>
<span class="c">#      - bookinfo-gateway</span>
<span class="c">#      http:</span>
<span class="c">#      - match:</span>
<span class="c">#        - uri:</span>
<span class="c">#            exact: /productpage</span>
<span class="c">#        - uri:</span>
<span class="c">#            prefix: /static</span>
<span class="c">#        - uri:</span>
<span class="c">#            exact: /login</span>
<span class="c">#        - uri:</span>
<span class="c">#            exact: /logout</span>
<span class="c">#        - uri:</span>
<span class="c">#            prefix: /api/v1/products</span>
<span class="c">#        route:</span>
<span class="c">#        - destination:</span>
<span class="c">#            host: productpage</span>
<span class="c">#            port:</span>
<span class="c">#              number: 9080</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> ~/istio-<span class="nv">$ISTIOV</span>/samples/bookinfo/networking/bookinfo-gateway.yaml
<span class="c"># =&gt; gateway.networking.istio.io/bookinfo-gateway created</span>
<span class="c">#    virtualservice.networking.istio.io/bookinfo created</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get gw,vs
<span class="nv">$ </span>istioctl proxy-status
<span class="c"># =&gt; NAME                                                   CLUSTER        CDS                LDS                EDS                RDS                ECDS        ISTIOD                      VERSION</span>
<span class="c">#    deploy-websrv-778ffd6947-cxf5k.default                 Kubernetes     SYNCED (5m9s)      SYNCED (5m9s)      SYNCED (4m24s)     SYNCED (5m9s)      IGNORED     istiod-7f8b586864-8mc4c     1.23.2</span>
<span class="c">#    details-v1-65cfcf56f9-8465x.default                    Kubernetes     SYNCED (4m43s)     SYNCED (4m43s)     SYNCED (4m24s)     SYNCED (4m43s)     IGNORED     istiod-7f8b586864-8mc4c     1.23.2</span>
<span class="c">#    istio-ingressgateway-5f9f654d46-l7mqp.istio-system     Kubernetes     SYNCED (10s)       SYNCED (10s)       SYNCED (4m24s)     SYNCED (10s)       IGNORED     istiod-7f8b586864-8mc4c     1.23.2</span>
<span class="c">#    productpage-v1-d5789fdfb-f8gdf.default                 Kubernetes     SYNCED (4m53s)     SYNCED (4m53s)     SYNCED (4m24s)     SYNCED (4m53s)     IGNORED     istiod-7f8b586864-8mc4c     1.23.2</span>
<span class="c">#    ratings-v1-7c9bd4b87f-s9gxs.default                    Kubernetes     SYNCED (4m24s)     SYNCED (4m24s)     SYNCED (4m24s)     SYNCED (4m24s)     IGNORED     istiod-7f8b586864-8mc4c     1.23.2</span>
<span class="c">#    reviews-v1-6584ddcf65-gnc9j.default                    Kubernetes     SYNCED (4m47s)     SYNCED (4m47s)     SYNCED (4m24s)     SYNCED (4m47s)     IGNORED     istiod-7f8b586864-8mc4c     1.23.2</span>
<span class="c">#    reviews-v2-6f85cb9b7c-cfc68.default                    Kubernetes     SYNCED (4m41s)     SYNCED (4m41s)     SYNCED (4m24s)     SYNCED (4m41s)     IGNORED     istiod-7f8b586864-8mc4c     1.23.2</span>
<span class="c">#    reviews-v3-6f5b775685-cw7tc.default                    Kubernetes     SYNCED (4m43s)     SYNCED (4m43s)     SYNCED (4m24s)     SYNCED (4m43s)     IGNORED     istiod-7f8b586864-8mc4c     1.23.2</span>

<span class="c"># productpage 파드의 istio-proxy 로그 확인 Access log 가 출력 - Default access log format : 링크</span>
<span class="nv">$ </span>kubetail <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>productpage <span class="nt">-c</span> istio-proxy <span class="nt">-f</span>
</code></pre></div></div>

<ul>
  <li><strong>k3s-m</strong> NodePort 접속 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">IGWHTTP</span><span class="o">=</span><span class="si">$(</span>kubectl get service <span class="nt">-n</span> istio-system istio-ingressgateway <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.spec.ports[1].nodePort}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$IGWHTTP</span>
<span class="c"># =&gt; 31677</span>

<span class="c"># 접속 확인</span>
<span class="nv">$ </span>kubectl get svc <span class="nt">-n</span> istio-system istio-ingressgateway
<span class="c"># =&gt; NAME                   TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)                                                                      AGE</span>
<span class="c">#    istio-ingressgateway   NodePort   10.10.200.171   &amp;lt;none&amp;gt;        15021:30953/TCP,80:31677/TCP,443:30737/TCP,31400:30617/TCP,15443:31668/TCP   3h31m</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> http://localhost:<span class="nv">$IGWHTTP</span>/productpage
<span class="nv">$ </span>curl <span class="nt">-s</span> http://192.168.10.101:<span class="nv">$IGWHTTP</span>/productpage
<span class="nv">$ </span>curl <span class="nt">-s</span> http://192.168.10.102:<span class="nv">$IGWHTTP</span>/productpage
<span class="c"># =&gt; &amp;lt;meta charset=&amp;quot;utf-8&amp;quot;&amp;gt;</span>
<span class="c">#    &amp;lt;meta http-equiv=&amp;quot;X-UA-Compatible&amp;quot; content=&amp;quot;IE=edge&amp;quot;&amp;gt;</span>
<span class="c">#    &amp;lt;meta name=&amp;quot;viewport&amp;quot; content=&amp;quot;width=device-width, initial-scale=1.0&amp;quot;&amp;gt;</span>
<span class="c">#    </span>
<span class="c">#    &amp;lt;title&amp;gt;Simple Bookstore App&amp;lt;/title&amp;gt;</span>
<span class="c">#    ...</span>

<span class="c"># 정보 확인</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$MYDOMAIN</span>
<span class="c"># =&gt; sweetlittlebird.com</span>
<span class="nv">$ </span><span class="nb">cat</span> /etc/hosts
<span class="c"># =&gt; ...</span>
<span class="c">#    127.0.2.1 k3s-m k3s-m</span>
<span class="c">#    192.168.10.10 k3s-m</span>
<span class="c">#    192.168.10.101 k3s-w1</span>
<span class="c">#    192.168.10.102 k3s-w2</span>
<span class="c">#    192.168.10.103 k3s-w3</span>
<span class="c">#    192.168.10.10 sweetlittlebird.com</span>

<span class="c">#</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> http://<span class="nv">$MYDOMAIN</span>:<span class="nv">$IGWHTTP</span>/productpage
<span class="c"># =&gt; &amp;lt;meta charset=&amp;quot;utf-8&amp;quot;&amp;gt;</span>
<span class="c">#    &amp;lt;meta http-equiv=&amp;quot;X-UA-Compatible&amp;quot; content=&amp;quot;IE=edge&amp;quot;&amp;gt;</span>
<span class="c">#    &amp;lt;meta name=&amp;quot;viewport&amp;quot; content=&amp;quot;width=device-width, initial-scale=1.0&amp;quot;&amp;gt;</span>
<span class="c">#    </span>
<span class="c">#    &amp;lt;title&amp;gt;Simple Bookstore App&amp;lt;/title&amp;gt;</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<ul>
  <li>자신의 PC에서 접속 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$MYDOMAIN</span> <span class="nv">$IGWHTTP</span>
<span class="c"># =&gt; sweetlittlebird.com 31677</span>
<span class="nv">$ </span><span class="nb">cat</span> /etc/hosts

<span class="c">#</span>
<span class="nv">$ </span>curl <span class="nt">-v</span> <span class="nt">-s</span> <span class="nv">$MYDOMAIN</span>:<span class="nv">$IGWHTTP</span>/productpage
</code></pre></div></div>

<p><img src="/assets/2024/kans-3th/w7/20241019_kans_w7_12.png" alt="img.png" class="image-center" />
<em class="image-caption">Bookinfo 접속 결과 - 새로고침 할 때 마다 다른 파드에 접속되면서 리뷰가 달라짐</em></p>

<ul>
  <li><strong>testpc 에서 접속 실행</strong></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># istio ingress gw 를 통한 접속 테스트</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$MYDOMAIN</span>:<span class="nv">$IGWHTTP</span>/productpage | <span class="nb">grep</span> <span class="nt">-o</span> <span class="s2">"&lt;title&gt;.*&lt;/title&gt;"</span>
<span class="c"># =&gt; &amp;lt;title&amp;gt;Simple Bookstore App&amp;lt;/title&amp;gt;</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$MYDOMAIN</span>:<span class="nv">$IGWHTTP</span>/productpage | <span class="nb">grep</span> <span class="nt">-o</span> <span class="s2">"&lt;title&gt;.*&lt;/title&gt;"</span> <span class="p">;</span> <span class="nb">echo</span> <span class="s2">"--------------"</span> <span class="p">;</span> <span class="nb">sleep </span>1<span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;lt;title&amp;gt;Simple Bookstore App&amp;lt;/title&amp;gt;</span>
<span class="c">#    --------------</span>
<span class="c">#    &amp;lt;title&amp;gt;Simple Bookstore App&amp;lt;/title&amp;gt;</span>
<span class="c">#    --------------</span>
<span class="c">#    ...</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span>  <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$MYDOMAIN</span>:<span class="nv">$IGWHTTP</span>/productpage | <span class="nb">grep</span> <span class="nt">-o</span> <span class="s2">"&lt;title&gt;.*&lt;/title&gt;"</span> <span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;lt;title&amp;gt;Simple Bookstore App&amp;lt;/title&amp;gt;</span>
<span class="c">#    &amp;lt;title&amp;gt;Simple Bookstore App&amp;lt;/title&amp;gt;</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<h4 id="모니터링">모니터링</h4>

<ul>
  <li>옵저빌리티 연동 문서 : <a href="https://istio.io/latest/docs/ops/integrations/">링크</a></li>
</ul>

<h5 id="kiali-키알리-소개">Kiali (키알리) 소개</h5>

<ul>
  <li>Kiali는 Istio 서비스 메시의 모니터링 및 시각화 도구입니다.</li>
  <li>주 데이터 소스는 Prometheus와 Jaeger 등입니다.</li>
  <li>특히 Jaeger와 연동하여 서비스 간의 호출 관계를 시각화하여 볼 수 있습니다.</li>
  <li>Istiod의 health 상태를 확인하기 위해 istiod 파드를 직접 접속합니다. (기본 15014포트)</li>
</ul>

<h5 id="kiali-설치-및-확인">Kiali 설치 및 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Install Kiali and the other addons and wait for them to be deployed. : Kiali dashboard, along with Prometheus, Grafana, and Jaeger.</span>
<span class="nv">$ </span>tree ~/istio-<span class="nv">$ISTIOV</span>/samples/addons/
<span class="c"># =&gt; /root/istio-1.23.2/samples/addons/</span>
<span class="c">#    ├── README.md</span>
<span class="c">#    ├── extras</span>
<span class="c">#    │   ├── prometheus-operator.yaml</span>
<span class="c">#    │   ├── skywalking.yaml</span>
<span class="c">#    │   └── zipkin.yaml</span>
<span class="c">#    ├── grafana.yaml</span>
<span class="c">#    ├── jaeger.yaml</span>
<span class="c">#    ├── kiali.yaml</span>
<span class="c">#    ├── loki.yaml</span>
<span class="c">#    └── prometheus.yaml</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> ~/istio-<span class="nv">$ISTIOV</span>/samples/addons <span class="c"># 디렉터리에 있는 모든 yaml 자원을 생성</span>
<span class="c"># =&gt; deployment.apps/grafana created</span>
<span class="c">#    deployment.apps/jaeger created</span>
<span class="c">#    deployment.apps/kiali created</span>
<span class="c">#    deployment.apps/prometheus created</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>kubectl rollout status deployment/kiali <span class="nt">-n</span> istio-system
<span class="c"># =&gt; deployment &amp;quot;kiali&amp;quot; successfully rolled out</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get all,sa,cm <span class="nt">-n</span> istio-system
<span class="nv">$ </span>kubectl get svc,ep <span class="nt">-n</span> istio-system
<span class="c"># =&gt; NAME                           TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                                                                      AGE</span>
<span class="c">#    service/grafana                ClusterIP   10.10.200.178   &amp;lt;none&amp;gt;        3000/TCP                                                                     69s</span>
<span class="c">#    service/istio-ingressgateway   NodePort    10.10.200.171   &amp;lt;none&amp;gt;        15021:30953/TCP,80:31677/TCP,443:30737/TCP,31400:30617/TCP,15443:31668/TCP   5h48m</span>
<span class="c">#    service/istiod                 ClusterIP   10.10.200.215   &amp;lt;none&amp;gt;        15010/TCP,15012/TCP,443/TCP,15014/TCP                                        5h48m</span>
<span class="c">#    service/jaeger-collector       ClusterIP   10.10.200.121   &amp;lt;none&amp;gt;        14268/TCP,14250/TCP,9411/TCP,4317/TCP,4318/TCP                               69s</span>
<span class="c">#    service/kiali                  ClusterIP   10.10.200.19    &amp;lt;none&amp;gt;        20001/TCP,9090/TCP                                                           68s</span>
<span class="c">#    service/loki                   ClusterIP   10.10.200.227   &amp;lt;none&amp;gt;        3100/TCP,9095/TCP                                                            68s</span>
<span class="c">#    service/loki-headless          ClusterIP   None            &amp;lt;none&amp;gt;        3100/TCP                                                                     68s</span>
<span class="c">#    service/loki-memberlist        ClusterIP   None            &amp;lt;none&amp;gt;        7946/TCP                                                                     68s</span>
<span class="c">#    service/prometheus             ClusterIP   10.10.200.148   &amp;lt;none&amp;gt;        9090/TCP                                                                     68s</span>
<span class="c">#    service/tracing                ClusterIP   10.10.200.133   &amp;lt;none&amp;gt;        80/TCP,16685/TCP                                                             69s</span>
<span class="c">#    service/zipkin                 ClusterIP   10.10.200.29    &amp;lt;none&amp;gt;        9411/TCP                                                                     69s</span>
<span class="c">#    </span>
<span class="c">#    NAME                             ENDPOINTS                                                           AGE</span>
<span class="c">#    endpoints/grafana                172.16.2.17:3000                                                    69s</span>
<span class="c">#    endpoints/istio-ingressgateway   172.16.2.14:15443,172.16.2.14:15021,172.16.2.14:31400 + 2 more...   5h48m</span>
<span class="c">#    endpoints/istiod                 172.16.3.16:15012,172.16.3.16:15010,172.16.3.16:15017 + 1 more...   5h48m</span>
<span class="c">#    endpoints/jaeger-collector       172.16.3.19:9411,172.16.3.19:14250,172.16.3.19:4317 + 2 more...     69s</span>
<span class="c">#    endpoints/kiali                  172.16.1.16:9090,172.16.1.16:20001                                  68s</span>
<span class="c">#    endpoints/loki                                                                                       68s</span>
<span class="c">#    endpoints/loki-headless                                                                              68s</span>
<span class="c">#    endpoints/loki-memberlist                                                                            68s</span>
<span class="c">#    endpoints/prometheus             172.16.3.20:9090                                                    67s</span>
<span class="c">#    endpoints/tracing                172.16.3.19:16685,172.16.3.19:16686                                 69s</span>
<span class="c">#    endpoints/zipkin                 172.16.3.19:9411                                                    69s</span>

<span class="c"># kiali 서비스 변경</span>
<span class="nv">$ </span>kubectl patch svc <span class="nt">-n</span> istio-system kiali <span class="nt">-p</span> <span class="s1">'{"spec":{"type":"NodePort"}}'</span>
<span class="c"># =&gt; service/kiali patched</span>

<span class="c"># kiali 웹 접속 주소 확인</span>
<span class="nv">$ KIALINodePort</span><span class="o">=</span><span class="si">$(</span>kubectl get svc <span class="nt">-n</span> istio-system kiali <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.spec.ports[0].nodePort<span class="o">}</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"KIALI UI URL = http://</span><span class="si">$(</span>curl <span class="nt">-s</span> ipinfo.io/ip<span class="si">)</span><span class="s2">:</span><span class="nv">$KIALINodePort</span><span class="s2">"</span>
<span class="c"># =&gt; KIALI UI URL = http://54.123.42.212:31274</span>

<span class="c"># Grafana 서비스 변경</span>
<span class="nv">$ </span>kubectl patch svc <span class="nt">-n</span> istio-system grafana <span class="nt">-p</span> <span class="s1">'{"spec":{"type":"NodePort"}}'</span>
<span class="c"># =&gt; service/grafana patched</span>

<span class="c"># Grafana 웹 접속 주소 확인 : 7개의 대시보드</span>
<span class="nv">$ GRAFANANodePort</span><span class="o">=</span><span class="si">$(</span>kubectl get svc <span class="nt">-n</span> istio-system grafana <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.spec.ports[0].nodePort<span class="o">}</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"Grafana URL = http://</span><span class="si">$(</span>curl <span class="nt">-s</span> ipinfo.io/ip<span class="si">)</span><span class="s2">:</span><span class="nv">$GRAFANANodePort</span><span class="s2">"</span>
<span class="c"># =&gt; Grafana URL = http://54.123.42.212:30266</span>

<span class="c"># Prometheus 서비스 변경</span>
<span class="nv">$ </span>kubectl patch svc <span class="nt">-n</span> istio-system prometheus <span class="nt">-p</span> <span class="s1">'{"spec":{"type":"NodePort"}}'</span>
<span class="c"># =&gt; service/prometheus patched</span>

<span class="c"># Prometheus 웹 접속 주소 확인</span>
<span class="nv">$ PROMENodePort</span><span class="o">=</span><span class="si">$(</span>kubectl get svc <span class="nt">-n</span> istio-system prometheus <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.spec.ports[0].nodePort<span class="o">}</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"Prometheus URL = http://</span><span class="si">$(</span>curl <span class="nt">-s</span> ipinfo.io/ip<span class="si">)</span><span class="s2">:</span><span class="nv">$PROMENodePort</span><span class="s2">"</span>
<span class="c"># =&gt; Prometheus URL = http://54.123.42.212:30506</span>
</code></pre></div></div>

<ul>
  <li>Prometheus : Targets - 파드별로 tcp/15020의 /stats/prometheus를 통해 수집</li>
</ul>

<p><img src="/assets/2024/kans-3th/w7/20241019_kans_w7_13.png" alt="img.png" class="image-center" /></p>

<p><img src="/assets/2024/kans-3th/w7/20241019_kans_w7_14.png" alt="img.png" class="image-center" /></p>

<p><img src="/assets/2024/kans-3th/w7/20241019_kans_w7_15.png" alt="img.png" class="image-center" /></p>

<ul>
  <li>Grafana : 7개의 대시보드</li>
</ul>

<p><img src="/assets/2024/kans-3th/w7/20241019_kans_w7_17.png" alt="img.png" class="image-center" /></p>

<p><img src="/assets/2024/kans-3th/w7/20241019_kans_w7_16.png" alt="img.png" class="image-center" /></p>

<ul>
  <li>Kiali : 서비스간의 호출 관계를 시각화</li>
</ul>

<p><img src="/assets/2024/kans-3th/w7/20241019_kans_w7_18.png" alt="img.png" class="image-center" /></p>

<h5 id="kiali-키알리-대시보드-둘러보기">Kiali (키알리) 대시보드 둘러보기</h5>

<ul>
  <li>Namespace 를 default 로 선택 후 Graph (Traffic, Versioned app graph) 에서 Display 옵션 중 ‘Traffic Distribution’과
‘Traffic Animation’ 활성화, Security 체크 해서 확인해보겠습니다.</li>
  <li>트래픽을 발생시켜서 Kiali 대시보드를 확인해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># testpc 에서 아래 실행</span>
<span class="c"># 반복 접속 테스트</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$MYDOMAIN</span>:<span class="nv">$IGWHTTP</span>/productpage | <span class="nb">grep</span> <span class="nt">-o</span> <span class="s2">"&lt;title&gt;.*&lt;/title&gt;"</span> <span class="p">;</span> <span class="nb">echo</span> <span class="s2">"--------------"</span> <span class="p">;</span> <span class="nb">sleep </span>1<span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$MYDOMAIN</span>:<span class="nv">$IGWHTTP</span>/productpage | <span class="nb">grep</span> <span class="nt">-o</span> <span class="s2">"&lt;title&gt;.*&lt;/title&gt;"</span> <span class="p">;</span> <span class="nb">echo</span> <span class="s2">"--------------"</span> <span class="p">;</span> <span class="nb">sleep </span>0.1<span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$MYDOMAIN</span>:<span class="nv">$IGWHTTP</span>/productpage | <span class="nb">grep</span> <span class="nt">-o</span> <span class="s2">"&lt;title&gt;.*&lt;/title&gt;"</span> <span class="p">;</span> <span class="nb">echo</span> <span class="s2">"--------------"</span> <span class="p">;</span> <span class="nb">sleep </span>0.5<span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span>  <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$MYDOMAIN</span>:<span class="nv">$IGWHTTP</span>/productpage | <span class="nb">grep</span> <span class="nt">-o</span> <span class="s2">"&lt;title&gt;.*&lt;/title&gt;"</span> <span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..1000<span class="o">}</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$MYDOMAIN</span>:<span class="nv">$IGWHTTP</span>/productpage | <span class="nb">grep</span> <span class="nt">-o</span> <span class="s2">"&lt;title&gt;.*&lt;/title&gt;"</span> <span class="p">;</span> <span class="k">done</span>
</code></pre></div></div>

<ul>
  <li><strong>Traffic Graph</strong>에서는 트래픽 흐름을 확인할 수 있습니다.</li>
</ul>

<p><img src="/assets/2024/kans-3th/w7/20241019_kans_w7_19.png" alt="img.png" class="image-center" /></p>

<ul>
  <li><strong>Workloads</strong>에서는 Log 등을 확인할 수 있고, Envoy 관련 설정 정보(Listener, Cluster, Route, Endpoint 등)를 확인할 수 있습니다.</li>
</ul>

<p><img src="/assets/2024/kans-3th/w7/20241019_kans_w7_20.png" alt="img.png" class="image-center" /></p>

<ul>
  <li><strong>Istio Config</strong>에서 Istio 관련 설정을 볼 수 있고, <strong>Action</strong> 으로 Istio 관련 오브젝트를 설정/삭제 할 수 있습니다.</li>
</ul>

<h4 id="traffic-management">Traffic Management</h4>

<ul>
  <li><strong>동작 소개</strong> : 클라이언트 PC → Istio <strong>ingressgateway</strong> 파드 → (Gateway, <strong>VirtualService</strong> + <strong>DestinationRule</strong>) → Cluster(<strong>Endpoint</strong> - 파드)
    <ul>
      <li><strong>Gateway</strong> : 지정한 인그레스 게이트웨이로부터 트래픽이 인입, 프로토콜 및 포트, HOSTS, Proxy 등 설정이 가능합니다.</li>
      <li><strong>VirtualService</strong> : 인입 처리할 hosts 설정, L7 PATH 별 라우팅, 목적지에 대한 정책 설정 가능합니다. (envoy route config) - <a href="https://istio.io/latest/docs/concepts/traffic-management/#virtual-services">링크</a>
        <ul>
          <li>VirtualService 는 DestinationRule 에서 설정된 <strong>서브셋(subset)</strong>을 사용하여 <strong>트래픽 컨트롤</strong>을 할 수 있습니다.</li>
          <li><strong>hosts 필드</strong> : 목적지 주소 - IP address, a DNS name (FQDN), 혹은 k8s svc 이름, wildcard (”*”) prefixes</li>
          <li><strong>Routing rules</strong> : HTTP 경우 - Match 필드(예) 헤더), Destination(istio/envoy 에 등록된 대상, subnet 에 DestinationRule 활용)
            <ul>
              <li><strong>HTTPRoute</strong> : redirect , rewrite , fault(장애 주입) , mirror(복제, 기본 100%) , corsPolicy(CORS 삽입) , headers(헤더 조작) 등 - <a href="https://istio.io/latest/docs/reference/config/networking/virtual-service/#HTTPRoute">링크</a></li>
            </ul>
          </li>
          <li>Routing rule precedence : Routing rules are evaluated in sequential order from top to bottom - 위에서 순차적 적용</li>
        </ul>
      </li>
      <li>DestinationRule : 실제 도착지(서비스와 1:1 연결)의 정교한 정책(부하분산, 연결 옵션, 서킷 브레이크, TLS 등)을 설정 - <a href="https://istio.io/latest/docs/concepts/traffic-management/#destination-rules">링크</a>
        <ul>
          <li><strong>Load balancing options</strong> : Round robin(기본값) , Random , Weighted , Least requests - <a href="https://www.envoyproxy.io/docs/envoy/v1.5.0/intro/arch_overview/load_balancing">링크</a>
            <ul>
              <li><strong>Destination Rule</strong> : TrafficPolicy , Subset , ConnectionPoolSettings 등 - <a href="https://istio.io/latest/docs/reference/config/networking/destination-rule/">링크</a></li>
              <li>서브셋(subsets)을 정의할 수 있어 마이크로서비스 <strong>버전별로 라우팅</strong>할 때 사용한다</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h5 id="request-routing-실습">Request Routing 실습</h5>

<ul>
  <li>실습전 기본 DestinationRule 적용</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 샘플 파일들 확인</span>
<span class="nv">$ </span>tree ~/istio-<span class="nv">$ISTIOV</span>/samples/bookinfo/networking
<span class="c"># =&gt; /root/istio-1.23.2/samples/bookinfo/networking</span>
<span class="c">#    ├── bookinfo-gateway.yaml</span>
<span class="c">#    ├── certmanager-gateway.yaml</span>
<span class="c">#    ├── destination-rule-all-mtls.yaml</span>
<span class="c">#    ├── destination-rule-all.yaml</span>
<span class="c">#    ├── destination-rule-reviews.yaml</span>
<span class="c">#    ├── egress-rule-google-apis.yaml</span>
<span class="c">#    ├── fault-injection-details-v1.yaml</span>
<span class="c">#    ├── virtual-service-all-v1.yaml</span>
<span class="c">#    ├── virtual-service-details-v2.yaml</span>
<span class="c">#    ├── virtual-service-ratings-db.yaml</span>
<span class="c">#    ├── virtual-service-ratings-mysql-vm.yaml</span>
<span class="c">#    ├── virtual-service-ratings-mysql.yaml</span>
<span class="c">#    ├── virtual-service-ratings-test-abort.yaml</span>
<span class="c">#    ├── virtual-service-ratings-test-delay.yaml</span>
<span class="c">#    ├── virtual-service-reviews-50-v3.yaml</span>
<span class="c">#    ├── virtual-service-reviews-80-20.yaml</span>
<span class="c">#    ├── virtual-service-reviews-90-10.yaml</span>
<span class="c">#    ├── virtual-service-reviews-jason-v2-v3.yaml</span>
<span class="c">#    ├── virtual-service-reviews-test-v2.yaml</span>
<span class="c">#    ├── virtual-service-reviews-v2-v3.yaml</span>
<span class="c">#    └── virtual-service-reviews-v3.yaml</span>

<span class="c"># 기본 DestinationRule 적용</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> ~/istio-<span class="nv">$ISTIOV</span>/samples/bookinfo/networking/destination-rule-all.yaml
<span class="c"># =&gt; destinationrule.networking.istio.io/productpage created</span>
<span class="c">#    destinationrule.networking.istio.io/reviews created</span>
<span class="c">#    destinationrule.networking.istio.io/ratings created</span>
<span class="c">#    destinationrule.networking.istio.io/details created</span>

<span class="c"># DestinationRule 확인 dr(=destinationrules) : KIALI Services 확인 시 GW, VS, DR 확인</span>
<span class="nv">$ </span>kubectl get dr
<span class="c"># =&gt; NAME          HOST          AGE</span>
<span class="c">#    details       details       31s</span>
<span class="c">#    productpage   productpage   31s</span>
<span class="c">#    ratings       ratings       31s</span>
<span class="c">#    reviews       reviews       31s</span>
</code></pre></div></div>

<p><img src="/assets/2024/kans-3th/w7/20241019_kans_w7_21.png" alt="img.png" /></p>

<ul>
  <li><strong>virtual-service-all-v1.yaml</strong> : 4개 서비스 모두 v1 의 서브셋(subset) 에 전송하는 정책 테스트</li>
</ul>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># virtual-service-all-v1.yaml</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">networking.istio.io/v1alpha3</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">VirtualService</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">productpage</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">hosts</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s">productpage</span>
  <span class="na">http</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">route</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">destination</span><span class="pi">:</span>
        <span class="na">host</span><span class="pi">:</span> <span class="s">productpage</span>
        <span class="na">subset</span><span class="pi">:</span> <span class="s">v1</span>
<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">networking.istio.io/v1alpha3</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">VirtualService</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">reviews</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">hosts</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s">reviews</span>
  <span class="na">http</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">route</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">destination</span><span class="pi">:</span>
        <span class="na">host</span><span class="pi">:</span> <span class="s">reviews</span>
        <span class="na">subset</span><span class="pi">:</span> <span class="s">v1</span>
<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">networking.istio.io/v1alpha3</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">VirtualService</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">ratings</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">hosts</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s">ratings</span>
  <span class="na">http</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">route</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">destination</span><span class="pi">:</span>
        <span class="na">host</span><span class="pi">:</span> <span class="s">ratings</span>
        <span class="na">subset</span><span class="pi">:</span> <span class="s">v1</span>
<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">networking.istio.io/v1alpha3</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">VirtualService</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">details</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">hosts</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s">details</span>
  <span class="na">http</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">route</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">destination</span><span class="pi">:</span>
        <span class="na">host</span><span class="pi">:</span> <span class="s">details</span>
        <span class="na">subset</span><span class="pi">:</span> <span class="s">v1</span>
<span class="nn">---</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># istio vs(virtualservices) 확인</span>
<span class="nv">$ </span>kubectl get vs
<span class="c"># =&gt; NAME       GATEWAYS               HOSTS   AGE</span>
<span class="c">#    bookinfo   [&amp;quot;bookinfo-gateway&amp;quot;]   [&amp;quot;*&amp;quot;]   3h30m</span>

<span class="c"># 모든 마이크로서비스에 대해 v1 의 서브셋(subset) 에 전송되게 virtualservices 적용</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> virtual-service-all-v1.yaml
<span class="c"># =&gt; virtualservice.networking.istio.io/productpage created</span>
<span class="c">#    virtualservice.networking.istio.io/reviews created</span>
<span class="c">#    virtualservice.networking.istio.io/ratings created</span>
<span class="c">#    virtualservice.networking.istio.io/details created</span>

<span class="c"># istio vs(virtualservices) 확인 &gt;&gt; KIALI 에서 reviews v2,v3 향하는 트래픽 경로가 사라진다!</span>
<span class="nv">$ </span>kubectl get virtualservices
<span class="c"># =&gt; NAME          GATEWAYS               HOSTS             AGE</span>
<span class="c">#    bookinfo      [&amp;quot;bookinfo-gateway&amp;quot;]   [&amp;quot;*&amp;quot;]             3h30m</span>
<span class="c">#    details                              [&amp;quot;details&amp;quot;]       10s</span>
<span class="c">#    productpage                          [&amp;quot;productpage&amp;quot;]   10s</span>
<span class="c">#    ratings                              [&amp;quot;ratings&amp;quot;]       10s</span>
<span class="c">#    reviews                              [&amp;quot;reviews&amp;quot;]       10s</span>
</code></pre></div></div>

<p><img src="/assets/2024/kans-3th/w7/20241019_kans_w7_22.png" alt="img.png" /></p>

<ul>
  <li>
    <p>모든 트래픽이 v1으로 향하게 되어서 브라우저를 새로고침해도 v1만 나오게 됩니다.</p>
  </li>
  <li>
    <p><strong>virtual-service-reviews-test-v2.yaml</strong> : User Identity 기반 라우팅, end-user 커스텀 헤더에 <strong>jason</strong> 매칭 시 <strong>reviews v2</strong> 로 전달</p>
    <ul>
      <li>Match 조건에는 완전 일치(exact) , 전방 일치(prefix) , 정규 표현(regex) - 3가지 패턴을 선택할 수 있다</li>
    </ul>
  </li>
</ul>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># virtual-service-reviews-test-v2.yaml</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">networking.istio.io/v1alpha3</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">VirtualService</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">reviews</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">hosts</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">reviews</span>
  <span class="na">http</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">match</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">headers</span><span class="pi">:</span>
        <span class="na">end-user</span><span class="pi">:</span>
          <span class="na">exact</span><span class="pi">:</span> <span class="s">jason</span>
    <span class="na">route</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">destination</span><span class="pi">:</span>
        <span class="na">host</span><span class="pi">:</span> <span class="s">reviews</span>
        <span class="na">subset</span><span class="pi">:</span> <span class="s">v2</span>
  <span class="pi">-</span> <span class="na">route</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">destination</span><span class="pi">:</span>
        <span class="na">host</span><span class="pi">:</span> <span class="s">reviews</span>
        <span class="na">subset</span><span class="pi">:</span> <span class="s">v1</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 모든 마이크로서비스에 대해 v1 의 서브셋(subset) 에 전송되게 virtualservices 적용</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> virtual-service-reviews-test-v2.yaml
<span class="c"># =&gt; virtualservice.networking.istio.io/reviews configured</span>

<span class="c"># jason 로그인 시 로그 확인</span>
<span class="nv">$ </span>kubetail <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>productpage <span class="nt">-f</span>
<span class="c"># =&gt; [productpage-v1-d5789fdfb-f8gdf productpage] DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): details:9080</span>
<span class="c">#    [productpage-v1-d5789fdfb-f8gdf productpage] send: b'GET /details/0 HTTP/1.1\r\nHost: details:9080\r\nuser-agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.6 Safari/605.1.15\r\nAccept-Encoding: gzip, deflate\r\nAccept: */*\r\nConnection: keep-alive\r\nx-request-id: 3aa3c711-d014-930f-8c2a-563c3dbbd8b5\r\n\r\n'</span>
<span class="c">#    [productpage-v1-d5789fdfb-f8gdf productpage] reply: 'HTTP/1.1 200 OK\r\n'</span>
<span class="c">#    [productpage-v1-d5789fdfb-f8gdf productpage] header: content-type: application/json</span>
<span class="c">#    [productpage-v1-d5789fdfb-f8gdf productpage] header: server: envoy</span>
<span class="c">#    [productpage-v1-d5789fdfb-f8gdf productpage] header: date: Sat, 19 Oct 2024 14:32:09 GMT</span>
<span class="c">#    [productpage-v1-d5789fdfb-f8gdf productpage] header: content-length: 178</span>
<span class="c">#    [productpage-v1-d5789fdfb-f8gdf productpage] header: x-envoy-upstream-service-time: 6</span>
<span class="c">#    [productpage-v1-d5789fdfb-f8gdf productpage] DEBUG:urllib3.connectionpool:http://details:9080 &amp;quot;GET /details/0 HTTP/1.1&amp;quot; 200 178</span>
<span class="c">#    [productpage-v1-d5789fdfb-f8gdf productpage] DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): reviews:9080</span>
<span class="c">#    [productpage-v1-d5789fdfb-f8gdf productpage] send: b'GET /reviews/0 HTTP/1.1</span>
<span class="c">#    Host: reviews:9080</span>
<span class="c">#    user-agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.6 Safari/605.1.15</span>
<span class="c">#    Accept-Encoding: gzip, deflate</span>
<span class="c">#    Accept: */*</span>
<span class="c">#    Connection: keep-alive</span>
<span class="c">#    x-request-id: 3aa3c711-d014-930f-8c2a-563c3dbbd8b5\r\n\r\n'</span>
<span class="c">#    [productpage-v1-d5789fdfb-f8gdf productpage] reply: 'HTTP/1.1 200 OK\r\n'</span>
<span class="c">#    [productpage-v1-d5789fdfb-f8gdf productpage] header: x-powered-by: Servlet/3.1</span>
<span class="c">#    [productpage-v1-d5789fdfb-f8gdf productpage] header: content-type: application/json</span>
<span class="c">#    [productpage-v1-d5789fdfb-f8gdf productpage] header: date: Sat, 19 Oct 2024 14:32:09 GMT</span>
<span class="c">#    [productpage-v1-d5789fdfb-f8gdf productpage] header: content-language: en-US</span>
<span class="c">#    [productpage-v1-d5789fdfb-f8gdf productpage] header: content-length: 358</span>
<span class="c">#    [productpage-v1-d5789fdfb-f8gdf productpage] header: x-envoy-upstream-service-time: 1</span>
<span class="c">#    [productpage-v1-d5789fdfb-f8gdf productpage] header: server: envoy</span>
<span class="c">#    [productpage-v1-d5789fdfb-f8gdf productpage] DEBUG:urllib3.connectionpool:http://reviews:9080 &amp;quot;GET /reviews/0 HTTP/1.1&amp;quot; 200 358</span>
<span class="c">#    [productpage-v1-d5789fdfb-f8gdf productpage] INFO:werkzeug:::ffff:127.0.0.6 - - [19/Oct/2024 14:32:09] &amp;quot;GET /productpage HTTP/1.1&amp;quot; 200 -</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<ul>
  <li>웹브라우저에서 productpage로 접속 후 새로고침을 해보겠습니다.
    <ul>
      <li>로그인 전에는 v1으로 접속 됩니다.
<img src="/assets/2024/kans-3th/w7/20241019_kans_w7_23.png" alt="img.png" /></li>
    </ul>
  </li>
  <li>오른쪽 상단의 Sign in 클릭 후 jason으로 로그인 후 새로고침을 해보겠습니다.
    <ul>
      <li>로그인 후에는 v2로 접속 됩니다.
<img src="/assets/2024/kans-3th/w7/20241019_kans_w7_24.png" alt="img_1.png" /></li>
      <li>
        <p>헤더에는 end-user:jason 이 추가되어 있습니다.</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 로그인 후 헤더헤더</span>
<span class="c"># =&gt; [productpage-v1-d5789fdfb-f8gdf productpage] send: b'GET /reviews/0 HTTP/1.1</span>
<span class="c">#    Host: reviews:9080</span>
<span class="c">#    user-agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.6 Safari/605.1.15</span>
<span class="c">#    Accept-Encoding: gzip, deflate</span>
<span class="c">#    Accept: */*</span>
<span class="c">#    Connection: keep-alive</span>
<span class="c">#    &lt;span style="color: red;"&gt;end-user: jason&lt;/span&gt;</span>
<span class="c">#    x-request-id: 03366677-7032-9291-a4b9-7009a6257394</span>
<span class="c">#    cookie: session=eyJ1c2VyIjoiamFzb24ifQ.ZxPUxA.3MJkXTFH8zJtg_YlXlvzq8xArpc'</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
</ul>

<h5 id="fault-injection-실습">Fault Injection 실습</h5>

<ul>
  <li><strong>virtual-service-ratings-test-delay.yaml</strong> : end-user 가 jason 는 ratings v1 에 7초 지연 발생, 그외 사용자는 ratings v1 정상 연결</li>
</ul>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># virtual-service-ratings-test-delay.yaml</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">networking.istio.io/v1alpha3</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">VirtualService</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">ratings</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">hosts</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">ratings</span>
  <span class="na">http</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">match</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">headers</span><span class="pi">:</span>
            <span class="na">end-user</span><span class="pi">:</span>
              <span class="na">exact</span><span class="pi">:</span> <span class="s">jason</span>
      <span class="na">fault</span><span class="pi">:</span>
        <span class="na">delay</span><span class="pi">:</span>
          <span class="na">percentage</span><span class="pi">:</span>
            <span class="na">value</span><span class="pi">:</span> <span class="m">100.0</span>
          <span class="na">fixedDelay</span><span class="pi">:</span> <span class="s">7s</span>
      <span class="na">route</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">destination</span><span class="pi">:</span>
            <span class="na">host</span><span class="pi">:</span> <span class="s">ratings</span>
            <span class="na">subset</span><span class="pi">:</span> <span class="s">v1</span>
    <span class="pi">-</span> <span class="na">route</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">destination</span><span class="pi">:</span>
            <span class="na">host</span><span class="pi">:</span> <span class="s">ratings</span>
            <span class="na">subset</span><span class="pi">:</span> <span class="s">v1</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># virtualservices 적용</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> virtual-service-ratings-test-delay.yaml
<span class="c"># =&gt; virtualservice.networking.istio.io/ratings configured</span>

<span class="c"># 로그 확인 : product 입장에서 접속 사용자(clinet) 연결을 끊어버림 0 DC downstream_remote_disconnect</span>
<span class="nv">$ </span>kubetail <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>productpage <span class="nt">-f</span>
</code></pre></div></div>

<ul>
  <li>웹브라우저에서 jason으로 로그인된 상태에서 접속시 6~7초 지연이 발생하는것을 확인할 수 있습니다.</li>
</ul>

<p><img src="/assets/2024/kans-3th/w7/20241019_kans_w7_25.png" alt="img.png" /></p>

<ul>
  <li><strong>virtual-service-ratings-test-abort.yaml</strong> : end-user 가 jason 는 ratings v1 에 500 에러 리턴, 그외 사용자는 ratings v1 정상 연결</li>
</ul>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># virtual-service-ratings-test-abort.yaml</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">networking.istio.io/v1alpha3</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">VirtualService</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">ratings</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">hosts</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">ratings</span>
  <span class="na">http</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">match</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">headers</span><span class="pi">:</span>
            <span class="na">end-user</span><span class="pi">:</span>
              <span class="na">exact</span><span class="pi">:</span> <span class="s">jason</span>
      <span class="na">fault</span><span class="pi">:</span>
        <span class="na">abort</span><span class="pi">:</span>
          <span class="na">percentage</span><span class="pi">:</span>
            <span class="na">value</span><span class="pi">:</span> <span class="m">100.0</span>
          <span class="na">httpStatus</span><span class="pi">:</span> <span class="m">500</span>
      <span class="na">route</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">destination</span><span class="pi">:</span>
            <span class="na">host</span><span class="pi">:</span> <span class="s">ratings</span>
            <span class="na">subset</span><span class="pi">:</span> <span class="s">v1</span>
    <span class="pi">-</span> <span class="na">route</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">destination</span><span class="pi">:</span>
            <span class="na">host</span><span class="pi">:</span> <span class="s">ratings</span>
            <span class="na">subset</span><span class="pi">:</span> <span class="s">v1</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># virtualservices 적용</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> virtual-service-ratings-test-abort.yaml
<span class="c"># =&gt; virtualservice.networking.istio.io/ratings configured</span>

<span class="c"># 로그 확인</span>
<span class="nv">$ </span>kubetail <span class="nt">-l</span> <span class="nv">version</span><span class="o">=</span>v2 <span class="nt">-f</span>
</code></pre></div></div>

<p>jason으로 로그인 했을때 Rating 서비스에 500 에러가 발생하는것을 확인할 수 있습니다.</p>

<p><img src="/assets/2024/kans-3th/w7/20241019_kans_w7_26.png" alt="img.png" /></p>

<p>또한 kiali에서도 어느 구간에서 오류가 발생했는지 확인할 수 있으며, Flags도 확인할 수 있습니다. <a href="https://www.envoyproxy.io/docs/envoy/latest/configuration/observability/access_log/usage#config-access-log-format-response-flags">링크</a><br />
(이경우 FI는 Fault Injection을 의미으로 일부러 오류를 일으킨 것을 확인 할 수 있습니다.)</p>

<p><img src="/assets/2024/kans-3th/w7/20241019_kans_w7_27.png" alt="img.png" /></p>

<h5 id="traffic-shifting-실습">Traffic Shifting 실습</h5>

<ul>
  <li>
    <p>카나라 배포 전략 등 활용 - <a href="https://istio.io/latest/docs/tasks/traffic-management/traffic-shifting/">링크</a></p>
  </li>
  <li>
    <p><strong>virtual-service-reviews-50-v3.yaml</strong> : 가중치 (weight-based routing), reviews 에 v1(50%), v3(50%)</p>
  </li>
</ul>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">networking.istio.io/v1alpha3</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">VirtualService</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">reviews</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">hosts</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">reviews</span>
  <span class="na">http</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">route</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">destination</span><span class="pi">:</span>
        <span class="na">host</span><span class="pi">:</span> <span class="s">reviews</span>
        <span class="na">subset</span><span class="pi">:</span> <span class="s">v1</span>
      <span class="na">weight</span><span class="pi">:</span> <span class="m">50</span>
    <span class="pi">-</span> <span class="na">destination</span><span class="pi">:</span>
        <span class="na">host</span><span class="pi">:</span> <span class="s">reviews</span>
        <span class="na">subset</span><span class="pi">:</span> <span class="s">v3</span>
      <span class="na">weight</span><span class="pi">:</span> <span class="m">50</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># virtualservices 적용</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> virtual-service-reviews-50-v3.yaml
<span class="c"># =&gt; virtualservice.networking.istio.io/reviews configured</span>

<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span>  <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$MYDOMAIN</span>:<span class="nv">$IGWHTTP</span>/productpage | <span class="nb">grep</span> <span class="nt">-m</span> 1 <span class="s2">"reviews-v</span><span class="se">\?</span><span class="s2">"</span> <span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span>
<span class="c"># =&gt;      53                   reviews-v1-6584ddcf65-gnc9j</span>
<span class="c">#         47                   reviews-v3-6f5b775685-cw7tc</span>
</code></pre></div></div>

<p>대략 50%의 확률로 v1과 v3로 접속되는것을 확인할 수 있습니다.</p>

<ul>
  <li><strong>virtual-service-reviews-80-20.yaml</strong> : 가중치 (weight-based routing), reviews 에 v1(80%), v2(20%)</li>
</ul>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">networking.istio.io/v1alpha3</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">VirtualService</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">reviews</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">hosts</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s">reviews</span>
  <span class="na">http</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">route</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">destination</span><span class="pi">:</span>
        <span class="na">host</span><span class="pi">:</span> <span class="s">reviews</span>
        <span class="na">subset</span><span class="pi">:</span> <span class="s">v1</span>
      <span class="na">weight</span><span class="pi">:</span> <span class="m">80</span>
    <span class="pi">-</span> <span class="na">destination</span><span class="pi">:</span>
        <span class="na">host</span><span class="pi">:</span> <span class="s">reviews</span>
        <span class="na">subset</span><span class="pi">:</span> <span class="s">v2</span>
      <span class="na">weight</span><span class="pi">:</span> <span class="m">20</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># virtualservices 적용</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> virtual-service-reviews-80-20.yaml
<span class="c"># =&gt; virtualservice.networking.istio.io/reviews configured</span>

<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span>  <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$MYDOMAIN</span>:<span class="nv">$IGWHTTP</span>/productpage | <span class="nb">grep</span> <span class="nt">-m</span> 1 <span class="s2">"reviews-v</span><span class="se">\?</span><span class="s2">"</span> <span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span>
<span class="c"># =&gt;      79                   reviews-v1-6584ddcf65-gnc9j</span>
<span class="c">#         21                   reviews-v2-6f85cb9b7c-cfc68</span>
</code></pre></div></div>

<p>대략 80%의 확률로 v1과 20%의 확률로 v2로 접속되는것을 확인할 수 있습니다.</p>

<p>kiali에서도 어느 구간에서 어떠한 비중으로 트래픽이 흘러가는지 확인할 수 있습니다.
<img src="/assets/2024/kans-3th/w7/20241019_kans_w7_28.png" alt="img.png" /></p>

<h4 id="security-보안">Security (보안)</h4>

<ul>
  <li>요구사항
    <ul>
      <li>MITM (Man-In-The-Middle) 공격 방지를 위해 모든 트래픽은 mTLS로 암호화 되어야 합니다.</li>
      <li>또한 접근 제어 정책이 필요하며, 감사 로깅을 통해 보안 이슈를 식별이 가능 해야 합니다.</li>
    </ul>
  </li>
  <li>목표
    <ul>
      <li>기본 셋팅을 안전하게 하기 : 별도의 셋팅이 없어도 보안을 유지할 수 있도록 설정</li>
      <li>깊은 방어 : 기존에 존재하는 보안 시스템과 통합되어, 다층 방어를 구성</li>
      <li><strong>Zero-trust network</strong> : 네트워크를 신뢰하지 않음으로써 보안 강화 <a href="https://genians.co.kr/genians-nac/zt/">https://genians.co.kr/genians-nac/zt/</a></li>
    </ul>
  </li>
  <li>구성요소
    <ul>
      <li>Certification Authority (CA) : 인증서 발급, 관리, 갱신</li>
      <li>보안 정책 (인증정책, 인가정책 등) 관련 설정을 각 프록시에 전달하는 API 서버</li>
      <li>사이드카와 프록시를 정책 강제 지점(Policy Enforcement Point-PEPs)으로 사용하여 클라이언트와 서버간의 통신을 보호</li>
      <li>Envoy Proxy 확장 기능을 통해 telemetry와 감사 로깅 수집</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/2024/kans-3th/w7/20241019_kans_w7_29.svg" alt="20241019_kans_w7_29.svg" class="image-center" />
<em class="image-caption">istio 보안 아키텍쳐</em></p>

<ul>
  <li>TLS와 mTLS
    <ul>
      <li><strong>TLS (Transport Layer Security)</strong> : 통신 보안을 위한 프로토콜로, 인터넷 상에서 데이터를 암호화하는 표준화된 방법입니다.
기본적으로 서버의 인증서만 확인하는 방식을 사용합니다.</li>
      <li><strong>mTLS (mutual TLS)</strong> : 서버와 클라이언트가 서로 인증을 하고 서로 신뢰할 수 있는지 확인하는 방식입니다.</li>
    </ul>
  </li>
  <li>Authentication (인증), Authorization (인가) (Auto mTLS)
    <ul>
      <li>Istio는 모든 워크로드에 X.509 인증서를 부여하고, 서로 인증을 통해 통신을 보호합니다.</li>
      <li>Envoy proxy와 함께 실행되는 Istio agent는 istiod와 함께 동작하면서 자동으로 인증서를 갱신합니다. 
 <img src="/assets/2024/kans-3th/w7/20241019_kans_w7_30.svg" alt="20241019_kans_w7_30.svg" class="image-center" />
        <ol>
          <li>istiod는 CSR(인증서 서명 요청)을 수행하기 위해 gRPC 서비스를 제공합니다.</li>
          <li>Envoy는 SDS(Secret Discovery Serice) API를 통해 인증서와 키 요청을 보냅니다.</li>
          <li>istio-agent는 SDs 요청을 받으면 Private Key와 CSR을 생성한 후 자격증명
   (credential)과 함께 CSR istiod에 전송하여 서명을 요청합니다.</li>
          <li>CA는 CSR에 포함된 자격증명(credential) 의 유효성을 검사하고 CSR에 서명하여 인증서를 생성합니다.</li>
          <li>istio-agent는 istiod로부터 받은 인증서(certiftcate)와 개인키 private Key)를 Envoy SDS
   API를 통해 Envoy에게 보냅니다.</li>
          <li>위의 CSR 프로세스는 인증서 및 키 순환을 위해 주기적으로 반복됩니다</li>
        </ol>
      </li>
    </ul>
  </li>
  <li>Authentication (인증) : 2가지 타입 제공
<img src="/assets/2024/kans-3th/w7/20241019_kans_w7_31.svg" alt="20241019_kans_w7_31.svg" />
    <ol>
      <li>Peer Authentication :
        <ul>
          <li>서비스간 인증에 사용되며 Client가 연결을 확인하는데 사용. 서비스 코드 변경없이 mTLS 제공</li>
        </ul>
      </li>
      <li>Request Authentication :
        <ul>
          <li>Request에 첨부된 자격증명(Credential)을 통해 최종 사용자 인증에 사용</li>
          <li>istio는 JWT (JSON Web Token)을 지원하여 최종 사용자 인증을 제공</li>
          <li>커스텀 인증 제공자를 비롯하여 OpenID Connect, Keycloak, Auth0 등 다양한 인증 방식을 지원</li>
        </ul>
      </li>
    </ol>
  </li>
  <li>Authorization (인가)
<img src="/assets/2024/kans-3th/w7/20241019_kans_w7_32.svg" alt="20241019_kans_w7_32.svg" />
    <ul>
      <li>istio는 mesh 단위, 네임스페이스 단위, 워크로드 단위로 접근을 제어 할 수 있는 인가 기능을 제공합니다. 다음과 같은 이점이 있습니다.
        <ul>
          <li>워크로드와 워크로드간, 또는 사용자와 워크로드간 인가 제공</li>
          <li>단일한 AuthorizationPolicy CRD를 사용한 단순한 API 제공</li>
          <li>유연한 정책 제공 : 커스텀 조건을 등록할 수 있고, CUSTOM, DENY, ALLOW 액션 지원</li>
          <li>고성능 : Envoy Proxy를 통해 인가 정책을 적용하므로 성능 저하가 없음</li>
          <li>높은 호환성 : gRPC, HTTP, HTTPS 등을 지원하며, 일반적인 TCP 프로토콜도 지원</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h5 id="authentication-auto-mtls-실습">Authentication (Auto mTLS) 실습</h5>

<ul>
  <li>
    <p>기존 파드에 로그에서 인증서 등 보안 관련 내용 확인</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c"># CA Endpoint, CA(/var/run/secret/istio/root-cert,pem), citadelclient, SDS server 등등</span>
  <span class="nv">$ </span>kubectl logs ratings-v1-7c9bd4b87f-s9gxs <span class="nt">-c</span> istio-proxy <span class="nt">-f</span>
  <span class="nv">$ </span>kubetail
  
  <span class="c"># 인증정책 확인</span>
  <span class="nv">$ </span>kubectl get peerauthentications.security.istio.io
  <span class="c"># =&gt; No resources found </span>
    
  <span class="c"># envoy 에 cert 정보 확인 : istio-proxy 에 admin페이지 접속 or kaila 에서 envoy 에서 확인    </span>
</code></pre></div>    </div>
  </li>
  <li>bookinfo → kiali → product 계속 접속</li>
  <li>kiali 에서 Display(Security 체크) 후 자물쇠 클릭하면 오른쪽 창에서 보안설정을 확이할 수 있습니다. : mTLS Enabled, spiffe(Secure name)</li>
</ul>

<p><img src="/assets/2024/kans-3th/w7/20241019_kans_w7_33.png" alt="img.png" /></p>

<ul>
  <li>test 네임스페이스 생성 후 파드 생성(sidecar 미적용) 후 ratings 접속</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 네임스페이스 생성</span>
<span class="nv">$ </span>kubectl create ns <span class="nb">test</span>
<span class="c"># =&gt; namespace/test created</span>

<span class="c"># 파드 생성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl create -f -
apiVersion: v1
kind: Pod
metadata:
  name: netpod
  namespace: test
spec:
  containers:
  - name: netshoot-pod
    image: nicolaka/netshoot
    command: ["tail"]
    args: ["-f", "/dev/null"]
  terminationGracePeriodSeconds: 0
</span><span class="no">EOF

</span><span class="c"># 확인 : sidecar 미적용</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-n</span> <span class="nb">test</span>
<span class="c"># =&gt; NAME     READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    netpod   1/1     Running   0          19s</span>

<span class="c"># ratings 서비스 확인</span>
<span class="nv">$ </span>kubectl get svc ratings
<span class="c"># =&gt; NAME      TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE</span>
<span class="c">#    ratings   ClusterIP   10.10.200.163   &amp;lt;none&amp;gt;        9080/TCP   8h</span>

<span class="c"># ratings 접속 시도 : 성공</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> <span class="nb">test </span>netpod <span class="nt">--</span> curl ratings.default:9080/health <span class="p">;</span><span class="nb">echo</span>
<span class="nv">$ </span><span class="o">{</span><span class="s2">"status"</span>:<span class="s2">"Ratings is healthy"</span><span class="o">}</span>

<span class="c"># 로그 확인</span>
<span class="nv">$ </span>kubetail <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>ratings <span class="nt">-f</span>
</code></pre></div></div>

<p><img src="/assets/2024/kans-3th/w7/20241019_kans_w7_34.png" alt="img.png" class="image-center w-80" />
<em class="image-caption">NS(default, test 체크) netpod 에서 접속 시 unknown 으로 표기되며, 접근 성공(녹색) 확인</em></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Peer authentication 설정 변경 : PERMISSIVE(mTLS 사용/미사용 모두 허용) → STRICT(반드시 mTLS 사용, 미사용 시 거부)</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl create -f -
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  name: default-strict
spec:
  mtls:
    mode: STRICT
</span><span class="no">EOF

</span><span class="c"># ratings 접속 시도 : 실패!</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> <span class="nb">test </span>netpod <span class="nt">--</span> curl ratings.default:9080/health <span class="p">;</span><span class="nb">echo</span>
<span class="c"># =&gt; curl: (56) Recv failure: Connection reset by peer</span>
<span class="c">#    command terminated with exit code 56</span>

<span class="nv">$ </span>kubetail <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>ratings <span class="nt">-f</span>
<span class="c"># =&gt; [ratings-v1-7c9bd4b87f-s9gxs istio-proxy] [2024-10-01T17:21:12.708Z] &amp;quot;- - -&amp;quot; 0 NR filter_chain_not_found - &amp;quot;-&amp;quot; 0 0 0 - &amp;quot;-&amp;quot; &amp;quot;-&amp;quot; &amp;quot;-&amp;quot; &amp;quot;-&amp;quot; &amp;quot;-&amp;quot; - - 172.16.3.17:9080 172.16.1.17:34938 - -</span>
</code></pre></div></div>

<ul>
  <li>실습 자원 삭제</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl delete PeerAuthentication default-strict
<span class="c"># =&gt; peerauthentication.security.istio.io &amp;quot;default-strict&amp;quot; deleted</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> <span class="nb">test </span>netpod <span class="nt">--</span> curl ratings.default:9080/health <span class="p">;</span><span class="nb">echo</span>
<span class="c"># =&gt; {&amp;quot;status&amp;quot;:&amp;quot;Ratings is healthy&amp;quot;}</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 인증정책 강제 정책 삭제시 다시 통신이 됩니다.&lt;/span&gt;</span>

<span class="nv">$ </span>kubectl delete pod <span class="nt">-n</span> <span class="nb">test </span>netpod
<span class="nv">$ </span>kubectl delete ns <span class="nb">test</span>
</code></pre></div></div>

<h3 id="istio-통신-흐름">Istio 통신 흐름</h3>

<p>istio 사용시 트래픽은 호스트의 tcp/ip 스택과 iptables, 파드내의 iptables와 envoy를 경유하게 됩니다.
istio는 강력하고 다양한 기능들을 제공하지만 비용(지연추가, 프로세서 사용량 추가, 복잡한 구조)이 필요합니다.</p>

<p><img src="/assets/2024/kans-3th/w7/20241019_kans_w7_35.png" alt="img.png" class="image-center w-80" /></p>

<p>외부 클라이언트(PC 등)에서 파드로 접속되는 과정은 다음과 같습니다.</p>

<p><img src="/assets/2024/kans-3th/w7/20241019_kans_w7_36.png" alt="img_1.png" /></p>

<p>위의 그림에서 처럼 iptables를 여러번 거치고, DNAT등을 통해 포트번호등이 80 (http) =&gt; 15006 (istio-proxy) 로 변경되는 등의 작업을 여러번 거칩니다.
또한 파드와 호스트간 통신 envoy를 요청을 받을때와 응답할때 모두 거쳐가는 것을 확인할 수 있습니다.</p>

<ul>
  <li>파드 내 Iptables 적용 흐름</li>
</ul>

<p><img src="/assets/2024/kans-3th/w7/20241019_kans_w7_37.png" alt="img.png" class="image-center" />
<em class="image-caption">출처 : <a href="https://jimmysong.io/en/blog/sidecar-injection-iptables-and-traffic-routing/#understand-outbound-handler">Jimmy song</a> 블로그</em></p>

<p>다음 블로그에서 자세한 내용을 확인할 수 있습니다.
<a href="https://jimmysong.io/en/blog/sidecar-injection-iptables-and-traffic-routing/#understand-outbound-handler">Understanding the Sidecar Injection, Traffic Intercepting &amp; Routing Process in Istio</a></p>

<hr />

<h2 id="마치며">마치며</h2>

<p>1주차 컨테이너 격리 이후에 또 다시 뇌정지가 찾아온 주차였습니다.
이번주에 학습한것도 많은데, 이것이 일부만 살펴본것이라니 놀랍습니다.
정말 만든 분들도, 쓰는 분들도, 스터디를 진행해주시는 분들도 대단합니다. :thumbsup:</p>

<p>인증이나 인가 등 gateway api에서 아쉬웠던 부분들이 나와서 좋았습니다.
찾던 기능인데 마침 이번주에 다루게 되어서 좋았습니다. 
Kiali를 통한 트래픽 시각화도 정말 유용하게 쓰일 것 같습니다.
복잡하긴 하지만 좋은 기능들이 많았습니다.</p>

<p>시간이 모자라서 미처 실습하지 못한 부분들과 Ambient Mesh도 바쁜일이 지나가면 다시 살펴봐야겠습니다.
스터디를 준비해주신 가시다님과 참여하신 분들 감사합니다. :pray:</p>]]></content><author><name></name></author><category term="kans" /><category term="kubernetes," /><category term="network," /><category term="linux" /><summary type="html"><![CDATA[이번주에는 Service Mesh와 대표적인 오픈소스 프로젝트인 Istio에 대해 알아 보겠습니다.]]></summary></entry><entry><title type="html">[KANS 3기] Ingress &amp;amp; Gateway API</title><link href="https://sweetlittlebird.github.io/posts/2024-10-13-KANS-Study-Week6/" rel="alternate" type="text/html" title="[KANS 3기] Ingress &amp;amp; Gateway API" /><published>2024-10-13T01:00:18+09:00</published><updated>2024-10-13T01:00:18+09:00</updated><id>https://sweetlittlebird.github.io/posts/KANS%20Study%20-%20Week6</id><content type="html" xml:base="https://sweetlittlebird.github.io/posts/2024-10-13-KANS-Study-Week6/"><![CDATA[<h2 id="들어가며">들어가며</h2>

<p>이번주에는 ingress와 gateway api 에대해 알아 보겠습니다.
KANS 3기 6주차 스터디를 시작하겠습니다.</p>

<hr />

<h2 id="ingress">Ingress</h2>

<h3 id="ingress란">Ingress란?</h3>

<ul>
  <li>Ingress는 클러스터 외부에서 클러스터 내부로 HTTP 및 HTTPS 트래픽을 라우팅하는 Web Proxy 역할을 수행합니다.</li>
  <li>지난주에 스터디했던 LoadBalancer와 비슷한 역할을 수행하지만, LoadBalancer는 Layer 4에서 동작하는 반면 Ingress는 Layer 7에서 동작한다는 차이가 있습니다.</li>
  <li>Ingress는 HTTP와 HTTPS를 이해하기 때문에 호스트명, 경로 등에 따라 트래픽을 라우팅할 수도 있고, SSL Offloading 등의 기능도 제공합니다.</li>
  <li>이렇게 다양한 기능이 있지만 <strong>Ingress는 동결처리</strong> 되었으며, <strong>신규 기능들은 Gateway API라는 다른 API에 추가되고 있고</strong>, 향후에는 Ingress 대신 Gateway API를 사용하는 것이 권장될것으로 보입니다.</li>
</ul>

<p><img src="/assets/2024/kans-3th/w6/20241012_kans_w6_1.png" alt="img.png" class="image-center" /></p>

<ul>
  <li>특이한 점은 Ingress 를 통한 트래픽은 서비스를 통하지 않고, 서비스를 통해서 파드의 IP를 확인하고, 위의 그림과 같이 서비스를 거치지 않고 파드와 직접 통신합니다.</li>
</ul>

<h3 id="ingress-controller의-종류">Ingress Controller의 종류</h3>

<ul>
  <li>Ingress는 Kubernetes에 내장된 기능이 아니어서 별도의 Ingress Controller를 설치해야만 사용할 수 있습니다. 
많이 사용되는 Ingress Controller는 다음과 같습니다.</li>
</ul>

<table>
  <thead>
    <tr>
      <th>구분</th>
      <th>특징</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Pomerium</td>
      <td>보안에 특화 된 Ingress로 Identity-Aware 접근이 가능하며 Zero Trust 모델을 지원합니다.</td>
    </tr>
    <tr>
      <td>NGINX Ingress Controller</td>
      <td>신뢰할 수 있는 안정적으로, 라우팅이 유연하고, Lua 스크립트 등으로 기능확장이 가능합니다.</td>
    </tr>
    <tr>
      <td>Traefik</td>
      <td>Auto-discovery를 제공하고, 실시간으로 업데이트 되며, 관리 대시보드를 제공합니다. 동적으로 운영하기 좋습니다.</td>
    </tr>
    <tr>
      <td>HAProxy Ingress</td>
      <td>고성능이며, 다양한 고급 기능을 제공합니다.</td>
    </tr>
    <tr>
      <td>Envoy</td>
      <td>확장성이 있으며 재시도, 서킷 브레이커, 레이트 제한 등 다양한 기능을 제공합니다.</td>
    </tr>
    <tr>
      <td>Istio Ingress Gateway</td>
      <td>트래픽 관리에 강점이 있으며, Istio 서비스 메시와 연동하기 좋습니다.</td>
    </tr>
    <tr>
      <td>Contour</td>
      <td>HTTP/2와 gRPC를 지원하는 경량의 고성능을 제공합니다.</td>
    </tr>
    <tr>
      <td>Kong Ingress Controller</td>
      <td>Kong은 API Gateway로 널리 알려져있지만 Ingress Controller 기능도 제공합니다. NGINX Ingress Controller의 기능에 추가적인 기능을 제공하지만 학습 곡선이 높은 편입니다.</td>
    </tr>
  </tbody>
</table>

<p>이외에도 다양한 Ingress Controller가 존재하며 다음의 링크에서 확인 할 수 있습니다. <a href="https://docs.google.com/spreadsheets/d/191WWNpjJ2za6-nbG4ZoUMXMpUK8KlCIosvQB0f-oq3k/">Kubernetes Ingress Controllers 비교</a></p>

<h3 id="실습-환경-준비">실습 환경 준비</h3>

<ul>
  <li>이번 실습에는 k3s라는 경량 Kubernetes 클러스터를 사용하겠습니다. k3s는 Rancher에서 개발한 경량 Kubernetes 클러스터로, 쉽게 설치가 가능하고, 
전체가 100MB보다 적을 정도로 적은 자원으로도 Kubernetes를 사용할 수 있습니다.</li>
  <li>하지만 K8S와는 기능 차이가 있기 때문에, 이러한 부분을 감안하고 사용하시면 됩니다.</li>
</ul>

<h4 id="k3s-특징">k3s 특징</h4>

<ul>
  <li>k3s의 특징은 다음과 같습니다
    <ul>
      <li>단일 바이너리 또는 최소 컨테이너 이미지로 배포됩니다.</li>
      <li>기본 저장소 백엔드로 sqlite3를 기반으로 한 경량 데이터 저장소가 사용됩니다. etcd, MySQL 및 Postgres도 사용할 수 있습니다.</li>
      <li>TLS 및 옵션의 복잡성을 처리하는 런처에 포함되어 있습니다.</li>
      <li>경량 환경에 적합한 합리적인 기본값으로 보안에 신경을 썼습니다.</li>
      <li>모든 Kubernetes 컨트롤 플레인 구성 요소의 작동이 단일 바이너리 및 프로세스에 캡슐화되어 있고, k3s가 인증서 배포와 같은 복잡한 클러스터 작업을 자동화합니다.</li>
      <li>외부 종속성이 최소화되었습니다. 필요한 것은 최신 커널과 cgroup 마운트뿐입니다.</li>
      <li>손쉬운 클러스터 생성을 위해 필요한 패키지를 기본 제공합니다:
        <ul>
          <li>containerd / cri-dockerd 컨테이너 런타임 (CRI)</li>
          <li>Flannel 컨테이너 네트워크 인터페이스 (CNI)</li>
          <li>CoreDNS 클러스터 DNS</li>
          <li>Traefik Ingress 컨트롤러</li>
          <li>ServiceLB 로드 밸런서 컨트롤러</li>
          <li>Kube-router 네트워크 정책 컨트롤러</li>
          <li>Local-path-provisioner 영구 볼륨 컨트롤러</li>
          <li>Spegel 분산 컨테이너 이미지 레지스트리 미러</li>
          <li>호스트 유틸리티 (iptables, socat 등)</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="k3s의-아키텍쳐">k3s의 아키텍쳐</h4>

<ul>
  <li>k3s는 서버 (Control Plane)와 에이전트 (Worker Node)로 구성되어 있습니다.
    <ul>
      <li>서버 노드는 Kubernetes의 <code class="language-plaintext highlighter-rouge">k3s server</code> 명령으로 실행되며 모든 컨트롤 플레인 구성 요소와 데이터 저장 컴포넌트를 실행하며 k3s가 관리합니다.</li>
      <li>에이전트 노드는 <code class="language-plaintext highlighter-rouge">k3s agent</code> 명령으로 실행되며 컨트롤 플레인 요소등 없이 워커 노드로 동작합니다.</li>
      <li>모든 서버와 에이전트는 kublet, 컨테이너 런타임, CNI 등을 포함한 모든 Kubernetes 구성 요소를 실행합니다.</li>
      <li>더 자세한 내용은 다음 링크를 참고하세요. <a href="https://docs.k3s.io/advanced#running-agentless-servers-experimental">링크</a>
<img src="/assets/2024/kans-3th/w6/20241012_kans_w6_2.svg" alt="20241012_kans_w6_2.svg" /></li>
    </ul>
  </li>
  <li>단일 서버 구성 : 1대 K3S 서버(경량 DB = SQLite), 필요한 만큼의 K3S Agents (Worker Node) 구성
<img src="/assets/2024/kans-3th/w6/20241012_kans_w6_3.png" alt="img.png" /></li>
  <li>고가용성 구성 : Embedded DB (etcd 등), 외부 DB (MySQL, PostgreSQL 등) 사용 가능
<img src="/assets/2024/kans-3th/w6/20241012_kans_w6_4.png" alt="img_1.png" /></li>
</ul>

<h4 id="k3s-설치">k3s 설치</h4>

<ul>
  <li>k3s는 기본적으로 <code class="language-plaintext highlighter-rouge">traefik</code>을 Ingress Controller로 사용하는데 이번 실습에서는 nginx ingress controller를 사용할 것이기 때문에 <code class="language-plaintext highlighter-rouge">traefik</code>을 설치하지 않겠습니다.</li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">INSTALL_K3S_EXEC=" --disable=traefik"</code> 옵션을 사용하여 traefik을 설치하지 않을 수 있습니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Install k3s-server</span>
<span class="nv">$ </span>curl <span class="nt">-sfL</span> https://get.k3s.io | <span class="nv">INSTALL_K3S_EXEC</span><span class="o">=</span><span class="s2">" --disable=traefik"</span>  sh <span class="nt">-s</span> - server <span class="nt">--token</span> <span class="o">[[</span>인증토큰]] <span class="nt">--cluster-cidr</span> <span class="s2">"172.16.0.0/16"</span> <span class="nt">--service-cidr</span> <span class="s2">"10.10.200.0/24"</span> <span class="nt">--write-kubeconfig-mode</span> 644 
  
<span class="c"># Install k3s-agent</span>
<span class="nv">$ </span>curl <span class="nt">-sfL</span> https://get.k3s.io | <span class="nv">K3S_URL</span><span class="o">=</span>https://192.168.10.10:6443 <span class="nv">K3S_TOKEN</span><span class="o">=[[</span>인증토큰]]  sh <span class="nt">-s</span> -
</code></pre></div>    </div>
  </li>
  <li>k3s 설치 후, k3의 설정을 확인해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 노드 확인</span>
<span class="nv">$ </span>kubectl get node <span class="nt">-owide</span>
<span class="c"># =&gt; NAME     STATUS   ROLES                  AGE     VERSION        INTERNAL-IP   EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION       CONTAINER-RUNTIME</span>
<span class="c">#    k3s-m    Ready    control-plane,master   30m     v1.30.5+k3s1   10.0.2.15     &amp;lt;none&amp;gt;        Ubuntu 22.04.5 LTS   5.15.0-119-generic   containerd://1.7.21-k3s2</span>
<span class="c">#    k3s-w1   Ready    &amp;lt;none&amp;gt;                 4m24s   v1.30.5+k3s1   10.0.2.15     &amp;lt;none&amp;gt;        Ubuntu 22.04.5 LTS   5.15.0-119-generic   containerd://1.7.21-k3s2</span>
<span class="c">#    k3s-w2   Ready    &amp;lt;none&amp;gt;                 26m     v1.30.5+k3s1   10.0.2.15     &amp;lt;none&amp;gt;        Ubuntu 22.04.5 LTS   5.15.0-119-generic   containerd://1.7.21-k3s2</span>
<span class="c">#    k3s-w3   Ready    &amp;lt;none&amp;gt;                 24m     v1.30.5+k3s1   10.0.2.15     &amp;lt;none&amp;gt;        Ubuntu 22.04.5 LTS   5.15.0-119-generic   containerd://1.7.21-k3s2</span>

<span class="nv">$ </span>kubectl describe node k3s-m | <span class="nb">grep </span>Taint  <span class="c"># Taints 없음</span>
<span class="c"># =&gt; Taints:             &amp;lt;none&amp;gt;</span>
<span class="nv">$ </span>kubectl describe node k3s-w1 | <span class="nb">grep </span>Taint  <span class="c"># Taints 없음</span>
<span class="c"># =&gt; Taints:             &amp;lt;none&amp;gt;</span>

<span class="c"># 파드 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-n</span> kube-system
<span class="c"># =&gt; NAME                                      READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    coredns-7b98449c4-8l64d                   1/1     Running   0          31m</span>
<span class="c">#    local-path-provisioner-6795b5f9d8-b5gt6   1/1     Running   0          31m</span>
<span class="c">#    metrics-server-cdcc87586-d87gv            1/1     Running   0          31m</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl top node
<span class="c"># =&gt; NAME     CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%</span>
<span class="c">#    k3s-m    147m         3%     1128Mi          28%</span>
<span class="c">#    k3s-w1   147m         3%     1128Mi          57%</span>
<span class="c">#    k3s-w2   147m         3%     1128Mi          57%</span>
<span class="c">#    k3s-w3   147m         3%     1128Mi          57%</span>
<span class="nv">$ </span>kubectl top pod <span class="nt">-A</span> <span class="nt">--sort-by</span><span class="o">=</span><span class="s1">'cpu'</span>
<span class="c"># =&gt; NAMESPACE     NAME                                      CPU(cores)   MEMORY(bytes)</span>
<span class="c">#    kube-system   metrics-server-cdcc87586-d87gv            15m          19Mi</span>
<span class="c">#    kube-system   coredns-7b98449c4-8l64d                   4m           13Mi</span>
<span class="c">#    kube-system   local-path-provisioner-6795b5f9d8-b5gt6   1m           6Mi</span>
<span class="nv">$ </span>kubectl top pod <span class="nt">-A</span> <span class="nt">--sort-by</span><span class="o">=</span><span class="s1">'memory'</span>
<span class="nv">$ </span>kubectl get storageclass
<span class="c"># =&gt; NAME                   PROVISIONER             RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE</span>
<span class="c">#    local-path (default)   rancher.io/local-path   Delete          WaitForFirstConsumer   false                  32m</span>

<span class="c"># config 정보(위치) 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-v</span><span class="o">=</span>6
<span class="c"># =&gt; I1012 05:55:56.507623    6817 loader.go:395] Config loaded from file:  /etc/rancher/k3s/k3s.yaml</span>
<span class="c">#    I1012 05:55:56.518338    6817 round_trippers.go:553] GET https://127.0.0.1:6443/api/v1/namespaces/default/pods?limit=500 200 OK in 5 milliseconds</span>
<span class="c">#    No resources found in default namespace.</span>

<span class="nv">$ </span><span class="nb">cat</span> /etc/rancher/k3s/k3s.yaml
<span class="c"># =&gt; apiVersion: v1</span>
<span class="c">#    clusters:</span>
<span class="c">#    - cluster:</span>
<span class="c">#        certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJlRENDQVIyZ0F3SUJBZ0lCQURBS0JnZ3Foa2pPUFFRREFqQWpNU0V3SHdZRFZRUUREQmhyTTNNdGMyVnkKZG1WeUxXTmhRREUzTWpnM01UQTJNREF3SGhjTk1qUXhNREV5TURVeU16SXdXaGNOTXpReE1ERXdNRFV5TXpJdwpXakFqTVNFd0h3WURWUVFEREJock0zTXRjMlZ5ZG1WeUxXTmhRREUzTWpnM01UQTJNREF3V1RBVEJnY3Foa2pPClBRSUJCZ2dxaGtqT1BRTUJCd05DQUFReEdLOFFEcHMvNmNHdE45RWRCYmZJRmg2UjBpQlFLYUhHYWhVQXVMdjUKWHhpd1JjTVdia1FZNmxBdWM1RC9zWWYrTmhZYUFjcmNzMk01LzAyTkQ5bERvMEl3UURBT0JnTlZIUThCQWY4RQpCQU1DQXFRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBZEJnTlZIUTRFRmdRVXJzL1ZVODFCZEJnS3N2YmJDRmhjCkJ5aStxUTB3Q2dZSUtvWkl6ajBFQXdJRFNRQXdSZ0loQUxwWXpzZkVMdjZScG56OGdqcDZXYkZuUFk2S3FrQ2gKTWYwRWZvMnRzM2d5QWlFQXhkaDM4akJCMWJrTWlwWDNSMTFyTnBtZmc2S2huZzliNUJDTUs0M3UyTjA9Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K</span>
<span class="c">#        server: https://127.0.0.1:6443</span>
<span class="c">#      name: default</span>
<span class="c">#    ...</span>
<span class="nv">$ </span><span class="nb">export</span> | <span class="nb">grep </span>KUBECONFIG
<span class="c"># =&gt; (공백)</span>

<span class="c"># 네트워크 정보 확인 : flannel CNI(vxlan mode), podCIDR</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> addr
<span class="c"># =&gt; ...</span>
<span class="c">#    4: flannel.1: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1450 qdisc noqueue state UNKNOWN group default</span>
<span class="c">#        link/ether 02:21:77:da:a3:91 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet 172.16.0.0/32 scope global flannel.1</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    5: cni0: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1450 qdisc noqueue state UP group default qlen 1000</span>
<span class="c">#        link/ether ca:30:a0:c8:5c:cd brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet 172.16.0.1/24 brd 172.16.0.255 scope global cni0</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    6: veth41d9e3b2@if2: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1450 qdisc noqueue master cni0 state UP group default</span>
<span class="c">#        link/ether fa:47:5c:4a:8d:af brd ff:ff:ff:ff:ff:ff link-netns cni-9c26655e-b22f-97a1-f97c-db88daccc77f</span>
<span class="c">#    7: veth5c3de18a@if2: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1450 qdisc noqueue master cni0 state UP group default</span>
<span class="c">#        link/ether 6a:5e:39:72:4f:4c brd ff:ff:ff:ff:ff:ff link-netns cni-cff25bf8-d23b-790a-91d0-ed5c4ee526d5</span>
<span class="c">#    8: vethfaeebb1c@if2: &amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1450 qdisc noqueue master cni0 state UP group default</span>
<span class="c">#        link/ether c6:f5:31:a1:56:21 brd ff:ff:ff:ff:ff:ff link-netns cni-06a3672f-70dc-7445-48c9-8cf8c26e7fb3</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 10.0.2.2 dev enp0s3 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    ...</span>
<span class="c">#    172.16.0.0/24 dev cni0 proto kernel scope link src 172.16.0.1</span>
<span class="c">#    172.16.1.0/24 via 172.16.1.0 dev flannel.1 onlink</span>
<span class="c">#    172.16.2.0/24 via 172.16.2.0 dev flannel.1 onlink</span>
<span class="c">#    172.16.3.0/24 via 172.16.3.0 dev flannel.1 onlink</span>
<span class="c">#    192.168.10.0/24 dev enp0s8 proto kernel scope link src 192.168.10.10</span>
<span class="nv">$ </span><span class="nb">cat</span> /run/flannel/subnet.env
<span class="c"># =&gt; FLANNEL_NETWORK=172.16.0.0/16</span>
<span class="c">#    FLANNEL_SUBNET=172.16.0.1/24</span>
<span class="c">#    FLANNEL_MTU=1450</span>
<span class="c">#    FLANNEL_IPMASQ=true</span>
<span class="nv">$ </span>kubectl get nodes <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[*].spec.podCIDR}'</span> <span class="p">;</span><span class="nb">echo</span>
<span class="c"># =&gt; 172.16.0.0/24 172.16.3.0/24 172.16.1.0/24 172.16.2.0/24</span>
<span class="nv">$ </span>kubectl describe node | <span class="nb">grep</span> <span class="nt">-A3</span> Annotations
<span class="c"># =&gt; Annotations:        alpha.kubernetes.io/provided-node-ip: 10.0.2.15</span>
<span class="c">#                        flannel.alpha.coreos.com/backend-data: {&amp;quot;VNI&amp;quot;:1,&amp;quot;VtepMAC&amp;quot;:&amp;quot;02:21:77:da:a3:91&amp;quot;}</span>
<span class="c">#                        flannel.alpha.coreos.com/backend-type: vxlan</span>
<span class="c">#                        flannel.alpha.coreos.com/kube-subnet-manager: true</span>
<span class="c">#    --</span>
<span class="c">#    Annotations:        alpha.kubernetes.io/provided-node-ip: 10.0.2.15</span>
<span class="c">#                        flannel.alpha.coreos.com/backend-data: {&amp;quot;VNI&amp;quot;:1,&amp;quot;VtepMAC&amp;quot;:&amp;quot;72:95:9e:3d:c6:35&amp;quot;}</span>
<span class="c">#                        flannel.alpha.coreos.com/backend-type: vxlan</span>
<span class="c">#                        flannel.alpha.coreos.com/kube-subnet-manager: true</span>
<span class="c">#    --</span>
<span class="c">#    Annotations:        alpha.kubernetes.io/provided-node-ip: 10.0.2.15</span>
<span class="c">#                        flannel.alpha.coreos.com/backend-data: {&amp;quot;VNI&amp;quot;:1,&amp;quot;VtepMAC&amp;quot;:&amp;quot;ae:28:43:65:df:f4&amp;quot;}</span>
<span class="c">#                        flannel.alpha.coreos.com/backend-type: vxlan</span>
<span class="c">#                        flannel.alpha.coreos.com/kube-subnet-manager: true</span>
<span class="c">#    --</span>
<span class="c">#    Annotations:        alpha.kubernetes.io/provided-node-ip: 10.0.2.15</span>
<span class="c">#                        flannel.alpha.coreos.com/backend-data: {&amp;quot;VNI&amp;quot;:1,&amp;quot;VtepMAC&amp;quot;:&amp;quot;8e:91:37:7d:c1:d7&amp;quot;}</span>
<span class="c">#                        flannel.alpha.coreos.com/backend-type: vxlan</span>
<span class="c">#                        flannel.alpha.coreos.com/kube-subnet-manager: true</span>
<span class="nv">$ </span>brctl show
<span class="c"># =&gt; bridge name     bridge id               STP enabled     interfaces</span>
<span class="c">#    cni0            8000.ca30a0c85ccd       no              veth41d9e3b2</span>
<span class="c">#                                                            veth5c3de18a</span>
<span class="c">#                                                            vethfaeebb1c</span>

<span class="c"># 서비스와 엔드포인트 확인</span>
<span class="nv">$ </span>kubectl get svc,ep <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE     NAME                     TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                  AGE</span>
<span class="c">#    default       service/kubernetes       ClusterIP   10.10.200.1     &amp;lt;none&amp;gt;        443/TCP                  38m</span>
<span class="c">#    kube-system   service/kube-dns         ClusterIP   10.10.200.10    &amp;lt;none&amp;gt;        53/UDP,53/TCP,9153/TCP   38m</span>
<span class="c">#    kube-system   service/metrics-server   ClusterIP   10.10.200.103   &amp;lt;none&amp;gt;        443/TCP                  38m</span>
<span class="c">#    </span>
<span class="c">#    NAMESPACE     NAME                       ENDPOINTS                                     AGE</span>
<span class="c">#    default       endpoints/kubernetes       10.0.2.15:6443                                38m</span>
<span class="c">#    kube-system   endpoints/kube-dns         172.16.0.4:53,172.16.0.4:53,172.16.0.4:9153   38m</span>
<span class="c">#    kube-system   endpoints/metrics-server   172.16.0.3:10250                              38m</span>

<span class="c"># iptables 정보 확인</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> filter <span class="nt">-S</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> mangle <span class="nt">-S</span>

<span class="c"># tcp listen 포트 정보 확인</span>
<span class="nv">$ </span>ss <span class="nt">-tnlp</span>
</code></pre></div></div>

<ul>
  <li>flannel CNI를 사용하고 있고, 클러스터 IP는 172.16.0.0/16이며, 컨트롤 플레인의기능들이 많이 내장되어있어 실행중인 파드가 적음을 확인 할 수 있습니다.</li>
</ul>

<h3 id="nginx-ingress-controller-설치">Nginx Ingress Controller 설치</h3>

<ul>
  <li>Nginx Ingress Controller는 가장 많이 사용되는 Ingress Controller 중 하나로 Ingress 실습을 위해 설치해보겠습니다.</li>
  <li>먼저 NGINX Ingress 의 특징을 살펴보겠습니다.
    <ul>
      <li>NGINX Ingress는 고성능 웹서버인 NGINX를 기반으로 동작하며, Layer 7에서 동작합니다.</li>
      <li>k8s의 configmap 설정을 lua 스크립트로 가공하여 nginx config로 변환하여 사용합니다.</li>
      <li>설정을 변경하면 내부의 nginx가 reload 되면서 자동으로 적용되며, 설정을 쉽게 변경할 수 있습니다.</li>
    </ul>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Ingress-Nginx 컨트롤러 생성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh">&gt; ingress-nginx-values.yaml
controller:
  service:
    type: NodePort
    nodePorts:
      http: 30080
      https: 30443
  nodeSelector:
    kubernetes.io/hostname: "k3s-s"
  metrics:
    enabled: true
  serviceMonitor:
      enabled: true
</span><span class="no">EOT

</span><span class="nv">$ </span>helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
<span class="c"># =&gt; "ingress-nginx" has been added to your repositories</span>
<span class="nv">$ </span>helm repo update
<span class="c"># =&gt; ...Successfully got an update from the "ingress-nginx" chart repository</span>

<span class="nv">$ </span>kubectl create ns ingress
<span class="c"># =&gt; namespace/ingress created</span>
<span class="nv">$ </span>helm <span class="nb">install </span>ingress-nginx ingress-nginx/ingress-nginx <span class="nt">-f</span> ingress-nginx-values.yaml <span class="nt">--namespace</span> ingress <span class="nt">--version</span> 4.11.2
<span class="c"># =&gt; Release &amp;quot;ingress-nginx&amp;quot; has been upgraded. Happy Helming!</span>
<span class="c">#    NAME: ingress-nginx</span>
<span class="c">#    NAMESPACE: ingress</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    ...</span>
<span class="c">#    The ingress-nginx controller has been installed.</span>
<span class="c">#    Get the application URL by running these commands:</span>
<span class="c">#      export HTTP_NODE_PORT=30080</span>
<span class="c">#      export HTTPS_NODE_PORT=30443</span>
<span class="c">#      export NODE_IP=&amp;quot;$(kubectl get nodes --output jsonpath=&amp;quot;{.items[0].status.addresses[1].address}&amp;quot;)&amp;quot;</span>
<span class="c">#    </span>
<span class="c">#      echo &amp;quot;Visit http://${NODE_IP}:${HTTP_NODE_PORT} to access your application via HTTP.&amp;quot;</span>
<span class="c">#      echo &amp;quot;Visit https://${NODE_IP}:${HTTPS_NODE_PORT} to access your application via HTTPS.&amp;quot;</span>
<span class="c">#    ...</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get all <span class="nt">-n</span> ingress
<span class="c"># =&gt; NAME                                            READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/ingress-nginx-controller-7b67846f8f-jdt65   1/1     Running   0          47s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE</span>
<span class="c">#    service/ingress-nginx-controller             NodePort    10.10.200.113   &amp;lt;none&amp;gt;        80:30080/TCP,443:30443/TCP   47s</span>
<span class="c">#    service/ingress-nginx-controller-admission   ClusterIP   10.10.200.176   &amp;lt;none&amp;gt;        443/TCP                      47s</span>
<span class="c">#    service/ingress-nginx-controller-metrics     ClusterIP   10.10.200.218   &amp;lt;none&amp;gt;        10254/TCP                    47s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                       READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/ingress-nginx-controller   1/1     1            1           47s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                                  DESIRED   CURRENT   READY   AGE</span>
<span class="c">#    replicaset.apps/ingress-nginx-controller-7b67846f8f   1         1         1       47s</span>

<span class="nv">$ </span>kubectl describe svc <span class="nt">-n</span> ingress ingress-nginx-controller
<span class="c"># =&gt; Name:                     ingress-nginx-controller</span>
<span class="c">#    Namespace:                ingress</span>
<span class="c">#    Labels:                   app.kubernetes.io/component=controller</span>
<span class="c">#                              app.kubernetes.io/instance=ingress-nginx</span>
<span class="c">#    ...</span>
<span class="c">#    Selector:                 app.kubernetes.io/component=controller,app.kubernetes.io/instance=ingress-nginx,app.kubernetes.io/name=ingress-nginx</span>
<span class="c">#    Type:                     NodePort</span>
<span class="c">#    IP Family Policy:         SingleStack</span>
<span class="c">#    IP Families:              IPv4</span>
<span class="c">#    IP:                       10.10.200.113</span>
<span class="c">#    ...</span>
<span class="c">#    Port:                     http  80/TCP</span>
<span class="c">#    TargetPort:               http/TCP</span>
<span class="c">#    NodePort:                 http  30080/TCP</span>
<span class="c">#    Endpoints:                172.16.0.16:80</span>
<span class="c">#    Port:                     https  443/TCP</span>
<span class="c">#    TargetPort:               https/TCP</span>
<span class="c">#    NodePort:                 https  30443/TCP</span>
<span class="c">#    Endpoints:                172.16.0.16:443</span>
<span class="c">#    ...</span>

<span class="c"># externalTrafficPolicy 설정</span>
<span class="nv">$ </span>kubectl patch svc <span class="nt">-n</span> ingress ingress-nginx-controller <span class="nt">-p</span> <span class="s1">'{"spec":{"externalTrafficPolicy": "Local"}}'</span>
<span class="c"># =&gt; service/ingress-nginx-controller patched</span>

<span class="c"># 기본 nginx conf 파일 확인</span>
<span class="nv">$ </span>kubectl describe cm <span class="nt">-n</span> ingress ingress-nginx-controller
<span class="c"># =&gt; ...</span>
<span class="c">#    Data</span>
<span class="c">#    ====</span>
<span class="c">#    allow-snippet-annotations:</span>
<span class="c">#    ----</span>
<span class="c">#    false</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>deploy/ingress-nginx-controller <span class="nt">-n</span> ingress <span class="nt">-it</span> <span class="nt">--</span> <span class="nb">cat</span> /etc/nginx/nginx.conf
<span class="c"># =&gt; # Configuration checksum: 13054992059071414660</span>
<span class="c">#    # setup custom paths that do not require root access</span>
<span class="c">#    pid /tmp/nginx/nginx.pid;</span>
<span class="c">#    </span>
<span class="c">#    daemon off;</span>
<span class="c">#    worker_processes 4;</span>
<span class="c">#    worker_rlimit_nofile 1047552;</span>
<span class="c">#    worker_shutdown_timeout 240s ;</span>
<span class="c">#    </span>
<span class="c">#    events {</span>
<span class="c">#            multi_accept        on;</span>
<span class="c">#            worker_connections  16384;</span>
<span class="c">#            use                 epoll;</span>
<span class="c">#    }</span>
<span class="c">#    </span>
<span class="c">#    http {</span>
<span class="c">#            lua_package_path &amp;quot;/etc/nginx/lua/?.lua;;&amp;quot;;</span>
<span class="c">#            lua_shared_dict balancer_ewma 10M;</span>
<span class="c">#    ...</span>

<span class="c"># 관련된 정보 확인 : 포드(Nginx 서버), 서비스, 디플로이먼트, 리플리카셋, 컨피그맵, 롤, 클러스터롤, 서비스 어카운트 등</span>
<span class="nv">$ </span>kubectl get all,sa,cm,secret,roles <span class="nt">-n</span> ingress
<span class="c"># =&gt; NAME                                            READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/ingress-nginx-controller-7b67846f8f-jdt65   1/1     Running   0          4m21s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE</span>
<span class="c">#    service/ingress-nginx-controller             NodePort    10.10.200.113   &amp;lt;none&amp;gt;        80:30080/TCP,443:30443/TCP   4m21s</span>
<span class="c">#    service/ingress-nginx-controller-admission   ClusterIP   10.10.200.176   &amp;lt;none&amp;gt;        443/TCP                      4m21s</span>
<span class="c">#    service/ingress-nginx-controller-metrics     ClusterIP   10.10.200.218   &amp;lt;none&amp;gt;        10254/TCP                    4m21s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                       READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/ingress-nginx-controller   1/1     1            1           4m21s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                                  DESIRED   CURRENT   READY   AGE</span>
<span class="c">#    replicaset.apps/ingress-nginx-controller-7b67846f8f   1         1         1       4m21s</span>
<span class="c">#    </span>
<span class="c">#    NAME                           SECRETS   AGE</span>
<span class="c">#    serviceaccount/default         0         4m29s</span>
<span class="c">#    serviceaccount/ingress-nginx   0         4m21s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                 DATA   AGE</span>
<span class="c">#    configmap/ingress-nginx-controller   1      4m21s</span>
<span class="c">#    configmap/kube-root-ca.crt           1      4m30s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                         TYPE                 DATA   AGE</span>
<span class="c">#    secret/ingress-nginx-admission               Opaque               3      4m24s</span>
<span class="c">#    secret/sh.helm.release.v1.ingress-nginx.v1   helm.sh/release.v1   1      4m26s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                           CREATED AT</span>
<span class="c">#    role.rbac.authorization.k8s.io/ingress-nginx   2024-01-01T08:53:04Z</span>
<span class="nv">$ </span>kubectl describe clusterroles ingress-nginx
<span class="nv">$ </span>kubectl get pod,svc,ep <span class="nt">-n</span> ingress <span class="nt">-o</span> wide <span class="nt">-l</span> app.kubernetes.io/component<span class="o">=</span>controller

<span class="c"># 버전 정보 확인</span>
<span class="nv">$ POD_NAMESPACE</span><span class="o">=</span>ingress
<span class="nv">$ POD_NAME</span><span class="o">=</span><span class="si">$(</span>kubectl get pods <span class="nt">-n</span> <span class="nv">$POD_NAMESPACE</span> <span class="nt">-l</span> app.kubernetes.io/name<span class="o">=</span>ingress-nginx <span class="nt">--field-selector</span><span class="o">=</span>status.phase<span class="o">=</span>Running <span class="nt">-o</span> name<span class="si">)</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nv">$POD_NAME</span> <span class="nt">-n</span> <span class="nv">$POD_NAMESPACE</span> <span class="nt">--</span> /nginx-ingress-controller <span class="nt">--version</span>
<span class="c"># =&gt; -------------------------------------------------------------------------------</span>
<span class="c">#    NGINX Ingress controller</span>
<span class="c">#      Release:       v1.11.2</span>
<span class="c">#      Build:         46e76e5916813cfca2a9b0bfdc34b69a0000f6b9</span>
<span class="c">#      Repository:    https://github.com/kubernetes/ingress-nginx</span>
<span class="c">#      nginx version: nginx/1.25.5</span>
<span class="c">#    -------------------------------------------------------------------------------</span>
</code></pre></div></div>

<ul>
  <li>Ingress Controller가 설치되었으며, NodePort로 서비스가 생성된것을 확인할 수 있습니다.</li>
  <li>
    <p>또한 Nginx Ingress Controller의 경우 내부적으로는 일반적인 <strong>nginx 서버가 동일하게 동작</strong>하고, <strong>lua 스크립트를 사용하여 configmap의 설정이 적용/관리</strong>되고 있음을 확인할 수 있습니다.</p>
  </li>
  <li>(옵션) kubectl krew 설치 - <a href="https://krew.sigs.k8s.io/docs/user-guide/setup/install/">링크</a> &amp; ingress-nginx plugin 설치 - <a href="https://kubernetes.github.io/ingress-nginx/kubectl-plugin/">링크</a></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># (참고) 운영체제 확인 : linux</span>
<span class="nv">$ OS</span><span class="o">=</span><span class="s2">"</span><span class="si">$(</span><span class="nb">uname</span> | <span class="nb">tr</span> <span class="s1">'[:upper:]'</span> <span class="s1">'[:lower:]'</span><span class="si">)</span><span class="s2">"</span>
<span class="c"># (참고)  CPU 아키텍처 확인 : amd64</span>
<span class="nv">$ ARCH</span><span class="o">=</span><span class="s2">"</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span> | <span class="nb">sed</span> <span class="nt">-e</span> <span class="s1">'s/x86_64/amd64/'</span> <span class="nt">-e</span> <span class="s1">'s/\(arm\)\(64\)\?.*/\1\2/'</span> <span class="nt">-e</span> <span class="s1">'s/aarch64$/arm64/'</span><span class="si">)</span><span class="s2">"</span>
<span class="c"># (참고)  KREW 지정 : krew-linux_amd64</span>
<span class="nv">$ KREW</span><span class="o">=</span><span class="s2">"krew-</span><span class="k">${</span><span class="nv">OS</span><span class="k">}</span><span class="s2">_</span><span class="k">${</span><span class="nv">ARCH</span><span class="k">}</span><span class="s2">"</span>

<span class="c"># kubectl krew 설치</span>
<span class="c"># curl -fsSLO "https://github.com/kubernetes-sigs/krew/releases/latest/download/${KREW}.tar.gz"</span>
<span class="nv">$ </span>curl <span class="nt">-fsSLO</span> <span class="s2">"https://github.com/kubernetes-sigs/krew/releases/latest/download/krew-linux_amd64.tar.gz"</span> <span class="o">&amp;&amp;</span> <span class="nb">tar </span>zxvf krew-linux_amd64.tar.gz <span class="o">&amp;&amp;</span> ./krew-linux_amd64 <span class="nb">install </span>krew
<span class="nv">$ </span><span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="s2">"</span><span class="k">${</span><span class="nv">KREW_ROOT</span><span class="k">:-</span><span class="nv">$HOME</span><span class="p">/.krew</span><span class="k">}</span><span class="s2">/bin:</span><span class="nv">$PATH</span><span class="s2">"</span>

<span class="c"># 플러그인 정보 업데이트 후 확인 - 링크</span>
<span class="nv">$ </span>kubectl krew update
<span class="nv">$ </span>kubectl krew search

<span class="c"># ingress-nginx 플러그인 설치</span>
<span class="nv">$ </span>kubectl krew <span class="nb">install </span>ingress-nginx
<span class="c"># =&gt; (아쉽게도 옛날 버전이라서 설치가 안 됩니다.) </span>

<span class="c"># ingress-nginx 플러그인 명령어 실행(도움말 출력)</span>
<span class="nv">$ </span>kubectl ingress-nginx

<span class="c"># nginx ctrl 의 backends 설정 정보 출력</span>
<span class="nv">$ </span>kubectl ingress-nginx backends <span class="nt">-n</span> ingress-nginx <span class="nt">--list</span>
<span class="nv">$ </span>kubectl ingress-nginx backends <span class="nt">-n</span> ingress-nginx

<span class="c"># conf 출력</span>
<span class="nv">$ </span>kubectl ingress-nginx conf <span class="nt">-n</span> ingress-nginx
<span class="c">## 특정 호스트(도메인) 설정 확인</span>
<span class="nv">$ </span>kubectl ingress-nginx conf <span class="nt">-n</span> ingress-nginx <span class="nt">--host</span> gasida.cndk.link
<span class="nv">$ </span>kubectl ingress-nginx conf <span class="nt">-n</span> ingress-nginx <span class="nt">--host</span> nasida.cndk.link

<span class="c"># 정보 보기 편함!</span>
<span class="nv">$ </span>kubectl ingress-nginx ingresses
<span class="nv">$ </span>kubectl ingress-nginx ingresses <span class="nt">--all-namespaces</span>
</code></pre></div></div>

<h3 id="인그레스ingress-실습-및-통신-흐름-확인">인그레스(Ingress) 실습 및 통신 흐름 확인</h3>

<ul>
  <li>실습 구성도
    <ul>
      <li>컨트롤플레인 노드에 인그레스 컨트롤러(Nginx) 파드를 생성하고, NodePort 로 외부에 노출합니다.</li>
      <li>인그레스 정책 설정 : Host/Path routing, 실습의 편리를 위해서 도메인 없이 IP로 접속 설정 가능하도록 합니다.</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/2024/kans-3th/w6/20241012_kans_w6_5.png" alt="img.png" /></p>

<p><img src="/assets/2024/kans-3th/w6/20241012_kans_w6_6.png" alt="img_1.png" /></p>

<h4 id="deployment와-service-생성">deployment와 service 생성</h4>

<ul>
  <li>svc1-pod.yml 생성
    <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># svc1-pod.yml</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">deploy1-websrv</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">replicas</span><span class="pi">:</span> <span class="m">1</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">matchLabels</span><span class="pi">:</span>
      <span class="na">app</span><span class="pi">:</span> <span class="s">websrv</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">metadata</span><span class="pi">:</span>
      <span class="na">labels</span><span class="pi">:</span>
        <span class="na">app</span><span class="pi">:</span> <span class="s">websrv</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">containers</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">pod-web</span>
        <span class="na">image</span><span class="pi">:</span> <span class="s">nginx</span>
<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Service</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">svc1-web</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">ports</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">web-port</span>
      <span class="na">port</span><span class="pi">:</span> <span class="m">9001</span>
      <span class="na">targetPort</span><span class="pi">:</span> <span class="m">80</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">app</span><span class="pi">:</span> <span class="s">websrv</span>
  <span class="na">type</span><span class="pi">:</span> <span class="s">ClusterIP</span>
</code></pre></div>    </div>
  </li>
  <li>svc2-pod.yml 생성
    <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># svc2-pod.yml </span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">deploy2-guestsrv</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">replicas</span><span class="pi">:</span> <span class="m">2</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">matchLabels</span><span class="pi">:</span>
      <span class="na">app</span><span class="pi">:</span> <span class="s">guestsrv</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">metadata</span><span class="pi">:</span>
      <span class="na">labels</span><span class="pi">:</span>
        <span class="na">app</span><span class="pi">:</span> <span class="s">guestsrv</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">containers</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">pod-guest</span>
        <span class="na">image</span><span class="pi">:</span> <span class="s">gcr.io/google-samples/kubernetes-bootcamp:v1</span>
        <span class="na">ports</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">containerPort</span><span class="pi">:</span> <span class="m">8080</span>
<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Service</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">svc2-guest</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">ports</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">guest-port</span>
      <span class="na">port</span><span class="pi">:</span> <span class="m">9002</span>
      <span class="na">targetPort</span><span class="pi">:</span> <span class="m">8080</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">app</span><span class="pi">:</span> <span class="s">guestsrv</span>
  <span class="na">type</span><span class="pi">:</span> <span class="s">NodePort</span>
</code></pre></div>    </div>
  </li>
  <li>svc3-pod.yml 생성
    <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># svc3-pod.yml</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">deploy3-adminsrv</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">replicas</span><span class="pi">:</span> <span class="m">3</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">matchLabels</span><span class="pi">:</span>
      <span class="na">app</span><span class="pi">:</span> <span class="s">adminsrv</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">metadata</span><span class="pi">:</span>
      <span class="na">labels</span><span class="pi">:</span>
        <span class="na">app</span><span class="pi">:</span> <span class="s">adminsrv</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">containers</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">pod-admin</span>
        <span class="na">image</span><span class="pi">:</span> <span class="s">k8s.gcr.io/echoserver:1.5</span>
        <span class="na">ports</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">containerPort</span><span class="pi">:</span> <span class="m">8080</span>
<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Service</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">svc3-admin</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">ports</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">admin-port</span>
      <span class="na">port</span><span class="pi">:</span> <span class="m">9003</span>
      <span class="na">targetPort</span><span class="pi">:</span> <span class="m">8080</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">app</span><span class="pi">:</span> <span class="s">adminsrv</span>
</code></pre></div>    </div>
  </li>
  <li>생성 및 확인
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 모니터링</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> <span class="s1">'kubectl get ingress,svc,ep,pod -owide'</span>
  
<span class="c"># 생성</span>
<span class="nv">$ </span>kubectl taint nodes k3s-m <span class="nv">role</span><span class="o">=</span>controlplane:NoSchedule
<span class="c"># &lt;span style="color: green;"&gt;&lt;/span&gt;</span>
  
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> svc1-pod.yml,svc2-pod.yml,svc3-pod.yml
<span class="c"># =&gt; deployment.apps/deploy1-websrv created</span>
<span class="c">#    service/svc1-web created</span>
<span class="c">#    deployment.apps/deploy2-guestsrv created</span>
<span class="c">#    service/svc2-guest created</span>
<span class="c">#    deployment.apps/deploy3-adminsrv created</span>
<span class="c">#    service/svc3-admin created</span>
  
<span class="c"># 확인 : svc1, svc3 은 ClusterIP 로 클러스터 외부에서는 접속할 수 없다 &gt;&gt; Ingress 는 연결 가능!</span>
<span class="nv">$ </span>kubectl get pod,svc,ep
<span class="c"># =&gt; NAME                                    READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/deploy1-websrv-5c6b88bd77-ht5hl     1/1     Running   0          34s</span>
<span class="c">#    pod/deploy2-guestsrv-649875f78b-8wh8r   1/1     Running   0          34s</span>
<span class="c">#    pod/deploy2-guestsrv-649875f78b-jcvrf   1/1     Running   0          34s</span>
<span class="c">#    pod/deploy3-adminsrv-7c8f8b8c87-4mzv7   1/1     Running   0          34s</span>
<span class="c">#    pod/deploy3-adminsrv-7c8f8b8c87-4sqmh   1/1     Running   0          34s</span>
<span class="c">#    pod/deploy3-adminsrv-7c8f8b8c87-ztltl   1/1     Running   0          34s</span>
<span class="c">#    </span>
<span class="c">#    NAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span>
<span class="c">#    service/kubernetes   ClusterIP   10.10.200.1     &amp;lt;none&amp;gt;        443/TCP          5h52m</span>
<span class="c">#    service/svc1-web     ClusterIP   10.10.200.141   &amp;lt;none&amp;gt;        9001/TCP         34s</span>
<span class="c">#    service/svc2-guest   NodePort    10.10.200.60    &amp;lt;none&amp;gt;        9002:30901/TCP   34s</span>
<span class="c">#    service/svc3-admin   ClusterIP   10.10.200.171   &amp;lt;none&amp;gt;        9003/TCP         34s</span>
<span class="c">#    &lt;span style="color: green;"&gt;# ingress는 pod 정보로 바로 접근 가능하므로 서비스가 ClusterIP이든 NodePort 타입이든 관계 없습니다.&lt;/span&gt;</span>
<span class="c">#    </span>
<span class="c">#    NAME                   ENDPOINTS                                         AGE</span>
<span class="c">#    endpoints/kubernetes   192.168.10.10:6443                                5h52m</span>
<span class="c">#    endpoints/svc1-web     172.16.1.8:80                                     34s</span>
<span class="c">#    endpoints/svc2-guest   172.16.2.8:8080,172.16.3.7:8080                   34s</span>
<span class="c">#    endpoints/svc3-admin   172.16.1.7:8080,172.16.2.9:8080,172.16.3.8:8080   34s</span>
</code></pre></div>    </div>
  </li>
</ul>

<h4 id="인그레스정책-생성">인그레스(정책) 생성</h4>

<p><img src="/assets/2024/kans-3th/w6/20241012_kans_w6_7.png" alt="img.png" class="image-center" />
<em class="image-caption">ingress 정책 적용 구조 (<a href="https://kschoi728.tistory.com/266">출처</a>)</em></p>

<ul>
  <li>ingress1.yml 파일 생성</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh">&gt; ingress1.yml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ingress-1
  annotations:
    #nginx.ingress.kubernetes.io/upstream-hash-by: "true"
spec:
  ingressClassName: nginx
  rules:
  - http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: svc1-web
            port:
              number: 80
      - path: /guest
        pathType: Prefix
        backend:
          service:
            name: svc2-guest
            port:
              number: 8080
      - path: /admin
        pathType: Prefix
        backend:
          service:
            name: svc3-admin
            port:
              number: 8080
</span><span class="no">EOT
</span></code></pre></div></div>

<ul>
  <li>ingress 정책 생성</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 모니터링</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> <span class="s1">'kubectl get ingress,svc,ep,pod -owide'</span>

<span class="c"># 생성</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> ingress1.yml
<span class="c"># =&gt; ingress.networking.k8s.io/ingress-1 created</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get ingress
<span class="c"># =&gt; NAME        CLASS   HOSTS   ADDRESS   PORTS   AGE</span>
<span class="c">#    ingress-1   nginx   *                 80      11s</span>
<span class="nv">$ </span>kubectl describe ingress ingress-1
<span class="c"># =&gt; ...</span>
<span class="c">#    Rules:</span>
<span class="c">#      Host        Path  Backends</span>
<span class="c">#      ----        ----  --------</span>
<span class="c">#      *</span>
<span class="c">#                  /        svc1-web:80 ()</span>
<span class="c">#                  /guest   svc2-guest:8080 ()</span>
<span class="c">#                  /admin   svc3-admin:8080 ()</span>
<span class="c">#    ...</span>

<span class="c"># 설정이 반영된 nginx conf 파일 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>deploy/ingress-nginx-controller <span class="nt">-n</span> ingress <span class="nt">-it</span> <span class="nt">--</span> <span class="nb">cat</span> /etc/nginx/nginx.conf
<span class="nv">$ </span>kubectl <span class="nb">exec </span>deploy/ingress-nginx-controller <span class="nt">-n</span> ingress <span class="nt">-it</span> <span class="nt">--</span> <span class="nb">cat</span> /etc/nginx/nginx.conf | <span class="nb">grep</span> <span class="s1">'location /'</span> <span class="nt">-A5</span>
<span class="c"># =&gt;      location /guest/ {</span>
<span class="c">#    </span>
<span class="c">#         set $namespace      &amp;quot;default&amp;quot;;</span>
<span class="c">#         set $ingress_name   &amp;quot;ingress-1&amp;quot;;</span>
<span class="c">#         set $service_name   &amp;quot;svc2-guest&amp;quot;;</span>
<span class="c">#         set $service_port   &amp;quot;8080&amp;quot;;</span>
<span class="c">#    --</span>
<span class="c">#         location /admin/ {</span>
<span class="c">#    </span>
<span class="c">#         set $namespace      &amp;quot;default&amp;quot;;</span>
<span class="c">#         set $ingress_name   &amp;quot;ingress-1&amp;quot;;</span>
<span class="c">#         set $service_name   &amp;quot;svc3-admin&amp;quot;;</span>
<span class="c">#         set $service_port   &amp;quot;8080&amp;quot;;</span>
<span class="c">#    --</span>
<span class="c">#         location / {</span>
<span class="c">#    </span>
<span class="c">#         set $namespace      &amp;quot;default&amp;quot;;</span>
<span class="c">#         set $ingress_name   &amp;quot;ingress-1&amp;quot;;</span>
<span class="c">#         set $service_name   &amp;quot;svc1-web&amp;quot;;</span>
<span class="c">#         set $service_port   &amp;quot;80&amp;quot;;</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<h4 id="ingress를-통한-내부-접속">ingress를 통한 내부 접속</h4>

<ul>
  <li>
    <p>Nginx ingress controller를 통해 접속시 서비스는 파드의 엔드포인트의 정보만 참조되고, 서비스를 거치지 않고 바로 파드로 전달됩니다.
<img src="/assets/2024/kans-3th/w6/20241012_kans_w6_8.png" alt="img.png" class="w-80 image-center" />
<em class="image-caption">인그레스 접속 경로(서비스 Bypass) : Ingress → 애플리케이션(Deploy, Pod 등)</em></p>
  </li>
  <li>참고 : URI(Uniform Resource Identifier)는 RFC 3986에 정의된 통합 자원 식별자로, 흔히 사용되는 URL(Uniform Resource Locator)과 URN(Uniform Resource Name)을 포함합니다.
    <ul>
      <li>Request URI는 서버 주소나 파일이름, 파라미터 등 다양한 리소스를 식별하기 위해 사용되는 문자열입니다.</li>
      <li>절대 URI(absolute URI)는 스키마와 호스트를 포함한 완전한 URI를 의미하며, 상대 URI(relative URI)는 스키마와 호스트를 포함하지 않고 현재 위치에서 상대적인 위치를 기록한 URI를 의미합니다.
        <ul>
          <li>URI의 구조는 아래와 같습니다.
<img src="/assets/2024/kans-3th/w6/20241012_kans_w6_9.png" alt="img.png" class="image-center" />
<em class="image-caption">책 ‘그림으로 공부하는 TCP/IP 구조’ 중 발췌</em></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>참고 : X-Forwarded-For 헤더, X-Forwarded-Proto 헤더
    <ul>
      <li>X-Forwarded-For 헤더는 송신지 IP 주소가 변환되는 환경(장비, 서버, 솔루션 등)에서, 변환 전 송신지(클라이언트) IP 주소를 저장하는 헤더입니다.
        <ul>
          <li>여러 장비나 솔루션을 거칠 경우 <code class="language-plaintext highlighter-rouge">,</code>로 구분하여 여러 건이 넘어올 수도 있습니다. 그럴 경우 가장 왼쪽 것이 클라이언트 IP이고, 오른쪽으로 갈 수록 나중에 처리된 장비/솔루션의 IP가 됩니다.</li>
        </ul>
      </li>
      <li>X-Forwarded-Proto 헤더는 변환 전 프로토콜을 저장합니다. (예. SSL Offload 환경에서 서버 측에서 클라이언트가 요청 시 사용한 원래 프로토콜을 확인)</li>
      <li>이러한 헤더는 클라이언트의 IP 주소를 확인하거나, 프로토콜을 확인하는 등의 용도로 사용되며, 어플리케이션에서 NodePort나 LoadBalancer를 통해서 접속되었을때도 원래의 클라이언트의 IP를 확인할 수 있게 해줍니다. (<code class="language-plaintext highlighter-rouge">externalTrafficPolicy: Local</code>를 사용할 필요가 줄어듭니다!)</li>
      <li>원래의 IP를 가져오는 방법은 다음의 방법들이 있습니다.
        <ul>
          <li>Http request header 중 다음 값들에서 원래의 IP 찾기
            <ol>
              <li>X-Forwarded-For : HTTP RFC 표준에는 없지만 사실상 표준!!!</li>
              <li>Proxy-Client-IP : 특정 웹 어플리케이션에서 사용 (예. WebLogic Connector - mod_wl)</li>
              <li>WL-Proxy-Client-IP : 특정 웹 어플리케이션에서 사용 (예. WebLogic Connector - mod_wl)</li>
              <li>CLIENT_IP</li>
            </ol>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>인그레스(Nginx 인그레스 컨트롤러)를 통한 접속(HTTP 인입)을 확인해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># (krew 플러그인 설치 시) 인그레스 정책 확인</span>
<span class="c"># $ kubectl ingress-nginx ingresses</span>
<span class="c"># INGRESS NAME   HOST+PATH   ADDRESSES       TLS   SERVICE      SERVICE PORT   ENDPOINTS</span>
<span class="c"># ingress-1      /           192.168.10.10   NO    svc1-web     80             1</span>
<span class="c"># ingress-1      /guest      192.168.10.10   NO    svc2-guest   8080           2</span>
<span class="c"># ingress-1      /admin      192.168.10.10   NO    svc3-admin   8080           3</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get ingress
<span class="c"># =&gt; NAME        CLASS   HOSTS   ADDRESS         PORTS   AGE</span>
<span class="c">#    ingress-1   nginx   *       10.10.200.113   80      18m</span>
 
<span class="nv">$ </span>kubectl describe ingress ingress-1 | <span class="nb">sed</span> <span class="nt">-n</span> <span class="s2">"5, </span><span class="se">\$</span><span class="s2">p"</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    Rules:</span>
<span class="c">#      Host        Path  Backends</span>
<span class="c">#      ----        ----  --------</span>
<span class="c">#      *</span>
<span class="c">#                  /        svc1-web:80 ()</span>
<span class="c">#                  /guest   svc2-guest:8080 ()</span>
<span class="c">#                  /admin   svc3-admin:8080 ()</span>
<span class="c">#    ...</span>

<span class="c"># 접속 로그 확인 : kubetail 설치되어 있음 - 출력되는 nginx 의 로그의 IP 확인</span>
<span class="nv">$ </span>kubetail <span class="nt">-n</span> ingress <span class="nt">-l</span> app.kubernetes.io/component<span class="o">=</span>controller

<span class="nt">-------------------------------</span>
<span class="c"># 자신의 집 PC에서 인그레스를 통한 접속 : 각각 </span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"Ingress1 sv1-web URL = http://</span><span class="si">$(</span>curl <span class="nt">-s</span> ipinfo.io/ip<span class="si">)</span><span class="s2">:30080"</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"Ingress1 sv2-guest URL = http://</span><span class="si">$(</span>curl <span class="nt">-s</span> ipinfo.io/ip<span class="si">)</span><span class="s2">:30080/guest"</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"Ingress1 sv3-admin URL = http://</span><span class="si">$(</span>curl <span class="nt">-s</span> ipinfo.io/ip<span class="si">)</span><span class="s2">:30080/admin"</span>

<span class="c"># svc1-web 접속</span>
<span class="c"># $ MYIP=&lt;EC2 공인 IP 또는 컨트롤플레인 node ip&gt;</span>
<span class="nv">$ MYIP</span><span class="o">=</span>192.168.10.10
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$MYIP</span>:30080
<span class="c"># =&gt; ...</span>
<span class="c">#    &amp;lt;h1&amp;gt;Welcome to nginx!&amp;lt;/h1&amp;gt;</span>
<span class="c">#    &amp;lt;p&amp;gt;If you see this page, the nginx web server is successfully installed and</span>
<span class="c">#    working. Further configuration is required.&amp;lt;/p&amp;gt;</span>
<span class="c">#    </span>
<span class="c">#    &amp;lt;p&amp;gt;For online documentation and support please refer to</span>
<span class="c">#    &amp;lt;a href=&amp;quot;http://nginx.org/&amp;quot;&amp;gt;nginx.org&amp;lt;/a&amp;gt;.&amp;lt;br/&amp;gt;</span>
<span class="c">#    Commercial support is available at</span>
<span class="c">#    &amp;lt;a href=&amp;quot;http://nginx.com/&amp;quot;&amp;gt;nginx.com&amp;lt;/a&amp;gt;.&amp;lt;/p&amp;gt;</span>
<span class="c">#    </span>
<span class="c">#    &amp;lt;p&amp;gt;&amp;lt;em&amp;gt;Thank you for using nginx.&amp;lt;/em&amp;gt;&amp;lt;/p&amp;gt;</span>
<span class="c">#    ...</span>

<span class="c"># svc2-guest 접속</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$MYIP</span>:30080/guest
<span class="c"># =&gt; Hello Kubernetes bootcamp! | Running on: deploy2-guestsrv-649875f78b-jcvrf | v=1</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$MYIP</span>:30080/guest <span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;      51 Hello Kubernetes bootcamp! | Running on: deploy2-guestsrv-649875f78b-8wh8r | v=1</span>
<span class="c">#         49 Hello Kubernetes bootcamp! | Running on: deploy2-guestsrv-649875f78b-jcvrf | v=1</span>

<span class="c"># svc3-admin 접속 &gt; 기본적으로 Nginx 는 라운드로빈 부하분산 알고리즘을 사용 &gt;&gt; Client_address 와 XFF 주소는 어떤 주소인가요?</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$MYIP</span>:30080/admin
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$MYIP</span>:30080/admin | egrep <span class="s1">'(client_address|x-forwarded-for)'</span>
<span class="c"># =&gt;  client_address=172.16.0.16</span>
<span class="c">#     x-forwarded-for=172.16.0.1</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$MYIP</span>:30080/admin | <span class="nb">grep </span>Hostname <span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;      34 Hostname: deploy3-adminsrv-7c8f8b8c87-4sqmh</span>
<span class="c">#         33 Hostname: deploy3-adminsrv-7c8f8b8c87-ztltl</span>
<span class="c">#         33 Hostname: deploy3-adminsrv-7c8f8b8c87-4mzv7</span>

<span class="c"># (옵션) 디플로이먼트의 파드 갯수를 증가/감소 설정 후 접속 테스트 해보자</span>
<span class="nv">$ </span>kubectl scale deployment deploy3-adminsrv <span class="nt">--replicas</span> 2   <span class="c"># svc3-admin의 파드 갯수를 2개로 감소</span>
<span class="c"># =&gt; deployment.apps/deploy3-adminsrv scaled</span>
<span class="nv">$ </span>kubectl get deploy deploy3-adminsrv
<span class="c"># =&gt; NAME               READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deploy3-adminsrv   2/2     2            2           80m</span>
<span class="c"># &lt;span style="color: green;"&gt;파드수가 3개 =&gt; 2개로 줄었습니다.&lt;/span&gt;</span>
 
<span class="c"># 접속 테스트</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$MYIP</span>:30080/admin | <span class="nb">grep </span>Hostname <span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;      50 Hostname: deploy3-adminsrv-7c8f8b8c87-4sqmh</span>
<span class="c">#         50 Hostname: deploy3-adminsrv-7c8f8b8c87-4mzv7</span>
<span class="c"># &lt;span style="color: green;"&gt;2개로 줄어든 파드수만큼 2개의 파드에 부하가 분산 되는것을 확인하였습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<ul>
  <li>노드에서 패킷 캡쳐 확인 : flannel vxlan의 파드간 통신시 IP정보 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># ngrep을 이용해 패킷 캡쳐</span>
<span class="nv">$ </span>ngrep <span class="nt">-tW</span> byline <span class="nt">-d</span> enp0s8 <span class="s1">''</span> udp port 8472 or tcp port 80
<span class="c"># =&gt; interface: enp0s8 (192.168.10.0/255.255.255.0)</span>
<span class="c">#    filter: ( udp port 8472 or tcp port 80 ) and ((ip || ip6) || (vlan &amp;amp;&amp;amp; (ip || ip6)))</span>
<span class="c">#    #</span>
<span class="c">#    U 2024/10/12 12:42:39.071289 192.168.10.10:39828 -&amp;gt; 192.168.10.102:8472 #1</span>
<span class="c">#    .........(Ce...!w.....E..&amp;lt;..@.?............|.P...........\...........</span>
<span class="c">#    d9?.........</span>
<span class="c">#    #</span>
<span class="c">#    U 2024/10/12 12:42:39.072521 192.168.10.102:37126 -&amp;gt; 192.168.10.10:8472 #2</span>
<span class="c">#    .........!w....(Ce....E..&amp;lt;..@.?............P.|(3c@.......4.y.........</span>
<span class="c">#    ....d9?.....</span>
<span class="c">#    #</span>
<span class="c">#    U 2024/10/12 12:42:39.072734 192.168.10.10:39828 -&amp;gt; 192.168.10.102:8472 #3</span>
<span class="c">#    .........(Ce...!w.....E..4..@.?............|.P....(3cA.....K.....</span>
<span class="c">#    d9?.....</span>
<span class="c">#    #</span>
<span class="c">#    U 2024/10/12 12:42:39.072855 192.168.10.10:39828 -&amp;gt; 192.168.10.102:8472 #4</span>
<span class="c">#    .........(Ce...!w.....E..c..@.?..Y.........|.P....(3cA...........</span>
<span class="c">#    d9?.....GET / HTTP/1.1.</span>
<span class="c">#    Host: localhost:30080.</span>
<span class="c">#    X-Request-ID: e8aa4e70150ae6ae8de5a34637e294e6.</span>
<span class="c">#    X-Real-IP: 172.16.0.1.</span>
<span class="c">#    X-Forwarded-For: 172.16.0.1.</span>
<span class="c">#    X-Forwarded-Host: localhost:30080.</span>
<span class="c">#    X-Forwarded-Port: 80.</span>
<span class="c">#    X-Forwarded-Proto: http.</span>
<span class="c">#    X-Forwarded-Scheme: http.</span>
<span class="c">#    X-Scheme: http.</span>
<span class="c">#    User-Agent: curl/7.81.0.</span>
<span class="c">#    Accept: */*.</span>
<span class="c">#    ...</span>

<span class="c"># tcp dump를 이용해 vxlan(udp 8472) 통신 확인</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> enp0s8 udp port 8472 <span class="nt">-nn</span>
<span class="c"># =&gt; tcpdump: verbose output suppressed, use -v[v]... for full protocol decode</span>
<span class="c">#    listening on enp0s8, link-type EN10MB (Ethernet), snapshot length 262144 bytes</span>
<span class="c">#    12:42:13.504948 IP 192.168.10.10.55617 &amp;gt; 192.168.10.102.8472: OTV, flags [I] (0x08), overlay 0, instance 1</span>
<span class="c">#    IP 172.16.0.16.57692 &amp;gt; 172.16.1.8.80: Flags [S], seq 911277209, win 64860, options [mss 1410,sackOK,TS val 1681447926 ecr 0,nop,wscale 7], length 0</span>
<span class="c">#    ...</span>

<span class="c"># vethY는 각자 k3s-s 의 가장 마지막 veth 를 지정</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> vethY tcp port 8080 <span class="nt">-nn</span>
<span class="c"># =&gt; tcpdump: verbose output suppressed, use -v[v]... for full protocol decode</span>
<span class="c">#    listening on veth5ae3dd58, link-type EN10MB (Ethernet), snapshot length 262144 bytes</span>
<span class="c">#    12:44:11.609334 IP 172.16.0.16.41240 &amp;gt; 172.16.2.9.8080: Flags [S], seq 1593288127, win 64860, options [mss 1410,sackOK,TS val 3487210526 ecr 0,nop,wscale 7], length 0</span>
<span class="c">#    12:44:11.610875 IP 172.16.2.9.8080 &amp;gt; 172.16.0.16.41240: Flags [S.], seq 1820942288, ack 1593288128, win 64308, options [mss 1410,sackOK,TS val 257720908 ecr 3487210526,nop,wscale 7], length 0</span>
<span class="nv">$ </span>tcpdump <span class="nt">-i</span> vethY tcp port 8080 <span class="nt">-w</span> /tmp/ingress-nginx.pcap

<span class="nt">---</span> 

<span class="c"># 다른 터미널에서 svc3-admin 접속</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$MYIP</span>:30080/admin 

<span class="nt">---</span>

<span class="c"># 자신의 PC에서 k3s-s EC2 공인 IP로 pcap 다운로드</span>
<span class="c"># $ scp ubuntu@&lt;k3s-s EC2 공인 IP&gt;:/tmp/ingress-nginx.pcap ~/Downloads</span>
<span class="nv">$ </span>scp ubuntu@43.202.1.177:/tmp/ingress-nginx.pcap ~/Downloads
</code></pre></div></div>

<p><img src="/assets/2024/kans-3th/w6/20241012_kans_w6_10.png" alt="20241012_kans_w6_10.png" class="image-center" />
<em class="image-caption">인그레스를 통한 접속 흐름</em></p>

<ul>
  <li>패킷 캡쳐 결과 ingress controller에서 파드의 ip로 바로 접속 됨을 확인할 수 있었습니다.</li>
  <li>
    <p>또한, flannel CNI를 사용하기 때문에 vxlan을 통해 통신이 이루어지고 있음을 확인할 수 있습니다.</p>
  </li>
  <li>Nginx 파드가 endpoint 정보 등을 모니터링 가능한 이유는 클러스터롤과 롤(엔드포인트 list, watch)를 바인딩된 서비스 어카운트를 파드가 사용하기 때문입니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl describe deployments.apps <span class="nt">-n</span> ingress ingress-nginx-controller | <span class="nb">grep</span> <span class="s1">'Service Account'</span>
<span class="c"># =&gt;   Service Account:  ingress-nginx</span>

<span class="nv">$ </span>kubectl get <span class="nt">-n</span> ingress clusterrolebindings ingress-nginx
<span class="c"># =&gt; NAME            ROLE                        AGE</span>
<span class="c">#    ingress-nginx   ClusterRole/ingress-nginx   4h9m</span>

<span class="nv">$ </span>kubectl get <span class="nt">-n</span> ingress rolebindings ingress-nginx
<span class="c"># =&gt; NAME            ROLE                 AGE</span>
<span class="c">#    ingress-nginx   Role/ingress-nginx   4h9m</span>

<span class="nv">$ </span>kubectl describe clusterrole ingress <span class="nt">-n</span> ingress | egrep <span class="s1">'(Verbs|endpoints)'</span>
<span class="c"># =&gt;   Resources                           Non-Resource URLs  Resource Names  Verbs</span>
<span class="c">#      endpointslices.discovery.k8s.io     []                 []              [list watch get]</span>
<span class="c">#      endpoints                           []                 []              [list watch]</span>

<span class="nv">$ </span>kubectl describe roles ingress-nginx <span class="nt">-n</span> ingress | egrep <span class="s1">'(Verbs|endpoints)'</span>
<span class="c"># =&gt;   Resources                           Non-Resource URLs  Resource Names          Verbs</span>
<span class="c">#      endpoints                           []                 []                      [get list watch]</span>
<span class="c">#      endpointslices.discovery.k8s.io     []                 []                      [list watch get]</span>
</code></pre></div></div>

<h4 id="패킷-분석">패킷 분석</h4>

<ul>
  <li>클러스터 외부에서 접속 후 내부로 접속하는 패킷을 분석해보겠습니다.</li>
  <li>위의 실습과 동일하지만 veth에서 8080을 캡쳐하고 노드의 nic에서 8472 (vxnet)를 캡쳐하여 병합(merge)하여 확인하였습니다.</li>
  <li>또한, 클라이언트의 IP 주소를 확인하기 위해 X-Forwarded-For 헤더를 확인하였습니다.</li>
</ul>

<p><img src="/assets/2024/kans-3th/w6/20241012_kans_w6_11.png" alt="20241012_kans_w6_11.png" /></p>

<ul>
  <li>위의 그림과 같이 프로토콜의 정보를 그림으로 보려면 아래와 같이 환경설정에서 Appearance &gt; Layout에서 Pane 3에 
“Packet Diagram”을 선택하시면 됩니다.
<img src="/assets/2024/kans-3th/w6/20241012_kans_w6_12.png" alt="20241012_kans_w6_12.png" class="w-80 image-center" /></li>
</ul>

<h4 id="nginx-분산-알고리즘-변경">Nginx 분산 알고리즘 변경</h4>

<ul>
  <li>nginx는 기본 RR(Round Robin) 방식으로 부하분산을 수행하지만, IP-Hash나 Session Cookie 설정으로 변경할 수 있습니다.</li>
  <li>특히 IP-Hash 나 Session Cookie를 사용하면 각 클라이언트에서 대상 파드를 고정할 수 있습니다.</li>
  <li>이를 변경하기 위해서는 <code class="language-plaintext highlighter-rouge">nginx.ingress.kubernetes.io/upstream-hash-by</code> annotation을 사용하여 변경하여야 하는데 실습을 통해 확인해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># mypc</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$MYIP</span>:30080/admin | <span class="nb">grep </span>Hostname <span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;   51 Hostname: deploy3-adminsrv-7c8f8b8c87-4sqmh</span>
<span class="c">#      49 Hostname: deploy3-adminsrv-7c8f8b8c87-4mzv7</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 <span class="nv">$MYIP</span>:30080/admin | <span class="nb">grep </span>Hostname <span class="p">;</span> <span class="nb">date</span> <span class="s2">"+%Y-%m-%d %H:%M:%S"</span> <span class="p">;</span> <span class="nb">echo</span> <span class="s2">"--------------"</span> <span class="p">;</span> <span class="nb">sleep </span>1<span class="p">;</span> <span class="k">done</span>

<span class="c"># 아래 ingress 설정 중 IP-Hash 설정 &gt; # 주석 제거</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'s/#nginx.ingress/nginx.ingress/g'</span> ingress1.yml
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> ingress1.yml
<span class="c"># =&gt; ingress.networking.k8s.io/ingress-1 configured</span>

<span class="c"># 접속 확인</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$MYIP</span>:30080/admin | <span class="nb">grep </span>Hostname <span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;  100 Hostname: deploy3-adminsrv-7c8f8b8c87-4sqmh</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 <span class="nv">$MYIP</span>:30080/admin | <span class="nb">grep </span>Hostname <span class="p">;</span> <span class="nb">date</span> <span class="s2">"+%Y-%m-%d %H:%M:%S"</span> <span class="p">;</span> <span class="nb">echo</span> <span class="s2">"--------------"</span> <span class="p">;</span> <span class="nb">sleep </span>1<span class="p">;</span> <span class="k">done</span>

<span class="c"># 다시 원복(라운드 로빈) &gt; # 주석 추가</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'s/nginx.ingress/#nginx.ingress/g'</span> ingress1.yml
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> ingress1.yml
<span class="c"># =&gt; ingress.networking.k8s.io/ingress-1 configured</span>

<span class="c"># 접속 확인</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$MYIP</span>:30080/admin | <span class="nb">grep </span>Hostname <span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;   50 Hostname: deploy3-adminsrv-7c8f8b8c87-4sqmh</span>
<span class="c">#      50 Hostname: deploy3-adminsrv-7c8f8b8c87-4mzv7</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 <span class="nv">$MYIP</span>:30080/admin | <span class="nb">grep </span>Hostname <span class="p">;</span> <span class="nb">date</span> <span class="s2">"+%Y-%m-%d %H:%M:%S"</span> <span class="p">;</span> <span class="nb">echo</span> <span class="s2">"--------------"</span> <span class="p">;</span> <span class="nb">sleep </span>1<span class="p">;</span> <span class="k">done</span>
</code></pre></div></div>

<ul>
  <li>ip-hash 설정을 통해 클라이언트의 IP 주소를 해싱하여 특정 파드로 접속되는 것을 확인할 수 있습니다.</li>
  <li>오브젝트 삭제</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl delete deployments,svc,ingress <span class="nt">--all</span>
</code></pre></div></div>

<h4 id="host-기반-라우팅">Host 기반 라우팅</h4>

<ul>
  <li>ingress2.yml 파일 생성</li>
</ul>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">networking.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Ingress</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">ingress-2</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">ingressClassName</span><span class="pi">:</span> <span class="s">nginx</span>
  <span class="na">rules</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">host</span><span class="pi">:</span> <span class="s">kans.com</span>
    <span class="na">http</span><span class="pi">:</span>
      <span class="na">paths</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">path</span><span class="pi">:</span> <span class="s">/</span>
        <span class="na">pathType</span><span class="pi">:</span> <span class="s">Prefix</span>
        <span class="na">backend</span><span class="pi">:</span>
          <span class="na">service</span><span class="pi">:</span>
            <span class="na">name</span><span class="pi">:</span> <span class="s">svc3-admin</span>
            <span class="na">port</span><span class="pi">:</span>
              <span class="na">number</span><span class="pi">:</span> <span class="m">8080</span>
  <span class="pi">-</span> <span class="na">host</span><span class="pi">:</span> <span class="s2">"</span><span class="s">*.kans.com"</span>
    <span class="na">http</span><span class="pi">:</span>
      <span class="na">paths</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">path</span><span class="pi">:</span> <span class="s">/echo</span>
        <span class="na">pathType</span><span class="pi">:</span> <span class="s">Prefix</span>
        <span class="na">backend</span><span class="pi">:</span>
          <span class="na">service</span><span class="pi">:</span>
            <span class="na">name</span><span class="pi">:</span> <span class="s">svc3-admin</span>
            <span class="na">port</span><span class="pi">:</span>
              <span class="na">number</span><span class="pi">:</span> <span class="m">8080</span>
</code></pre></div></div>

<ul>
  <li>ingress 정책 생성</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 터미널1</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> <span class="s1">'kubectl get ingresses,svc,ep,pod -owide'</span>

<span class="c"># 도메인 변경</span>
<span class="c"># $ MYDOMAIN1=&lt;각자 자신의 닉네임의 도메인&gt; 예시) gasida.com</span>
<span class="nv">$ MYDOMAIN1</span><span class="o">=</span>sweetlittlebird.com
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/kans.com/</span><span class="nv">$MYDOMAIN1</span><span class="s2">/g"</span> ingress2.yaml

<span class="c"># 생성</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> ingress2.yaml,svc3-pod.yaml
<span class="c"># =&gt; ingress.networking.k8s.io/ingress-2 created</span>
<span class="c">#    deployment.apps/deploy3-adminsrv created</span>
<span class="c">#    service/svc3-admin created</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get ingress
<span class="c"># =&gt; NAME        CLASS   HOSTS                                       ADDRESS         PORTS   AGE</span>
<span class="c">#    ingress-2   nginx   sweetlittlebird.com,*.sweetlittlebird.com   10.10.200.113   80      14s</span>
<span class="nv">$ </span>kubectl describe ingress ingress-2
<span class="nv">$ </span>kubectl describe ingress ingress-2 | <span class="nb">sed</span> <span class="nt">-n</span> <span class="s2">"5, </span><span class="se">\$</span><span class="s2">p"</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    Default backend:  &amp;lt;default&amp;gt;</span>
<span class="c">#    Rules:</span>
<span class="c">#      Host                   Path    Backends</span>
<span class="c">#      ----                   ----    --------</span>
<span class="c">#      sweetlittlebird.com    /       svc3-admin:8080 ()</span>
<span class="c">#      *.sweetlittlebird.com  /echo   svc3-admin:8080 ()</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<ul>
  <li>Host 기반 라우팅을 통해 서비스에 접속해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 로그 모니터링</span>
<span class="nv">$ </span>kubetail <span class="nt">-n</span> ingress <span class="nt">-l</span> app.kubernetes.io/component<span class="o">=</span>controller
<span class="c"># =&gt; Will tail 1 logs...</span>
<span class="c">#    ingress-nginx-controller-7b67846f8f-jdt65</span>
<span class="c"># =&gt; [ingress-nginx-controller-7b67846f8f-jdt65] 192.168.10.1 - - [01/Jan/2024:13:52:42 +0000] &amp;quot;GET / HTTP/1.1&amp;quot; 200 677 &amp;quot;-&amp;quot; &amp;quot;curl/8.5.0&amp;quot; 88 0.002 [default-svc3-admin-8080] [] 172.16.3.10:8080 852 0.002 200 f22ddba305f55138796fc866f7416890</span>
<span class="c">#    [ingress-nginx-controller-7b67846f8f-jdt65] 192.168.10.1 - - [01/Jan/2024:13:53:47 +0000] &amp;quot;GET /admin HTTP/1.1&amp;quot; 200 687 &amp;quot;-&amp;quot; &amp;quot;curl/8.5.0&amp;quot; 93 0.002 [default-svc3-admin-8080] [] 172.16.2.10:8080 863 0.002 200 966f7a55060f1497eed20818d4bef890</span>
<span class="c">#    ...</span>

<span class="nt">------------</span>
<span class="c"># 자신의 PC 에서 접속 테스트</span>
<span class="c"># svc3-admin 접속 &gt; 결과 확인 : 왜 접속이 되지 않는가? HTTP 헤더에 Host 필드를 잘 확인해보자!</span>
<span class="nv">$ </span>curl <span class="nv">$MYIP</span>:30080 <span class="nt">-v</span>
<span class="nv">$ </span>curl <span class="nv">$MYIP</span>:30080/echo <span class="nt">-v</span>

<span class="c"># mypc에서 접속을 위한 설정</span>
<span class="c">## /etc/hosts 수정 : 도메인 이름으로 접속하기 위해서 변수 지정</span>
<span class="c">## 윈도우 C:\Windows\System32\drivers\etc\hosts</span>
<span class="c">## 맥 sudo vim /etc/hosts</span>
<span class="c"># $ MYDOMAIN1=&lt;각자 자신의 닉네임의 도메인&gt;</span>
<span class="c"># $ MYDOMAIN2=&lt;test.각자 자신의 닉네임의 도메인&gt;</span>
<span class="nv">$ MYDOMAIN1</span><span class="o">=</span>sweetlittlebird.com
<span class="nv">$ MYDOMAIN2</span><span class="o">=</span>test.sweetlittlebird.com
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$MYIP</span> <span class="nv">$MYDOMAIN1</span> <span class="nv">$MYDOMAIN2</span>
<span class="c"># =&gt; 192.168.10.10 sweetlittlebird.com test.sweetlittlebird.com</span>

<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"</span><span class="nv">$MYIP</span><span class="s2"> </span><span class="nv">$MYDOMAIN1</span><span class="s2">"</span> | <span class="nb">sudo tee</span> <span class="nt">-a</span> /etc/hosts
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"</span><span class="nv">$MYIP</span><span class="s2"> </span><span class="nv">$MYDOMAIN2</span><span class="s2">"</span> | <span class="nb">sudo tee</span> <span class="nt">-a</span> /etc/hosts
<span class="nv">$ </span><span class="nb">cat</span> /etc/hosts | <span class="nb">grep</span> <span class="nv">$MYDOMAIN1</span>
<span class="c"># =&gt; 192.168.10.10 sweetlittlebird.com</span>
<span class="c">#    192.168.10.10 test.sweetlittlebird.com</span>

<span class="c"># svc3-admin 접속 &gt; 결과 확인</span>
<span class="nv">$ </span>curl <span class="nv">$MYDOMAIN1</span>:30080 <span class="nt">-v</span>
<span class="c"># =&gt; * Host sweetlittlebird.com:30080 was resolved.</span>
<span class="c">#    * IPv4: 192.168.10.10</span>
<span class="c">#    *   Trying 192.168.10.10:30080...</span>
<span class="c">#    * Connected to sweetlittlebird.com (192.168.10.10) port 30080</span>
<span class="c">#    &amp;gt; GET / HTTP/1.1</span>
<span class="c">#    &amp;gt; Host: sweetlittlebird.com:30080</span>
<span class="c">#    &amp;gt; User-Agent: curl/8.5.0</span>
<span class="c">#    &amp;gt; Accept: */*</span>
<span class="c">#    &amp;gt;</span>
<span class="c">#    &amp;lt; HTTP/1.1 200 OK</span>
<span class="c">#    &amp;lt; Date: Sat, 01 Jan 2024 13:52:42 GMT</span>
<span class="c">#    &amp;lt; Content-Type: text/plain</span>
<span class="c">#    &amp;lt; Transfer-Encoding: chunked</span>
<span class="c">#    &amp;lt; Connection: keep-alive</span>
<span class="c">#    &amp;lt;</span>
<span class="c">#    </span>
<span class="c">#    Hostname: deploy3-adminsrv-7c8f8b8c87-48xwp</span>
<span class="c">#    </span>
<span class="c">#    Pod Information:</span>
<span class="c">#            -no pod information available-</span>
<span class="c">#    </span>
<span class="c">#    Server values:</span>
<span class="c">#            server_version=nginx: 1.13.0 - lua: 10008</span>
<span class="c">#    </span>
<span class="c">#    Request Information:</span>
<span class="c">#            client_address=172.16.0.16</span>
<span class="c">#            method=GET</span>
<span class="c">#            real path=/</span>
<span class="c">#            query=</span>
<span class="c">#            request_version=1.1</span>
<span class="c">#            request_uri=http://sweetlittlebird.com:8080/</span>
<span class="c">#    </span>
<span class="c">#    Request Headers:</span>
<span class="c">#            accept=*/*</span>
<span class="c">#            host=sweetlittlebird.com:30080</span>
<span class="c">#            user-agent=curl/8.5.0</span>
<span class="c">#            x-forwarded-for=192.168.10.1</span>
<span class="c">#            x-forwarded-host=sweetlittlebird.com:30080</span>
<span class="c">#            x-forwarded-port=80</span>
<span class="c">#            x-forwarded-proto=http</span>
<span class="c">#            ...</span>
<span class="nv">$ </span>curl <span class="nv">$MYDOMAIN1</span>:30080/admin
<span class="c"># =&gt; </span>
<span class="c">#    </span>
<span class="c">#    Hostname: deploy3-adminsrv-7c8f8b8c87-bm7dq</span>
<span class="c">#            ...</span>
<span class="c">#            client_address=172.16.0.16</span>
<span class="c">#            method=GET</span>
<span class="c">#            real path=/admin</span>
<span class="c">#            ...</span>
<span class="c">#            request_uri=http://sweetlittlebird.com:8080/admin</span>
<span class="c">#    </span>
<span class="c">#    Request Headers:</span>
<span class="c">#            accept=*/*</span>
<span class="c">#            host=sweetlittlebird.com:30080</span>
<span class="c">#            user-agent=curl/8.5.0</span>
<span class="c">#            x-forwarded-for=192.168.10.1</span>
<span class="c">#            x-forwarded-host=sweetlittlebird.com:30080</span>
<span class="c">#            x-forwarded-port=80</span>
<span class="c">#            x-forwarded-proto=http</span>
<span class="c">#            x-forwarded-scheme=http</span>
<span class="c">#            ...</span>
<span class="nv">$ </span>curl <span class="nv">$MYDOMAIN1</span>:30080/echo
<span class="c"># =&gt; Hostname: deploy3-adminsrv-7c8f8b8c87-ndwkj</span>
<span class="c">#            ...</span>
<span class="c">#            client_address=172.16.0.16</span>
<span class="c">#            method=GET</span>
<span class="c">#            real path=/echo</span>
<span class="c">#            ...</span>
<span class="c">#            request_uri=http://sweetlittlebird.com:8080/echo</span>
<span class="c">#    </span>
<span class="c">#    Request Headers:</span>
<span class="c">#            accept=*/*</span>
<span class="c">#            host=sweetlittlebird.com:30080</span>
<span class="c">#            user-agent=curl/8.5.0</span>
<span class="c">#            x-forwarded-for=192.168.10.1</span>
<span class="c">#            x-forwarded-host=sweetlittlebird.com:30080</span>
<span class="c">#            x-forwarded-port=80</span>
<span class="c">#            x-forwarded-proto=http</span>
<span class="c">#            x-forwarded-scheme=http</span>
<span class="c">#            ...    </span>
<span class="nv">$ </span>curl <span class="nv">$MYDOMAIN1</span>:30080/echo/1
<span class="c"># =&gt; Hostname: deploy3-adminsrv-7c8f8b8c87-48xwp</span>
<span class="c">#    </span>
<span class="c">#    Pod Information:</span>
<span class="c">#            -no pod information available-</span>
<span class="c">#    </span>
<span class="c">#    Server values:</span>
<span class="c">#            server_version=nginx: 1.13.0 - lua: 10008</span>
<span class="c">#    </span>
<span class="c">#    Request Information:</span>
<span class="c">#            client_address=172.16.0.16</span>
<span class="c">#            method=GET</span>
<span class="c">#            real path=/echo/1</span>
<span class="c">#            query=</span>
<span class="c">#            request_version=1.1</span>
<span class="c">#            request_uri=http://sweetlittlebird.com:8080/echo/1</span>
<span class="c">#            ...</span>

<span class="nv">$ </span>curl <span class="nv">$MYDOMAIN2</span>:30080 <span class="nt">-v</span>
<span class="c"># =&gt; * Host test.sweetlittlebird.com:30080 was resolved.</span>
<span class="c">#    * IPv4: 192.168.10.10</span>
<span class="c">#    *   Trying 192.168.10.10:30080...</span>
<span class="c">#    * Connected to test.sweetlittlebird.com (192.168.10.10) port 30080</span>
<span class="c">#    &amp;gt; GET / HTTP/1.1</span>
<span class="c">#    &amp;gt; Host: test.sweetlittlebird.com:30080</span>
<span class="c">#    ...</span>
<span class="c">#    &amp;lt; HTTP/1.1 404 Not Found</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>curl <span class="nv">$MYDOMAIN2</span>:30080/admin
<span class="c"># =&gt; &amp;lt;html&amp;gt;</span>
<span class="c">#    &amp;lt;head&amp;gt;&amp;lt;title&amp;gt;404 Not Found&amp;lt;/title&amp;gt;&amp;lt;/head&amp;gt;</span>
<span class="c">#    &amp;lt;body&amp;gt;</span>
<span class="c">#    &amp;lt;center&amp;gt;&amp;lt;h1&amp;gt;404 Not Found&amp;lt;/h1&amp;gt;&amp;lt;/center&amp;gt;</span>
<span class="c">#    &amp;lt;hr&amp;gt;&amp;lt;center&amp;gt;nginx&amp;lt;/center&amp;gt;</span>
<span class="c">#    &amp;lt;/body&amp;gt;</span>
<span class="c">#    &amp;lt;/html&amp;gt;</span>
<span class="nv">$ </span>curl <span class="nv">$MYDOMAIN2</span>:30080/echo
<span class="c"># =&gt; Hostname: deploy3-adminsrv-7c8f8b8c87-ndwkj</span>
<span class="c">#    </span>
<span class="c">#    Pod Information:</span>
<span class="c">#            -no pod information available-</span>
<span class="c">#    </span>
<span class="c">#    Server values:</span>
<span class="c">#            server_version=nginx: 1.13.0 - lua: 10008</span>
<span class="c">#    </span>
<span class="c">#    Request Information:</span>
<span class="c">#            client_address=172.16.0.16</span>
<span class="c">#            method=GET</span>
<span class="c">#            real path=/echo</span>
<span class="c">#            ...</span>
<span class="c">#            request_uri=http://test.sweetlittlebird.com:8080/echo</span>
<span class="c">#    </span>
<span class="c">#    Request Headers:</span>
<span class="c">#            accept=*/*</span>
<span class="c">#            host=test.sweetlittlebird.com:30080</span>
<span class="c">#            user-agent=curl/8.5.0</span>
<span class="c">#            x-forwarded-for=192.168.10.1</span>
<span class="c">#            x-forwarded-host=test.sweetlittlebird.com:30080</span>
<span class="c">#            x-forwarded-port=80</span>
<span class="c">#            x-forwarded-proto=http</span>
<span class="c">#            x-forwarded-scheme=http</span>
<span class="c">#            ...</span>
<span class="nv">$ </span>curl <span class="nv">$MYDOMAIN2</span>:30080/echo/1
<span class="nv">$ </span>curl <span class="nv">$MYDOMAIN2</span>:30080/echo/1/2

<span class="c">## (옵션) /etc/hosts 파일 변경 없이 접속 방안</span>
<span class="nv">$ </span>curl <span class="nt">-H</span> <span class="s2">"host: </span><span class="nv">$MYDOMAIN1</span><span class="s2">"</span> <span class="nv">$MYIP</span>:30080
<span class="c"># =&gt; (정상)</span>
<span class="nv">$ </span>curl <span class="nt">-H</span> <span class="s2">"host: </span><span class="nv">$MYDOMAIN2</span><span class="s2">"</span> <span class="nv">$MYIP</span>:30080
<span class="c"># =&gt; (404 에러)</span>
<span class="nv">$ </span>curl <span class="nt">-H</span> <span class="s2">"host: </span><span class="nv">$MYDOMAIN2</span><span class="s2">"</span> <span class="nv">$MYIP</span>:30080/echo
<span class="c"># =&gt; (정상 응답 옴)</span>
</code></pre></div></div>

<ul>
  <li>실습결과 sweetlittlebird.com으로는 모든 응답이 200 OK 응답이 오고,
test.sweetlittlebird.com으로 접속시에는 /echo 경로로 접속해야만 200 OK 응답이 오고, 그 외의 경로로 접속시에는 404 에러가 발생하는 것을 확인할 수 있습니다.</li>
  <li>아래의 룰대로 잘 접속이 되는 것을 확인할 수 있습니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># sweetlittlebird.com이라는 호스트로 접속시 모든 경로에 대해서 200 OK 응답</span>
sweetlittlebird.com    /       svc3-admin:8080   
  
<span class="c"># test.sweetlittlebird.com 처럼 서브 도메인이 있는 호스트명으로 접속시 /echo 경로로만 200 OK 응답</span>
<span class="k">*</span>.sweetlittlebird.com  /echo   svc3-admin:8080   
</code></pre></div>    </div>
  </li>
  <li>오브젝트 삭제
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl delete deployments,svc,ingress <span class="nt">--all</span>
</code></pre></div>    </div>
  </li>
</ul>

<h4 id="카나리-업데이트">카나리 업데이트</h4>

<ul>
  <li>카나리 업데이트는 새로운 버전의 파드를  배포하고, 일부 트래픽만 새로운 버전으로 전환하고, 새로운 버전의 정상동작 확인 후 전체를 새로운 버전으로 전환하는 업데이트 방식입니다.</li>
  <li>배포 자동화시 최소 중단/무중단으로 하는 방법을 몇가지 살펴보겠습니다.
    <ol>
      <li>롤링 업데이트
  <img src="/assets/2024/kans-3th/w6/20241012_kans_w6_13.png" alt="img.png" class="w-80 image-center" />
        <ul>
          <li>파드를 하나씩 새로운 버전으로 교체하는 방식으로, 기존 버전의 파드가 정상동작하는지 확인 후 다음 파드로 교체하는 방식입니다.</li>
        </ul>
      </li>
      <li>카나리 업데이트
  <img src="/assets/2024/kans-3th/w6/20241012_kans_w6_14.png" alt="img_1.png" class="w-80 image-center" />
        <ul>
          <li>일부 트래픽을 새로운 버전으로 전환하고, 정상동작 확인 후 전체로 전환하는 방식입니다.</li>
        </ul>
      </li>
      <li>블루/그린 업데이트
  <img src="/assets/2024/kans-3th/w6/20241012_kans_w6_15.png" alt="img_2.png" class="w-80 image-center" />
        <ul>
          <li>새로운 버전의 파드를 새로운 서비스로 배포하고, 모든 파드 배포 후, 하나씩 전환하는 롤링 업데이트와는 다르게 전체 트래픽을 한꺼번에 새로운 서비스로 전환하는 방식입니다.</li>
        </ul>
      </li>
    </ol>
  </li>
  <li>실습을 통해 nginx ingress controller를 이용한 카나리 업데이트를 진행해보겠습니다.
    <ul>
      <li>
        <p>canary-svc1-pod.yml 파일 생성</p>

        <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">dp-v1</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">replicas</span><span class="pi">:</span> <span class="m">3</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">matchLabels</span><span class="pi">:</span>
      <span class="na">app</span><span class="pi">:</span> <span class="s">svc-v1</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">metadata</span><span class="pi">:</span>
      <span class="na">labels</span><span class="pi">:</span>
        <span class="na">app</span><span class="pi">:</span> <span class="s">svc-v1</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">containers</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">pod-v1</span>
          <span class="na">image</span><span class="pi">:</span> <span class="s">k8s.gcr.io/echoserver:1.5</span>
          <span class="na">ports</span><span class="pi">:</span>
            <span class="pi">-</span> <span class="na">containerPort</span><span class="pi">:</span> <span class="m">8080</span>
      <span class="na">terminationGracePeriodSeconds</span><span class="pi">:</span> <span class="m">0</span>
<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Service</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">svc-v1</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">ports</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">web-port</span>
      <span class="na">port</span><span class="pi">:</span> <span class="m">9001</span>
      <span class="na">targetPort</span><span class="pi">:</span> <span class="m">8080</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">app</span><span class="pi">:</span> <span class="s">svc-v1</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p>canary-svc2-pod.yml 파일 생성</p>

        <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">dp-v2</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">replicas</span><span class="pi">:</span> <span class="m">3</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">matchLabels</span><span class="pi">:</span>
      <span class="na">app</span><span class="pi">:</span> <span class="s">svc-v2</span>
  <span class="na">template</span><span class="pi">:</span>
    <span class="na">metadata</span><span class="pi">:</span>
      <span class="na">labels</span><span class="pi">:</span>
        <span class="na">app</span><span class="pi">:</span> <span class="s">svc-v2</span>
    <span class="na">spec</span><span class="pi">:</span>
      <span class="na">containers</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">pod-v2</span>
        <span class="na">image</span><span class="pi">:</span> <span class="s">k8s.gcr.io/echoserver:1.6</span>
        <span class="na">ports</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">containerPort</span><span class="pi">:</span> <span class="m">8080</span>
      <span class="na">terminationGracePeriodSeconds</span><span class="pi">:</span> <span class="m">0</span>
<span class="nn">---</span>
<span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Service</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">svc-v2</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">ports</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">web-port</span>
      <span class="na">port</span><span class="pi">:</span> <span class="m">9001</span>
      <span class="na">targetPort</span><span class="pi">:</span> <span class="m">8080</span>
  <span class="na">selector</span><span class="pi">:</span>
    <span class="na">app</span><span class="pi">:</span> <span class="s">svc-v2</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p>생성 및 확인</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 터미널1</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> <span class="s1">'kubectl get ingress,svc,ep,pod -owide'</span>
    
<span class="c"># 생성</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> canary-svc1-pod.yml,canary-svc2-pod.yml
<span class="c"># =&gt; deployment.apps/dp-v1 created</span>
<span class="c">#    service/svc-v1 created</span>
<span class="c">#    deployment.apps/dp-v2 created</span>
<span class="c">#    service/svc-v2 created</span>
    
<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get svc,ep,pod
<span class="c"># =&gt; NAME                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE</span>
<span class="c">#    service/kubernetes   ClusterIP   10.10.200.1     &amp;lt;none&amp;gt;        443/TCP    12m</span>
<span class="c">#    service/svc-v1       ClusterIP   10.10.200.231   &amp;lt;none&amp;gt;        9001/TCP   18s</span>
<span class="c">#    service/svc-v2       ClusterIP   10.10.200.216   &amp;lt;none&amp;gt;        9001/TCP   18s</span>
<span class="c">#    </span>
<span class="c">#    NAME                   ENDPOINTS                                            AGE</span>
<span class="c">#    endpoints/kubernetes   192.168.10.10:6443                                   12m</span>
<span class="c">#    endpoints/svc-v1       172.16.1.10:8080,172.16.2.12:8080,172.16.3.11:8080   18s</span>
<span class="c">#    endpoints/svc-v2       172.16.1.11:8080,172.16.2.11:8080,172.16.3.12:8080   18s</span>
<span class="c">#    </span>
<span class="c">#    NAME                         READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/dp-v1-8684d45558-22nbv   1/1     Running   0          18s</span>
<span class="c">#    pod/dp-v1-8684d45558-59pnl   1/1     Running   0          18s</span>
<span class="c">#    pod/dp-v1-8684d45558-87xrs   1/1     Running   0          18s</span>
<span class="c">#    pod/dp-v2-7757c4bdc-5xmcm    1/1     Running   0          18s</span>
<span class="c">#    pod/dp-v2-7757c4bdc-bm2gq    1/1     Running   0          18s</span>
<span class="c">#    pod/dp-v2-7757c4bdc-h7fzl    1/1     Running   0          18s</span>
    
<span class="c"># 파드 버전 확인: 1.13.0 vs 1.13.1</span>
<span class="nv">$ </span><span class="k">for </span>pod <span class="k">in</span> <span class="si">$(</span>kubectl get pod <span class="nt">-o</span> wide <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>svc-v1 |awk <span class="s1">'NR&gt;1 {print $6}'</span><span class="si">)</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$pod</span>:8080 | egrep <span class="s1">'(Hostname|nginx)'</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; Hostname: dp-v1-8684d45558-22nbv</span>
<span class="c">#     server_version=nginx: 1.13.0 - lua: 10008</span>
<span class="c">#    ...</span>
<span class="nv">$ </span><span class="k">for </span>pod <span class="k">in</span> <span class="si">$(</span>kubectl get pod <span class="nt">-o</span> wide <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>svc-v2 |awk <span class="s1">'NR&gt;1 {print $6}'</span><span class="si">)</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$pod</span>:8080 | egrep <span class="s1">'(Hostname|nginx)'</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; Hostname: dp-v2-7757c4bdc-5xmcm</span>
<span class="c">#     server_version=nginx: 1.13.1 - lua: 10008</span>
<span class="c">#    ...		</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p>canary-ingress1.yml</p>

        <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">networking.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Ingress</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">ingress-canary-v1</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">ingressClassName</span><span class="pi">:</span> <span class="s">nginx</span>
  <span class="na">rules</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">host</span><span class="pi">:</span> <span class="s">kans.com</span>
    <span class="na">http</span><span class="pi">:</span>
      <span class="na">paths</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">path</span><span class="pi">:</span> <span class="s">/</span>
        <span class="na">pathType</span><span class="pi">:</span> <span class="s">Prefix</span>
        <span class="na">backend</span><span class="pi">:</span>
          <span class="na">service</span><span class="pi">:</span>
            <span class="na">name</span><span class="pi">:</span> <span class="s">svc-v1</span>
            <span class="na">port</span><span class="pi">:</span>
              <span class="na">number</span><span class="pi">:</span> <span class="m">8080</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p>canary-ingress2.yml</p>

        <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">networking.k8s.io/v1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">Ingress</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">ingress-canary-v2</span>
  <span class="na">annotations</span><span class="pi">:</span>
    <span class="na">nginx.ingress.kubernetes.io/canary</span><span class="pi">:</span> <span class="s2">"</span><span class="s">true"</span>
    <span class="na">nginx.ingress.kubernetes.io/canary-weight</span><span class="pi">:</span> <span class="s2">"</span><span class="s">10"</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">ingressClassName</span><span class="pi">:</span> <span class="s">nginx</span>
  <span class="na">rules</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">host</span><span class="pi">:</span> <span class="s">kans.com</span>
    <span class="na">http</span><span class="pi">:</span>
      <span class="na">paths</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">path</span><span class="pi">:</span> <span class="s">/</span>
        <span class="na">pathType</span><span class="pi">:</span> <span class="s">Prefix</span>
        <span class="na">backend</span><span class="pi">:</span>
          <span class="na">service</span><span class="pi">:</span>
            <span class="na">name</span><span class="pi">:</span> <span class="s">svc-v2</span>
            <span class="na">port</span><span class="pi">:</span>
              <span class="na">number</span><span class="pi">:</span> <span class="m">8080</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p>카나리 업그레이드 확인</p>
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 터미널1</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> <span class="s1">'kubectl get ingress,svc,ep'</span>
    
<span class="c"># 도메인 변경</span>
<span class="c"># $ MYDOMAIN1=&lt;각자 자신의 닉네임의 도메인&gt; 예시) gasida.com</span>
<span class="nv">$ MYDOMAIN1</span><span class="o">=</span>sweetlittlebird.com
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/kans.com/</span><span class="nv">$MYDOMAIN1</span><span class="s2">/g"</span> canary-ingress1.yml
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/kans.com/</span><span class="nv">$MYDOMAIN1</span><span class="s2">/g"</span> canary-ingress2.yml
    
<span class="c"># 생성</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> canary-ingress1.yml,canary-ingress2.yml
<span class="c"># =&gt; ingress.networking.k8s.io/ingress-canary-v1 created</span>
<span class="c">#    ingress.networking.k8s.io/ingress-canary-v2 created</span>
    
<span class="c"># 로그 모니터링</span>
<span class="nv">$ </span>kubetail <span class="nt">-n</span> ingress <span class="nt">-l</span> app.kubernetes.io/component<span class="o">=</span>controller
    
<span class="c"># 접속 테스트</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$MYDOMAIN1</span>:30080
<span class="nv">$ </span>curl <span class="nt">-s</span> <span class="nv">$MYDOMAIN1</span>:30080 | <span class="nb">grep </span>nginx
<span class="c"># =&gt; &amp;lt;hr&amp;gt;&amp;lt;center&amp;gt;nginx&amp;lt;/center&amp;gt;</span>
    
<span class="c"># 접속 시 v1 v2 버전별 비율이 어떻게 되나요? 왜 이렇게 되나요?</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span>  <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$MYDOMAIN1</span>:30080 | <span class="nb">grep </span>nginx <span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;      84         server_version=nginx: 1.13.0 - lua: 10008</span>
<span class="c">#         16         server_version=nginx: 1.13.1 - lua: 10008</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..1000<span class="o">}</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$MYDOMAIN1</span>:30080 | <span class="nb">grep </span>nginx <span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;     919         server_version=nginx: 1.13.0 - lua: 10008</span>
<span class="c">#         81         server_version=nginx: 1.13.1 - lua: 10008</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 <span class="nv">$MYDOMAIN1</span>:30080 | <span class="nb">grep </span>Hostname <span class="p">;</span> <span class="nb">echo</span> <span class="s2">"--------------"</span> <span class="p">;</span> <span class="nb">date</span> <span class="s2">"+%Y-%m-%d %H:%M:%S"</span> <span class="p">;</span> <span class="nb">sleep </span>1<span class="p">;</span> <span class="k">done</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 v2의 canary 비율을 10%로 두어서 그렇습니다.&lt;/span&gt;</span>
    
<span class="c"># 비율 조정하여 절반을 v2로 전환하겠습니다. &gt;&gt; 개발 배포 버전 전략에 유용하다!</span>
<span class="nv">$ </span>kubectl annotate <span class="nt">--overwrite</span> ingress ingress-canary-v2 nginx.ingress.kubernetes.io/canary-weight<span class="o">=</span>50
    
<span class="c"># 접속 테스트</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span>  <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$MYDOMAIN1</span>:30080 | <span class="nb">grep </span>nginx <span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;      53         server_version=nginx: 1.13.1 - lua: 10008</span>
<span class="c">#         47         server_version=nginx: 1.13.0 - lua: 10008</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..1000<span class="o">}</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$MYDOMAIN1</span>:30080 | <span class="nb">grep </span>nginx <span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;     526         server_version=nginx: 1.13.1 - lua: 10008</span>
<span class="c">#        474         server_version=nginx: 1.13.0 - lua: 10008</span>
        
<span class="c"># (옵션) 비율 조정 &lt;&lt; 어떻게 비율이 조정될까요?</span>
<span class="nv">$ </span>kubectl annotate <span class="nt">--overwrite</span> ingress ingress-canary-v2 nginx.ingress.kubernetes.io/canary-weight<span class="o">=</span>100
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span>  <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$MYDOMAIN1</span>:30080 | <span class="nb">grep </span>nginx <span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;    100         server_version=nginx: 1.13.1 - lua: 10008</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 카나리 비율을 100%로 하니 v2버전으로 100% 전환 되었습니다.&lt;/span&gt;</span>
    
<span class="c"># (옵션) 비율 조정 &lt;&lt; 어떻게 비율이 조정될까요?</span>
<span class="nv">$ </span>kubectl annotate <span class="nt">--overwrite</span> ingress ingress-canary-v2 nginx.ingress.kubernetes.io/canary-weight<span class="o">=</span>0
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span>  <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$MYDOMAIN1</span>:30080 | <span class="nb">grep </span>nginx <span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;     100         server_version=nginx: 1.13.0 - lua: 10008</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 카나리 비율을 0%로 하니 v2버전으로 0% 로 전환 되고 모든 트래픽이 v1으로 전달되었습니다.&lt;/span&gt;</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li>오브젝트 삭제
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl delete deployments,svc,ingress <span class="nt">--all</span>
</code></pre></div>    </div>
  </li>
</ul>

<hr />

<h2 id="gateway-api">Gateway API</h2>

<h3 id="gateway-api-소개">Gateway API 소개</h3>

<p>앞서 Ingress를 살펴볼때 말씀드린것 처럼 Ingress는 Frozen 되어서 더이상 업데이트 되지 않고, Gateway API에 기능을 추가할 계획이라고 합니다.
이어서 Gateway API에 대해 알아보겠습니다.</p>

<p>Gateway API는 Kubernetes에서 API Gateway를 정의하고 구성하기 위한 API를 제공하는 프로젝트입니다. <a href="https://medium.com/@disha.20.10/introduction-to-the-gateway-api-revolutionizing-kubernetes-networking-7b0c9a696038">Gateway API 소개</a>
Gateway API는 서비스 메시(예) istio 등)에서 제공하는 풍부한 기능 중 일부 기능들과 운영 관리에 필요한 기능들을 추가하였습니다.
추가된 기능의 예로는 헤더 기반 라우팅, 헤더 변조, 트래픽 미러링(쉽게 트래픽 복제), 역할 기반 접근 제어 등이 있습니다.</p>

<p><img src="/assets/2024/kans-3th/w6/20241012_kans_w6_16.png" alt="img.png" class="w-80 image-center" /></p>

<p>Gateway API는 이를 통해 동적 인프라 구성을 지원하고, 고급 트래픽 라우팅을 지원합니다.</p>

<ul>
  <li>Gateway API의 주요 기능은 다음과 같습니다.
    <ol>
      <li>
        <dl>
          <dt><strong>개선된 리소스 모델</strong></dt>
          <dd>API는 GatewayClass, Gateway 및 Route(HTTPRoute, TCPRoute 등)와 같은 새로운 사용자 정의 리소스를 도입하여 라우팅 규칙을 정의하는 보다 세부적이고 표현력 있는 방법을 제공합니다.</dd>
        </dl>
      </li>
      <li>
        <dl>
          <dt><strong>프로토콜 독립적</strong></dt>
          <dd>주로 HTTP용으로 설계된 Ingress와 달리 Gateway API는 TCP, UDP, TLS를 포함한 여러 프로토콜을 지원합니다.</dd>
        </dl>
      </li>
      <li>
        <dl>
          <dt><strong>강화된 보안</strong></dt>
          <dd>TLS 구성 및 보다 세부적인 액세스 제어에 대한 기본 제공 지원.</dd>
        </dl>
      </li>
      <li>
        <dl>
          <dt><strong>교차 네임스페이스 지원</strong></dt>
          <dd>서로 다른 네임스페이스의 서비스로 트래픽을 라우팅하여 보다 유연한 아키텍처를 구축할 수 있는 기능을 제공합니다.</dd>
        </dl>
      </li>
      <li>
        <dl>
          <dt><strong>확장성</strong></dt>
          <dd>API는 사용자 정의 리소스 및 정책으로 쉽게 확장할 수 있도록 설계되었습니다.</dd>
        </dl>
      </li>
      <li>
        <dl>
          <dt><strong>역할 지향</strong></dt>
          <dd>클러스터 운영자, 애플리케이션 개발자, 보안 팀 간의 우려를 명확하게 분리합니다.</dd>
        </dl>
      </li>
    </ol>
  </li>
  <li>다음의 구성요소 (Resource)를 가집니다.
    <ul>
      <li>GatewayClass, Gateway, HTTPRoute, TCPRoute, Service
<img src="/assets/2024/kans-3th/w6/20241012_kans_w6_17.png" alt="img.png" />
        <ul>
          <li><strong>GatewayClass:</strong> 공통 구성을 가진 게이트웨이 세트를 정의하고 클래스를 구현하는 컨트롤러에 의해 관리됩니다.</li>
          <li><strong>Gateway:</strong> 클라우드 로드 밸런서와 같은 트래픽 처리 인프라의 인스턴스를 정의합니다.</li>
          <li><strong>HTTPRoute:</strong> Gateway 리스너에서 백엔드 네트워크 엔드포인트의 표현으로 트래픽을 매핑하기 위한 HTTP 전용 규칙을 정의합니다. 이러한 엔드포인트는 종종 <a href="https://kubernetes.io/docs/concepts/services-networking/service/">Service</a>로 표현됩니다<br />
<img src="/assets/2024/kans-3th/w6/20241012_kans_w6_18.png" alt="img.png" class="image-center" />
<em class="image-caption">출처 : <a href="https://gateway-api.sigs.k8s.io/">https://gateway-api.sigs.k8s.io/</a></em></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>리퀘스트 흐름
<img src="/assets/2024/kans-3th/w6/20241012_kans_w6_19.svg" alt="20241012_kans_w6_19.svg" /></li>
  <li>role-oriented  API 가 중요한 이유
    <ul>
      <li>담당 업무의 역할에 따라서 동작/권한을 유연하게 제공할 수 있습니다.</li>
      <li>아래 그림 처럼 ‘스토어 개발자’는 Store 네임스페이스내에서 해당 store PATH 라우팅 관련 정책을 스스로 관리 할 수 있습니다.
<img src="/assets/2024/kans-3th/w6/20241012_kans_w6_20.png" alt="img.png" /></li>
      <li>역할의 예시입니다.
        <ul>
          <li><strong>인프라 제공자:</strong> 여러 격리된 클러스터가 여러 테넌트를 서비스할 수 있도록 인프라를 관리합니다. 예: 클라우드 제공자.</li>
          <li><strong>클러스터 운영자:</strong> 클러스터를 관리하며 주로 정책, 네트워크 접근, 애플리케이션 권한 등을 관리합니다.</li>
          <li><strong>애플리케이션 개발자:</strong> 클러스터에서 실행되는 애플리케이션을 관리하며 주로 애플리케이션 수준의 구성 및 <a href="https://kubernetes.io/docs/concepts/services-networking/service/">서비스</a> 구성에 관심이 있습니다.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>추천글
    <ul>
      <li><a href="https://www.anyflow.net/sw-engineer/kubernetes-gateway-api-1">Ingress + API Gateway = Kubernetes Gateway API</a></li>
      <li><a href="https://www.anyflow.net/sw-engineer/kubernetes-gateway-api-2">API Gateway + Service Mesh = Kubernetes Gateway API</a></li>
    </ul>
  </li>
</ul>

<h3 id="gloo-gateway">Gloo Gateway</h3>

<p>Gloo Gateway는 Solo.io에서 개발한 API Gateway로, Gateway API를 구현한 대표적인 제품 중 하나입니다. 
Gloo Gateway는 다양한 환경에서 사용할 수 있도록 설계되어 있으며, 다음과 같은 특징을 가지고 있습니다.</p>

<ul>
  <li><strong>Envoy Proxy 기반</strong> : Gloo Gateway는 고성능의 Envoy Proxy를 기반으로 하여 뛰어난 확장성과 성능을 제공합니다.</li>
  <li><strong>API 관리 및 라우팅</strong> : 다양한 API 라우팅 옵션을 제공하며, REST, gRPC, GraphQL 등의 다양한 프로토콜을 지원합니다. 이를 통해 복잡한 트래픽 관리와 라우팅이 가능합니다.</li>
  <li><strong>보안 기능</strong> : 인증, 인가, TLS 암호화, OAuth, OpenID Connect 등 다양한 보안 기능을 제공합니다. 이를 통해 API를 안전하게 보호할 수 있습니다.</li>
  <li><strong>확장성</strong> : 플러그인 아키텍처를 통해 쉽게 확장할 수 있으며, 다양한 서드파티 통합을 지원합니다. 필요에 따라 기능을 확장하거나 사용자 정의 기능을 추가할 수 있습니다.</li>
  <li><strong>서비스 디스커버리</strong> : Kubernetes, Consul, EC2 등 다양한 서비스 디스커버리 메커니즘을 지원하여 동적 환경에서도 효율적으로 작동합니다.</li>
  <li><strong>Observability</strong> : 트래픽 모니터링, 로깅, 트레이싱 등의 기능을 제공하여 운영 중인 시스템의 상태를 쉽게 파악하고 문제를 해결할 수 있습니다.</li>
  <li><strong>유연한</strong> 배포 : 클라우드, 온프레미스, 하이브리드 환경 등 다양한 배포 옵션을 지원합니다. 이를 통해 다양한 인프라 환경에 맞춰 유연하게 배포할 수 있습니다.</li>
</ul>

<h4 id="gloo-gateway-architecture">Gloo Gateway Architecture</h4>

<p><img src="/assets/2024/kans-3th/w6/20241012_kans_w6_21.png" alt="img.png" /></p>

<ul>
  <li>Envoy를 통해서 Http의 L7 라우팅을 지원하며, Gloo의 역할은 라우팅 규칙을 관리하고 Envoy에 전달하는 역할을 합니다.</li>
</ul>

<p>Gloo Gateway는 내용이 방대하기 때문에 아래의 링크들로 설명을 대체하겠습니다.</p>

<ul>
  <li><a href="https://www.solo.io/blog/">Gloo Blog</a></li>
  <li><a href="https://docs.solo.io/gateway/latest/quickstart/">Docs</a></li>
  <li><a href="https://www.solo.io/blog/gateway-api-tutorial-blog/">https://www.solo.io/blog/gateway-api-tutorial-blog/</a></li>
  <li><a href="https://www.solo.io/blog/gateway-api-workshop/">https://www.solo.io/blog/gateway-api-workshop/</a></li>
  <li><a href="https://www.solo.io/blog/fast-and-furious-gateway-api-at-scale-with-envoy-proxy-and-gloo-gateway/">https://www.solo.io/blog/fast-and-furious-gateway-api-at-scale-with-envoy-proxy-and-gloo-gateway/</a></li>
  <li><a href="https://www.solo.io/blog/getting-the-most-out-of-gateway-api-lessons-learned-from-gloo-migrations/">https://www.solo.io/blog/getting-the-most-out-of-gateway-api-lessons-learned-from-gloo-migrations/</a></li>
  <li><a href="https://www.solo.io/blog/solving-an-information-leakage-problem-with-the-envoy-extproc-filter-and-kube-gateway-api/">https://www.solo.io/blog/solving-an-information-leakage-problem-with-the-envoy-extproc-filter-and-kube-gateway-api/</a></li>
  <li><a href="https://www.solo.io/blog/gateway-api-gitops-argo-tutorial-blog/">https://www.solo.io/blog/gateway-api-gitops-argo-tutorial-blog/</a></li>
</ul>

<h4 id="실습">실습</h4>

<p>실습을 통해 Gloo Gateway를 설치하고, Gateway API를 사용해보겠습니다.
실습은 <a href="https://www.solo.io/blog/gateway-api-tutorial-blog/">[Tutorial] Hands-On with the Kubernetes Gateway API and Envoy Proxy</a>를 참고하였습니다.
kind를 통해서 실습할 수 있도록 잘 구성되었고 30분 정도면 따라할 수 있다고 합니다.</p>

<h5 id="install">Install</h5>

<p><strong>Install KinD Cluster</strong></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh">&gt; kind-1node.yaml
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
  extraPortMappings:
  - containerPort: 30000
    hostPort: 30000
  - containerPort: 30001
    hostPort: 30001
  - containerPort: 30002
    hostPort: 30002
</span><span class="no">EOT

</span><span class="c"># Install KinD Cluster</span>
<span class="nv">$ </span>kind create cluster <span class="nt">--image</span> kindest/node:v1.30.0 <span class="nt">--config</span> kind-1node.yaml <span class="nt">--name</span> myk8s

<span class="c"># 노드에 기본 툴 설치</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane sh <span class="nt">-c</span> <span class="s1">'apt update &amp;&amp; apt install tree psmisc lsof wget bsdmainutils bridge-utils net-tools dnsutils tcpdump ngrep iputils-ping git vim -y'</span>

<span class="c"># 노드/파드 확인</span>
<span class="nv">$ </span>kubectl get nodes <span class="nt">-o</span> wide
<span class="c"># =&gt; NAME                  STATUS   ROLES           AGE   VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE                         KERNEL-VERSION     CONTAINER-RUNTIME</span>
<span class="c">#    myk8s-control-plane   Ready    control-plane   32s   v1.30.0   172.20.0.2    &amp;lt;none&amp;gt;        Debian GNU/Linux 12 (bookworm)   5.10.76-linuxkit   containerd://1.7.15</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE            NAME                                          READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    kube-system          coredns-7db6d8ff4d-45mzg                      1/1     Running   0          38s</span>
<span class="c">#    kube-system          coredns-7db6d8ff4d-gc4zp                      1/1     Running   0          38s</span>
<span class="c">#    kube-system          etcd-myk8s-control-plane                      1/1     Running   0          52s</span>
<span class="c">#    kube-system          kindnet-h4dwk                                 1/1     Running   0          38s</span>
<span class="c">#    kube-system          kube-apiserver-myk8s-control-plane            1/1     Running   0          54s</span>
<span class="c">#    kube-system          kube-controller-manager-myk8s-control-plane   1/1     Running   0          52s</span>
<span class="c">#    kube-system          kube-proxy-sptf6                              1/1     Running   0          38s</span>
<span class="c">#    kube-system          kube-scheduler-myk8s-control-plane            1/1     Running   0          52s</span>
<span class="c">#    local-path-storage   local-path-provisioner-988d74bc-gl679         1/1     Running   0          38s</span>
</code></pre></div></div>

<p><strong>Install Gateway API CRDs</strong> : The Kubernetes Gateway API abstractions are expressed using Kubernetes CRDs.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># CRDs 설치 및 확인</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://github.com/kubernetes-sigs/gateway-api/releases/download/v1.0.0/standard-install.yaml
<span class="nv">$ </span>kubectl get crd
<span class="c"># =&gt; NAME                                        CREATED AT</span>
<span class="c">#    gatewayclasses.gateway.networking.k8s.io    2024-10-01T15:50:32Z</span>
<span class="c">#    gateways.gateway.networking.k8s.io          2024-10-01T15:50:32Z</span>
<span class="c">#    httproutes.gateway.networking.k8s.io        2024-10-01T15:50:32Z</span>
<span class="c">#    referencegrants.gateway.networking.k8s.io   2024-10-01T15:50:32Z</span>
</code></pre></div></div>

<p><strong>Install Glooctl Utility</strong> : GLOOCTL is a command-line utility that allows users to view, manage, and debug Gloo Gateway deployments - <a href="https://docs.solo.io/gloo-edge/latest/installation/glooctl_setup/">Link</a></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># [신규 터미널] 아래 bash 진입 후 glooctl 툴 사용</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane bash
<span class="nt">----------------------------------------</span>
<span class="c"># Install Glooctl Utility</span>
<span class="c">## glooctl install gateway     # install gloo's function gateway functionality into the 'gloo-system' namespace</span>
<span class="c">## glooctl install ingress     # install very basic Kubernetes Ingress support with Gloo into namespace gloo-system</span>
<span class="c">## glooctl install knative     # install Knative serving with Gloo configured as the default cluster ingress</span>
<span class="c">## curl -sL https://run.solo.io/gloo/install | sh</span>
<span class="nv">$ </span>curl <span class="nt">-sL</span> https://run.solo.io/gloo/install | <span class="nv">GLOO_VERSION</span><span class="o">=</span>v1.17.7 sh
<span class="nv">$ </span><span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="nv">$HOME</span>/.gloo/bin:<span class="nv">$PATH</span>

<span class="c"># 버전 확인</span>
<span class="nv">$ </span>glooctl version
<span class="c"># =&gt; Server: version undefined, could not find any version of gloo running</span>
<span class="c">#    </span>
<span class="c">#    {</span>
<span class="c">#      &amp;quot;client&amp;quot;: {</span>
<span class="c">#        &amp;quot;version&amp;quot;: &amp;quot;1.17.7&amp;quot;</span>
<span class="c">#      },</span>
<span class="c">#      &amp;quot;kubernetesCluster&amp;quot;: {</span>
<span class="c">#        &amp;quot;major&amp;quot;: &amp;quot;1&amp;quot;,</span>
<span class="c">#        &amp;quot;minor&amp;quot;: &amp;quot;30&amp;quot;,</span>
<span class="c">#        &amp;quot;gitVersion&amp;quot;: &amp;quot;v1.30.0&amp;quot;,</span>
<span class="c">#        &amp;quot;buildDate&amp;quot;: &amp;quot;2024-05-13T22:02:25Z&amp;quot;,</span>
<span class="c">#        &amp;quot;platform&amp;quot;: &amp;quot;linux/arm64&amp;quot;</span>
<span class="c">#      }</span>
<span class="c">#    }</span>

<span class="c"># &lt;span style="color: green;"&gt;👉 서버가 설치되지 않았기 때문에 클라이언트 정보만 나옵니다.&lt;/span&gt;</span>
<span class="nt">----------------------------------------</span>
</code></pre></div></div>

<p><strong>Install Gloo Gateway : 오픈소스 버전</strong></p>

<p><strong>rosetta 비활성화 방법</strong></p>

<ul>
  <li>
    <p>[macOS m시리즈] <strong>Docker Desktop</strong> : 아래 옵션 Uncheck 해둘 것 → Apply &amp; restart</p>

    <p><img src="/assets/2024/kans-3th/w6/20241012_kans_w6_22.png" alt="img.png" /></p>
  </li>
  <li>
    <p>[macOS m시리즈] <strong>Orbstack</strong> : 터미널에서 아래 입력</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c"># rosetta 비활성화 </span>
  <span class="nv">$ </span>orb config <span class="nb">set </span>rosetta <span class="nb">false</span>
    
  <span class="c">#  orb 설정 확인 </span>
  <span class="nv">$ </span>orb config show
    
  <span class="c"># orbstack 재시작 </span>
  <span class="nv">$ </span>orb stop 
  <span class="nv">$ </span>orb start 
</code></pre></div>    </div>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># [신규 터미널] 모니터링</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> kubectl get pod,svc,endpointslices,ep <span class="nt">-n</span> gloo-system

<span class="c"># Install Gloo Gateway</span>
<span class="c">## --set kubeGateway.enabled=true: Kubernetes Gateway 기능을 활성화합니다.</span>
<span class="c">## --set gloo.disableLeaderElection=true: Gloo의 리더 선출 기능을 비활성화합니다. (단일 인스턴스에서 Gloo를 실행 시 유용)</span>
<span class="c">## --set discovery.enabled=false: 서비스 디스커버리 기능을 비활성화합니다.</span>
<span class="nv">$ </span>helm repo add gloo https://storage.googleapis.com/solo-public-helm
<span class="c"># =&gt; &amp;quot;gloo&amp;quot; has been added to your repositories</span>
<span class="nv">$ </span>helm repo update
<span class="nv">$ </span>helm <span class="nb">install</span> <span class="nt">-n</span> gloo-system gloo-gateway gloo/gloo <span class="se">\</span>
<span class="nt">--create-namespace</span> <span class="se">\</span>
<span class="nt">--version</span> 1.17.7 <span class="se">\</span>
<span class="nt">--set</span> kubeGateway.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> gloo.disableLeaderElection<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--set</span> discovery.enabled<span class="o">=</span><span class="nb">false</span>
<span class="c"># =&gt; NAME: gloo-gateway</span>
<span class="c">#    LAST DEPLOYED: Sun Oct 13 00:57:27 2024</span>
<span class="c">#    NAMESPACE: gloo-system</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 1</span>
<span class="c">#    TEST SUITE: None</span>

<span class="c"># Confirm that the Gloo control plane has successfully been deployed using this command</span>
<span class="nv">$ </span>kubectl rollout status deployment/gloo <span class="nt">-n</span> gloo-system
<span class="c"># =&gt; deployment &amp;quot;gloo&amp;quot; successfully rolled out</span>

<span class="c"># 설치 확인</span>
<span class="nv">$ </span>kubectl get crd | <span class="nb">grep</span> <span class="s1">'networking.k8s.io'</span>
<span class="c"># =&gt; gatewayclasses.gateway.networking.k8s.io    2024-10-01T15:50:32Z</span>
<span class="c">#    gateways.gateway.networking.k8s.io          2024-10-01T15:50:32Z</span>
<span class="c">#    httproutes.gateway.networking.k8s.io        2024-10-01T15:50:32Z</span>
<span class="c">#    referencegrants.gateway.networking.k8s.io   2024-10-01T15:50:32Z</span>
<span class="nv">$ </span>kubectl get crd | <span class="nb">grep</span> <span class="nt">-v</span> <span class="s1">'networking.k8s.io'</span>
<span class="nv">$ </span>kubectl get pod,svc,endpointslices <span class="nt">-n</span> gloo-system
<span class="c"># =&gt; NAME                                    READY   STATUS      RESTARTS   AGE</span>
<span class="c">#    pod/gateway-proxy-57c49d4f48-xm8vv      1/1     Running     0          87s</span>
<span class="c">#    pod/gloo-748d877c4-24ngk                1/1     Running     0          87s</span>
<span class="c">#    pod/gloo-resource-rollout-5bt7d         0/1     Completed   0          87s</span>
<span class="c">#    pod/gloo-resource-rollout-check-xwxd4   0/1     Completed   0          86s</span>
<span class="c">#    </span>
<span class="c">#    NAME                    TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)                                                AGE</span>
<span class="c">#    service/gateway-proxy   LoadBalancer   10.96.69.126    &amp;lt;pending&amp;gt;     80:30172/TCP,443:32484/TCP                             87s</span>
<span class="c">#    service/gloo            ClusterIP      10.96.100.145   &amp;lt;none&amp;gt;        9977/TCP,9976/TCP,9988/TCP,9966/TCP,9979/TCP,443/TCP   87s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                                 ADDRESSTYPE   PORTS                        ENDPOINTS    AGE</span>
<span class="c">#    endpointslice.discovery.k8s.io/gateway-proxy-n7f7v   IPv4          8080,8443                    10.244.0.7   87s</span>
<span class="c">#    endpointslice.discovery.k8s.io/gloo-9bf7g            IPv4          9979,9988,9966 + 3 more...   10.244.0.8   87s</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl explain gatewayclasses
<span class="nv">$ </span>kubectl get gatewayclasses
<span class="c"># =&gt; NAME           CONTROLLER             ACCEPTED   AGE</span>
<span class="c">#    gloo-gateway   solo.io/gloo-gateway   True       2m18s</span>

<span class="nv">$ </span>kubectl get gatewayclasses <span class="nt">-o</span> yaml
<span class="c"># =&gt; apiVersion: v1</span>
<span class="c">#    items:</span>
<span class="c">#    - apiVersion: gateway.networking.k8s.io/v1</span>
<span class="c">#      kind: GatewayClass</span>
<span class="c">#      metadata:</span>
<span class="c">#        labels:</span>
<span class="c">#          app: gloo</span>
<span class="c">#        name: gloo-gateway</span>
<span class="c">#      spec:</span>
<span class="c">#        controllerName: solo.io/gloo-gateway</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<p><strong>Install Httpbin Application</strong> : A simple HTTP Request &amp; Response Service - <a href="https://httpbin.org/">Link</a></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> kubectl get pod,svc,endpointslices,ep <span class="nt">-n</span> httpbin

<span class="c"># Install Httpbin Application</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/solo-io/solo-blog/main/gateway-api-tutorial/01-httpbin-svc.yaml
<span class="c"># =&gt; namespace/httpbin created</span>
<span class="c">#    serviceaccount/httpbin created</span>
<span class="c">#    service/httpbin created</span>
<span class="c">#    deployment.apps/httpbin created</span>

<span class="c"># 설치 확인</span>
<span class="nv">$ </span>kubectl get deploy,pod,svc,endpointslices,sa <span class="nt">-n</span> httpbin
<span class="c"># =&gt; NAME                      READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/httpbin   0/1     1            0           10s</span>
<span class="c">#    </span>
<span class="c">#    NAME                           READY   STATUS              RESTARTS   AGE</span>
<span class="c">#    pod/httpbin-5855dc8bdd-xh2vf   0/1     ContainerCreating   0          10s</span>
<span class="c">#    </span>
<span class="c">#    NAME              TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE</span>
<span class="c">#    service/httpbin   ClusterIP   10.96.169.139   &amp;lt;none&amp;gt;        8000/TCP   10s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                           ADDRESSTYPE   PORTS     ENDPOINTS   AGE</span>
<span class="c">#    endpointslice.discovery.k8s.io/httpbin-6zhsk   IPv4          &amp;lt;unset&amp;gt;   &amp;lt;unset&amp;gt;     10s</span>
<span class="c">#    </span>
<span class="c">#    NAME                     SECRETS   AGE</span>
<span class="c">#    serviceaccount/default   0         10s</span>
<span class="c">#    serviceaccount/httpbin   0         10s</span>
<span class="nv">$ </span>kubectl rollout status deploy/httpbin <span class="nt">-n</span> httpbin
<span class="c"># =&gt; deployment &amp;quot;httpbin&amp;quot; successfully rolled out</span>

<span class="c"># (옵션) NodePort 설정</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Service
metadata:
  labels:
    app: httpbin
    service: httpbin
  name: httpbin
  namespace: httpbin
spec:
  type: NodePort
  ports:
  - name: http
    port: 8000
    targetPort: 80
    nodePort: 30000
  selector:
    app: httpbin
</span><span class="no">EOF
</span><span class="c"># =&gt; service/httpbin configured</span>

<span class="c"># (옵션) 로컬 접속 확인</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"httpbin web - http://localhost:30000"</span>     <span class="c"># macOS 사용자</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"httpbin web - http://192.168.50.10:30000"</span> <span class="c"># Windows 사용자</span>
</code></pre></div></div>

<p><img src="/assets/2024/kans-3th/w6/20241012_kans_w6_23.png" alt="img.png" class="w-80 image-center" />
<em class="image-caption">httpbin 설치결과</em></p>

<p><strong>Gateway API 종류</strong> - <a href="https://kubernetes.io/docs/concepts/services-networking/gateway/#resource-model">Docs</a></p>

<ul>
  <li><strong>GatewayClass:</strong> Defines a set of gateways with <strong>common configuration</strong> and managed by a controller that implements the <strong>class</strong>. - 예) 인프라 엔지니어가 관리</li>
  <li><strong>Gateway:</strong> Defines an instance of traffic handling <strong>infrastructure</strong>, such as cloud load balancer. - 예) 데브옵스 엔지니어가 관리</li>
  <li><strong>HTTPRoute:</strong> Defines <strong>HTTP-specific rules</strong> for mapping traffic from a Gateway listener to a representation of backend network endpoints. These endpoints are often represented as a <a href="https://kubernetes.io/docs/concepts/services-networking/service/">Service</a>. - 예) 개발자가 관리</li>
</ul>

<p><img src="/assets/2024/kans-3th/w6/20241012_kans_w6_24.png" alt="img.png" class="image-center" /></p>

<h5 id="control--envoy-data-plane-and-the-gloo-control-plane">Control : <strong>Envoy</strong> data plane and the <strong>Gloo</strong> control plane.</h5>

<ul>
  <li>Now we’ll configure a <strong>Gateway listener</strong>, establish external access to <strong>Gloo Gateway,</strong> and test the <strong>routing</strong> <strong>rules</strong> that are the core of the proxy configuration.</li>
</ul>

<p><strong>Configure a Gateway Listener</strong></p>

<ul>
  <li>Let’s begin by establishing a Gateway resource that sets up an HTTP listener on port 8080 to expose routes from all our namespaces. Gateway custom resources like this are part of the Gateway API standard.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 02-gateway.yaml</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; 02-gateway.yaml
kind: Gateway
apiVersion: gateway.networking.k8s.io/v1
metadata:
  name: http
  namespace: gloo-system
spec:
  gatewayClassName: gloo-gateway
  listeners:
  - protocol: HTTP
    port: 8080
    name: http
    allowedRoutes:
      namespaces:
        from: All
</span><span class="no">EOF

</span><span class="c"># gateway 리소스 생성</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> 02-gateway.yaml
<span class="c"># =&gt; gateway.gateway.networking.k8s.io/http created</span>

<span class="c"># 확인 : Now we can confirm that the Gateway has been activated</span>
<span class="nv">$ </span>kubectl get gateway <span class="nt">-n</span> gloo-system
<span class="c"># =&gt; NAME   CLASS          ADDRESS   PROGRAMMED   AGE</span>
<span class="c">#    http   gloo-gateway             True         8s</span>
<span class="nv">$ </span>kubectl get gateway <span class="nt">-n</span> gloo-system <span class="nt">-o</span> yaml
<span class="c"># =&gt; apiVersion: v1</span>
<span class="c">#    items:</span>
<span class="c">#    - apiVersion: gateway.networking.k8s.io/v1</span>
<span class="c">#      kind: Gateway</span>
<span class="c">#      metadata:</span>
<span class="c">#        name: http</span>
<span class="c">#        namespace: gloo-system</span>
<span class="c">#      spec:</span>
<span class="c">#        gatewayClassName: gloo-gateway</span>
<span class="c">#        listeners:</span>
<span class="c">#        - allowedRoutes:</span>
<span class="c">#            namespaces:</span>
<span class="c">#              from: All</span>
<span class="c">#          name: http</span>
<span class="c">#          port: 8080</span>
<span class="c">#          protocol: HTTP</span>
<span class="c">#    ...</span>

<span class="c"># You can also confirm that Gloo Gateway has spun up an Envoy proxy instance in response to the creation of this Gateway object by deploying gloo-proxy-http:</span>
<span class="nv">$ </span>kubectl get deployment gloo-proxy-http <span class="nt">-n</span> gloo-system
<span class="c"># =&gt; NAME              READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    gloo-proxy-http   1/1     1            1           66s</span>

<span class="c"># envoy 사용 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-n</span> gloo-system
<span class="c"># =&gt; NAME                               READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    gateway-proxy-57c49d4f48-xm8vv     1/1     Running   0          13m</span>
<span class="c">#    gloo-748d877c4-24ngk               1/1     Running   0          13m</span>
<span class="c">#    gloo-proxy-http-587765f6b6-mpnt5   1/1     Running   0          78s</span>
<span class="nv">$ </span>kubectl describe pod <span class="nt">-n</span> gloo-system  |grep Image:
<span class="c"># =&gt;     Image:         quay.io/solo-io/gloo-envoy-wrapper:1.17.7 # &lt;span style="color: green;"&gt;👉 이름에서 알 수 있듯이 envoy가 들어있고 감싸고 있는것으로 보입니다.&lt;/span&gt;</span>
<span class="c">#        Image:          quay.io/solo-io/gloo:1.17.7</span>
<span class="c">#        Image:         quay.io/solo-io/gloo-envoy-wrapper:1.17.7</span>

<span class="c"># gloo-proxy-http 서비스는 External-IP는 Pending 상태</span>
<span class="nv">$ </span>kubectl get svc <span class="nt">-n</span> gloo-system gloo-proxy-http
<span class="c"># =&gt; NAME              TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span>
<span class="c">#    gloo-proxy-http   LoadBalancer   10.96.104.226   &amp;lt;pending&amp;gt;     8080:31461/TCP   101s</span>

<span class="c"># gloo-proxy-http NodePort 30001 설정</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/instance: http
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: gloo-proxy-http
    app.kubernetes.io/version: 1.17.7
    gateway.networking.k8s.io/gateway-name: http
    gloo: kube-gateway
    helm.sh/chart: gloo-gateway-1.17.7
  name: gloo-proxy-http
  namespace: gloo-system
spec:
  ports:
  - name: http
    nodePort: 30001
    port: 8080
  selector:
    app.kubernetes.io/instance: http
    app.kubernetes.io/name: gloo-proxy-http
    gateway.networking.k8s.io/gateway-name: http
  type: LoadBalancer
</span><span class="no">EOF
</span><span class="c"># =&gt; service/gloo-proxy-http configured</span>

<span class="nv">$ </span>kubectl get svc <span class="nt">-n</span> gloo-system gloo-proxy-http
<span class="c"># =&gt; NAME              TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span>
<span class="c">#    gloo-proxy-http   LoadBalancer   10.96.104.226   &amp;lt;pending&amp;gt;     8080:30001/TCP   2m17s </span>
<span class="c"># &lt;span style="color: green;"&gt;👉 노드포트가 30001로 변경되었습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<p><strong>Establish External Access to Proxy</strong></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 간편한 테스트를 위해 port-forward를 사용하여 외부로 노출하겠습니다.</span>
<span class="nv">$ </span>kubectl port-forward deployment/gloo-proxy-http <span class="nt">-n</span> gloo-system 8080:8080 &amp;
</code></pre></div></div>

<p><strong>Configure Simple Routing with an HTTPRoute</strong></p>

<p>Let’s begin our routing configuration with the simplest possible <strong>route</strong> to expose the <strong>/get</strong> operation on <strong>httpbin</strong></p>

<p><code class="language-plaintext highlighter-rouge">HTTPRoute</code> is one of the new Kubernetes CRDs introduced by the Gateway API, as documented <a href="https://gateway-api.sigs.k8s.io/api-types/httproute/">here</a>. We’ll start by introducing a simple <code class="language-plaintext highlighter-rouge">HTTPRoute</code> for our service.</p>

<p><strong>HTTPRoute Spec</strong></p>

<ul>
  <li><a href="https://gateway-api.sigs.k8s.io/reference/spec/#gateway.networking.k8s.io/v1.ParentRef">ParentRefs</a>-Define which <strong>Gateways</strong> this <strong>Route</strong> wants to be <strong>attached</strong> to.</li>
  <li><a href="https://gateway-api.sigs.k8s.io/reference/spec/#gateway.networking.k8s.io/v1.Hostname">Hostnames</a> (optional)- Define a list of <strong>hostnames</strong> to use for matching the <strong>Host header</strong> of HTTP requests.</li>
  <li><a href="https://gateway-api.sigs.k8s.io/reference/spec/#gateway.networking.k8s.io/v1.HTTPRouteRule">Rules</a>-Define a list of <strong>rules</strong> to perform <strong>actions</strong> against matching HTTP requests.
    <ul>
      <li>Each rule consists of <a href="https://gateway-api.sigs.k8s.io/reference/spec/#gateway.networking.k8s.io/v1.HTTPRouteMatch">matches</a>, <a href="https://gateway-api.sigs.k8s.io/reference/spec/#gateway.networking.k8s.io/v1.HTTPRouteFilter">filters</a> (optional), <a href="https://gateway-api.sigs.k8s.io/reference/spec/#gateway.networking.k8s.io/v1.HTTPBackendRef">backendRefs</a> (optional) and <a href="https://gateway-api.sigs.k8s.io/reference/spec/#gateway.networking.k8s.io/v1.HTTPRouteTimeouts">timeouts</a> (optional) fields.</li>
    </ul>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>apiVersion: gateway.networking.k8s.io/v1beta1
kind: HTTPRoute
metadata:
  name: httpbin
  namespace: httpbin
  labels:
    example: httpbin-route
spec:
  parentRefs:
    - name: http
      namespace: gloo-system
  hostnames:
    - <span class="s2">"api.example.com"</span>
  rules:
  - matches:
    - path:
        <span class="nb">type</span>: Exact
        value: /get
    backendRefs:
      - name: httpbin
        port: 8000
</code></pre></div></div>

<p>This example <strong>attaches</strong> to the default <code class="language-plaintext highlighter-rouge">Gateway</code> object created for us when we installed Gloo Gateway earlier.</p>

<p>See the <code class="language-plaintext highlighter-rouge">gloo-system/http</code> reference in the <code class="language-plaintext highlighter-rouge">parentRefs</code> stanza.</p>

<p>The <a href="https://gateway-api.sigs.k8s.io/api-types/gateway/">Gateway</a> object simply represents a host:port listener that the proxy will expose to accept ingress traffic.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Our route watches for HTTP requests directed at the host api.example.com with the request path /get and then forwards the request to the httpbin service on port 8000.</span>
<span class="c"># Let’s establish this route now:</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/solo-io/gloo-gateway-use-cases/main/gateway-api-tutorial/03-httpbin-route.yaml
<span class="c"># =&gt; httproute.gateway.networking.k8s.io/httpbin created</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get httproute <span class="nt">-n</span> httpbin
<span class="c"># =&gt; NAME      HOSTNAMES             AGE</span>
<span class="c">#    httpbin   [&amp;quot;api.example.com&amp;quot;]   12s</span>

<span class="nv">$ </span>kubectl describe httproute <span class="nt">-n</span> httpbin
<span class="c"># =&gt; ...</span>
<span class="c">#    Spec:</span>
<span class="c">#      Hostnames:</span>
<span class="c">#        api.example.com</span>
<span class="c">#      Parent Refs:</span>
<span class="c">#        Group:      gateway.networking.k8s.io</span>
<span class="c">#        Kind:       Gateway</span>
<span class="c">#        Name:       http</span>
<span class="c">#        Namespace:  gloo-system</span>
<span class="c">#      Rules:</span>
<span class="c">#        Backend Refs:</span>
<span class="c">#          Group:   </span>
<span class="c">#          Kind:    Service</span>
<span class="c">#          Name:    httpbin</span>
<span class="c">#          Port:    8000</span>
<span class="c">#          Weight:  1</span>
<span class="c">#        Matches:</span>
<span class="c">#          Path:</span>
<span class="c">#            Type:   Exact</span>
<span class="c">#            Value:  /get</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<p><strong>Test the Simple Route with Curl</strong></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># let’s use curl to display the response with the -i option to additionally show the HTTP response code and headers.</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"127.0.0.1 api.example.com"</span> | <span class="nb">sudo tee</span> <span class="nt">-a</span> /etc/hosts
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"httproute - http://api.example.com:30001/get"</span> <span class="c"># 웹브라우저</span>
<span class="c"># 혹은</span>
<span class="nv">$ </span>curl <span class="nt">-is</span> <span class="nt">-H</span> <span class="s2">"Host: api.example.com"</span> http://localhost:8080/get <span class="c"># kubectl port-forward 사용 시</span>
<span class="c"># =&gt; HTTP/1.1 200 OK</span>
<span class="c">#    &lt;span style="color: red;"&gt;server: envoy&lt;/span&gt; # &lt;span style="color: green;"&gt;👉 서버가 envoy임을 확인할 수 있습니다.&lt;/span&gt;</span>
<span class="c">#    date: Sat, 1 Oct 2024 16:19:18 GMT</span>
<span class="c">#    content-type: application/json</span>
<span class="c">#    content-length: 239</span>
<span class="c">#    access-control-allow-origin: *</span>
<span class="c">#    access-control-allow-credentials: true</span>
<span class="c">#    x-envoy-upstream-service-time: 13</span>
<span class="c">#    </span>
<span class="c">#    {</span>
<span class="c">#      &amp;quot;args&amp;quot;: {},</span>
<span class="c">#      &amp;quot;headers&amp;quot;: {</span>
<span class="c">#        &amp;quot;Accept&amp;quot;: &amp;quot;*/*&amp;quot;,</span>
<span class="c">#        &amp;quot;Host&amp;quot;: &amp;quot;api.example.com&amp;quot;,</span>
<span class="c">#        &amp;quot;User-Agent&amp;quot;: &amp;quot;curl/8.1.2&amp;quot;,</span>
<span class="c">#        &amp;quot;X-Envoy-Expected-Rq-Timeout-Ms&amp;quot;: &amp;quot;15000&amp;quot;</span>
<span class="c">#      },</span>
<span class="c">#      &amp;quot;origin&amp;quot;: &amp;quot;10.244.0.12&amp;quot;,</span>
<span class="c">#      &amp;quot;url&amp;quot;: &amp;quot;http://api.example.com/get&amp;quot;</span>
<span class="c">#    }</span>
</code></pre></div></div>

<p>Note that if we attempt to invoke another valid endpoint <code class="language-plaintext highlighter-rouge">/delay</code> on the <code class="language-plaintext highlighter-rouge">httpbin</code> service, it will fail with a <code class="language-plaintext highlighter-rouge">404 Not Found</code> error. Why? Because our <code class="language-plaintext highlighter-rouge">HTTPRoute</code> policy is only exposing access to <code class="language-plaintext highlighter-rouge">/get</code>, one of the many endpoints available on the service. If we try to consume an alternative <code class="language-plaintext highlighter-rouge">httpbin</code> endpoint like <code class="language-plaintext highlighter-rouge">/delay</code>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 호출 응답 왜 그럴까?</span>
<span class="nv">$ </span>curl <span class="nt">-is</span> <span class="nt">-H</span> <span class="s2">"Host: api.example.com"</span> http://localhost:8080/delay/1
<span class="c"># =&gt; Handling connection for 8080</span>
<span class="c">#    HTTP/1.1 404 Not Found</span>
<span class="c">#    date: Sat, 1 Oct 2024 16:20:23 GMT</span>
<span class="c">#    server: envoy</span>
<span class="c">#    content-length: 0</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 gloo를 통했을때는 HTTProute 설정에서 /get 이라는 경로에대해서 정확하게 일치(Exact) 할 경우에만 라우팅하도록 해서 그렇습니다.&lt;/span&gt;</span>

<span class="c"># nodeport 직접 접속 테스트</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"httproute - http://api.example.com:30000/delay/1"</span> <span class="c"># 1초 후 응답</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"httproute - http://api.example.com:30000/delay/5"</span> <span class="c"># 5초 후 응답</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 노드포트로 직접 접속할 경우 gloo HTTPRoute를 거치지 않기 때문에 접속이 가능합니다.&lt;/span&gt;</span>
</code></pre></div></div>

<p>kind 클러스터를 구성할때 30000 포트를 열었기 때문에 NodePort로 직접 접속이 가능합니다.</p>

<p><img src="/assets/2024/kans-3th/w6/20241012_kans_w6_25.png" alt="img.png" class="w-80 image-center" />
<em class="image-caption">http://api.example.com:30000/delay/1 호출 결과 =&gt; 1초후 응답</em></p>

<p><strong>[정규식 패턴 매칭] Explore Routing with Regex Matching Patterns</strong></p>

<p>Let’s assume that now we DO want to expose other <code class="language-plaintext highlighter-rouge">httpbin</code> endpoints like <code class="language-plaintext highlighter-rouge">/delay</code>. Our initial <code class="language-plaintext highlighter-rouge">HTTPRoute</code> is inadequate, because it is looking for an exact path match with <code class="language-plaintext highlighter-rouge">/get</code>.</p>

<p>We’ll <strong>modify</strong> it in a couple of ways. <strong>First</strong>, we’ll modify the matcher to look for <strong>path prefix matches</strong> instead of an <strong>exact match</strong>. <strong>Second</strong>, we’ll add a <strong>new request filter</strong> to <strong>rewrite</strong> the matched <code class="language-plaintext highlighter-rouge">/api/httpbin/</code> prefix with just a <code class="language-plaintext highlighter-rouge">/</code> prefix, which will give us the flexibility to access any endpoint available on the <code class="language-plaintext highlighter-rouge">httpbin</code> service. So a path like <code class="language-plaintext highlighter-rouge">/api/httpbin/delay/1</code> will be sent to <code class="language-plaintext highlighter-rouge">httpbin</code> with the path <code class="language-plaintext highlighter-rouge">/delay/1</code>.</p>

<p>URL에 패턴이 매치가 되면 rewrite해서 실제 접속되는 경로를 변경할 수 있습니다.</p>
<ul>
  <li>예시) <code class="language-plaintext highlighter-rouge">/api/httpbin/delay/1</code> ⇒ <code class="language-plaintext highlighter-rouge">/delay/1</code></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Here are the modifications we’ll apply to our HTTPRoute:</span>

    - matches:
        <span class="c"># Switch from an Exact Matcher(정확한 매팅) to a PathPrefix (경로 매팅) Matcher</span>
        - path:
            <span class="nb">type</span>: PathPrefix
            value: /api/httpbin/
      filters:
        <span class="c"># Replace(변경) the /api/httpbin matched prefix with /</span>
        - <span class="nb">type</span>: URLRewrite
          urlRewrite:
            path:
              <span class="nb">type</span>: ReplacePrefixMatch
              replacePrefixMatch: /
</code></pre></div></div>

<ul>
  <li>2가지 수정 내용 적용 후 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/solo-io/gloo-gateway-use-cases/main/gateway-api-tutorial/04-httpbin-rewrite.yaml
<span class="c"># =&gt; httproute.gateway.networking.k8s.io/httpbin configured</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl describe httproute <span class="nt">-n</span> httpbin
<span class="c"># =&gt; ...</span>
<span class="c">#    Spec:</span>
<span class="c">#      Hostnames:</span>
<span class="c">#        api.example.com</span>
<span class="c">#      Parent Refs:</span>
<span class="c">#        Group:      gateway.networking.k8s.io</span>
<span class="c">#        Kind:       Gateway</span>
<span class="c">#        Name:       http</span>
<span class="c">#        Namespace:  gloo-system</span>
<span class="c">#      Rules:</span>
<span class="c">#        Backend Refs:</span>
<span class="c">#          Group:</span>
<span class="c">#          Kind:    Service</span>
<span class="c">#          Name:    httpbin</span>
<span class="c">#          Port:    8000</span>
<span class="c">#          Weight:  1</span>
<span class="c">#        Filters:</span>
<span class="c">#          Type:  URLRewrite</span>
<span class="c">#          URL Rewrite:</span>
<span class="c">#            Path:</span>
<span class="c">#              Replace Prefix Match:  /</span>
<span class="c">#              Type:                  ReplacePrefixMatch</span>
<span class="c">#        Matches:</span>
<span class="c">#          Path:</span>
<span class="c">#            Type:   PathPrefix</span>
<span class="c">#            Value:  /api/httpbin/</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<p><strong>Test Routing with Regex Matching Patterns</strong></p>

<p>When we used only a single route with an exact match pattern, we could only exercise the httpbin <code class="language-plaintext highlighter-rouge">/get</code> endpoint. Let’s now use <code class="language-plaintext highlighter-rouge">curl</code> to confirm that both <code class="language-plaintext highlighter-rouge">/get</code> and <code class="language-plaintext highlighter-rouge">/delay</code> work as expected.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"httproute - http://api.example.com:30001/api/httpbin/get"</span> <span class="c"># 웹브라우저</span>
<span class="c"># 혹은</span>
<span class="nv">$ </span>curl <span class="nt">-is</span> <span class="nt">-H</span> <span class="s2">"Host: api.example.com"</span> http://localhost:8080/api/httpbin/get <span class="c"># kubectl port-forward 사용 시</span>
<span class="c"># =&gt; HTTP/1.1 200 OK</span>
<span class="c">#    server: envoy</span>
<span class="c">#    date: Sat, 1 Oct 2024 16:33:20 GMT</span>
<span class="c">#    content-type: application/json</span>
<span class="c">#    content-length: 289</span>
<span class="c">#    access-control-allow-origin: *</span>
<span class="c">#    access-control-allow-credentials: true</span>
<span class="c">#    x-envoy-upstream-service-time: 20</span>
<span class="c">#    </span>
<span class="c">#    {</span>
<span class="c">#      &amp;quot;args&amp;quot;: {},</span>
<span class="c">#      &amp;quot;headers&amp;quot;: {</span>
<span class="c">#        &amp;quot;Accept&amp;quot;: &amp;quot;*/*&amp;quot;,</span>
<span class="c">#        &amp;quot;Host&amp;quot;: &amp;quot;api.example.com&amp;quot;,</span>
<span class="c">#        &amp;quot;User-Agent&amp;quot;: &amp;quot;curl/8.1.2&amp;quot;,</span>
<span class="c">#        &amp;quot;X-Envoy-Expected-Rq-Timeout-Ms&amp;quot;: &amp;quot;15000&amp;quot;,</span>
<span class="c">#        &amp;quot;X-Envoy-Original-Path&amp;quot;: &amp;quot;/api/httpbin/get&amp;quot;</span>
<span class="c">#      },</span>
<span class="c">#      &amp;quot;origin&amp;quot;: &amp;quot;10.244.0.12&amp;quot;,</span>
<span class="c">#      &amp;quot;url&amp;quot;: &amp;quot;http://api.example.com/get&amp;quot;</span>
<span class="c">#    }</span>

<span class="c"># 아래 NodePort 와 GW API 통한 접속 비교</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"httproute - http://api.example.com:30001/api/httpbin/get"</span>
<span class="c"># =&gt; HTTP/1.1 200 OK</span>
<span class="c">#    ...</span>
<span class="c">#      &amp;quot;url&amp;quot;: &amp;quot;&lt;span style="color: red;"&gt;http://api.example.com/get&lt;/span&gt;&amp;quot;</span>
<span class="c">#    }</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 gloo gateway가 /app/httpbin/get =&gt; / 로 변경하여 잘 접속이 되었습니다.&lt;/span&gt;</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"httproute - http://api.example.com:30000/api/httpbin/get"</span> <span class="c"># NodePort 직접 접근</span>
<span class="c"># =&gt; HTTP/1.1 404 NOT FOUND</span>
<span class="c">#    ...</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 NodePort에 직접 접근시에는 /app/httpbin/get이 그대로 파드에 전달되어 없는 경로라서 404 에러가 납니다.&lt;/span&gt;</span>

<span class="nt">---</span>
<span class="c">#</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"httproute - http://api.example.com:30001/api/httpbin/delay/1"</span> <span class="c"># 웹브라우저</span>
<span class="c"># 혹은</span>
<span class="nv">$ </span>curl <span class="nt">-is</span> <span class="nt">-H</span> <span class="s2">"Host: api.example.com"</span> http://localhost:8080/api/httpbin/delay/1 <span class="c"># kubectl port-forward 사용 시</span>
<span class="c"># =&gt; HTTP/1.1 200 OK</span>
<span class="c">#    server: envoy</span>
<span class="c">#    date: Sat, 1 Oct 2024 16:36:49 GMT</span>
<span class="c">#    content-type: application/json</span>
<span class="c">#    content-length: 343</span>
<span class="c">#    access-control-allow-origin: *</span>
<span class="c">#    access-control-allow-credentials: true</span>
<span class="c">#    x-envoy-upstream-service-time: 1049     # envoy 가 업스트림 httpbin 요청 처리에 걸리 시간 1초 이상</span>
<span class="c">#    </span>
<span class="c">#    {</span>
<span class="c">#      &amp;quot;args&amp;quot;: {},</span>
<span class="c">#      &amp;quot;data&amp;quot;: &amp;quot;&amp;quot;,</span>
<span class="c">#      &amp;quot;files&amp;quot;: {},</span>
<span class="c">#      &amp;quot;form&amp;quot;: {},</span>
<span class="c">#      &amp;quot;headers&amp;quot;: {</span>
<span class="c">#        &amp;quot;Accept&amp;quot;: &amp;quot;*/*&amp;quot;,</span>
<span class="c">#        &amp;quot;Host&amp;quot;: &amp;quot;api.example.com&amp;quot;,</span>
<span class="c">#        &amp;quot;User-Agent&amp;quot;: &amp;quot;curl/8.1.2&amp;quot;,</span>
<span class="c">#        &amp;quot;X-Envoy-Expected-Rq-Timeout-Ms&amp;quot;: &amp;quot;15000&amp;quot;,</span>
<span class="c">#        &amp;quot;X-Envoy-Original-Path&amp;quot;: &amp;quot;/api/httpbin/delay/1&amp;quot;</span>
<span class="c">#      },</span>
<span class="c">#      &amp;quot;origin&amp;quot;: &amp;quot;10.244.0.12&amp;quot;,</span>
<span class="c">#      &amp;quot;url&amp;quot;: &amp;quot;http://api.example.com/delay/1&amp;quot;</span>
<span class="c">#    }</span>

<span class="nv">$ </span>curl <span class="nt">-is</span> <span class="nt">-H</span> <span class="s2">"Host: api.example.com"</span> http://localhost:8080/api/httpbin/delay/2
<span class="c"># =&gt; ...</span>
<span class="c">#    x-envoy-upstream-service-time: 2133</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<p>Perfect! It works just as expected! Note that the <code class="language-plaintext highlighter-rouge">/delay</code> operation completed successfully and that the 1-second delay was applied. The response header <code class="language-plaintext highlighter-rouge">x-envoy-upstream-service-time: 1023</code> indicates that Envoy reported that the upstream <code class="language-plaintext highlighter-rouge">httpbin</code> service required just over 1 second (1,023 milliseconds) to process the request. In the initial <code class="language-plaintext highlighter-rouge">/get</code> operation, which doesn’t inject an artificial delay, observe that the same header reported only 14 milliseconds of upstream processing time.</p>

<p><strong>[업스트림 베어러 토큰을 사용한 변환] Test Transformations with Upstream Bearer Tokens</strong></p>

<p><strong>목적</strong> : 요청을 라우팅하는 <strong>백엔드</strong> 시스템 중 하나에서 <strong>인증</strong>해야 하는 <strong>요구</strong> 사항이 있는 경우는 어떻게 할까요? 이 업스트림 시스템에는 권한 부여를 위한 API 키가 필요하고, 이를 소비하는 <strong>클라이언트에 직접 노출하고 싶지 않다</strong>고 가정해 보겠습니다. 즉<strong>, 프록시 계층</strong>에서 <strong>요청</strong>에 <strong>주입</strong>할 간단한 <strong>베어러 토큰</strong>을 구성하고 싶습니다. (정적 API 키 토큰을 직접 주입)</p>

<p>What if we have a requirement to <strong>authenticate</strong> with one of the <strong>backend</strong> systems to which we route our requests?</p>

<p>Let’s assume that this <strong>upstream</strong> system requires an <strong>API key</strong> for authorization, and that we <strong>don’t</strong> want to expose this directly to the <strong>consuming client</strong>. In other words, we’d like to configure a <strong>simple bearer toke</strong>n to be <strong>injected</strong> into the <strong>request</strong> at the <strong>proxy layer.</strong></p>

<p>We can <strong>express</strong> this in the <strong>Gateway API</strong> by adding a <strong>filter</strong> that applies a simple <strong>transformation</strong> to the i<strong>ncoming request</strong>.</p>

<p>This will be applied along with the <strong>URLRewrite</strong> filter we created in the previous step.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># The new filters stanza in our HTTPRoute now looks like this:</span>

      filters:
        - <span class="nb">type</span>: URLRewrite
          urlRewrite:
            path:
              <span class="nb">type</span>: ReplacePrefixMatch
              replacePrefixMatch: /
              
        <span class="c"># Add a Bearer token to supply a static API key when routing to backend system</span>
        - <span class="nb">type</span>: RequestHeaderModifier
          requestHeaderModifier:
            add:
              - name: Authorization
                value: Bearer my-api-key
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/solo-io/gloo-gateway-use-cases/main/gateway-api-tutorial/05-httpbin-rewrite-xform.yaml

<span class="c">#</span>
<span class="nv">$ </span>kubectl describe httproute <span class="nt">-n</span> httpbin
<span class="c"># =&gt; ...</span>
<span class="c">#    Spec:</span>
<span class="c">#      ...</span>
<span class="c">#      Rules:</span>
<span class="c">#        Backend Refs:</span>
<span class="c">#          Group:</span>
<span class="c">#          Kind:    Service</span>
<span class="c">#          Name:    httpbin</span>
<span class="c">#          Port:    8000</span>
<span class="c">#          Weight:  1</span>
<span class="c">#        Filters:</span>
<span class="c">#          Type:  URLRewrite</span>
<span class="c">#          URL Rewrite:</span>
<span class="c">#            Path:</span>
<span class="c">#              Replace Prefix Match:  /</span>
<span class="c">#              Type:                  ReplacePrefixMatch</span>
<span class="c">#          Request Header Modifier:</span>
<span class="c">#            Add:</span>
<span class="c">#              Name:   Authorization</span>
<span class="c">#              Value:  Bearer my-api-key</span>
<span class="c">#          Type:       RequestHeaderModifier</span>
<span class="c">#        Matches:</span>
<span class="c">#          Path:</span>
<span class="c">#            Type:   PathPrefix</span>
<span class="c">#            Value:  /api/httpbin/</span>
</code></pre></div></div>

<ul>
  <li>동작 테스트</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"httproute - http://api.example.com:30001/api/httpbin/get"</span> <span class="c"># 웹브라우저</span>
<span class="c"># 혹은</span>
<span class="nv">$ </span>curl <span class="nt">-is</span> <span class="nt">-H</span> <span class="s2">"Host: api.example.com"</span> http://localhost:8080/api/httpbin/get <span class="c"># kubectl port-forward 사용 시</span>
<span class="c"># =&gt; HTTP/1.1 200 OK</span>
<span class="c">#    server: envoy</span>
<span class="c">#    date: Sat, 1 Oct 2024 16:40:59 GMT</span>
<span class="c">#    content-type: application/json</span>
<span class="c">#    content-length: 332</span>
<span class="c">#    access-control-allow-origin: *</span>
<span class="c">#    access-control-allow-credentials: true</span>
<span class="c">#    x-envoy-upstream-service-time: 19</span>
<span class="c">#    </span>
<span class="c">#    {</span>
<span class="c">#      &amp;quot;args&amp;quot;: {},</span>
<span class="c">#      &amp;quot;headers&amp;quot;: {</span>
<span class="c">#        &amp;quot;Accept&amp;quot;: &amp;quot;*/*&amp;quot;,</span>
<span class="c">#        &lt;span style="color: red"&gt;&amp;quot;Authorization&amp;quot;: &amp;quot;Bearer my-api-key&amp;quot;,&lt;/span&gt; </span>
<span class="c">#        &amp;quot;Host&amp;quot;: &amp;quot;api.example.com&amp;quot;,</span>
<span class="c">#        &amp;quot;User-Agent&amp;quot;: &amp;quot;curl/8.1.2&amp;quot;,</span>
<span class="c">#        &amp;quot;X-Envoy-Expected-Rq-Timeout-Ms&amp;quot;: &amp;quot;15000&amp;quot;,</span>
<span class="c">#        &amp;quot;X-Envoy-Original-Path&amp;quot;: &amp;quot;/api/httpbin/get&amp;quot;</span>
<span class="c">#      },</span>
<span class="c">#      &amp;quot;origin&amp;quot;: &amp;quot;10.244.0.12&amp;quot;,</span>
<span class="c">#      &amp;quot;url&amp;quot;: &amp;quot;http://api.example.com/get&amp;quot;</span>
<span class="c">#    }</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 클라이언트에서는 Authorization 헤더를 안 주었지만, Gloo gateway를 통하자&lt;/span&gt; </span>
<span class="c"># &lt;span style="color: green;"&gt;    Authorization 헤더에 Bearer my-api-key 가 추가되어 있습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<h5 id="migrate">Migrate</h5>

<p>In this section, we’ll explore how a couple of common service migration techniques, <strong>dark launches with header-based routing</strong> and <strong>canary releases with percentage-based routing,</strong> are supported by the Gateway API standard.</p>

<p><strong>Configure Two Workloads for Migration Routing</strong></p>

<p>Let’s first establish <strong>two versions</strong> of a <strong>workload</strong> to facilitate our migration example. We’ll use the open-source <a href="https://github.com/nicholasjackson/fake-service">Fake Service</a> to enable this.</p>

<ul>
  <li><strong>Fake service</strong> that can handle both <strong>HTTP</strong> and <strong>gRPC</strong> traffic, for <strong>testing</strong> upstream service communications and testing service mesh and other scenarios.</li>
</ul>

<p>Let’s establish a <code class="language-plaintext highlighter-rouge">v1</code> of our <code class="language-plaintext highlighter-rouge">my-workload</code> service that’s configured to return a response string containing “v1”. We’ll create a corresponding <code class="language-plaintext highlighter-rouge">my-workload-v2</code> service as well.</p>

<ul>
  <li>ingress의 카나리 배포와 유사하게 V1의 일부 트래픽을 V2로 라우팅할 수 있습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># You should see the response below, indicating deployments for both v1 and v2 of my-workload have been created in the my-workload namespace.</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/solo-io/gloo-gateway-use-cases/main/gateway-api-tutorial/06-workload-svcs.yaml
<span class="c"># =&gt; namespace/my-workload created</span>
<span class="c">#    serviceaccount/my-workload created</span>
<span class="c">#    deployment.apps/my-workload-v1 created</span>
<span class="c">#    deployment.apps/my-workload-v2 created</span>
<span class="c">#    service/my-workload-v1 created</span>
<span class="c">#    service/my-workload-v2 created</span>

<span class="c"># v1,v2 2가지 버전 워크로드 확인</span>
<span class="nv">$ </span>kubectl get deploy,pod,svc,endpointslices <span class="nt">-n</span> my-workload
<span class="c"># =&gt; NAME                             READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/my-workload-v1   1/1     1            1           15s</span>
<span class="c">#    deployment.apps/my-workload-v2   1/1     1            1           15s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                  READY   STATUS    RESTARTS   AGE</span>
<span class="c">#    pod/my-workload-v1-644f98bbd9-q6cs5   1/1     Running   0          15s</span>
<span class="c">#    pod/my-workload-v2-5bb5fcfcbc-bq88c   1/1     Running   0          15s</span>
<span class="c">#    </span>
<span class="c">#    NAME                     TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE</span>
<span class="c">#    service/my-workload-v1   ClusterIP   10.96.203.193   &amp;lt;none&amp;gt;        8080/TCP   15s</span>
<span class="c">#    service/my-workload-v2   ClusterIP   10.96.210.160   &amp;lt;none&amp;gt;        8080/TCP   15s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                                  ADDRESSTYPE   PORTS   ENDPOINTS     AGE</span>
<span class="c">#    endpointslice.discovery.k8s.io/my-workload-v1-d9sqd   IPv4          8080    10.244.0.14   15s</span>
<span class="c">#    endpointslice.discovery.k8s.io/my-workload-v2-mv7fq   IPv4          8080    10.244.0.13   15s</span>
</code></pre></div></div>

<p><strong>Test Simple V1 Routing</strong></p>

<p>Before we dive into routing to multiple services, we’ll start by building a simple <strong><code class="language-plaintext highlighter-rouge">HTTPRoute</code></strong> that sends HTTP requests to host <code class="language-plaintext highlighter-rouge">api.example.com</code> whose paths begin with <strong><code class="language-plaintext highlighter-rouge">/api/my-workload</code></strong> to the <strong><code class="language-plaintext highlighter-rouge">v1</code></strong> workload:</p>

<p><img src="/assets/2024/kans-3th/w6/20241012_kans_w6_26.png" alt="img.png" /></p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">gateway.networking.k8s.io/v1beta1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">HTTPRoute</span>
<span class="na">metadata</span><span class="pi">:</span>
  <span class="na">name</span><span class="pi">:</span> <span class="s">my-workload</span>
  <span class="na">namespace</span><span class="pi">:</span> <span class="s">my-workload</span>
  <span class="na">labels</span><span class="pi">:</span>
    <span class="na">example</span><span class="pi">:</span> <span class="s">my-workload-route</span>
<span class="na">spec</span><span class="pi">:</span>
  <span class="na">parentRefs</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">http</span>
      <span class="na">namespace</span><span class="pi">:</span> <span class="s">gloo-system</span>
  <span class="na">hostnames</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s2">"</span><span class="s">api.example.com"</span>
  <span class="na">rules</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">matches</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">path</span><span class="pi">:</span>
          <span class="na">type</span><span class="pi">:</span> <span class="s">PathPrefix</span>
          <span class="na">value</span><span class="pi">:</span> <span class="s">/api/my-workload</span>
      <span class="na">backendRefs</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">my-workload-v1</span>
          <span class="na">namespace</span><span class="pi">:</span> <span class="s">my-workload</span>
          <span class="na">port</span><span class="pi">:</span> <span class="m">8080</span>
</code></pre></div></div>

<p>Now apply this route:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/solo-io/gloo-gateway-use-cases/main/gateway-api-tutorial/07-workload-route.yaml
<span class="c"># =&gt; httproute.gateway.networking.k8s.io/my-workload created</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get httproute <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE     NAME          HOSTNAMES             AGE</span>
<span class="c">#    httpbin       httpbin       [&amp;quot;api.example.com&amp;quot;]   29m</span>
<span class="c">#    my-workload   my-workload   [&amp;quot;api.example.com&amp;quot;]   29s</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl describe httproute <span class="nt">-n</span> my-workload
<span class="c"># =&gt; ...</span>
<span class="c">#    Spec:</span>
<span class="c">#      Hostnames:</span>
<span class="c">#        api.example.com</span>
<span class="c">#      Parent Refs:</span>
<span class="c">#        Group:      gateway.networking.k8s.io</span>
<span class="c">#        Kind:       Gateway</span>
<span class="c">#        Name:       http</span>
<span class="c">#        Namespace:  gloo-system</span>
<span class="c">#      Rules:</span>
<span class="c">#        Backend Refs:</span>
<span class="c">#          Group:</span>
<span class="c">#          Kind:       Service</span>
<span class="c">#          Name:       my-workload-v1</span>
<span class="c">#          Namespace:  my-workload</span>
<span class="c">#          Port:       8080</span>
<span class="c">#          Weight:     1</span>
<span class="c">#        Matches:</span>
<span class="c">#          Path:</span>
<span class="c">#            Type:   PathPrefix</span>
<span class="c">#            Value:  /api/my-workload</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> http://api.example.com:8080/api/my-workload | <span class="nb">grep </span>Workload<span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;  100   &amp;quot;body&amp;quot;: &amp;quot;Hello From My Workload (v1)!&amp;quot;,</span>

<span class="c"># &lt;span style="color: green;"&gt;👉 현재는 모든 연결이 v1으로 향합니다.&lt;/span&gt;</span>
</code></pre></div></div>

<p><strong>Simulate a v2 Dark Launch with Header-Based Routing</strong></p>

<p><img src="/assets/2024/kans-3th/w6/20241012_kans_w6_27.png" alt="img.png" /></p>

<p><a href="https://www.cloudbees.com/blog/when-dark-launch-right-release-strategy">Dark Launch</a> is a great cloud migration technique that <strong>releases new feature</strong>s to a select <strong>subset of users</strong> to gather <strong>feedback</strong> and experiment with improvements <strong>before</strong> potentially disrupting a larger user community.</p>

<ul>
  <li>Dark Launch : 일부 사용자에게 새로운 기능을 출시하여 피드백을 수집하고 잠재적으로 더 큰 사용자 커뮤니티를 방해하기 전에 개선 사항을 실험하는 훌륭한 클라우드 마이그레이션 기술</li>
</ul>

<p>We will simulate a dark launch in our example by installing the <strong>new cloud version</strong> of our <strong>service</strong> in our Kubernetes cluster, and then using declarative policy to route only requests containing a <strong>particular heade</strong>r to the new <code class="language-plaintext highlighter-rouge">v2</code> instance. The <strong>vast majority of users</strong> will continue to use the original <strong><code class="language-plaintext highlighter-rouge">v1</code></strong> of the service just as before.</p>

<ul>
  <li>우리는 Kubernetes 클러스터에 서비스의 새로운 클라우드 버전을 설치한 다음 선언적 정책을 사용하여 특정 헤더를 포함하는 요청만 새 인스턴스로 라우팅하여 예제에서 다크 런치를 시뮬레이션할 것입니다 . 대다수의 사용자는 이전과 마찬가지로 서비스의 <code class="language-plaintext highlighter-rouge">v1</code>을 계속 사용할 것 입니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  rules:
    - matches:
      - path:
          <span class="nb">type</span>: PathPrefix
          value: /api/my-workload
        <span class="c"># Add a matcher to route requests with a v2 version header to v2</span>
        <span class="c"># version=v2 헤더값이 있는 사용자만 v2 라우팅</span>
        headers:
        - name: version
          value: v2
      backendRefs:
        - name: my-workload-v2
          namespace: my-workload
          port: 8080      
    - matches:
      <span class="c"># Route requests without the version header to v1 as before</span>
      <span class="c"># 대다수 일반 사용자는 기존 처럼 v1 라우팅</span>
      - path:
          <span class="nb">type</span>: PathPrefix
          value: /api/my-workload
      backendRefs:
        - name: my-workload-v1
          namespace: my-workload
          port: 8080
</code></pre></div></div>

<p>Configure two separate routes, one for <code class="language-plaintext highlighter-rouge">v1</code> that the majority of service consumers will still use, and another route for <code class="language-plaintext highlighter-rouge">v2</code> that will be accessed by specifying a request header with name <code class="language-plaintext highlighter-rouge">version</code> and value <code class="language-plaintext highlighter-rouge">v2</code>. Let’s apply the modified <code class="language-plaintext highlighter-rouge">HTTPRoute</code>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/solo-io/gloo-gateway-use-cases/main/gateway-api-tutorial/08-workload-route-header.yaml
<span class="c"># =&gt; httproute.gateway.networking.k8s.io/my-workload configured</span>

<span class="c"># </span>
<span class="nv">$ </span>kubectl describe httproute <span class="nt">-n</span> my-workload
<span class="c"># =&gt; ...</span>
<span class="c">#    Spec:  </span>
<span class="c">#      Rules:</span>
<span class="c">#        Backend Refs:</span>
<span class="c">#          Group:</span>
<span class="c">#          Kind:       Service</span>
<span class="c">#          Name:       my-workload-v2</span>
<span class="c">#          Namespace:  my-workload</span>
<span class="c">#          Port:       8080</span>
<span class="c">#          Weight:     1</span>
<span class="c">#        Matches:</span>
<span class="c">#          Headers:</span>
<span class="c">#            Name:   version</span>
<span class="c">#            Type:   Exact</span>
<span class="c">#            Value:  v2</span>
<span class="c">#          Path:</span>
<span class="c">#            Type:   PathPrefix</span>
<span class="c">#            Value:  /api/my-workload</span>
<span class="c">#        Backend Refs:</span>
<span class="c">#          Group:</span>
<span class="c">#          Kind:       Service</span>
<span class="c">#          Name:       my-workload-v1</span>
<span class="c">#          Namespace:  my-workload</span>
<span class="c">#          Port:       8080</span>
<span class="c">#          Weight:     1</span>
<span class="c">#        Matches:</span>
<span class="c">#          Path:</span>
<span class="c">#            Type:   PathPrefix</span>
<span class="c">#            Value:  /api/my-workload</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># version: v2 헤더가 없는 경우 v1으로 라우팅됩니다.</span>
<span class="nv">$ </span>curl <span class="nt">-is</span> <span class="nt">-H</span> <span class="s2">"Host: api.example.com"</span> http://localhost:8080/api/my-workload
<span class="nv">$ </span>curl <span class="nt">-is</span> <span class="nt">-H</span> <span class="s2">"Host: api.example.com"</span> http://localhost:8080/api/my-workload | <span class="nb">grep </span>body
<span class="c"># =&gt; "body": "Hello From My Workload (v1)!",</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> http://api.example.com:8080/api/my-workload | <span class="nb">grep </span>Workload<span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;  100   &amp;quot;body&amp;quot;: &amp;quot;Hello From My Workload (v1)!&amp;quot;,</span>

<span class="c"># 하지만 version: v2 헤더가 있는 경우 v2로 라우팅됩니다.</span>
<span class="nv">$ </span>curl <span class="nt">-is</span> <span class="nt">-H</span> <span class="s2">"Host: api.example.com"</span> <span class="nt">-H</span> <span class="s2">"version: v2"</span> http://localhost:8080/api/my-workload
<span class="nv">$ </span>curl <span class="nt">-is</span> <span class="nt">-H</span> <span class="s2">"Host: api.example.com"</span> <span class="nt">-H</span> <span class="s2">"version: v2"</span> http://localhost:8080/api/my-workload | <span class="nb">grep </span>body
<span class="c"># =&gt;   &amp;quot;body&amp;quot;: &amp;quot;Hello From My Workload (v2)!&amp;quot;,</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> http://api.example.com:8080/api/my-workload | <span class="nb">grep </span>Workload<span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;  100   &amp;quot;body&amp;quot;: &amp;quot;Hello From My Workload (v1)!&amp;quot;,</span>
</code></pre></div></div>

<p><strong>Expand V2 Testing with Percentage-Based Routing</strong></p>

<p>After a successful dark-launch, we may want a period where we use a <strong>blue-green strategy</strong> of gradually <strong>shifting</strong> user traffic from the <strong>old</strong> version to the <strong>new</strong> one. Let’s explore this with a routing policy that splits our traffic evenly, sending half our traffic to <strong><code class="language-plaintext highlighter-rouge">v1</code></strong> and the other <strong>half</strong> to <strong><code class="language-plaintext highlighter-rouge">v2</code></strong>.</p>

<ul>
  <li>성공적인 다크 런칭 이후, 우리는 <strong>점진적</strong>으로 이전 버전에서 새 버전으로 사용자 트래픽을 옮기는 <strong>블루-그린 전략</strong>을 사용하는 기간을 원할 수 있습니다. 트래픽을 균등하게 분할하고 트래픽의 절반을 로 보내고 <code class="language-plaintext highlighter-rouge">v1</code>나머지 절반을 로 보내는 라우팅 정책으로 이를 살펴보겠습니다 <code class="language-plaintext highlighter-rouge">v2</code>.</li>
</ul>

<p>We will modify our <strong><code class="language-plaintext highlighter-rouge">HTTPRoute</code></strong> to accomplish this by removing the header-based routing rule that drove our dark launch. Then we will <strong>replace</strong> that with a <strong>50-50 <code class="language-plaintext highlighter-rouge">weight</code></strong> applied to each of the routes, as shown below:</p>

<p><img src="/assets/2024/kans-3th/w6/20241012_kans_w6_28.png" alt="img.png" /></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  rules:
    - matches:
      - path:
          <span class="nb">type</span>: PathPrefix
          value: /api/my-workload
      <span class="c"># Configure a 50-50 traffic split across v1 and v2 : 버전 1,2 50:50 비율</span>
      backendRefs:
        - name: my-workload-v1
          namespace: my-workload
          port: 8080
          weight: 50
        - name: my-workload-v2
          namespace: my-workload
          port: 8080
          weight: 50
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Apply this 50-50 routing policy with kubectl:</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/solo-io/gloo-gateway-use-cases/main/gateway-api-tutorial/09-workload-route-split.yaml
<span class="c"># =&gt; httproute.gateway.networking.k8s.io/my-workload configured</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl describe httproute <span class="nt">-n</span> my-workload
<span class="c"># =&gt; Spec:</span>
<span class="c">#      ...</span>
<span class="c">#      Rules:</span>
<span class="c">#        Backend Refs:</span>
<span class="c">#          Group:</span>
<span class="c">#          Kind:       Service</span>
<span class="c">#          Name:       my-workload-v1</span>
<span class="c">#          Namespace:  my-workload</span>
<span class="c">#          Port:       8080</span>
<span class="c">#          Weight:     50</span>
<span class="c">#          Group:</span>
<span class="c">#          Kind:       Service</span>
<span class="c">#          Name:       my-workload-v2</span>
<span class="c">#          Namespace:  my-workload</span>
<span class="c">#          Port:       8080</span>
<span class="c">#          Weight:     50</span>
<span class="c">#        Matches:</span>
<span class="c">#          Path:</span>
<span class="c">#            Type:   PathPrefix</span>
<span class="c">#            Value:  /api/my-workload</span>
</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 반복 접속 후 대략 비률 확인</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">-H</span> <span class="s2">"Host: api.example.com"</span> http://localhost:8080/api/my-workload/ | <span class="nb">grep </span>body<span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;   51   &amp;quot;body&amp;quot;: &amp;quot;Hello From My Workload (v1)!&amp;quot;,</span>
<span class="c">#      49   &amp;quot;body&amp;quot;: &amp;quot;Hello From My Workload (v2)!&amp;quot;,</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..200<span class="o">}</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">-H</span> <span class="s2">"Host: api.example.com"</span> http://localhost:8080/api/my-workload/ | <span class="nb">grep </span>body<span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;  116   &amp;quot;body&amp;quot;: &amp;quot;Hello From My Workload (v1)!&amp;quot;,</span>
<span class="c">#      84   &amp;quot;body&amp;quot;: &amp;quot;Hello From My Workload (v2)!&amp;quot;,</span>
</code></pre></div></div>

<h5 id="debug">Debug</h5>

<p><strong>Solve a Problem with Glooctl CLI</strong></p>

<p>A common source of Gloo configuration <strong>errors</strong> is <strong>mistyping</strong> an upstream reference, perhaps when copy/pasting it from another source but “missing a spot” when changing the name of the backend service target. In this example, we’ll simulate making an error like that, and then demonstrating how <code class="language-plaintext highlighter-rouge">glooctl</code> can be used to detect it.</p>

<ul>
  <li>Gloo 구성 오류의 일반적인 원인은 <strong>업스트림 참조를 잘못 입력</strong>하는 것입니다. 아마도 다른 소스에서 복사/붙여넣을 때이지만 백엔드 서비스 대상의 이름을 변경할 때 “한 군데를 놓친” 것입니다. 이 예에서 우리는 그런 오류를 만드는 것을 시뮬레이션하고, <code class="language-plaintext highlighter-rouge">glooctl</code>그것을 감지하는 데 어떻게 사용할 수 있는지 보여줍니다.</li>
</ul>

<p><strong>First</strong>, let’s apply a change to simulate the <strong>mistyping</strong> of an upstream config so that it is targeting a <strong>non-existent <code class="language-plaintext highlighter-rouge">my-bad-workload-v2</code></strong> backend service, rather than the correct <strong><code class="language-plaintext highlighter-rouge">my-workload-v2</code></strong>.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">my-bad-workload-v2</code> 업스트림 구성의 오타를 시뮬레이션하여 올바른 타겟팅하는 대신 존재하지 않는 백엔드 서비스를 타겟팅하도록 변경</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># [신규 터미널] 모니터링</span>
<span class="nv">$ </span>kubectl get httproute <span class="nt">-n</span> my-workload my-workload <span class="nt">-o</span> yaml <span class="nt">-w</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/solo-io/gloo-gateway-use-cases/main/gateway-api-tutorial/10-workload-route-split-bad-dest.yaml
<span class="c"># =&gt; httproute.gateway.networking.k8s.io/my-workload configured</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl describe httproute <span class="nt">-n</span> my-workload
<span class="c"># =&gt; ...</span>
<span class="c">#    Spec:</span>
<span class="c">#      Rules:</span>
<span class="c">#        Backend Refs:</span>
<span class="c">#          Group:</span>
<span class="c">#          Kind:       Service</span>
<span class="c">#          Name:       my-workload-v1</span>
<span class="c">#          Namespace:  my-workload</span>
<span class="c">#          Port:       8080</span>
<span class="c">#          Weight:     50</span>
<span class="c">#          Group:</span>
<span class="c">#          Kind:       Service</span>
<span class="c">#          Name:       my-bad-workload-v2</span>
<span class="c">#          Namespace:  my-workload</span>
<span class="c">#          Port:       8080</span>
<span class="c">#          Weight:     50</span>
<span class="c">#        Matches:</span>
<span class="c">#          Path:</span>
<span class="c">#            Type:   PathPrefix</span>
<span class="c">#            Value:  /api/my-workload</span>
<span class="c">#    Status:</span>
<span class="c">#      Parents:</span>
<span class="c">#        Conditions:</span>
<span class="c">#          Last Transition Time:  2024-10-12T16:55:06Z</span>
<span class="c">#          Message:               Service &amp;quot;my-bad-workload-v2&amp;quot; not found</span>
<span class="c">#          Observed Generation:   4</span>
<span class="c">#          Reason:                BackendNotFound</span>
<span class="c">#          Status:                False</span>
<span class="c">#          Type:                  ResolvedRefs</span>
<span class="c">#          Last Transition Time:  2024-10-12T16:45:41Z</span>
<span class="c">#          Message:</span>
<span class="c">#          Observed Generation:   4</span>
<span class="c">#          Reason:                Accepted</span>
<span class="c">#          Status:                True</span>
<span class="c">#          Type:                  Accepted</span>
<span class="c">#        Controller Name:         solo.io/gloo-gateway</span>
<span class="c">#        Parent Ref:</span>
<span class="c">#          Group:      gateway.networking.k8s.io</span>
<span class="c">#          Kind:       Gateway</span>
<span class="c">#          Name:       http</span>
<span class="c">#          Namespace:  gloo-system</span>
<span class="c">#    Events:           &amp;lt;none&amp;gt;</span>
</code></pre></div></div>

<p>When we test this out, note that the 50-50 traffic split is still in place. This means that about half of the requests will be routed to <code class="language-plaintext highlighter-rouge">my-workload-v1</code> and succeed, while the others will attempt to use the non-existent <code class="language-plaintext highlighter-rouge">my-bad-workload-v2</code> and fail like this:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>curl <span class="nt">-is</span> <span class="nt">-H</span> <span class="s2">"Host: api.example.com"</span> http://localhost:8080/api/my-workload
<span class="c"># =&gt; HTTP/1.1 500 Internal Server Error</span>
<span class="nv">$ </span>curl <span class="nt">-is</span> <span class="nt">-H</span> <span class="s2">"Host: api.example.com"</span> http://localhost:8080/api/my-workload
<span class="c"># =&gt; HTTP/1.1 200 OK</span>
<span class="c">#    vary: Origin</span>
<span class="c">#    date: Sat, 12 Oct 2024 16:56:37 GMT</span>
<span class="c">#    content-length: 292</span>
<span class="c">#    content-type: text/plain; charset=utf-8</span>
<span class="c">#    x-envoy-upstream-service-time: 5</span>
<span class="c">#    server: envoy</span>
<span class="c">#    ...</span>

<span class="c"># </span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nt">-H</span> <span class="s2">"Host: api.example.com"</span> http://localhost:8080/api/my-workload/ | <span class="nb">grep </span>body<span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;   55   &amp;quot;body&amp;quot;: &amp;quot;Hello From My Workload (v1)!&amp;quot;,</span>

<span class="c"># &lt;span style="color: green;"&gt;👉 디버깅 테스트를 위해 일부러 50%의 워크로드에는 오타를 내어서&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;    50%의 요청은 v1로 라우팅되어 성공하고 나머지 50%는 실패합니다.&lt;/span&gt;</span>
</code></pre></div></div>

<p>So we’ll deploy one of the first weapons from the Gloo debugging arsenal, the <code class="language-plaintext highlighter-rouge">glooctl check</code> utility. It verifies a number of Gloo resources, confirming that they are configured correctly and are interconnected with other resources correctly. For example, in this case, <code class="language-plaintext highlighter-rouge">glooctl</code> will detect the error in the mis-connection between the <code class="language-plaintext highlighter-rouge">HTTPRoute</code> and its backend target:</p>

<ul>
  <li>gloo에서 제공하는 <code class="language-plaintext highlighter-rouge">glooctl check</code> 명령으로 구성 오류를 확인합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane bash
<span class="c"># -----------------------------------</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="nv">$HOME</span>/.gloo/bin:<span class="nv">$PATH</span>
<span class="nv">$ </span>glooctl check
<span class="c"># =&gt; ...</span>
<span class="c">#    Checking Gateways... OK</span>
<span class="c">#    Checking Proxies... 1 Errors!</span>
<span class="c">#    </span>
<span class="c">#    Detected Kubernetes Gateway integration!</span>
<span class="c">#    Checking Kubernetes GatewayClasses... OK</span>
<span class="c">#    Checking Kubernetes Gateways... OK</span>
<span class="c">#    Checking Kubernetes HTTPRoutes... 1 Errors!</span>
<span class="c">#    </span>
<span class="c">#    Skipping Gloo Instance check -- Gloo Federation not detected.</span>
<span class="c">#    Error: 2 errors occurred:</span>
<span class="c">#     * Found proxy with warnings by 'gloo-system': gloo-system gloo-system-http</span>
<span class="c">#    Reason: warning:</span>
<span class="c">#      Route Warning: InvalidDestinationWarning. Reason: invalid destination in weighted destination list: *v1.Upstream { blackhole_ns.kube-svc:blackhole-ns-blackhole-cluster-8080 } not found</span>
<span class="c">#    </span>
<span class="c">#     * HTTPRoute my-workload.my-workload.http status (ResolvedRefs) is not set to expected (True). Reason: BackendNotFound, Message: Service &amp;quot;my-bad-workload-v2&amp;quot; not found</span>

<span class="c"># 원인 관련 정보 확인</span>
<span class="nv">$ </span>kubectl get httproute my-workload <span class="nt">-n</span> my-workload <span class="nt">-o</span> yaml
<span class="c"># =&gt; ...</span>
<span class="c">#    status:</span>
<span class="c">#      parents:</span>
<span class="c">#      - conditions:</span>
<span class="c">#        - lastTransitionTime: &amp;quot;2024-10-12T16:55:06Z&amp;quot;</span>
<span class="c">#          message: Service &amp;quot;my-bad-workload-v2&amp;quot; not found</span>
<span class="c">#          observedGeneration: 4</span>
<span class="c">#          reason: BackendNotFound</span>
<span class="c">#          status: &amp;quot;False&amp;quot;</span>
<span class="c">#          type: ResolvedRefs</span>
<span class="c">#          ...</span>

<span class="c"># 정상 설정으로 해결 configuration is again clean.</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/solo-io/gloo-gateway-use-cases/main/gateway-api-tutorial/09-workload-route-split.yaml
<span class="c"># =&gt; httproute.gateway.networking.k8s.io/my-workload configured</span>
<span class="nv">$ </span>kubectl get httproute my-workload <span class="nt">-n</span> my-workload <span class="nt">-o</span> yaml

<span class="c">#</span>
<span class="nv">$ </span>glooctl check
<span class="c"># =&gt; Checking Deployments... OK</span>
<span class="c">#    Checking Pods... OK</span>
<span class="c">#    Checking Upstreams... OK</span>
<span class="c">#    Checking UpstreamGroups... OK</span>
<span class="c">#    Checking AuthConfigs... OK</span>
<span class="c">#    Checking RateLimitConfigs... OK</span>
<span class="c">#    Checking VirtualHostOptions... OK</span>
<span class="c">#    Checking RouteOptions... OK</span>
<span class="c">#    Checking Secrets... OK</span>
<span class="c">#    Checking VirtualServices... OK</span>
<span class="c">#    Checking Gateways... OK</span>
<span class="c">#    Checking Proxies... OK</span>
<span class="c">#    </span>
<span class="c">#    Detected Kubernetes Gateway integration!</span>
<span class="c">#    Checking Kubernetes GatewayClasses... OK</span>
<span class="c">#    Checking Kubernetes Gateways... OK</span>
<span class="c">#    Checking Kubernetes HTTPRoutes... OK</span>
<span class="c">#    </span>
<span class="c">#    Skipping Gloo Instance check -- Gloo Federation not detected.</span>
<span class="c">#    No problems detected.</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 이제 문제가 없다고 합니다. 😀&lt;/span&gt;</span>
</code></pre></div></div>

<h5 id="observe">Observe</h5>

<p><strong>Explore Envoy Metrics</strong></p>

<p><strong>Envoy</strong> publishes a host of <strong>metrics</strong> that may be useful for observing system behavior. In our very modest kind cluster for this exercise, you can count over <strong>3,000 individual metrics</strong>! You can learn more about them in the Envoy documentation <a href="https://www.envoyproxy.io/docs/envoy/latest/configuration/upstream/cluster_manager/cluster_stats">here</a>.</p>

<p>For this 30-minute exercise, let’s take a quick look at a couple of the useful metrics that Envoy produces for every one of our backend targets.</p>

<p>First, we’ll <strong>port-forward</strong> the <strong>Envoy</strong> <strong>administrative</strong> <strong>port</strong> <strong>19000</strong> to our local workstation:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> gloo-system port-forward deployment/gloo-proxy-http 19000 &amp;

<span class="c"># 아래 관리 페이지에서 각각 메뉴 링크 클릭 확인</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"Envoy Proxy Admin - http://localhost:19000"</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"Envoy Proxy Admin - http://localhost:19000/stats/prometheus"</span>tZBli7jsXv<span class="s1">'XALZnaKnB2MSBvJNI
</span></code></pre></div></div>

<p>For this exercise, let’s view <strong>two</strong> of the relevant <strong>metrics</strong> from the first part of this exercise: one that counts the <strong>number</strong> of <strong>successful</strong> (HTTP 2xx) requests processed by our <code class="language-plaintext highlighter-rouge">httpbin</code> backend (or <strong><code class="language-plaintext highlighter-rouge">cluster</code></strong>, in Envoy terminology), and another that <strong>counts</strong> the number of requests <strong>returning</strong> server errors (HTTP <strong>5xx</strong>) from that same backend:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 2xx, 5xx 요청 확인</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> http://localhost:19000/stats | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s2">"(^cluster.kube-svc_httpbin-httpbin-8000_httpbin.upstream.*(2xx|5xx))"</span>
<span class="c"># =&gt; cluster.kube-svc_httpbin-httpbin-8000_httpbin.upstream_rq_2xx: 7</span>

<span class="c"># If we apply a curl request that forces a 500 failure from the httpbin backend, using the /status/500 endpoint, I’d expect the number of 2xx requests to remain the same, and the number of 5xx requests to increment by one:</span>
<span class="nv">$ </span>curl <span class="nt">-is</span> <span class="nt">-H</span> <span class="s2">"Host: api.example.com"</span> http://localhost:8080/api/httpbin/status/500
<span class="c"># =&gt; HTTP/1.1 500 Internal Server Error</span>
<span class="c">#    server: envoy</span>
<span class="c">#    date: Sat, 12 Oct 2024 17:02:53 GMT</span>
<span class="c">#    content-type: text/html; charset=utf-8</span>
<span class="c">#    access-control-allow-origin: *</span>
<span class="c">#    access-control-allow-credentials: true</span>
<span class="c">#    content-length: 0</span>
<span class="c">#    x-envoy-upstream-service-time: 38</span>

<span class="c"># 500에러를 발생시키자 500에러가 1개 증가하고 2xx는 변화가 없습니다.</span>
<span class="nv">$ </span>curl <span class="nt">-s</span> http://localhost:19000/stats | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s2">"(^cluster.kube-svc_httpbin-httpbin-8000_httpbin.upstream.*(2xx|5xx))"</span>
<span class="c"># =&gt; cluster.kube-svc_httpbin-httpbin-8000_httpbin.upstream_rq_2xx: 7</span>
<span class="c">#    cluster.kube-svc_httpbin-httpbin-8000_httpbin.upstream_rq_5xx: 1</span>
</code></pre></div></div>

<h5 id="정리">정리</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kind delete cluster <span class="nt">--name</span> myk8s
<span class="c"># =&gt; Deleted nodes: [&amp;quot;myk8s-control-plane&amp;quot;]</span>
</code></pre></div></div>

<h3 id="기타-gateway-api-구현체">기타 Gateway API 구현체</h3>

<ul>
  <li>
    <dl>
      <dt><strong><code class="language-plaintext highlighter-rouge">Cilium</code></strong></dt>
      <dd>Cilium은 CNI로 알려져있지만 Gateway API 역할도 지원합니다.</dd>
    </dl>
    <ul>
      <li><strong>(참고) [OnlineLab] Cilium Gateway API - <a href="https://isovalent.com/labs/cilium-gateway-api/">Link</a></strong></li>
      <li><strong>(참고) [OnlineLab] Advanced Gateway API Use Cases - <a href="https://isovalent.com/labs/cilium-gateway-api-advanced/">Link</a></strong></li>
    </ul>
  </li>
  <li>
    <dl>
      <dt><strong><code class="language-plaintext highlighter-rouge">Istio</code></strong></dt>
      <dd>Istio는 Service Mesh로 알려져있지만 Gateway API 역할도 지원합니다. Gateway API 자체가 Service Mesh인 Istio 등을 참조하였기에 어찌보면 당연한 일입니다.</dd>
    </dl>
    <ul>
      <li>Kubernetes Traffic Management: Combining Gateway API with Service Mesh for North-South and East-West Use Cases - <a href="https://medium.com/@disha.20.10/kubernetes-traffic-management-combining-gateway-api-with-service-mesh-for-north-south-and-63e39ad95dcc">Blog</a></li>
      <li>Istio Gateway API 활용하기 <a href="https://devops-james.tistory.com/317">https://devops-james.tistory.com/317</a></li>
    </ul>
  </li>
  <li><strong><code class="language-plaintext highlighter-rouge">Kong API Gateway</code></strong>
    <ul>
      <li>Kong API Gateway 를 Gateway API 형태 설치 <a href="https://mokpolar.tistory.com/68">https://mokpolar.tistory.com/68</a></li>
    </ul>
  </li>
  <li><strong><code class="language-plaintext highlighter-rouge">Envoy Gateway</code></strong>
    <ul>
      <li>Envoy Gateway 사용하여 + 부하분산 <a href="https://devops-james.tistory.com/320">https://devops-james.tistory.com/320</a></li>
    </ul>
  </li>
</ul>

<hr />

<h2 id="마치며">마치며</h2>

<p>파드 통신에서 부터 CNI, 서비스(ClusterIP, NodePort, LoadBalancer)를 거쳐, ingress, gateway api까지 왔습니다.
나중에 배운 기술이 이전 기술을 필요없게 만드는 부분도 있지만, 기초의 중요성을 알기에 더욱 중요하다고 생각합니다.</p>

<p>그런데 gateway api를 만들면서 ingress를 frozen 하게 된것은 살짝 충격적입니다.
ingress를 없앤다는 얘기는 없지만 결국 gateway api가 더 좋은 기술이고, 
ingress는 점점 점유율을 잃다가 조용히 deprecated 될것 같은 느낌입니다.
ingress가 심심하지 않도록 더 자주 써줘야겠습니다.</p>

<p>이번주는 특히나 실습이 많았던것 같은데, 다른 분들도 다들 잘 생존했으면 좋겠습니다.
(일단 저부터 스터디에서 생존하기를 빕니다.. :smile:)</p>]]></content><author><name></name></author><category term="kans" /><category term="kubernetes," /><category term="network," /><category term="linux" /><summary type="html"><![CDATA[이번주에는 ingress와 gateway api 에대해 알아 보겠습니다.]]></summary></entry><entry><title type="html">[KANS 3기] LoadBalancer(MetalLB), IPVS</title><link href="https://sweetlittlebird.github.io/posts/2024-10-05-KANS-Study-Week5/" rel="alternate" type="text/html" title="[KANS 3기] LoadBalancer(MetalLB), IPVS" /><published>2024-10-05T01:00:18+09:00</published><updated>2024-10-05T01:00:18+09:00</updated><id>https://sweetlittlebird.github.io/posts/KANS%20Study%20-%20Week5</id><content type="html" xml:base="https://sweetlittlebird.github.io/posts/2024-10-05-KANS-Study-Week5/"><![CDATA[<h2 id="들어가며">들어가며</h2>

<p>이번 주에는 LoadBalancer 서비스와 MetalLB, 그리고 kube-proxy의 모드중 하나인 IPVS에 대해 알아보겠습니다.
KANS 3기 5주차 스터디를 시작하겠습니다.</p>

<hr />

<h2 id="loadbalancer-서비스">LoadBalancer 서비스</h2>

<h3 id="loadbalancer란">LoadBalancer란?</h3>

<ul>
  <li>LoadBalancer는 Kubernetes의 Service 유형의 하나로, 클러스터 외부에서 클러스터 내부의 서비스에 접근할 수 있도록 서비스를
노출시키는 역할을 합니다.</li>
  <li>Kubernetes에서는 자체적으로 LoadBalancer를 제공하지 않고, 클라우드 서비스 제공업체의 LoadBalancer(AWS의 ALB, NLB),
LoadBalancer 하드웨어 장비(Citrix, F5 networks), 또는 오픈소스 LoadBalancer (MetalLB 등)를 사용합니다.</li>
  <li>기본적으로 LoadBalancer를 사용하면 NodePort를 먼저 생성한 다음 LoadBalancer와 연결해야 하지만 (NodePort 접근 방식),
구성에 따라 NodePort 없이 바로 LoadBalancer를 생성할 수도 (Pod Direct 접근 방식) 있습니다.</li>
</ul>

<h3 id="환경별-loadbalancer">환경별 LoadBalancer</h3>

<p><img src="/assets/2024/kans-3th/w5/20241005_kans_w5_1.png" alt="환경별 LoadBalancer 비교" class="image-center" />
<em class="image-caption">환경별 LoadBalancer 비교</em></p>

<h4 id="클라우드-서비스-제공업체의-loadbalancer">클라우드 서비스 제공업체의 LoadBalancer</h4>

<ul>
  <li>클라우드 서비스 제공업체의 LoadBalancer는 클라우드 서비스 제공업체가 제공하는 서비스로, 클라우드 서비스 제공업체의
LoadBalancer를 사용하면 클라우드 서비스 제공업체의 LoadBalancer를 통해 클러스터 외부에서 클러스터 내부의 서비스에
접근할 수 있습니다.</li>
  <li>하지만 클라우드 서비스 제공업체마다 동작 방식과 기능이 다르기 때문에 각 클라우드 서비스 제공업체의 LoadBalancer를
사용할 때는 해당 클라우드 서비스 제공업체의 LoadBalancer의 동작 방식과 기능을 확인해야 합니다.</li>
  <li>대표적인 클라우드 서비스 제공업체인 Amazon Web Service는 다음의 LoadBalancer를 제공합니다.
    <ul>
      <li><strong>Classic Load Balancer (CLB)</strong> : 가장 오래된 로드밸런서로 NLB, ALB보다 기능이 적습니다.</li>
      <li><strong>Network Load Balancer (NLB)</strong> : Layer 4 계층의 네트워크 로드밸런서로 TCP/UDP/TLS 트래픽을 지원합니다. CLB/ALB에 비해서 처리속도가 빠릅니다.
(<strong>Application Load Balancer (ALB)</strong>는 Layer 7 계층의 애플리케이션 로드밸런서로 http/https/gRPC 트래픽을 지원합니다. ALB는 Ingress시 생성됩니다.)</li>
    </ul>
  </li>
</ul>

<h5 id="클라우드-서비스-제공업체의-loadbalancer-서비스-동작-방식">클라우드 서비스 제공업체의 LoadBalancer 서비스 동작 방식</h5>

<ol>
  <li>NodePort 접근 방식
<img src="/assets/2024/kans-3th/w5/20241005_kans_w5_3.png" alt="img.png" class="w-80 image-center" />
    <ul>
      <li>외부 클라이언트는 LoadBalancer의 IP 주소로 요청을 보내면 LoadBalancer는 요청을 받아서 노드들의 NodePort로 부하를 분산하여 전달합니다.</li>
      <li>이때 NodePort로 인입 후에 iptables를 통해 파드로 랜덤 부하분산을 통해 전달합니다.</li>
      <li>이 과정에서 DNAT를 통한 부하 분산과정이 두번 수행됩니다. (LoadBalancer에서 NodePort로 전달될때, 노드의 iptables 룰로 파드 IP로 전달될때)</li>
    </ul>
  </li>
  <li>Pod Direct 접근 방식
<img src="/assets/2024/kans-3th/w5/20241005_kans_w5_4.png" alt="img.png" class="w-80 image-center" />
    <ul>
      <li>LoadBalancer에서 파드의 IP로 직접 부하분산해서 전달합니다.</li>
      <li>LoadBalancer가 파드의 IP 정보를 알기 위해서, 별도의 LoadBalancer Controller를 구성하고 LoadBalancer Controller가 
LoadBalancer에게 파드의 IP를 동적으로 전달합니다.</li>
      <li>이 과정에서 부하 분산과정이 한번 수행되며 NodePort 방식 보다 효율 적입니다.</li>
    </ul>
  </li>
</ol>

<p><img src="/assets/2024/kans-3th/w5/20241005_kans_w5_2.png" alt="클라우드의 LoadBalancer 제공 방식 비교" class="image-center" />
<em class="image-caption">클라우드의 LoadBalancer 제공 방식 비교</em></p>

<h4 id="온프레미스-환경에서의-loadbalancer">온프레미스 환경에서의 LoadBalancer</h4>

<h5 id="하드웨어-장비-기반-loadbalancer-서비스-동작-방식">하드웨어 장비 기반 LoadBalancer 서비스 동작 방식</h5>

<p><img src="/assets/2024/kans-3th/w5/20241005_kans_w5_5.png" alt="img.png" class="w-80 image-center" /></p>
<ul>
  <li>하드웨어 장비 기반 LoadBalancer는 AWS LoadBalancer 서비스와 거의 동일하게 별도의 장비로 접속 후 노드에 NodePort 혹은 파드로 직접
전달하여 통신할 수 있습니다.</li>
  <li>대표적으로 Citrix, F5 Networks의 제품 등이 있습니다.</li>
  <li>예시) Citrix ADC for K8S - <a href="https://www.citrix.com/blogs/2019/09/16/citrix-adc-for-kubernetes-service-of-type-loadbalancer/">링크</a> &amp; Citrix ADC(Ingress/Service) with k8s - <a href="https://www.notion.so/e57b6056f1334c9094f444d1c183f378">링크</a>
<img src="/assets/2024/kans-3th/w5/20241005_kans_w5_17.png" alt="img.png" /></li>
</ul>

<h5 id="소프트웨어-기반-loadbalancer-서비스-동작-방식">소프트웨어 기반 LoadBalancer 서비스 동작 방식</h5>

<ul>
  <li>소프트웨어 기반 LoadBalancer는 별도의 네트워크 장비 없이 소프트웨어로 동작합니다.</li>
  <li>대표적으로 MetalLB, OpenELB, PubeLB, kube-vip, LoxiLB 등이 있습니다.</li>
  <li>MetalLB에 대해서는 좀 더 자세히 알아보겠습니다.</li>
</ul>

<h3 id="metallb">MetalLB</h3>

<ul>
  <li>MetalLB는 Bare<strong>MetalL</strong>oad<strong>B</strong>alancer의 약자로, 온프레미스 환경에서 사용할 수 있는 오픈소스 LoadBalancer입니다.</li>
  <li>쿠버네티스는 DaemonSet으로 Speaker 파드를 생성하여 External IP를 전파합니다. External IP는 노드의 IP 대신 외부에서 
접속할 수 있는 IP 입니다.</li>
  <li>이를 통해 노드의 IP를 외부에 노출하지 않을 수 있어서 보안성을 높일 수 있습니다.</li>
  <li>Speaker 파드는 External IP 전파를 위해 표준 프로토콜인 ARP(Address Resolution Protocol) 혹은 BGP(Border Gateway Protocol)를 사용합니다.</li>
  <li>MetalLB는 일부 퍼블릭 클라우드 플랫폼 환경에서 동작하지 않습니다. 이유는 가상서버 IP에 매칭되는 MAC 주소가 아닌 IP에 대한 ARP 요청을 차단하기 때문입니다.</li>
  <li>또한 일부 CNI에서의 동작에 이슈가 있습니다. Calico의 IPIP 모드에서 BGP 사용시 MetalLB의 BGP와 충돌이 생겨 문제가 발생하곤 합니다.</li>
  <li>실무에서 사용시에는 이슈나 제약사항을 확인하고, 사전 테스트 진행후 사용할 필요가 있습니다.</li>
</ul>

<h4 id="layer2-모드">Layer2 모드</h4>

<ul>
  <li>Layer2 모드는 ARP(Address Resolution Protocol)를 통해서 External IP를 전파합니다.</li>
  <li>ARP란?
<img src="/assets/2024/kans-3th/w5/20241005_kans_w5_6.png" alt="img.png" class="w-80 image-center" />
<em class="image-caption">ARP 동작 모식도 (<a href="https://velog.io/@louie/ARPAddress-Resolution-Protocol">출처</a>)</em>
    <ul>
      <li>동일 네트워크 내부에서 통신을 위해서는 상대방의 MAC(Media Access Control) 주소를 알아야 합니다.</li>
      <li>이때 IP 주소를 전송하면서 이 IP의 주인의 MAC 주소를 알려달라는 패킷을 보내면, 해당 IP 주소를 가진 호스트에서 자신의 MAC 주소를 응답합니다.</li>
      <li>이것이 ARP의 동작 방식이며, ARP 테이블에 IP와 MAC 주소를 저장하고, 이후 통신시 ARP 테이블을 참조하여 통신을 합니다.</li>
    </ul>
  </li>
  <li>ARP에 대해서 알아보았으니 Layer2 동작에 대해 다시 알아보겠습니다.
<img src="/assets/2024/kans-3th/w5/20241005_kans_w5_7.png" alt="img.png" class="image-center" />
<em class="image-caption">MetalLB Layer2 동작 (출처: 추가예정)</em></li>
  <li>위의 그림에서 호스트 NS/파드 NS의 NS는 네임스페이스를 의미하며, 여기서의 네임스페이스는 첫주차 컨테이너 격리에서 배웠던
Linux OS 차원의 네임스페이스를 의미합니다.</li>
  <li>흐름을 파악해보면 아래와 같습니다.
    <ol>
      <li>LoadBalancer 서비스 리소스 생성시 MetalLB 스피커 파드중에 리더(Leader) 스피커 파드가 선택됩니다. 리더 스피커 파드는
해당 LoadBalancer 서비스의 External IP를 가지고 ARP 응답을 합니다. 또한 GARP(Gratuitous ARP)를 통해 네트워크 내의 모든 호스트에게
해당 External IP의 MAC 주소를 전파합니다.
        <ul>
          <li>데몬셋으로 배포된 speaker 파드는 <code class="language-plaintext highlighter-rouge">NetworkMode: host</code>로 호스트 네임스페이스를 공유하며, 호스트 네임스페이스에서 ARP 응답을 합니다.</li>
          <li>만약 리더 스피커 파드에 장애가 발생하면, 다른 스피커 파드가 리더 스피커 파드로 선출됩니다.
            <ul>
              <li>멤버 리스터 및 자애 발견은 hashicorp의 memberlist를 사용합니다.</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>클라이언트1이 SVC1의 External IP로 접속을 시도하면, 해당 트래픽은 SVC1의 External IP 정보를 전파하는 리더 스피커파드가 
있는 노드1으로 전달됩니다. 또한 클라이언트2는 SVC2의 External IP로 접속을 시도하면, 해당 트래픽은 SVC2의 External IP 정보를 전파하는
리더 스피커파드가 있는 노드3로 전달됩니다.</li>
      <li>노드에 도착한 트래픽은 해당 노드의 iptables를 통해 ClusterIP와 동일하게 해당 서비스에 연동된 엔드포인트 파드들로
(4) 랜덤 부하분산 되어 전달됩니다.</li>
    </ol>
  </li>
  <li>Layer2 모드의 단점
    <ul>
      <li>single-node bottlenecking : 리더 스피커 파드가 있는 노드에만 트래픽이 인입되어 부하가 집중 됩니다.</li>
      <li>potentially slow failover : 리더 스피커 파드에 장애가 발생하면, 나머지 노드 리더가 선출되고, ARP 전파 및 갱신 완료전까지는
장애가 발생됩니다. (대략 10초~20초 소요)</li>
    </ul>
  </li>
</ul>

<h4 id="bgp-모드">BGP 모드</h4>

<p><img src="/assets/2024/kans-3th/w5/20241005_kans_w5_8.png" alt="img.png" /></p>

<ul>
  <li>BGP 모드는 Routing 프로토콜인 BGP(Border Gateway Protocol)를 통해서 External IP를 전파합니다.
    <ul>
      <li>기본은 IP주소(32bit)를 전파하며, 설정으로 축약된 네트워크 정보를 전파할 수 있습니다. (bgp-advertisements에 aggregation-length 설정)</li>
      <li>BGP 커뮤니티, localpref 등 다양한 BGP 속성을 사용할 수 있습니다.</li>
      <li>IP 주소의 마지막이 0과 255로 끝나는 IP를 처리 못하는 라우터 장비가 있는 경우 <code class="language-plaintext highlighter-rouge">avoid-buggy-ips: true</code> 설정을 통해 IP가 0과 255로 끝나는 IP를 사용하지 않도록 설정할 수 있습니다.</li>
    </ul>
  </li>
  <li>외부에서 라우터를 통해 ECMP(Equal Cost Multi Path) 라우팅을 통해 부하 분산을 지원합니다.
    <ul>
      <li>일반적으로 ECMP는 5-tuple(프로토콜, 출발지 IP, 목적지 IP, 출발지 포트, 목적지 포트)을 기반으로 동작합니다.</li>
      <li>라우터 장비에 따라 다양한 라우팅(분산) 처리가 가능합니다.</li>
    </ul>
  </li>
  <li>BGP 모드의 제한사항
    <ul>
      <li>라우터에서 서비스로 인입이 되기 때문에, 라우터 설정이 중요하며 네트워크 팀과 협업이 권장됩니다.</li>
      <li>Speaker 노드 파드 장애시 BGP Timer 설정 등, 구성하고 있는 네트워크 환경에 맞게 최적화 작업이 필요합니다.</li>
      <li>ECMP 부하 분산 접속시 특정 파드에 부하가 집중되거나, 세션 고정, flapping 등 다양한 환경에 대응이 필요합니다.</li>
      <li>BGP 라우팅 설정 및 라우팅 전파 관련 최적화 설정이 필요합니다.</li>
    </ul>
  </li>
</ul>

<h3 id="metallb-실습">MetalLB 실습</h3>

<h4 id="실습환경-준비">실습환경 준비</h4>

<ul>
  <li>이번에도 KIND를 통해 실습을 진행해보겠습니다.</li>
</ul>

<h5 id="kind-클러스터-구성">KIND 클러스터 구성</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># kind 클러스터 설정 파일 작성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh">&gt; kind-svc-2w.yaml
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
featureGates:
  "InPlacePodVerticalScaling": true  #실행 중인 파드의 리소스 요청 및 제한을 변경할 수 있게 합니다.
  "MultiCIDRServiceAllocator": true  #서비스에 대해 여러 CIDR 블록을 사용할 수 있게 합니다.
nodes:
- role: control-plane
  labels:
    mynode: control-plane
    topology.kubernetes.io/zone: ap-northeast-2a
  extraPortMappings:  #컨테이너 포트를 호스트 포트에 매핑하여 클러스터 외부에서 서비스에 접근할 수 있도록 합니다.
  - containerPort: 30000
    hostPort: 30000
  - containerPort: 30001
    hostPort: 30001
  - containerPort: 30002
    hostPort: 30002
  - containerPort: 30003
    hostPort: 30003
  - containerPort: 30004
    hostPort: 30004
  kubeadmConfigPatches:
  - |
    kind: ClusterConfiguration
    apiServer:
      extraArgs:  #API 서버에 추가 인수를 제공
        runtime-config: api/all=true  #모든 API 버전을 활성화
    controllerManager:
      extraArgs:
        bind-address: 0.0.0.0
    etcd:
      local:
        extraArgs:
          listen-metrics-urls: http://0.0.0.0:2381
    scheduler:
      extraArgs:
        bind-address: 0.0.0.0
  - |
    kind: KubeProxyConfiguration
    metricsBindAddress: 0.0.0.0
- role: worker
  labels:
    mynode: worker1
    topology.kubernetes.io/zone: ap-northeast-2a
- role: worker
  labels:
    mynode: worker2
    topology.kubernetes.io/zone: ap-northeast-2b
- role: worker
  labels:
    mynode: worker3
    topology.kubernetes.io/zone: ap-northeast-2c
networking:
  podSubnet: 10.10.0.0/16  #파드 IP를 위한 CIDR 범위를 정의합니다. 파드는 이 범위에서 IP를 할당받습니다.
  serviceSubnet: 10.200.1.0/24  #서비스 IP를 위한 CIDR 범위를 정의합니다. 서비스는 이 범위에서 IP를 할당받습니다.
</span><span class="no">EOT

</span><span class="c"># k8s 클러스터 설치</span>
<span class="nv">$ </span>kind create cluster <span class="nt">--config</span> kind-svc-2w.yaml <span class="nt">--name</span> myk8s <span class="nt">--image</span> kindest/node:v1.31.0
<span class="nv">$ </span>docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE                  COMMAND                  CREATED          STATUS          PORTS                                                             NAMES</span>
<span class="c">#    83661e652fb1   kindest/node:v1.31.0   &amp;quot;/usr/local/bin/entr…&amp;quot;   39 seconds ago   Up 34 seconds   0.0.0.0:30000-30004-&amp;gt;30000-30004/tcp, 127.0.0.1:59215-&amp;gt;6443/tcp   myk8s-control-plane</span>
<span class="c">#    242777ad8f3c   kindest/node:v1.31.0   &amp;quot;/usr/local/bin/entr…&amp;quot;   39 seconds ago   Up 34 seconds                                                                     myk8s-worker</span>
<span class="c">#    f8022585c864   kindest/node:v1.31.0   &amp;quot;/usr/local/bin/entr…&amp;quot;   39 seconds ago   Up 34 seconds                                                                     myk8s-worker2</span>
<span class="c">#    80988133cdfc   kindest/node:v1.31.0   &amp;quot;/usr/local/bin/entr…&amp;quot;   39 seconds ago   Up 34 seconds                                                                     myk8s-worker3</span>

<span class="c"># 노드에 기본 툴 설치</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane sh <span class="nt">-c</span> <span class="s1">'apt update &amp;&amp; apt install tree psmisc lsof wget bsdmainutils bridge-utils net-tools dnsutils ipset ipvsadm nfacct tcpdump ngrep iputils-ping arping git vim arp-scan -y'</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>worker worker2 worker3<span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node myk8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-<span class="nv">$i</span> sh <span class="nt">-c</span> <span class="s1">'apt update &amp;&amp; apt install tree psmisc lsof wget bsdmainutils bridge-utils net-tools dnsutils ipset ipvsadm nfacct tcpdump ngrep iputils-ping arping -y'</span><span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>

<span class="c"># k8s v1.31.0 버전 확인</span>
<span class="nv">$ </span>kubectl get node
<span class="c"># =&gt; NAME                  STATUS   ROLES           AGE    VERSION</span>
<span class="c">#    myk8s-control-plane   Ready    control-plane   110s   v1.31.0</span>
<span class="c">#    myk8s-worker          Ready    &amp;lt;none&amp;gt;          100s   v1.31.0</span>
<span class="c">#    myk8s-worker2         Ready    &amp;lt;none&amp;gt;          100s   v1.31.0</span>
<span class="c">#    myk8s-worker3         Ready    &amp;lt;none&amp;gt;          100s   v1.31.0</span>

<span class="c"># 노드 labels 확인</span>
<span class="nv">$ </span>kubectl get nodes <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.items[*].metadata.labels}"</span> | jq
<span class="c"># =&gt; {</span>
<span class="c">#      &amp;quot;kubernetes.io/hostname&amp;quot;: &amp;quot;myk8s-control-plane&amp;quot;,</span>
<span class="c">#      &amp;quot;mynode&amp;quot;: &amp;quot;control-plane&amp;quot;,</span>
<span class="c">#      ...</span>
<span class="c">#    }</span>
<span class="c">#    {</span>
<span class="c">#      &amp;quot;kubernetes.io/hostname&amp;quot;: &amp;quot;myk8s-worker&amp;quot;,</span>
<span class="c">#      &amp;quot;mynode&amp;quot;: &amp;quot;worker1&amp;quot;,</span>
<span class="c">#      ...</span>
<span class="c">#    }</span>
<span class="c">#    {</span>
<span class="c">#      &amp;quot;kubernetes.io/hostname&amp;quot;: &amp;quot;myk8s-worker2&amp;quot;,</span>
<span class="c">#      &amp;quot;mynode&amp;quot;: &amp;quot;worker2&amp;quot;,</span>
<span class="c">#      ...</span>
<span class="c">#    }</span>
<span class="c">#    {</span>
<span class="c">#      &amp;quot;kubernetes.io/hostname&amp;quot;: &amp;quot;myk8s-worker3&amp;quot;,</span>
<span class="c">#      &amp;quot;mynode&amp;quot;: &amp;quot;worker3&amp;quot;,</span>
<span class="c">#      ...</span>
<span class="c">#    }</span>

<span class="c"># kind network 중 컨테이너(노드) IP(대역) 확인</span>
<span class="nv">$ </span>docker ps <span class="nt">-q</span> | xargs docker inspect <span class="nt">--format</span> <span class="s1">' '</span>
<span class="c"># =&gt; /myk8s-control-plane 172.20.0.5</span>
<span class="c">#    /myk8s-worker 172.20.0.4</span>
<span class="c">#    /myk8s-worker2 172.20.0.2</span>
<span class="c">#    /myk8s-worker3 172.20.0.3</span>

<span class="c"># 파드CIDR 과 Service 대역 확인 : CNI는 kindnet 사용</span>
<span class="nv">$ </span>kubectl get cm <span class="nt">-n</span> kube-system kubeadm-config <span class="nt">-oyaml</span> | <span class="nb">grep</span> <span class="nt">-i</span> subnet
<span class="c"># =&gt; podSubnet: 10.10.0.0/16</span>
<span class="c">#    serviceSubnet: 10.200.1.0/24</span>
<span class="nv">$ </span>kubectl cluster-info dump | <span class="nb">grep</span> <span class="nt">-m</span> 2 <span class="nt">-E</span> <span class="s2">"cluster-cidr|service-cluster-ip-range"</span>
<span class="c"># =&gt; &amp;quot;--service-cluster-ip-range=10.200.1.0/24&amp;quot;,</span>
<span class="c">#    &amp;quot;--cluster-cidr=10.10.0.0/16&amp;quot;,</span>

<span class="c"># MultiCIDRServiceAllocator : https://kubernetes.io/docs/tasks/network/extend-service-ip-ranges/</span>
<span class="nv">$ </span>kubectl get servicecidr
<span class="c"># =&gt; NAME         CIDRS           AGE</span>
<span class="c">#    kubernetes   10.200.1.0/24   4m59s</span>

<span class="c"># 노드마다 할당된 dedicated subnet (podCIDR) 확인</span>
<span class="nv">$ </span>kubectl get nodes <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.items[*].spec.podCIDR}"</span>
<span class="c"># =&gt; 10.10.0.0/24 10.10.3.0/24 10.10.2.0/24 10.10.1.0/24</span>

<span class="c"># kube-proxy configmap 확인</span>
<span class="nv">$ </span>kubectl describe cm <span class="nt">-n</span> kube-system kube-proxy
<span class="c"># =&gt; ...</span>
<span class="c">#    mode: iptables</span>
<span class="c">#    iptables:</span>
<span class="c">#      localhostNodePorts: null</span>
<span class="c">#      masqueradeAll: false</span>
<span class="c">#      masqueradeBit: null</span>
<span class="c">#      minSyncPeriod: 1s</span>
<span class="c">#      syncPeriod: 0s</span>
<span class="c">#    ...</span>

<span class="c"># 노드 별 네트워트 정보 확인 : CNI는 kindnet 사용</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>control-plane worker worker2 worker3<span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node myk8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-<span class="nv">$i</span> <span class="nb">cat</span> /etc/cni/net.d/10-kindnet.conflist<span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; node myk8s-control-plane &amp;lt;&amp;lt;</span>
<span class="c">#    {</span>
<span class="c">#     &amp;quot;cniVersion&amp;quot;: &amp;quot;0.3.1&amp;quot;,</span>
<span class="c">#     &amp;quot;name&amp;quot;: &amp;quot;kindnet&amp;quot;,</span>
<span class="c">#     &amp;quot;plugins&amp;quot;: [</span>
<span class="c">#     {</span>
<span class="c">#       &amp;quot;type&amp;quot;: &amp;quot;ptp&amp;quot;,</span>
<span class="c">#       &amp;quot;ipMasq&amp;quot;: false,</span>
<span class="c">#       &amp;quot;ipam&amp;quot;: {</span>
<span class="c">#         &amp;quot;type&amp;quot;: &amp;quot;host-local&amp;quot;,</span>
<span class="c">#         &amp;quot;dataDir&amp;quot;: &amp;quot;/run/cni-ipam-state&amp;quot;,</span>
<span class="c">#         &amp;quot;routes&amp;quot;: [</span>
<span class="c">#           { &amp;quot;dst&amp;quot;: &amp;quot;0.0.0.0/0&amp;quot; }</span>
<span class="c">#         ],</span>
<span class="c">#         &amp;quot;ranges&amp;quot;: [</span>
<span class="c">#           [ { &amp;quot;subnet&amp;quot;: &amp;quot;10.10.0.0/24&amp;quot; } ]</span>
<span class="c">#         ]</span>
<span class="c">#       },</span>
<span class="c">#       &amp;quot;mtu&amp;quot;: 1500</span>
<span class="c">#     },</span>
<span class="c">#     ...</span>
<span class="c">#     ]</span>
<span class="c">#    }</span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; node myk8s-worker &amp;lt;&amp;lt;</span>
<span class="c">#    ...</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>control-plane worker worker2 worker3<span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node myk8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-<span class="nv">$i</span> ip <span class="nt">-c</span> route<span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; node myk8s-control-plane &amp;lt;&amp;lt;</span>
<span class="c">#    default via &lt;span style="color:purple;"&gt;172.20.0.1 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;</span>
<span class="c">#    &lt;span style="color:purple;"&gt;10.10.0.2 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;veth545bb56e &lt;/span&gt;scope host </span>
<span class="c">#    &lt;span style="color:purple;"&gt;10.10.0.3 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;veth184fcd53 &lt;/span&gt;scope host </span>
<span class="c">#    &lt;span style="color:purple;"&gt;10.10.0.4 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;vethc5dfe430 &lt;/span&gt;scope host </span>
<span class="c">#    &lt;span style="color:purple;"&gt;10.10.1.0/24 &lt;/span&gt;via &lt;span style="color:purple;"&gt;172.20.0.3 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;</span>
<span class="c">#    &lt;span style="color:purple;"&gt;10.10.2.0/24 &lt;/span&gt;via &lt;span style="color:purple;"&gt;172.20.0.2 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;</span>
<span class="c">#    &lt;span style="color:purple;"&gt;10.10.3.0/24 &lt;/span&gt;via &lt;span style="color:purple;"&gt;172.20.0.4 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;</span>
<span class="c">#    &lt;span style="color:purple;"&gt;172.20.0.0/16 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;proto kernel scope link src &lt;span style="color:purple;"&gt;172.20.0.5 &lt;/span&gt;</span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; node myk8s-worker &amp;lt;&amp;lt;</span>
<span class="c">#    default via &lt;span style="color:purple;"&gt;172.20.0.1 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;</span>
<span class="c">#    &lt;span style="color:purple;"&gt;10.10.0.0/24 &lt;/span&gt;via &lt;span style="color:purple;"&gt;172.20.0.5 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;</span>
<span class="c">#    &lt;span style="color:purple;"&gt;10.10.1.0/24 &lt;/span&gt;via &lt;span style="color:purple;"&gt;172.20.0.3 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;</span>
<span class="c">#    &lt;span style="color:purple;"&gt;10.10.2.0/24 &lt;/span&gt;via &lt;span style="color:purple;"&gt;172.20.0.2 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;</span>
<span class="c">#    &lt;span style="color:purple;"&gt;172.20.0.0/16 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;proto kernel scope link src &lt;span style="color:purple;"&gt;172.20.0.4 &lt;/span&gt;</span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; node myk8s-worker2 &amp;lt;&amp;lt;</span>
<span class="c">#    default via &lt;span style="color:purple;"&gt;172.20.0.1 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;</span>
<span class="c">#    &lt;span style="color:purple;"&gt;10.10.0.0/24 &lt;/span&gt;via &lt;span style="color:purple;"&gt;172.20.0.5 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;</span>
<span class="c">#    &lt;span style="color:purple;"&gt;10.10.1.0/24 &lt;/span&gt;via &lt;span style="color:purple;"&gt;172.20.0.3 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;</span>
<span class="c">#    &lt;span style="color:purple;"&gt;10.10.3.0/24 &lt;/span&gt;via &lt;span style="color:purple;"&gt;172.20.0.4 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;</span>
<span class="c">#    &lt;span style="color:purple;"&gt;172.20.0.0/16 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;proto kernel scope link src &lt;span style="color:purple;"&gt;172.20.0.2 &lt;/span&gt;</span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; node myk8s-worker3 &amp;lt;&amp;lt;</span>
<span class="c">#    default via &lt;span style="color:purple;"&gt;172.20.0.1 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;</span>
<span class="c">#    &lt;span style="color:purple;"&gt;10.10.0.0/24 &lt;/span&gt;via &lt;span style="color:purple;"&gt;172.20.0.5 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;</span>
<span class="c">#    &lt;span style="color:purple;"&gt;10.10.2.0/24 &lt;/span&gt;via &lt;span style="color:purple;"&gt;172.20.0.2 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;</span>
<span class="c">#    &lt;span style="color:purple;"&gt;10.10.3.0/24 &lt;/span&gt;via &lt;span style="color:purple;"&gt;172.20.0.4 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;</span>
<span class="c">#    &lt;span style="color:purple;"&gt;172.20.0.0/16 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;proto kernel scope link src &lt;span style="color:purple;"&gt;172.20.0.3 &lt;/span&gt;</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>control-plane worker worker2 worker3<span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node myk8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-<span class="nv">$i</span> ip <span class="nt">-c</span> addr<span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; node myk8s-control-plane &amp;lt;&amp;lt;</span>
<span class="c">#    1: &lt;span style="color:teal;"&gt;lo: &lt;/span&gt;&amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span>
<span class="c">#        link/loopback &lt;span style="color:olive;"&gt;00:00:00:00:00:00&lt;/span&gt; brd &lt;span style="color:olive;"&gt;00:00:00:00:00:00&lt;/span&gt;</span>
<span class="c">#        inet &lt;span style="color:purple;"&gt;127.0.0.1&lt;/span&gt;/8 scope host lo</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    2: &lt;span style="color:teal;"&gt;tunl0@NONE: &lt;/span&gt;&amp;lt;NOARP&amp;gt; mtu 1480 qdisc noop state &lt;span style="color:red;"&gt;DOWN &lt;/span&gt;group default qlen 1000</span>
<span class="c">#        link/ipip &lt;span style="color:olive;"&gt;0.0.0.0&lt;/span&gt; brd &lt;span style="color:olive;"&gt;0.0.0.0&lt;/span&gt;</span>
<span class="c">#    4: &lt;span style="color:teal;"&gt;veth545bb56e@if4: &lt;/span&gt;&amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state &lt;span style="color:green;"&gt;UP &lt;/span&gt;group default </span>
<span class="c">#        link/ether &lt;span style="color:olive;"&gt;0e:8b:3c:4f:43:43&lt;/span&gt; brd &lt;span style="color:olive;"&gt;ff:ff:ff:ff:ff:ff&lt;/span&gt; link-netns cni-98b7b37a-bb7a-ea56-47c9-ce3a0b1fb08a</span>
<span class="c">#        inet &lt;span style="color:purple;"&gt;10.10.0.1&lt;/span&gt;/32 scope global veth545bb56e</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    5: &lt;span style="color:teal;"&gt;vethc5dfe430@if4: &lt;/span&gt;&amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state &lt;span style="color:green;"&gt;UP &lt;/span&gt;group default </span>
<span class="c">#        link/ether &lt;span style="color:olive;"&gt;8a:70:dd:42:02:96&lt;/span&gt; brd &lt;span style="color:olive;"&gt;ff:ff:ff:ff:ff:ff&lt;/span&gt; link-netns cni-79ddddfd-6177-bbd6-5fdc-3f7f6bf07fdc</span>
<span class="c">#        inet &lt;span style="color:purple;"&gt;10.10.0.1&lt;/span&gt;/32 scope global vethc5dfe430</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    6: &lt;span style="color:teal;"&gt;veth184fcd53@if4: &lt;/span&gt;&amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state &lt;span style="color:green;"&gt;UP &lt;/span&gt;group default </span>
<span class="c">#        link/ether &lt;span style="color:olive;"&gt;8a:92:74:11:f9:d9&lt;/span&gt; brd &lt;span style="color:olive;"&gt;ff:ff:ff:ff:ff:ff&lt;/span&gt; link-netns cni-5e4ecb7e-2120-f372-76cc-9a467c85159b</span>
<span class="c">#        inet &lt;span style="color:purple;"&gt;10.10.0.1&lt;/span&gt;/32 scope global veth184fcd53</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    28: &lt;span style="color:teal;"&gt;eth0@if29: &lt;/span&gt;&amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state &lt;span style="color:green;"&gt;UP &lt;/span&gt;group default </span>
<span class="c">#        link/ether &lt;span style="color:olive;"&gt;02:42:ac:14:00:05&lt;/span&gt; brd &lt;span style="color:olive;"&gt;ff:ff:ff:ff:ff:ff&lt;/span&gt; link-netnsid 0</span>
<span class="c">#        inet &lt;span style="color:purple;"&gt;172.20.0.5&lt;/span&gt;/16 brd &lt;span style="color:purple;"&gt;172.20.255.255 &lt;/span&gt;scope global eth0</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; node myk8s-worker &amp;lt;&amp;lt;</span>
<span class="c">#    1: &lt;span style="color:teal;"&gt;lo: &lt;/span&gt;&amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span>
<span class="c">#        link/loopback &lt;span style="color:olive;"&gt;00:00:00:00:00:00&lt;/span&gt; brd &lt;span style="color:olive;"&gt;00:00:00:00:00:00&lt;/span&gt;</span>
<span class="c">#        inet &lt;span style="color:purple;"&gt;127.0.0.1&lt;/span&gt;/8 scope host lo</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    2: &lt;span style="color:teal;"&gt;tunl0@NONE: &lt;/span&gt;&amp;lt;NOARP&amp;gt; mtu 1480 qdisc noop state &lt;span style="color:red;"&gt;DOWN &lt;/span&gt;group default qlen 1000</span>
<span class="c">#        link/ipip &lt;span style="color:olive;"&gt;0.0.0.0&lt;/span&gt; brd &lt;span style="color:olive;"&gt;0.0.0.0&lt;/span&gt;</span>
<span class="c">#    26: &lt;span style="color:teal;"&gt;eth0@if27: &lt;/span&gt;&amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state &lt;span style="color:green;"&gt;UP &lt;/span&gt;group default </span>
<span class="c">#        link/ether &lt;span style="color:olive;"&gt;02:42:ac:14:00:04&lt;/span&gt; brd &lt;span style="color:olive;"&gt;ff:ff:ff:ff:ff:ff&lt;/span&gt; link-netnsid 0</span>
<span class="c">#        inet &lt;span style="color:purple;"&gt;172.20.0.4&lt;/span&gt;/16 brd &lt;span style="color:purple;"&gt;172.20.255.255 &lt;/span&gt;scope global eth0</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    ...</span>

<span class="c"># iptables 정보 확인</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>filter nat mangle raw <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; IPTables Type : </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane  iptables <span class="nt">-t</span> <span class="nv">$i</span> <span class="nt">-S</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>filter nat mangle raw <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; IPTables Type : </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker  iptables <span class="nt">-t</span> <span class="nv">$i</span> <span class="nt">-S</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>filter nat mangle raw <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; IPTables Type : </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker2 iptables <span class="nt">-t</span> <span class="nv">$i</span> <span class="nt">-S</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>filter nat mangle raw <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; IPTables Type : </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker3 iptables <span class="nt">-t</span> <span class="nv">$i</span> <span class="nt">-S</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>

<span class="c"># 각 노드 bash 접속</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane bash
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker bash
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker2 bash
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker3 bash
<span class="c"># ----------------------------------------</span>
<span class="nv">$ </span><span class="nb">exit</span>
<span class="c"># ----------------------------------------</span>

<span class="c"># kind 설치 시 kind 이름의 도커 브리지가 생성된다 : 172.20.0.0/16 대역</span>
<span class="nv">$ </span>docker network <span class="nb">ls</span>
<span class="c"># =&gt; NETWORK ID     NAME                     DRIVER    SCOPE</span>
<span class="c">#    a8d530305515   bridge                   bridge    local</span>
<span class="c">#    8204a0851463   host                     host      local</span>
<span class="c">#    3bbcc6aa8f38   kind                     bridge    local</span>

<span class="nv">$ </span>docker inspect kind
<span class="c"># =&gt; [</span>
<span class="c">#        {</span>
<span class="c">#            &amp;quot;Name&amp;quot;: &amp;quot;kind&amp;quot;,</span>
<span class="c">#            &amp;quot;Id&amp;quot;: &amp;quot;3bbcc6aa8f388f86f02478f41de1e4dd917e5812b6cf6257972e4af0bedf5021&amp;quot;,</span>
<span class="c">#            &amp;quot;Created&amp;quot;: &amp;quot;2020-01-01T11:37:09.195259833Z&amp;quot;,</span>
<span class="c">#            &amp;quot;Scope&amp;quot;: &amp;quot;local&amp;quot;,</span>
<span class="c">#            &amp;quot;Driver&amp;quot;: &amp;quot;bridge&amp;quot;,</span>
<span class="c">#            &amp;quot;IPAM&amp;quot;: {</span>
<span class="c">#                &amp;quot;Driver&amp;quot;: &amp;quot;default&amp;quot;,</span>
<span class="c">#                &amp;quot;Options&amp;quot;: {},</span>
<span class="c">#                &amp;quot;Config&amp;quot;: [</span>
<span class="c">#                    {</span>
<span class="c">#                        &amp;quot;Subnet&amp;quot;: &amp;quot;172.20.0.0/16&amp;quot;,</span>
<span class="c">#                        &amp;quot;Gateway&amp;quot;: &amp;quot;172.20.0.1&amp;quot;</span>
<span class="c">#                    }</span>
<span class="c">#                ]</span>
<span class="c">#            },</span>
<span class="c">#            &amp;quot;Internal&amp;quot;: false,</span>
<span class="c">#            &amp;quot;Attachable&amp;quot;: false,</span>
<span class="c">#            &amp;quot;Ingress&amp;quot;: false,</span>
<span class="c">#            &amp;quot;ConfigFrom&amp;quot;: {</span>
<span class="c">#                &amp;quot;Network&amp;quot;: &amp;quot;&amp;quot;</span>
<span class="c">#            },</span>
<span class="c">#            &amp;quot;ConfigOnly&amp;quot;: false,</span>
<span class="c">#            &amp;quot;Containers&amp;quot;: {</span>
<span class="c">#                &amp;quot;242777ad8f3c7009963155c3d7c4551e1407570d6986d9ef6346e6d33990e538&amp;quot;: {</span>
<span class="c">#                    &amp;quot;Name&amp;quot;: &amp;quot;myk8s-worker&amp;quot;,</span>
<span class="c">#                    &amp;quot;EndpointID&amp;quot;: &amp;quot;f6fb304fa38125ed1075d9c71b83559cff5066e71630c272e94311258021144e&amp;quot;,</span>
<span class="c">#                    &amp;quot;MacAddress&amp;quot;: &amp;quot;02:42:ac:14:00:04&amp;quot;,</span>
<span class="c">#                    &amp;quot;IPv4Address&amp;quot;: &amp;quot;172.20.0.4/16&amp;quot;,</span>
<span class="c">#                },</span>
<span class="c">#                &amp;quot;80988133cdfcfaafe520b35cec924b9fa87f26ea474102b833e92d7ca693fb2b&amp;quot;: {</span>
<span class="c">#                    &amp;quot;Name&amp;quot;: &amp;quot;myk8s-worker3&amp;quot;,</span>
<span class="c">#                    &amp;quot;EndpointID&amp;quot;: &amp;quot;42aec973b496fdc7b8ede07c11fd94fe35631216d3ecd54d2ab794849b834787&amp;quot;,</span>
<span class="c">#                    &amp;quot;MacAddress&amp;quot;: &amp;quot;02:42:ac:14:00:03&amp;quot;,</span>
<span class="c">#                    &amp;quot;IPv4Address&amp;quot;: &amp;quot;172.20.0.3/16&amp;quot;,</span>
<span class="c">#                },</span>
<span class="c">#                &amp;quot;83661e652fb1d34542b760209f670f330e25b1c51c8c0404e69d47eb9c79f407&amp;quot;: {</span>
<span class="c">#                    &amp;quot;Name&amp;quot;: &amp;quot;myk8s-control-plane&amp;quot;,</span>
<span class="c">#                    &amp;quot;EndpointID&amp;quot;: &amp;quot;d1e1efb2d90b7d8e9ce16b6274a62e7799d923681739dc8826c36c8b122d09c0&amp;quot;,</span>
<span class="c">#                    &amp;quot;MacAddress&amp;quot;: &amp;quot;02:42:ac:14:00:05&amp;quot;,</span>
<span class="c">#                    &amp;quot;IPv4Address&amp;quot;: &amp;quot;172.20.0.5/16&amp;quot;,</span>
<span class="c">#                },</span>
<span class="c">#                &amp;quot;f8022585c864bd53b31b84e22e2b4381da6c5b7a2ada1583f18136e7f8c6b3b9&amp;quot;: {</span>
<span class="c">#                    &amp;quot;Name&amp;quot;: &amp;quot;myk8s-worker2&amp;quot;,</span>
<span class="c">#                    &amp;quot;EndpointID&amp;quot;: &amp;quot;0866892fb0c2c1c8c2021d92a665a130a20aae5b76fbdc1549138da642a60883&amp;quot;,</span>
<span class="c">#                    &amp;quot;MacAddress&amp;quot;: &amp;quot;02:42:ac:14:00:02&amp;quot;,</span>
<span class="c">#                    &amp;quot;IPv4Address&amp;quot;: &amp;quot;172.20.0.2/16&amp;quot;,</span>
<span class="c">#                }</span>
<span class="c">#            },</span>
<span class="c">#            &amp;quot;Options&amp;quot;: {</span>
<span class="c">#                &amp;quot;com.docker.network.bridge.enable_ip_masquerade&amp;quot;: &amp;quot;true&amp;quot;,</span>
<span class="c">#                &amp;quot;com.docker.network.driver.mtu&amp;quot;: &amp;quot;1500&amp;quot;</span>
<span class="c">#            },</span>
<span class="c">#            &amp;quot;Labels&amp;quot;: {}</span>
<span class="c">#        }</span>
<span class="c">#    ]</span>

<span class="c"># arp scan 해두기</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane arp-scan <span class="nt">--interfac</span><span class="o">=</span>eth0 <span class="nt">--localnet</span>
<span class="c"># =&gt; Interface: eth0, type: EN10MB, MAC: 02:42:ac:14:00:05, IPv4: 172.20.0.5</span>
<span class="c">#    Starting arp-scan 1.10.0 with 65536 hosts (https://github.com/royhills/arp-scan)</span>
<span class="c">#    172.20.0.1      02:42:a0:b9:45:0f       (Unknown: locally administered)</span>
<span class="c">#    172.20.0.2      02:42:ac:14:00:02       (Unknown: locally administered)</span>
<span class="c">#    172.20.0.3      02:42:ac:14:00:03       (Unknown: locally administered)</span>
<span class="c">#    172.20.0.4      02:42:ac:14:00:04       (Unknown: locally administered)</span>

<span class="c"># mypc 컨테이너 기동 : kind 도커 브리지를 사용하고, 컨테이너 IP를 지정 없이 혹은 지정 해서 사용</span>
<span class="nv">$ </span>docker run <span class="nt">-d</span> <span class="nt">--rm</span> <span class="nt">--name</span> mypc <span class="nt">--network</span> kind <span class="nt">--ip</span> 172.20.0.100 nicolaka/netshoot <span class="nb">sleep </span>infinity <span class="c"># IP 지정 실행 시</span>
<span class="c"># =&gt; docker: Error response from daemon: Invalid address 172.20.0.100: It does not belong to any of this network's subnets.</span>
<span class="c"># IP 지정 실행 시 에러 발생 시 아래 처럼 IP 지정 없이 실행</span>
<span class="nv">$ </span>docker run <span class="nt">-d</span> <span class="nt">--rm</span> <span class="nt">--name</span> mypc <span class="nt">--network</span> kind nicolaka/netshoot <span class="nb">sleep </span>infinity <span class="c"># IP 지정 없이 실행 시</span>
<span class="c"># =&gt; 5863ee53a7334a4a524c8c965b2505237c43037ff33f435340b6c167e3484eb6</span>
<span class="nv">$ </span>docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE                  COMMAND                  CREATED          STATUS          PORTS                                                             NAMES</span>
<span class="c">#    5863ee53a733   nicolaka/netshoot      &amp;quot;sleep infinity&amp;quot;         15 seconds ago   Up 14 seconds                                                                     mypc</span>
<span class="c">#    ...</span>

<span class="c"># mypc2 컨테이너 기동 : kind 도커 브리지를 사용하고, 컨테이너 IP를 지정 없이 혹은 지정 해서 사용</span>
<span class="nv">$ </span>docker run <span class="nt">-d</span> <span class="nt">--rm</span> <span class="nt">--name</span> mypc2 <span class="nt">--network</span> kind <span class="nt">--ip</span> 172.20.0.200 nicolaka/netshoot <span class="nb">sleep </span>infinity <span class="c"># IP 지정 실행 시</span>
<span class="c"># =&gt; docker: Error response from daemon: Invalid address 172.20.0.200: It does not belong to any of this network's subnets.</span>
<span class="c"># IP 지정 실행 시 에러 발생 시 아래 처럼 IP 지정 없이 실행</span>
<span class="nv">$ </span>docker run <span class="nt">-d</span> <span class="nt">--rm</span> <span class="nt">--name</span> mypc2 <span class="nt">--network</span> kind nicolaka/netshoot <span class="nb">sleep </span>infinity <span class="c"># IP 지정 없이 실행 시</span>
<span class="c"># =&gt; 0d1d3bc32161bafcf5e188e4788553c88cd278d0a2e8dac02d42216e80a9985c</span>
<span class="nv">$ </span>docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE                  COMMAND                  CREATED              STATUS              PORTS                                                             NAMES</span>
<span class="c">#    0d1d3bc32161   nicolaka/netshoot      &amp;quot;sleep infinity&amp;quot;         9 seconds ago        Up 7 seconds                                                                          mypc2</span>
<span class="c">#    5863ee53a733   nicolaka/netshoot      &amp;quot;sleep infinity&amp;quot;         About a minute ago   Up About a minute                                                                     mypc</span>
<span class="c">#    ...</span>

<span class="c"># kind network 중 컨테이너(노드) IP(대역) 확인</span>
<span class="nv">$ </span>docker ps <span class="nt">-q</span> | xargs docker inspect <span class="nt">--format</span> <span class="s1">' '</span>
<span class="c"># =&gt; /myk8s-control-plane 172.20.0.5</span>
<span class="c">#    /myk8s-worker 172.20.0.4</span>
<span class="c">#    /myk8s-worker2 172.20.0.2</span>
<span class="c">#    /myk8s-worker3 172.20.0.3</span>
<span class="c">#    /mypc 172.20.0.6</span>
<span class="c">#    /mypc2 172.20.0.7</span>

<span class="c"># kube-ops-view 설치</span>
<span class="nv">$ </span>helm repo add geek-cookbook https://geek-cookbook.github.io/charts/
<span class="nv">$ </span>helm <span class="nb">install </span>kube-ops-view geek-cookbook/kube-ops-view <span class="nt">--version</span> 1.2.2 <span class="nt">--set</span> service.main.type<span class="o">=</span>NodePort,service.main.ports.http.nodePort<span class="o">=</span>30000 <span class="nt">--set</span> env.TZ<span class="o">=</span><span class="s2">"Asia/Seoul"</span> <span class="nt">--namespace</span> kube-system
<span class="c"># =&gt; NAME: kube-ops-view</span>
<span class="c">#    LAST DEPLOYED: Sun Jan  1 15:57:45 2020</span>
<span class="c">#    NAMESPACE: kube-system</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 1</span>
<span class="c">#    TEST SUITE: None</span>
<span class="c">#    NOTES:</span>
<span class="c">#    1. Get the application URL by running these commands:</span>
<span class="c">#      export NODE_PORT=$(kubectl get --namespace kube-system -o jsonpath="{.spec.ports[0].nodePort}" services kube-ops-view)</span>
<span class="c">#      export NODE_IP=$(kubectl get nodes --namespace kube-system -o jsonpath="{.items[0].status.addresses[0].address}")</span>
<span class="c">#      echo http://$NODE_IP:$NODE_PORT</span>

<span class="c"># myk8s-control-plane 배치하기 위해서 nodeSelector, tolerations 설정</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system edit deploy kube-ops-view
<span class="c"># =&gt; ---</span>
<span class="c">#    spec:</span>
<span class="c">#      ...</span>
<span class="c">#      template:</span>
<span class="c">#        ...</span>
<span class="c">#        spec:</span>
<span class="c">#          nodeSelector:</span>
<span class="c">#            mynode: control-plane</span>
<span class="c">#          tolerations:</span>
<span class="c">#          - key: "node-role.kubernetes.io/control-plane"</span>
<span class="c">#            operator: "Equal"</span>
<span class="c">#            effect: "NoSchedule"</span>
<span class="c">#    ---</span>

<span class="c"># 설치 확인</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system get pod <span class="nt">-o</span> wide <span class="nt">-l</span> app.kubernetes.io/instance<span class="o">=</span>kube-ops-view
<span class="c"># =&gt; NAME                             READY   STATUS              RESTARTS   AGE   IP       NODE                  NOMINATED NODE   READINESS GATES</span>
<span class="c">#    kube-ops-view-58f96c464d-kp8l8   0/1     ContainerCreating   0          5s    &amp;lt;none&amp;gt;   &lt;span style="color: red;"&gt;myk8s-control-plane&lt;/span&gt;   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>

<span class="c"># kube-ops-view 접속 URL 확인 (1.5 , 2 배율) : macOS 사용자</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"KUBE-OPS-VIEW URL = http://localhost:30000/#scale=1.5"</span>
<span class="c"># =&gt; KUBE-OPS-VIEW URL = http://localhost:30000/#scale=1.5</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"KUBE-OPS-VIEW URL = http://localhost:30000/#scale=2"</span>

<span class="c"># kube-ops-view 접속 URL 확인 (1.5 , 2 배율) : Windows 사용자</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"KUBE-OPS-VIEW URL = http://192.168.50.10:30000/#scale=1.5"</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"KUBE-OPS-VIEW URL = http://192.168.50.10:30000/#scale=2"</span>

<span class="c"># kube-ops-view 접속 URL 확인 (1.5 , 2 배율) : AWS_EC2 사용자</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"KUBE-OPS-VIEW URL = http://</span><span class="si">$(</span>curl <span class="nt">-s</span> ipinfo.io/ip<span class="si">)</span><span class="s2">:30000/#scale=1.5"</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"KUBE-OPS-VIEW URL = http://</span><span class="si">$(</span>curl <span class="nt">-s</span> ipinfo.io/ip<span class="si">)</span><span class="s2">:30000/#scale=2"</span>
</code></pre></div></div>

<p><img src="/assets/2024/kans-3th/w5/20241005_kans_w5_9.png" alt="img.png" class="image-center" />
<em class="image-caption">실습환경이 구축 완료된 kube-ops-view 화면</em></p>

<h5 id="프로메테우스-스택-설치">프로메테우스 스택 설치</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
<span class="c"># =&gt; "prometheus-community" has been added to your repositories</span>

<span class="c"># 파라미터 파일 생성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh"> &gt; monitor-values.yaml
prometheus:
  service:
    type: NodePort
    nodePort: 30001

  prometheusSpec:
    podMonitorSelectorNilUsesHelmValues: false
    serviceMonitorSelectorNilUsesHelmValues: false
    nodeSelector:
      mynode: control-plane
    tolerations:
    - key: "node-role.kubernetes.io/control-plane"
      operator: "Equal"
      effect: "NoSchedule"


grafana:
  defaultDashboardsTimezone: Asia/Seoul
  adminPassword: kans1234

  service:
    type: NodePort
    nodePort: 30002
  nodeSelector:
    mynode: control-plane
  tolerations:
  - key: "node-role.kubernetes.io/control-plane"
    operator: "Equal"
    effect: "NoSchedule"

  #  sidecar:
  #    dashboards:
  #      enabled: true
  #  dashboards:
  #    default:
  #      custom-dashboard:
  #        gnetId: 20162  # MetalLB 대시보드 ID
  #        datasource: Prometheus  # 사용할 데이터소스 이름을 명시
  #        revision: 1    # 대시보드의 버전

defaultRules:
  create: false
alertmanager:
  enabled: false
</span><span class="no">EOT

</span><span class="c"># 배포</span>
<span class="nv">$ </span>kubectl create ns monitoring
<span class="c"># =&gt; namespace/monitoring created</span>
<span class="nv">$ </span>helm <span class="nb">install </span>kube-prometheus-stack prometheus-community/kube-prometheus-stack <span class="nt">--version</span> 62.3.0 <span class="nt">-f</span> monitor-values.yaml <span class="nt">--namespace</span> monitoring
<span class="c"># =&gt; NAME: kube-prometheus-stack</span>
<span class="c">#    LAST DEPLOYED: Sun Jan  1 16:16:32 2020</span>
<span class="c">#    NAMESPACE: monitoring</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 1</span>
<span class="c">#    NOTES:</span>
<span class="c">#    kube-prometheus-stack has been installed. Check its status by running:</span>
<span class="c">#      kubectl --namespace monitoring get pods -l &amp;quot;release=kube-prometheus-stack&amp;quot;</span>
<span class="c">#    </span>
<span class="c">#    Visit https://github.com/prometheus-operator/kube-prometheus for instructions on how to create &amp;amp; configure Alertmanager and Prometheus instances using the Operator.</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>helm list <span class="nt">-n</span> monitoring
<span class="c"># =&gt; NAME                   NAMESPACE   REVISION  UPDATED                               STATUS    CHART                         APP VERSION</span>
<span class="c">#    kube-prometheus-stack  monitoring  1         2020-01-01 16:16:32.988771 +0900 KST  deployed  kube-prometheus-stack-62.3.0  v0.76.0    </span>

<span class="c"># Grafana 접속 계정 : admin / kans1234 : macOS 사용자</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"Prometheus URL = http://localhost:30001"</span>
<span class="c"># =&gt; Prometheus URL = http://localhost:30001</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"Grafana URL = http://localhost:30002"</span>
<span class="c"># =&gt; Grafana URL = http://localhost:30002</span>

<span class="c"># Grafana 접속 계정 : admin / kans1234 : Windows 사용자</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"Prometheus URL = http://192.168.50.10:30001"</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"Grafana URL = http://192.168.50.10:30002"</span>

<span class="c"># Grafana 접속 계정 : admin / kans1234 : AWS_EC2 사용자</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"Prometheus URL = http://</span><span class="si">$(</span>curl <span class="nt">-s</span> ipinfo.io/ip<span class="si">)</span><span class="s2">:30001"</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"Grafana URL = http://</span><span class="si">$(</span>curl <span class="nt">-s</span> ipinfo.io/ip<span class="si">)</span><span class="s2">:30002"</span>

<span class="c"># (참고) helm 삭제</span>
<span class="nv">$ </span>helm uninstall <span class="nt">-n</span> monitoring kube-prometheus-stack
</code></pre></div></div>

<ul>
  <li>그라파나 접속 후 MetalLB 대시보드 import
    <ul>
      <li>Dashboards &gt; Manage &gt; Import</li>
      <li>GnetId : 20162</li>
      <li>Datasource : Prometheus</li>
      <li>Import 버튼 클릭</li>
    </ul>
  </li>
  <li>그라파나 대시보드 확인
    <ul>
      <li>Home &gt; MetalLB 대시보드 선택
<img src="/assets/2024/kans-3th/w5/20241005_kans_w5_10.png" alt="img.png" class="image-center" /></li>
    </ul>
  </li>
</ul>

<h5 id="파드-생성">파드 생성</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: webpod1
  labels:
    app: webpod
spec:
  nodeName: myk8s-worker
  containers:
  - name: container
    image: traefik/whoami
  terminationGracePeriodSeconds: 0
---
apiVersion: v1
kind: Pod
metadata:
  name: webpod2
  labels:
    app: webpod
spec:
  nodeName: myk8s-worker2
  containers:
  - name: container
    image: traefik/whoami
  terminationGracePeriodSeconds: 0
</span><span class="no">EOF
</span><span class="c"># =&gt; pod/webpod1 created</span>
<span class="c">#    pod/webpod2 created</span>

<span class="c"># 파드 정보 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME      READY   STATUS    RESTARTS   AGE   IP          NODE            NOMINATED NODE   READINESS GATES</span>
<span class="c">#    webpod1   1/1     Running   0          38s   10.10.3.2   myk8s-worker    &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    webpod2   1/1     Running   0          38s   10.10.2.3   myk8s-worker2   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>

<span class="c"># 파드 IP주소를 변수에 지정</span>
<span class="nv">$ WPOD1</span><span class="o">=</span><span class="si">$(</span>kubectl get pod webpod1 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.status.podIP}"</span><span class="si">)</span>
<span class="nv">$ WPOD2</span><span class="o">=</span><span class="si">$(</span>kubectl get pod webpod2 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.status.podIP}"</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$WPOD1</span> <span class="nv">$WPOD2</span>
<span class="c"># =&gt; 10.10.3.2 10.10.2.3</span>

<span class="c"># 접속 확인</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane  ping <span class="nt">-i</span> 1 <span class="nt">-W</span> 1 <span class="nt">-c</span> 1 <span class="nv">$WPOD1</span>
<span class="c"># =&gt; PING 10.10.3.2 (10.10.3.2) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 10.10.3.2: icmp_seq=1 ttl=63 time=0.082 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 10.10.3.2 ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 0.082/0.082/0.082/0.000 ms</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane  ping <span class="nt">-i</span> 1 <span class="nt">-W</span> 1 <span class="nt">-c</span> 1 <span class="nv">$WPOD2</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane  curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 <span class="nv">$WPOD1</span> | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod1</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane  curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 <span class="nv">$WPOD2</span> | <span class="nb">grep </span>Hostname
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane  curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 <span class="nv">$WPOD1</span> | egrep <span class="s1">'Hostname|RemoteAddr|Host:'</span>
<span class="c"># =&gt; Hostname: webpod1</span>
<span class="c">#    RemoteAddr: 172.20.0.5:41896</span>
<span class="c">#    Host: 10.10.3.2</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane  curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 <span class="nv">$WPOD2</span> | egrep <span class="s1">'Hostname|RemoteAddr|Host:'</span>
</code></pre></div></div>

<p><img src="/assets/2024/kans-3th/w5/20241005_kans_w5_11.png" alt="img.png" /></p>

<h4 id="metallb---layer2-모드-실습">MetalLB - Layer2 모드 실습</h4>

<h5 id="metallb-설치">MetalLB 설치</h5>

<ul>
  <li>링크 : <a href="https://metallb.universe.tf/installation/">https://metallb.universe.tf/installation/</a></li>
  <li>설치 방법 : Kubernetes manifests, Kustomize, using Helm
    <ul>
      <li>kube-proxy가 ipvs 모드 사용시 <code class="language-plaintext highlighter-rouge">strictARP: true</code> 설정 필요</li>
    </ul>
  </li>
  <li>간단하게 manifests로 설치하겠습니다. - <a href="https://github.com/metallb/metallb/tree/main/config/manifests">링크</a></li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Kubernetes manifests 로 설치</span>
<span class="c"># kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.14.8/config/manifests/metallb-native.yaml</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/metallb/metallb/refs/heads/main/config/manifests/metallb-native-prometheus.yaml
<span class="c"># =&gt; namespace/metallb-system created</span>
<span class="c">#    ...</span>
<span class="c">#    serviceaccount/speaker created</span>
<span class="c">#    ...</span>
<span class="c">#    daemonset.apps/speaker created</span>
<span class="c">#    servicemonitor.monitoring.coreos.com/controller-monitor created</span>
<span class="c">#    servicemonitor.monitoring.coreos.com/speaker-monitor created</span>
<span class="c">#    validatingwebhookconfiguration.admissionregistration.k8s.io/metallb-webhook-configuration created</span>

<span class="c"># metallb crd 확인</span>
<span class="nv">$ </span>kubectl get crd | <span class="nb">grep </span>metallb
<span class="c"># =&gt; bfdprofiles.metallb.io                      2020-01-01T07:31:16Z</span>
<span class="c">#    bgpadvertisements.metallb.io                2020-01-01T07:31:16Z</span>
<span class="c">#    bgppeers.metallb.io                         2020-01-01T07:31:16Z</span>
<span class="c">#    communities.metallb.io                      2020-01-01T07:31:16Z</span>
<span class="c">#    ipaddresspools.metallb.io                   2020-01-01T07:31:17Z</span>
<span class="c">#    l2advertisements.metallb.io                 2020-01-01T07:31:17Z</span>
<span class="c">#    servicel2statuses.metallb.io                2020-01-01T07:31:17Z</span>

<span class="c"># 생성된 리소스 확인 : metallb-system 네임스페이스 생성, 파드(컨트롤러, 스피커) 생성, RBAC(서비스/파드/컨피그맵 조회 등등 권한들), SA 등</span>
<span class="nv">$ </span>kubectl get-all <span class="nt">-n</span> metallb-system <span class="c"># kubectl krew 플러그인 get-all 설치 후 사용 가능</span>
<span class="nv">$ </span>kubectl get all,configmap,secret,ep <span class="nt">-n</span> metallb-system
<span class="c"># =&gt; NAME                              READY   STATUS    RESTARTS      AGE</span>
<span class="c">#    pod/controller-679855f7d7-m8spp   2/2     Running   0             5m36s</span>
<span class="c">#    pod/speaker-dm26z                 2/2     Running   4 (91s ago)   5m36s</span>
<span class="c">#    pod/speaker-dr8kh                 2/2     Running   0             5m36s</span>
<span class="c">#    pod/speaker-pctt7                 2/2     Running   3 (90s ago)   5m36s</span>
<span class="c">#    pod/speaker-w69v6                 2/2     Running   4 (91s ago)   5m36s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                 TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE</span>
<span class="c">#    service/controller-monitor-service   ClusterIP   None           &amp;lt;none&amp;gt;        9120/TCP   5m36s</span>
<span class="c">#    service/metallb-webhook-service      ClusterIP   10.200.1.191   &amp;lt;none&amp;gt;        443/TCP    5m36s</span>
<span class="c">#    service/speaker-monitor-service      ClusterIP   None           &amp;lt;none&amp;gt;        9120/TCP   5m36s</span>
<span class="c">#    </span>
<span class="c">#    NAME                     DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE</span>
<span class="c">#    daemonset.apps/speaker   4         4         4       4            4           kubernetes.io/os=linux   5m36s</span>
<span class="c">#    </span>
<span class="c">#    NAME                         READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/controller   1/1     1            1           5m36s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                    DESIRED   CURRENT   READY   AGE</span>
<span class="c">#    replicaset.apps/controller-679855f7d7   1         1         1       5m36s</span>
<span class="c">#    </span>
<span class="c">#    NAME                          DATA   AGE</span>
<span class="c">#    configmap/kube-root-ca.crt    1      5m37s</span>
<span class="c">#    configmap/metallb-excludel2   1      5m36s</span>
<span class="c">#    </span>
<span class="c">#    NAME                          TYPE     DATA   AGE</span>
<span class="c">#    secret/memberlist             Opaque   1      5m18s</span>
<span class="c">#    secret/metallb-webhook-cert   Opaque   4      5m36s</span>
<span class="c">#    </span>
<span class="c">#    NAME                                   ENDPOINTS                                                     AGE</span>
<span class="c">#    endpoints/controller-monitor-service   10.10.1.3:9120                                                5m36s</span>
<span class="c">#    endpoints/metallb-webhook-service      10.10.1.3:9443                                                5m36s</span>
<span class="c">#    endpoints/speaker-monitor-service      172.20.0.2:9120,172.20.0.3:9120,172.20.0.4:9120 + 1 more...   5m36s</span>

<span class="c"># 파드 내에 kube-rbac-proxy 컨테이너는 프로메테우스 익스포터 역할 제공</span>
<span class="nv">$ </span>kubectl get pods <span class="nt">-n</span> metallb-system <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>metallb <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{range .items[*]}{.metadata.name}{':</span><span class="se">\n</span><span class="s2">'}{range .spec.containers[*]}{'  '}{.name}{' -&gt; '}{.image}{'</span><span class="se">\n</span><span class="s2">'}{end}{end}"</span>
<span class="c"># =&gt; controller-679855f7d7-m8spp:</span>
<span class="c">#      kube-rbac-proxy -&amp;gt; gcr.io/kubebuilder/kube-rbac-proxy:v0.12.0</span>
<span class="c">#      controller -&amp;gt; quay.io/metallb/controller:main</span>
<span class="c">#    speaker-dm26z:</span>
<span class="c">#      kube-rbac-proxy -&amp;gt; gcr.io/kubebuilder/kube-rbac-proxy:v0.12.0</span>
<span class="c">#      speaker -&amp;gt; quay.io/metallb/speaker:main</span>
<span class="c">#    speaker-dr8kh:</span>
<span class="c">#      kube-rbac-proxy -&amp;gt; gcr.io/kubebuilder/kube-rbac-proxy:v0.12.0</span>
<span class="c">#      speaker -&amp;gt; quay.io/metallb/speaker:main</span>
<span class="c">#    speaker-pctt7:</span>
<span class="c">#      kube-rbac-proxy -&amp;gt; gcr.io/kubebuilder/kube-rbac-proxy:v0.12.0</span>
<span class="c">#      speaker -&amp;gt; quay.io/metallb/speaker:main</span>
<span class="c">#    speaker-w69v6:</span>
<span class="c">#      kube-rbac-proxy -&amp;gt; gcr.io/kubebuilder/kube-rbac-proxy:v0.12.0</span>
<span class="c">#      speaker -&amp;gt; quay.io/metallb/speaker:main</span>

<span class="c">## metallb 컨트롤러는 디플로이먼트로 배포됨</span>
<span class="nv">$ </span>kubectl get ds,deploy <span class="nt">-n</span> metallb-system
<span class="c"># =&gt; NAME                     DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE</span>
<span class="c">#    daemonset.apps/speaker   4         4         4       4            4           kubernetes.io/os=linux   6m26s</span>
<span class="c">#    </span>
<span class="c">#    NAME                         READY   UP-TO-DATE   AVAILABLE   AGE</span>
<span class="c">#    deployment.apps/controller   1/1     1            1           6m26s</span>

<span class="c">## 데몬셋으로 배포되는 metallb 스피커 파드의 IP는 네트워크가 host 모드이므로 노드의 IP를 그대로 사용</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-n</span> metallb-system <span class="nt">-o</span> wide
<span class="c"># =&gt; NAME                          READY   STATUS    RESTARTS   AGE   IP           NODE                  NOMINATED NODE   READINESS GATES</span>
<span class="c">#    controller-679855f7d7-rg9pw   2/2     Running   0          22m   10.10.1.3    myk8s-worker3         &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    speaker-9njww                 2/2     Running   0          22m   172.20.0.3   myk8s-worker3         &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    speaker-lk9wt                 2/2     Running   0          22m   172.20.0.2   myk8s-worker2         &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    speaker-wz9w5                 2/2     Running   0          22m   172.20.0.5   myk8s-control-plane   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    speaker-zbwdq                 2/2     Running   0          22m   172.20.0.4   myk8s-worker          &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>

<span class="c"># (참고) 상세 정보 확인</span>
<span class="nv">$ </span>kubectl get sa,cm,secret <span class="nt">-n</span> metallb-system
<span class="nv">$ </span>kubectl describe role <span class="nt">-n</span> metallb-system
<span class="nv">$ </span>kubectl describe deploy controller <span class="nt">-n</span> metallb-system
<span class="nv">$ </span>kubectl describe ds speaker <span class="nt">-n</span> metallb-system
</code></pre></div></div>

<ul>
  <li>컨피그맵 생성 : 모드 및 서비스 대역 지정
    <ul>
      <li>서비스(External-IP) 대역을 노드가 속한 eth0의 대역이 아니여도 상관없습니다.
다만, 이 경우 GW 역할의 라우터에서 노드들로 라우팅 경로 지정 필요합니다.</li>
    </ul>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># kind 설치 시 kind 이름의 도커 브리지가 생성됩니다 : 172.20.0.0/16 대역</span>
<span class="nv">$ </span>docker network <span class="nb">ls</span>
<span class="c"># =&gt; NETWORK ID     NAME                     DRIVER    SCOPE</span>
<span class="c">#    a8d530305515   bridge                   bridge    local</span>
<span class="c">#    8204a0851463   host                     host      local</span>
<span class="c">#    3bbcc6aa8f38   kind                     bridge    local</span>
<span class="nv">$ </span>docker inspect kind
<span class="c"># kind network 중 컨테이너(노드) IP(대역) 확인 : 172.20.0.2~ 부터 할당되며, control-plane 이 꼭 172.20.0.2가 안될 수 도 있음</span>
<span class="nv">$ </span>docker ps <span class="nt">-q</span> | xargs docker inspect <span class="nt">--format</span> <span class="s1">' '</span>
<span class="c"># =&gt; /mypc2 172.20.0.7</span>
<span class="c">#    /mypc 172.20.0.6</span>
<span class="c">#    /myk8s-worker 172.20.0.4</span>
<span class="c">#    /myk8s-control-plane 172.20.0.5</span>
<span class="c">#    /myk8s-worker2 172.20.0.2</span>
<span class="c">#    /myk8s-worker3 172.20.0.3</span>

<span class="c"># IPAddressPool 생성 : LoadBalancer External IP로 사용할 IP 대역</span>
<span class="c">## MetalLB는 서비스를 위한 외부 IP 주소를 관리하고, 서비스가 생성될 때 해당 IP 주소를 동적으로 할당할 수 있습니다.</span>
<span class="nv">$ </span>kubectl explain ipaddresspools.metallb.io

<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: metallb.io/v1beta1
kind: IPAddressPool
metadata:
  name: my-ippool
  namespace: metallb-system
spec:
  addresses:
  - 172.20.255.200-172.20.255.250
</span><span class="no">EOF
</span><span class="c"># =&gt; ipaddresspool.metallb.io/my-ippool unchanged</span>

<span class="nv">$ </span>kubectl get ipaddresspools <span class="nt">-n</span> metallb-system
<span class="c"># =&gt; NAME        AUTO ASSIGN   AVOID BUGGY IPS   ADDRESSES</span>
<span class="c">#    my-ippool   true          false             [&amp;quot;172.20.255.200-172.20.255.250&amp;quot;]</span>

<span class="c"># L2Advertisement 생성 : 설정한 IPpool을 기반으로 Layer2 모드로 LoadBalancer IP 사용 허용</span>
<span class="c">## Kubernetes 클러스터 내의 서비스가 외부 네트워크에 IP 주소를 광고하는 방식을 정의</span>

<span class="nv">$ </span>kubectl explain l2advertisements.metallb.io

<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: metallb.io/v1beta1
kind: L2Advertisement
metadata:
  name: my-l2-advertise
  namespace: metallb-system
spec:
  ipAddressPools:
  - my-ippool
</span><span class="no">EOF
</span><span class="c"># =&gt; l2advertisement.metallb.io/my-l2-advertise created</span>

<span class="nv">$ </span>kubectl get l2advertisements <span class="nt">-n</span> metallb-system
<span class="c"># =&gt; NAME              IPADDRESSPOOLS   IPADDRESSPOOL SELECTORS   INTERFACES</span>
<span class="c">#    my-l2-advertise   [&amp;quot;my-ippool&amp;quot;]                              </span>
</code></pre></div></div>

<ul>
  <li>로그 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># (옵션) metallb-speaker 파드 로그 확인</span>
<span class="nv">$ </span>kubectl logs <span class="nt">-n</span> metallb-system <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>metallb <span class="nt">-f</span>
<span class="nv">$ </span>kubectl logs <span class="nt">-n</span> metallb-system <span class="nt">-l</span> <span class="nv">component</span><span class="o">=</span>speaker <span class="nt">--since</span> 1h
<span class="nv">$ </span>kubectl logs <span class="nt">-n</span> metallb-system <span class="nt">-l</span> <span class="nv">component</span><span class="o">=</span>speaker <span class="nt">-f</span>

<span class="c"># (옵션) kubectl krew 플러그인 stern 설치 후 아래 명령 사용 가능</span>
<span class="nv">$ </span>kubectl stern <span class="nt">-n</span> metallb-system <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>metallb
<span class="nv">$ </span>kubectl stern <span class="nt">-n</span> metallb-system <span class="nt">-l</span> <span class="nv">component</span><span class="o">=</span>speaker <span class="nt">--since</span> 1h
<span class="nv">$ </span>kubectl stern <span class="nt">-n</span> metallb-system <span class="nt">-l</span> <span class="nv">component</span><span class="o">=</span>speaker <span class="c"># 기본 설정이 follow</span>
<span class="nv">$ </span>kubectl stern <span class="nt">-n</span> metallb-system speaker  <span class="c"># 매칭 사용 가능</span>
</code></pre></div></div>

<h5 id="서비스-생성-및-확인">서비스 생성 및 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Service
metadata:
  name: svc1
spec:
  ports:
    - name: svc1-webport
      port: 80
      targetPort: 80
  selector:
    app: webpod
  type: LoadBalancer  # 서비스 타입이 LoadBalancer
---
apiVersion: v1
kind: Service
metadata:
  name: svc2
spec:
  ports:
    - name: svc2-webport
      port: 80
      targetPort: 80
  selector:
    app: webpod
  type: LoadBalancer
---
apiVersion: v1
kind: Service
metadata:
  name: svc3
spec:
  ports:
    - name: svc3-webport
      port: 80
      targetPort: 80
  selector:
    app: webpod
  type: LoadBalancer
</span><span class="no">EOF
</span><span class="c"># =&gt; service/svc1 created</span>
<span class="c">#    service/svc2 created</span>
<span class="c">#    service/svc3 created</span>
</code></pre></div></div>

<h5 id="서비스-확인-및-리더-speaker-파드-확인">서비스 확인 및 리더 Speaker 파드 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># arp scan 해두기</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane arp-scan <span class="nt">--interfac</span><span class="o">=</span>eth0 <span class="nt">--localnet</span>
<span class="c"># =&gt; Interface: eth0, type: EN10MB, MAC: 02:42:ac:14:00:05, IPv4: 172.20.0.5</span>
<span class="c">#    Starting arp-scan 1.10.0 with 65536 hosts (https://github.com/royhills/arp-scan)</span>
<span class="c">#    172.20.0.1      02:42:1f:41:79:66       (Unknown: locally administered)</span>
<span class="c">#    172.20.0.2      02:42:ac:14:00:02       (Unknown: locally administered)</span>
<span class="c">#    172.20.0.3      02:42:ac:14:00:03       (Unknown: locally administered)</span>
<span class="c">#    172.20.0.4      02:42:ac:14:00:04       (Unknown: locally administered)</span>
<span class="c">#    172.20.0.6      02:42:ac:14:00:06       (Unknown: locally administered)</span>
<span class="c">#    172.20.0.7      02:42:ac:14:00:07       (Unknown: locally administered)</span>

<span class="c"># LoadBalancer 타입의 서비스 생성 확인 : EXTERNAL-IP가 서비스 마다 할당되며, 실습 환경에 따라 다를 수 있음</span>
<span class="c">## LoadBalancer 타입의 서비스는 NodePort 와 ClusterIP 를 포함함 - 'allocateLoadBalancerNodePorts : true' 기본값</span>
<span class="c">## ExternalIP 로 접속 시 사용하는 포트는 PORT(S) 의 앞에 있는 값을 사용 (아래의 경우는 TCP 80 임)</span>
<span class="c">## 만약 노드의 IP에 NodePort 로 접속 시 사용하는 포트는 PORT(S) 의 뒤에 있는 값을 사용 (아래는 30485 임)</span>
<span class="nv">$ </span>kubectl get service,ep
<span class="c"># =&gt; NAME                 TYPE           CLUSTER-IP     EXTERNAL-IP      PORT(S)        AGE</span>
<span class="c">#    service/kubernetes   ClusterIP      10.200.1.1     &amp;lt;none&amp;gt;           443/TCP        3h55m</span>
<span class="c">#    service/svc1         LoadBalancer   10.200.1.213   172.20.255.200   80:32145/TCP   128m</span>
<span class="c">#    service/svc2         LoadBalancer   10.200.1.59    172.20.255.201   80:32238/TCP   128m</span>
<span class="c">#    service/svc3         LoadBalancer   10.200.1.201   172.20.255.202   80:31593/TCP   128m</span>
<span class="c">#    </span>
<span class="c">#    NAME                   ENDPOINTS                   AGE</span>
<span class="c">#    endpoints/kubernetes   172.20.0.5:6443             3h55m</span>
<span class="c">#    endpoints/svc1         10.10.2.3:80,10.10.3.2:80   128m</span>
<span class="c">#    endpoints/svc2         10.10.2.3:80,10.10.3.2:80   128m</span>
<span class="c">#    endpoints/svc3         10.10.2.3:80,10.10.3.2:80   128m</span>

<span class="c"># LoadBalancer 타입은 기본적으로 NodePort를 포함 사용. NodePort는 ClusterIP를 포함 사용.</span>
<span class="c">## 클라우드사업자 LB Type이나 온프레미스환경 HW LB Type 경우 LB 사용 시 NodePort 미사용 설정 가능</span>
<span class="nv">$ </span>kubectl describe svc svc1
<span class="c"># =&gt; Name:                     svc1</span>
<span class="c">#    ...</span>
<span class="c">#    Annotations:              metallb.io/ip-allocated-from-pool: my-ippool</span>
<span class="c">#    Selector:                 app=webpod</span>
<span class="c">#    Type:                     LoadBalancer</span>
<span class="c">#    IP Family Policy:         SingleStack</span>
<span class="c">#    IP Families:              IPv4</span>
<span class="c">#    IP:                       10.200.1.213</span>
<span class="c">#    IPs:                      10.200.1.213</span>
<span class="c">#    LoadBalancer Ingress:     172.20.255.200 (VIP)</span>
<span class="c">#    Port:                     svc1-webport  80/TCP</span>
<span class="c">#    TargetPort:               80/TCP</span>
<span class="c">#    NodePort:                 svc1-webport  32145/TCP</span>
<span class="c">#    Endpoints:                10.10.3.2:80,10.10.2.3:80</span>
<span class="c">#    Session Affinity:         None</span>
<span class="c">#    External Traffic Policy:  Cluster</span>
<span class="c">#    Internal Traffic Policy:  Cluster</span>
<span class="c">#    Events:</span>
<span class="c">#      Type    Reason       Age    From                Message</span>
<span class="c">#      ----    ------       ----   ----                -------</span>
<span class="c">#      Normal  IPAllocated  3m19s  metallb-controller  Assigned IP [&amp;quot;172.20.255.200&amp;quot;]</span>
<span class="c">#      Normal  nodeAssigned  5m55s (x2 over 5m55s)  metallb-speaker  announcing from node &amp;quot;myk8s-worker&amp;quot; with protocol &amp;quot;layer2&amp;quot;</span>

<span class="c">## 아래 처럼 LB VIP 별로 이던 speaker 배포된 노드가 리더 역할을 하는지 확인 가능</span>
<span class="nv">$ </span>kubectl describe svc | <span class="nb">grep </span>Events: <span class="nt">-A5</span>
<span class="c"># =&gt; Events:                   &amp;lt;none&amp;gt;</span>
<span class="c">#</span>
<span class="c">#    Name:                     svc1</span>
<span class="c">#    Namespace:                default</span>
<span class="c">#    Labels:                   &amp;lt;none&amp;gt;</span>
<span class="c">#    --</span>
<span class="c">#    Events:</span>
<span class="c">#      Type    Reason       Age    From                Message</span>
<span class="c">#      ----    ------       ----   ----                -------</span>
<span class="c">#      Normal  IPAllocated  4m24s  metallb-controller  Assigned IP [&amp;quot;172.20.255.200&amp;quot;]</span>
<span class="c">#      Normal  nodeAssigned 6m42s (x2 over 6m42s)  metallb-speaker  announcing from node "myk8s-worker" with protocol "layer2"</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>kubectl get svc svc1 <span class="nt">-o</span> json | jq
<span class="c"># =&gt; ...</span>
<span class="c">#      &amp;quot;spec&amp;quot;: {</span>
<span class="c">#        &amp;quot;allocateLoadBalancerNodePorts&amp;quot;: true,</span>
<span class="c">#      ...</span>
<span class="c">#      &amp;quot;status&amp;quot;: {</span>
<span class="c">#        &amp;quot;loadBalancer&amp;quot;: {</span>
<span class="c">#          &amp;quot;ingress&amp;quot;: [</span>
<span class="c">#            {</span>
<span class="c">#              &amp;quot;ip&amp;quot;: &amp;quot;172.20.255.200&amp;quot;,</span>
<span class="c">#              &amp;quot;ipMode&amp;quot;: &amp;quot;VIP&amp;quot;</span>
<span class="c">#    ...</span>

<span class="c"># metallb CRD인 servicel2status 로 상태 정보 확인</span>
<span class="nv">$ </span>kubectl explain servicel2status
<span class="nv">$ </span>kubectl get servicel2status <span class="nt">-n</span> metallb-system
<span class="c"># =&gt; NAME       ALLOCATED NODE   SERVICE NAME   SERVICE NAMESPACE</span>
<span class="c">#    l2-cm8sw   myk8s-worker     svc2           default</span>
<span class="c">#    l2-j6w4k   myk8s-worker     svc1           default</span>
<span class="c">#    l2-k5cdm   myk8s-worker3    svc3           default</span>
<span class="nv">$ </span>kubectl describe servicel2status <span class="nt">-n</span> metallb-system
<span class="nv">$ </span>kubectl get servicel2status <span class="nt">-n</span> metallb-system <span class="nt">-o</span> json <span class="nt">--watch</span> <span class="c"># watch 모드</span>

<span class="c"># 현재 SVC EXTERNAL-IP를 변수에 지정</span>
<span class="nv">$ SVC1EXIP</span><span class="o">=</span><span class="si">$(</span>kubectl get svc svc1 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.loadBalancer.ingress[0].ip}'</span><span class="si">)</span>
<span class="nv">$ SVC2EXIP</span><span class="o">=</span><span class="si">$(</span>kubectl get svc svc2 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.loadBalancer.ingress[0].ip}'</span><span class="si">)</span>
<span class="nv">$ SVC3EXIP</span><span class="o">=</span><span class="si">$(</span>kubectl get svc svc3 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.loadBalancer.ingress[0].ip}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$SVC1EXIP</span> <span class="nv">$SVC2EXIP</span> <span class="nv">$SVC3EXIP</span>
<span class="c"># =&gt; 172.20.255.200 172.20.255.201 172.20.255.202</span>

<span class="c"># mypc/mypc2 에서 현재 SVC EXTERNAL-IP를 담당하는 리더 Speaker 파드 찾는법 : arping 툴 사용</span>
<span class="c">## Unicast reply from 172.20.255.200: 해당 IP 주소에서 응답을 받았음을 의미합니다. </span>
<span class="c">## Sent 1 probes (1 broadcast(s)): 하나의 ARP 요청을 보냈고, 브로드캐스트 방식으로 요청을 전송했음을 나타냅니다.</span>
<span class="c">## Received 1 response(s): 하나의 응답을 수신했음을 나타냅니다.</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc arping <span class="nt">-I</span> eth0 <span class="nt">-f</span> <span class="nt">-c</span> 1 <span class="nv">$SVC1EXIP</span>
<span class="c"># =&gt; ARPING 172.20.255.200 from 172.20.0.6 eth0</span>
<span class="c">#    Unicast reply from 172.20.255.200 [02:42:AC:14:00:03]  1.139ms</span>
<span class="c">#    Sent 1 probes (1 broadcast(s))</span>
<span class="c">#    Received 1 response(s)</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc arping <span class="nt">-I</span> eth0 <span class="nt">-f</span> <span class="nt">-c</span> 1 <span class="nv">$SVC2EXIP</span>
<span class="c"># =&gt; ARPING 172.20.255.201 from 172.20.0.6 eth0</span>
<span class="c">#    Unicast reply from 172.20.255.201 [02:42:AC:14:00:02]  1.827ms</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc arping <span class="nt">-I</span> eth0 <span class="nt">-f</span> <span class="nt">-c</span> 1 <span class="nv">$SVC3EXIP</span>
<span class="c"># =&gt; ARPING 172.20.255.202 from 172.20.0.6 eth0</span>
<span class="c">#    Unicast reply from 172.20.255.202 [02:42:AC:14:00:04]  0.982ms</span>
<span class="c">#    ...</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="nv">$SVC1EXIP</span> <span class="nv">$SVC2EXIP</span> <span class="nv">$SVC3EXIP</span><span class="p">;</span> <span class="k">do </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc arping <span class="nt">-I</span> eth0 <span class="nt">-f</span> <span class="nt">-c</span> 1 <span class="nv">$i</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; ARPING 172.20.255.200 from 172.20.0.6 eth0</span>
<span class="c">#    Unicast reply from 172.20.255.200 [02:42:AC:14:00:03]  1.016ms</span>
<span class="c">#    Sent 1 probes (1 broadcast(s))</span>
<span class="c">#    Received 1 response(s)</span>
<span class="c">#    ARPING 172.20.255.201 from 172.20.0.6 eth0</span>
<span class="c">#    Unicast reply from 172.20.255.201 [02:42:AC:14:00:02]  1.965ms</span>
<span class="c">#    ...</span>
<span class="c">#    ARPING 172.20.255.202 from 172.20.0.6 eth0</span>
<span class="c">#    Unicast reply from 172.20.255.202 [02:42:AC:14:00:04]  1.789ms</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc ip <span class="nt">-c</span> neigh
<span class="c"># =&gt; &lt;span style="color:purple;"&gt;172.20.0.1 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;lladdr &lt;span style="color:olive;"&gt;02:42:1f:41:79:66 &lt;/span&gt;STALE </span>
<span class="c">#    &lt;span style="color:purple;"&gt;172.20.0.4 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;lladdr &lt;span style="color:olive;"&gt;02:42:ac:14:00:04 &lt;/span&gt;STALE </span>
<span class="c">#    &lt;span style="color:purple;"&gt;172.20.0.5 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;lladdr &lt;span style="color:olive;"&gt;02:42:ac:14:00:05 &lt;/span&gt;STALE </span>
<span class="c">#    &lt;span style="color:purple;"&gt;172.20.255.200 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;lladdr &lt;span style="color:olive;"&gt;02:42:ac:14:00:03 &lt;/span&gt;REACHABLE </span>
<span class="c">#    &lt;span style="color:purple;"&gt;172.20.255.201 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;lladdr &lt;span style="color:olive;"&gt;02:42:ac:14:00:02 &lt;/span&gt;REACHABLE </span>
<span class="c">#    &lt;span style="color:purple;"&gt;172.20.255.202 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;lladdr &lt;span style="color:olive;"&gt;02:42:ac:14:00:04 &lt;/span&gt;REACHABLE </span>

<span class="c"># &lt;span style="color: green;"&gt;ping은 모두 패킷 100% 로스되면서 실패합니다.&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;서비스 port로만 열려있기때문에 ping은 실패하는것입니다.&lt;/span&gt;</span>
<span class="c"># &lt;span style="color: green;"&gt;여기서 ping을 하는 이유는 arp table을 생성하기 위함입니다.&lt;/span&gt;</span>
  
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc ping <span class="nt">-c</span> 1 <span class="nt">-w</span> 1 <span class="nt">-W</span> 1 <span class="nv">$SVC1EXIP</span>
<span class="c"># =&gt; PING 172.20.255.200 (172.20.255.200) 56(84) bytes of data.</span>
<span class="c">#    </span>
<span class="c">#    --- 172.20.255.200 ping statistics ---</span>
<span class="c">#    1 packets transmitted, 0 received, 100% packet loss, time 0ms</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc ping <span class="nt">-c</span> 1 <span class="nt">-w</span> 1 <span class="nt">-W</span> 1 <span class="nv">$SVC2EXIP</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc ping <span class="nt">-c</span> 1 <span class="nt">-w</span> 1 <span class="nt">-W</span> 1 <span class="nv">$SVC3EXIP</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="nv">$SVC1EXIP</span> <span class="nv">$SVC2EXIP</span> <span class="nv">$SVC3EXIP</span><span class="p">;</span> <span class="k">do </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc ping <span class="nt">-c</span> 1 <span class="nt">-w</span> 1 <span class="nt">-W</span> 1 <span class="nv">$i</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>172.20.0.2 172.20.0.3 172.20.0.4 172.20.0.5<span class="p">;</span> <span class="k">do </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc ping <span class="nt">-c</span> 1 <span class="nt">-w</span> 1 <span class="nt">-W</span> 1 <span class="nv">$i</span><span class="p">;</span> <span class="k">done</span>

<span class="c"># mypc/mypc2 에서 arp 테이블 정보 확인 &gt;&gt; SVC IP별로 리더 파드(스피커) 역할의 노드를 확인!</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc ip <span class="nt">-c</span> neigh | <span class="nb">sort</span>
<span class="c"># =&gt; &lt;span style="color:purple;"&gt;172.20.0.1 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;lladdr &lt;span style="color:olive;"&gt;02:42:1f:41:79:66 &lt;/span&gt;STALE </span>
<span class="c">#    &lt;span style="color:purple;"&gt;172.20.0.2 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;lladdr &lt;span style="color:olive;"&gt;02:42:ac:14:00:02 &lt;/span&gt;REACHABLE </span>
<span class="c">#    &lt;span style="color:purple;"&gt;172.20.0.3 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;lladdr &lt;span style="color:olive;"&gt;02:42:ac:14:00:03 &lt;/span&gt;REACHABLE </span>
<span class="c">#    &lt;span style="color:purple;"&gt;172.20.0.4 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;lladdr &lt;span style="color:olive;"&gt;02:42:ac:14:00:04 &lt;/span&gt;REACHABLE </span>
<span class="c">#    &lt;span style="color:purple;"&gt;172.20.0.5 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;lladdr &lt;span style="color:olive;"&gt;02:42:ac:14:00:05 &lt;/span&gt;REACHABLE </span>
<span class="c">#    &lt;span style="color:purple;"&gt;172.20.255.200 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;lladdr &lt;span style="color:olive;"&gt;02:42:ac:14:00:03 &lt;/span&gt;REACHABLE </span>
<span class="c">#    &lt;span style="color:purple;"&gt;172.20.255.201 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;lladdr &lt;span style="color:olive;"&gt;02:42:ac:14:00:02 &lt;/span&gt;REACHABLE </span>
<span class="c">#    &lt;span style="color:purple;"&gt;172.20.255.202 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;lladdr &lt;span style="color:olive;"&gt;02:42:ac:14:00:04 &lt;/span&gt;REACHABLE </span>

<span class="nv">$ </span>kubectl get node <span class="nt">-owide</span> <span class="c"># mac 주소에 매칭되는 IP(노드) 찾기</span>
<span class="c"># =&gt; NAME                  STATUS   ROLES           AGE     VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE                         KERNEL-VERSION     CONTAINER-RUNTIME</span>
<span class="c">#    myk8s-control-plane   Ready    control-plane   4h35m   v1.31.0   172.20.0.5    &amp;lt;none&amp;gt;        Debian GNU/Linux 12 (bookworm)   5.10.76-linuxkit   containerd://1.7.18</span>
<span class="c">#    myk8s-worker          Ready    &amp;lt;none&amp;gt;          4h34m   v1.31.0   172.20.0.4    &amp;lt;none&amp;gt;        Debian GNU/Linux 12 (bookworm)   5.10.76-linuxkit   containerd://1.7.18</span>
<span class="c">#    myk8s-worker2         Ready    &amp;lt;none&amp;gt;          4h34m   v1.31.0   172.20.0.2    &amp;lt;none&amp;gt;        Debian GNU/Linux 12 (bookworm)   5.10.76-linuxkit   containerd://1.7.18</span>
<span class="c">#    myk8s-worker3         Ready    &amp;lt;none&amp;gt;          4h34m   v1.31.0   172.20.0.3    &amp;lt;none&amp;gt;        Debian GNU/Linux 12 (bookworm)   5.10.76-linuxkit   containerd://1.7.18</span>

<span class="c"># (옵션) 노드에서 ARP 패킷 캡쳐 확인</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane tcpdump <span class="nt">-i</span> eth0 <span class="nt">-nn</span> arp
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker        tcpdump <span class="nt">-i</span> eth0 <span class="nt">-nn</span> arp
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker2       tcpdump <span class="nt">-i</span> eth0 <span class="nt">-nn</span> arp
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker3       tcpdump <span class="nt">-i</span> eth0 <span class="nt">-nn</span> arp

<span class="c"># (옵션) metallb-speaker 파드 로그 확인</span>
<span class="nv">$ </span>kubectl logs <span class="nt">-n</span> metallb-system <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>metallb <span class="nt">-f</span>
<span class="nv">$ </span>kubectl logs <span class="nt">-n</span> metallb-system <span class="nt">-l</span> <span class="nv">component</span><span class="o">=</span>speaker <span class="nt">--since</span> 1h
<span class="nv">$ </span>kubectl logs <span class="nt">-n</span> metallb-system <span class="nt">-l</span> <span class="nv">component</span><span class="o">=</span>speaker <span class="nt">-f</span>

<span class="c"># (옵션) kubectl krew 플러그인 stern 설치 후 아래 명령 사용 가능</span>
<span class="nv">$ </span>kubectl stern <span class="nt">-n</span> metallb-system <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>metallb
<span class="nv">$ </span>kubectl stern <span class="nt">-n</span> metallb-system <span class="nt">-l</span> <span class="nv">component</span><span class="o">=</span>speaker <span class="nt">--since</span> 1h
<span class="nv">$ </span>kubectl stern <span class="nt">-n</span> metallb-system <span class="nt">-l</span> <span class="nv">component</span><span class="o">=</span>speaker <span class="c"># 기본 설정이 follow</span>
<span class="nv">$ </span>kubectl stern <span class="nt">-n</span> metallb-system speaker  <span class="c"># 매칭 사용 가능</span>
</code></pre></div></div>

<p><img src="/assets/2024/kans-3th/w5/20241005_kans_w5_12.png" alt="20241005_kans_w5_12.png" /></p>

<h5 id="서비스-접속-테스트">서비스 접속 테스트</h5>

<ul>
  <li>클러스터 외부에서 external ip와 port를 통해 k8s 클러스터 내부의 서비스에 접속해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 현재 SVC EXTERNAL-IP를 변수에 지정</span>
<span class="nv">$ SVC1EXIP</span><span class="o">=</span><span class="si">$(</span>kubectl get svc svc1 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.loadBalancer.ingress[0].ip}'</span><span class="si">)</span>
<span class="nv">$ SVC2EXIP</span><span class="o">=</span><span class="si">$(</span>kubectl get svc svc2 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.loadBalancer.ingress[0].ip}'</span><span class="si">)</span>
<span class="nv">$ SVC3EXIP</span><span class="o">=</span><span class="si">$(</span>kubectl get svc svc3 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.loadBalancer.ingress[0].ip}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$SVC1EXIP</span> <span class="nv">$SVC2EXIP</span> <span class="nv">$SVC3EXIP</span>
<span class="c"># =&gt; 172.20.255.200 172.20.255.201 172.20.255.202</span>

<span class="c"># mypc/mypc2 에서 접속 테스트</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc curl <span class="nt">-s</span> <span class="nv">$SVC1EXIP</span>
<span class="c"># =&gt; Hostname: webpod2</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: 10.10.2.3</span>
<span class="c">#    RemoteAddr: 172.20.0.3:40816</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: 172.20.255.200</span>
<span class="c">#    User-Agent: curl/8.7.1</span>
<span class="c">#    Accept: */*</span>

<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc curl <span class="nt">-s</span> <span class="nv">$SVC1EXIP</span> | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod2</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="nv">$SVC1EXIP</span> <span class="nv">$SVC2EXIP</span> <span class="nv">$SVC3EXIP</span><span class="p">;</span> <span class="k">do </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc curl <span class="nt">-s</span> <span class="nv">$i</span> | <span class="nb">grep </span>Hostname <span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; Hostname: webpod1</span>
<span class="c">#    Hostname: webpod2</span>
<span class="c">#    Hostname: webpod2</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="nv">$SVC1EXIP</span> <span class="nv">$SVC2EXIP</span> <span class="nv">$SVC3EXIP</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; Access Service External-IP : </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span> <span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> mypc curl <span class="nt">-s</span> <span class="nv">$i</span> | <span class="nb">grep </span>Hostname <span class="p">;</span> <span class="nb">echo</span> <span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; Access Service External-IP : 172.20.255.200 &amp;lt;&amp;lt;</span>
<span class="c">#    Hostname: webpod1</span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; Access Service External-IP : 172.20.255.201 &amp;lt;&amp;lt;</span>
<span class="c">#    Hostname: webpod2</span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; Access Service External-IP : 172.20.255.202 &amp;lt;&amp;lt;</span>
<span class="c">#    Hostname: webpod1    </span>

<span class="c">## RemoteAddr 주소는 어떻게 나오나요? 왜 그럴까요?</span>
<span class="c">##  NodePort 기본 동작과 동일하게 인입한 노드의 인터페이스로 SNAT 되어서 최종 파드로 전달되기 때문입니다.</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="nv">$SVC1EXIP</span> <span class="nv">$SVC2EXIP</span> <span class="nv">$SVC3EXIP</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; Access Service External-IP : </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span> <span class="p">;</span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc curl <span class="nt">-s</span> <span class="nv">$i</span> | egrep <span class="s1">'Hostname|RemoteAddr|Host:'</span> <span class="p">;</span> <span class="nb">echo</span> <span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; Access Service External-IP : 172.20.255.200 &amp;lt;&amp;lt;</span>
<span class="c">#    Hostname: webpod2</span>
<span class="c">#    RemoteAddr: 172.20.0.3:23163</span>
<span class="c">#    Host: 172.20.255.200</span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; Access Service External-IP : 172.20.255.201 &amp;lt;&amp;lt;</span>
<span class="c">#    Hostname: webpod2</span>
<span class="c">#    RemoteAddr: 10.10.2.1:15401</span>
<span class="c">#    Host: 172.20.255.201</span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; Access Service External-IP : 172.20.255.202 &amp;lt;&amp;lt;</span>
<span class="c">#    Hostname: webpod2</span>
<span class="c">#    RemoteAddr: 172.20.0.4:12711</span>
<span class="c">#    Host: 172.20.255.202</span>

<span class="c"># 부하분산 접속됨</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc zsh <span class="nt">-c</span> <span class="s2">"for i in {1..100}; do curl -s </span><span class="nv">$SVC1EXIP</span><span class="s2"> | grep Hostname; done | sort | uniq -c | sort -nr"</span>
<span class="c"># =&gt;      54 Hostname: webpod2</span>
<span class="c">#         46 Hostname: webpod1</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc zsh <span class="nt">-c</span> <span class="s2">"for i in {1..100}; do curl -s </span><span class="nv">$SVC2EXIP</span><span class="s2"> | grep Hostname; done | sort | uniq -c | sort -nr"</span>
<span class="c"># =&gt;      56 Hostname: webpod1</span>
<span class="c">#         44 Hostname: webpod2</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc zsh <span class="nt">-c</span> <span class="s2">"for i in {1..100}; do curl -s </span><span class="nv">$SVC3EXIP</span><span class="s2"> | grep Hostname; done | sort | uniq -c | sort -nr"</span>
<span class="c"># =&gt;      53 Hostname: webpod1</span>
<span class="c">#         47 Hostname: webpod2</span>

<span class="c"># 지속적으로 반복 접속</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc zsh <span class="nt">-c</span> <span class="s2">"while true; do curl -s --connect-timeout 1 </span><span class="nv">$SVC1EXIP</span><span class="s2"> | egrep 'Hostname|RemoteAddr'; date '+%Y-%m-%d %H:%M:%S' ; echo ;  sleep 1; done"</span>
<span class="c"># =&gt; Hostname: webpod1</span>
<span class="c">#    RemoteAddr: 172.20.0.3:39516</span>
<span class="c">#    2024-01-01 11:22:10</span>
<span class="c">#    </span>
<span class="c">#    Hostname: webpod1</span>
<span class="c">#    RemoteAddr: 172.20.0.3:20966</span>
<span class="c">#    2024-01-01 11:22:11</span>
<span class="c">#    </span>
<span class="c">#    Hostname: webpod2</span>
<span class="c">#    RemoteAddr: 172.20.0.3:3638</span>
<span class="c">#    2024-01-01 11:22:12</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc zsh <span class="nt">-c</span> <span class="s2">"while true; do curl -s --connect-timeout 1 </span><span class="nv">$SVC2EXIP</span><span class="s2"> | egrep 'Hostname|RemoteAddr'; date '+%Y-%m-%d %H:%M:%S' ; echo ;  sleep 1; done"</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc zsh <span class="nt">-c</span> <span class="s2">"while true; do curl -s --connect-timeout 1 </span><span class="nv">$SVC3EXIP</span><span class="s2"> | egrep 'Hostname|RemoteAddr'; date '+%Y-%m-%d %H:%M:%S' ; echo ;  sleep 1; done"</span>

<span class="c"># LoadBalancer Type은 기본값으로 NodePort 포함. NodePort 서비스는 ClusterIP 를 포함</span>
<span class="c"># NodePort:PORT 및 CLUSTER-IP:PORT 로 접속 가능!</span>
<span class="nv">$ </span>kubectl get svc svc1
<span class="c"># =&gt; NAME   TYPE           CLUSTER-IP    EXTERNAL-IP      PORT(S)        AGE</span>
<span class="c">#    svc1   LoadBalancer   10.200.1.89   172.20.255.200   80:30613/TCP   22m</span>

<span class="c"># 컨트롤노드에서 각각 접속 확인 실행 해보자</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane curl <span class="nt">-s</span> 127.0.0.1:30613 <span class="c"># NodePort Type</span>
<span class="c"># =&gt; Hostname: webpod2</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: 10.10.2.3</span>
<span class="c">#    RemoteAddr: 172.20.0.5:44387</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: 127.0.0.1:30613</span>
<span class="c">#    User-Agent: curl/7.88.1</span>
<span class="c">#    Accept: */*    </span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane curl <span class="nt">-s</span> 10.200.1.89     <span class="c"># ClusterIP Tpye</span>
<span class="c"># =&gt; Hostname: webpod2</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: 10.10.2.3</span>
<span class="c">#    RemoteAddr: 172.20.0.5:28647</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: 10.200.1.89</span>
<span class="c">#    User-Agent: curl/7.88.1</span>
<span class="c">#    Accept: */*</span>
</code></pre></div></div>

<h5 id="failover-테스트">Failover 테스트</h5>

<p><img src="/assets/2024/kans-3th/w5/20241005_kans_w5_13.png" alt="img.png" /></p>

<ul>
  <li>위의 그림처럼 장애 발생전에 워커노드 1의 스피커 파드가 SVC1, SVC2 서비스의 리더 역할을 하고 있는 상태에서,
워커노드 1에 장애가 발생하면, 남아있는 스피커 파드들이 워커노드 1의 장애 상황을 인지하게 됩니다.</li>
  <li>이후 장애가 발생한 스피커 파드가 소유한 ExternalIP에 대해 리더파드를 다시 선출하고 GARP로 새로 선출된 리더파드의 MAC 주소를 전파합니다.</li>
  <li>다만 장애 발생으로 문제를 인식하는 시간과 ARP 정보가 전파되는 시간, 그리고 클라이언트의 ARP 캐시 갱신 시간 등을 
고려하면 20초~1분 이내의 장애 지속시간이 발생할 수 있습니다.</li>
  <li>현재 실습에서 SVC1 =&gt; worker node 3, SVC2 =&gt; worker node 2, SVC3 =&gt; worker node 1 에 배포되어 있는 상태에서
워커노드 중 1대를 중지하여 장애를 발생시키고, 장애시간을 확인해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 사전 준비</span>
<span class="c">## 지속적으로 반복 접속</span>
<span class="nv">$ SVC1EXIP</span><span class="o">=</span><span class="si">$(</span>kubectl get svc svc1 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.status.loadBalancer.ingress[0].ip}'</span><span class="si">)</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc zsh <span class="nt">-c</span> <span class="s2">"while true; do curl -s --connect-timeout 1 </span><span class="nv">$SVC1EXIP</span><span class="s2"> | egrep 'Hostname|RemoteAddr'; date '+%Y-%m-%d %H:%M:%S' ; echo ;  sleep 1; done"</span>

<span class="c">## 상태 모니터링</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> kubectl get pod,svc,ep

<span class="c">## 실시간 로그 확인</span>
<span class="nv">$ </span>kubectl logs <span class="nt">-n</span> metallb-system <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>metallb <span class="nt">-f</span>
<span class="c"># 혹은</span>
<span class="nv">$ </span>kubectl stern <span class="nt">-n</span> metallb-system <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>metallb


<span class="c"># 장애 재연</span>
<span class="c">## 리더 Speaker 파드가 존재하는 노드(실제는 컨테이너)를 중지</span>
<span class="c"># $ docker stop &lt;svc1 번 리더 Speaker 파드가 존재하는 노드(실제는 컨테이너)&gt; --signal 9</span>
<span class="nv">$ </span>docker stop myk8s-worker <span class="nt">--signal</span> 9
<span class="c"># 혹은</span>
<span class="c"># $ docker stop &lt;svc1 번 리더 Speaker 파드가 존재하는 노드(실제는 컨테이너)&gt; --signal 15</span>
<span class="nv">$ </span>docker stop myk8s-worker <span class="nt">--signal</span> 15

<span class="nv">$ </span>docker ps <span class="nt">-a</span>
<span class="nv">$ </span>docker ps <span class="nt">-a</span> | <span class="nb">grep </span>worker<span class="err">$</span>
<span class="c"># =&gt; 242777ad8f3c   kindest/node:v1.31.0                 "/usr/local/bin/entr…"   6 hours ago     Exited (130) 7 minutes ago    myk8s-worker</span>

<span class="c">## 지속적으로 반복 접속 상태 모니터링</span>
<span class="c">### curl 연속 접속 시도 &gt;&gt; 대략 10초 이내에 정상 접근 되었지만, 20초까지는 불안정하게 접속이 되었다</span>
<span class="c">### 실제로는 다른 노드의 speaker 파드가 리더가 되고, 이후 다시 노드(컨테이너)가 정상화되면, 다시 리더 speaker 가 됨</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc zsh <span class="nt">-c</span> <span class="s2">"while true; do curl -s --connect-timeout 1 </span><span class="nv">$SVC1EXIP</span><span class="s2"> | egrep 'Hostname|RemoteAddr'; date '+%Y-%m-%d %H:%M:%S' ; echo ;  sleep 1; done"</span>
<span class="c"># =&gt; Hostname: webpod2</span>
<span class="c">#    RemoteAddr: 172.20.0.3:25432</span>
<span class="c">#    2024-10-05 12:04:30</span>
<span class="c">#    </span>
<span class="c">#    2024-10-05 12:04:32</span>
<span class="c">#    </span>
<span class="c">#    2024-10-05 12:04:34</span>
<span class="c">#    </span>
<span class="c">#    Hostname: webpod2</span>
<span class="c">#    RemoteAddr: 172.20.0.3:18511</span>
<span class="c">#    2024-10-05 12:04:35</span>
<span class="c">#    </span>
<span class="c">#    2024-10-05 12:04:37</span>
<span class="c">#    </span>
<span class="c">#    2024-10-05 12:04:39</span>
<span class="c">#    ...</span>

<span class="c"># 변경된 리더 Speaker 파드 확인</span>
<span class="c"># mypc/mypc2 에서 현재 SVC EXTERNAL-IP를 담당하는 리더 Speaker 파드 찾기</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="nv">$SVC1EXIP</span> <span class="nv">$SVC2EXIP</span> <span class="nv">$SVC3EXIP</span><span class="p">;</span> <span class="k">do </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc ping <span class="nt">-c</span> 1 <span class="nt">-w</span> 1 <span class="nt">-W</span> 1 <span class="nv">$i</span><span class="p">;</span> <span class="k">done</span>

<span class="c"># mypc/mypc2 에서 arp 테이블 정보 확인 &gt;&gt; SVC IP별로 리더 파드(스피커) 역할의 노드를 확인!</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc ip <span class="nt">-c</span> neigh | <span class="nb">sort</span>
<span class="c"># =&gt; &lt;span style="color:purple;"&gt;172.20.0.1 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;lladdr &lt;span style="color:olive;"&gt;02:42:1f:41:79:66 &lt;/span&gt;STALE </span>
<span class="c">#    &lt;span style="color:purple;"&gt;172.20.0.2 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;lladdr &lt;span style="color:olive;"&gt;02:42:ac:14:00:02 &lt;/span&gt;STALE </span>
<span class="c">#    &lt;span style="color:purple;"&gt;172.20.0.3 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;lladdr &lt;span style="color:olive;"&gt;02:42:ac:14:00:03 &lt;/span&gt;STALE </span>
<span class="c">#    &lt;span style="color:purple;"&gt;172.20.0.4 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;lladdr &lt;span style="color:olive;"&gt;02:42:ac:14:00:04 &lt;/span&gt;STALE </span>
<span class="c">#    &lt;span style="color:purple;"&gt;172.20.0.5 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;lladdr &lt;span style="color:olive;"&gt;02:42:ac:14:00:05 &lt;/span&gt;STALE </span>
<span class="c">#    &lt;span style="color:purple;"&gt;172.20.255.200 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;lladdr &lt;span style="color:olive;"&gt;02:42:ac:14:00:03 &lt;/span&gt;REACHABLE </span>
<span class="c">#    &lt;span style="color:purple;"&gt;172.20.255.201 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;lladdr &lt;span style="color:olive;"&gt;02:42:ac:14:00:02 &lt;/span&gt;REACHABLE </span>
<span class="c">#    &lt;span style="color:purple;"&gt;172.20.255.202 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;lladdr &lt;span style="color:olive;"&gt;02:42:ac:14:00:03 &lt;/span&gt;REACHABLE </span>
<span class="nv">$ </span>kubectl get node <span class="nt">-owide</span> <span class="c"># mac 주소에 매칭되는 IP(노드) 찾기</span>
<span class="c"># =&gt; NAME                  STATUS     ROLES           AGE     VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE                         KERNEL-VERSION     CONTAINER-RUNTIME</span>
<span class="c">#    myk8s-control-plane   Ready      control-plane   5h47m   v1.31.0   172.20.0.5    &amp;lt;none&amp;gt;        Debian GNU/Linux 12 (bookworm)   5.10.76-linuxkit   containerd://1.7.18</span>
<span class="c">#    myk8s-worker          NotReady   &amp;lt;none&amp;gt;          5h47m   v1.31.0   172.20.0.4    &amp;lt;none&amp;gt;        Debian GNU/Linux 12 (bookworm)   5.10.76-linuxkit   containerd://1.7.18</span>
<span class="c">#    myk8s-worker2         Ready      &amp;lt;none&amp;gt;          5h47m   v1.31.0   172.20.0.2    &amp;lt;none&amp;gt;        Debian GNU/Linux 12 (bookworm)   5.10.76-linuxkit   containerd://1.7.18</span>
<span class="c">#    myk8s-worker3         Ready      &amp;lt;none&amp;gt;          5h47m   v1.31.0   172.20.0.3    &amp;lt;none&amp;gt;        Debian GNU/Linux 12 (bookworm)   5.10.76-linuxkit   containerd://1.7.18</span>

<span class="c"># &lt;span style="color: green;"&gt;원래 리더 Speaker 파드가 존재했던 myk8s-worker 노드가 아닌&lt;/span&gt; </span>
<span class="c"># &lt;span style="color: green;"&gt;myk8s-worker3 노드가 리더 Speaker 파드를 가지고 있음을 확인할 수 있습니다.&lt;/span&gt;</span>

<span class="c"># 장애 원복(노드 정상화)</span>
<span class="c">## 노드(실제 컨테이너) 정상화 </span>
<span class="c"># $ docker start &lt;svc1 번 리더 Speaker 파드가 존재하는 노드(실제는 컨테이너)&gt;</span>
<span class="nv">$ </span>docker start myk8s-worker

<span class="c"># 변경된 리더 Speaker 파드 확인</span>
<span class="c"># mypc/mypc2 에서 현재 SVC EXTERNAL-IP를 담당하는 리더 Speaker 파드 찾기</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="nv">$SVC1EXIP</span> <span class="nv">$SVC2EXIP</span> <span class="nv">$SVC3EXIP</span><span class="p">;</span> <span class="k">do </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc ping <span class="nt">-c</span> 1 <span class="nt">-w</span> 1 <span class="nt">-W</span> 1 <span class="nv">$i</span><span class="p">;</span> <span class="k">done</span>

<span class="c"># mypc/mypc2 에서 arp 테이블 정보 확인 &gt;&gt; SVC IP별로 리더 파드(스피커) 역할의 노드를 확인!</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc ip <span class="nt">-c</span> neigh | <span class="nb">sort</span>
<span class="c"># =&gt; &lt;span style="color:purple;"&gt;172.20.0.1 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;lladdr &lt;span style="color:olive;"&gt;02:42:1f:41:79:66 &lt;/span&gt;STALE </span>
<span class="c">#    &lt;span style="color:purple;"&gt;172.20.0.2 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;lladdr &lt;span style="color:olive;"&gt;02:42:ac:14:00:02 &lt;/span&gt;STALE </span>
<span class="c">#    &lt;span style="color:purple;"&gt;172.20.0.3 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;lladdr &lt;span style="color:olive;"&gt;02:42:ac:14:00:03 &lt;/span&gt;STALE </span>
<span class="c">#    &lt;span style="color:purple;"&gt;172.20.0.4 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;lladdr &lt;span style="color:olive;"&gt;02:42:ac:14:00:04 &lt;/span&gt;STALE </span>
<span class="c">#    &lt;span style="color:purple;"&gt;172.20.0.5 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;lladdr &lt;span style="color:olive;"&gt;02:42:ac:14:00:05 &lt;/span&gt;STALE </span>
<span class="c">#    &lt;span style="color:purple;"&gt;172.20.255.200 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;lladdr &lt;span style="color:olive;"&gt;02:42:ac:14:00:03 &lt;/span&gt;REACHABLE </span>
<span class="c">#    &lt;span style="color:purple;"&gt;172.20.255.201 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;lladdr &lt;span style="color:olive;"&gt;02:42:ac:14:00:02 &lt;/span&gt;REACHABLE </span>
<span class="c">#    &lt;span style="color:purple;"&gt;172.20.255.202 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;lladdr &lt;span style="color:olive;"&gt;02:42:ac:14:00:04 &lt;/span&gt;REACHABLE </span>
<span class="nv">$ </span>kubectl get node <span class="nt">-owide</span> <span class="c"># mac 주소에 매칭되는 IP(노드) 찾기</span>

<span class="c"># &lt;span style="color: green;"&gt;myk8s-worker를 복구하니 SVC3의 리더 스피커 파드가 다시 myk8s-worker가 되었습니다.&lt;/span&gt; </span>
</code></pre></div></div>

<p><img src="/assets/2024/kans-3th/w5/20241005_kans_w5_14.png" alt="20241005_kans_w5_14.png" class="image-center" />
<em class="image-caption">장애발생후 복구 되기까지 실습 화면</em></p>

<h5 id="옵션-externaltrafficpolicy-local">(옵션) externalTrafficPolicy: Local</h5>

<ul>
  <li>LoadBalancer도 NodePort와 마찬가지로 externalTrafficPolicy 옵션을 사용할 수 있습니다.</li>
  <li>설정 방법</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl patch svc svc1 <span class="nt">-p</span> <span class="s1">'{"spec":{"externalTrafficPolicy": "Local"}}'</span>
<span class="nv">$ </span>kubectl patch svc svc2 <span class="nt">-p</span> <span class="s1">'{"spec":{"externalTrafficPolicy": "Local"}}'</span>
<span class="nv">$ </span>kubectl patch svc svc3 <span class="nt">-p</span> <span class="s1">'{"spec":{"externalTrafficPolicy": "Local"}}'</span>
</code></pre></div></div>

<ul>
  <li>클라이언트에서 서비스의 External IP로 접속시, 리더 스피커 노드에 위치한 애플리케이션 파드로만 접속이 되며, 클라이언트 IP가 보존됩니다.</li>
  <li>단점
    <ul>
      <li>부하분산이 되지 않아 비효율적입니다.</li>
      <li>리더 노드에 애플리케이션 파드가 없을 경우 서비스 접속이 불가능합니다.</li>
    </ul>
  </li>
  <li>따라서 MetalLB에서는 externalTrafficPolicy: Local 옵션을 사용하지 않는 것을 권장합니다.</li>
</ul>

<h4 id="metallb---bgp-모드">MetalLB - BGP 모드</h4>

<ul>
  <li>현재 실습환경이 KIND 여서 BGP 모드는 실습을 못해보는것 같습니다.</li>
  <li>향후에 baremetal이나 VM으로 구성된 클러스터에서 BGP 모드를 실습해 보고 이번에는 이론만 살펴보겠습니다.</li>
</ul>

<p><img src="/assets/2024/kans-3th/w5/20241005_kans_w5_15.png" alt="img.png" /></p>

<ul>
  <li>BGP 모드에서는 ARP를 사용하지 않고, BGP 데몬을 사용하여, 클러스터 외부의 라우터에 External IP를 전파합니다.</li>
  <li>ARP 모드는 스피커 리더가 있는 노드로만 트래픽이 전달되었지만, BGP 모드에서는 ECMP를 지원하여 여러 노드에 서비스를 분산시킬 수 있습니다.</li>
  <li>BGP 패킷을 캡쳐해보면 아래와 같이 Service의 External IP를 전파하는 것을 확인할 수 있습니다.
<img src="/assets/2024/kans-3th/w5/20241005_kans_w5_16.png" alt="img.png" /></li>
  <li>이때는 <code class="language-plaintext highlighter-rouge">externalTrafficPolicy: Local</code> 의 사용을 적극 권장합니다.</li>
  <li>또한 Failover가 매우 빠르며 거의 무중단으로 서비스가 가능합니다.</li>
</ul>

<h5 id="bgp-모드-설정">BGP 모드 설정</h5>

<ul>
  <li>
    <p>MetalLB의 BGP 모드 설정은 ConfigMap을 통해 설정합니다.</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl replace --force -f -
apiVersion: v1
kind: ConfigMap
metadata:
  namespace: metallb-system
  name: config
data:
  config: |
    peers:
    - peer-address: 192.168.10.254
      peer-asn: 64513
      my-asn: 64512
    address-pools:
    - name: default
      protocol: bgp
      avoid-buggy-ips: true
      addresses:
      - 172.20.1.0/24
</span><span class="no">EOF
</span></code></pre></div>    </div>
  </li>
  <li>
    <p>리눅스 라우터에 BGP 설정 예시</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>router bgp 64513
  bgp router-id 192.168.10.254
  maximum-paths 4
  network 10.1.1.0/24
  neighbor 192.168.10.10  remote-as 64512
  neighbor 192.168.10.101 remote-as 64512
  neighbor 192.168.10.102 remote-as 64512
  ...
</code></pre></div>    </div>
  </li>
</ul>

<hr />

<h2 id="externalip-서비스">ExternalIP 서비스</h2>

<ul>
  <li>ExternalIP 서비스는 NodePort 서비스와 유사하게 외부 IP를 제공하는 서비스입니다.</li>
  <li>ExternalIP 서비스는 특정 노드IP로 인입한 트래픽을 해당 노드의 파드로 전달해서 외부에서 접속할 수 있게 합니다.</li>
  <li>단 사용을 권장하고 있지는 않으며, 특별한 이유가 없다면 NodePort를 사용하는것이 좋습니다.</li>
</ul>

<table>
  <thead>
    <tr>
      <th>설정 항목</th>
      <th>설명</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>spec.externalIPs</td>
      <td>노드 IP 주소(ExternalIP)</td>
    </tr>
    <tr>
      <td>spec.ports[].port</td>
      <td>ExternalIP 와 ClusterIP 에서 수신할 포트 번호</td>
    </tr>
    <tr>
      <td>spec.ports[].targetPort</td>
      <td>목적지 컨테이너 포트 번호</td>
    </tr>
  </tbody>
</table>

<ul>
  <li>실습</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl create -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: deploy-echo
spec:
  replicas: 2
  selector:
    matchLabels:
      app: deploy-websrv
  template:
    metadata:
      labels:
        app: deploy-websrv
    spec:
      terminationGracePeriodSeconds: 0
      containers:
      - name: ndks-websrv
        image: k8s.gcr.io/echoserver:1.5
        ports:
        - containerPort: 8080
---
apiVersion: v1
kind: Service
metadata:
  name: svc-externalip
spec:
  type: ClusterIP
  externalIPs:
    - 192.168.10.101
    - 192.168.10.102
  ports:
    - name: svc-webport
      port: 9000
      targetPort: 8080
  selector:
    app: deploy-websrv
</span><span class="no">EOF
</span><span class="c"># =&gt; deployment.apps/deploy-echo created</span>
<span class="c">#    service/svc-externalip created</span>

<span class="c"># 확인 : ExternalIP 도 결국 ClusterIP를 사용(포함)</span>
<span class="nv">$ </span>kubectl get svc svc-externalip
<span class="c"># =&gt; NAME             TYPE        CLUSTER-IP    EXTERNAL-IP                     PORT(S)    AGE</span>
<span class="c">#    svc-externalip   ClusterIP   10.200.1.42   192.168.10.101,192.168.10.102   9000/TCP   14s</span>

<span class="nv">$ </span>kubectl describe svc svc-externalip
<span class="c"># =&gt; Name:                     svc-externalip</span>
<span class="c">#    Namespace:                default</span>
<span class="c">#    Labels:                   &amp;lt;none&amp;gt;</span>
<span class="c">#    Annotations:              &amp;lt;none&amp;gt;</span>
<span class="c">#    Selector:                 app=deploy-websrv</span>
<span class="c">#    Type:                     ClusterIP</span>
<span class="c">#    IP Family Policy:         SingleStack</span>
<span class="c">#    IP Families:              IPv4</span>
<span class="c">#    IP:                       10.200.1.42</span>
<span class="c">#    IPs:                      10.200.1.42</span>
<span class="c">#    External IPs:             192.168.10.101,192.168.10.102</span>
<span class="c">#    Port:                     svc-webport  9000/TCP</span>
<span class="c">#    TargetPort:               8080/TCP</span>
<span class="c">#    Endpoints:                10.10.1.3:8080,10.10.3.2:8080</span>
<span class="c">#    Session Affinity:         None</span>
<span class="c">#    External Traffic Policy:  Cluster</span>
<span class="c">#    Internal Traffic Policy:  Cluster</span>
<span class="c">#    Events:                   &amp;lt;none&amp;gt;</span>

<span class="c"># ExternalTrafficPolicy 설정이 없음</span>
<span class="nv">$ </span>kubectl get svc svc-externalip <span class="nt">-o</span> yaml
<span class="c"># =&gt; apiVersion: v1</span>
<span class="c">#    kind: Service</span>
<span class="c">#    metadata:</span>
<span class="c">#      creationTimestamp: &amp;quot;2024-10-05T12:45:06Z&amp;quot;</span>
<span class="c">#      name: svc-externalip</span>
<span class="c">#      namespace: default</span>
<span class="c">#      resourceVersion: &amp;quot;38088&amp;quot;</span>
<span class="c">#      uid: b64588f5-1589-4b9b-9652-b5979f8872a1</span>
<span class="c">#    spec:</span>
<span class="c">#      clusterIP: 10.200.1.42</span>
<span class="c">#      clusterIPs:</span>
<span class="c">#      - 10.200.1.42</span>
<span class="c">#      externalIPs:</span>
<span class="c">#      - 192.168.10.101</span>
<span class="c">#      - 192.168.10.102</span>
<span class="c">#      externalTrafficPolicy: Cluster</span>
<span class="c">#      internalTrafficPolicy: Cluster</span>
<span class="c">#      ipFamilies:</span>
<span class="c">#      - IPv4</span>
<span class="c">#      ipFamilyPolicy: SingleStack</span>
<span class="c">#      ports:</span>
<span class="c">#      - name: svc-webport</span>
<span class="c">#        port: 9000</span>
<span class="c">#        protocol: TCP</span>
<span class="c">#        targetPort: 8080</span>
<span class="c">#      selector:</span>
<span class="c">#        app: deploy-websrv</span>
<span class="c">#      sessionAffinity: None</span>
<span class="c">#      type: ClusterIP</span>
<span class="c">#    status:</span>
<span class="c">#      loadBalancer: {}</span>
</code></pre></div></div>

<hr />

<h2 id="ipvs-proxy-모드">IPVS Proxy 모드</h2>

<h3 id="ipvs-proxy-모드-소개">IPVS Proxy 모드 소개</h3>

<ul>
  <li>IPVS Proxy 모드는 지난주에 살펴보았던 <strong>kube-proxy의 모드중 하나</strong>로, 리눅스 <strong>커널의 IPVS 기능을 사용하여 로드밸런싱을 수행</strong>합니다.</li>
  <li>IPVS는 L4 레이어에서 동작하며, kube-proxy의 iptables 모드보다 <strong>성능이 우수</strong>하고, 대규모 클러스터에서 더 <strong>효율적으로 동작</strong>합니다.</li>
  <li>iptables이 비해 좀 더 높은 성능을 보여주며, 규칙 갯수도 줄일 수 있습니다.</li>
  <li>부하분산 알고리즘도 다음과 같이 다양하게 지원합니다.
    <ul>
      <li>라운드 로빈 (Round Robin) : 우선순위를 두지 않고 요청을 순차적으로 전달합니다.
        <ul>
          <li>가중치 라운드 로빈 (Weighted Round Robin) : 서버에 가중치를 부여하여 요청을 전달합니다.</li>
        </ul>
      </li>
      <li>최소 연결 (Least Connection) : 현재 연결 수가 가장 적은 서버로 요청을 전달합니다.
        <ul>
          <li>가중치 최소 연결 (Weighted Least Connection) : 서버에 가중치를 부여하여 연결 수가 가장 적은 서버로 요청을 전달합니다.</li>
          <li>지역성 기반 최소 연결 (Locality-Based Least Connection) : 클라이언트와 가까우면서 요청이 적은 서버로 요청을 전달합니다.</li>
        </ul>
      </li>
      <li>목적지 해싱 (Destination Hashing) : 요청의 목적지 IP 주소를 해싱하여 서버를 선택합니다.</li>
      <li>출발지 해싱 (Source Hashing) : 요청의 출발지 IP 주소를 해싱하여 서버를 선택합니다.</li>
      <li>최단 지연 (Shortest Expected Delay) : 서버의 응답 지연 시간을 고려하여 서버를 선택합니다.</li>
      <li>큐잉 방지 (Never Queue) : 연결이 없는 서버에 우선적으로 트래픽을 보내고, 모든 서버에 트래픽이 있으면 최단 지연 방식으로 트래픽을 보냅니다.</li>
    </ul>
  </li>
</ul>

<h3 id="ipvs-proxy-모드-실습">IPVS Proxy 모드 실습</h3>

<h4 id="실습환경-설정">실습환경 설정</h4>

<ul>
  <li>먼저 기존 실습 환경을 삭제합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kind delete cluster <span class="nt">--name</span> myk8s
<span class="c"># =&gt; Deleting cluster "myk8s" ...</span>
<span class="c">#    Deleted nodes: ["myk8s-worker" "myk8s-control-plane" "myk8s-worker2" "myk8s-worker3"]</span>
</code></pre></div></div>

<ul>
  <li>실습환경은 KIND를 사용하며, KIND 클러스터에 IPVS Proxy 모드를 적용해보겠습니다.</li>
  <li>실습 환경 : K8S v1.31.0, CNI(Kindnet / Direct Routing mode),  IPVS proxy mode
    <ul>
      <li>노드(실제로는 컨테이너) 네트워크 대역 : 172.20.0.0/16</li>
      <li>파드 사용 네트워크 대역 : 10.10.0.0/16 ⇒ 각각 10.10.1.0/24, 10.10.2.0/24, 10.10.3.0/24, 10.10.4.0/24</li>
      <li>서비스 사용 네트워크 대역 : 10.200.1.0/24</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/2024/kans-3th/w5/20241005_kans_w5_18.png" alt="img.png" class="image-center" /></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 파일 작성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh">&gt; kind-svc-2w-ipvs.yaml
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
featureGates:
  "InPlacePodVerticalScaling": true
  "MultiCIDRServiceAllocator": true
nodes:
- role: control-plane
  labels:
    mynode: control-plane
    topology.kubernetes.io/zone: ap-northeast-2a
  extraPortMappings:
  - containerPort: 30000
    hostPort: 30000
  - containerPort: 30001
    hostPort: 30001
  - containerPort: 30002
    hostPort: 30002
  - containerPort: 30003
    hostPort: 30003
  - containerPort: 30004
    hostPort: 30004
  kubeadmConfigPatches:
  - |
    kind: ClusterConfiguration
    apiServer:
      extraArgs:
        runtime-config: api/all=true
    controllerManager:
      extraArgs:
        bind-address: 0.0.0.0
    etcd:
      local:
        extraArgs:
          listen-metrics-urls: http://0.0.0.0:2381
    scheduler:
      extraArgs:
        bind-address: 0.0.0.0
  - |
    kind: KubeProxyConfiguration
    metricsBindAddress: 0.0.0.0
    ipvs:
      strictARP: true
- role: worker
  labels:
    mynode: worker1
    topology.kubernetes.io/zone: ap-northeast-2a
- role: worker
  labels:
    mynode: worker2
    topology.kubernetes.io/zone: ap-northeast-2b
- role: worker
  labels:
    mynode: worker3
    topology.kubernetes.io/zone: ap-northeast-2c
networking:
  podSubnet: 10.10.0.0/16
  serviceSubnet: 10.200.1.0/24
  kubeProxyMode: "ipvs"        
</span><span class="no">EOT

</span><span class="c"># k8s 클러스터 설치</span>
<span class="nv">$ </span>kind create cluster <span class="nt">--config</span> kind-svc-2w-ipvs.yaml <span class="nt">--name</span> myk8s <span class="nt">--image</span> kindest/node:v1.31.0
<span class="nv">$ </span>docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE                  COMMAND                  CREATED         STATUS         PORTS                                                             NAMES</span>
<span class="c">#    aa2f031f0959   kindest/node:v1.31.0   &amp;quot;/usr/local/bin/entr…&amp;quot;   2 minutes ago   Up 2 minutes                                                                     myk8s-worker3</span>
<span class="c">#    0a67b245f7ee   kindest/node:v1.31.0   &amp;quot;/usr/local/bin/entr…&amp;quot;   2 minutes ago   Up 2 minutes   0.0.0.0:30000-30004-&amp;gt;30000-30004/tcp, 127.0.0.1:49623-&amp;gt;6443/tcp   myk8s-control-plane</span>
<span class="c">#    4525aac3b06f   kindest/node:v1.31.0   &amp;quot;/usr/local/bin/entr…&amp;quot;   2 minutes ago   Up 2 minutes                                                                     myk8s-worker2</span>
<span class="c">#    0087fe52e3d2   kindest/node:v1.31.0   &amp;quot;/usr/local/bin/entr…&amp;quot;   2 minutes ago   Up 2 minutes                                                                     myk8s-worker</span>

<span class="c"># 노드에 기본 툴 설치</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane sh <span class="nt">-c</span> <span class="s1">'apt update &amp;&amp; apt install tree psmisc lsof wget bsdmainutils bridge-utils net-tools dnsutils ipset ipvsadm nfacct tcpdump ngrep iputils-ping arping git vim arp-scan -y'</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>worker worker2 worker3<span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node myk8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-<span class="nv">$i</span> sh <span class="nt">-c</span> <span class="s1">'apt update &amp;&amp; apt install tree psmisc lsof wget bsdmainutils bridge-utils net-tools dnsutils ipset ipvsadm nfacct tcpdump ngrep iputils-ping arping -y'</span><span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>

<span class="c"># kube-proxy configmap 확인</span>
<span class="nv">$ </span>kubectl describe cm <span class="nt">-n</span> kube-system kube-proxy
<span class="c"># =&gt; ...</span>
<span class="c">#    mode: ipvs</span>
<span class="c">#    ipvs: # 아래 각각 옵션 의미 조사해봅시다.</span>
<span class="c">#      excludeCIDRs: null   # IPVS에서 제외할 CIDR을 지정합니다. IPVS 룰을 정리할때 제외할 대역을 지정합니다.</span>
<span class="c">#      minSyncPeriod: 0s    # IPVS 룰을 동기화할 최소 주기를 지정합니다. 이 옵션을 사용하면 IPVS 룰을 동기화하는 주기를 제한할 수 있습니다.</span>
<span class="c">#      scheduler: ""        # IPVS 스케줄러는 IPVS가 사용할 로드밸런싱 알고리즘을 지정합니다.</span>
<span class="c">#      strictARP: true      # MetalLB 동작을 위해서 true 설정 변경 필요</span>
<span class="c">#      syncPeriod: 0s       # IPVS 룰을 동기화할 주기를 지정합니다. 이 옵션을 사용하면 IPVS 룰을 동기화하는 주기를 지정할 수 있습니다.</span>
<span class="c">#      tcpFinTimeout: 0s    # IPVS에서 TCP 연결이 종료된 후 FIN 상태를 유지하는 시간을 지정합니다.</span>
<span class="c">#      tcpTimeout: 0s       # IPVS에서 TCP 패킷을 처리하는 시간을 지정합니다.</span>
<span class="c">#      udpTimeout: 0s       # IPVS에서 UDP 패킷을 처리하는 시간을 지정합니다.</span>
<span class="c">#    ...</span>

<span class="c"># strictARP: true는 ARP 패킷을 보다 엄격하게 처리하겠다는 설정입니다.</span>
<span class="c">## IPVS 모드에서 strict ARP가 활성화되면, 노드의 인터페이스는 자신에게 할당된 IP 주소에 대해서만 ARP 응답을 보내게 됩니다. </span>
<span class="c">## 이는 IPVS로 로드밸런싱할 때 ARP 패킷이 잘못된 인터페이스로 전달되는 문제를 방지합니다.</span>
<span class="c">## 이 설정은 특히 클러스터 내에서 여러 노드가 동일한 IP를 갖는 VIP(Virtual IP)를 사용하는 경우 중요합니다.</span>

<span class="c"># 노드 별 네트워트 정보 확인 : kube-ipvs0 네트워크 인터페이스 확인</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>control-plane worker worker2 worker3<span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node myk8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-<span class="nv">$i</span> ip <span class="nt">-c</span> route<span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; node myk8s-control-plane &amp;lt;&amp;lt;</span>
<span class="c">#    default via &lt;span style="color:purple;"&gt;172.20.0.1 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;</span>
<span class="c">#    &lt;span style="color:purple;"&gt;10.10.0.2 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;vethc61550c2 &lt;/span&gt;scope host </span>
<span class="c">#    &lt;span style="color:purple;"&gt;10.10.0.3 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;veth85b53091 &lt;/span&gt;scope host </span>
<span class="c">#    &lt;span style="color:purple;"&gt;10.10.0.4 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;veth8ad445fd &lt;/span&gt;scope host </span>
<span class="c">#    &lt;span style="color:purple;"&gt;10.10.1.0/24 &lt;/span&gt;via &lt;span style="color:purple;"&gt;172.20.0.3 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;</span>
<span class="c">#    &lt;span style="color:purple;"&gt;10.10.2.0/24 &lt;/span&gt;via &lt;span style="color:purple;"&gt;172.20.0.2 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;</span>
<span class="c">#    &lt;span style="color:purple;"&gt;10.10.3.0/24 &lt;/span&gt;via &lt;span style="color:purple;"&gt;172.20.0.4 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;</span>
<span class="c">#    &lt;span style="color:purple;"&gt;172.20.0.0/16 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;proto kernel scope link src &lt;span style="color:purple;"&gt;172.20.0.5 &lt;/span&gt;</span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; node myk8s-worker &amp;lt;&amp;lt;</span>
<span class="c">#    default via &lt;span style="color:purple;"&gt;172.20.0.1 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;</span>
<span class="c">#    &lt;span style="color:purple;"&gt;10.10.0.0/24 &lt;/span&gt;via &lt;span style="color:purple;"&gt;172.20.0.5 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;</span>
<span class="c">#    &lt;span style="color:purple;"&gt;10.10.1.0/24 &lt;/span&gt;via &lt;span style="color:purple;"&gt;172.20.0.3 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;</span>
<span class="c">#    &lt;span style="color:purple;"&gt;10.10.2.0/24 &lt;/span&gt;via &lt;span style="color:purple;"&gt;172.20.0.2 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;</span>
<span class="c">#    &lt;span style="color:purple;"&gt;172.20.0.0/16 &lt;/span&gt;dev &lt;span style="color:teal;"&gt;eth0 &lt;/span&gt;proto kernel scope link src &lt;span style="color:purple;"&gt;172.20.0.4 &lt;/span&gt;</span>
<span class="c">#    ...</span>

<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>control-plane worker worker2 worker3<span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node myk8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-<span class="nv">$i</span> ip <span class="nt">-c</span> addr<span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; node myk8s-control-plane &amp;lt;&amp;lt;</span>
<span class="c">#    1: &lt;span style="color:teal;"&gt;lo: &lt;/span&gt;&amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span>
<span class="c">#        link/loopback &lt;span style="color:olive;"&gt;00:00:00:00:00:00&lt;/span&gt; brd &lt;span style="color:olive;"&gt;00:00:00:00:00:00&lt;/span&gt;</span>
<span class="c">#        inet &lt;span style="color:purple;"&gt;127.0.0.1&lt;/span&gt;/8 scope host lo</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    2: &lt;span style="color:teal;"&gt;tunl0@NONE: &lt;/span&gt;&amp;lt;NOARP&amp;gt; mtu 1480 qdisc noop state &lt;span style="color:red;"&gt;DOWN &lt;/span&gt;group default qlen 1000</span>
<span class="c">#        link/ipip &lt;span style="color:olive;"&gt;0.0.0.0&lt;/span&gt; brd &lt;span style="color:olive;"&gt;0.0.0.0&lt;/span&gt;</span>
<span class="c">#    4: &lt;span style="color:teal;"&gt;kube-ipvs0: &lt;/span&gt;&amp;lt;BROADCAST,NOARP&amp;gt; mtu 1500 qdisc noop state &lt;span style="color:red;"&gt;DOWN &lt;/span&gt;group default </span>
<span class="c">#        link/ether &lt;span style="color:olive;"&gt;0a:91:66:a1:e6:bb&lt;/span&gt; brd &lt;span style="color:olive;"&gt;ff:ff:ff:ff:ff:ff&lt;/span&gt;</span>
<span class="c">#        inet &lt;span style="color:purple;"&gt;10.200.1.1&lt;/span&gt;/32 scope global kube-ipvs0</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#        inet &lt;span style="color:purple;"&gt;10.200.1.10&lt;/span&gt;/32 scope global kube-ipvs0</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    5: &lt;span style="color:teal;"&gt;vethc61550c2@if4: &lt;/span&gt;&amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state &lt;span style="color:green;"&gt;UP &lt;/span&gt;group default </span>
<span class="c">#        link/ether &lt;span style="color:olive;"&gt;de:a6:86:25:bb:08&lt;/span&gt; brd &lt;span style="color:olive;"&gt;ff:ff:ff:ff:ff:ff&lt;/span&gt; link-netns cni-4751a95b-cc8c-ff23-9dd5-35e7f1a2223b</span>
<span class="c">#        inet &lt;span style="color:purple;"&gt;10.10.0.1&lt;/span&gt;/32 scope global vethc61550c2</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    6: &lt;span style="color:teal;"&gt;veth85b53091@if4: &lt;/span&gt;&amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state &lt;span style="color:green;"&gt;UP &lt;/span&gt;group default </span>
<span class="c">#        link/ether &lt;span style="color:olive;"&gt;ea:36:d9:10:fc:2f&lt;/span&gt; brd &lt;span style="color:olive;"&gt;ff:ff:ff:ff:ff:ff&lt;/span&gt; link-netns cni-db21fe8b-f48c-f3fe-6c6a-b2f204eea0e5</span>
<span class="c">#        inet &lt;span style="color:purple;"&gt;10.10.0.1&lt;/span&gt;/32 scope global veth85b53091</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    7: &lt;span style="color:teal;"&gt;veth8ad445fd@if4: &lt;/span&gt;&amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state &lt;span style="color:green;"&gt;UP &lt;/span&gt;group default </span>
<span class="c">#        link/ether &lt;span style="color:olive;"&gt;b6:bb:1b:44:13:eb&lt;/span&gt; brd &lt;span style="color:olive;"&gt;ff:ff:ff:ff:ff:ff&lt;/span&gt; link-netns cni-26749ed0-4863-eef5-640b-96f804e871ae</span>
<span class="c">#        inet &lt;span style="color:purple;"&gt;10.10.0.1&lt;/span&gt;/32 scope global veth8ad445fd</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    46: &lt;span style="color:teal;"&gt;eth0@if47: &lt;/span&gt;&amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state &lt;span style="color:green;"&gt;UP &lt;/span&gt;group default </span>
<span class="c">#        link/ether &lt;span style="color:olive;"&gt;02:42:ac:14:00:05&lt;/span&gt; brd &lt;span style="color:olive;"&gt;ff:ff:ff:ff:ff:ff&lt;/span&gt; link-netnsid 0</span>
<span class="c">#        inet &lt;span style="color:purple;"&gt;172.20.0.5&lt;/span&gt;/16 brd &lt;span style="color:purple;"&gt;172.20.255.255 &lt;/span&gt;scope global eth0</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; node myk8s-worker &amp;lt;&amp;lt;</span>
<span class="c">#    1: &lt;span style="color:teal;"&gt;lo: &lt;/span&gt;&amp;lt;LOOPBACK,UP,LOWER_UP&amp;gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span>
<span class="c">#        link/loopback &lt;span style="color:olive;"&gt;00:00:00:00:00:00&lt;/span&gt; brd &lt;span style="color:olive;"&gt;00:00:00:00:00:00&lt;/span&gt;</span>
<span class="c">#        inet &lt;span style="color:purple;"&gt;127.0.0.1&lt;/span&gt;/8 scope host lo</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    2: &lt;span style="color:teal;"&gt;tunl0@NONE: &lt;/span&gt;&amp;lt;NOARP&amp;gt; mtu 1480 qdisc noop state &lt;span style="color:red;"&gt;DOWN &lt;/span&gt;group default qlen 1000</span>
<span class="c">#        link/ipip &lt;span style="color:olive;"&gt;0.0.0.0&lt;/span&gt; brd &lt;span style="color:olive;"&gt;0.0.0.0&lt;/span&gt;</span>
<span class="c">#    4: &lt;span style="color:teal;"&gt;kube-ipvs0: &lt;/span&gt;&amp;lt;BROADCAST,NOARP&amp;gt; mtu 1500 qdisc noop state &lt;span style="color:red;"&gt;DOWN &lt;/span&gt;group default </span>
<span class="c">#        link/ether &lt;span style="color:olive;"&gt;fe:2c:45:76:c8:8d&lt;/span&gt; brd &lt;span style="color:olive;"&gt;ff:ff:ff:ff:ff:ff&lt;/span&gt;</span>
<span class="c">#        inet &lt;span style="color:purple;"&gt;10.200.1.1&lt;/span&gt;/32 scope global kube-ipvs0</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#        inet &lt;span style="color:purple;"&gt;10.200.1.10&lt;/span&gt;/32 scope global kube-ipvs0</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    44: &lt;span style="color:teal;"&gt;eth0@if45: &lt;/span&gt;&amp;lt;BROADCAST,MULTICAST,UP,LOWER_UP&amp;gt; mtu 1500 qdisc noqueue state &lt;span style="color:green;"&gt;UP &lt;/span&gt;group default </span>
<span class="c">#        link/ether &lt;span style="color:olive;"&gt;02:42:ac:14:00:04&lt;/span&gt; brd &lt;span style="color:olive;"&gt;ff:ff:ff:ff:ff:ff&lt;/span&gt; link-netnsid 0</span>
<span class="c">#        inet &lt;span style="color:purple;"&gt;172.20.0.4&lt;/span&gt;/16 brd &lt;span style="color:purple;"&gt;172.20.255.255 &lt;/span&gt;scope global eth0</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    ...</span>

<span class="c"># &lt;span style="color: green;"&gt;👉 노드별로 kube-ipvs0 인터페이스가 생성되었으며, IP 주소가 할당되어 있습니다.&lt;/span&gt;</span>

<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>control-plane worker worker2 worker3<span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node myk8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-<span class="nv">$i</span> ip <span class="nt">-br</span> <span class="nt">-c</span> addr show kube-ipvs0<span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; node myk8s-control-plane &amp;lt;&amp;lt;</span>
<span class="c">#    &lt;span style="color:teal;"&gt;kube-ipvs0       &lt;/span&gt;&lt;span style="color:red;"&gt;DOWN           &lt;/span&gt;&lt;span style="color:purple;"&gt;10.200.1.1&lt;/span&gt;/32 &lt;span style="color:purple;"&gt;10.200.1.10&lt;/span&gt;/32 </span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; node myk8s-worker &amp;lt;&amp;lt;</span>
<span class="c">#    &lt;span style="color:teal;"&gt;kube-ipvs0       &lt;/span&gt;&lt;span style="color:red;"&gt;DOWN           &lt;/span&gt;&lt;span style="color:purple;"&gt;10.200.1.1&lt;/span&gt;/32 &lt;span style="color:purple;"&gt;10.200.1.10&lt;/span&gt;/32 </span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; node myk8s-worker2 &amp;lt;&amp;lt;</span>
<span class="c">#    &lt;span style="color:teal;"&gt;kube-ipvs0       &lt;/span&gt;&lt;span style="color:red;"&gt;DOWN           &lt;/span&gt;&lt;span style="color:purple;"&gt;10.200.1.1&lt;/span&gt;/32 &lt;span style="color:purple;"&gt;10.200.1.10&lt;/span&gt;/32 </span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; node myk8s-worker3 &amp;lt;&amp;lt;</span>
<span class="c">#    &lt;span style="color:teal;"&gt;kube-ipvs0       &lt;/span&gt;&lt;span style="color:red;"&gt;DOWN           &lt;/span&gt;&lt;span style="color:purple;"&gt;10.200.1.1&lt;/span&gt;/32 &lt;span style="color:purple;"&gt;10.200.1.10&lt;/span&gt;/32 </span>

<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>control-plane worker worker2 worker3<span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node myk8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-<span class="nv">$i</span> ip <span class="nt">-d</span> <span class="nt">-c</span> addr show kube-ipvs0<span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; node myk8s-control-plane &amp;lt;&amp;lt;</span>
<span class="c">#    4: &lt;span style="color:teal;"&gt;kube-ipvs0: &lt;/span&gt;&amp;lt;BROADCAST,NOARP&amp;gt; mtu 1500 qdisc noop state &lt;span style="color:red;"&gt;DOWN &lt;/span&gt;group default </span>
<span class="c">#        link/ether &lt;span style="color:olive;"&gt;0a:91:66:a1:e6:bb&lt;/span&gt; brd &lt;span style="color:olive;"&gt;ff:ff:ff:ff:ff:ff&lt;/span&gt; promiscuity 0 minmtu 0 maxmtu 0 </span>
<span class="c">#        dummy numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535 </span>
<span class="c">#        inet &lt;span style="color:purple;"&gt;10.200.1.1&lt;/span&gt;/32 scope global kube-ipvs0</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#        inet &lt;span style="color:purple;"&gt;10.200.1.10&lt;/span&gt;/32 scope global kube-ipvs0</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; node myk8s-worker &amp;lt;&amp;lt;</span>
<span class="c">#    4: &lt;span style="color:teal;"&gt;kube-ipvs0: &lt;/span&gt;&amp;lt;BROADCAST,NOARP&amp;gt; mtu 1500 qdisc noop state &lt;span style="color:red;"&gt;DOWN &lt;/span&gt;group default </span>
<span class="c">#        link/ether &lt;span style="color:olive;"&gt;fe:2c:45:76:c8:8d&lt;/span&gt; brd &lt;span style="color:olive;"&gt;ff:ff:ff:ff:ff:ff&lt;/span&gt; promiscuity 0 minmtu 0 maxmtu 0 </span>
<span class="c">#        dummy numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535 </span>
<span class="c">#        inet &lt;span style="color:purple;"&gt;10.200.1.1&lt;/span&gt;/32 scope global kube-ipvs0</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#        inet &lt;span style="color:purple;"&gt;10.200.1.10&lt;/span&gt;/32 scope global kube-ipvs0</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; node myk8s-worker2 &amp;lt;&amp;lt;</span>
<span class="c">#    4: &lt;span style="color:teal;"&gt;kube-ipvs0: &lt;/span&gt;&amp;lt;BROADCAST,NOARP&amp;gt; mtu 1500 qdisc noop state &lt;span style="color:red;"&gt;DOWN &lt;/span&gt;group default </span>
<span class="c">#        link/ether &lt;span style="color:olive;"&gt;5a:26:49:54:18:21&lt;/span&gt; brd &lt;span style="color:olive;"&gt;ff:ff:ff:ff:ff:ff&lt;/span&gt; promiscuity 0 minmtu 0 maxmtu 0 </span>
<span class="c">#        dummy numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535 </span>
<span class="c">#        inet &lt;span style="color:purple;"&gt;10.200.1.1&lt;/span&gt;/32 scope global kube-ipvs0</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#        inet &lt;span style="color:purple;"&gt;10.200.1.10&lt;/span&gt;/32 scope global kube-ipvs0</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; node myk8s-worker3 &amp;lt;&amp;lt;</span>
<span class="c">#    4: &lt;span style="color:teal;"&gt;kube-ipvs0: &lt;/span&gt;&amp;lt;BROADCAST,NOARP&amp;gt; mtu 1500 qdisc noop state &lt;span style="color:red;"&gt;DOWN &lt;/span&gt;group default </span>
<span class="c">#        link/ether &lt;span style="color:olive;"&gt;fa:0c:2d:44:52:23&lt;/span&gt; brd &lt;span style="color:olive;"&gt;ff:ff:ff:ff:ff:ff&lt;/span&gt; promiscuity 0 minmtu 0 maxmtu 0 </span>
<span class="c">#        dummy numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535 </span>
<span class="c">#        inet &lt;span style="color:purple;"&gt;10.200.1.1&lt;/span&gt;/32 scope global kube-ipvs0</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#        inet &lt;span style="color:purple;"&gt;10.200.1.10&lt;/span&gt;/32 scope global kube-ipvs0</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>

<span class="c"># kube-ipvs0 에 할당된 IP(기본 IP + 보조 IP들) 정보 확인 </span>
<span class="nv">$ </span>kubectl get svc,ep <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE     NAME                 TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)                  AGE</span>
<span class="c">#    default       service/kubernetes   ClusterIP   10.200.1.1    &amp;lt;none&amp;gt;        443/TCP                  31m</span>
<span class="c">#    kube-system   service/kube-dns     ClusterIP   10.200.1.10   &amp;lt;none&amp;gt;        53/UDP,53/TCP,9153/TCP   31m</span>
<span class="c">#    </span>
<span class="c">#    NAMESPACE     NAME                   ENDPOINTS                                            AGE</span>
<span class="c">#    default       endpoints/kubernetes   172.20.0.5:6443                                      31m</span>
<span class="c">#    kube-system   endpoints/kube-dns     10.10.0.3:53,10.10.0.4:53,10.10.0.3:53 + 3 more...   31m</span>

<span class="c"># ipvsadm 툴로 부하분산 되는 정보 확인 : 서비스의 IP와 서비스에 연동되어 있는 파드의 IP 를 확인</span>
<span class="c">## Service IP(VIP) 처리를 ipvs 에서 담당 -&gt; 이를 통해 iptables 에 체인/정책이 상당 수준 줄어듬</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>control-plane worker worker2 worker3<span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node myk8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-<span class="nv">$i</span> ipvsadm <span class="nt">-Ln</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; node myk8s-control-plane &amp;lt;&amp;lt;</span>
<span class="c">#    IP Virtual Server version 1.2.1 (size=4096)</span>
<span class="c">#    Prot LocalAddress:Port Scheduler Flags</span>
<span class="c">#      -&amp;gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn</span>
<span class="c">#    TCP  10.200.1.1:443 rr</span>
<span class="c">#      -&amp;gt; 172.20.0.5:6443              Masq    1      3          0         </span>
<span class="c">#    TCP  10.200.1.10:53 rr</span>
<span class="c">#      -&amp;gt; 10.10.0.3:53                 Masq    1      0          0         </span>
<span class="c">#      -&amp;gt; 10.10.0.4:53                 Masq    1      0          0         </span>
<span class="c">#    TCP  10.200.1.10:9153 rr</span>
<span class="c">#      -&amp;gt; 10.10.0.3:9153               Masq    1      0          0         </span>
<span class="c">#      -&amp;gt; 10.10.0.4:9153               Masq    1      0          0         </span>
<span class="c">#    UDP  10.200.1.10:53 rr</span>
<span class="c">#      -&amp;gt; 10.10.0.3:53                 Masq    1      0          0         </span>
<span class="c">#      -&amp;gt; 10.10.0.4:53                 Masq    1      0          0         </span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; node myk8s-worker &amp;lt;&amp;lt;</span>
<span class="c">#    IP Virtual Server version 1.2.1 (size=4096)</span>
<span class="c">#    Prot LocalAddress:Port Scheduler Flags</span>
<span class="c">#      -&amp;gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn</span>
<span class="c">#    TCP  10.200.1.1:443 rr</span>
<span class="c">#      -&amp;gt; 172.20.0.5:6443              Masq    1      0          0         </span>
<span class="c">#    TCP  10.200.1.10:53 rr</span>
<span class="c">#      -&amp;gt; 10.10.0.3:53                 Masq    1      0          0         </span>
<span class="c">#      -&amp;gt; 10.10.0.4:53                 Masq    1      0          0         </span>
<span class="c">#    TCP  10.200.1.10:9153 rr</span>
<span class="c">#      -&amp;gt; 10.10.0.3:9153               Masq    1      0          0         </span>
<span class="c">#      -&amp;gt; 10.10.0.4:9153               Masq    1      0          0         </span>
<span class="c">#    UDP  10.200.1.10:53 rr</span>
<span class="c">#      -&amp;gt; 10.10.0.3:53                 Masq    1      0          0         </span>
<span class="c">#      -&amp;gt; 10.10.0.4:53                 Masq    1      0          0         </span>
<span class="c">#    ...</span>

<span class="c">## IPSET 확인</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker ipset <span class="nt">-h</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker ipset <span class="nt">-L</span>

<span class="c"># iptables 정보 확인 : 정책 갯수를 iptables proxy 모드와 비교해보자</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>filter nat mangle raw <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; IPTables Type : </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane  iptables <span class="nt">-t</span> <span class="nv">$i</span> <span class="nt">-S</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>filter nat mangle raw <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; IPTables Type : </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker  iptables <span class="nt">-t</span> <span class="nv">$i</span> <span class="nt">-S</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>filter nat mangle raw <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; IPTables Type : </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker2 iptables <span class="nt">-t</span> <span class="nv">$i</span> <span class="nt">-S</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>filter nat mangle raw <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; IPTables Type : </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker3 iptables <span class="nt">-t</span> <span class="nv">$i</span> <span class="nt">-S</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>

<span class="c"># 각 노드 bash 접속</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane bash
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker bash
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker2 bash
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker3 bash
<span class="nt">----------------------------------------</span>
<span class="nv">$ </span><span class="nb">exit</span>
<span class="nt">----------------------------------------</span>

<span class="c"># mypc 컨테이너 기동 : kind 도커 브리지를 사용하고, 컨테이너 IP를 직접 지정 혹은 IP 지정 없이 배포</span>
<span class="nv">$ </span>docker run <span class="nt">-d</span> <span class="nt">--rm</span> <span class="nt">--name</span> mypc <span class="nt">--network</span> kind <span class="nt">--ip</span> 172.20.0.100 nicolaka/netshoot <span class="nb">sleep </span>infinity
<span class="c"># 혹은</span>
<span class="nv">$ </span>docker run <span class="nt">-d</span> <span class="nt">--rm</span> <span class="nt">--name</span> mypc <span class="nt">--network</span> kind nicolaka/netshoot <span class="nb">sleep </span>infinity

<span class="nv">$ </span>docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE                  COMMAND                  CREATED          STATUS          PORTS                                                             NAMES</span>
<span class="c">#    16b541ee953e   nicolaka/netshoot      &amp;quot;sleep infinity&amp;quot;         31 seconds ago   Up 31 seconds                                                                     mypc</span>
<span class="c">#    aa2f031f0959   kindest/node:v1.31.0   &amp;quot;/usr/local/bin/entr…&amp;quot;   34 minutes ago   Up 34 minutes                                                                     myk8s-worker3</span>
<span class="c">#    0a67b245f7ee   kindest/node:v1.31.0   &amp;quot;/usr/local/bin/entr…&amp;quot;   34 minutes ago   Up 34 minutes   0.0.0.0:30000-30004-&amp;gt;30000-30004/tcp, 127.0.0.1:49623-&amp;gt;6443/tcp   myk8s-control-plane</span>
<span class="c">#    4525aac3b06f   kindest/node:v1.31.0   &amp;quot;/usr/local/bin/entr…&amp;quot;   34 minutes ago   Up 34 minutes                                                                     myk8s-worker2</span>
<span class="c">#    0087fe52e3d2   kindest/node:v1.31.0   &amp;quot;/usr/local/bin/entr…&amp;quot;   34 minutes ago   Up 34 minutes                                                                     myk8s-worker</span>
</code></pre></div></div>

<h5 id="ipvs-정보-확인">IPVS 정보 확인</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># kube-proxy 로그 확인 :  기본값 부하분산 스케줄러(RoundRobin = RR)</span>
<span class="nv">$ </span>kubectl stern <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>kube-proxy <span class="nt">--since</span> 2h | egrep <span class="s1">'(ipvs|IPVS)'</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    kube-proxy-24z49 kube-proxy I1005 15:10:04.041490       1 server_linux.go:230] "Using ipvs Proxier"</span>
<span class="c">#    kube-proxy-24z49 kube-proxy I1005 15:10:04.048394       1 proxier.go:364] "IPVS scheduler not specified, use rr by default" ipFamily="IPv4"</span>
<span class="c">#    kube-proxy-24z49 kube-proxy I1005 15:10:04.048529       1 proxier.go:364] "IPVS scheduler not specified, use rr by default" ipFamily="IPv6"</span>

<span class="c"># 기본 모드 정보 확인</span>
<span class="nv">$ </span>kubectl get cm <span class="nt">-n</span> kube-system kube-proxy <span class="nt">-o</span> yaml | egrep <span class="s1">'mode|strictARP|scheduler'</span>
<span class="c"># =&gt;       scheduler: &amp;quot;&amp;quot;</span>
<span class="c">#          strictARP: true</span>
<span class="c">#        mode: ipvs</span>

<span class="c"># ipvsadm 툴로 부하분산 되는 정보 확인 : RR 부하분산 스케줄러 확인</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>control-plane worker worker2 worker3<span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node myk8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-<span class="nv">$i</span> ipvsadm <span class="nt">-Ln</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; node myk8s-control-plane &amp;lt;&amp;lt;</span>
<span class="c">#    IP Virtual Server version 1.2.1 (size=4096)</span>
<span class="c">#    Prot LocalAddress:Port Scheduler Flags</span>
<span class="c">#      -&amp;gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn</span>
<span class="c">#    TCP  10.200.1.1:443 rr</span>
<span class="c">#      -&amp;gt; 172.20.0.5:6443              Masq    1      3          0         </span>
<span class="c">#    ...</span>

<span class="c"># 커널 파라미터 확인</span>
<span class="c"># (심화 옵션) strictARP - 링크 설정(유사한)이유</span>
<span class="c"># --ipvs-strict-arp : Enable strict ARP by setting arp_ignore to 1 and arp_announce to 2</span>
<span class="c"># arp_ignore : ARP request 를 받았을때 응답 여부 - 0(ARP 요청 도착시, any Interface 있으면 응답), 1(ARP 요청을 받은 Interface 가 해당 IP일때만 응답)</span>
<span class="c"># arp_announce : ARP request 를 보낼 때 'ARP Sender IP 주소'에 지정 값 - 0(sender IP로 시스템의 any IP 가능), 2(sender IP로 실제 전송하는 Interface 에 IP를 사용)</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker tree /proc/sys/net/ipv4/conf/kube-ipvs0
<span class="c"># =&gt; /proc/sys/net/ipv4/conf/kube-ipvs0</span>
<span class="c">#    |-- ...</span>
<span class="c">#    |-- arp_accept</span>
<span class="c">#    |-- arp_announce</span>
<span class="c">#    `-- ...</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker <span class="nb">cat</span> /proc/sys/net/ipv4/conf/kube-ipvs0/arp_ignore
<span class="c"># =&gt; 0</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker <span class="nb">cat</span> /proc/sys/net/ipv4/conf/kube-ipvs0/arp_announce
<span class="c"># =&gt; 0</span>

<span class="c"># all 은 모든 인터페이스에 영항을 줌, 단 all 과 interface 값이 다를때 우선순위는 커널 파라미터 별로 다르다 - 링크</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker sysctl net.ipv4.conf.all.arp_ignore
<span class="c"># =&gt; net.ipv4.conf.all.arp_ignore = 1</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker sysctl net.ipv4.conf.all.arp_announce
<span class="c"># =&gt; net.ipv4.conf.all.arp_announce = 2</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker sysctl net.ipv4.conf.kube-ipvs0.arp_ignore
<span class="c"># =&gt; net.ipv4.conf.kube-ipvs0.arp_ignore = 0</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker sysctl net.ipv4.conf.kube-ipvs0.arp_announce
<span class="c"># =&gt; net.ipv4.conf.kube-ipvs0.arp_announce = 0</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker sysctl <span class="nt">-a</span> | <span class="nb">grep </span>arp_ignore
<span class="c"># =&gt; net.ipv4.conf.all.arp_ignore = 1</span>
<span class="c">#    net.ipv4.conf.default.arp_ignore = 0</span>
<span class="c">#    net.ipv4.conf.eth0.arp_ignore = 0</span>
<span class="c">#    net.ipv4.conf.ip6tnl0.arp_ignore = 0</span>
<span class="c">#    net.ipv4.conf.kube-ipvs0.arp_ignore = 0</span>
<span class="c">#    net.ipv4.conf.lo.arp_ignore = 0</span>
<span class="c">#    net.ipv4.conf.tunl0.arp_ignore = 0</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker sysctl <span class="nt">-a</span> | <span class="nb">grep </span>arp_announce
<span class="c"># =&gt; net.ipv4.conf.all.arp_announce = 2</span>
<span class="c">#    net.ipv4.conf.default.arp_announce = 0</span>
<span class="c">#    net.ipv4.conf.eth0.arp_announce = 0</span>
<span class="c">#    net.ipv4.conf.ip6tnl0.arp_announce = 0</span>
<span class="c">#    net.ipv4.conf.kube-ipvs0.arp_announce = 0</span>
<span class="c">#    net.ipv4.conf.lo.arp_announce = 0</span>
<span class="c">#    net.ipv4.conf.tunl0.arp_announce = 0</span>

<span class="c"># IPSET 확인</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker ipset <span class="nt">-h</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker ipset <span class="nt">-L</span>
</code></pre></div></div>

<h5 id="목적지backend-파드pod-생성--3podyaml">목적지(backend) 파드(Pod) 생성 : 3pod.yaml</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh">&gt; 3pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: webpod1
  labels:
    app: webpod
spec:
  nodeName: myk8s-worker
  containers:
  - name: container
    image: traefik/whoami
  terminationGracePeriodSeconds: 0
---
apiVersion: v1
kind: Pod
metadata:
  name: webpod2
  labels:
    app: webpod
spec:
  nodeName: myk8s-worker2
  containers:
  - name: container
    image: traefik/whoami
  terminationGracePeriodSeconds: 0
---
apiVersion: v1
kind: Pod
metadata:
  name: webpod3
  labels:
    app: webpod
spec:
  nodeName: myk8s-worker3
  containers:
  - name: container
    image: traefik/whoami
  terminationGracePeriodSeconds: 0
</span><span class="no">EOT
</span></code></pre></div></div>

<h5 id="클라이언트testpod-생성--netpodyaml">클라이언트(TestPod) 생성 : netpod.yaml</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh">&gt; netpod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: net-pod
spec:
  nodeName: myk8s-control-plane
  containers:
  - name: netshoot-pod
    image: nicolaka/netshoot
    command: ["tail"]
    args: ["-f", "/dev/null"]
  terminationGracePeriodSeconds: 0
</span><span class="no">EOT
</span></code></pre></div></div>

<h5 id="서비스clusterip-생성--svc-clusteripyaml">서비스(ClusterIP) 생성 : svc-clusterip.yaml</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh">&gt; svc-clusterip.yaml
apiVersion: v1
kind: Service
metadata:
  name: svc-clusterip
spec:
  ports:
    - name: svc-webport
      port: 9000        # 서비스 IP 에 접속 시 사용하는 포트 port 를 의미
      targetPort: 80    # 타킷 targetPort 는 서비스를 통해서 목적지 파드로 접속 시 해당 파드로 접속하는 포트를 의미
  selector:
    app: webpod         # 셀렉터 아래 app:webpod 레이블이 설정되어 있는 파드들은 해당 서비스에 연동됨
  type: ClusterIP       # 서비스 타입
</span><span class="no">EOT
</span></code></pre></div></div>

<p><img src="/assets/2024/kans-3th/w5/20241005_kans_w5_19.png" alt="img.png" /></p>

<h5 id="생성-및-확인--ipvs-proxy-모드">생성 및 확인 : IPVS Proxy 모드</h5>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 생성</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> 3pod.yaml,netpod.yaml,svc-clusterip.yaml
<span class="c"># =&gt; pod/webpod1 created</span>
<span class="c">#    pod/webpod2 created</span>
<span class="c">#    pod/webpod3 created</span>
<span class="c">#    pod/net-pod created</span>
<span class="c">#    service/svc-clusterip created</span>

<span class="c"># 파드와 서비스 사용 네트워크 대역 정보 확인 </span>
<span class="nv">$ </span>kubectl cluster-info dump | <span class="nb">grep</span> <span class="nt">-m</span> 2 <span class="nt">-E</span> <span class="s2">"cluster-cidr|service-cluster-ip-range"</span>
<span class="c"># =&gt;                             &amp;quot;--service-cluster-ip-range=10.200.1.0/24&amp;quot;,</span>
<span class="c">#                                &amp;quot;--cluster-cidr=10.10.0.0/16&amp;quot;,</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME      READY   STATUS    RESTARTS   AGE   IP          NODE                  NOMINATED NODE   READINESS GATES</span>
<span class="c">#    net-pod   1/1     Running   0          36s   10.10.0.5   myk8s-control-plane   &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    webpod1   1/1     Running   0          36s   10.10.3.2   myk8s-worker          &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    webpod2   1/1     Running   0          36s   10.10.1.2   myk8s-worker2         &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="c">#    webpod3   1/1     Running   0          36s   10.10.2.2   myk8s-worker3         &amp;lt;none&amp;gt;           &amp;lt;none&amp;gt;</span>
<span class="nv">$ </span>kubectl get svc svc-clusterip
<span class="c"># =&gt; NAME            TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)    AGE</span>
<span class="c">#    svc-clusterip   ClusterIP   10.200.1.17   &amp;lt;none&amp;gt;        9000/TCP   44s</span>
<span class="nv">$ </span>kubectl describe svc svc-clusterip
<span class="nv">$ </span>kubectl get endpoints svc-clusterip
<span class="c"># =&gt; NAME            ENDPOINTS                                AGE</span>
<span class="c">#    svc-clusterip   10.10.1.2:80,10.10.2.2:80,10.10.3.2:80   55s</span>
<span class="nv">$ </span>kubectl get endpointslices <span class="nt">-l</span> kubernetes.io/service-name<span class="o">=</span>svc-clusterip
<span class="c"># =&gt; NAME                  ADDRESSTYPE   PORTS   ENDPOINTS                       AGE</span>
<span class="c">#    svc-clusterip-scf9k   IPv4          80      10.10.2.2,10.10.1.2,10.10.3.2   63s</span>

<span class="c"># 노드 별 네트워트 정보 확인 : kube-ipvs0 네트워크 인터페이스 확인</span>
<span class="c">## ClusterIP 생성 시 kube-ipvs0 인터페이스에 ClusterIP 가 할당되는 것을 확인</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>control-plane worker worker2 worker3<span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node myk8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-<span class="nv">$i</span> ip <span class="nt">-c</span> addr<span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>control-plane worker worker2 worker3<span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node myk8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-<span class="nv">$i</span> ip <span class="nt">-br</span> <span class="nt">-c</span> addr show kube-ipvs0<span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>control-plane worker worker2 worker3<span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node myk8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-<span class="nv">$i</span> ip <span class="nt">-d</span> <span class="nt">-c</span> addr show kube-ipvs0<span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>

<span class="c"># 변수 지정</span>
<span class="nv">$ CIP</span><span class="o">=</span><span class="si">$(</span>kubectl get svc svc-clusterip <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.spec.clusterIP}"</span><span class="si">)</span>
<span class="nv">$ CPORT</span><span class="o">=</span><span class="si">$(</span>kubectl get svc svc-clusterip <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.spec.ports[0].port}"</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$CIP</span> <span class="nv">$CPORT</span>
<span class="c"># =&gt; 10.200.1.17 9000</span>

<span class="c"># ipvsadm 툴로 부하분산 되는 정보 확인</span>
<span class="c">## 10.200.1.216(TCP 9000) 인입 시 3곳의 목적지로 라운드로빈(rr)로 부하분산하여 전달됨을 확인 : 모든 노드에서 동일한 IPVS 분산 설정 정보 확인</span>
<span class="c">## 3곳의 목적지는 각각 서비스에 연동된 목적지 파드 3개이며, 전달 시 출발지 IP는 마스커레이딩 변환 처리</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane ipvsadm <span class="nt">-Ln</span> <span class="nt">-t</span> <span class="nv">$CIP</span>:<span class="nv">$CPORT</span>
<span class="c"># =&gt; Prot LocalAddress:Port Scheduler Flags</span>
<span class="c">#      -&amp;gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn</span>
<span class="c">#    TCP  10.200.1.17:9000 rr</span>
<span class="c">#      -&amp;gt; 10.10.1.2:80                 Masq    1      0          0         </span>
<span class="c">#      -&amp;gt; 10.10.2.2:80                 Masq    1      0          0         </span>
<span class="c">#      -&amp;gt; 10.10.3.2:80                 Masq    1      0          0         </span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>control-plane worker worker2 worker3<span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node myk8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-<span class="nv">$i</span> ipvsadm <span class="nt">-Ln</span> <span class="nt">-t</span> <span class="nv">$CIP</span>:<span class="nv">$CPORT</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; node myk8s-control-plane &amp;lt;&amp;lt;</span>
<span class="c">#    Prot LocalAddress:Port Scheduler Flags</span>
<span class="c">#      -&amp;gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn</span>
<span class="c">#    TCP  10.200.1.17:9000 rr</span>
<span class="c">#      -&amp;gt; 10.10.1.2:80                 Masq    1      0          0         </span>
<span class="c">#      -&amp;gt; 10.10.2.2:80                 Masq    1      0          0         </span>
<span class="c">#      -&amp;gt; 10.10.3.2:80                 Masq    1      0          0         </span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; node myk8s-worker &amp;lt;&amp;lt;</span>
<span class="c">#    Prot LocalAddress:Port Scheduler Flags</span>
<span class="c">#      -&amp;gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn</span>
<span class="c">#    TCP  10.200.1.17:9000 rr</span>
<span class="c">#      -&amp;gt; 10.10.1.2:80                 Masq    1      0          0         </span>
<span class="c">#      -&amp;gt; 10.10.2.2:80                 Masq    1      0          0         </span>
<span class="c">#      -&amp;gt; 10.10.3.2:80                 Masq    1      0          0         </span>
<span class="c">#    ...</span>

<span class="c"># ipvsadm 툴로 부하분산 되는 현재 연결 정보 확인 : 추가로 --rate 도 있음</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane ipvsadm <span class="nt">-Ln</span> <span class="nt">-t</span> <span class="nv">$CIP</span>:<span class="nv">$CPORT</span> <span class="nt">--stats</span>
<span class="c"># =&gt; Prot LocalAddress:Port               Conns   InPkts  OutPkts  InBytes OutBytes</span>
<span class="c">#      -&amp;gt; RemoteAddress:Port</span>
<span class="c">#    TCP  10.200.1.17:9000                    0        0        0        0        0</span>
<span class="c">#      -&amp;gt; 10.10.1.2:80                        0        0        0        0        0</span>
<span class="c">#      -&amp;gt; 10.10.2.2:80                        0        0        0        0        0</span>
<span class="c">#      -&amp;gt; 10.10.3.2:80                        0        0        0        0        0</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>control-plane worker worker2 worker3<span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node myk8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-<span class="nv">$i</span> ipvsadm <span class="nt">-Ln</span> <span class="nt">-t</span> <span class="nv">$CIP</span>:<span class="nv">$CPORT</span> <span class="nt">--stats</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; node myk8s-control-plane &amp;lt;&amp;lt;</span>
<span class="c">#    Prot LocalAddress:Port               Conns   InPkts  OutPkts  InBytes OutBytes</span>
<span class="c">#      -&amp;gt; RemoteAddress:Port</span>
<span class="c">#    TCP  10.200.1.17:9000                    0        0        0        0        0</span>
<span class="c">#      -&amp;gt; 10.10.1.2:80                        0        0        0        0        0</span>
<span class="c">#      -&amp;gt; 10.10.2.2:80                        0        0        0        0        0</span>
<span class="c">#      -&amp;gt; 10.10.3.2:80                        0        0        0        0        0</span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; node myk8s-worker &amp;lt;&amp;lt;</span>
<span class="c">#    Prot LocalAddress:Port               Conns   InPkts  OutPkts  InBytes OutBytes</span>
<span class="c">#      -&amp;gt; RemoteAddress:Port</span>
<span class="c">#    TCP  10.200.1.17:9000                    0        0        0        0        0</span>
<span class="c">#      -&amp;gt; 10.10.1.2:80                        0        0        0        0        0</span>
<span class="c">#      -&amp;gt; 10.10.2.2:80                        0        0        0        0        0</span>
<span class="c">#      -&amp;gt; 10.10.3.2:80                        0        0        0        0        0</span>
<span class="c">#    ...</span>

<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane ipvsadm <span class="nt">-Ln</span> <span class="nt">-t</span> <span class="nv">$CIP</span>:<span class="nv">$CPORT</span> <span class="nt">--rate</span>
<span class="c"># =&gt; Prot LocalAddress:Port                 CPS    InPPS   OutPPS    InBPS   OutBPS</span>
<span class="c">#      -&amp;gt; RemoteAddress:Port</span>
<span class="c">#    TCP  10.200.1.17:9000                    0        0        0        0        0</span>
<span class="c">#      -&amp;gt; 10.10.1.2:80                        0        0        0        0        0</span>
<span class="c">#      -&amp;gt; 10.10.2.2:80                        0        0        0        0        0</span>
<span class="c">#      -&amp;gt; 10.10.3.2:80                        0        0        0        0        0</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>control-plane worker worker2 worker3<span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node myk8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-<span class="nv">$i</span> ipvsadm <span class="nt">-Ln</span> <span class="nt">-t</span> <span class="nv">$CIP</span>:<span class="nv">$CPORT</span> <span class="nt">--rate</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; node myk8s-control-plane &amp;lt;&amp;lt;</span>
<span class="c">#    Prot LocalAddress:Port                 CPS    InPPS   OutPPS    InBPS   OutBPS</span>
<span class="c">#      -&amp;gt; RemoteAddress:Port</span>
<span class="c">#    TCP  10.200.1.17:9000                    0        0        0        0        0</span>
<span class="c">#      -&amp;gt; 10.10.1.2:80                        0        0        0        0        0</span>
<span class="c">#      -&amp;gt; 10.10.2.2:80                        0        0        0        0        0</span>
<span class="c">#      -&amp;gt; 10.10.3.2:80                        0        0        0        0        0</span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; node myk8s-worker &amp;lt;&amp;lt;</span>
<span class="c">#    Prot LocalAddress:Port                 CPS    InPPS   OutPPS    InBPS   OutBPS</span>
<span class="c">#      -&amp;gt; RemoteAddress:Port</span>
<span class="c">#    TCP  10.200.1.17:9000                    0        0        0        0        0</span>
<span class="c">#      -&amp;gt; 10.10.1.2:80                        0        0        0        0        0</span>
<span class="c">#      -&amp;gt; 10.10.2.2:80                        0        0        0        0        0</span>
<span class="c">#      -&amp;gt; 10.10.3.2:80                        0        0        0        0        0</span>
<span class="c">#    ...</span>

<span class="c"># iptables 규칙 확인 : ipset list 를 활용</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane iptables <span class="nt">-t</span> nat <span class="nt">-S</span> | <span class="nb">grep </span>KUBE-CLUSTER-IP
<span class="c"># =&gt; -A KUBE-SERVICES ! -s 10.10.0.0/16 -m comment --comment &amp;quot;Kubernetes service cluster ip + port for masquerade purpose&amp;quot; -m set --match-set KUBE-CLUSTER-IP dst,dst -j KUBE-MARK-MASQ</span>
<span class="c">#    -A KUBE-SERVICES -m set --match-set KUBE-CLUSTER-IP dst,dst -j ACCEPT</span>

<span class="c"># ipset list 정보를 확인 : KUBE-CLUSTER-IP 이름은 아래 6개의 IP:Port 조합을 지칭</span>
<span class="c"># 예를 들면 ipset list 를 사용하지 않을 경우 6개의 iptables 규칙이 필요하지만, ipset 사용 시 1개의 규칙으로 가능</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane ipset list KUBE-CLUSTER-IP
<span class="c"># =&gt; Name: KUBE-CLUSTER-IP</span>
<span class="c">#    Type: hash:ip,port</span>
<span class="c">#    Revision: 5</span>
<span class="c">#    Header: family inet hashsize 1024 maxelem 65536</span>
<span class="c">#    Size in memory: 512</span>
<span class="c">#    References: 3</span>
<span class="c">#    Number of entries: 5</span>
<span class="c">#    Members:</span>
<span class="c">#    10.200.1.1,tcp:443</span>
<span class="c">#    10.200.1.10,tcp:9153</span>
<span class="c">#    10.200.1.10,tcp:53</span>
<span class="c">#    10.200.1.17,tcp:9000</span>
<span class="c">#    10.200.1.10,udp:53</span>
</code></pre></div></div>

<h4 id="ipvs-정보-확인-및-서비스-접속-확인">IPVS 정보 확인 및 서비스 접속 확인</h4>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>control-plane worker worker2 worker3<span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node myk8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-<span class="nv">$i</span> ipvsadm <span class="nt">-Ln</span> <span class="nt">-t</span> <span class="nv">$CIP</span>:<span class="nv">$CPORT</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &amp;gt;&amp;gt; node myk8s-control-plane &amp;lt;&amp;lt;</span>
<span class="c">#    Prot LocalAddress:Port Scheduler Flags</span>
<span class="c">#      -&amp;gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn</span>
<span class="c">#    TCP  10.200.1.17:9000 rr</span>
<span class="c">#      -&amp;gt; 10.10.1.2:80                 Masq    1      0          0         </span>
<span class="c">#      -&amp;gt; 10.10.2.2:80                 Masq    1      0          0         </span>
<span class="c">#      -&amp;gt; 10.10.3.2:80                 Masq    1      0          0         </span>
<span class="c">#    </span>
<span class="c">#    &amp;gt;&amp;gt; node myk8s-worker &amp;lt;&amp;lt;</span>
<span class="c">#    Prot LocalAddress:Port Scheduler Flags</span>
<span class="c">#      -&amp;gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn</span>
<span class="c">#    TCP  10.200.1.17:9000 rr</span>
<span class="c">#      -&amp;gt; 10.10.1.2:80                 Masq    1      0          0         </span>
<span class="c">#      -&amp;gt; 10.10.2.2:80                 Masq    1      0          0         </span>
<span class="c">#      -&amp;gt; 10.10.3.2:80                 Masq    1      0          0         </span>
<span class="c">#    ...</span>

<span class="c"># 변수 지정</span>
<span class="nv">$ CIP</span><span class="o">=</span><span class="si">$(</span>kubectl get svc svc-clusterip <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.spec.clusterIP}"</span><span class="si">)</span>
<span class="nv">$ CPORT</span><span class="o">=</span><span class="si">$(</span>kubectl get svc svc-clusterip <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.spec.ports[0].port}"</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$CIP</span> <span class="nv">$CPORT</span>
<span class="c"># =&gt; 10.200.1.17 9000</span>

<span class="c"># 컨트롤플레인 노드에서 ipvsadm 모니터링 실행 : ClusterIP 접속 시 아래 처럼 연결 정보 확인됨</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> <span class="s2">"docker exec -it myk8s-control-plane ipvsadm -Ln -t </span><span class="nv">$CIP</span><span class="s2">:</span><span class="nv">$CPORT</span><span class="s2"> --stats; echo; docker exec -it myk8s-control-plane ipvsadm -Ln -t </span><span class="nv">$CIP</span><span class="s2">:</span><span class="nv">$CPORT</span><span class="s2"> --rate"</span>

<span class="c"># --------------------------</span>

<span class="c"># 서비스 IP 변수 지정 : svc-clusterip 의 ClusterIP주소</span>
<span class="nv">$ SVC1</span><span class="o">=</span><span class="si">$(</span>kubectl get svc svc-clusterip <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.spec.clusterIP<span class="o">}</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$SVC1</span>
<span class="c"># =&gt; 10.200.1.17</span>

<span class="c"># TCP 80,9000 포트별 접속 확인 : 출력 정보 의미 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> net-pod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 <span class="nv">$SVC1</span>:9000
<span class="c"># =&gt; Hostname: webpod2</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: ::1</span>
<span class="c">#    IP: 10.10.1.2</span>
<span class="c">#    IP: fe80::3009:36ff:fe8f:d5a</span>
<span class="c">#    RemoteAddr: 10.10.0.5:58980</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: 10.200.1.17:9000</span>
<span class="c">#    User-Agent: curl/8.7.1</span>
<span class="c">#    Accept: */*</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> net-pod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 <span class="nv">$SVC1</span>:9000 | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod3</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> net-pod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 <span class="nv">$SVC1</span>:9000 | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod1</span>

<span class="c"># 서비스(ClusterIP) 부하분산 접속 확인 : 부하분산 비률 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> net-pod <span class="nt">--</span> zsh <span class="nt">-c</span> <span class="s2">"for i in {1..10};   do curl -s </span><span class="nv">$SVC1</span><span class="s2">:9000 | grep Hostname; done | sort | uniq -c | sort -nr"</span>
<span class="c"># =&gt;       4 Hostname: webpod3</span>
<span class="c">#          3 Hostname: webpod2</span>
<span class="c">#          3 Hostname: webpod1</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> net-pod <span class="nt">--</span> zsh <span class="nt">-c</span> <span class="s2">"for i in {1..100};  do curl -s </span><span class="nv">$SVC1</span><span class="s2">:9000 | grep Hostname; done | sort | uniq -c | sort -nr"</span>
<span class="c"># =&gt;      34 Hostname: webpod1</span>
<span class="c">#         33 Hostname: webpod3</span>
<span class="c">#         33 Hostname: webpod2</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> net-pod <span class="nt">--</span> zsh <span class="nt">-c</span> <span class="s2">"for i in {1..1000}; do curl -s </span><span class="nv">$SVC1</span><span class="s2">:9000 | grep Hostname; done | sort | uniq -c | sort -nr"</span>
<span class="c"># =&gt;     334 Hostname: webpod2</span>
<span class="c">#        333 Hostname: webpod3</span>
<span class="c">#        333 Hostname: webpod1</span>
<span class="c"># 혹은</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> net-pod <span class="nt">--</span> zsh <span class="nt">-c</span> <span class="s2">"for i in {1..100};   do curl -s </span><span class="nv">$SVC1</span><span class="s2">:9000 | grep Hostname; sleep 1; done"</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> net-pod <span class="nt">--</span> zsh <span class="nt">-c</span> <span class="s2">"for i in {1..100};   do curl -s </span><span class="nv">$SVC1</span><span class="s2">:9000 | grep Hostname; sleep 0.1; done"</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> net-pod <span class="nt">--</span> zsh <span class="nt">-c</span> <span class="s2">"for i in {1..10000}; do curl -s </span><span class="nv">$SVC1</span><span class="s2">:9000 | grep Hostname; sleep 0.01; done"</span>

<span class="c"># 반복 접속</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> net-pod <span class="nt">--</span> zsh <span class="nt">-c</span> <span class="s2">"while true; do curl -s --connect-timeout 1 </span><span class="nv">$SVC1</span><span class="s2">:9000 | egrep 'Hostname|RemoteAddr|Host:'; date '+%Y-%m-%d %H:%M:%S' ; echo '--------------' ;  sleep 1; done"</span>
</code></pre></div></div>

<p><img src="/assets/2024/kans-3th/w5/20241005_kans_w5_20.png" alt="img.png" class="image-center" />
<em class="image-caption">IPVS Proxy 모드 : 부하분산 확인</em></p>

<ul>
  <li>IPVS는 기존의 iptables의 부하분산보다 더 균등하게 부하분산을 수행함을 확인 할 수 있었습니다.</li>
</ul>

<hr />

<h2 id="마치며">마치며</h2>

<p>이번 주에는 LoadBalancer, LoadBalancer를 온프레미스에서 사용하기 위한 MetalLB, ClusterIP, IPVS Proxy 모드에 대해 알아보았습니다.
온프레미스 K8S에서 서비스 유형을 LoadBalancer로 했을때 ExternalIP가 할당 되지 않은 이유를 이제야 알았습니다. 
단순히 쓰기만 해왔던 기술의 원리와 이유를 알게되니 뿌듯합니다. 
아직 알아야 할 것이 산더미이고 지금 이순간에도 새로운 기술들이 개발된다니 또다시 첩첩산중이라는것을 느낍니다.</p>

<p>IPVS는 아직 모르는 부분이 많지만, 실무에 적용해보고 싶은 기술입니다. 네트워크 부하때문에 CPU가 높아지는 경우가 많은데, 
이를 해결할 수 있는 방법인것 같아 유용할것 같습니다.</p>

<p>정말 매운맛의 스터디이지만 많은 것을 배우고 있습니다.
다음 주에는 드디어 기다리던 GatewayAPI를 스터디 합니다. 기대가 됩니다. :)</p>]]></content><author><name></name></author><category term="kans" /><category term="kubernetes," /><category term="network," /><category term="linux" /><summary type="html"><![CDATA[이번 주에는 LoadBalancer 서비스와 MetalLB, 그리고 kube-proxy의 모드중 하나인 IPVS에 대해 알아보겠습니다.]]></summary></entry><entry><title type="html">[KANS 3기] K8S Service : ClusterIP, NodePort</title><link href="https://sweetlittlebird.github.io/posts/2024-09-27-KANS-Study-Week4/" rel="alternate" type="text/html" title="[KANS 3기] K8S Service : ClusterIP, NodePort" /><published>2024-09-27T01:00:18+09:00</published><updated>2024-09-27T01:00:18+09:00</updated><id>https://sweetlittlebird.github.io/posts/KANS%20Study%20-%20Week4</id><content type="html" xml:base="https://sweetlittlebird.github.io/posts/2024-09-27-KANS-Study-Week4/"><![CDATA[<h2 id="들어가며">들어가며</h2>

<p>지난주에 이어 이번주에는 Kubernetes의 Service, 그 중에 ClusterIP, NodePort에 대해 알아보겠습니다.
KANS 3기 4주차 스터디를 시작하겠습니다.</p>

<hr />

<h2 id="k8s-service">K8S Service</h2>

<p>Kubernetes의 Service는 개별 Pod에 접근하기 위한 추상화된 방법을 제공합니다.
Pod는 생성될 때마다 IP가 동적으로 할당되기 때문에 Pod의 IP를 직접 사용하는 것은 좋은 방법이 아닙니다.
Service는 Pod의 IP를 추상화하여 Pod에 접근할 수 있도록 해줍니다.</p>

<h3 id="service의-탄생-배경">Service의 탄생 배경</h3>

<p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_4.png" alt="img.png" /></p>

<p>위의 그림과 같이 하나의 파드의 엔드포인트를 다른 파드 (또는 외부)에서 사용할때, 해당 파드의 IP로 지정을 하면, 파드가 재실행 될 때 IP가 변경되어 접속이 안 되서 장애가 발생하는 현상이 생깁니다.</p>

<p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_5.png" alt="img.png" /></p>

<p>그래서 고정된 IP의 서비스를 만들고 서비스의 IP로 접속시 파드가 재실행되어도 안정적으로 접속할 수 있도록 하기위해서 만들어졌습니다.</p>

<p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_6.png" alt="img.png" /></p>

<p>서비스는 또한 부하분산의 기능도 할 수 있습니다. 위의 그림과 같이 파드가 여러개일때 서비스 IP로 접속시 각 파드들에 부하를 분산시킬 수 있게 됩니다.</p>

<h3 id="k8s-service-종류">K8S Service 종류</h3>

<h4 id="clusterip">ClusterIP</h4>

<p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_1.png" alt="img.png" class="w-80 image-center" /></p>

<ul>
  <li>동일한 애플리케이션을 실행하는 여러 Pod에 접속을 용이하기 위해 사용합니다.</li>
  <li>ClusterIP는 Cluster 내부에서만 접근이 가능하며 외부에서는 접근이 불가능합니다.</li>
  <li>iptables 의 NAT 기능을 이용하여 Pod에 접근하며, 동일한 iptables 분산룰을 각 노드에 적용합니다.</li>
</ul>

<h4 id="nodeport">NodePort</h4>

<p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_2.png" alt="img.png" class="w-80 image-center" /></p>

<ul>
  <li>NodePort는 ClusterIP와 같이 Cluster 내부에서 접근이 가능하며, 외부에서도 접근이 가능합니다.</li>
  <li>NodePort도 ClusterIP와 같이 iptables의 NAT 기능을 이용하여 Pod에 접근하며, 각 노드에 NodePort를 할당합니다.</li>
  <li>외부에서는 NodePort를 통해 각 노드에 접근 할 수 있습니다.</li>
</ul>

<h4 id="loadbalancer">LoadBalancer</h4>

<p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_3.png" alt="img.png" class="w-80 image-center" /></p>

<ul>
  <li>LoadBalancer도 외부에서 접근이 가능하며, 클라우드 서비스에서 제공하는 LoadBalancer를 사용합니다. (AWS의 경우 ELB(Elastic Load Balancer)가 사용됩니다.)</li>
  <li>온프레미스 환경에서도 MetalLB와 같은 LoadBalancer를 사용할 수 있습니다.</li>
</ul>

<h3 id="서비스의-구조">서비스의 구조</h3>

<p>서비스를 선언시 <code class="language-plaintext highlighter-rouge">port</code>와 <code class="language-plaintext highlighter-rouge">targetPort</code>, 그리고 <code class="language-plaintext highlighter-rouge">label</code> <code class="language-plaintext highlighter-rouge">selector</code> 를 사용합니다. 각각의 역할은 다음과 같습니다.</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">port</code> : 서비스가 listen 할 포트를 지정합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">targetPort</code> : 대상 파드의 port를 지정합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">label selector</code>  : 대상 파드를 특정합니다.</li>
</ul>

<p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_7.png" alt="img.png" /></p>

<h3 id="kube-proxy-모드">kube-proxy 모드</h3>

<ul>
  <li>kube-proxy는 서비스 통신 동작에 대한 설정을 관리합니다. 데몬셋으로 배포되어 모든 노드에 파드가 생성됩니다.</li>
  <li>kube-proxy 모드의 종류는 userspace proxy 모드, iptables proxy 모드, ipvs proxy 모드, nftables proxy 모드 등이 있습니다.</li>
</ul>

<h4 id="userspace-proxy-모드">userspace proxy 모드</h4>

<p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_8.png" alt="img.png" /></p>

<ul>
  <li>기초적인 모드이며 사용자 영역의 kube-proxy를 통해 NIC1으로 들어온 패킷을 NIC2로 전달하여 목적 파드로 전달합니다.</li>
  <li>이렇게 하는 과정에서 커널영역(netfilter)과 사용자영역(kube-proxy)를 오가는 과정에서 스위칭에 의한 오버헤드가 발생하는 단점이 있습니다.</li>
</ul>

<h4 id="iptables-proxy-모드">iptables proxy 모드</h4>

<p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_9.png" alt="img.png" /></p>

<ul>
  <li>쿠버네티스 설치시 기본 모드이며, kube-proxy는  트래픽 전달에 직접 관여하지는 않고, iptables 규칙을 관리하는 역할을 합니다.</li>
  <li>iptables proxy 모드는 트래픽 전달 과정에서 kube-proxy를 경유하지 않고, 커널 영역과 사용자 영역 전환이 필요하지 않아서, 유저스페이스 proxy 모드에 비해 오버헤드가 줄어듭니다.</li>
  <li>단점으로는 iptables 규칙이 많아 질 경우 모든 규칙 평가 하는데 지연이 발생할 수 있습니다.</li>
  <li>또한 장애시 모든 규칙을 확인하기 어려워 장애 처리에 불리합니다.</li>
</ul>

<h4 id="ipvs-proxy-모드">ipvs proxy 모드</h4>

<p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_10.png" alt="img.png" /></p>

<ul>
  <li>ipvs proxy 모드는 지금까지의 모드 중 가장 효율적인 모드입니다. IPVS(IP Virtual Server)는 넷필터에서 동작하는 Layer 4 로드밸런서입니다. iptables 보다 더 높은 성능 처리를 보여주고, 규칙 갯수를 줄일 수 있습니다. 또한 다양한 부하분산 알고리즘을 제공합니다.</li>
</ul>

<h4 id="nftables-proxy-모드">nftables proxy 모드</h4>
<ul>
  <li>nftables 는 iptables를 대체하기 위해 개발된 패킷 필터링 프레임워크로, iptables 보다 더 유연하고 강력한 규칙 설정을 제공합니다.</li>
  <li>하지만 아직  실험적으로 개발중인 단계로 실무에서는 ipvs proxy 모드를 권장합니다.</li>
</ul>

<h4 id="ebpf-모드--xdp">eBPF 모드 + XDP</h4>

<p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_11.png" alt="img.png" class="w-90 image-center" /></p>

<ul>
  <li>앞에서 알아보았던 모든 모드들이 netfilter 기반인데 반해, eBPF 모드 +  XDP 는 netfilter 전 단계에서 트래픽 라우팅을 처리하여 훨씬 효율 적입니다. calico나 cilium을 사용하여서 eBPF 모드를 사용할 수 있습니다.</li>
</ul>

<h3 id="실습">실습</h3>

<h4 id="실습환경-구축">실습환경 구축</h4>

<ul>
  <li>이번 실습은 실습환경 구축의 용이성을 위해서 kind를 이용하여 실습하였습니다.</li>
  <li>실습 환경 구축은 다음과 같이 진행 하였습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># kind 클러스터 정의 파일 생성</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOT</span><span class="sh">&gt; kind-svc-w3.yaml
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
featureGates:
  "InPlacePodVerticalScaling": true
  "MultiCIDRServiceAllocator": true
nodes:
- role: control-plane
  labels:
    mynode: control-plane
  extraPortMappings:
  - containerPort: 30000
    hostPort: 30000
  - containerPort: 30001
    hostPort: 30001
  - containerPort: 30002
    hostPort: 30002
  kubeadmConfigPatches:
  - |
    kind: ClusterConfiguration
    apiServer:
      extraArgs:
        runtime-config: api/all=true
- role: worker
  labels:
    mynode: worker1
- role: worker
  labels:
    mynode: worker2
- role: worker
  labels:
    mynode: worker3
networking:
  podSubnet: 10.10.0.0/16
  serviceSubnet: 10.200.1.0/24
</span><span class="no">EOT

</span><span class="c"># k8s 클러스터 설치</span>
<span class="nv">$ </span>kind create cluster <span class="nt">--config</span> kind-svc-w3.yaml <span class="nt">--name</span> myk8s <span class="nt">--image</span> kindest/node:v1.31.0
<span class="c"># =&gt; Creating cluster "myk8s" ...</span>
<span class="c">#     ✓ Ensuring node image (kindest/node:v1.31.0) 🖼</span>
<span class="c">#     ✓ Preparing nodes 📦 📦 📦 📦</span>
<span class="c">#     ✓ Writing configuration 📜</span>
<span class="c">#     ✓ Starting control-plane 🕹️</span>
<span class="c">#     ✓ Installing CNI 🔌</span>
<span class="c">#     ✓ Installing StorageClass 💾</span>
<span class="c">#     ✓ Joining worker nodes 🚜</span>
<span class="c">#    Set kubectl context to "kind-myk8s"</span>
<span class="c">#    You can now use your cluster with:</span>
<span class="c">#    </span>
<span class="c">#    kubectl cluster-info --context kind-myk8s</span>

<span class="nv">$ </span>docker ps
<span class="c"># =&gt; CONTAINER ID   IMAGE                                COMMAND                  CREATED          STATUS                 PORTS                                                            NAMES</span>
<span class="c">#    1b7e6b646e48   kindest/node:v1.31.0                 "/usr/local/bin/entr…"   18 minutes ago   Up 18 minutes                                                                           myk8s-worker</span>
<span class="c">#    5406c013a571   kindest/node:v1.31.0                 "/usr/local/bin/entr…"   18 minutes ago   Up 18 minutes          0.0.0.0:30000-30002-&gt;30000-30002/tcp, 127.0.0.1:43315-&gt;6443/tcp  myk8s-control-plane</span>
<span class="c">#    4134657c5a70   kindest/node:v1.31.0                 "/usr/local/bin/entr…"   18 minutes ago   Up 18 minutes                                                                           myk8s-worker3</span>
<span class="c">#    6caf2b177502   kindest/node:v1.31.0                 "/usr/local/bin/entr…"   18 minutes ago   Up 18 minutes                                                                           myk8s-worker2</span>

<span class="c"># 노드에 기본 툴 설치</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane sh <span class="nt">-c</span> <span class="s1">'apt update &amp;&amp; apt install tree psmisc lsof wget bridge-utils net-tools ipset ipvsadm nfacct tcpdump ngrep iputils-ping arping git vim arp-scan -y'</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>worker worker2 worker3<span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node myk8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-<span class="nv">$i</span> sh <span class="nt">-c</span> <span class="s1">'apt update &amp;&amp; apt install tree psmisc lsof wget bridge-utils net-tools ipset ipvsadm nfacct tcpdump ngrep iputils-ping arping -y'</span><span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>

<span class="c"># k8s v1.31.0 버전 확인</span>
<span class="nv">$ </span>kubectl get node
<span class="c"># =&gt; NAME                  STATUS   ROLES           AGE   VERSION</span>
<span class="c">#    myk8s-control-plane   Ready    control-plane   40m   v1.31.0</span>
<span class="c">#    myk8s-worker          Ready    &lt;none&gt;          40m   v1.31.0</span>
<span class="c">#    myk8s-worker2         Ready    &lt;none&gt;          40m   v1.31.0</span>
<span class="c">#    myk8s-worker3         Ready    &lt;none&gt;          40m   v1.31.0</span>

<span class="c"># 노드 labels 확인</span>
<span class="nv">$ </span>kubectl get nodes <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.items[*].metadata.labels}"</span> | <span class="nb">grep </span>mynode
<span class="nv">$ </span>kubectl get nodes <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.items[*].metadata.labels}"</span> | jq | <span class="nb">grep </span>mynode
<span class="c"># =&gt;   "mynode": "control-plane",</span>
<span class="c">#      "mynode": "worker1"</span>
<span class="c">#      "mynode": "worker2"</span>
<span class="c">#      "mynode": "worker3"</span>

<span class="c"># kind network 중 컨테이너(노드) IP(대역) 확인 : 172.18.0.2~ 부터 할당되며, control-plane 이 꼭 172.18.0.2가 안될 수 도 있음</span>
<span class="nv">$ </span>docker ps <span class="nt">-q</span> | xargs docker inspect <span class="nt">--format</span> <span class="s1">' '</span>
<span class="c"># =&gt; /myk8s-control-plane 172.23.0.2</span>
<span class="c">#    /myk8s-worker 172.23.0.4</span>
<span class="c">#    /myk8s-worker2 172.23.0.5</span>
<span class="c">#    /myk8s-worker3 172.23.0.3</span>
    
<span class="c"># 파드CIDR 과 Service 대역 확인 : CNI는 kindnet 사용</span>
<span class="nv">$ </span>kubectl get cm <span class="nt">-n</span> kube-system kubeadm-config <span class="nt">-oyaml</span> | <span class="nb">grep</span> <span class="nt">-i</span> subnet
<span class="c"># =&gt;       podSubnet: 10.10.0.0/16</span>
<span class="c">#          serviceSubnet: 10.200.1.0/24</span>
<span class="nv">$ </span>kubectl cluster-info dump | <span class="nb">grep</span> <span class="nt">-m</span> 2 <span class="nt">-E</span> <span class="s2">"cluster-cidr|service-cluster-ip-range"</span>
<span class="c"># =&gt;                             "--service-cluster-ip-range=10.200.1.0/24",</span>
<span class="c">#                                "--cluster-cidr=10.10.0.0/16",</span>

<span class="c"># feature-gates 확인 : https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/</span>
<span class="nv">$ </span>kubectl describe pod <span class="nt">-n</span> kube-system | <span class="nb">grep </span>feature-gates
<span class="c"># =&gt;       --feature-gates=InPlacePodVerticalScaling=true,MultiCIDRServiceAllocator=true</span>
<span class="nv">$ </span>kubectl describe pod <span class="nt">-n</span> kube-system | <span class="nb">grep </span>runtime-config
<span class="c"># =&gt;       --runtime-config=api/all=true</span>

<span class="c"># MultiCIDRServiceAllocator : https://kubernetes.io/docs/tasks/network/extend-service-ip-ranges/</span>
<span class="nv">$ </span>kubectl get servicecidr
<span class="c"># =&gt; NAME         CIDRS           AGE</span>
<span class="c">#    kubernetes   10.200.1.0/24   62m</span>

<span class="c"># 노드마다 할당된 dedicated subnet (podCIDR) 확인</span>
<span class="nv">$ </span>kubectl get nodes <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.items[*].spec.podCIDR}"</span>
<span class="c"># =&gt; 10.10.0.0/24 10.10.4.0/24 10.10.1.0/24 10.10.2.0/24</span>

<span class="c"># kube-proxy configmap 확인</span>
<span class="nv">$ </span>kubectl describe cm <span class="nt">-n</span> kube-system kube-proxy
<span class="c"># =&gt; ...</span>
<span class="c">#    iptables:</span>
<span class="c">#      localhostNodePorts: null</span>
<span class="c">#      masqueradeAll: false</span>
<span class="c">#      masqueradeBit: null</span>
<span class="c">#      minSyncPeriod: 1s</span>
<span class="c">#      syncPeriod: 0s</span>
<span class="c">#    mode: iptables</span>
<span class="c">#    ...</span>

<span class="c"># kube-proxy가 iptables 모드로 동작중임을 확인할 수 있습니다.</span>

<span class="c"># 노드 별 네트워트 정보 확인 : CNI는 kindnet 사용</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>control-plane worker worker2 worker3<span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node myk8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-<span class="nv">$i</span> <span class="nb">ls</span> /opt/cni/bin/<span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>control-plane worker worker2 worker3<span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node myk8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-<span class="nv">$i</span> <span class="nb">cat</span> /etc/cni/net.d/10-kindnet.conflist<span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>control-plane worker worker2 worker3<span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node myk8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-<span class="nv">$i</span> ip <span class="nt">-c</span> route<span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>control-plane worker worker2 worker3<span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node myk8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-<span class="nv">$i</span> ip <span class="nt">-c</span> addr<span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>control-plane worker worker2 worker3<span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node myk8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-<span class="nv">$i</span> ip <span class="nt">-c</span> <span class="nt">-4</span> addr show dev eth0<span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>

<span class="c"># iptables 정보 확인</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>filter nat mangle raw <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; IPTables Type : </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane  iptables <span class="nt">-t</span> <span class="nv">$i</span> <span class="nt">-S</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>filter nat mangle raw <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; IPTables Type : </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker  iptables <span class="nt">-t</span> <span class="nv">$i</span> <span class="nt">-S</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>filter nat mangle raw <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; IPTables Type : </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker2 iptables <span class="nt">-t</span> <span class="nv">$i</span> <span class="nt">-S</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>filter nat mangle raw <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; IPTables Type : </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker3 iptables <span class="nt">-t</span> <span class="nv">$i</span> <span class="nt">-S</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>

<span class="c"># 각 노드 bash 접속</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane bash
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker bash
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker2 bash
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker3 bash
<span class="nt">----------------------------------------</span>
<span class="nv">$ </span><span class="nb">exit</span>
<span class="nt">----------------------------------------</span>

<span class="c"># kind 설치 시 kind 이름의 도커 브리지가 생성됩니다. : 172.18.0.0/16 대역</span>
<span class="nv">$ </span>docker network <span class="nb">ls</span>
<span class="c"># =&gt; NETWORK ID     NAME                           DRIVER    SCOPE</span>
<span class="c">#    ...</span>
<span class="c">#    1c5d73657215   kind                           bridge    local</span>

<span class="nv">$ </span>docker inspect kind
<span class="c"># =&gt; [</span>
<span class="c">#        {</span>
<span class="c">#            "Name": "kind",</span>
<span class="c">#            ...</span>
<span class="c">#            "IPAM": {</span>
<span class="c">#                ...</span>
<span class="c">#                "Config": [</span>
<span class="c">#                    {</span>
<span class="c">#                        "Subnet": "172.23.0.0/16",</span>
<span class="c">#                        "Gateway": "172.23.0.1"</span>
<span class="c">#                    }</span>
<span class="c">#                ]</span>
<span class="c">#            },</span>
<span class="c">#            ...</span>
<span class="c">#            "Containers": {</span>
<span class="c">#                "1b7e6b646e4867591b5dd2a3bb4fcd2223dfcfd36dc08d86c8efc8fdc2112462": {</span>
<span class="c">#                    "Name": "myk8s-worker",</span>
<span class="c">#                    "IPv4Address": "172.23.0.4/16",</span>
<span class="c">#                },</span>
<span class="c">#                "4134657c5a7049d20944c2f80d3a3183a91a70107a47be72888e5c5fa972312a": {</span>
<span class="c">#                    "Name": "myk8s-worker3",</span>
<span class="c">#                    "IPv4Address": "172.23.0.3/16",</span>
<span class="c">#                },</span>
<span class="c">#                "5406c013a57167caf9a94ee9e89e550899a6efed9386f35548f03d2f670e8196": {</span>
<span class="c">#                    "Name": "myk8s-control-plane",</span>
<span class="c">#                    "IPv4Address": "172.23.0.2/16",</span>
<span class="c">#                },</span>
<span class="c">#                "6caf2b177502b92eccd4353ae3f4b3ac2da2949fc840225a02c9e83e1d24b09a": {</span>
<span class="c">#                    "Name": "myk8s-worker2",</span>
<span class="c">#                    "IPv4Address": "172.23.0.5/16",</span>
<span class="c">#                }</span>
<span class="c">#            },</span>
<span class="c">#            ...</span>
<span class="c">#        }</span>
<span class="c">#    ]</span>

<span class="c"># arp scan 해두기</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane arp-scan <span class="nt">--interfac</span><span class="o">=</span>eth0 <span class="nt">--localnet</span>
<span class="c"># =&gt; Interface: eth0, type: EN10MB, MAC: 02:42:ac:17:00:02, IPv4: 172.23.0.2</span>
<span class="c">#    Starting arp-scan 1.10.0 with 65536 hosts (https://github.com/royhills/arp-scan)</span>
<span class="c">#    172.23.0.1	02:42:a4:3f:b3:d9	(Unknown: locally administered)</span>
<span class="c">#    172.23.0.3	02:42:ac:17:00:03	(Unknown: locally administered)</span>
<span class="c">#    172.23.0.4	02:42:ac:17:00:04	(Unknown: locally administered)</span>
<span class="c">#    172.23.0.5	02:42:ac:17:00:05	(Unknown: locally administered)</span>

<span class="c"># mypc 컨테이너 기동 : kind 도커 브리지를 사용하고, 컨테이너 IP를 직접 지정</span>
<span class="nv">$ </span>docker run <span class="nt">-d</span> <span class="nt">--rm</span> <span class="nt">--name</span> mypc <span class="nt">--network</span> kind <span class="nt">--ip</span> 172.23.0.100 nicolaka/netshoot <span class="nb">sleep </span>infinity
<span class="nv">$ </span>docker ps
<span class="c">## 만약 kind 네트워크 대역이 다를 경우 위 IP 지정이 실패할 수 있으니, 그냥 IP 지정 없이 mypc 컨테이너 기동 할 것</span>
<span class="c">## docker run -d --rm --name mypc --network kind nicolaka/netshoot sleep infinity</span>

<span class="c"># 통신 확인</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc ping <span class="nt">-c</span> 1 172.23.0.1
<span class="c"># =&gt; PING 172.23.0.1 (172.23.0.1) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 172.23.0.1: icmp_seq=1 ttl=64 time=0.154 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 172.23.0.1 ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 0.154/0.154/0.154/0.000 ms</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..5<span class="o">}</span> <span class="p">;</span> <span class="k">do </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc ping <span class="nt">-c</span> 1 172.23.0.<span class="nv">$i</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc zsh
<span class="nt">-------------</span>
<span class="nv">$ </span>ifconfig
<span class="c"># =&gt; eth0      Link encap:Ethernet  HWaddr 02:42:AC:17:00:06  </span>
<span class="c">#              inet addr:172.23.0.6  Bcast:172.23.255.255  Mask:255.255.0.0</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>ping <span class="nt">-c</span> 1 172.23.0.2
<span class="c"># =&gt; PING 172.23.0.2 (172.23.0.2) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 172.23.0.2: icmp_seq=1 ttl=64 time=0.258 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 172.23.0.2 ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 0.258/0.258/0.258/0.000 ms</span>
<span class="nv">$ </span><span class="nb">exit</span>
<span class="nt">-------------</span>

<span class="c"># kube-ops-view 설치</span>
<span class="nv">$ </span>helm repo add geek-cookbook https://geek-cookbook.github.io/charts/
<span class="c"># =&gt; "geek-cookbook" has been added to your repositories</span>
<span class="nv">$ </span>helm <span class="nb">install </span>kube-ops-view geek-cookbook/kube-ops-view <span class="nt">--version</span> 1.2.2 <span class="nt">--set</span> service.main.type<span class="o">=</span>NodePort,service.main.ports.http.nodePort<span class="o">=</span>30000 <span class="nt">--set</span> env.TZ<span class="o">=</span><span class="s2">"Asia/Seoul"</span> <span class="nt">--namespace</span> kube-system
<span class="c"># =&gt; NAME: kube-ops-view</span>
<span class="c">#    ...</span>
<span class="c">#    1. Get the application URL by running these commands:</span>
<span class="c">#      export NODE_PORT=$(kubectl get --namespace kube-system -o jsonpath="{.spec.ports[0].nodePort}" services kube-ops-view)</span>
<span class="c">#      export NODE_IP=$(kubectl get nodes --namespace kube-system -o jsonpath="{.items[0].status.addresses[0].address}")</span>
<span class="c">#      echo http://$NODE_IP:$NODE_PORT</span>

<span class="c"># myk8s-control-plane 배치</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system edit deploy kube-ops-view
<span class="nt">---</span>
spec:
  ...
  template:
    ...
    spec:
      nodeSelector:
        mynode: control-plane
      tolerations:
      - key: <span class="s2">"node-role.kubernetes.io/control-plane"</span>
        operator: <span class="s2">"Equal"</span>
        effect: <span class="s2">"NoSchedule"</span>
<span class="nt">---</span>

<span class="c"># 설치 확인</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system get pod <span class="nt">-o</span> wide <span class="nt">-l</span> app.kubernetes.io/instance<span class="o">=</span>kube-ops-view
<span class="c"># =&gt; NAME                             READY   STATUS    RESTARTS   AGE   IP          NODE                  NOMINATED NODE   READINESS GATES</span>
<span class="c">#    kube-ops-view-58f96c464d-t5t68   1/1     Running   0          30s   10.10.0.5   myk8s-control-plane   &lt;none&gt;           &lt;none&gt;</span>

<span class="c"># kube-ops-view 접속 URL 확인 (1.5 , 2 배율) : macOS 사용자</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"KUBE-OPS-VIEW URL = http://localhost:30000/#scale=1.5"</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"KUBE-OPS-VIEW URL = http://localhost:30000/#scale=2"</span>

<span class="c"># kube-ops-view 접속 URL 확인 (1.5 , 2 배율) : Windows 사용자</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"KUBE-OPS-VIEW URL = http://192.168.50.10:30000/#scale=1.5"</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nt">-e</span> <span class="s2">"KUBE-OPS-VIEW URL = http://192.168.50.10:30000/#scale=2"</span>

</code></pre></div></div>

<p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_12.png" alt="img.png" /></p>

<h4 id="clusterip-실습">ClusterIP 실습</h4>

<ul>
  <li>앞에서 알아본 ClusterIP 타입에 대해 실습해 보겠습니다.</li>
  <li>다음의 사항들을 살펴볼 것입니다.
    <ul>
      <li>ClusterIP의 서비스의 경우 클러스터 내부에서만 접근이 가능한 특성이 있습니다.</li>
      <li>IP로도 접속할 수 있지만 도메인 명으로도 접속이 가능합니다.</li>
      <li>서비스 타입(ClusterIP)을 생성하면 apiserver ⇒ (kubelet) ⇒ kube-proxy ⇒ iptables 에 rule 이 생성 됩니다.</li>
      <li>모든 노드(컨트롤 플레인 포함) 에 iptables rule이 설정 되므로, 파드에서 접속 시 해당 노드에 존재하는 iptables rule 에 의해 분산 접속됩니다.</li>
    </ul>
  </li>
  <li>실습 구성
    <ul>
      <li>
        <p>목적지(backend) 파드 (pod) 생성 : 3pod.yml</p>

        <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c1"># 3pod.yml</span>
  <span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
  <span class="na">kind</span><span class="pi">:</span> <span class="s">Pod</span>
  <span class="na">metadata</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">webpod1</span>
    <span class="na">labels</span><span class="pi">:</span>
      <span class="na">app</span><span class="pi">:</span> <span class="s">webpod</span>
  <span class="na">spec</span><span class="pi">:</span>
    <span class="na">nodeName</span><span class="pi">:</span> <span class="s">myk8s-worker</span>
    <span class="na">containers</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">container</span>
      <span class="na">image</span><span class="pi">:</span> <span class="s">traefik/whoami</span>
    <span class="na">terminationGracePeriodSeconds</span><span class="pi">:</span> <span class="m">0</span>
  <span class="s">---</span>
  <span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
  <span class="na">kind</span><span class="pi">:</span> <span class="s">Pod</span>
  <span class="na">metadata</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">webpod2</span>
    <span class="na">labels</span><span class="pi">:</span>
      <span class="na">app</span><span class="pi">:</span> <span class="s">webpod</span>
  <span class="na">spec</span><span class="pi">:</span>
    <span class="na">nodeName</span><span class="pi">:</span> <span class="s">myk8s-worker2</span>
    <span class="na">containers</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">container</span>
      <span class="na">image</span><span class="pi">:</span> <span class="s">traefik/whoami</span>
    <span class="na">terminationGracePeriodSeconds</span><span class="pi">:</span> <span class="m">0</span>
  <span class="s">---</span>
  <span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
  <span class="na">kind</span><span class="pi">:</span> <span class="s">Pod</span>
  <span class="na">metadata</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">webpod3</span>
    <span class="na">labels</span><span class="pi">:</span>
      <span class="na">app</span><span class="pi">:</span> <span class="s">webpod</span>
  <span class="na">spec</span><span class="pi">:</span>
    <span class="na">nodeName</span><span class="pi">:</span> <span class="s">myk8s-worker3</span>
    <span class="na">containers</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">container</span>
      <span class="na">image</span><span class="pi">:</span> <span class="s">traefik/whoami</span>
    <span class="na">terminationGracePeriodSeconds</span><span class="pi">:</span> <span class="m">0</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p>클라이언트 생성 : netpod.yml</p>

        <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c1"># netpod.yml</span>
  <span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
  <span class="na">kind</span><span class="pi">:</span> <span class="s">Pod</span>
  <span class="na">metadata</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">net-pod</span>
  <span class="na">spec</span><span class="pi">:</span>
    <span class="na">nodeName</span><span class="pi">:</span> <span class="s">myk8s-control-plane</span>
    <span class="na">containers</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">netshoot-pod</span>
      <span class="na">image</span><span class="pi">:</span> <span class="s">nicolaka/netshoot</span>
      <span class="na">command</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">tail"</span><span class="pi">]</span>
      <span class="na">args</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">-f"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">/dev/null"</span><span class="pi">]</span>
    <span class="na">terminationGracePeriodSeconds</span><span class="pi">:</span> <span class="m">0</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p>서비스(ClusterIP) 생성 : svc-clusterip.yml</p>

        <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c1"># svc-clusterip.yml</span>
  <span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
  <span class="na">kind</span><span class="pi">:</span> <span class="s">Service</span>
  <span class="na">metadata</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">svc-clusterip</span>
  <span class="na">spec</span><span class="pi">:</span>
    <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">svc-webport</span>
        <span class="na">port</span><span class="pi">:</span> <span class="m">9000</span>        <span class="c1"># 서비스 IP 에 접속 시 사용하는 포트 port 를 의미</span>
        <span class="na">targetPort</span><span class="pi">:</span> <span class="m">80</span>    <span class="c1"># 타킷 targetPort 는 서비스를 통해서 목적지 파드로 접속 시 해당 파드로 접속하는 포트를 의미</span>
    <span class="na">selector</span><span class="pi">:</span>
      <span class="na">app</span><span class="pi">:</span> <span class="s">webpod</span>         <span class="c1"># 셀렉터 아래 app:webpod 레이블이 설정되어 있는 파드들은 해당 서비스에 연동됨</span>
    <span class="na">type</span><span class="pi">:</span> <span class="s">ClusterIP</span>       <span class="c1"># 서비스 타입</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p>생성 및 확인</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c"># 모니터링</span>
  <span class="nv">$ </span><span class="k">**</span>watch <span class="nt">-d</span> <span class="s1">'kubectl get pod -owide ;echo; kubectl get svc,ep svc-clusterip'</span><span class="k">**</span>
      
  <span class="c"># 생성</span>
  <span class="nv">$ </span>kubectl apply <span class="nt">-f</span> 3pod.yml,netpod.yml,svc-clusterip.yml
  <span class="c"># =&gt; pod/webpod1 created</span>
  <span class="c">#    pod/webpod2 created</span>
  <span class="c">#    pod/webpod3 created</span>
  <span class="c">#    pod/net-pod created</span>
  <span class="c">#    service/svc-clusterip created</span>
      
  <span class="c"># 파드와 서비스 사용 네트워크 대역 정보 확인 </span>
  <span class="nv">$ </span>kubectl cluster-info dump | <span class="nb">grep</span> <span class="nt">-m</span> 2 <span class="nt">-E</span> <span class="s2">"cluster-cidr|service-cluster-ip-range"</span>
  <span class="c"># =&gt; "--service-cluster-ip-range=10.200.1.0/24",</span>
  <span class="c">#    "--cluster-cidr=10.10.0.0/16",</span>
      
  <span class="c"># 확인</span>
  <span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
  <span class="c"># =&gt; NAME      READY   STATUS    RESTARTS   AGE    IP          NODE                  NOMINATED NODE   READINESS GATES</span>
  <span class="c">#    net-pod   1/1     Running   0          2m8s   10.10.0.7   myk8s-control-plane   &lt;none&gt;           &lt;none&gt;</span>
  <span class="c">#    webpod1   1/1     Running   0          2m8s   10.10.4.3   myk8s-worker          &lt;none&gt;           &lt;none&gt;</span>
  <span class="c">#    webpod2   1/1     Running   0          2m8s   10.10.1.4   myk8s-worker2         &lt;none&gt;           &lt;none&gt;</span>
  <span class="c">#    webpod3   1/1     Running   0          2m8s   10.10.2.3   myk8s-worker3         &lt;none&gt;           &lt;none&gt;</span>
  <span class="nv">$ </span>kubectl get svc svc-clusterip
  <span class="c"># =&gt; NAME            TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)    AGE</span>
  <span class="c">#    svc-clusterip   ClusterIP   10.200.1.96   &lt;none&gt;        9000/TCP   2m15s</span>
      
  <span class="c"># spec.ports.port 와 spec.ports.targetPort 가 어떤 의미인지 꼭 이해하자!</span>
  <span class="nv">$ </span>kubectl describe svc svc-clusterip
  <span class="c"># =&gt; Name:              svc-clusterip</span>
  <span class="c">#    Namespace:         default</span>
  <span class="c">#    Labels:            &lt;none&gt;</span>
  <span class="c">#    Annotations:       &lt;none&gt;</span>
  <span class="c">#    Selector:          app=webpod</span>
  <span class="c">#    Type:              ClusterIP</span>
  <span class="c">#    IP Family Policy:  SingleStack</span>
  <span class="c">#    IP Families:       IPv4</span>
  <span class="c">#    IP:                10.200.1.96</span>
  <span class="c">#    IPs:               10.200.1.96</span>
  <span class="c">#    Port:              svc-webport  9000/TCP                    # service의 listening port</span>
  <span class="c">#    TargetPort:        80/TCP                                   # pod의 실제 port</span>
  <span class="c">#    Endpoints:         10.10.1.4:80,10.10.2.3:80,10.10.4.3:80   # pod의 ip:port 목록</span>
  <span class="c">#    Session Affinity:  None</span>
  <span class="c">#    Events:            &lt;none&gt;</span>
      
  <span class="c"># 서비스 생성 시 엔드포인트를 자동으로 생성, 물론 수동으로 설정 생성도 가능</span>
  <span class="nv">$ </span>kubectl get endpoints svc-clusterip
  <span class="c"># =&gt; NAME            ENDPOINTS                                AGE</span>
  <span class="c">#    svc-clusterip   10.10.1.4:80,10.10.2.3:80,10.10.4.3:80   3m32s</span>
  <span class="nv">$ </span>kubectl get endpointslices <span class="nt">-l</span> kubernetes.io/service-name<span class="o">=</span>svc-clusterip
  <span class="c"># =&gt; NAME                  ADDRESSTYPE   PORTS   ENDPOINTS                       AGE</span>
  <span class="c">#    svc-clusterip-xxvws   IPv4          80      10.10.4.3,10.10.1.4,10.10.2.3   3m39s</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
</ul>

<p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_13.png" alt="img.png" /></p>

<ul>
  <li>서비스 (ClusterIP) 접속 확인
    <ul>
      <li>
        <p>클라이언트 (TestPod)의 Shell 에 접속하여 서비스(ClusterIP) 부하분산 접속 확인</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c"># webpod 파드의 IP 를 출력</span>
  <span class="nv">$ </span>kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>webpod <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.items[*].status.podIP}"</span>
  <span class="c"># =&gt; 10.10.4.3 10.10.1.4 10.10.2.3</span>
      
  <span class="c"># webpod 파드의 IP를 변수에 지정</span>
  <span class="nv">$ WEBPOD1</span><span class="o">=</span><span class="si">$(</span>kubectl get pod webpod1 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.status.podIP<span class="o">}</span><span class="si">)</span>
  <span class="nv">$ WEBPOD2</span><span class="o">=</span><span class="si">$(</span>kubectl get pod webpod2 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.status.podIP<span class="o">}</span><span class="si">)</span>
  <span class="nv">$ WEBPOD3</span><span class="o">=</span><span class="si">$(</span>kubectl get pod webpod3 <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.status.podIP<span class="o">}</span><span class="si">)</span>
  <span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$WEBPOD1</span> <span class="nv">$WEBPOD2</span> <span class="nv">$WEBPOD3</span>
  <span class="c"># =&gt; 10.10.4.3 10.10.1.4 10.10.2.3</span>
      
  <span class="c"># net-pod 파드에서 webpod 파드의 IP로 직접 curl 로 반복 접속</span>
  <span class="nv">$ </span><span class="k">for </span>pod <span class="k">in</span> <span class="nv">$WEBPOD1</span> <span class="nv">$WEBPOD2</span> <span class="nv">$WEBPOD3</span><span class="p">;</span> <span class="k">do </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> net-pod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nv">$pod</span><span class="p">;</span> <span class="k">done</span>
  <span class="c"># =&gt; Hostname: webpod1</span>
  <span class="c">#    IP: 10.10.4.3</span>
  <span class="c">#    RemoteAddr: 10.10.0.7:56374</span>
  <span class="c">#    GET / HTTP/1.1</span>
  <span class="c">#    Host: 10.10.4.3</span>
  <span class="c">#    User-Agent: curl/8.7.1</span>
  <span class="c">#    Accept: */*</span>
  <span class="c">#    </span>
  <span class="c">#    Hostname: webpod2</span>
  <span class="c">#    ...</span>
  <span class="c">#    Hostname: webpod3</span>
  <span class="c">#    ...</span>
  <span class="nv">$ </span><span class="k">for </span>pod <span class="k">in</span> <span class="nv">$WEBPOD1</span> <span class="nv">$WEBPOD2</span> <span class="nv">$WEBPOD3</span><span class="p">;</span> <span class="k">do </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> net-pod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nv">$pod</span> | <span class="nb">grep </span>Hostname<span class="p">;</span> <span class="k">done</span>
  <span class="c"># =&gt; Hostname: webpod1</span>
  <span class="c">#    Hostname: webpod2</span>
  <span class="c">#    Hostname: webpod3</span>
  <span class="nv">$ </span><span class="k">for </span>pod <span class="k">in</span> <span class="nv">$WEBPOD1</span> <span class="nv">$WEBPOD2</span> <span class="nv">$WEBPOD3</span><span class="p">;</span> <span class="k">do </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> net-pod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nv">$pod</span> | <span class="nb">grep </span>Host<span class="p">;</span> <span class="k">done</span>
  <span class="c"># =&gt; Hostname: webpod1</span>
  <span class="c">#    Host: 10.10.4.3</span>
  <span class="c">#    Hostname: webpod2</span>
  <span class="c">#    Host: 10.10.1.4</span>
  <span class="c">#    Hostname: webpod3</span>
  <span class="c">#    Host: 10.10.2.3</span>
  <span class="nv">$ </span><span class="k">for </span>pod <span class="k">in</span> <span class="nv">$WEBPOD1</span> <span class="nv">$WEBPOD2</span> <span class="nv">$WEBPOD3</span><span class="p">;</span> <span class="k">do </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> net-pod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nv">$pod</span> | egrep <span class="s1">'Host|RemoteAddr'</span><span class="p">;</span> <span class="k">done</span>
  <span class="c"># =&gt; Hostname: webpod1</span>
  <span class="c">#    RemoteAddr: 10.10.0.7:36382</span>
  <span class="c">#    Host: 10.10.4.3</span>
  <span class="c">#    Hostname: webpod2</span>
  <span class="c">#    RemoteAddr: 10.10.0.7:52122</span>
  <span class="c">#    Host: 10.10.1.4</span>
  <span class="c">#    Hostname: webpod3</span>
  <span class="c">#    RemoteAddr: 10.10.0.7:55962</span>
  <span class="c">#    Host: 10.10.2.3</span>
      
  <span class="c"># 서비스 IP 변수 지정 : svc-clusterip 의 ClusterIP주소</span>
  <span class="nv">$ SVC1</span><span class="o">=</span><span class="si">$(</span>kubectl get svc svc-clusterip <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.spec.clusterIP<span class="o">}</span><span class="si">)</span>
  <span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$SVC1</span>
  <span class="c"># =&gt; 10.200.1.96</span>
      
  <span class="c"># 위 서비스 생성 시 kube-proxy 에 의해서 iptables 규칙이 모든 노드에 추가됨 </span>
  <span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane iptables <span class="nt">-t</span> nat <span class="nt">-S</span> | <span class="nb">grep</span> <span class="nv">$SVC1</span>
  <span class="c"># =&gt; -A KUBE-SERVICES -d 10.200.1.96/32 -p tcp -m comment --comment "default/svc-clusterip:svc-webport cluster IP" -m tcp --dport 9000 -j KUBE-SVC-KBDEBIL6IU6WL7RF</span>
  <span class="c">#    -A KUBE-SVC-KBDEBIL6IU6WL7RF ! -s 10.10.0.0/16 -d 10.200.1.96/32 -p tcp -m comment --comment "default/svc-clusterip:svc-webport cluster IP" -m tcp --dport 9000 -j KUBE-MARK-MASQ</span>
  <span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>control-plane worker worker2 worker3<span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node myk8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-<span class="nv">$i</span> iptables <span class="nt">-t</span> nat <span class="nt">-S</span> | <span class="nb">grep</span> <span class="nv">$SVC1</span><span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
  <span class="c"># =&gt; &gt;&gt; node myk8s-control-plane &lt;&lt;</span>
  <span class="c">#    -A KUBE-SERVICES -d 10.200.1.96/32 -p tcp -m comment --comment "default/svc-clusterip:svc-webport cluster IP" -m tcp --dport 9000 -j KUBE-SVC-KBDEBIL6IU6WL7RF</span>
  <span class="c">#    -A KUBE-SVC-KBDEBIL6IU6WL7RF ! -s 10.10.0.0/16 -d 10.200.1.96/32 -p tcp -m comment --comment "default/svc-clusterip:svc-webport cluster IP" -m tcp --dport 9000 -j KUBE-MARK-MASQ</span>
  <span class="c">#    </span>
  <span class="c">#    &gt;&gt; node myk8s-worker &lt;&lt;</span>
  <span class="c">#    -A KUBE-SERVICES -d 10.200.1.96/32 -p tcp -m comment --comment "default/svc-clusterip:svc-webport cluster IP" -m tcp --dport 9000 -j KUBE-SVC-KBDEBIL6IU6WL7RF</span>
  <span class="c">#    -A KUBE-SVC-KBDEBIL6IU6WL7RF ! -s 10.10.0.0/16 -d 10.200.1.96/32 -p tcp -m comment --comment "default/svc-clusterip:svc-webport cluster IP" -m tcp --dport 9000 -j KUBE-MARK-MASQ</span>
  <span class="c">#    </span>
  <span class="c">#    &gt;&gt; node myk8s-worker2 &lt;&lt;</span>
  <span class="c">#    -A KUBE-SERVICES -d 10.200.1.96/32 -p tcp -m comment --comment "default/svc-clusterip:svc-webport cluster IP" -m tcp --dport 9000 -j KUBE-SVC-KBDEBIL6IU6WL7RF</span>
  <span class="c">#    -A KUBE-SVC-KBDEBIL6IU6WL7RF ! -s 10.10.0.0/16 -d 10.200.1.96/32 -p tcp -m comment --comment "default/svc-clusterip:svc-webport cluster IP" -m tcp --dport 9000 -j KUBE-MARK-MASQ</span>
  <span class="c">#    </span>
  <span class="c">#    &gt;&gt; node myk8s-worker3 &lt;&lt;</span>
  <span class="c">#    -A KUBE-SERVICES -d 10.200.1.96/32 -p tcp -m comment --comment "default/svc-clusterip:svc-webport cluster IP" -m tcp --dport 9000 -j KUBE-SVC-KBDEBIL6IU6WL7RF</span>
  <span class="c">#    -A KUBE-SVC-KBDEBIL6IU6WL7RF ! -s 10.10.0.0/16 -d 10.200.1.96/32 -p tcp -m comment --comment "default/svc-clusterip:svc-webport cluster IP" -m tcp --dport 9000 -j KUBE-MARK-MASQ</span>
      
  <span class="c">## (참고) ss 툴로 tcp listen 정보에는 없음 , 별도 /32 host 라우팅 추가 없음 -&gt; 즉, iptables rule 에 의해서 처리됨을 확인</span>
  <span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane ss <span class="nt">-tnlp</span>
  <span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane ip <span class="nt">-c</span> route
      
  <span class="c"># TCP 80,9000 포트별 접속 확인 : 출력 정보 의미 확인</span>
  <span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> net-pod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 <span class="nv">$SVC1</span>:80
  <span class="c"># =&gt; (공백)</span>
  <span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> net-pod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 <span class="nv">$SVC1</span>:9000
  <span class="c"># =&gt; Hostname: webpod2</span>
  <span class="c">#    ...</span>
  <span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> net-pod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 <span class="nv">$SVC1</span>:9000 | <span class="nb">grep </span>Hostname
  <span class="c"># =&gt; Hostname: webpod3</span>
  <span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> net-pod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 <span class="nv">$SVC1</span>:9000 | <span class="nb">grep </span>Hostname
  <span class="c"># =&gt; Hostname: webpod1 </span>
      
  <span class="c"># curl로 접속했을때 컨테이너의 포트인 targetPort 80으로는 접속이 안 되고 port 9000로는 접속이 됩니다.</span>
  <span class="c"># 또한 접속시마다 각 pod에 부하가 분산되어 HostName: 이 변경됨을 확인할 수 있습니다.</span>
      
  <span class="c"># 서비스(ClusterIP) 부하분산 접속 확인</span>
  <span class="c">## for 문을 이용하여 SVC1 IP 로 100번 접속을 시도 후 출력되는 내용 중 반복되는 내용의 갯수 출력</span>
  <span class="c">## 반복해서 실행을 해보면, SVC1 IP로 curl 접속 시 3개의 파드로 대략 33% 정도로 부하분산 접속됨을 확인</span>
  <span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> net-pod <span class="nt">--</span> zsh <span class="nt">-c</span> <span class="s2">"for i in {1..10};   do curl -s </span><span class="nv">$SVC1</span><span class="s2">:9000 | grep Hostname; done | sort | uniq -c | sort -nr"</span>
  <span class="c"># =&gt;       4 Hostname: webpod3</span>
  <span class="c">#          4 Hostname: webpod2</span>
  <span class="c">#          2 Hostname: webpod1</span>
  <span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> net-pod <span class="nt">--</span> zsh <span class="nt">-c</span> <span class="s2">"for i in {1..100};  do curl -s </span><span class="nv">$SVC1</span><span class="s2">:9000 | grep Hostname; done | sort | uniq -c | sort -nr"</span>
  <span class="c"># =&gt;      38 Hostname: webpod3</span>
  <span class="c">#         35 Hostname: webpod1</span>
  <span class="c">#         27 Hostname: webpod2</span>
  <span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> net-pod <span class="nt">--</span> zsh <span class="nt">-c</span> <span class="s2">"for i in {1..1000}; do curl -s </span><span class="nv">$SVC1</span><span class="s2">:9000 | grep Hostname; done | sort | uniq -c | sort -nr"</span>
  <span class="c"># =&gt;     346 Hostname: webpod2</span>
  <span class="c">#        336 Hostname: webpod1</span>
  <span class="c">#        318 Hostname: webpod3</span>
  <span class="c"># 혹은</span>
  <span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> net-pod <span class="nt">--</span> zsh <span class="nt">-c</span> <span class="s2">"for i in {1..100};   do curl -s </span><span class="nv">$SVC1</span><span class="s2">:9000 | grep Hostname; sleep 1; done"</span>
  <span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> net-pod <span class="nt">--</span> zsh <span class="nt">-c</span> <span class="s2">"for i in {1..100};   do curl -s </span><span class="nv">$SVC1</span><span class="s2">:9000 | grep Hostname; sleep 0.1; done"</span>
  <span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> net-pod <span class="nt">--</span> zsh <span class="nt">-c</span> <span class="s2">"for i in {1..10000}; do curl -s </span><span class="nv">$SVC1</span><span class="s2">:9000 | grep Hostname; sleep 0.01; done"</span>
      
  <span class="c"># conntrack 확인</span>
  <span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane bash
  <span class="nt">----------------------------------------</span>
  <span class="nv">$ </span>conntrack <span class="nt">-h</span>
  <span class="nv">$ </span>conntrack <span class="nt">-E</span>
  <span class="c"># =&gt;     [NEW] tcp      6 120 SYN_SENT src=172.23.0.2 dst=172.23.0.2 sport=45466 dport=6443 [UNREPLIED] src=172.23.0.2 dst=172.23.0.2 sport=6443 dport=45466</span>
  <span class="c">#     [UPDATE] tcp      6 60 SYN_RECV src=172.23.0.2 dst=172.23.0.2 sport=45466 dport=6443 src=172.23.0.2 dst=172.23.0.2 sport=6443 dport=45466</span>
  <span class="nv">$ </span>conntrack <span class="nt">-C</span>
  <span class="c"># =&gt; 2763</span>
  <span class="nv">$ </span>conntrack <span class="nt">-S</span>
  <span class="c"># =&gt; cpu=0           found=0 invalid=0 insert=0 insert_failed=0 drop=0 early_drop=0 error=0 search_restart=3 clash_resolve=0 chaintoolong=0</span>
  <span class="c">#    cpu=1           found=0 invalid=0 insert=0 insert_failed=0 drop=0 early_drop=0 error=0 search_restart=0 clash_resolve=0 chaintoolong=0</span>
  <span class="nv">$ </span>conntrack <span class="nt">-L</span> <span class="nt">--src</span> 10.200.0.7 <span class="c"># net-pod IP</span>
  <span class="c"># =&gt; tcp      6 93 TIME_WAIT src=10.10.0.7 dst=10.200.1.96 sport=37008 dport=9000 src=10.10.2.3 dst=10.10.0.7 sport=80 dport=37008 [ASSURED] mark=0 use=1</span>
  <span class="c">#    tcp      6 93 TIME_WAIT src=10.10.0.7 dst=10.200.1.96 sport=36584 dport=9000 src=10.10.2.3 dst=10.10.0.7 sport=80 dport=36584 [ASSURED] mark=0 use=1</span>
  <span class="nv">$ SVC1</span><span class="o">=</span><span class="si">$(</span>kubectl get svc svc-clusterip <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.spec.clusterIP<span class="o">}</span><span class="si">)</span>
  <span class="nv">$ </span>conntrack <span class="nt">-L</span> <span class="nt">--dst</span> <span class="nv">$SVC1</span>     <span class="c"># service ClusterIP</span>
  <span class="c"># =&gt; tcp      6 31 TIME_WAIT src=10.10.0.7 dst=10.200.1.96 sport=37008 dport=9000 src=10.10.2.3 dst=10.10.0.7 sport=80 dport=37008 [ASSURED] mark=0 use=1</span>
  <span class="c">#    tcp      6 31 TIME_WAIT src=10.10.0.7 dst=10.200.1.96 sport=36584 dport=9000 src=10.10.2.3 dst=10.10.0.7 sport=80 dport=36584 [ASSURED] mark=0 use=1</span>
  <span class="nv">$ </span><span class="nb">exit</span>
  <span class="nt">----------------------------------------</span>
      
  <span class="c"># (참고) Link layer 에서 동작하는 ebtables</span>
  <span class="nv">$ </span>ebtables <span class="nt">-L</span>
  <span class="c"># =&gt; Bridge table: filter</span>
  <span class="c">#    Bridge chain: INPUT, entries: 0, policy: ACCEPT</span>
  <span class="c">#    Bridge chain: FORWARD, entries: 0, policy: ACCEPT</span>
  <span class="c">#    Bridge chain: OUTPUT, entries: 0, policy: ACCEPT</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p>각 워커 노드에서 패킷  덤프 확인</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c"># 방안1 : 1대 혹은 3대 bash 진입 후 tcpdump 해둘 것</span>
  <span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker bash
  <span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker2 bash
  <span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker3 bash
  <span class="nt">----------------------------------</span>
  <span class="c"># nic 정보 확인</span>
  <span class="nv">$ </span>ip <span class="nt">-c</span> <span class="nb">link</span>
  <span class="c"># =&gt; &lt;&lt;myk8s-worker&gt;&gt;</span>
  <span class="c">#    3: veth9a888981@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default</span>
  <span class="c">#        link/ether 26:a5:d2:44:f4:b4 brd ff:ff:ff:ff:ff:ff link-netns cni-0b7e59c3-3920-ce1f-874a-9e228adf3b72</span>
  <span class="c">#    134: eth0@if135: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default</span>
  <span class="c">#        link/ether 02:42:ac:17:00:04 brd ff:ff:ff:ff:ff:ff link-netnsid 0</span>
  <span class="c">#    </span>
  <span class="c">#    &lt;&lt;myk8s-worker2&gt;&gt;</span>
  <span class="c">#    4: veth570fce87@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default</span>
  <span class="c">#        link/ether a6:8a:d8:a3:f4:ac brd ff:ff:ff:ff:ff:ff link-netns cni-8dcb2d16-f339-2571-03d2-d6b0f850878d</span>
  <span class="c">#    136: eth0@if137: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default</span>
  <span class="c">#        link/ether 02:42:ac:17:00:05 brd ff:ff:ff:ff:ff:ff link-netnsid 0</span>
  <span class="c">#    </span>
  <span class="c">#    &lt;&lt;myk8s-worker3&gt;&gt;</span>
  <span class="c">#    3: veth2e19df47@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default</span>
  <span class="c">#        link/ether da:5e:a5:14:62:7b brd ff:ff:ff:ff:ff:ff link-netns cni-1f44bebd-9ebf-6af4-7888-945649a2b5c8</span>
  <span class="c">#    132: eth0@if133: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default</span>
  <span class="c">#        link/ether 02:42:ac:17:00:03 brd ff:ff:ff:ff:ff:ff link-netnsid 0</span>
      
  <span class="nv">$ </span>ip <span class="nt">-c</span> route
  <span class="c"># =&gt; &lt;&lt;myk8s-worker&gt;&gt;</span>
  <span class="c">#    default via 172.23.0.1 dev eth0</span>
  <span class="c">#    10.10.0.0/24 via 172.23.0.2 dev eth0</span>
  <span class="c">#    10.10.1.0/24 via 172.23.0.5 dev eth0</span>
  <span class="c">#    10.10.2.0/24 via 172.23.0.3 dev eth0</span>
  <span class="c">#    10.10.4.3 dev veth9a888981 scope host</span>
  <span class="c">#    172.23.0.0/16 dev eth0 proto kernel scope link src 172.23.0.4</span>
  <span class="c">#</span>
  <span class="c">#    &lt;&lt;myk8s-worker2&gt;&gt;</span>
  <span class="c">#    default via 172.23.0.1 dev eth0</span>
  <span class="c">#    10.10.0.0/24 via 172.23.0.2 dev eth0</span>
  <span class="c">#    10.10.1.4 dev veth570fce87 scope host</span>
  <span class="c">#    10.10.2.0/24 via 172.23.0.3 dev eth0</span>
  <span class="c">#    10.10.4.0/24 via 172.23.0.4 dev eth0</span>
  <span class="c">#    172.23.0.0/16 dev eth0 proto kernel scope link src 172.23.0.5</span>
  <span class="c">#    </span>
  <span class="c">#    &lt;&lt;myk8s-worker3&gt;&gt;</span>
  <span class="c">#    default via 172.23.0.1 dev eth0</span>
  <span class="c">#    10.10.0.0/24 via 172.23.0.2 dev eth0</span>
  <span class="c">#    10.10.1.0/24 via 172.23.0.5 dev eth0</span>
  <span class="c">#    10.10.2.3 dev veth2e19df47 scope host</span>
  <span class="c">#    10.10.4.0/24 via 172.23.0.4 dev eth0</span>
  <span class="c">#    172.23.0.0/16 dev eth0 proto kernel scope link src 172.23.0.3</span>
      
  <span class="nv">$ </span>ip <span class="nt">-c</span> addr
  <span class="c"># =&gt; &lt;&lt;myk8s-worker&gt;&gt;</span>
  <span class="c">#    3: veth9a888981@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default</span>
  <span class="c">#        link/ether 26:a5:d2:44:f4:b4 brd ff:ff:ff:ff:ff:ff link-netns cni-0b7e59c3-3920-ce1f-874a-9e228adf3b72</span>
  <span class="c">#        inet 10.10.4.1/32 scope global veth9a888981</span>
  <span class="c">#           valid_lft forever preferred_lft forever</span>
  <span class="c">#    134: eth0@if135: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default</span>
  <span class="c">#        link/ether 02:42:ac:17:00:04 brd ff:ff:ff:ff:ff:ff link-netnsid 0</span>
  <span class="c">#        inet 172.23.0.4/16 brd 172.23.255.255 scope global eth0</span>
  <span class="c">#           valid_lft forever preferred_lft forever</span>
  <span class="c">#    </span>
  <span class="c">#    &lt;&lt;myk8s-worker2&gt;&gt;</span>
  <span class="c">#    4: veth570fce87@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default</span>
  <span class="c">#        link/ether a6:8a:d8:a3:f4:ac brd ff:ff:ff:ff:ff:ff link-netns cni-8dcb2d16-f339-2571-03d2-d6b0f850878d</span>
  <span class="c">#        inet 10.10.1.1/32 scope global veth570fce87</span>
  <span class="c">#           valid_lft forever preferred_lft forever</span>
  <span class="c">#    136: eth0@if137: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default</span>
  <span class="c">#        link/ether 02:42:ac:17:00:05 brd ff:ff:ff:ff:ff:ff link-netnsid 0</span>
  <span class="c">#        inet 172.23.0.5/16 brd 172.23.255.255 scope global eth0</span>
  <span class="c">#           valid_lft forever preferred_lft forever</span>
  <span class="c">#    </span>
  <span class="c">#    &lt;&lt;myk8s-worker3&gt;&gt;</span>
  <span class="c">#    3: veth2e19df47@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default</span>
  <span class="c">#        link/ether da:5e:a5:14:62:7b brd ff:ff:ff:ff:ff:ff link-netns cni-1f44bebd-9ebf-6af4-7888-945649a2b5c8</span>
  <span class="c">#        inet 10.10.2.1/32 scope global veth2e19df47</span>
  <span class="c">#           valid_lft forever preferred_lft forever</span>
  <span class="c">#    132: eth0@if133: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default</span>
  <span class="c">#        link/ether 02:42:ac:17:00:03 brd ff:ff:ff:ff:ff:ff link-netnsid 0</span>
  <span class="c">#        inet 172.23.0.3/16 brd 172.23.255.255 scope global eth0</span>
  <span class="c">#           valid_lft forever preferred_lft forever</span>
      
  <span class="c"># tcpdump/ngrep : eth0 &gt;&gt; tcp 9000 포트 트래픽은 왜 없을까? iptables rule 동작 그림을 한번 더 확인하고 이해해보자</span>
  <span class="c">## ngrep 네트워크 패킷 분석기 활용해보기 : 특정 url 호출에 대해서만 필터 등 깔끔하게 볼 수 있음 - 링크</span>
  <span class="nv">$ </span>tcpdump <span class="nt">-i</span> eth0 tcp port 80 <span class="nt">-nnq</span>
  <span class="nv">$ </span>tcpdump <span class="nt">-i</span> eth0 tcp port 80 <span class="nt">-w</span> /root/svc1-1.pcap
  <span class="nv">$ </span>tcpdump <span class="nt">-i</span> eth0 tcp port 9000 <span class="nt">-nnq</span>
  <span class="nv">$ </span>ngrep <span class="nt">-tW</span> byline <span class="nt">-d</span> eth0 <span class="s1">''</span> <span class="s1">'tcp port 80'</span>
      
  <span class="c"># tcpdump/ngrep : vethX</span>
  <span class="c"># $ VETH1=&lt;각자 자신의 veth 이름&gt;</span>
  <span class="nv">$ VETH1</span><span class="o">=</span>veth9a888981
  <span class="nv">$ </span>tcpdump <span class="nt">-i</span> <span class="nv">$VETH1</span> tcp port 80 <span class="nt">-nn</span>
  <span class="nv">$ </span>tcpdump <span class="nt">-i</span> <span class="nv">$VETH1</span> tcp port 80 <span class="nt">-w</span> /root/svc1-2.pcap
  <span class="nv">$ </span>tcpdump <span class="nt">-i</span> <span class="nv">$VETH1</span> tcp port 9000 <span class="nt">-nn</span>
  <span class="nv">$ </span>ngrep <span class="nt">-tW</span> byline <span class="nt">-d</span> <span class="nv">$VETH1</span> <span class="s1">''</span> <span class="s1">'tcp port 80'</span>
      
  <span class="nv">$ </span><span class="nb">exit</span>
  <span class="nt">----------------------------------</span>
      
  <span class="c"># 방안2 : kind 노드 컨테이너 bash 직접 접속하지 않고 호스트에서 tcpdump 하기</span>
  <span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker tcpdump <span class="nt">-i</span> eth0 tcp port 80 <span class="nt">-nnq</span>
  <span class="nv">$ VETH1</span><span class="o">=</span>&lt;각자 자신의 veth 이름&gt; docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker ip <span class="nt">-c</span> route
  <span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker tcpdump <span class="nt">-i</span> <span class="nv">$VETH1</span> tcp port 80 <span class="nt">-nnq</span>
      
  <span class="c"># 호스트PC에 pcap 파일 복사 &gt;&gt; wireshark 에서 분석</span>
  <span class="nv">$ </span>docker <span class="nb">cp </span>myk8s-worker:/root/svc1-1.pcap <span class="nb">.</span>
  <span class="nv">$ </span>docker <span class="nb">cp </span>myk8s-worker:/root/svc1-2.pcap <span class="nb">.</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p>net-pod 포드에 접속 후 10개 curl 요청</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> net-pod <span class="nt">--</span> zsh
<span class="nt">----------------------------------</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..10<span class="o">}</span><span class="p">;</span>   <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$SVC1</span>:9000 | <span class="nb">grep </span>Hostname<span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
<span class="c"># =&gt;       4 Hostname: webpod3</span>
<span class="c">#          3 Hostname: webpod2</span>
<span class="c">#          3 Hostname: webpod1</span>
    
<span class="nv">$ </span><span class="nb">exit</span>
<span class="nt">----------------------------------</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p>각각 net-pod와 워커 노드들의 패킷캡쳐파일(*.pcap)를 받아서 와이어샤크로 확인해보겠습니다.</p>
        <ul>
          <li>
            <p>net-pod(10.10.0.7)에서 서비스:9000 (IP:10.200.1.96)으로 요청된 패킷이 DNAT 되어 k8s-worker의 webpod1:80 (IP:10.10.4.3)으로 전달되고, 응답은 그 반대로 전달 되는 것을 확인 할 수 있습니다.</p>

            <p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_14.png" alt="img.png" /></p>
          </li>
          <li>
            <p>또한 Stastics 메뉴의→ Flow Graph 기능을 통해 패킷의 흐름을 확인할 수 있었습니다.</p>

            <p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_15.png" alt="img.png" /></p>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>iptables 정책 확인
    <ul>
      <li>kubernetes에서 service는 다음의 iptables 과정을 거칩니다.
        <ul>
          <li>(1) PREROUTING ⇒ (2) KUBE-SERVICES ⇒ (3) KUBE-SVC-YYY ⇒ (4) KUBE-SEP-#파드1, KUBE-SEP-#파드2, KUBE-SEP-#파드3</li>
          <li>그림으로 나타내면 다음과 같습니다.</li>
        </ul>

        <p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_16.png" alt="img.png" /></p>

        <ul>
          <li>
            <p>각각에 대하여 iptables 룰을 확인해보겠습니다.</p>

            <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c"># 컨트롤플레인에서 확인하겠습니다.</span>
  <span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane bash
  <span class="nt">----------------------------------------</span>
        
  <span class="c"># iptables 확인</span>
  <span class="nv">$ </span>iptables <span class="nt">-t</span> filter <span class="nt">-S</span>
  <span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span>
  <span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span> | <span class="nb">wc</span> <span class="nt">-l</span>
  <span class="c"># =&gt; 97</span>
  <span class="nv">$ </span>iptables <span class="nt">-t</span> mangle <span class="nt">-S</span>
        
  <span class="c"># iptables 상세 확인 - 매칭 패킷 카운트, 인터페이스 정보 등 포함</span>
  <span class="nv">$ </span>iptables <span class="nt">-nvL</span> <span class="nt">-t</span> filter
  <span class="nv">$ </span>iptables <span class="nt">-nvL</span> <span class="nt">-t</span> nat
  <span class="nv">$ </span>iptables <span class="nt">-nvL</span> <span class="nt">-t</span> mangle
        
  <span class="c"># rule 갯수 확인</span>
  <span class="nv">$ </span>iptables <span class="nt">-nvL</span> <span class="nt">-t</span> filter | <span class="nb">wc</span> <span class="nt">-l</span>
  <span class="c"># =&gt; 47</span>
  <span class="nv">$ </span>iptables <span class="nt">-nvL</span> <span class="nt">-t</span> nat | <span class="nb">wc</span> <span class="nt">-l</span>
  <span class="c"># =&gt; 158</span>
        
  <span class="c"># 규칙 패킷 바이트 카운트 초기화</span>
  <span class="nv">$ </span>iptables <span class="nt">-t</span> filter <span class="nt">--zero</span><span class="p">;</span> iptables <span class="nt">-t</span> nat <span class="nt">--zero</span><span class="p">;</span> iptables <span class="nt">-t</span> mangle <span class="nt">--zero</span>
        
  <span class="c"># 정책 확인 : 아래 정책 내용은 핵심적인 룰(rule)만 표시했습니다!</span>
  <span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-nvL</span>
  <span class="c"># =&gt; Chain PREROUTING (policy ACCEPT 121 packets, 7260 bytes) &lt;&lt;1. PREROUTING&gt;&gt;</span>
  <span class="c">#     pkts bytes target     prot opt in     out     source               destination         </span>
  <span class="c">#      121  7260 KUBE-SERVICES  0    --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes service portals */</span>
  <span class="c">#    ...</span>
  <span class="c">#    </span>
  <span class="c">#    Chain INPUT (policy ACCEPT 121 packets, 7260 bytes)</span>
  <span class="c">#    </span>
  <span class="c">#    Chain OUTPUT (policy ACCEPT 392 packets, 23520 bytes)</span>
  <span class="c">#     pkts bytes target     prot opt in     out     source               destination         </span>
  <span class="c">#      392 23520 KUBE-SERVICES  0    --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes service portals */</span>
  <span class="c">#    ...</span>
  <span class="c">#    </span>
  <span class="c">#    Chain KUBE-MARK-MASQ (18 references)</span>
  <span class="c">#     pkts bytes target     prot opt in     out     source               destination         </span>
  <span class="c">#        0     0 MARK       0    --  *      *       0.0.0.0/0            0.0.0.0/0            MARK or 0x4000</span>
  <span class="c">#    </span>
  <span class="c">#    Chain KUBE-SERVICES (2 references) &lt;&lt;2. SERVICES&gt;&gt;</span>
  <span class="c">#     pkts bytes target     prot opt in     out     source               destination         </span>
  <span class="c">#        0     0 KUBE-SVC-KBDEBIL6IU6WL7RF  6    --  *      *       0.0.0.0/0            10.200.1.96          /* default/svc-clusterip:svc-webport cluster IP */ tcp dpt:9000</span>
  <span class="c">#    ...</span>
  <span class="c">#    </span>
  <span class="c">#    Chain KUBE-SVC-KBDEBIL6IU6WL7RF (1 references) &lt;&lt;3. KUBE-SVC-YYY&gt;&gt;</span>
  <span class="c">#     pkts bytes target     prot opt in     out     source               destination         </span>
  <span class="c">#        0     0 KUBE-MARK-MASQ  6    --  *      *      !10.10.0.0/16         10.200.1.96          /* default/svc-clusterip:svc-webport cluster IP */ tcp dpt:9000</span>
  <span class="c">#        0     0 KUBE-SEP-T7YVH2JOMUTQFUDU  0    --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/svc-clusterip:svc-webport -&gt; 10.10.1.4:80 */ statistic mode random probability 0.33333333349</span>
  <span class="c">#        0     0 KUBE-SEP-SZHENXPAXVOCHRDA  0    --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/svc-clusterip:svc-webport -&gt; 10.10.2.3:80 */ statistic mode random probability 0.50000000000</span>
  <span class="c">#        0     0 KUBE-SEP-X47GKN7LA32LZ4H7  0    --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/svc-clusterip:svc-webport -&gt; 10.10.4.3:80 */</span>
  <span class="c">#    </span>
  <span class="c">#    Chain KUBE-SEP-X47GKN7LA32LZ4H7 (1 references) &lt;&lt;4. KUBE-SEP-#WEBPOD1&gt;&gt;</span>
  <span class="c">#     pkts bytes target     prot opt in     out     source               destination         </span>
  <span class="c">#        0     0 KUBE-MARK-MASQ  0    --  *      *       10.10.4.3            0.0.0.0/0            /* default/svc-clusterip:svc-webport */</span>
  <span class="c">#        0     0 DNAT       6    --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/svc-clusterip:svc-webport */ tcp to:10.10.4.3:80</span>
  <span class="c">#    </span>
  <span class="c">#    Chain KUBE-SEP-T7YVH2JOMUTQFUDU (1 references) &lt;&lt;4. KUBE-SEP-#WEBPOD2&gt;&gt;</span>
  <span class="c">#     pkts bytes target     prot opt in     out     source               destination         </span>
  <span class="c">#        0     0 KUBE-MARK-MASQ  0    --  *      *       10.10.1.4            0.0.0.0/0            /* default/svc-clusterip:svc-webport */</span>
  <span class="c">#        0     0 DNAT       6    --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/svc-clusterip:svc-webport */ tcp to:10.10.1.4:80</span>
  <span class="c">#</span>
  <span class="c">#    Chain KUBE-SEP-SZHENXPAXVOCHRDA (1 references) &lt;&lt;4. KUBE-SEP-#WEBPOD3&gt;&gt;</span>
  <span class="c">#     pkts bytes target     prot opt in     out     source               destination         </span>
  <span class="c">#        0     0 KUBE-MARK-MASQ  0    --  *      *       10.10.2.3            0.0.0.0/0            /* default/svc-clusterip:svc-webport */</span>
  <span class="c">#        0     0 DNAT       6    --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/svc-clusterip:svc-webport */ tcp to:10.10.2.3:80</span>
        
  <span class="nv">$ </span>iptables <span class="nt">-v</span> <span class="nt">--numeric</span> <span class="nt">--table</span> nat <span class="nt">--list</span> PREROUTING | column <span class="nt">-t</span>
  <span class="c"># =&gt; Chain  PREROUTING  (policy        ACCEPT  777  packets,  46620  bytes)</span>
  <span class="c">#    pkts   bytes       target         prot    opt  in        out    source     destination</span>
  <span class="c">#    777    46620       KUBE-SERVICES  0       --   *         *      0.0.0.0/0  0.0.0.0/0    /*  kubernetes  service  portals  */</span>
  <span class="c">#    0      0           DOCKER_OUTPUT  0       --   *         *      0.0.0.0/0  172.23.0.1</span>
        
  <span class="nv">$ </span>iptables <span class="nt">-v</span> <span class="nt">--numeric</span> <span class="nt">--table</span> nat <span class="nt">--list</span> KUBE-SERVICES | column
  <span class="c"># 바로 아래 룰(rule)에 의해서 서비스(ClusterIP)를 인지하고 처리를 합니다</span>
  <span class="c"># =&gt; Chain  KUBE-SERVICES  (2                         references)</span>
  <span class="c">#    pkts   bytes          target                     prot         opt  in  out  source     destination</span>
  <span class="c">#    0      0              KUBE-SVC-KBDEBIL6IU6WL7RF  6            --   *   *    0.0.0.0/0  10.200.1.96   /*  default/svc-clusterip:svc-webport  cluster  IP          */     tcp   dpt:9000</span>
        
  <span class="nv">$ </span>iptables <span class="nt">-v</span> <span class="nt">--numeric</span> <span class="nt">--table</span> nat <span class="nt">--list</span> KUBE-SVC-KBDEBIL6IU6WL7RF | column
  <span class="c"># =&gt; Chain  KUBE-SVC-KBDEBIL6IU6WL7RF  (1                         references)</span>
  <span class="c">#    pkts   bytes                      target                     prot         opt  in  out  source         destination</span>
  <span class="c">#    0      0                          KUBE-SEP-T7YVH2JOMUTQFUDU  0            --   *   *    0.0.0.0/0      0.0.0.0/0    /*  default/svc-clusterip:svc-webport  -&gt;       10.10.1.4:80  */  statistic  mode      random  probability  0.33333333349</span>
  <span class="c">#    0      0                          KUBE-SEP-SZHENXPAXVOCHRDA  0            --   *   *    0.0.0.0/0      0.0.0.0/0    /*  default/svc-clusterip:svc-webport  -&gt;       10.10.2.3:80  */  statistic  mode      random  probability  0.50000000000</span>
  <span class="c">#    0      0                          KUBE-SEP-X47GKN7LA32LZ4H7  0            --   *   *    0.0.0.0/0      0.0.0.0/0    /*  default/svc-clusterip:svc-webport  -&gt;       10.10.4.3:80  */</span>
        
  <span class="c"># 패킷 전달 수를 확인 하기 위해 watch를 겁니다.</span>
  <span class="nv">$ </span>watch <span class="nt">-d</span> <span class="s1">'iptables -v --numeric --table nat --list KUBE-SVC-KBDEBIL6IU6WL7RF'</span>
        
  <span class="c"># control-plane 에서 테스트 패킷을 보냅니다.</span>
  <span class="nv">$ SVC1</span><span class="o">=</span><span class="si">$(</span>kubectl get svc svc-clusterip <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.spec.clusterIP<span class="o">}</span><span class="si">)</span>
  <span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> net-pod <span class="nt">--</span> zsh <span class="nt">-c</span> <span class="s2">"for i in {1..100};   do curl -s </span><span class="nv">$SVC1</span><span class="s2">:9000 | grep Hostname; sleep 1; done"</span>
</code></pre></div>            </div>

            <p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_17.png" alt="img.png" /></p>
          </li>
          <li>
            <p>iptables에서  카운트가 증가함을 확인 할 수 있습니다.</p>

            <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># SVC-### 에서 랜덤 확률(대략 33%)로 SEP(Service EndPoint)인 각각 파드 IP로 DNAT 됩니다!</span>
<span class="c">## 첫번째 룰에 일치 확률은 33% 이고, 매칭되지 않을 경우 아래 2개 남을때는 룰 일치 확률은 50%가 됩니다. 이것도 매칭되지 않으면 마지막 룰로 100% 일치됩니다</span>
<span class="c">#    Chain KUBE-SVC-KBDEBIL6IU6WL7RF (1 references)</span>
<span class="c">#     pkts bytes target     prot opt in     out     source               destination</span>
<span class="c">#        0     0 KUBE-MARK-MASQ  6    --  *      *      !10.10.0.0/16         10.200.1.96          /* default/svc-clusterip:svc-webport cluster IP */ tcp dpt:9000</span>
<span class="c">#       41  2460 KUBE-SEP-T7YVH2JOMUTQFUDU  0    --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/svc-clusterip:svc-webport -&gt; 10.10.1.4:80 */ statistic mode random probability 0.33333333349</span>
<span class="c">#       47  2820 KUBE-SEP-SZHENXPAXVOCHRDA  0    --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/svc-clusterip:svc-webport -&gt; 10.10.2.3:80 */ statistic mode random probability 0.50000000000</span>
<span class="c">#       45  2700 KUBE-SEP-X47GKN7LA32LZ4H7  0    --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/svc-clusterip:svc-webport -&gt; 10.10.4.3:80 */</span>
      
<span class="c"># $ iptables -v --numeric --table nat --list KUBE-SEP-&lt;각자 값 입력&gt;</span>
<span class="nv">$ </span>iptables <span class="nt">-v</span> <span class="nt">--numeric</span> <span class="nt">--table</span> nat <span class="nt">--list</span> KUBE-SEP-T7YVH2JOMUTQFUDU
<span class="c"># =&gt; Chain  KUBE-SEP-T7YVH2JOMUTQFUDU  (1              references)</span>
<span class="c">#    pkts   bytes                      target          prot         opt  in  out  source     destination</span>
<span class="c">#    49     2940                       DNAT            6            --   *   *    0.0.0.0/0  0.0.0.0/0    /*  default/svc-clusterip:svc-webport  */  tcp  to:10.10.1.4:80</span>
      
<span class="nv">$ </span>iptables <span class="nt">-v</span> <span class="nt">--numeric</span> <span class="nt">--table</span> nat <span class="nt">--list</span> KUBE-SEP-SZHENXPAXVOCHRDA  | column <span class="nt">-t</span>
<span class="c"># =&gt; Chain  KUBE-SEP-SZHENXPAXVOCHRDA  (1              references)</span>
<span class="c">#    pkts   bytes                      target          prot         opt  in  out  source     destination</span>
<span class="c">#    0      0                          KUBE-MARK-MASQ  0            --   *   *    10.10.2.3  0.0.0.0/0    /*  default/svc-clusterip:svc-webport  */</span>
<span class="c">#    56     3360                       DNAT            6            --   *   *    0.0.0.0/0  0.0.0.0/0    /*  default/svc-clusterip:svc-webport  */  tcp  to:10.10.2.3:80</span>
      
<span class="nv">$ </span>iptables <span class="nt">-v</span> <span class="nt">--numeric</span> <span class="nt">--table</span> nat <span class="nt">--list</span> KUBE-SEP-X47GKN7LA32LZ4H7  | column <span class="nt">-t</span>
<span class="c"># =&gt; Chain  KUBE-SEP-X47GKN7LA32LZ4H7  (1              references)</span>
<span class="c">#    pkts   bytes                      target          prot         opt  in  out  source     destination</span>
<span class="c">#    0      0                          KUBE-MARK-MASQ  0            --   *   *    10.10.4.3  0.0.0.0/0    /*  default/svc-clusterip:svc-webport  */</span>
<span class="c">#    48     2880                       DNAT            6            --   *   *    0.0.0.0/0  0.0.0.0/0    /*  default/svc-clusterip:svc-webport  */  tcp  to:10.10.4.3:80</span>
      
<span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">--zero</span>
<span class="nv">$ </span>iptables <span class="nt">-v</span> <span class="nt">--numeric</span> <span class="nt">--table</span> nat <span class="nt">--list</span> POSTROUTING | column<span class="p">;</span> <span class="nb">echo</span> <span class="p">;</span> iptables <span class="nt">-v</span> <span class="nt">--numeric</span> <span class="nt">--table</span> nat <span class="nt">--list</span> KUBE-POSTROUTING | column
<span class="nv">$ </span>watch <span class="nt">-d</span> <span class="s1">'iptables -v --numeric --table nat --list POSTROUTING; echo ; iptables -v --numeric --table nat --list KUBE-POSTROUTING'</span>
<span class="c"># POSTROUTE(nat) : 0x4000 마킹 되어 있지 않으니 RETURN 되고 그냥 빠져나가서 SNAT 되지 않는다!</span>
<span class="c"># =&gt; Chain  POSTROUTING  (policy             ACCEPT  0    packets,  0    bytes)</span>
<span class="c">#    pkts   bytes        target              prot    opt  in        out  source     destination</span>
<span class="c">#    0      0            KUBE-POSTROUTING    0       --   *         *    0.0.0.0/0  0.0.0.0/0    /*        kubernetes  postrouting  rules   */</span>
<span class="c">#    0      0            DOCKER_POSTROUTING  0       --   *         *    0.0.0.0/0  172.23.0.1</span>
<span class="c">#    0      0            KIND-MASQ-AGENT     0       --   *         *    0.0.0.0/0  0.0.0.0/0    ADDRTYPE  match       dst-type     !LOCAL  /*  kind-masq-agent:  ensure  nat  POSTROUTING  directs  all  non-LOCAL  destination  traffic  to  our  custom  KIND-MASQ-AGENT  chain  */</span>
<span class="c"># =&gt; Chain  KUBE-POSTROUTING  (1          references)</span>
<span class="c">#    pkts   bytes             target      prot         opt  in  out  source     destination</span>
<span class="c">#    0      0                 RETURN      0            --   *   *    0.0.0.0/0  0.0.0.0/0    mark  match       !        0x4000/0x4000</span>
<span class="c">#    0      0                 MARK        0            --   *   *    0.0.0.0/0  0.0.0.0/0    MARK  xor         0x4000</span>
<span class="c">#    0      0                 MASQUERADE  0            --   *   *    0.0.0.0/0  0.0.0.0/0    /*    kubernetes  service  traffic        requiring  SNAT  */  random-fully</span>
      
<span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span> | <span class="nb">grep </span>KUBE-POSTROUTING
<span class="c"># =&gt; -N KUBE-POSTROUTING</span>
<span class="c">#    -A POSTROUTING -m comment --comment "kubernetes postrouting rules" -j KUBE-POSTROUTING</span>
<span class="c">#    -A KUBE-POSTROUTING -m mark ! --mark 0x4000/0x4000 -j RETURN</span>
<span class="c">#    -A KUBE-POSTROUTING -j MARK --set-xmark 0x4000/0x0</span>
<span class="c">#    -A KUBE-POSTROUTING -m comment --comment "kubernetes service traffic requiring SNAT" -j MASQUERADE --random-fully</span>
      
<span class="nv">$ </span><span class="nb">exit</span>
<span class="nt">----------------------------------------</span>
      
<span class="c"># 위 서비스 생성 시 kube-proxy 에 의해서 iptables 규칙이 모든 노드에 추가됨을 한번 더 확인</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane iptables <span class="nt">-v</span> <span class="nt">--numeric</span> <span class="nt">--table</span> nat <span class="nt">--list</span> KUBE-SVC-KBDEBIL6IU6WL7RF
<span class="c"># =&gt; Chain KUBE-SVC-KBDEBIL6IU6WL7RF (1 references)</span>
<span class="c">#     pkts bytes target     prot opt in     out     source               destination         </span>
<span class="c">#        0     0 KUBE-MARK-MASQ  6    --  *      *      !10.10.0.0/16         10.200.1.96          /* default/svc-clusterip:svc-webport cluster IP */ tcp dpt:9000</span>
<span class="c">#        0     0 KUBE-SEP-T7YVH2JOMUTQFUDU  0    --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/svc-clusterip:svc-webport -&gt; 10.10.1.4:80 */ statistic mode random probability 0.33333333349</span>
<span class="c">#        0     0 KUBE-SEP-SZHENXPAXVOCHRDA  0    --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/svc-clusterip:svc-webport -&gt; 10.10.2.3:80 */ statistic mode random probability 0.50000000000</span>
<span class="c">#        0     0 KUBE-SEP-X47GKN7LA32LZ4H7  0    --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/svc-clusterip:svc-webport -&gt; 10.10.4.3:80 */</span>
      
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>control-plane worker worker2 worker3<span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node myk8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-<span class="nv">$i</span> iptables <span class="nt">-v</span> <span class="nt">--numeric</span> <span class="nt">--table</span> nat <span class="nt">--list</span> KUBE-SVC-KBDEBIL6IU6WL7RF<span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node myk8s-control-plane &lt;&lt;</span>
<span class="c">#    Chain KUBE-SVC-KBDEBIL6IU6WL7RF (1 references)</span>
<span class="c">#     pkts bytes target     prot opt in     out     source               destination         </span>
<span class="c">#        0     0 KUBE-MARK-MASQ  6    --  *      *      !10.10.0.0/16         10.200.1.96          /* default/svc-clusterip:svc-webport cluster IP */ tcp dpt:9000</span>
<span class="c">#        0     0 KUBE-SEP-T7YVH2JOMUTQFUDU  0    --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/svc-clusterip:svc-webport -&gt; 10.10.1.4:80 */ statistic mode random probability 0.33333333349</span>
<span class="c">#        0     0 KUBE-SEP-SZHENXPAXVOCHRDA  0    --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/svc-clusterip:svc-webport -&gt; 10.10.2.3:80 */ statistic mode random probability 0.50000000000</span>
<span class="c">#        0     0 KUBE-SEP-X47GKN7LA32LZ4H7  0    --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/svc-clusterip:svc-webport -&gt; 10.10.4.3:80 */</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node myk8s-worker &lt;&lt;</span>
<span class="c">#    Chain KUBE-SVC-KBDEBIL6IU6WL7RF (1 references)</span>
<span class="c">#     pkts bytes target     prot opt in     out     source               destination         </span>
<span class="c">#        0     0 KUBE-MARK-MASQ  6    --  *      *      !10.10.0.0/16         10.200.1.96          /* default/svc-clusterip:svc-webport cluster IP */ tcp dpt:9000</span>
<span class="c">#        0     0 KUBE-SEP-T7YVH2JOMUTQFUDU  0    --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/svc-clusterip:svc-webport -&gt; 10.10.1.4:80 */ statistic mode random probability 0.33333333349</span>
<span class="c">#        0     0 KUBE-SEP-SZHENXPAXVOCHRDA  0    --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/svc-clusterip:svc-webport -&gt; 10.10.2.3:80 */ statistic mode random probability 0.50000000000</span>
<span class="c">#        0     0 KUBE-SEP-X47GKN7LA32LZ4H7  0    --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/svc-clusterip:svc-webport -&gt; 10.10.4.3:80 */</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node myk8s-worker2 &lt;&lt;</span>
<span class="c">#    Chain KUBE-SVC-KBDEBIL6IU6WL7RF (1 references)</span>
<span class="c">#     pkts bytes target     prot opt in     out     source               destination         </span>
<span class="c">#        0     0 KUBE-MARK-MASQ  6    --  *      *      !10.10.0.0/16         10.200.1.96          /* default/svc-clusterip:svc-webport cluster IP */ tcp dpt:9000</span>
<span class="c">#        0     0 KUBE-SEP-T7YVH2JOMUTQFUDU  0    --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/svc-clusterip:svc-webport -&gt; 10.10.1.4:80 */ statistic mode random probability 0.33333333349</span>
<span class="c">#        0     0 KUBE-SEP-SZHENXPAXVOCHRDA  0    --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/svc-clusterip:svc-webport -&gt; 10.10.2.3:80 */ statistic mode random probability 0.50000000000</span>
<span class="c">#        0     0 KUBE-SEP-X47GKN7LA32LZ4H7  0    --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/svc-clusterip:svc-webport -&gt; 10.10.4.3:80 */</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node myk8s-worker3 &lt;&lt;</span>
<span class="c">#    Chain KUBE-SVC-KBDEBIL6IU6WL7RF (1 references)</span>
<span class="c">#     pkts bytes target     prot opt in     out     source               destination         </span>
<span class="c">#        0     0 KUBE-MARK-MASQ  6    --  *      *      !10.10.0.0/16         10.200.1.96          /* default/svc-clusterip:svc-webport cluster IP */ tcp dpt:9000</span>
<span class="c">#        0     0 KUBE-SEP-T7YVH2JOMUTQFUDU  0    --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/svc-clusterip:svc-webport -&gt; 10.10.1.4:80 */ statistic mode random probability 0.33333333349</span>
<span class="c">#        0     0 KUBE-SEP-SZHENXPAXVOCHRDA  0    --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/svc-clusterip:svc-webport -&gt; 10.10.2.3:80 */ statistic mode random probability 0.50000000000</span>
<span class="c">#        0     0 KUBE-SEP-X47GKN7LA32LZ4H7  0    --  *      *       0.0.0.0/0            0.0.0.0/0            /* default/svc-clusterip:svc-webport -&gt; 10.10.4.3:80 */</span>
</code></pre></div>            </div>
          </li>
          <li>
            <p>동일한 iptables 룰이 각 노드에 있는 것을 확인할 수 있습니다.</p>
          </li>
        </ul>
      </li>
      <li>파드 1개에 장애를 발생시켜서 장애시 동작을 확인해보겠습니다.
        <ul>
          <li>
            <p>동작 확인을 위한 모니터링</p>

            <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c"># 터미널1 &gt;&gt; ENDPOINTS 변화를 잘 확인해보자!</span>
  <span class="nv">$ </span>watch <span class="nt">-d</span> <span class="s1">'kubectl get pod -owide;echo; kubectl get svc,ep svc-clusterip;echo; kubectl get endpointslices -l kubernetes.io/service-name=svc-clusterip'</span>
        
  <span class="c"># 터미널2</span>
  <span class="nv">$ SVC1</span><span class="o">=</span><span class="si">$(</span>kubectl get svc svc-clusterip <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">={</span>.spec.clusterIP<span class="o">}</span><span class="si">)</span>
  <span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> net-pod <span class="nt">--</span> zsh <span class="nt">-c</span> <span class="s2">"while true; do curl -s --connect-timeout 1 </span><span class="nv">$SVC1</span><span class="s2">:9000 | egrep 'Hostname|IP: 10'; date '+%Y-%m-%d %H:%M:%S' ; echo ;  sleep 1; done"</span>
  <span class="c"># 혹은</span>
  <span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> net-pod <span class="nt">--</span> zsh <span class="nt">-c</span> <span class="s2">"for i in {1..100};  do curl -s </span><span class="nv">$SVC1</span><span class="s2">:9000 | grep Hostname; done | sort | uniq -c | sort -nr"</span>
</code></pre></div>            </div>
          </li>
          <li>
            <p>파드 1개 삭제 후 확인</p>

            <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c"># (방안1) 파드3번 삭제 &gt;&gt; 서비스의 엔드포인트가 어떻게 변경되는지 확인 하자!, 지속적인 curl 접속 결과 확인!, for 문 실행 시 결과 확인!, 절체 시간(순단) 확인!</span>
  <span class="nv">$ </span>kubectl delete pod webpod3
        
  <span class="c"># (방안1) 결과 확인 후 다시 파드 3번 생성 &gt;&gt; 서비스 디스커버리!</span>
  <span class="nv">$ </span>kubectl apply <span class="nt">-f</span> 3pod.yaml
        
  <span class="nt">---------------------------------</span>
  <span class="c"># (방안2) 파드3번에 레이블 삭제</span>
  <span class="nv">$ </span>kubectl get pod <span class="nt">--show-labels</span>
        
  <span class="c">## 레이블(라벨)의 키값 바로 뒤에 하이픈(-) 입력 시 해당 레이블 삭제됨! &gt;&gt; 레이블과 셀렉터는 쿠버네티스 환경에서 매우 많이 활용된다!</span>
  <span class="nv">$ </span>kubectl label pod webpod3 app-
  <span class="nv">$ </span>kubectl get pod <span class="nt">--show-labels</span>
        
  <span class="c"># (방안2) 결과 확인 후 파드3번에 다시 레이블 생성</span>
  <span class="nv">$ </span>kubectl label pod webpod3 <span class="nv">app</span><span class="o">=</span>webpod
</code></pre></div>            </div>

            <ul>
              <li>
                <p>파드 삭제 전</p>

                <p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_18.png" alt="img.png" /></p>
              </li>
              <li>
                <p>파드 삭제 후</p>

                <p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_19.png" alt="img.png" /></p>
              </li>
              <li>
                <p>파드 다시 생성 후</p>

                <p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_20.png" alt="img.png" /></p>
              </li>
              <li>
                <p>레이블 삭제 후</p>

                <p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_21.png" alt="img.png" /></p>
              </li>
              <li>
                <p>레이블 복구 후</p>

                <p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_22.png" alt="img.png" /></p>
              </li>
            </ul>
          </li>
          <li>
            <p>파드가 삭제되고 복구 됨에 따라 서비스 엔드포인트에서 삭제되고, label selector 에 따라서도 엔드포인트에서 삭제되고 복구됨을 확인할 수 있었습니다.</p>
          </li>
        </ul>
      </li>
      <li>sessionAffinity: ClientIP
        <ul>
          <li><code class="language-plaintext highlighter-rouge">sessionAffinity: ClientIP</code> : 클라이언트가 접속한 목적지(파드)에 고정적인 접속을 지원하게 할 수 있습니다.</li>
          <li>
            <p>기본적으로 서비스는 파드에 랜덤으로 부하를 분산하지만 <code class="language-plaintext highlighter-rouge">sessionAffinity: ClientIP</code>를 통해 동일한 파드에 접속하도록 강제 할 수 있습니다.</p>

            <p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_23.png" alt="img.png" /></p>
          </li>
          <li>
            <p>설정 및 파드 접속 확인</p>

            <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c"># 기본 정보 확인</span>
  <span class="nv">$ </span>kubectl get svc svc-clusterip <span class="nt">-o</span> yaml
  <span class="nv">$ </span>kubectl get svc svc-clusterip <span class="nt">-o</span> yaml | <span class="nb">grep </span>sessionAffinity
  <span class="c"># =&gt;   sessionAffinity: None</span>
        
  <span class="c"># 반복 접속</span>
  <span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> net-pod <span class="nt">--</span> zsh <span class="nt">-c</span> <span class="s2">"while true; do curl -s --connect-timeout 1 </span><span class="nv">$SVC1</span><span class="s2">:9000 | egrep 'Hostname|IP: 10|Remote'; date '+%Y-%m-%d %H:%M:%S' ; echo ;  sleep 1; done"</span>
  <span class="c"># =&gt; Hostname: webpod2</span>
  <span class="c">#    IP: 10.10.1.4</span>
  <span class="c">#    RemoteAddr: 10.10.0.7:57246</span>
  <span class="c">#    2024-09-01 12:25:49</span>
  <span class="c">#    </span>
  <span class="c">#    Hostname: webpod1</span>
  <span class="c">#    IP: 10.10.4.3</span>
  <span class="c">#    RemoteAddr: 10.10.0.7:57250</span>
  <span class="c">#    2024-09-01 12:25:50</span>
  <span class="c">#    </span>
  <span class="c">#    Hostname: webpod3</span>
  <span class="c">#    IP: 10.10.2.6</span>
  <span class="c">#    RemoteAddr: 10.10.0.7:57252</span>
  <span class="c">#    2024-09-01 12:25:51</span>
        
  <span class="c"># 현재는 랜덤으로 접속 됩니다.</span>
        
  <span class="c"># sessionAffinity: ClientIP 설정 변경</span>
  <span class="nv">$ </span>kubectl patch svc svc-clusterip <span class="nt">-p</span> <span class="s1">'{"spec":{"sessionAffinity":"ClientIP"}}'</span>
  <span class="c"># =&gt; service/svc-clusterip patched</span>
  <span class="c"># 혹은</span>
  <span class="c">## $ kubectl get svc svc-clusterip -o yaml | sed -e "s/sessionAffinity: None/sessionAffinity: ClientIP/" | kubectl apply -f -</span>
        
  <span class="c">#</span>
  <span class="nv">$ </span>kubectl get svc svc-clusterip <span class="nt">-o</span> yaml
  <span class="c"># =&gt; ...</span>
  <span class="c">#      sessionAffinity: ClientIP</span>
  <span class="c">#      sessionAffinityConfig:</span>
  <span class="c">#        clientIP:</span>
  <span class="c">#          timeoutSeconds: 10800</span>
  <span class="c">#    ...</span>
        
  <span class="c"># 클라이언트(TestPod) Shell 실행</span>
  <span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> net-pod <span class="nt">--</span> zsh <span class="nt">-c</span> <span class="s2">"for i in {1..100};  do curl -s </span><span class="nv">$SVC1</span><span class="s2">:9000 | grep Hostname; done | sort | uniq -c | sort -nr"</span>
  <span class="c"># =&gt; 100 Hostname: webpod2</span>
  <span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> net-pod <span class="nt">--</span> zsh <span class="nt">-c</span> <span class="s2">"for i in {1..1000}; do curl -s </span><span class="nv">$SVC1</span><span class="s2">:9000 | grep Hostname; done | sort | uniq -c | sort -nr"</span>
  <span class="c"># =&gt; 1000 Hostname: webpod2</span>
</code></pre></div>            </div>

            <ul>
              <li>sessionAffinity: ClientIP를 하면 spec.sessionAffinityConfig.clientIP.timeoutSeconds 시간동안 서비스를 통해 접속 되는 파드가 고정됨을 확인할 수 있었습니다.</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>이상과 같이 ClusterIP 타입의 서비스를 확인해보았습니다.</li>
  <li>ClusterIP 타입의 서비스는 다음과 같은 단점이 있다고 합니다.
    <ul>
      <li>클러스터 외부에서는 서비스(ClusterIP)로 접속이 불가능합니다. ⇒ <strong>NodePort</strong> 타입으로 외부에서 접속 가능</li>
      <li>IPtables 는 파드에 대한 헬스체크 기능이 없어서 문제 있는 파드에 연결이 되는 경우가 있습니다. ⇒ 서비스 사용, 파드에 Readiness Probe 설정으로 파드 문제 시 서비스의 엔드포인트에서 제거되게 하자! ← 이 정도면 충분한가? 혹시 부족한 점이 없을까?</li>
      <li>서비스에 연동된 파드 갯수 퍼센트(%)로 <strong>랜덤 분산</strong> 방식, <strong>세션어피니티</strong> 이외에 <strong>다른 분산 방식 불가능합니다.</strong> ⇒ <strong>IPVS</strong> 경우 다양한 분산 방식(알고리즘) 가능
        <ul>
          <li>목적지 파드 다수가 있는 환경에서, 출발지 파드와 목적지 파드가 동일한 노드에 배치되어 있어도, 랜덤 분산으로 다른 노드에 목적지 파드로 연결 가능</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="nodeport-실습">NodePort 실습</h4>

<ul>
  <li>NodePort는 ClusterIP와 다르게 클러스터 외부에서도 접속 할 수 있습니다.</li>
  <li>컨트롤플레인을 포함한 모든 노드에 iptables rule이 적용되므로, 모든 노드에 NodePort로 접속시 iptables rule에 의해서 분산 접속이 됩니다.</li>
  <li>Node의 모든 Local IP (loopback을 포함한 각 호스트의 interface의 IP) 사용 가능하고 Local IP 지정도 가능합니다.</li>
  <li>쿠버네티스의 NodePort는 기본 30000~32767 포트에서 랜덤으로 지정됩니다.
    <ul>
      <li>
        <p>랜덤 포트 범위를 바꾸려면 다음과 같이  <code class="language-plaintext highlighter-rouge">/etc/kubernetes/manifests/kube-apiserver.yaml</code> 파일을 수정하여 kube-apiserver 의 파라메터에 <code class="language-plaintext highlighter-rouge">--service-node-port-range=시작포트-종료포트</code>를 변경하면됩니다. <a href="https://blog.frec.kr/cloud/modify_nodeport_range/">참고</a></p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c"># /etc/kubernetes/manifests/kube-apiserver.yaml</span>
      
  ...
  spec:
    containers:
    - <span class="nb">command</span>:
      - kube-apiserver
      - <span class="nt">--authorization-mode</span><span class="o">=</span>Node,RBAC
      ...
      - <span class="nt">--service-node-port-range</span><span class="o">=</span>30000-50000
  ...
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li>실습 구성
    <ul>
      <li>
        <p>목적지(backend) 디플로이먼트 파일 생성 : echo-deploy.yml</p>

        <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="na">apiVersion</span><span class="pi">:</span> <span class="s">apps/v1</span>
  <span class="na">kind</span><span class="pi">:</span> <span class="s">Deployment</span>
  <span class="na">metadata</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">deploy-echo</span>
  <span class="na">spec</span><span class="pi">:</span>
    <span class="na">replicas</span><span class="pi">:</span> <span class="m">3</span>
    <span class="na">selector</span><span class="pi">:</span>
      <span class="na">matchLabels</span><span class="pi">:</span>
        <span class="na">app</span><span class="pi">:</span> <span class="s">deploy-websrv</span>
    <span class="na">template</span><span class="pi">:</span>
      <span class="na">metadata</span><span class="pi">:</span>
        <span class="na">labels</span><span class="pi">:</span>
          <span class="na">app</span><span class="pi">:</span> <span class="s">deploy-websrv</span>
      <span class="na">spec</span><span class="pi">:</span>
        <span class="na">terminationGracePeriodSeconds</span><span class="pi">:</span> <span class="m">0</span>
        <span class="na">containers</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">kans-websrv</span>
          <span class="na">image</span><span class="pi">:</span> <span class="s">mendhak/http-https-echo</span>
          <span class="na">ports</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="na">containerPort</span><span class="pi">:</span> <span class="m">8080</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p>서비스(NodePort) 파일 생성 : svc-nodeport.yml</p>

        <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
  <span class="na">kind</span><span class="pi">:</span> <span class="err">*</span><span class="nv">*Service</span><span class="err">**</span>
  <span class="na">metadata</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">svc-nodeport</span>
  <span class="na">spec</span><span class="pi">:</span>
    <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">svc-webport</span>
        <span class="na">port</span><span class="pi">:</span> <span class="m">9000</span>        <span class="c1"># 서비스 ClusterIP 에 접속 시 사용하는 포트 port 를 의미</span>
        <span class="na">targetPort</span><span class="pi">:</span> <span class="m">8080</span>  <span class="c1"># 타킷 targetPort 는 서비스를 통해서 목적지 파드로 접속 시 해당 파드로 접속하는 포트를 의미</span>
    <span class="na">selector</span><span class="pi">:</span>
      <span class="na">app</span><span class="pi">:</span> <span class="s">deploy-websrv</span>
    <span class="na">**type</span><span class="pi">:</span> <span class="s">NodePort**</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p>생성 및 확인</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c"># 생성</span>
  <span class="nv">$ </span>kubectl apply <span class="nt">-f</span> echo-deploy.yml,svc-nodeport.yml
  <span class="c"># =&gt; deployment.apps/deploy-echo created</span>
  <span class="c">#    service/svc-nodeport created</span>
      
  <span class="c"># 모니터링</span>
  <span class="nv">$ </span>watch <span class="nt">-d</span> <span class="s1">'kubectl get pod -owide;echo; kubectl get svc,ep svc-nodeport'</span>
      
  <span class="c"># 확인</span>
  <span class="nv">$ </span>kubectl get deploy,pod <span class="nt">-o</span> wide
  <span class="c"># =&gt; NAME                          READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS    IMAGES                    SELECTOR</span>
  <span class="c">#    deployment.apps/deploy-echo   3/3     3            3           49s   kans-websrv   mendhak/http-https-echo   app=deploy-websrv</span>
  <span class="c">#    </span>
  <span class="c">#    NAME                               READY   STATUS    RESTARTS   AGE    IP          NODE                  NOMINATED NODE   READINESS GATES</span>
  <span class="c">#    pod/deploy-echo-5c689d5454-dxf2t   1/1     Running   0          49s    10.10.4.4   myk8s-worker          &lt;none&gt;           &lt;none&gt;</span>
  <span class="c">#    pod/deploy-echo-5c689d5454-rbgcp   1/1     Running   0          49s    10.10.1.5   myk8s-worker2         &lt;none&gt;           &lt;none&gt;</span>
  <span class="c">#    pod/deploy-echo-5c689d5454-wppr8   1/1     Running   0          49s    10.10.2.7   myk8s-worker3         &lt;none&gt;           &lt;none&gt;</span>
      
  <span class="c"># 아래 31791은 서비스(NodePort) 정보!</span>
  <span class="nv">$ </span>kubectl get svc svc-nodeport
  <span class="c"># =&gt; NAME           TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE</span>
  <span class="c">#    svc-nodeport   NodePort   10.200.1.169   &lt;none&gt;        9000:31791/TCP   69s</span>
      
  <span class="nv">$ </span>kubectl get endpoints svc-nodeport
  <span class="c"># =&gt; NAME           ENDPOINTS                                      AGE</span>
  <span class="c">#    svc-nodeport   10.10.1.5:8080,10.10.2.7:8080,10.10.4.4:8080   85s</span>
      
  <span class="c"># Port , TargetPort , NodePort 각각의 차이점의 의미를 알자!</span>
  <span class="nv">$ </span>kubectl describe svc svc-nodeport
  <span class="c"># =&gt; Name:                     svc-nodeport</span>
  <span class="c">#    Namespace:                default</span>
  <span class="c">#    Labels:                   &lt;none&gt;</span>
  <span class="c">#    Annotations:              &lt;none&gt;</span>
  <span class="c">#    Selector:                 app=deploy-websrv</span>
  <span class="c">#    Type:                     NodePort</span>
  <span class="c">#    IP Family Policy:         SingleStack</span>
  <span class="c">#    IP Families:              IPv4</span>
  <span class="c">#    IP:                       10.200.1.169</span>
  <span class="c">#    IPs:                      10.200.1.169</span>
  <span class="c">#    Port:                     svc-webport  9000/TCP     &lt;&lt;ClusterIP와 동일하게 동작하는 클러스터 내부에서 사용하는 포트&gt;&gt;</span>
  <span class="c">#    TargetPort:               8080/TCP                  &lt;&lt;파드의 컨테이너의 포트&gt;&gt;</span>
  <span class="c">#    NodePort:                 svc-webport  31791/TCP    &lt;&lt;각 Node에서 Listening 하는 nodePort&gt;&gt;</span>
  <span class="c">#    Endpoints:                10.10.1.5:8080,10.10.2.7:8080,10.10.4.4:8080    &lt;&lt;Port Forwarding 대상이 되는 파드의 엔드포인트 파드IP:파드Port&gt;&gt;</span>
  <span class="c">#    Session Affinity:         None</span>
  <span class="c">#    External Traffic Policy:  Cluster &lt;&lt;부하 분산방식&gt;&gt;</span>
  <span class="c">#    Events:                   &lt;none&gt;</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li>2.3. 서비스 접속 확인
    <ul>
      <li>
        <p>NodePort의 서비스 접속을 통한 통신의 흐름</p>

        <p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_24.png" alt="img.png" /></p>

        <ul>
          <li>Client 가상 머신(192.168.10.200)에서 컨트롤 플레인 IP(192.168.10.10)의 nodePort 접속을 시도합니다.</li>
          <li>nodePort는 서비스(NodePort) 생성시에 할당된 랜덤포트가 사용 됩니다.</li>
          <li>컨트롤 플레인의 iptables의 NAT 테이블의 규칙과 매칭되어 목적지 IP와 목적지 Port는 변환 됩니다. 목적지 IP는 app=deploy-websrv 레이블을 가지고 있는 파드 3개가 대상이 되며, 랜덤 부하분산이 선택됩니다.</li>
        </ul>
      </li>
      <li>
        <p>실습을 통해 위의 과정을 확인해보겠습니다. 단 현재 실습환경에서는 컨트롤 플레인에는 파드가 없으므로 위의 설명과는 다르게 워커노드의 파드를 접속하는것으로 실습하겠습니다.</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c"># NodePort 확인 : 아래 NodePort 는 범위내 랜덤 할당으로 실습 환경마다 다릅니다</span>
  <span class="nv">$ </span>kubectl get service svc-nodeport <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.spec.ports[0].nodePort}'</span>
  <span class="c"># =&gt; 31791</span>
      
  <span class="c"># NodePort 를 변수에 지정</span>
  <span class="nv">$ NPORT</span><span class="o">=</span><span class="si">$(</span>kubectl get service svc-nodeport <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.spec.ports[0].nodePort}'</span><span class="si">)</span>
  <span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$NPORT</span>
  <span class="c"># =&gt; 31791</span>
      
  <span class="c"># 현재 k8s 버전에서는 포트 Listen 되지 않고, iptables rules 처리됨</span>
  <span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>control-plane worker worker2 worker3<span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node myk8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-<span class="nv">$i</span> ss <span class="nt">-tlnp</span><span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
  <span class="c"># =&gt; &gt;&gt; node myk8s-control-plane &lt;&lt;</span>
  <span class="c">#    State  Recv-Q Send-Q Local Address:Port  Peer Address:PortProcess                                  </span>
  <span class="c">#    LISTEN 0      4096       127.0.0.1:2381       0.0.0.0:*    users:(("etcd",pid=710,fd=15))          </span>
  <span class="c">#    ... nodePort인 31791를 LISTEN하는 건이 없음</span>
  <span class="c">#</span>
  <span class="c">#    &gt;&gt; node myk8s-worker &lt;&lt;</span>
  <span class="c">#    State  Recv-Q Send-Q Local Address:Port  Peer Address:PortProcess                              </span>
  <span class="c">#    LISTEN 0      4096      127.0.0.11:35033      0.0.0.0:*                                        </span>
  <span class="c">#    ... nodePort인 31791를 LISTEN하는 건이 없음</span>
  <span class="c">#    </span>
  <span class="c">#    &gt;&gt; node myk8s-worker2 &lt;&lt;</span>
  <span class="c">#    State  Recv-Q Send-Q Local Address:Port  Peer Address:PortProcess                              </span>
  <span class="c">#    LISTEN 0      4096      127.0.0.11:45927      0.0.0.0:*                                        </span>
  <span class="c">#    ... nodePort인 31791를 LISTEN하는 건이 없음</span>
  <span class="c">#    </span>
  <span class="c">#    &gt;&gt; node myk8s-worker3 &lt;&lt;</span>
  <span class="c">#    State  Recv-Q Send-Q Local Address:Port  Peer Address:PortProcess                              </span>
  <span class="c">#    LISTEN 0      4096       127.0.0.1:10248      0.0.0.0:*    users:(("kubelet",pid=262,fd=19))   </span>
  <span class="c">#    ... nodePort인 31791를 LISTEN하는 건이 없음</span>
      
  <span class="c">## (참고) 아래처럼 예전 k8s 환경에서 Service(NodePort) 생성 시, TCP Port Listen 되었었음</span>
  <span class="c"># $ root@k8s-m:~# ss -4tlnp | egrep "(Process|$NPORT)"</span>
  <span class="c"># State     Recv-Q    Send-Q        Local Address:Port        Peer Address:Port   Process</span>
  <span class="c"># LISTEN    0         4096                0.0.0.0:30466            0.0.0.0:*       users:(("kube-proxy",pid=8661,fd=10))</span>
      
  <span class="c"># 파드 로그 실시간 확인 (웹 파드에 접속자의 IP가 출력)</span>
  <span class="nv">$ </span>kubectl logs <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>deploy-websrv <span class="nt">-f</span>
  <span class="c"># =&gt; Listening on ports 8080 for http, and 8443 for https.</span>
  <span class="c">#    ...</span>
  <span class="c">#    ::ffff:172.23.0.2 - - [26/Sep/2024:04:35:00 +0000] "GET / HTTP/1.1" 200 396 "-" "curl/7.88.1"</span>
  <span class="c">#    ...</span>
      
  <span class="c"># 외부 클라이언트(mypc 컨테이너)에서 접속 시도를 해보자</span>
      
  <span class="c"># 노드의 IP와 NodePort를 변수에 지정</span>
  <span class="c">## CNODE=&lt;컨트롤플레인노드의 IP주소&gt;</span>
  <span class="c">## NODE1=&lt;노드1의 IP주소&gt;</span>
  <span class="c">## NODE2=&lt;노드2의 IP주소&gt;</span>
  <span class="c">## NODE3=&lt;노드3의 IP주소&gt;</span>
  <span class="nv">$ CNODE</span><span class="o">=</span>172.23.0.2
  <span class="nv">$ NODE1</span><span class="o">=</span>172.23.0.4
  <span class="nv">$ NODE2</span><span class="o">=</span>172.23.0.5
  <span class="nv">$ NODE3</span><span class="o">=</span>172.23.0.3
      
  <span class="nv">$ NPORT</span><span class="o">=</span><span class="si">$(</span>kubectl get service svc-nodeport <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.spec.ports[0].nodePort}'</span><span class="si">)</span>
  <span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$NPORT</span>
      
  <span class="c"># 서비스(NodePort) 부하분산 접속 확인</span>
  <span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc curl <span class="nt">-s</span> <span class="nv">$CNODE</span>:<span class="nv">$NPORT</span> | jq <span class="c"># headers.host 주소는 왜 그런거죠?</span>
  <span class="c"># =&gt; {</span>
  <span class="c">#      "path": "/",</span>
  <span class="c">#      "headers": {</span>
  <span class="c">#        "host": "172.23.0.2:31791",  &lt;&lt;여기의 headers.host는 요청하는 url의 주소인데, 우리가 $CNODE(컨트롤플레인의 IP)의 url로 접속했기 때문입니다.&gt;&gt;</span>
  <span class="c">#        "user-agent": "curl/8.7.1",</span>
  <span class="c">#        "accept": "*/*"</span>
  <span class="c">#      },</span>
  <span class="c">#      "method": "GET",</span>
  <span class="c">#      "body": "",</span>
  <span class="c">#      "fresh": false,</span>
  <span class="c">#      "hostname": "172.23.0.2",   &lt;&lt;이 hostname과&gt;&gt;</span>
  <span class="c">#      "ip": "::ffff:172.23.0.2",  &lt;&lt;이 ip는 접속하는 클라이언트의 ip인데 부하분산 과정에서 목적지가 Local Pod가 아닌 경우 Node IP로 POSTROUTING(SNAT) 되기 때문입니다.&gt;&gt;</span>
  <span class="c">#      "ips": [],</span>
  <span class="c">#      "protocol": "http",</span>
  <span class="c">#      "query": {},</span>
  <span class="c">#      "subdomains": [],</span>
  <span class="c">#      "xhr": false,</span>
  <span class="c">#      "os": {</span>
  <span class="c">#        "hostname": "deploy-echo-5c689d5454-dxf2t"</span>
  <span class="c">#      },</span>
  <span class="c">#      "connection": {}</span>
  <span class="c">#    }</span>
      
  <span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="nv">$CNODE</span> <span class="nv">$NODE1</span> <span class="nv">$NODE2</span> <span class="nv">$NODE3</span> <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> mypc curl <span class="nt">-s</span> <span class="nv">$i</span>:<span class="nv">$NPORT</span><span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
  <span class="c"># =&gt; &gt;&gt; node 172.23.0.2 &lt;&lt;</span>
  <span class="c">#    {</span>
  <span class="c">#      "headers": {</span>
  <span class="c">#        "host": "172.23.0.2:31791",</span>
  <span class="c">#        ...</span>
  <span class="c">#      },</span>
  <span class="c">#      ...</span>
  <span class="c">#      "hostname": "172.23.0.2",</span>
  <span class="c">#      "ip": "::ffff:172.23.0.2",</span>
  <span class="c">#      ...</span>
  <span class="c">#      "os": {</span>
  <span class="c">#        "hostname": "deploy-echo-5c689d5454-dxf2t" </span>
  <span class="c">#      }</span>
  <span class="c">#    }</span>
  <span class="c">#    &gt;&gt; node 172.23.0.4 &lt;&lt;</span>
  <span class="c">#    {</span>
  <span class="c">#      "headers": {</span>
  <span class="c">#        "host": "172.23.0.4:31791",</span>
  <span class="c">#        ...</span>
  <span class="c">#      },</span>
  <span class="c">#      ...</span>
  <span class="c">#      "hostname": "172.23.0.4",</span>
  <span class="c">#      "ip": "::ffff:10.10.4.1",</span>
  <span class="c">#      ...</span>
  <span class="c">#      "os": {</span>
  <span class="c">#        "hostname": "deploy-echo-5c689d5454-dxf2t"</span>
  <span class="c">#      }</span>
  <span class="c">#    }</span>
  <span class="c">#    &gt;&gt; node 172.23.0.5 &lt;&lt;</span>
  <span class="c">#    {</span>
  <span class="c">#      "headers": {</span>
  <span class="c">#        "host": "172.23.0.5:31791",</span>
  <span class="c">#        ...</span>
  <span class="c">#      },</span>
  <span class="c">#      ...</span>
  <span class="c">#      "hostname": "172.23.0.5",</span>
  <span class="c">#      "ip": "::ffff:10.10.1.1",</span>
  <span class="c">#      ...</span>
  <span class="c">#      "os": {</span>
  <span class="c">#        "hostname": "deploy-echo-5c689d5454-rbgcp"</span>
  <span class="c">#      }</span>
  <span class="c">#    }</span>
  <span class="c">#    &gt;&gt; node 172.23.0.3 &lt;&lt;</span>
  <span class="c">#    {</span>
  <span class="c">#      "headers": {</span>
  <span class="c">#        "host": "172.23.0.3:31791",</span>
  <span class="c">#        ...</span>
  <span class="c">#      },</span>
  <span class="c">#      ...</span>
  <span class="c">#      "hostname": "172.23.0.3",</span>
  <span class="c">#      "ip": "::ffff:10.10.2.1",</span>
  <span class="c">#      ...</span>
  <span class="c">#      "os": {</span>
  <span class="c">#        "hostname": "deploy-echo-5c689d5454-wppr8"</span>
  <span class="c">#      }</span>
  <span class="c">#    }</span>
      
  <span class="c"># 컨트롤플레인 노드에는 목적지 파드가 없는데도, 접속을 받아줍니다! 이유는 서비스(nodePort)의 endpoint로 로드밸런싱 되기 때문입니다.</span>
  <span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc zsh <span class="nt">-c</span> <span class="s2">"for i in {1..100}; do curl -s </span><span class="nv">$CNODE</span><span class="s2">:</span><span class="nv">$NPORT</span><span class="s2"> | grep hostname; done | sort | uniq -c | sort -nr"</span>
  <span class="c"># =&gt;     100   "hostname": "172.23.0.2",</span>
  <span class="c">#         37     "hostname": "deploy-echo-5c689d5454-wppr8"</span>
  <span class="c">#         33     "hostname": "deploy-echo-5c689d5454-rbgcp"</span>
  <span class="c">#         30     "hostname": "deploy-echo-5c689d5454-dxf2t"</span>
  <span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc zsh <span class="nt">-c</span> <span class="s2">"for i in {1..100}; do curl -s </span><span class="nv">$NODE1</span><span class="s2">:</span><span class="nv">$NPORT</span><span class="s2"> | grep hostname; done | sort | uniq -c | sort -nr"</span>
  <span class="c"># =&gt;     100   "hostname": "172.23.0.4",</span>
  <span class="c">#         40     "hostname": "deploy-echo-5c689d5454-wppr8"</span>
  <span class="c">#         32     "hostname": "deploy-echo-5c689d5454-dxf2t"</span>
  <span class="c">#         28     "hostname": "deploy-echo-5c689d5454-rbgcp"$ docker exec -it mypc zsh -c "for i in {1..100}; do curl -s $NODE2:$NPORT | grep hostname; done | sort | uniq -c | sort -nr"</span>
  <span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc zsh <span class="nt">-c</span> <span class="s2">"for i in {1..100}; do curl -s </span><span class="nv">$NODE3</span><span class="s2">:</span><span class="nv">$NPORT</span><span class="s2"> | grep hostname; done | sort | uniq -c | sort -nr"</span>
  <span class="c"># =&gt;     100   "hostname": "172.23.0.3",</span>
  <span class="c">#         43     "hostname": "deploy-echo-5c689d5454-wppr8"</span>
  <span class="c">#         34     "hostname": "deploy-echo-5c689d5454-dxf2t"</span>
  <span class="c">#         23     "hostname": "deploy-echo-5c689d5454-rbgcp"</span>
  <span class="c"># 아래 반복 접속 실행 해두자</span>
  <span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc zsh <span class="nt">-c</span> <span class="s2">"while true; do curl -s --connect-timeout 1 </span><span class="nv">$CNODE</span><span class="s2">:</span><span class="nv">$NPORT</span><span class="s2"> | grep hostname; date '+%Y-%m-%d %H:%M:%S' ; echo ;  sleep 1; done"</span>
      
  <span class="c"># NodePort 서비스는 ClusterIP 를 포함</span>
  <span class="c"># CLUSTER-IP:PORT 로 접속 가능! &lt;- 컨트롤노드에서 아래 실행 해보자</span>
  <span class="nv">$ </span>kubectl get svc svc-nodeport
  <span class="c"># =&gt; NAME           TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE</span>
  <span class="c">#    svc-nodeport   NodePort   10.200.1.169   &lt;none&gt;        9000:31791/TCP   51m</span>
      
  <span class="nv">$ CIP</span><span class="o">=</span><span class="si">$(</span>kubectl get service svc-nodeport <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.spec.clusterIP}"</span><span class="si">)</span>
  <span class="nv">$ CIPPORT</span><span class="o">=</span><span class="si">$(</span>kubectl get service svc-nodeport <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.spec.ports[0].port}"</span><span class="si">)</span>
  <span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$CIP</span> <span class="nv">$CIPPORT</span>
  <span class="c"># =&gt; 10.200.1.169 9000</span>
  <span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane curl <span class="nt">-s</span> <span class="nv">$CIP</span>:<span class="nv">$CIPPORT</span> | jq
  <span class="c"># =&gt; {</span>
  <span class="c">#      "path": "/",</span>
  <span class="c">#      "headers": {</span>
  <span class="c">#        "host": "10.200.1.169:9000",</span>
  <span class="c">#        "user-agent": "curl/7.88.1",</span>
  <span class="c">#        "accept": "*/*"</span>
  <span class="c">#      },</span>
  <span class="c">#      "method": "GET",</span>
  <span class="c">#      "body": "",</span>
  <span class="c">#      "fresh": false,</span>
  <span class="c">#      "hostname": "10.200.1.169",</span>
  <span class="c">#      "ip": "::ffff:172.23.0.2",</span>
  <span class="c">#      "ips": [],</span>
  <span class="c">#      "protocol": "http",</span>
  <span class="c">#      "query": {},</span>
  <span class="c">#      "subdomains": [],</span>
  <span class="c">#      "xhr": false,</span>
  <span class="c">#      "os": {</span>
  <span class="c">#        "hostname": "deploy-echo-5c689d5454-rbgcp"</span>
  <span class="c">#      },</span>
  <span class="c">#      "connection": {}</span>
  <span class="c">#    }</span>
      
  <span class="c"># mypc에서 CLUSTER-IP:PORT 로 접속 가능할까?</span>
  <span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc curl <span class="nt">-s</span> <span class="nv">$CIP</span>:<span class="nv">$CIPPORT</span>
  <span class="c"># =&gt; (에러)</span>
      
  <span class="c"># mypc에서 cluster ip port로의 접속은 불가능합니다. mypc는 kubernetes 클러스터 내부에 있지 않기 때문입니다.</span>
      
  <span class="c"># (옵션) 노드에서 Network Connection</span>
  <span class="nv">$ </span>conntrack <span class="nt">-E</span>
  <span class="c"># =&gt;     [NEW] tcp      6 120 SYN_SENT src=172.23.0.2 dst=10.10.4.4 sport=36907 dport=8080 [UNREPLIED] src=10.10.4.4 dst=172.23.0.2 sport=8080 dport=36907</span>
  <span class="c">#     [UPDATE] tcp      6 60 SYN_RECV src=172.23.0.2 dst=10.10.4.4 sport=36907 dport=8080 src=10.10.4.4 dst=172.23.0.2 sport=8080 dport=36907</span>
  <span class="c">#     [UPDATE] tcp      6 86400 ESTABLISHED src=172.23.0.2 dst=10.10.4.4 sport=36907 dport=8080 src=10.10.4.4 dst=172.23.0.2 sport=8080 dport=36907 [ASSURED]</span>
  <span class="c">#     [UPDATE] tcp      6 120 FIN_WAIT src=172.23.0.2 dst=10.10.4.4 sport=36907 dport=8080 src=10.10.4.4 dst=172.23.0.2 sport=8080 dport=36907 [ASSURED]</span>
  <span class="c">#     [UPDATE] tcp      6 30 LAST_ACK src=172.23.0.2 dst=10.10.4.4 sport=36907 dport=8080 src=10.10.4.4 dst=172.23.0.2 sport=8080 dport=36907 [ASSURED]</span>
  <span class="c">#     [UPDATE] tcp      6 120 TIME_WAIT src=172.23.0.2 dst=10.10.4.4 sport=36907 dport=8080 src=10.10.4.4 dst=172.23.0.2 sport=8080 dport=36907 [ASSURED]</span>
  <span class="c">#      ...</span>
  <span class="c"># SNAT나 빠른 iptables 룰 처리등을 위해 접속 정보가 추적됨을 알 수 있습니다.</span>
      
  <span class="nv">$ </span>conntrack <span class="nt">-L</span> <span class="nt">--any-nat</span>
</code></pre></div>        </div>
      </li>
      <li>파드에서 바라본 클라이언트의 주소가 실제 클라이언트가 아닌 node의 ip로 표시되는데 그 이유를 살펴보겠습니다.
        <ul>
          <li>
            <p>컨트롤 플레인에서 iptables의 nat 테이블의 KUBE-POSTROUTING 룰을 확인하면 다음과 같습니다.</p>

            <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nv">$ </span>iptables <span class="nt">-v</span> <span class="nt">--numeric</span> <span class="nt">--table</span> nat <span class="nt">--list</span> 
  <span class="c"># =&gt; Chain POSTROUTING (policy ACCEPT 5813 packets, 349K bytes)</span>
  <span class="c">#     pkts bytes target     prot opt in     out     source               destination         </span>
  <span class="c">#    37925 2276K KUBE-POSTROUTING  0    --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes postrouting rules */</span>
  <span class="c">#    ...</span>
  <span class="c">#    Chain KUBE-POSTROUTING (1 references)</span>
  <span class="c">#     pkts bytes target     prot opt in     out     source               destination</span>
  <span class="c">#     5343  321K RETURN     0    --  *      *       0.0.0.0/0            0.0.0.0/0            mark match ! 0x4000/0x4000</span>
  <span class="c">#     1265 75900 MARK       0    --  *      *       0.0.0.0/0            0.0.0.0/0            MARK xor 0x4000</span>
  <span class="c">#     1265 75900 MASQUERADE  0    --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes service traffic requiring SNAT */ random-fully</span>
</code></pre></div>            </div>

            <p>확인 결과 POSTROUTING시 KUBE-POSTROUTING을 통해 SNAT 되고 있음을 알 수 있습니다.</p>
          </li>
        </ul>
      </li>
      <li>
        <p>외부 클라이언트 → 서비스(NodePort) 접속 시 : 3개의 목적지(backend) 파드로 <strong>랜덤 부하 분산</strong> 접속됨을 확인해보겠습니다.</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$CNODE</span>:<span class="nv">$NPORT</span> | <span class="nb">grep hostname</span><span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
  <span class="c"># =&gt;    100   "hostname": "172.23.0.2",</span>
  <span class="c">#        42     "hostname": "deploy-echo-5c689d5454-wppr8"</span>
  <span class="c">#        31     "hostname": "deploy-echo-5c689d5454-dxf2t"</span>
  <span class="c">#        27     "hostname": "deploy-echo-5c689d5454-rbgcp"</span>
      
  <span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$NODE1</span>:<span class="nv">$NPORT</span> | <span class="nb">grep hostname</span><span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
  <span class="c"># =&gt;     100   "hostname": "172.23.0.4",</span>
  <span class="c">#         37     "hostname": "deploy-echo-5c689d5454-dxf2t"</span>
  <span class="c">#         34     "hostname": "deploy-echo-5c689d5454-rbgcp"</span>
  <span class="c">#         29     "hostname": "deploy-echo-5c689d5454-wppr8"</span>
      
  <span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$NODE2</span>:<span class="nv">$NPORT</span> | <span class="nb">grep hostname</span><span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
  <span class="c"># =&gt;     100   "hostname": "172.23.0.5",</span>
  <span class="c">#         41     "hostname": "deploy-echo-5c689d5454-wppr8"</span>
  <span class="c">#         32     "hostname": "deploy-echo-5c689d5454-rbgcp"</span>
  <span class="c">#         27     "hostname": "deploy-echo-5c689d5454-dxf2t"</span>
      
  <span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="o">{</span>1..100<span class="o">}</span><span class="p">;</span> <span class="k">do </span>curl <span class="nt">-s</span> <span class="nv">$NODE3</span>:<span class="nv">$NPORT</span> | <span class="nb">grep hostname</span><span class="p">;</span> <span class="k">done</span> | <span class="nb">sort</span> | <span class="nb">uniq</span> <span class="nt">-c</span> | <span class="nb">sort</span> <span class="nt">-nr</span>
  <span class="c"># =&gt;     100   "hostname": "172.23.0.3",</span>
  <span class="c">#         39     "hostname": "deploy-echo-5c689d5454-dxf2t"</span>
  <span class="c">#         34     "hostname": "deploy-echo-5c689d5454-wppr8"</span>
  <span class="c">#         27     "hostname": "deploy-echo-5c689d5454-rbgcp"</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p>웹 파드에서  log를 통해 접속자의 IP 확인시 외부 클라이언트 IP가 아닌, 노드의 IP로 SNAT 되어서 접속됨을 확인할 수 있습니다.</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nv">$ </span>kubectl logs <span class="nt">-f</span> deploy-echo-5c689d5454-dxf2t | <span class="nb">grep </span>HTTP
  <span class="c"># =&gt; ::ffff:172.23.0.3 - - [01/Sep/2024:05:28:36 +0000] "GET / HTTP/1.1" 200 398 "-" "curl/7.88.1"</span>
  <span class="c">#    ::ffff:172.23.0.3 - - [01/Sep/2024:05:28:36 +0000] "GET / HTTP/1.1" 200 398 "-" "curl/7.88.1"</span>
  <span class="c">#    ::ffff:172.23.0.3 - - [01/Sep/2024:05:28:36 +0000] "GET / HTTP/1.1" 200 398 "-" "curl/7.88.1"</span>
  <span class="c">#    ::ffff:172.23.0.3 - - [01/Sep/2024:05:28:36 +0000] "GET / HTTP/1.1" 200 398 "-" "curl/7.88.1"</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li>2.4.  IPTABLES 정책 확인
    <ul>
      <li>
        <p>iptables 정책 적용 순서는 다음과 같습니다.</p>

        <p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_25.png" alt="img.png" /></p>

        <ul>
          <li>PREROUTING → KUBE-SERVICES → KUBE-NODEPORTS → <strong>KUBE-EXT-#(MARK)</strong> → KUBE-SVC-# → KUBE-SEP-#  ⇒ KUBE-POSTROUTING (MASQUERADE) <strong>**</strong></li>
          <li><code class="language-plaintext highlighter-rouge">KUBE-EXT-#(MARK)</code> 규칙 과정이 추가됨을 확인할 수 있습니다.</li>
        </ul>
      </li>
      <li>기본 규칙은 ClusterIP 서비스 동작 규칙과 거의 같으며 차이점은 KUBE-NODEPORTS, KUBE-MARK-MASK, KUBE-POSTROUTING 체인이  다릅니다. 핵심 내용은 NodePort에 매칭시 마킹 후 출발지 IP를 해당 노드에 있는 네트워크 IP로 변환(MASQUERADE : SNAT)하여 목적지 파드로 전달합니다.</li>
      <li>
        <p>실습을 통해 iptables 정책에 대해 확인해보겠습니다.  컨트롤플레인에서 실습을 진행하겠습니다.</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane bash
  <span class="nt">----------------------------------------</span>
      
  <span class="c"># 패킷 카운트 초기화</span>
  <span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">--zero</span>
      
  <span class="c"># PREROUTING 정보 확인</span>
  <span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span> | <span class="nb">grep </span>PREROUTING
  <span class="c"># =&gt; -P PREROUTING ACCEPT</span>
  <span class="c">#    -A PREROUTING -m comment --comment "kubernetes service portals" -j KUBE-SERVICES</span>
  <span class="c">#    -A PREROUTING -d 172.23.0.1/32 -j DOCKER_OUTPUT</span>
      
  <span class="c"># 외부 클라이언트가 노드IP:NodePort 로 접속하기 때문에 --dst-type LOCAL 에 매칭되어서 -j KUBE-NODEPORTS 로 점프!</span>
  <span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span> | <span class="nb">grep </span>KUBE-SERVICES
  <span class="c"># =&gt; ...</span>
  <span class="c">#    -A KUBE-SERVICES -m comment --comment "kubernetes service nodeports; NOTE: this must be the last rule in this chain" -m addrtype --dst-type LOCAL -j KUBE-NODEPORTS</span>
      
  <span class="c"># KUBE-NODEPORTS 에서 KUBE-EXT-# 로 점프!</span>
  <span class="c">## -m nfacct --nfacct-name localhost_nps_accepted_pkts 추가됨 : 패킷 flow 카운팅 - 카운트 이름 지정 </span>
  <span class="nv">$ NPORT</span><span class="o">=</span><span class="si">$(</span>kubectl get service svc-nodeport <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.spec.ports[0].nodePort}'</span><span class="si">)</span>
  <span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$NPORT</span>
  <span class="c"># =&gt; 31791</span>
      
  <span class="c"># $ iptables -t nat -S | grep KUBE-NODEPORTS | grep &lt;NodePort&gt;</span>
  <span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span> | <span class="nb">grep </span>KUBE-NODEPORTS | <span class="nb">grep</span> <span class="nv">$NPORT</span>
  <span class="c"># =&gt; -A KUBE-NODEPORTS -p tcp -m comment --comment "default/svc-nodeport:svc-webport" -m tcp --dport 31791 -j KUBE-EXT-VTR7MTHHNMFZ3OFS</span>
      
  <span class="c"># (참고) nfacct 확인</span>
  <span class="nv">$ </span>nfacct list
  <span class="c">## nfacct flush # 초기화</span>
      
  <span class="c">## KUBE-EXT-# 에서 'KUBE-MARK-MASQ -j MARK --set-xmark 0x4000/0x4000' 마킹 및 KUBE-SVC-# 로 점프!</span>
  <span class="c"># docker exec -it mypc zsh -c "while true; do curl -s --connect-timeout 1 $CNODE:$NPORT | grep hostname; date '+%Y-%m-%d %H:%M:%S' ; echo ;  sleep 1; done" 반복 접속 후 아래 확인</span>
  <span class="nv">$ </span>watch <span class="nt">-d</span> <span class="s1">'iptables -v --numeric --table nat --list KUBE-EXT-VTR7MTHHNMFZ3OFS'</span>
  <span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span> | <span class="nb">grep</span> <span class="s2">"A KUBE-EXT-VTR7MTHHNMFZ3OFS"</span>
  <span class="c"># =&gt; -A KUBE-EXT-VTR7MTHHNMFZ3OFS -m comment --comment "masquerade traffic for default/svc-nodeport:svc-webport external destinations" -j KUBE-MARK-MASQ</span>
  <span class="c">#    -A KUBE-EXT-VTR7MTHHNMFZ3OFS -j KUBE-SVC-VTR7MTHHNMFZ3OFS</span>
      
  <span class="c"># iptables -t nat -S | grep "A KUBE-MARK-MASQ" | sed -e 's/^/#    /' -e '1s/^#    /# =&gt; /'</span>
  <span class="c"># =&gt; -A KUBE-MARK-MASQ -j MARK --set-xmark 0x4000/0x4000        # 0x4000/0x4000으로 마킹하는 룰</span>
      
  <span class="c"># KUBE-SVC-# 이후 과정은 Cluster-IP 와 동일! : 3개의 파드로 DNAT 되어서 전달</span>
  <span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span> | <span class="nb">grep</span> <span class="s2">"A KUBE-SVC-VTR7MTHHNMFZ3OFS -"</span>
  <span class="c"># =&gt; -A KUBE-SVC-VTR7MTHHNMFZ3OFS -m comment --comment "default/svc-nodeport:svc-webport -&gt; 10.10.1.5:8080" -m statistic --mode random --probability 0.33333333349 -j KUBE-SEP-SESYGQFRQSLJQZ6Q</span>
  <span class="c">#    -A KUBE-SVC-VTR7MTHHNMFZ3OFS -m comment --comment "default/svc-nodeport:svc-webport -&gt; 10.10.2.7:8080" -m statistic --mode random --probability 0.50000000000 -j KUBE-SEP-FBJG45W6XHLV2NA6</span>
  <span class="c">#    -A KUBE-SVC-VTR7MTHHNMFZ3OFS -m comment --comment "default/svc-nodeport:svc-webport -&gt; 10.10.4.4:8080" -j KUBE-SEP-GEQNJ6BO5AOHB6LH</span>
      
  <span class="c"># POSTROUTING 정보 확인</span>
  <span class="c"># 마킹되어 있어서 출발지IP를 접속한 노드의 IP 로 SNAT(MASQUERADE) 처리함! , 최초 출발지Port는 랜덤Port 로 변경</span>
  <span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span> | <span class="nb">grep</span> <span class="s2">"A KUBE-POSTROUTING"</span>
  <span class="c"># =&gt; -A KUBE-POSTROUTING -m mark ! --mark 0x4000/0x4000 -j RETURN   # 0x4000/0x4000 되어 있으니 여기에 매칭되지 않고 아래 Rule로 내려감</span>
  <span class="c">#    -A KUBE-POSTROUTING -j MARK --set-xmark 0x4000/0x0</span>
  <span class="c">#    -A KUBE-POSTROUTING -m comment --comment "kubernetes service traffic requiring SNAT" -j MASQUERADE --random-fully</span>
      
  <span class="c"># docker exec -it mypc zsh -c "while true; do curl -s --connect-timeout 1 $CNODE:$NPORT | grep hostname; date '+%Y-%m-%d %H:%M:%S' ; echo ;  sleep 1; done" 반복 접속 후 아래 확인</span>
  <span class="nv">$ </span>watch <span class="nt">-d</span> <span class="s1">'iptables -v --numeric --table nat --list KUBE-POSTROUTING;echo;iptables -v --numeric --table nat --list POSTROUTING'</span>
      
  <span class="nv">$ </span><span class="nb">exit</span>
  <span class="nt">----------------------------------------</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p>서비스 (NodePort) 생성 시 kube-proxy에 의해서 iptables 규칙이 모든 노드에 추가되는지 확인해보겠습니다.</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c">#</span>
  <span class="nv">$ NPORT</span><span class="o">=</span><span class="si">$(</span>kubectl get service svc-nodeport <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.spec.ports[0].nodePort}'</span><span class="si">)</span>
  <span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$NPORT</span> 
  <span class="c"># =&gt; 31791</span>
  <span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane iptables <span class="nt">-t</span> nat <span class="nt">-S</span> | <span class="nb">grep </span>KUBE-NODEPORTS | <span class="nb">grep</span> <span class="nv">$NPORT</span>
  <span class="c"># =&gt; -A KUBE-NODEPORTS -p tcp -m comment --comment "default/svc-nodeport:svc-webport" -m tcp --dport 31791 -j KUBE-EXT-VTR7MTHHNMFZ3OFS</span>
      
  <span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>control-plane worker worker2 worker3<span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node myk8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-<span class="nv">$i</span> iptables <span class="nt">-t</span> nat <span class="nt">-S</span> | <span class="nb">grep </span>KUBE-NODEPORTS | <span class="nb">grep</span> <span class="nv">$NPORT</span><span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
  <span class="c"># =&gt; &gt;&gt; node myk8s-control-plane &lt;&lt;</span>
  <span class="c">#    -A KUBE-NODEPORTS -p tcp -m comment --comment "default/svc-nodeport:svc-webport" -m tcp --dport 31791 -j KUBE-EXT-VTR7MTHHNMFZ3OFS</span>
  <span class="c">#    </span>
  <span class="c">#    &gt;&gt; node myk8s-worker &lt;&lt;</span>
  <span class="c">#    -A KUBE-NODEPORTS -p tcp -m comment --comment "default/svc-nodeport:svc-webport" -m tcp --dport 31791 -j KUBE-EXT-VTR7MTHHNMFZ3OFS</span>
  <span class="c">#    </span>
  <span class="c">#    &gt;&gt; node myk8s-worker2 &lt;&lt;</span>
  <span class="c">#    -A KUBE-NODEPORTS -p tcp -m comment --comment "default/svc-nodeport:svc-webport" -m tcp --dport 31791 -j KUBE-EXT-VTR7MTHHNMFZ3OFS</span>
  <span class="c">#    </span>
  <span class="c">#    &gt;&gt; node myk8s-worker3 &lt;&lt;</span>
  <span class="c">#    -A KUBE-NODEPORTS -p tcp -m comment --comment "default/svc-nodeport:svc-webport" -m tcp --dport 31791 -j KUBE-EXT-VTR7MTHHNMFZ3OFS</span>
</code></pre></div>        </div>
      </li>
      <li>iptables 룰이 모든 노드에 추가되어있음을 확인 할 수 있습니다.</li>
    </ul>
  </li>
  <li>2.5. externalTrafficPolicy  설정
    <ul>
      <li>
        <p><code class="language-plaintext highlighter-rouge">externalTrafficPolicy: Local</code> : 앞에서 실습한 바와같이 서비스가 바라보는 파드에 접속시 클라이언트 IP가 node의 IP로 접속됩니다. 이때 <code class="language-plaintext highlighter-rouge">externalTrafficPolicy: Local</code> 를 하면 <strong>해당 노드에 배치된 파드로만 접속되면서</strong>, SNAT가 되지않아 <strong>외부 클라이언트 IP가 보존</strong>됩니다.</p>

        <p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_26.png" alt="img.png" /></p>

        <ul>
          <li>이전까지는 같은 iptables 룰이 모든 노드에 적용 되었지만, 노드 자신의 파드로만 가는 룰만 있어서 각각 조금씩 다른 룰이 적용되게 됩니다.</li>
        </ul>

        <p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_27.png" alt="img.png" /></p>

        <ul>
          <li>만약 노드에 해당하는 파드가 없으면 위의 그림과 같이 연결이 실패하게되니 사용에 주의가 필요합니다.</li>
        </ul>
      </li>
      <li>
        <p><code class="language-plaintext highlighter-rouge">externalTrafficPolicy: Local</code> 설정 시의 통신 흐름을 좀 더 자세히 알아보겠습니다.</p>

        <p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_28.png" alt="img.png" /></p>

        <ul>
          <li>클라이언트에서 파드가 배포되어있는 워커노드1에 NodePort로 접속합니다.</li>
          <li>워커노드1의 IPTABLES의 nat 테이블 규칙과 매칭되어 목적지 IP와 목적지 Port는 변환 되지만, SNAT 되지 않고 바로 파드로 전달되므로 클라이언트의 IP가 파드에 그대로 전달 됩니다.</li>
        </ul>
      </li>
      <li>
        <p>설정 및 파드 접속 확인</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c"># 기본 정보 확인</span>
  <span class="nv">$ </span>kubectl get svc svc-nodeport <span class="nt">-o</span> json | <span class="nb">grep</span> <span class="s1">'TrafficPolicy"'</span>
  <span class="c"># =&gt;         "externalTrafficPolicy": "Cluster",</span>
  <span class="c">#            "internalTrafficPolicy": "Cluster",</span>
      
  <span class="c"># 기존 통신 연결 정보(conntrack) 제거 후 아래 실습 진행하자! : (모든 노드에서) conntrack -F</span>
  <span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>control-plane worker worker2 worker3<span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node myk8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-<span class="nv">$i</span> conntrack <span class="nt">-F</span><span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
  <span class="c"># =&gt; &gt;&gt; node myk8s-control-plane &lt;&lt;</span>
  <span class="c">#    conntrack v1.4.7 (conntrack-tools): connection tracking table has been emptied.</span>
  <span class="c">#    </span>
  <span class="c">#    &gt;&gt; node myk8s-worker &lt;&lt;</span>
  <span class="c">#    conntrack v1.4.7 (conntrack-tools): connection tracking table has been emptied.</span>
  <span class="c">#    </span>
  <span class="c">#    &gt;&gt; node myk8s-worker2 &lt;&lt;</span>
  <span class="c">#    conntrack v1.4.7 (conntrack-tools): connection tracking table has been emptied.</span>
  <span class="c">#    </span>
  <span class="c">#    &gt;&gt; node myk8s-worker3 &lt;&lt;</span>
  <span class="c">#    conntrack v1.4.7 (conntrack-tools): connection tracking table has been emptied.</span>
  <span class="c">#    </span>
  <span class="nv">$ </span>kubectl delete <span class="nt">-f</span> svc-nodeport.yml
  <span class="c"># =&gt; service "svc-nodeport" deleted</span>
  <span class="nv">$ </span>kubectl apply <span class="nt">-f</span> svc-nodeport.yml
  <span class="c"># =&gt; service/svc-nodeport created</span>
      
  <span class="c"># externalTrafficPolicy: local 설정 변경</span>
  <span class="nv">$ </span>kubectl patch svc svc-nodeport <span class="nt">-p</span> <span class="s1">'{"spec":{"externalTrafficPolicy": "Local"}}'</span>
  <span class="c"># =&gt; service/svc-nodeport patched</span>
  <span class="nv">$ </span>kubectl get svc svc-nodeport <span class="nt">-o</span> json | <span class="nb">grep</span> <span class="s1">'TrafficPolicy"'</span>
  <span class="c"># =&gt;         "externalTrafficPolicy": "Local",</span>
  <span class="c">#            "internalTrafficPolicy": "Cluster",</span>
      
  <span class="c"># 파드 3개를 2개로 줄입니다.</span>
  <span class="nv">$ </span>kubectl scale deployment deploy-echo <span class="nt">--replicas</span><span class="o">=</span>2
  <span class="c"># =&gt; deployment.apps/deploy-echo scaled</span>
</code></pre></div>        </div>

        <p><img src="/assets/2024/kans-3th/w4/20240928_kans_w4_29.png" alt="img.png" /></p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c"># 파드 존재하는 노드 정보 확인</span>
  <span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
  <span class="c"># =&gt; NAME                           READY   STATUS    RESTARTS   AGE   IP          NODE                  NOMINATED NODE   READINESS GATES</span>
  <span class="c">#    deploy-echo-5c689d5454-24cql   1/1     Running   0          30s   10.10.4.5   myk8s-worker          &lt;none&gt;           &lt;none&gt;</span>
  <span class="c">#    deploy-echo-5c689d5454-2kgfj   1/1     Running   0          30s   10.10.1.6   myk8s-worker2         &lt;none&gt;           &lt;none&gt;</span>
  <span class="c">#    net-pod                        1/1     Running   0          46h   10.10.0.7   myk8s-control-plane   &lt;none&gt;           &lt;none&gt;</span>
      
  <span class="c"># 파드 로그 실시간 확인 (웹 파드에 접속자의 IP가 출력)</span>
  <span class="nv">$ </span>kubectl logs <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>deploy-websrv <span class="nt">-f</span>
      
  <span class="c"># 외부 클라이언트(mypc)에서 접속 시도</span>
      
  <span class="c"># 노드의 IP와 NodePort를 변수에 지정</span>
  <span class="c">## CNODE=&lt;컨트롤플레인노드의 IP주소&gt;</span>
  <span class="c">## NODE1=&lt;노드1의 IP주소&gt;</span>
  <span class="c">## NODE2=&lt;노드2의 IP주소&gt;</span>
  <span class="c">## NODE3=&lt;노드3의 IP주소&gt;</span>
  <span class="nv">$ CNODE</span><span class="o">=</span>172.23.0.2
  <span class="nv">$ NODE1</span><span class="o">=</span>172.23.0.4
  <span class="nv">$ NODE2</span><span class="o">=</span>172.23.0.5
  <span class="nv">$ NODE3</span><span class="o">=</span>172.23.0.3
      
  <span class="c">## NodePort 를 변수에 지정</span>
  <span class="nv">$ NPORT</span><span class="o">=</span><span class="si">$(</span>kubectl get service svc-nodeport <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.spec.ports[0].nodePort}'</span><span class="si">)</span>
  <span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$NPORT</span>
  <span class="c"># =&gt; 31177</span>
      
  <span class="c"># 서비스(NodePort) 부하분산 접속 확인 : 파드가 존재하지 않는 노드로는 접속 실패!, 파드가 존재하는 노드는 접속 성공 및 클라이언트 IP 확인!</span>
  <span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 <span class="nv">$CNODE</span>:<span class="nv">$NPORT</span> | jq
  <span class="c"># =&gt; (공백)</span>
  <span class="c"># 컨트롤 플레인에는 파드가 없으므로 결과가 없습니다.</span>
      
  <span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="nv">$CNODE</span> <span class="nv">$NODE1</span> <span class="nv">$NODE2</span> <span class="nv">$NODE3</span> <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> mypc curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 <span class="nv">$i</span>:<span class="nv">$NPORT</span><span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
  <span class="c"># =&gt; &gt;&gt; node 172.23.0.2 &lt;&lt;</span>
  <span class="c">#    </span>
  <span class="c">#    &gt;&gt; node 172.23.0.4 &lt;&lt;</span>
  <span class="c">#    {</span>
  <span class="c">#      "path": "/",</span>
  <span class="c">#      "headers": {</span>
  <span class="c">#        "host": "172.23.0.4:31177",</span>
  <span class="c">#        ...</span>
  <span class="c">#      },</span>
  <span class="c">#      ...</span>
  <span class="c">#      "hostname": "172.23.0.4",</span>
  <span class="c">#      "ip": "::ffff:172.23.0.6",</span>
  <span class="c">#      ...</span>
  <span class="c">#      "os": {</span>
  <span class="c">#        "hostname": "deploy-echo-5c689d5454-24cql"</span>
  <span class="c">#      }</span>
  <span class="c">#    }</span>
  <span class="c">#    &gt;&gt; node 172.23.0.5 &lt;&lt;</span>
  <span class="c">#    {</span>
  <span class="c">#      "headers": {</span>
  <span class="c">#        "host": "172.23.0.5:31177",</span>
  <span class="c">#        ...</span>
  <span class="c">#      },</span>
      
  <span class="c">#      "hostname": "172.23.0.5",</span>
  <span class="c">#      "ip": "::ffff:172.23.0.6",</span>
  <span class="c">#      ...</span>
  <span class="c">#      "os": {</span>
  <span class="c">#        "hostname": "deploy-echo-5c689d5454-2kgfj"</span>
  <span class="c">#      }</span>
  <span class="c">#    }</span>
  <span class="c">#    &gt;&gt; node 172.23.0.3 &lt;&lt;</span>
  <span class="c">#    </span>
      
  <span class="c"># 목적지 파드가 배치되지 않은 노드는 접속이 어떻게? 왜 그런가?</span>
  <span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc zsh <span class="nt">-c</span> <span class="s2">"for i in {1..100}; do curl -s </span><span class="nv">$CNODE</span><span class="s2">:</span><span class="nv">$NPORT</span><span class="s2"> | grep hostname; done | sort | uniq -c | sort -nr"</span>
  <span class="c"># =&gt; </span>
  <span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc zsh <span class="nt">-c</span> <span class="s2">"for i in {1..100}; do curl -s </span><span class="nv">$NODE1</span><span class="s2">:</span><span class="nv">$NPORT</span><span class="s2"> | grep hostname; done | sort | uniq -c | sort -nr"</span>
  <span class="c"># =&gt;     100   "hostname": "172.23.0.4",</span>
  <span class="c">#        100     "hostname": "deploy-echo-5c689d5454-24cql"</span>
  <span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc zsh <span class="nt">-c</span> <span class="s2">"for i in {1..100}; do curl -s </span><span class="nv">$NODE2</span><span class="s2">:</span><span class="nv">$NPORT</span><span class="s2"> | grep hostname; done | sort | uniq -c | sort -nr"</span>
  <span class="c"># =&gt;     100   "hostname": "172.23.0.5",</span>
  <span class="c">#        100     "hostname": "deploy-echo-5c689d5454-2kgfj"</span>
  <span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc zsh <span class="nt">-c</span> <span class="s2">"for i in {1..100}; do curl -s </span><span class="nv">$NODE3</span><span class="s2">:</span><span class="nv">$NPORT</span><span class="s2"> | grep hostname; done | sort | uniq -c | sort -nr"</span>
  <span class="c"># =&gt; </span>
  <span class="c"># 목적지 파드가 배치되지 않은 노드는 응답이 없어 타임아웃이 됩니다. 그 이유는 externalTrafficPolicy: Local여서 노드포트로 온 패킷이, local pod로 전달하려고 하는데</span>
  <span class="c"># local pod가 없기 때문입니다.</span>
      
  <span class="c"># 아래 반복 접속 실행 해두자</span>
  <span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> mypc zsh <span class="nt">-c</span> <span class="s2">"while true; do curl -s --connect-timeout 1 </span><span class="nv">$NODE2</span><span class="s2">:</span><span class="nv">$NPORT</span><span class="s2"> | grep hostname; date '+%Y-%m-%d %H:%M:%S' ; echo ;  sleep 1; done"</span>
      
  <span class="c"># (옵션) 노드에서 Network Connection</span>
  <span class="nv">$ </span>conntrack <span class="nt">-E</span>
  <span class="nv">$ </span>conntrack <span class="nt">-L</span> <span class="nt">--any-nat</span>
</code></pre></div>        </div>
      </li>
      <li>
        <p>외부 클라이언트 → 각각 워커 노드 1,2 접속시 각각 노드의 파드로만 접속 됩니다.</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="c"># 호스트에서 실행</span>
  <span class="nv">$ </span><span class="k">for </span>i <span class="k">in</span> <span class="nv">$CNODE</span> <span class="nv">$NODE1</span> <span class="nv">$NODE2</span> <span class="nv">$NODE3</span> <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node </span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> curl <span class="nt">-s</span> <span class="nt">--connect-timeout</span> 1 <span class="nv">$i</span>:<span class="nv">$NPORT</span><span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
  <span class="c"># =&gt; &gt;&gt; node 172.23.0.2 &lt;&lt;</span>
  <span class="c">#    </span>
  <span class="c">#    &gt;&gt; node 172.23.0.4 &lt;&lt;</span>
  <span class="c">#    {</span>
  <span class="c">#      "headers": {</span>
  <span class="c">#        "host": "172.23.0.4:31177",</span>
  <span class="c">#      },</span>
  <span class="c">#      "hostname": "172.23.0.4",</span>
  <span class="c">#      "ip": "::ffff:172.23.0.1",</span>
  <span class="c">#      "os": {</span>
  <span class="c">#        "hostname": "deploy-echo-5c689d5454-24cql"</span>
  <span class="c">#      }</span>
  <span class="c">#    }</span>
  <span class="c">#    &gt;&gt; node 172.23.0.5 &lt;&lt;</span>
  <span class="c">#    {</span>
  <span class="c">#      "headers": {</span>
  <span class="c">#        "host": "172.23.0.5:31177",</span>
  <span class="c">#      },</span>
  <span class="c">#      "hostname": "172.23.0.5",</span>
  <span class="c">#      "ip": "::ffff:172.23.0.1",</span>
  <span class="c">#      "os": {</span>
  <span class="c">#        "hostname": "deploy-echo-5c689d5454-2kgfj"</span>
  <span class="c">#      }</span>
  <span class="c">#    }</span>
  <span class="c">#    &gt;&gt; node 172.23.0.3 &lt;&lt;    </span>
    
  <span class="c"># 다른 터미널에서 로그 표시</span>
  <span class="nv">$ </span>kubectl logs <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>deploy-websrv <span class="nt">-f</span> | <span class="nb">grep </span>HTTP
  ::ffff:172.23.0.1 - - <span class="o">[</span>26/Sep/2024:07:33:09 +0000] <span class="s2">"GET / HTTP/1.1"</span> 200 397 <span class="s2">"-"</span> <span class="s2">"curl/8.7.1"</span>
  ::ffff:172.23.0.1 - - <span class="o">[</span>26/Sep/2024:07:33:10 +0000] <span class="s2">"GET / HTTP/1.1"</span> 200 397 <span class="s2">"-"</span> <span class="s2">"curl/8.7.1"</span>
  ::ffff:172.23.0.1 - - <span class="o">[</span>26/Sep/2024:07:33:26 +0000] <span class="s2">"GET / HTTP/1.1"</span> 200 397 <span class="s2">"-"</span> <span class="s2">"curl/8.7.1"</span>
  ::ffff:172.23.0.1 - - <span class="o">[</span>26/Sep/2024:07:33:26 +0000] <span class="s2">"GET / HTTP/1.1"</span> 200 397 <span class="s2">"-"</span> <span class="s2">"curl/8.7.1"</span>
</code></pre></div>        </div>
        <ul>
          <li><code class="language-plaintext highlighter-rouge">kubectl logs -l app=deploy-websrv -f</code>로 확인시 외부 클라이언트인 172.23.0.1이 보존되는 것을 확인 할 수 있습니다.</li>
        </ul>
      </li>
      <li>이렇게 동작하는 이유를 iptables 룰을 통해 확인해보겠습니다.
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 컨트롤플레인 노드 - iptables 분석 &lt;&lt; 정책 확인 : 아래 정책 내용은 핵심적인 룰(rule)만 표시했습니다!</span>
<span class="c"># (예시) 파드가 배포되어 있는 노드1에서 확인했습니다</span>
    
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-worker bash
<span class="nt">---------------------------------------</span>
    
<span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span>
<span class="c"># $ iptables -t nat -S | grep &lt;NodePort&gt;</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span> | <span class="nb">grep </span>31177
<span class="c"># =&gt; -A KUBE-NODEPORTS -p tcp -m comment --comment "default/svc-nodeport:svc-webport" -m tcp --dport 31177 -j KUBE-EXT-VTR7MTHHNMFZ3OFS</span>
    
<span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span> | <span class="nb">grep</span> <span class="s1">'A KUBE-EXT-VTR7MTHHNMFZ3OFS'</span>
<span class="c"># =&gt; -A KUBE-EXT-VTR7MTHHNMFZ3OFS -s 10.10.0.0/16 -m comment --comment "pod traffic for default/svc-nodeport:svc-webport external destinations" -j KUBE-SVC-VTR7MTHHNMFZ3OFS</span>
<span class="c">#    -A KUBE-EXT-VTR7MTHHNMFZ3OFS -m comment --comment "masquerade LOCAL traffic for default/svc-nodeport:svc-webport external destinations" -m addrtype --src-type LOCAL -j KUBE-MARK-MASQ</span>
<span class="c">#    -A KUBE-EXT-VTR7MTHHNMFZ3OFS -m comment --comment "route LOCAL traffic for default/svc-nodeport:svc-webport external destinations" -m addrtype --src-type LOCAL -j KUBE-SVC-VTR7MTHHNMFZ3OFS</span>
<span class="c">#    -A KUBE-EXT-VTR7MTHHNMFZ3OFS -j KUBE-SVL-VTR7MTHHNMFZ3OFS</span>
    
<span class="c"># 실습 환경에서는 아래처럼 2개의 파드 중 자신의 노드에 생성된 파드 1개만 DNAT 연결됨</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span> | <span class="nb">grep</span> <span class="s1">'A KUBE-SVL-VTR7MTHHNMFZ3OFS'</span>
<span class="c"># =&gt; -A KUBE-SVL-VTR7MTHHNMFZ3OFS -m comment --comment "default/svc-nodeport:svc-webport -&gt; 10.10.4.5:8080" -j KUBE-SEP-COBCKEECYTEF2ZXK</span>
    
<span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span> | <span class="nb">grep</span> <span class="s1">'A KUBE-SEP-COBCKEECYTEF2ZXK'</span>
<span class="c"># =&gt; -A KUBE-SEP-COBCKEECYTEF2ZXK -s 10.10.4.5/32 -m comment --comment "default/svc-nodeport:svc-webport" -j KUBE-MARK-MASQ</span>
<span class="c">#    -A KUBE-SEP-COBCKEECYTEF2ZXK -p tcp -m comment --comment "default/svc-nodeport:svc-webport" -m tcp -j DNAT --to-destination 10.10.4.5:8080</span>
    
<span class="nv">$ </span><span class="nb">exit</span>
<span class="c"># ---------------------------------------</span>
</code></pre></div>        </div>
        <ul>
          <li>정책을 확인해보면 <code class="language-plaintext highlighter-rouge">externalTrafficPolicy: Local</code> 설정 전에는 MASQUERADE로 SNAT 되었지만, 설정 후에는 DNAT으로 바로 전달되는 것을 확인할 수 있습니다.</li>
          <li>SNAT 되지 않았기 때문에 클라이언트의 IP가 그대로 전달되어 파드에서 확인할 수 있습니다.</li>
        </ul>
      </li>
      <li>서비스(NodePort, externalTrafficPolicy: Local) 생성 시 iptables 규칙(KUBE-SVL-#)이 모든 노드에 추가되는지 확인해보겠습니다.
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 컨트롤 플레인에는 파드가 없으므로 결과가 없습니다.</span>
<span class="nv">$ </span>docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-control-plane iptables <span class="nt">-t</span> nat <span class="nt">-S</span> | <span class="nb">grep</span> <span class="s1">'A KUBE-SVL-VTR7MTHHNMFZ3OFS'</span>
<span class="c"># =&gt; (공백)</span>
    
<span class="c"># 각 노드에 확인해보겠습니다.</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>control-plane worker worker2 worker3<span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node myk8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> docker <span class="nb">exec</span> <span class="nt">-it</span> myk8s-<span class="nv">$i</span> iptables <span class="nt">-t</span> nat <span class="nt">-S</span> | <span class="nb">grep</span> <span class="s1">'A KUBE-SVL-VTR7MTHHNMFZ3OFS'</span><span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node myk8s-control-plane &lt;&lt;</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node myk8s-worker &lt;&lt;</span>
<span class="c">#    -A KUBE-SVL-VTR7MTHHNMFZ3OFS -m comment --comment "default/svc-nodeport:svc-webport -&gt; 10.10.4.5:8080" -j KUBE-SEP-COBCKEECYTEF2ZXK</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node myk8s-worker2 &lt;&lt;</span>
<span class="c">#    -A KUBE-SVL-VTR7MTHHNMFZ3OFS -m comment --comment "default/svc-nodeport:svc-webport -&gt; 10.10.1.6:8080" -j KUBE-SEP-ABUS75FNO53OAK6G</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node myk8s-worker3 &lt;&lt;</span>
</code></pre></div>        </div>
        <ul>
          <li>파드가 있는 worker, worker2 노드에만 iptables 규칙이 추가되어 있음을 확인할 수 있습니다.</li>
        </ul>
      </li>
      <li>NodePort의 부족한 점
        <ul>
          <li>외부에서 노드의 IP와 포트로 직접 접속이 필요합니다.</li>
          <li>따라서 내부망이 외부에 공개(라우팅 가능)되어 보안에 취약합니다.
            <ul>
              <li>=&gt; <strong>LoadBalancer 서비스</strong> 타입으로 외부 공개 최소화 가능</li>
            </ul>
          </li>
          <li>클라이언트 IP 보존을 위해서, <code class="language-plaintext highlighter-rouge">externalTrafficPolicy: local</code>를 사용하면 파드가 없는 노드 IP로 NodePort 접속 시 실패하게 됩니다.
            <ul>
              <li>=&gt; <strong>LoadBalancer 서비스</strong>에서 헬스체크(Probe) 로 대응 가능</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h4 id="파드간-속도-측정">파드간 속도 측정</h4>

<ul>
  <li>이번 실습에서는 iperf3를 사용해서 파드간 속도를 측정해보겠습니다.</li>
  <li>iperf3는 네트워크 대역폭을 측정하는 도구로, 서버와 클라이언트로 나뉘어 서버는 대역폭을 제공하고 클라이언트는 대역폭을 측정합니다. TCP와 UDP, SCTP를 지원합니다.</li>
  <li>iperf3의 기본 사용법을 살펴 보겠습니다.
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># iperf3 설치 </span>
<span class="c"># macOS 인 경우</span>
<span class="nv">$ </span>brew <span class="nb">install </span>iperf3
<span class="c"># ubuntu 등 debian 계열인 경우 </span>
<span class="nv">$ </span><span class="nb">sudo </span>apt <span class="nb">install </span>iperf3 <span class="nt">-y</span>
  
<span class="c"># iperf3 테스트 1 : TCP 5201, 측정시간 10초</span>
<span class="nv">$ </span>iperf3 <span class="nt">-s</span> <span class="c"># 서버모드 실행</span>
<span class="c"># =&gt; -----------------------------------------------------------</span>
<span class="c">#    Server listening on 5201</span>
<span class="c">#    -----------------------------------------------------------</span>
<span class="c">#    Accepted connection from 127.0.0.1, port 40142</span>
<span class="c">#    [  5] local 127.0.0.1 port 5201 connected to 127.0.0.1 port 40154</span>
<span class="c">#    [ ID] Interval           Transfer     Bitrate</span>
<span class="c">#    [  5]   0.00-1.00   sec  7.11 GBytes  61.1 Gbits/sec</span>
<span class="c">#    [  5]   1.00-2.00   sec  8.03 GBytes  68.9 Gbits/sec</span>
<span class="c">#    [  5]   2.00-3.00   sec  7.53 GBytes  64.7 Gbits/sec</span>
<span class="c">#    [  5]   3.00-4.00   sec  7.73 GBytes  66.4 Gbits/sec</span>
<span class="c">#    [  5]   4.00-5.00   sec  7.64 GBytes  65.6 Gbits/sec</span>
<span class="c">#    [  5]   5.00-6.00   sec  7.89 GBytes  67.8 Gbits/sec</span>
<span class="c">#    [  5]   6.00-7.00   sec  7.95 GBytes  68.3 Gbits/sec</span>
<span class="c">#    [  5]   7.00-8.00   sec  7.78 GBytes  66.9 Gbits/sec</span>
<span class="c">#    [  5]   8.00-9.00   sec  7.91 GBytes  67.9 Gbits/sec</span>
<span class="c">#    [  5]   9.00-10.00  sec  7.64 GBytes  65.6 Gbits/sec</span>
<span class="c">#    [  5]  10.00-10.05  sec   384 MBytes  66.0 Gbits/sec</span>
<span class="c">#    - - - - - - - - - - - - - - - - - - - - - - - - -</span>
<span class="c">#    [ ID] Interval           Transfer     Bitrate</span>
<span class="c">#    [  5]   0.00-10.05  sec  77.6 GBytes  66.3 Gbits/sec                  receiver</span>
<span class="nv">$ </span>iperf3 <span class="nt">-c</span> 127.0.0.1 <span class="c"># 다른 터미널에서 클라이언트모드 실행</span>
<span class="c"># =&gt; Connecting to host 127.0.0.1, port 5201</span>
<span class="c">#    [  5] local 127.0.0.1 port 40154 connected to 127.0.0.1 port 5201</span>
<span class="c">#    [ ID] Interval           Transfer     Bitrate         Retr  Cwnd</span>
<span class="c">#    [  5]   0.00-1.00   sec  7.48 GBytes  64.2 Gbits/sec    8   2.69 MBytes</span>
<span class="c">#    ...</span>
<span class="c">#    [  5]   9.00-10.00  sec  7.72 GBytes  66.3 Gbits/sec    1   3.06 MBytes</span>
<span class="c">#    - - - - - - - - - - - - - - - - - - - - - - - - -</span>
<span class="c">#    [ ID] Interval           Transfer     Bitrate         Retr</span>
<span class="c">#    [  5]   0.00-10.00  sec  77.6 GBytes  66.6 Gbits/sec   53             sender</span>
<span class="c">#    [  5]   0.00-10.05  sec  77.6 GBytes  66.3 Gbits/sec                  receiver</span>
  
<span class="c"># iperf3 테스트 2 : TCP 80, 측정시간 5초</span>
<span class="nv">$ </span>iperf3 <span class="nt">-s</span> <span class="nt">-p</span> 80
<span class="nv">$ </span>iperf3 <span class="nt">-c</span> 127.0.0.1 <span class="nt">-p</span> 80 <span class="nt">-t</span> 5
  
<span class="c"># iperf3 테스트 3 : UDP 사용, 역방향 모드(-R)</span>
<span class="nv">$ </span>iperf3 <span class="nt">-s</span> 
<span class="nv">$ </span>iperf3 <span class="nt">-c</span> 127.0.0.1 <span class="nt">-u</span> <span class="nt">-b</span> 100G
  
<span class="c"># iperf3 테스트 4 : 역방향 모드(-R) =&gt; 서버에서 클라이언트로 전송할때 속도를 측정합니다.  </span>
<span class="nv">$ </span>iperf3 <span class="nt">-s</span> 
<span class="nv">$ </span>iperf3 <span class="nt">-c</span> 127.0.0.1 <span class="nt">-R</span>
  
<span class="c"># iperf3 테스트 5 : 쌍방향 모드(-R)</span>
<span class="nv">$ </span>iperf3 <span class="nt">-s</span> 
<span class="nv">$ </span>iperf3 <span class="nt">-c</span> 127.0.0.1 <span class="nt">--bidir</span>
  
<span class="c"># iperf3 테스트 6 : TCP 다중 스트림(30개), -P(number of parallel client streams to run)</span>
<span class="nv">$ </span>iperf3 <span class="nt">-s</span> 
<span class="nv">$ </span>iperf3 <span class="nt">-c</span> 127.0.0.1 <span class="nt">-P</span> 2 <span class="nt">-t</span> 30
</code></pre></div>    </div>
  </li>
  <li>쿠버네티스 환경에서 속도 측정 테스트해보겠습니다.
    <ul>
      <li>테스트 환경 배포
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 배포</span>
<span class="nv">$ </span>kubectl apply <span class="nt">-f</span> https://raw.githubusercontent.com/gasida/PKOS/main/aews/k8s-iperf3.yaml
    
<span class="c"># 확인 : 서버와 클라이언트가 다른 워커노드에 배포되었는지 확인</span>
<span class="nv">$ </span>kubectl get deploy,svc,pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                            READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS      IMAGES                    SELECTOR</span>
<span class="c">#    deployment.apps/iperf3-client   0/1     1            0           5s    iperf3-client   networkstatic/iperf3      app=iperf3-client</span>
<span class="c">#    deployment.apps/iperf3-server   0/1     1            0           5s    iperf3-server   networkstatic/iperf3      app=iperf3-server</span>
<span class="c">#    </span>
<span class="c">#    NAME                    TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)             AGE    SELECTOR</span>
<span class="c">#    service/iperf3-server   ClusterIP   10.200.1.166   &lt;none&gt;        5201/TCP,5201/UDP   5s     app=iperf3-server</span>
<span class="c">#    </span>
<span class="c">#    NAME                                 READY   STATUS              RESTARTS   AGE    IP          NODE                  NOMINATED NODE   READINESS GATES</span>
<span class="c">#    pod/iperf3-client-598b85fd6b-tq5xg   0/1     ContainerCreating   0          5s     &lt;none&gt;      myk8s-worker3         &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    pod/iperf3-server-688df6d56f-hlhrm   0/1     ContainerCreating   0          5s     &lt;none&gt;      myk8s-worker          &lt;none&gt;           &lt;none&gt;</span>
    
<span class="c"># 서버 파드 로그 확인 : 기본 5201 포트 Listen</span>
<span class="nv">$ </span>kubectl logs <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>iperf3-server <span class="nt">-f</span>
</code></pre></div>        </div>
      </li>
      <li>TCP 5201, 측정시간 5초
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 클라이언트 파드에서 아래 명령 실행</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> deploy/iperf3-client <span class="nt">--</span> iperf3 <span class="nt">-c</span> iperf3-server <span class="nt">-t</span> 5
<span class="c"># =&gt; Connecting to host iperf3-server, port 5201</span>
<span class="c">#    [  5] local 10.10.2.9 port 54972 connected to 10.200.1.166 port 5201</span>
<span class="c">#    [ ID] Interval           Transfer     Bitrate         Retr  Cwnd</span>
<span class="c">#    [  5]   0.00-1.00   sec  4.68 GBytes  40.2 Gbits/sec  3333   1.07 MBytes</span>
<span class="c">#    [  5]   1.00-2.00   sec  4.87 GBytes  41.8 Gbits/sec  1293   1.09 MBytes</span>
<span class="c">#    [  5]   2.00-3.00   sec  4.86 GBytes  41.8 Gbits/sec  1020   1.11 MBytes</span>
<span class="c">#    [  5]   3.00-4.00   sec  4.85 GBytes  41.7 Gbits/sec  590   1.21 MBytes</span>
<span class="c">#    [  5]   4.00-5.00   sec  4.93 GBytes  42.4 Gbits/sec  988   1.27 MBytes</span>
<span class="c">#    - - - - - - - - - - - - - - - - - - - - - - - - -</span>
<span class="c">#    [ ID] Interval           Transfer     Bitrate         Retr</span>
<span class="c">#    [  5]   0.00-5.00   sec  24.2 GBytes  41.6 Gbits/sec  7224             sender</span>
<span class="c">#    [  5]   0.00-5.00   sec  24.2 GBytes  41.6 Gbits/sec                  receiver</span>
    
<span class="c"># 서버 파드 로그 확인 : 기본 5201 포트 Listen</span>
<span class="nv">$ </span>kubectl logs <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>iperf3-server <span class="nt">-f</span>
<span class="c"># =&gt; -----------------------------------------------------------</span>
<span class="c">#    Server listening on 5201 (test #1)</span>
<span class="c">#    -----------------------------------------------------------</span>
<span class="c">#    Accepted connection from 10.10.2.9, port 54962</span>
<span class="c">#    [  5] local 10.10.4.6 port 5201 connected to 10.10.2.9 port 54972</span>
<span class="c">#    [ ID] Interval           Transfer     Bitrate</span>
<span class="c">#    [  5]   0.00-1.00   sec  4.67 GBytes  40.1 Gbits/sec</span>
<span class="c">#    [  5]   1.00-2.00   sec  4.87 GBytes  41.8 Gbits/sec</span>
<span class="c">#    [  5]   2.00-3.00   sec  4.86 GBytes  41.8 Gbits/sec</span>
<span class="c">#    [  5]   3.00-4.00   sec  4.85 GBytes  41.7 Gbits/sec</span>
<span class="c">#    [  5]   4.00-5.00   sec  4.93 GBytes  42.4 Gbits/sec</span>
<span class="c">#    [  5]   5.00-5.00   sec   384 KBytes  41.4 Gbits/sec</span>
<span class="c">#    - - - - - - - - - - - - - - - - - - - - - - - - -</span>
<span class="c">#    [ ID] Interval           Transfer     Bitrate</span>
<span class="c">#    [  5]   0.00-5.00   sec  24.2 GBytes  41.6 Gbits/sec                  receiver</span>
</code></pre></div>        </div>
      </li>
      <li>UDP 사용, 역방향 모드(-R)
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 클라이언트 파드에서 아래 명령 실행</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> deploy/iperf3-client <span class="nt">--</span> iperf3 <span class="nt">-c</span> iperf3-server <span class="nt">-u</span> <span class="nt">-b</span> 20G
<span class="c"># =&gt; Connecting to host iperf3-server, port 5201</span>
<span class="c">#    [  5] local 10.10.2.9 port 41928 connected to 10.200.1.166 port 5201</span>
<span class="c">#    [ ID] Interval           Transfer     Bitrate         Total Datagrams</span>
<span class="c">#    [  5]   0.00-1.00   sec   161 MBytes  1.35 Gbits/sec  116453</span>
<span class="c">#    [  5]   1.00-2.00   sec   187 MBytes  1.57 Gbits/sec  135745</span>
<span class="c">#    [  5]   2.00-3.00   sec   163 MBytes  1.36 Gbits/sec  117693</span>
<span class="c">#    [  5]   3.00-4.00   sec   220 MBytes  1.84 Gbits/sec  159109</span>
<span class="c">#    [  5]   4.00-5.00   sec   168 MBytes  1.41 Gbits/sec  121705</span>
<span class="c">#    [  5]   5.00-6.00   sec   183 MBytes  1.54 Gbits/sec  132730</span>
<span class="c">#    [  5]   6.00-7.00   sec   184 MBytes  1.54 Gbits/sec  133267</span>
<span class="c">#    [  5]   7.00-8.00   sec   158 MBytes  1.32 Gbits/sec  114073</span>
<span class="c">#    [  5]   8.00-9.00   sec   171 MBytes  1.44 Gbits/sec  124005</span>
<span class="c">#    [  5]   9.00-10.00  sec   160 MBytes  1.35 Gbits/sec  116175</span>
<span class="c">#    - - - - - - - - - - - - - - - - - - - - - - - - -</span>
<span class="c">#    [ ID] Interval           Transfer     Bitrate         Jitter    Lost/Total Datagrams</span>
<span class="c">#    [  5]   0.00-10.00  sec  1.71 GBytes  1.47 Gbits/sec  0.000 ms  0/1270955 (0%)  sender</span>
<span class="c">#    [  5]   0.00-10.00  sec  1.68 GBytes  1.44 Gbits/sec  0.008 ms  28438/1270955 (2.2%)  receiver</span>
    
<span class="c"># 서버 파드 로그 확인 : 기본 5201 포트 Listen</span>
<span class="nv">$ </span>kubectl logs <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>iperf3-server <span class="nt">-f</span>
<span class="c"># =&gt; -----------------------------------------------------------</span>
<span class="c">#    Server listening on 5201 (test #3)</span>
<span class="c">#    -----------------------------------------------------------</span>
<span class="c">#    Accepted connection from 10.10.2.9, port 48546</span>
<span class="c">#    [  5] local 10.10.4.6 port 5201 connected to 10.10.2.9 port 41928</span>
<span class="c">#    [ ID] Interval           Transfer     Bitrate         Jitter    Lost/Total Datagrams</span>
<span class="c">#    [  5]   0.00-1.00   sec   158 MBytes  1.33 Gbits/sec  0.011 ms  2000/116449 (1.7%)</span>
<span class="c">#    [  5]   1.00-2.00   sec   180 MBytes  1.51 Gbits/sec  0.009 ms  5401/135743 (4%)</span>
<span class="c">#    [  5]   2.00-3.00   sec   161 MBytes  1.35 Gbits/sec  0.011 ms  1241/117696 (1.1%)</span>
<span class="c">#    [  5]   3.00-4.00   sec   215 MBytes  1.81 Gbits/sec  0.009 ms  3132/159105 (2%)</span>
<span class="c">#    [  5]   4.00-5.00   sec   165 MBytes  1.39 Gbits/sec  0.007 ms  2073/121704 (1.7%)</span>
<span class="c">#    [  5]   5.00-6.00   sec   179 MBytes  1.51 Gbits/sec  0.008 ms  2758/132731 (2.1%)</span>
<span class="c">#    [  5]   6.00-7.00   sec   181 MBytes  1.52 Gbits/sec  0.009 ms  2397/133243 (1.8%)</span>
<span class="c">#    [  5]   7.00-8.00   sec   153 MBytes  1.28 Gbits/sec  0.007 ms  3612/114097 (3.2%)</span>
<span class="c">#    [  5]   8.00-9.00   sec   166 MBytes  1.39 Gbits/sec  0.009 ms  3707/124005 (3%)</span>
<span class="c">#    [  5]   9.00-10.00  sec   158 MBytes  1.32 Gbits/sec  0.009 ms  2117/116179 (1.8%)</span>
<span class="c">#    [  5]  10.00-10.00  sec  4.24 KBytes   656 Mbits/sec  0.008 ms  0/3 (0%)</span>
<span class="c">#    - - - - - - - - - - - - - - - - - - - - - - - - -</span>
<span class="c">#    [ ID] Interval           Transfer     Bitrate         Jitter    Lost/Total Datagrams</span>
<span class="c">#    [  5]   0.00-10.00  sec  1.68 GBytes  1.44 Gbits/sec  0.008 ms  28438/1270955 (2.2%)  receiver</span>
</code></pre></div>        </div>
      </li>
      <li>TCP, 쌍방향 모드(-R)
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 클라이언트 파드에서 아래 명령 실행</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> deploy/iperf3-client <span class="nt">--</span> iperf3 <span class="nt">-c</span> iperf3-server <span class="nt">-t</span> 5 <span class="nt">--bidir</span>
<span class="c"># =&gt; Connecting to host iperf3-server, port 5201</span>
<span class="c">#    [  5] local 10.10.2.9 port 59852 connected to 10.200.1.166 port 5201</span>
<span class="c">#    [  7] local 10.10.2.9 port 59860 connected to 10.200.1.166 port 5201</span>
<span class="c">#    [ ID][Role] Interval           Transfer     Bitrate         Retr  Cwnd</span>
<span class="c">#    [  5][TX-C]   0.00-1.00   sec  3.85 GBytes  33.0 Gbits/sec  2249   1.55 MBytes</span>
<span class="c">#    [  7][RX-C]   0.00-1.00   sec   553 MBytes  4.64 Gbits/sec</span>
<span class="c">#    [  5][TX-C]   1.00-2.00   sec  1.77 GBytes  15.2 Gbits/sec  3105   1.07 MBytes</span>
<span class="c">#    [  7][RX-C]   1.00-2.00   sec  2.73 GBytes  23.4 Gbits/sec</span>
<span class="c">#    [  5][TX-C]   2.00-3.00   sec  1.64 GBytes  14.1 Gbits/sec  639    850 KBytes</span>
<span class="c">#    [  7][RX-C]   2.00-3.00   sec  2.93 GBytes  25.2 Gbits/sec</span>
<span class="c">#    [  5][TX-C]   3.00-4.00   sec  2.07 GBytes  17.8 Gbits/sec    0    853 KBytes</span>
<span class="c">#    [  7][RX-C]   3.00-4.00   sec  2.48 GBytes  21.3 Gbits/sec</span>
<span class="c">#    [  5][TX-C]   4.00-5.00   sec  1.22 GBytes  10.5 Gbits/sec    2    877 KBytes</span>
<span class="c">#    [  7][RX-C]   4.00-5.00   sec  3.25 GBytes  27.9 Gbits/sec</span>
<span class="c">#    - - - - - - - - - - - - - - - - - - - - - - - - -</span>
<span class="c">#    [ ID][Role] Interval           Transfer     Bitrate         Retr</span>
<span class="c">#    [  5][TX-C]   0.00-5.00   sec  10.5 GBytes  18.1 Gbits/sec  5995             sender</span>
<span class="c">#    [  5][TX-C]   0.00-5.00   sec  10.5 GBytes  18.1 Gbits/sec                  receiver</span>
<span class="c">#    [  7][RX-C]   0.00-5.00   sec  11.9 GBytes  20.5 Gbits/sec  9201             sender</span>
<span class="c">#    [  7][RX-C]   0.00-5.00   sec  11.9 GBytes  20.5 Gbits/sec                  receiver</span>
    
<span class="c"># 서버 파드 로그 확인 : 기본 5201 포트 Listen</span>
<span class="nv">$ </span>kubectl logs <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>iperf3-server <span class="nt">-f</span>
<span class="c"># =&gt; -----------------------------------------------------------</span>
<span class="c">#    Server listening on 5201 (test #2)</span>
<span class="c">#    -----------------------------------------------------------</span>
<span class="c">#    Accepted connection from 10.10.2.9, port 59836</span>
<span class="c">#    [  5] local 10.10.4.6 port 5201 connected to 10.10.2.9 port 59852</span>
<span class="c">#    [  8] local 10.10.4.6 port 5201 connected to 10.10.2.9 port 59860</span>
<span class="c">#    [ ID][Role] Interval           Transfer     Bitrate         Retr  Cwnd</span>
<span class="c">#    [  5][RX-S]   0.00-1.00   sec  3.85 GBytes  33.0 Gbits/sec</span>
<span class="c">#    [  8][TX-S]   0.00-1.00   sec   561 MBytes  4.70 Gbits/sec   59   1.02 MBytes</span>
<span class="c">#    [  5][RX-S]   1.00-2.00   sec  1.77 GBytes  15.2 Gbits/sec</span>
<span class="c">#    [  8][TX-S]   1.00-2.00   sec  2.73 GBytes  23.5 Gbits/sec  2468   1.09 MBytes</span>
<span class="c">#    [  5][RX-S]   2.00-3.00   sec  1.63 GBytes  14.0 Gbits/sec</span>
<span class="c">#    [  8][TX-S]   2.00-3.00   sec  2.92 GBytes  25.1 Gbits/sec  3327   1.10 MBytes</span>
<span class="c">#    [  5][RX-S]   3.00-4.00   sec  2.08 GBytes  17.9 Gbits/sec</span>
<span class="c">#    [  8][TX-S]   3.00-4.00   sec  2.49 GBytes  21.4 Gbits/sec  2315   1.13 MBytes</span>
<span class="c">#    [  5][RX-S]   4.00-5.00   sec  1.22 GBytes  10.5 Gbits/sec</span>
<span class="c">#    [  8][TX-S]   4.00-5.00   sec  3.25 GBytes  27.9 Gbits/sec  1032   1.16 MBytes</span>
<span class="c">#    [  5][RX-S]   5.00-5.00   sec   768 KBytes  27.6 Gbits/sec</span>
<span class="c">#    [  8][TX-S]   5.00-5.00   sec  1.25 MBytes  41.3 Gbits/sec    0   1.16 MBytes</span>
<span class="c">#    - - - - - - - - - - - - - - - - - - - - - - - - -</span>
<span class="c">#    [ ID][Role] Interval           Transfer     Bitrate         Retr</span>
<span class="c">#    [  5][RX-S]   0.00-5.00   sec  10.5 GBytes  18.1 Gbits/sec                  receiver</span>
<span class="c">#    [  8][TX-S]   0.00-5.00   sec  11.9 GBytes  20.5 Gbits/sec  9201             sender</span>
</code></pre></div>        </div>
      </li>
      <li>TCP 다중 스트림(30개), -P(number of parallel client streams to run)
        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 클라이언트 파드에서 아래 명령 실행</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> deploy/iperf3-client <span class="nt">--</span> iperf3 <span class="nt">-c</span> iperf3-server <span class="nt">-t</span> 10 <span class="nt">-P</span> 2
<span class="c"># =&gt; [  5] local 10.10.2.9 port 41976 connected to 10.200.1.166 port 5201</span>
<span class="c">#    [  7] local 10.10.2.9 port 41982 connected to 10.200.1.166 port 5201</span>
<span class="c">#    [ ID] Interval           Transfer     Bitrate         Retr  Cwnd</span>
<span class="c">#    [  5]   0.00-1.00   sec  2.87 GBytes  24.7 Gbits/sec  822    570 KBytes</span>
<span class="c">#    [  7]   0.00-1.00   sec  2.88 GBytes  24.7 Gbits/sec  159    576 KBytes</span>
<span class="c">#    [SUM]   0.00-1.00   sec  5.75 GBytes  49.4 Gbits/sec  981</span>
<span class="c">#    - - - - - - - - - - - - - - - - - - - - - - - - -</span>
<span class="c">#    ...</span>
<span class="c">#    - - - - - - - - - - - - - - - - - - - - - - - - -</span>
<span class="c">#    [ ID] Interval           Transfer     Bitrate         Retr</span>
<span class="c">#    [  5]   0.00-10.00  sec  29.2 GBytes  25.1 Gbits/sec  3825             sender</span>
<span class="c">#    [  5]   0.00-10.00  sec  29.2 GBytes  25.1 Gbits/sec                  receiver</span>
<span class="c">#    [  7]   0.00-10.00  sec  29.2 GBytes  25.1 Gbits/sec  2063             sender</span>
<span class="c">#    [  7]   0.00-10.00  sec  29.2 GBytes  25.0 Gbits/sec                  receiver</span>
<span class="c">#    [SUM]   0.00-10.00  sec  58.3 GBytes  50.1 Gbits/sec  5888             sender</span>
<span class="c">#    [SUM]   0.00-10.00  sec  58.3 GBytes  50.1 Gbits/sec                  receiver</span>
    
<span class="c"># 서버 파드 로그 확인 : 기본 5201 포트 Listen</span>
<span class="nv">$ </span>kubectl logs <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>iperf3-server <span class="nt">-f</span>
<span class="c"># =&gt; -----------------------------------------------------------</span>
<span class="c">#    Server listening on 5201 (test #4)</span>
<span class="c">#    -----------------------------------------------------------</span>
<span class="c">#    Accepted connection from 10.10.2.9, port 41962</span>
<span class="c">#    [  5] local 10.10.4.6 port 5201 connected to 10.10.2.9 port 41976</span>
<span class="c">#    [  8] local 10.10.4.6 port 5201 connected to 10.10.2.9 port 41982</span>
<span class="c">#    [ ID] Interval           Transfer     Bitrate</span>
<span class="c">#    [  5]   0.00-1.00   sec  2.87 GBytes  24.6 Gbits/sec</span>
<span class="c">#    [  8]   0.00-1.00   sec  2.87 GBytes  24.7 Gbits/sec</span>
<span class="c">#    [SUM]   0.00-1.00   sec  5.74 GBytes  49.3 Gbits/sec</span>
<span class="c">#    - - - - - - - - - - - - - - - - - - - - - - - - -</span>
<span class="c">#    ...</span>
<span class="c">#    - - - - - - - - - - - - - - - - - - - - - - - - -</span>
<span class="c">#    [ ID] Interval           Transfer     Bitrate</span>
<span class="c">#    [  5]   0.00-10.00  sec  29.2 GBytes  25.1 Gbits/sec                  receiver</span>
<span class="c">#    [  8]   0.00-10.00  sec  29.2 GBytes  25.0 Gbits/sec                  receiver</span>
<span class="c">#    [SUM]   0.00-10.00  sec  58.3 GBytes  50.1 Gbits/sec                  receiver</span>
</code></pre></div>        </div>
      </li>
      <li>실습결과 <code class="language-plaintext highlighter-rouge">iperf3 -c 127.0.0.1 -t 5</code>로 측정하였을때는 호스트에서는 67.1 Gbits/sec 였던것에 반해, 쿠버네티스를 통하면 41.6 Gbits/sec로 측정됩니다.
        <ul>
          <li>쿠버네티스도 로컬호스트에서 docker로 실행되는데 kube-proxy, iptables 포워딩 등의 오버헤드로 인해 발생하는것 같습니다.</li>
        </ul>
      </li>
      <li>UDP의 경우에도 <code class="language-plaintext highlighter-rouge">iperf3 -c 127.0.0.1 -u -b 20G</code>로 측정했을때 호스트에서는 20.0 Gbits/sec가 나오는데, 쿠버네티스를 통하면 1.41 Gbits/sec로 측정됩니다.
        <ul>
          <li>UDP는 더 오버헤드가 심한데 원인을 찾아봐야 할것 같습니다.</li>
        </ul>
      </li>
      <li>이번 실습을 통해 다양한 네트워크 CNI, 설정등을 변경해가며 최적의 설정을 찾아보는 방법을 배워보았습니다.</li>
    </ul>
  </li>
</ul>

<hr />

<h2 id="마치며">마치며</h2>

<p>실습을 할수록 점점 더 iptables과 친숙해지는것 같습니다.
눈에 익은게 많아지고는 있지만, nftables라던지 ipvs라던지, eBPF라던지 아직 갈길이 멉니다. 😅</p>

<p>새삼스레 스터디를 진행하시는 가시다님을 비롯해서 조력자 분들도 정말 대단하다는 생각이 듭니다.
그리고 내용들 및 그림들이 가시다님이 집필하신 책에서 많이 가져왔습니다.
책이 출판되면 꼭 구매해서 읽어보겠습니다! 
이제 스터디도 중반을 향해 달려가고 있습니다. 남은 날들도 스터디에서 생존할 수 있기를 바랍니다. :pray:</p>]]></content><author><name></name></author><category term="kans" /><category term="kubernetes," /><category term="network," /><category term="linux" /><summary type="html"><![CDATA[지난주에 이어 이번주에는 Kubernetes의 Service, 그 중에 ClusterIP, NodePort에 대해 알아보겠습니다.]]></summary></entry></feed>