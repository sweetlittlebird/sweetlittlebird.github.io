<!DOCTYPE html>
<html lang="ko">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>[Cilium] 실습 환경 구성 및 Cilium 설치 | Sweet Little Bird</title>
<meta name="generator" content="Jekyll v4.3.3">
<meta property="og:title" content="[Cilium] 실습 환경 구성 및 Cilium 설치">
<meta property="og:locale" content="ko">
<meta name="description" content="Cilium CNI를 실습하기 위한 환경을 구성하고 Cilium을 설치하는 방법을 알아봅니다.">
<meta property="og:description" content="Cilium CNI를 실습하기 위한 환경을 구성하고 Cilium을 설치하는 방법을 알아봅니다.">
<link rel="canonical" href="https://sweetlittlebird.github.io/posts/2025-07-20-Cilium-Week1/">
<meta property="og:url" content="https://sweetlittlebird.github.io/posts/2025-07-20-Cilium-Week1/">
<meta property="og:site_name" content="Sweet Little Bird">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2025-07-20T00:10:18+09:00">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="[Cilium] 실습 환경 구성 및 Cilium 설치">
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-07-20T00:10:18+09:00","datePublished":"2025-07-20T00:10:18+09:00","description":"Cilium CNI를 실습하기 위한 환경을 구성하고 Cilium을 설치하는 방법을 알아봅니다.","headline":"[Cilium] 실습 환경 구성 및 Cilium 설치","mainEntityOfPage":{"@type":"WebPage","@id":"https://sweetlittlebird.github.io/posts/2025-07-20-Cilium-Week1/"},"url":"https://sweetlittlebird.github.io/posts/2025-07-20-Cilium-Week1/"}</script>
<!-- End Jekyll SEO tag -->

  <link rel="stylesheet" href="/assets/dist/photoswipe.min.css">
  <link rel="stylesheet" href="/assets/dist/main.min.css">
  <link rel="stylesheet" href="/assets/dist/main_dark.min.css" media="(prefers-color-scheme: dark)">
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pretendard/1.3.9/static/pretendard.css" integrity="sha512-NzqTHTrO48HsIamogmIaVhTXoSgRF24Cn+ynrNYrFuKrY0AdDbmcNieiOHsQARS/r0Gax9VwV3/rVMHs3ipUlg==" crossorigin="anonymous" referrerpolicy="no-referrer">

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <!--  <link href="https://fonts.googleapis.com/css2?family=Elsie+Swash+Caps:wght@400;900&display=swap" rel="stylesheet">-->
  <link href="https://fonts.googleapis.com/css2?family=Elsie+Swash+Caps:wght@400;900&amp;family=Milonga&amp;display=swap" rel="stylesheet">

  <link rel="shortcut icon" href="/assets/favicon/favicon.ico" type="image/x-icon">
  <link rel="icon" href="/assets/favicon/favicon.ico" type="image/x-icon">
<link type="application/atom+xml" rel="alternate" href="https://sweetlittlebird.github.io/feed.xml" title="Sweet Little Bird">
</head>
<body class="body--contents">
<header class="site-header" role="banner">

  <div class="wrapper">
<a class="site-title" rel="author" href="/">Sweet Little Bird</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger">
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewbox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"></path>
            </svg>
          </span>
        </label>

        <div class="trigger">
<a class="page-link" href="/about/">소개</a><a class="page-link" href="/posts/">글 목록</a>
</div>
      </nav>
</div>
  
  <span id="scroll-indicator"></span>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">[Cilium] 실습 환경 구성 및 Cilium 설치</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2025-07-20T00:10:18+09:00" itemprop="datePublished">2025년 07월 20일에 작성
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <div class="table-of-content">
      <header>목차</header>
      <ul id="toc" class="section-nav">
<li class="toc-entry toc-h2"><a href="#%EB%93%A4%EC%96%B4%EA%B0%80%EB%A9%B0">들어가며</a></li>
<li class="toc-entry toc-h2">
<a href="#%EC%8B%A4%EC%8A%B5-%ED%99%98%EA%B2%BD-%EA%B5%AC%EC%84%B1">실습 환경 구성</a>
<ul>
<li class="toc-entry toc-h3"><a href="#%EC%8B%A4%EC%8A%B5-%ED%99%98%EA%B2%BD-%EA%B5%AC%EC%84%B1-%EC%A4%80%EB%B9%84">실습 환경 구성 준비</a></li>
<li class="toc-entry toc-h3"><a href="#%EC%8B%A4%EC%8A%B5-%ED%99%98%EA%B2%BD-%EC%86%8C%EA%B0%9C">실습 환경 소개</a></li>
<li class="toc-entry toc-h3">
<a href="#%EC%8B%A4%EC%8A%B5-%ED%99%98%EA%B2%BD-%EB%B0%B0%ED%8F%AC-%ED%8C%8C%EC%9D%BC-%EC%9E%91%EC%84%B1">실습 환경 배포 파일 작성</a>
<ul>
<li class="toc-entry toc-h4"><a href="#vagrantfile">Vagrantfile</a></li>
<li class="toc-entry toc-h4"><a href="#init_cfgsh">init_cfg.sh</a></li>
<li class="toc-entry toc-h4"><a href="#k8s-ctrsh">k8s-ctr.sh</a></li>
<li class="toc-entry toc-h4"><a href="#k8s-wsh">k8s-w.sh</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#%EC%8B%A4%EC%8A%B5-%ED%99%98%EA%B2%BD-%EB%B0%B0%ED%8F%AC">실습 환경 배포</a></li>
</ul>
</li>
<li class="toc-entry toc-h2">
<a href="#flannel-cni">Flannel CNI</a>
<ul>
<li class="toc-entry toc-h3"><a href="#flannel-%EC%86%8C%EA%B0%9C">Flannel 소개</a></li>
<li class="toc-entry toc-h3"><a href="#flannel-%EC%84%A4%EC%B9%98-%EB%B0%8F-%ED%99%95%EC%9D%B8">Flannel 설치 및 확인</a></li>
<li class="toc-entry toc-h3"><a href="#%EC%83%98%ED%94%8C-%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98-%EB%B0%B0%ED%8F%AC-%EB%B0%8F-%ED%99%95%EC%9D%B8">샘플 애플리케이션 배포 및 확인</a></li>
</ul>
</li>
<li class="toc-entry toc-h2">
<a href="#cilium-cni">Cilium CNI</a>
<ul>
<li class="toc-entry toc-h3"><a href="#cilium-cni-%EC%86%8C%EA%B0%9C">Cilium CNI 소개</a></li>
<li class="toc-entry toc-h3">
<a href="#cilium-cni-%EC%84%A4%EC%B9%98">Cilium CNI 설치</a>
<ul>
<li class="toc-entry toc-h4"><a href="#cilium-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%9A%94%EA%B5%AC-%EC%82%AC%ED%95%AD-%ED%99%95%EC%9D%B8---%EA%B3%B5%EC%8B%9D-%EB%AC%B8%EC%84%9C">Cilium 시스템 요구 사항 확인 - 공식 문서</a></li>
<li class="toc-entry toc-h4"><a href="#kube-proxy-%EC%A0%9C%EA%B1%B0">kube-proxy 제거</a></li>
<li class="toc-entry toc-h4"><a href="#cilium-cni-%EC%84%A4%EC%B9%98-with-helm">Cilium CNI 설치 with Helm</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#cilium-%EC%84%A4%EC%B9%98-%ED%99%95%EC%9D%B8">Cilium 설치 확인</a></li>
</ul>
</li>
<li class="toc-entry toc-h2">
<a href="#%ED%86%B5%EC%8B%A0-%ED%99%95%EC%9D%B8">통신 확인</a>
<ul>
<li class="toc-entry toc-h3"><a href="#%EB%85%B8%EB%93%9C%EA%B0%84-%ED%8C%8C%EB%93%9C---%ED%8C%8C%EB%93%9C-%ED%86%B5%EC%8B%A0">노드간 ‘파드 -&gt; 파드’ 통신</a></li>
<li class="toc-entry toc-h3"><a href="#%EB%85%B8%EB%93%9C%EA%B0%84-%ED%8C%8C%EB%93%9C---%EC%84%9C%EB%B9%84%EC%8A%A4-%ED%86%B5%EC%8B%A0">노드간 ‘파드 -&gt; 서비스’ 통신</a></li>
<li class="toc-entry toc-h3"><a href="#cilium-%EC%82%AC%EC%9A%A9%EC%8B%9C-%EC%A3%BC%EC%9D%98%EC%82%AC%ED%95%AD">Cilium 사용시 주의사항</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#%EB%A7%88%EC%B9%98%EB%A9%B0">마치며</a></li>
</ul>
    </div>
    <h2 id="들어가며">들어가며</h2>

<p>오랜만에 다시 스터디를 시작합니다.
이번에도 CloudNet@ 팀에서 진행하는 스터디로 고맙게도 스터디에 참여할 수 있게 되었습니다.
이번 스터디는 Cilium의 공식문서를 기반으로 실습해보는 스터디입니다.
Cilium 한가지 주제로 진행되는 만큼 깊고 진하게 학습할 수 있을것 같아 기대가 됩니다.</p>

<p>첫주차에는 실습 환경을 구성하고 Cilium을 설치하는 방법을 알아보겠습니다.</p>

<hr>

<h2 id="실습-환경-구성">실습 환경 구성</h2>

<h3 id="실습-환경-구성-준비">실습 환경 구성 준비</h3>

<p>저는 MacOS를 사용하고 있기때문에 homebrew를 이용하여 VirtualBox와 Vagrant를 설치하였습니다.</p>

<ul>
  <li>VirtualBox 설치</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install</span> <span class="nt">--cask</span> virtualbox
<span class="c"># =&gt; 🍺  virtualbox was successfully installed!</span>

<span class="nv">$ </span>VBoxManage <span class="nt">--version</span>
<span class="c"># =&gt; 7.1.10r169112</span>
</code></pre></div></div>

<ul>
  <li>Vagrant 설치</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>brew <span class="nb">install</span> <span class="nt">--cask</span> vagrant
<span class="c"># =&gt; 🍺  vagrant was successfully installed!</span>

<span class="nv">$ </span>vagrant version
<span class="c"># =&gt; Installed Version: 2.4.7</span>
<span class="c">#    Latest Version: 2.4.7</span>
<span class="c">#    </span>
<span class="c">#    You're running an up-to-date version of Vagrant!</span>
</code></pre></div></div>

<h3 id="실습-환경-소개">실습 환경 소개</h3>

<p>실습 환경을 도식화하면 다음과 같습니다.</p>

<p><img src="/assets/2025/cilium/w1/20250720_cilium_w1_1.png" alt="img.png" loading="lazy" width="1750" height="614"></p>

<ul>
  <li>배포 가상 머신은 컨트롤플레인인 k8s-ctr, 워커노드 k8s-w1, k8s-w2로 구성되어 있습니다.
    <ul>
      <li>eth0 : 10.0.2.15 (모든 노드가 동일)</li>
      <li>eth1 : 192.168.10.100~102</li>
    </ul>
  </li>
  <li>초기 프로비저닝시 <code class="language-plaintext highlighter-rouge">kubeadm init</code>과 <code class="language-plaintext highlighter-rouge">join</code> 을 실행하여 클러스터를 구성하며, 초기에는 <strong>CNI가 설치되어 있지 않습니다</strong>.</li>
</ul>

<h3 id="실습-환경-배포-파일-작성">실습 환경 배포 파일 작성</h3>

<h4 id="vagrantfile"><strong>Vagrantfile</strong></h4>
<ul>
  <li>가상머신을 정의하고 부팅시 실행할 프로비저닝 설정을 합니다.</li>
</ul>

<div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Variables</span>
<span class="no">K8SV</span> <span class="o">=</span> <span class="s1">'1.33.2-1.1'</span> <span class="c1"># Kubernetes Version : apt list -a kubelet , ex) 1.32.5-1.1</span>
<span class="no">CONTAINERDV</span> <span class="o">=</span> <span class="s1">'1.7.27-1'</span> <span class="c1"># Containerd Version : apt list -a containerd.io , ex) 1.6.33-1</span>
<span class="no">N</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1"># max number of worker nodes</span>

<span class="c1"># Base Image  https://portal.cloud.hashicorp.com/vagrant/discover/bento/ubuntu-24.04</span>
<span class="c1">## Rocky linux Image https://portal.cloud.hashicorp.com/vagrant/discover/rockylinux</span>
<span class="no">BOX_IMAGE</span> <span class="o">=</span> <span class="s2">"bento/ubuntu-24.04"</span>
<span class="no">BOX_VERSION</span> <span class="o">=</span> <span class="s2">"202502.21.0"</span>

<span class="no">Vagrant</span><span class="p">.</span><span class="nf">configure</span><span class="p">(</span><span class="s2">"2"</span><span class="p">)</span> <span class="k">do</span> <span class="o">|</span><span class="n">config</span><span class="o">|</span>
<span class="c1">#-ControlPlane Node</span>
    <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">define</span> <span class="s2">"k8s-ctr"</span> <span class="k">do</span> <span class="o">|</span><span class="n">subconfig</span><span class="o">|</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="no">BOX_IMAGE</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box_version</span> <span class="o">=</span> <span class="no">BOX_VERSION</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provider</span> <span class="s2">"virtualbox"</span> <span class="k">do</span> <span class="o">|</span><span class="n">vb</span><span class="o">|</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--groups"</span><span class="p">,</span> <span class="s2">"/Cilium-Lab"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--nicpromisc2"</span><span class="p">,</span> <span class="s2">"allow-all"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">name</span> <span class="o">=</span> <span class="s2">"k8s-ctr"</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">cpus</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">memory</span> <span class="o">=</span> <span class="mi">2048</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">linked_clone</span> <span class="o">=</span> <span class="kp">true</span>
      <span class="k">end</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">host_name</span> <span class="o">=</span> <span class="s2">"k8s-ctr"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.10.100"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="mi">60000</span><span class="p">,</span> <span class="ss">auto_correct: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">id: </span><span class="s2">"ssh"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">synced_folder</span> <span class="s2">"./"</span><span class="p">,</span> <span class="s2">"/vagrant"</span><span class="p">,</span> <span class="ss">disabled: </span><span class="kp">true</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"init_cfg.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">K8SV</span><span class="p">,</span> <span class="no">CONTAINERDV</span><span class="p">]</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"k8s-ctr.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">N</span> <span class="p">]</span>
    <span class="k">end</span>

<span class="c1">#-Worker Nodes Subnet1</span>
  <span class="p">(</span><span class="mi">1</span><span class="o">..</span><span class="no">N</span><span class="p">).</span><span class="nf">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">i</span><span class="o">|</span>
    <span class="n">config</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">define</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span> <span class="k">do</span> <span class="o">|</span><span class="n">subconfig</span><span class="o">|</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box</span> <span class="o">=</span> <span class="no">BOX_IMAGE</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">box_version</span> <span class="o">=</span> <span class="no">BOX_VERSION</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provider</span> <span class="s2">"virtualbox"</span> <span class="k">do</span> <span class="o">|</span><span class="n">vb</span><span class="o">|</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--groups"</span><span class="p">,</span> <span class="s2">"/Cilium-Lab"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">customize</span> <span class="p">[</span><span class="s2">"modifyvm"</span><span class="p">,</span> <span class="ss">:id</span><span class="p">,</span> <span class="s2">"--nicpromisc2"</span><span class="p">,</span> <span class="s2">"allow-all"</span><span class="p">]</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">name</span> <span class="o">=</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">cpus</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">memory</span> <span class="o">=</span> <span class="mi">1536</span>
        <span class="n">vb</span><span class="p">.</span><span class="nf">linked_clone</span> <span class="o">=</span> <span class="kp">true</span>
      <span class="k">end</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">host_name</span> <span class="o">=</span> <span class="s2">"k8s-w</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"private_network"</span><span class="p">,</span> <span class="ss">ip: </span><span class="s2">"192.168.10.10</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">network</span> <span class="s2">"forwarded_port"</span><span class="p">,</span> <span class="ss">guest: </span><span class="mi">22</span><span class="p">,</span> <span class="ss">host: </span><span class="s2">"6000</span><span class="si">#{</span><span class="n">i</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span> <span class="ss">auto_correct: </span><span class="kp">true</span><span class="p">,</span> <span class="ss">id: </span><span class="s2">"ssh"</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">synced_folder</span> <span class="s2">"./"</span><span class="p">,</span> <span class="s2">"/vagrant"</span><span class="p">,</span> <span class="ss">disabled: </span><span class="kp">true</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"init_cfg.sh"</span><span class="p">,</span> <span class="ss">args: </span><span class="p">[</span> <span class="no">K8SV</span><span class="p">,</span> <span class="no">CONTAINERDV</span><span class="p">]</span>
      <span class="n">subconfig</span><span class="p">.</span><span class="nf">vm</span><span class="p">.</span><span class="nf">provision</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="ss">path: </span><span class="s2">"k8s-w.sh"</span>
    <span class="k">end</span>
  <span class="k">end</span>
<span class="k">end</span>
</code></pre></div></div>

<h4 id="init_cfgsh"><strong>init_cfg.sh</strong></h4>
<ul>
  <li>프로비저닝시 vagrant가 실행할 초기 설정 스크립트입니다. arguments로 Kubernetes 버전과 Containerd 버전등을 받아서 설치합니다.</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>

<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config Start &lt;&lt;&lt;&lt;"</span>

<span class="nb">echo</span> <span class="s2">"[TASK 1] Setting Profile &amp; Change Timezone"</span>
<span class="nb">echo</span> <span class="s1">'alias vi=vim'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s2">"sudo su -"</span> <span class="o">&gt;&gt;</span> /home/vagrant/.bashrc
<span class="nb">ln</span> <span class="nt">-sf</span> /usr/share/zoneinfo/Asia/Seoul /etc/localtime

<span class="nb">echo</span> <span class="s2">"[TASK 2] Disable AppArmor"</span>
systemctl stop ufw <span class="o">&amp;&amp;</span> systemctl disable ufw <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
systemctl stop apparmor <span class="o">&amp;&amp;</span> systemctl disable apparmor <span class="o">&gt;</span>/dev/null 2&gt;&amp;1

<span class="nb">echo</span> <span class="s2">"[TASK 3] Disable and turn off SWAP"</span>
swapoff <span class="nt">-a</span> <span class="o">&amp;&amp;</span> <span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'/swap/s/^/#/'</span> /etc/fstab

<span class="nb">echo</span> <span class="s2">"[TASK 4] Install Packages"</span>
apt update <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
apt-get <span class="nb">install </span>apt-transport-https ca-certificates curl gpg <span class="nt">-y</span> <span class="nt">-qq</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1

<span class="c"># Download the public signing key for the Kubernetes package repositories.</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> <span class="nt">-m</span> 755 /etc/apt/keyrings
<span class="nv">K8SMMV</span><span class="o">=</span><span class="si">$(</span><span class="nb">echo</span> <span class="nv">$1</span> | <span class="nb">sed</span> <span class="nt">-En</span> <span class="s1">'s/^([0-9]+\.[0-9]+)\..*/\1/p'</span><span class="si">)</span>
curl <span class="nt">-fsSL</span> https://pkgs.k8s.io/core:/stable:/v<span class="nv">$K8SMMV</span>/deb/Release.key | <span class="nb">sudo </span>gpg <span class="nt">--dearmor</span> <span class="nt">-o</span> /etc/apt/keyrings/kubernetes-apt-keyring.gpg
<span class="nb">echo</span> <span class="s2">"deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v</span><span class="nv">$K8SMMV</span><span class="s2">/deb/ /"</span> <span class="o">&gt;&gt;</span> /etc/apt/sources.list.d/kubernetes.list
curl <span class="nt">-fsSL</span> https://download.docker.com/linux/ubuntu/gpg <span class="nt">-o</span> /etc/apt/keyrings/docker.asc
<span class="nb">echo</span> <span class="s2">"deb [arch=</span><span class="si">$(</span>dpkg <span class="nt">--print-architecture</span><span class="si">)</span><span class="s2"> signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu </span><span class="si">$(</span><span class="nb">.</span> /etc/os-release <span class="o">&amp;&amp;</span> <span class="nb">echo</span> <span class="s2">"</span><span class="nv">$VERSION_CODENAME</span><span class="s2">"</span><span class="si">)</span><span class="s2"> stable"</span> | <span class="nb">tee</span> /etc/apt/sources.list.d/docker.list <span class="o">&gt;</span> /dev/null

<span class="c"># packets traversing the bridge are processed by iptables for filtering</span>
<span class="nb">echo </span>1 <span class="o">&gt;</span> /proc/sys/net/ipv4/ip_forward
<span class="nb">echo</span> <span class="s2">"net.ipv4.ip_forward = 1"</span> <span class="o">&gt;&gt;</span> /etc/sysctl.d/k8s.conf

<span class="c"># enable br_netfilter for iptables </span>
modprobe br_netfilter
modprobe overlay
<span class="nb">echo</span> <span class="s2">"br_netfilter"</span> <span class="o">&gt;&gt;</span> /etc/modules-load.d/k8s.conf
<span class="nb">echo</span> <span class="s2">"overlay"</span> <span class="o">&gt;&gt;</span> /etc/modules-load.d/k8s.conf

<span class="nb">echo</span> <span class="s2">"[TASK 5] Install Kubernetes components (kubeadm, kubelet and kubectl)"</span>
<span class="c"># Update the apt package index, install kubelet, kubeadm and kubectl, and pin their version</span>
apt update <span class="o">&gt;</span>/dev/null 2&gt;&amp;1

<span class="c"># apt list -a kubelet ; apt list -a containerd.io</span>
apt-get <span class="nb">install</span> <span class="nt">-y</span> <span class="nv">kubelet</span><span class="o">=</span><span class="nv">$1</span> <span class="nv">kubectl</span><span class="o">=</span><span class="nv">$1</span> <span class="nv">kubeadm</span><span class="o">=</span><span class="nv">$1</span> containerd.io<span class="o">=</span><span class="nv">$2</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
apt-mark hold kubelet kubeadm kubectl <span class="o">&gt;</span>/dev/null 2&gt;&amp;1

<span class="c"># containerd configure to default and cgroup managed by systemd</span>
containerd config default <span class="o">&gt;</span> /etc/containerd/config.toml
<span class="nb">sed</span> <span class="nt">-i</span> <span class="s1">'s/SystemdCgroup = false/SystemdCgroup = true/g'</span> /etc/containerd/config.toml

<span class="c"># avoid WARN&amp;ERRO(default endpoints) when crictl run  </span>
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> &gt; /etc/crictl.yaml
runtime-endpoint: unix:///run/containerd/containerd.sock
image-endpoint: unix:///run/containerd/containerd.sock
</span><span class="no">EOF

</span><span class="c"># ready to install for k8s </span>
systemctl restart containerd <span class="o">&amp;&amp;</span> systemctl <span class="nb">enable </span>containerd
systemctl <span class="nb">enable</span> <span class="nt">--now</span> kubelet

<span class="nb">echo</span> <span class="s2">"[TASK 6] Install Packages &amp; Helm"</span>
apt-get <span class="nb">install</span> <span class="nt">-y</span> bridge-utils sshpass net-tools conntrack ngrep tcpdump ipset arping wireguard jq tree bash-completion unzip kubecolor <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
curl <span class="nt">-s</span> https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash <span class="o">&gt;</span>/dev/null 2&gt;&amp;1

<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; Initial Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div></div>

<h4 id="k8s-ctrsh"><strong>k8s-ctr.sh</strong></h4>
<ul>
  <li>
<code class="language-plaintext highlighter-rouge">kubeadm init</code>으로 컨트롤플레인을 설정하고, 편의를 위한 <code class="language-plaintext highlighter-rouge">k</code>, <code class="language-plaintext highlighter-rouge">kc</code> 등의 alias를 설정합니다.</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>

<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Controlplane config Start &lt;&lt;&lt;&lt;"</span>

<span class="nb">echo</span> <span class="s2">"[TASK 1] Initial Kubernetes"</span>
kubeadm init <span class="nt">--token</span> 123456.1234567890123456 <span class="nt">--token-ttl</span> 0 <span class="nt">--pod-network-cidr</span><span class="o">=</span>10.244.0.0/16 <span class="nt">--service-cidr</span><span class="o">=</span>10.96.0.0/16 <span class="nt">--apiserver-advertise-address</span><span class="o">=</span>192.168.10.100 <span class="nt">--cri-socket</span><span class="o">=</span>unix:///run/containerd/containerd.sock <span class="o">&gt;</span>/dev/null 2&gt;&amp;1


<span class="nb">echo</span> <span class="s2">"[TASK 2] Setting kube config file"</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> /root/.kube
<span class="nb">cp</span> <span class="nt">-i</span> /etc/kubernetes/admin.conf /root/.kube/config
<span class="nb">chown</span> <span class="si">$(</span><span class="nb">id</span> <span class="nt">-u</span><span class="si">)</span>:<span class="si">$(</span><span class="nb">id</span> <span class="nt">-g</span><span class="si">)</span> /root/.kube/config


<span class="nb">echo</span> <span class="s2">"[TASK 3] Source the completion"</span>
<span class="nb">echo</span> <span class="s1">'source &lt;(kubectl completion bash)'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'source &lt;(kubeadm completion bash)'</span> <span class="o">&gt;&gt;</span> /etc/profile


<span class="nb">echo</span> <span class="s2">"[TASK 4] Alias kubectl to k"</span>
<span class="nb">echo</span> <span class="s1">'alias k=kubectl'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'alias kc=kubecolor'</span> <span class="o">&gt;&gt;</span> /etc/profile
<span class="nb">echo</span> <span class="s1">'complete -F __start_kubectl k'</span> <span class="o">&gt;&gt;</span> /etc/profile


<span class="nb">echo</span> <span class="s2">"[TASK 5] Install Kubectx &amp; Kubens"</span>
git clone https://github.com/ahmetb/kubectx /opt/kubectx <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">ln</span> <span class="nt">-s</span> /opt/kubectx/kubens /usr/local/bin/kubens
<span class="nb">ln</span> <span class="nt">-s</span> /opt/kubectx/kubectx /usr/local/bin/kubectx


<span class="nb">echo</span> <span class="s2">"[TASK 6] Install Kubeps &amp; Setting PS1"</span>
git clone https://github.com/jonmosco/kube-ps1.git /root/kube-ps1 <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="sh">"</span><span class="no">EOT</span><span class="sh">" &gt;&gt; /root/.bash_profile
source /root/kube-ps1/kube-ps1.sh
KUBE_PS1_SYMBOL_ENABLE=true
function get_cluster_short() {
  echo "</span><span class="nv">$1</span><span class="sh">" | cut -d . -f1
}
KUBE_PS1_CLUSTER_FUNCTION=get_cluster_short
KUBE_PS1_SUFFIX=') '
PS1='</span><span class="si">$(</span>kube_ps1<span class="si">)</span><span class="sh">'</span><span class="nv">$PS1</span><span class="sh">
</span><span class="no">EOT
</span>kubectl config rename-context <span class="s2">"kubernetes-admin@kubernetes"</span> <span class="s2">"HomeLab"</span> <span class="o">&gt;</span>/dev/null 2&gt;&amp;1


<span class="nb">echo</span> <span class="s2">"[TASK 6] Install Kubeps &amp; Setting PS1"</span>
<span class="nb">echo</span> <span class="s2">"192.168.10.100 k8s-ctr"</span> <span class="o">&gt;&gt;</span> /etc/hosts
<span class="k">for</span> <span class="o">((</span> <span class="nv">i</span><span class="o">=</span>1<span class="p">;</span> i&lt;<span class="o">=</span><span class="nv">$1</span><span class="p">;</span> i++  <span class="o">))</span><span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"192.168.10.10</span><span class="nv">$i</span><span class="s2"> k8s-w</span><span class="nv">$i</span><span class="s2">"</span> <span class="o">&gt;&gt;</span> /etc/hosts<span class="p">;</span> <span class="k">done


</span><span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Controlplane Config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div></div>

<h4 id="k8s-wsh"><strong>k8s-w.sh</strong></h4>
<ul>
  <li>워커노드에서 <code class="language-plaintext highlighter-rouge">kubeadm join</code>을 실행하여 컨트롤플레인에 조인합니다.</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/usr/bin/env bash</span>

<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Node config Start &lt;&lt;&lt;&lt;"</span>

<span class="nb">echo</span> <span class="s2">"[TASK 1] K8S Controlplane Join"</span> 
kubeadm <span class="nb">join</span> <span class="nt">--token</span> 123456.1234567890123456 <span class="nt">--discovery-token-unsafe-skip-ca-verification</span> 192.168.10.100:6443  <span class="o">&gt;</span>/dev/null 2&gt;&amp;1

<span class="nb">echo</span> <span class="s2">"&gt;&gt;&gt;&gt; K8S Node config End &lt;&lt;&lt;&lt;"</span>
</code></pre></div></div>

<h3 id="실습-환경-배포">실습 환경 배포</h3>

<ul>
  <li>실습 환경 배포를 위한 파일이 준비되었으니 <code class="language-plaintext highlighter-rouge">vagrant up</code> 명령을 이용하여 가상 머신을 배포하겠습니다.</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>vagrant up
<span class="c"># =&gt; Bringing machine 'k8s-ctr' up with 'virtualbox' provider...</span>
<span class="c">#    Bringing machine 'k8s-w1' up with 'virtualbox' provider...</span>
<span class="c">#    Bringing machine 'k8s-w2' up with 'virtualbox' provider...</span>
<span class="c">#    ==&gt; k8s-ctr: Box 'bento/ubuntu-24.04' could not be found. Attempting to find and install...</span>
<span class="c">#        k8s-ctr: Box Provider: virtualbox</span>
<span class="c">#        k8s-ctr: Box Version: 202502.21.0</span>
<span class="c">#    ==&gt; k8s-ctr: Loading metadata for box 'bento/ubuntu-24.04'</span>
<span class="c">#        k8s-ctr: URL: https://vagrantcloud.com/api/v2/vagrant/bento/ubuntu-24.04</span>
<span class="c">#    ==&gt; k8s-ctr: Adding box 'bento/ubuntu-24.04' (v202502.21.0) for provider: virtualbox (arm64)</span>
<span class="c">#        k8s-ctr: Downloading: https://vagrantcloud.com/bento/boxes/ubuntu-24.04/versions/202502.21.0/providers/virtualbox/arm64/vagrant.box</span>
<span class="c">#    ==&gt; k8s-ctr: Successfully added box 'bento/ubuntu-24.04' (v202502.21.0) for 'virtualbox (arm64)'!</span>
<span class="c">#    ==&gt; k8s-ctr: Preparing master VM for linked clones...</span>
<span class="c">#    ...</span>
<span class="c">#        k8s-w2: &gt;&gt;&gt;&gt; K8S Node config End &lt;&lt;&lt;&lt;</span>
</code></pre></div></div>

<ul>
  <li>배포 후 각 노드에 ssh로 접속하여 ip를 확인해 보겠습니다.</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>ctr w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> vagrant ssh k8s-<span class="nv">$i</span> <span class="nt">-c</span> <span class="s1">'ip -c -4 addr show dev eth0'</span><span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span> <span class="c">#</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-ctr &lt;&lt;</span>
<span class="c">#    2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span>
<span class="c">#        altname enp0s8</span>
<span class="c">#        inet 10.0.2.15/24 metric 100 brd 10.0.2.255 scope global dynamic eth0</span>
<span class="c">#           valid_lft 85500sec preferred_lft 85500sec</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span>
<span class="c">#        altname enp0s8</span>
<span class="c">#        inet 10.0.2.15/24 metric 100 brd 10.0.2.255 scope global dynamic eth0</span>
<span class="c">#           valid_lft 85707sec preferred_lft 85707sec</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w2 &lt;&lt;</span>
<span class="c">#    2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span>
<span class="c">#        altname enp0s8</span>
<span class="c">#        inet 10.0.2.15/24 metric 100 brd 10.0.2.255 scope global dynamic eth0</span>
<span class="c">#           valid_lft 85781sec preferred_lft 85781sec</span>
</code></pre></div></div>

<ul>
  <li>
<code class="language-plaintext highlighter-rouge">k8s-ctr</code> 노드에 접속하여 기본 정보를 확인해 보겠습니다.</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>vagrant ssh k8s-ctr
<span class="nt">---</span>
<span class="c"># =&gt; Welcome to Ubuntu 24.04.2 LTS (GNU/Linux 6.8.0-53-generic aarch64)</span>
<span class="c">#    ...</span>
<span class="c">#    (⎈|HomeLab:N/A) root@k8s-ctr:~#</span>
<span class="nv">$ </span><span class="nb">whoami</span>
<span class="c"># =&gt; root</span>
<span class="nv">$ </span><span class="nb">pwd</span>
<span class="c"># =&gt; /root</span>
<span class="nv">$ </span>hostnamectl
<span class="c"># =&gt;  Static hostname: k8s-ctr</span>
<span class="c">#           Icon name: computer-vm</span>
<span class="c">#             Chassis: vm</span>
<span class="c">#          Machine ID: 3d6bd65db7dd43d392b2d5229abb5654</span>
<span class="c">#             Boot ID: 2d9ede04fd294425988e58c588dd201c</span>
<span class="c">#      Virtualization: qemu</span>
<span class="c">#    Operating System: Ubuntu 24.04.2 LTS</span>
<span class="c">#              Kernel: Linux 6.8.0-53-generic</span>
<span class="c">#        Architecture: arm64</span>
<span class="nv">$ </span>htop

<span class="nv">$ </span><span class="nb">cat</span> /etc/hosts
<span class="c"># =&gt; 127.0.0.1 localhost</span>
<span class="c">#    127.0.1.1 vagrant</span>
<span class="c">#    ...</span>
<span class="c">#    127.0.2.1 k8s-ctr k8s-ctr</span>
<span class="c">#    192.168.10.100 k8s-ctr</span>
<span class="c">#    192.168.10.101 k8s-w1</span>
<span class="c">#    192.168.10.102 k8s-w2</span>
<span class="nv">$ </span>ping <span class="nt">-c</span> 1 k8s-w1
<span class="c"># =&gt; PING k8s-w1 (192.168.10.101) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from k8s-w1 (192.168.10.101): icmp_seq=1 ttl=64 time=0.795 ms</span>
<span class="c">#    </span>
<span class="c">#    --- k8s-w1 ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 0.795/0.795/0.795/0.000 ms</span>
<span class="nv">$ </span>ping <span class="nt">-c</span> 1 k8s-w2
<span class="c"># =&gt; PING k8s-w2 (192.168.10.102) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from k8s-w2 (192.168.10.102): icmp_seq=1 ttl=64 time=1.20 ms</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-w1 <span class="nb">hostname</span>
<span class="c"># =&gt; k8s-w1</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-w2 <span class="nb">hostname</span>
<span class="c"># =&gt; k8s-w2</span>

<span class="c"># vagrant ssh 로 접속 시 tcp 연결 정보 : NAT Mode 10.0.2.2(GateWay)</span>
<span class="nv">$ </span>ss <span class="nt">-tnp</span> |grep sshd
<span class="c"># =&gt; ESTAB 0      0           [::ffff:10.0.2.15]:22          [::ffff:10.0.2.2]:63578 users:((&amp;quot;sshd&amp;quot;,pid=5141,fd=4),(&amp;quot;sshd&amp;quot;,pid=5094,fd=4))</span>

<span class="c"># nic 정보</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> addr
<span class="c"># =&gt; 1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span>
<span class="c">#       ...</span>
<span class="c">#    2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span>
<span class="c">#        link/ether 08:00:27:71:19:d8 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        altname enp0s8</span>
<span class="c">#        inet 10.0.2.15/24 metric 100 brd 10.0.2.255 scope global dynamic eth0</span>
<span class="c">#           valid_lft 82445sec preferred_lft 82445sec</span>
<span class="c">#    3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span>
<span class="c">#        link/ether 08:00:27:da:24:93 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        altname enp0s9</span>
<span class="c">#        inet 192.168.10.100/24 brd 192.168.10.255 scope global eth1</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>

<span class="c"># default 라우팅 정보 </span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.100</span>

<span class="c"># dns 서버 정보 : NAT Mode 10.0.2.3</span>
<span class="nv">$ </span>resolvectl
<span class="c"># =&gt; Global</span>
<span class="c">#             Protocols: -LLMNR -mDNS -DNSOverTLS DNSSEC=no/unsupported</span>
<span class="c">#      resolv.conf mode: stub</span>
<span class="c">#    </span>
<span class="c">#    Link 2 (eth0)</span>
<span class="c">#        Current Scopes: DNS</span>
<span class="c">#             Protocols: +DefaultRoute -LLMNR -mDNS -DNSOverTLS DNSSEC=no/unsupported</span>
<span class="c">#    Current DNS Server: 10.0.2.3</span>
<span class="c">#           DNS Servers: 10.0.2.3</span>
<span class="c">#    </span>
<span class="c">#    Link 3 (eth1)</span>
<span class="c">#        Current Scopes: none</span>
<span class="c">#             Protocols: -DefaultRoute -LLMNR -mDNS -DNSOverTLS DNSSEC=no/unsupported</span>
<span class="nv">$ </span><span class="nb">exit</span>
<span class="nt">---</span>
</code></pre></div></div>

<ul>
  <li>
<code class="language-plaintext highlighter-rouge">k8s-ctr</code> k8s 정보 확인</li>
</ul>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 클러스터 정보 확인</span>
<span class="nv">$ </span>kubectl cluster-info
<span class="c"># =&gt; Kubernetes control plane is running at https://192.168.10.100:6443</span>
<span class="c">#    CoreDNS is running at https://192.168.10.100:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</span>
<span class="c">#    </span>
<span class="c">#    To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.</span>

<span class="c"># 노드 정보 : 상태, INTERNAL-IP 확인</span>
<span class="nv">$ </span>kubectl get node <span class="nt">-owide</span>
<span class="c"># =&gt; NAME      STATUS     ROLES           AGE   VERSION   INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION     CONTAINER-RUNTIME</span>
<span class="c">#    k8s-ctr   NotReady   control-plane   2d    v1.33.2   192.168.10.100   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>
<span class="c">#    k8s-w1    NotReady   &lt;none&gt;          2d    v1.33.2   10.0.2.15        &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>
<span class="c">#    k8s-w2    NotReady   &lt;none&gt;          2d    v1.33.2   10.0.2.15        &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>

<span class="c"># 파드 정보 : 상태, 파드 IP 확인 - kube-proxy 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-A</span> <span class="nt">-owide</span>
<span class="c"># =&gt; NAMESPACE     NAME                              READY   STATUS    RESTARTS      AGE   IP               NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-79mbb          0/1     Pending   0             2d    &lt;none&gt;           &lt;none&gt;    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-rtx95          0/1     Pending   0             2d    &lt;none&gt;           &lt;none&gt;    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   etcd-k8s-ctr                      1/1     Running   1 (12m ago)   2d    192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-apiserver-k8s-ctr            1/1     Running   1 (12m ago)   2d    192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-controller-manager-k8s-ctr   1/1     Running   1 (12m ago)   2d    192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-proxy-hdffr                  1/1     Running   1 (11m ago)   2d    10.0.2.15        k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-proxy-r96sz                  1/1     Running   1 (12m ago)   2d    192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-proxy-swgmb                  1/1     Running   1 (11m ago)   2d    10.0.2.15        k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-scheduler-k8s-ctr            1/1     Running   1 (12m ago)   2d    192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>

<span class="c"># 단축어 확인(kc = kubecolor) &amp; coredns 파드 상태 확인</span>
<span class="nv">$ </span>k  describe pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>kube-dns
<span class="c"># =&gt; Name:                 coredns-674b8bbfcf-79mbb</span>
<span class="c">#    Namespace:            kube-system</span>
<span class="c">#    Priority:             2000000000</span>
<span class="c">#    Priority Class Name:  system-cluster-critical</span>
<span class="c">#    Service Account:      coredns</span>
<span class="c">#    Node:                 &lt;none&gt;</span>
<span class="c">#    Labels:               k8s-app=kube-dns</span>
<span class="c">#                          pod-template-hash=674b8bbfcf</span>
<span class="c">#    Annotations:          &lt;none&gt;</span>
<span class="c">#    Status:               Pending</span>
<span class="c">#    IP:</span>
<span class="c">#    IPs:                  &lt;none&gt;</span>
<span class="c">#    Controlled By:        ReplicaSet/coredns-674b8bbfcf</span>
<span class="c">#    Containers:</span>
<span class="c">#      coredns:</span>
<span class="c">#        Image:       registry.k8s.io/coredns/coredns:v1.12.0</span>
<span class="c">#        Ports:       53/UDP, 53/TCP, 9153/TCP</span>
<span class="c">#        Host Ports:  0/UDP, 0/TCP, 0/TCP</span>
<span class="c">#        Args:</span>
<span class="c">#          -conf</span>
<span class="c">#          /etc/coredns/Corefile</span>
<span class="c">#        Limits:</span>
<span class="c">#          memory:  170Mi</span>
<span class="c">#        Requests:</span>
<span class="c">#          cpu:        100m</span>
<span class="c">#          memory:     70Mi</span>
<span class="c">#        Liveness:     http-get http://:8080/health delay=60s timeout=5s period=10s #success=1 #failure=5</span>
<span class="c">#        Readiness:    http-get http://:8181/ready delay=0s timeout=1s period=10s #success=1 #failure=3</span>
<span class="c">#        Environment:  &lt;none&gt;</span>
<span class="c">#        Mounts:</span>
<span class="c">#          /etc/coredns from config-volume (ro)</span>
<span class="c">#          /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-vrqlj (ro)</span>
<span class="c">#    Conditions:</span>
<span class="c">#      Type           Status</span>
<span class="c">#      PodScheduled   False</span>
<span class="c">#    Volumes:</span>
<span class="c">#      config-volume:</span>
<span class="c">#        Type:      ConfigMap (a volume populated by a ConfigMap)</span>
<span class="c">#        Name:      coredns</span>
<span class="c">#        Optional:  false</span>
<span class="c">#      kube-api-access-vrqlj:</span>
<span class="c">#        Type:                    Projected (a volume that contains injected data from multiple sources)</span>
<span class="c">#        TokenExpirationSeconds:  3607</span>
<span class="c">#        ConfigMapName:           kube-root-ca.crt</span>
<span class="c">#        Optional:                false</span>
<span class="c">#        DownwardAPI:             true</span>
<span class="c">#    QoS Class:                   Burstable</span>
<span class="c">#    Node-Selectors:              kubernetes.io/os=linux</span>
<span class="c">#    Tolerations:                 CriticalAddonsOnly op=Exists</span>
<span class="c">#                                 node-role.kubernetes.io/control-plane:NoSchedule</span>
<span class="c">#                                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s</span>
<span class="c">#                                 node.kubernetes.io/unreachable:NoExecute op=Exists for 300s</span>
<span class="c">#    Events:</span>
<span class="c">#      Type     Reason            Age                  From               Message</span>
<span class="c">#      ----     ------            ----                 ----               -------</span>
<span class="c">#      Warning  FailedScheduling  7m18s (x2 over 12m)  default-scheduler  0/3 nodes are available: 3 node(s) had untolerated taint {node.kubernetes.io/not-ready: }. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.</span>
<span class="c">#      Warning  FailedScheduling  47h(x12 over 2d)    default-scheduler  0/3 nodes are available: 3 node(s) had untolerated taint {node.kubernetes.io/not-ready: }. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>kc describe pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>kube-dns
</code></pre></div></div>

<ul>
  <li>
<code class="language-plaintext highlighter-rouge">k8s-ctr</code> INTERNAL-IP 변경 설정</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span><span class="nb">cat</span> /var/lib/kubelet/kubeadm-flags.env
<span class="c"># =&gt; KUBELET_KUBEADM_ARGS="--container-runtime-endpoint=unix:///run/containerd/containerd.sock --pod-infra-container-image=registry.k8s.io/pause:3.10"</span>

<span class="c"># INTERNAL-IP 변경 설정</span>
<span class="nv">$ NODEIP</span><span class="o">=</span><span class="si">$(</span>ip <span class="nt">-4</span> addr show eth1 | <span class="nb">grep</span> <span class="nt">-oP</span> <span class="s1">'(?&lt;=inet\s)\d+(\.\d+){3}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">sed</span> <span class="nt">-i</span> <span class="s2">"s/^</span><span class="se">\(</span><span class="s2">KUBELET_KUBEADM_ARGS=</span><span class="se">\"\)</span><span class="s2">/</span><span class="se">\1</span><span class="s2">--node-ip=</span><span class="k">${</span><span class="nv">NODEIP</span><span class="k">}</span><span class="s2"> /"</span> /var/lib/kubelet/kubeadm-flags.env
<span class="nv">$ </span>systemctl daemon-reexec <span class="o">&amp;&amp;</span> systemctl restart kubelet

<span class="nv">$ </span><span class="nb">cat</span> /var/lib/kubelet/kubeadm-flags.env
<span class="c"># =&gt; KUBELET_KUBEADM_ARGS="--node-ip=192.168.10.100 --container-runtime-endpoint=unix:///run/containerd/containerd.sock --pod-infra-container-image=registry.k8s.io/pause:3.10"</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get node <span class="nt">-owide</span>
<span class="c"># =&gt; NAME      STATUS     ROLES           AGE   VERSION   INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION     CONTAINER-RUNTIME</span>
<span class="c">#    k8s-ctr   NotReady   control-plane   2d    v1.33.2   192.168.10.100   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>
<span class="c">#    k8s-w1    NotReady   &lt;none&gt;          2d    v1.33.2   10.0.2.15        &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>
<span class="c">#    k8s-w2    NotReady   &lt;none&gt;          2d    v1.33.2   10.0.2.15        &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>
</code></pre></div></div>

<ul>
  <li>
<code class="language-plaintext highlighter-rouge">k8s-w1</code>, <code class="language-plaintext highlighter-rouge">k8s-w2</code> 에도 위와 동일한 방법으로 INTERNAL-IP를 192.168.10.x로 변경합니다.</li>
  <li>
<code class="language-plaintext highlighter-rouge">k8s-w1/w2</code> 설정 완료 후 INTERNAL-IP 확인</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>kubectl get node <span class="nt">-owide</span>
<span class="c"># =&gt; NAME      STATUS     ROLES           AGE   VERSION   INTERNAL-IP      EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION     CONTAINER-RUNTIME</span>
<span class="c">#    k8s-ctr   NotReady   control-plane   2d    v1.33.2   192.168.10.100   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>
<span class="c">#    k8s-w1    NotReady   &lt;none&gt;          2d    v1.33.2   192.168.10.101   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>
<span class="c">#    k8s-w2    NotReady   &lt;none&gt;          2d    v1.33.2   192.168.10.102   &lt;none&gt;        Ubuntu 24.04.2 LTS   6.8.0-53-generic   containerd://1.7.27</span>

<span class="nv">$ </span>kubectl get pod <span class="nt">-A</span> <span class="nt">-owide</span>
<span class="c"># =&gt; NAMESPACE     NAME                              READY   STATUS    RESTARTS      AGE   IP               NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-79mbb          0/1     Pending   0             2d    &lt;none&gt;           &lt;none&gt;    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-rtx95          0/1     Pending   0             2d    &lt;none&gt;           &lt;none&gt;    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   etcd-k8s-ctr                      1/1     Running   1 (27m ago)   2d    192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-apiserver-k8s-ctr            1/1     Running   1 (27m ago)   2d    192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-controller-manager-k8s-ctr   1/1     Running   1 (27m ago)   2d    192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-proxy-hdffr                  1/1     Running   1 (26m ago)   2d    192.168.10.101   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-proxy-r96sz                  1/1     Running   1 (27m ago)   2d    192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-proxy-swgmb                  1/1     Running   1 (26m ago)   2d    192.168.10.102   k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-scheduler-k8s-ctr            1/1     Running   1 (27m ago)   2d    192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
</code></pre></div></div>

<ul>
  <li>
<code class="language-plaintext highlighter-rouge">k8s-ctr</code> static pod의 IP 변경 설정</li>
</ul>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>tree /etc/kubernetes/manifests
<span class="c"># =&gt; /etc/kubernetes/manifests</span>
<span class="c">#    ├── etcd.yaml</span>
<span class="c">#    ├── kube-apiserver.yaml</span>
<span class="c">#    ├── kube-controller-manager.yaml</span>
<span class="c">#    └── kube-scheduler.yaml</span>

<span class="c"># etcd 정보 확인</span>
<span class="nv">$ </span><span class="nb">cat</span> /etc/kubernetes/manifests/etcd.yaml
<span class="c"># =&gt;   ...</span>
<span class="c">#      volumes:</span>
<span class="c">#      - hostPath:</span>
<span class="c">#          path: /etc/kubernetes/pki/etcd</span>
<span class="c">#          type: DirectoryOrCreate</span>
<span class="c">#        name: etcd-certs</span>
<span class="c">#      - hostPath:</span>
<span class="c">#          path: /var/lib/etcd</span>
<span class="c">#          type: DirectoryOrCreate</span>
<span class="c">#        name: etcd-data</span>
<span class="c">#      ...</span>

<span class="nv">$ </span>tree /var/lib/etcd/
<span class="c"># =&gt; /var/lib/etcd/</span>
<span class="c">#    └── member</span>
<span class="c">#        ├── snap</span>
<span class="c">#        │   ├── 0000000000000003-0000000000002711.snap</span>
<span class="c">#        │   └── db</span>
<span class="c">#        └── wal</span>
<span class="c">#            ├── 0000000000000000-0000000000000000.wal</span>
<span class="c">#            └── 0.tmp</span>

<span class="c"># k8s-ctr 재부팅</span>
<span class="nv">$ </span>reboot
</code></pre></div></div>

<hr>

<h2 id="flannel-cni">Flannel CNI</h2>

<h3 id="flannel-소개">Flannel 소개</h3>

<ul>
  <li>Flannel은 쿠버네티스의 네트워크 요구사항을 충족하는 가장 간단하고 사용하기 쉬운 오버레이 네트워크 플러그인입니다.</li>
  <li>Flannel은 가상 네트워크를 생성하여 파드 간 통신을 가능하게 하며, VXLAN, UDP, Host-GW 등 다양한 백엔드를 지원합니다. 이 중에서는 VXLAN 사용이 가장 권장됩니다.</li>
  <li>VXLAN(Virtual eXtensible Local Area Network)은 물리적인 네트워크 환경 위에 논리적인 가상 네트워크를 구성하는 기술로, UDP 8472 포트를 통해 노드 간 터널링 방식으로 통신합니다.</li>
</ul>

<p><img src="/assets/2025/cilium/w1/20250720_cilium_w1_2.png" alt="img.png" class="image-center" loading="lazy" width="495" height="241">
<em class="image-caption">Flannel 구조 (출처: 추가예정)</em></p>

<ul>
  <li>위 그림처럼 파드의 eth0 네트워크 인터페이스는 호스트 네임스페이스의 veth 인터페이스와 연결되고, veth는 cni0와 연결됩니다.</li>
  <li>같은 노드 내에서는 cni0 브릿지를 통해 파드 간 통신이 이루어지며, 다른 노드와의 통신은 VXLAN을 통해 처리됩니다.</li>
  <li>VXLAN 경로에서는 cni0 브릿지를 거쳐 flannel.1 인터페이스로 패킷이 전달되고, flannel.1은 호스트의 eth0을 통해 다른 노드로 전송합니다. 이때 <strong>flannel.1은 VTEP(Vxlan Tunnel End Point)</strong> 역할을 하며, 패킷을 캡슐화하여 대상 노드의 IP로 전송하고, 도착한 노드에서는 캡슐을 해제해 해당 파드로 전달합니다.</li>
  <li>각 노드는 파드에 할당할 수 있는 IP 네트워크 대역을 가지고 있으며, flannel을 통해 ETCD나 Kubernetes API에 전달된 정보를 바탕으로 모든 노드는 자신의 라우팅 테이블을 업데이트합니다. 이를 통해 서로 다른 노드의 파드끼리도 내부 IP 주소로 통신할 수 있습니다.</li>
</ul>

<h3 id="flannel-설치-및-확인">Flannel 설치 및 확인</h3>

<ul>
  <li>설치 전 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># IP 주소 범위 확인</span>
<span class="nv">$ </span>kubectl cluster-info dump | <span class="nb">grep</span> <span class="nt">-m</span> 2 <span class="nt">-E</span> <span class="s2">"cluster-cidr|service-cluster-ip-range"</span>
<span class="c"># =&gt;                             "--service-cluster-ip-range=10.96.0.0/16",</span>
<span class="c">#                                "--cluster-cidr=10.244.0.0/16",</span>

<span class="c"># coredns 파드 상태 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-n</span> kube-system <span class="nt">-l</span> k8s-app<span class="o">=</span>kube-dns <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                       READY   STATUS    RESTARTS   AGE     IP       NODE     NOMINATED NODE   READINESS GATES</span>
<span class="c">#    coredns-674b8bbfcf-79mbb   0/1     &lt;span style="color: green;"&gt;Pending&lt;/span&gt;   0          2d14h   &lt;none&gt;   &lt;none&gt;   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    coredns-674b8bbfcf-rtx95   0/1     &lt;span style="color: green;"&gt;Pending&lt;/span&gt;   0          2d14h   &lt;none&gt;   &lt;none&gt;   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    &lt;span style="color: green;"&gt;👉 CNI가 설치되지 않아서 Pending 상태입니다&lt;/span&gt;</span>

<span class="c">#</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> <span class="nb">link</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 08:00:27:71:19:d8 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 08:00:27:da:24:93 brd ff:ff:ff:ff:ff:ff</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.100</span>
<span class="nv">$ </span>brctl show
<span class="c"># =&gt; &lt;span style="color: green;"&gt;없음&lt;/span&gt;</span>

<span class="nv">$ </span>ip <span class="nt">-c</span> addr
<span class="c"># =&gt; ...</span>
<span class="c">#    2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span>
<span class="c">#        link/ether 08:00:27:71:19:d8 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet 10.0.2.15/24 metric 100 brd 10.0.2.255 scope global dynamic eth0</span>
<span class="c">#           valid_lft 85957sec preferred_lft 85957sec</span>
<span class="c">#    3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000</span>
<span class="c">#        link/ether 08:00:27:da:24:93 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet 192.168.10.100/24 brd 192.168.10.255 scope global eth1</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="nv">$ </span>ifconfig | <span class="nb">grep</span> <span class="nt">-iEA1</span> <span class="s1">'eth[0-9]:'</span>
<span class="c"># =&gt; eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span>
<span class="c">#            inet 10.0.2.15  netmask 255.255.255.0  broadcast 10.0.2.255</span>
<span class="c">#    --</span>
<span class="c">#    eth1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span>
<span class="c">#            inet 192.168.10.100  netmask 255.255.255.0  broadcast 192.168.10.255</span>

<span class="c">#</span>
<span class="nv">$ </span>iptables-save
<span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> filter <span class="nt">-S</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> mangle <span class="nt">-S</span>

<span class="c"># flannel 설치 후 비교를 위해 설치 전의 iptables 설정을 저장합니다.</span>
<span class="nv">$ </span>iptables-save <span class="o">&gt;</span> iptables-before-flannel.txt

<span class="c">#</span>
<span class="nv">$ </span>tree /etc/cni/net.d/
<span class="c"># =&gt; /etc/cni/net.d/</span>
<span class="c">#    </span>
<span class="c">#    0 directories, 0 files</span>
</code></pre></div></div>

<ul>
  <li>Flannel 설치</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># helm에 의한 namespace 생성 오류 방지를 위해 kube-flannel 네임스페이스를 수동으로 생성합니다.</span>
<span class="nv">$ </span>kubectl create ns kube-flannel
<span class="c"># =&gt; namespace/kube-flannel created</span>
<span class="nv">$ </span>kubectl label <span class="nt">--overwrite</span> ns kube-flannel pod-security.kubernetes.io/enforce<span class="o">=</span>privileged
<span class="c"># =&gt; namespace/kube-flannel labeled</span>

<span class="nv">$ </span>helm repo add flannel https://flannel-io.github.io/flannel/
<span class="c"># =&gt; "flannel" has been added to your repositories</span>
<span class="nv">$ </span>helm repo list
<span class="c"># =&gt; NAME    URL</span>
<span class="c">#    flannel https://flannel-io.github.io/flannel/</span>

<span class="nv">$ </span>helm search repo flannel
<span class="c"># =&gt; NAME            CHART VERSION   APP VERSION     DESCRIPTION</span>
<span class="c">#    flannel/flannel v0.27.1         v0.27.1         Install Flannel Network Plugin.</span>
<span class="nv">$ </span>helm show values flannel/flannel
<span class="c"># =&gt; ...</span>
<span class="c">#    podCidr: "10.244.0.0/16"</span>
<span class="c">#    ...</span>
<span class="c">#      cniBinDir: "/opt/cni/bin"</span>
<span class="c">#      cniConfDir: "/etc/cni/net.d"</span>
<span class="c">#      skipCNIConfigInstallation: false</span>
<span class="c">#      enableNFTables: false</span>
<span class="c">#      args:</span>
<span class="c">#      - "--ip-masq"</span>
<span class="c">#      - "--kube-subnet-mgr"</span>
<span class="c">#      backend: "vxlan"</span>
<span class="c">#    ...</span>

<span class="c"># k8s 관련 트래픽 통신 동작하는 nic 지정</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> &gt; flannel-values.yaml
podCidr: "10.244.0.0/16"

flannel:
  args:
  - "--ip-masq"
  - "--kube-subnet-mgr"
  - "--iface=eth1"  
</span><span class="no">EOF

</span><span class="c"># helm 설치</span>
<span class="nv">$ </span>helm <span class="nb">install </span>flannel <span class="nt">--namespace</span> kube-flannel flannel/flannel <span class="nt">-f</span> flannel-values.yaml
<span class="c"># =&gt; NAME: flannel</span>
<span class="c">#    LAST DEPLOYED: Mon Jan 19 13:52:04 2025</span>
<span class="c">#    NAMESPACE: kube-flannel</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 1</span>
<span class="c">#    TEST SUITE: None</span>
<span class="nv">$ </span>helm list <span class="nt">-A</span>
<span class="c"># =&gt; NAME    NAMESPACE       REVISION        UPDATED                                 STATUS          CHART           APP VERSION</span>
<span class="c">#    flannel kube-flannel    1               2025-01-19 13:52:04.427781204 +0900 KST deployed        flannel-v0.27.1 v0.27.1</span>

<span class="c"># 확인 : install-cni-plugin, install-cni</span>
<span class="nv">$ </span>kc describe pod <span class="nt">-n</span> kube-flannel <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>flannel
<span class="c"># =&gt; Name:                 kube-flannel-ds-5fm6l</span>
<span class="c">#    Namespace:            kube-flannel</span>
<span class="c">#    Priority:             2000001000</span>
<span class="c">#    Priority Class Name:  system-node-critical</span>
<span class="c">#    Service Account:      flannel</span>
<span class="c">#    Node:                 &lt;span style="color: green;"&gt;k8s-w1/192.168.10.101&lt;/span&gt;</span>
<span class="c">#    Start Time:           Sat, 19 Jul 2025 13:52:06 +0900</span>
<span class="c">#    Labels:               app=flannel</span>
<span class="c">#                          controller-revision-hash=66c5c78475</span>
<span class="c">#                          pod-template-generation=1</span>
<span class="c">#                          tier=node</span>
<span class="c">#    Annotations:          &lt;none&gt;</span>
<span class="c">#    Status:               Running</span>
<span class="c">#    IP:                   192.168.10.101</span>
<span class="c">#    IPs:</span>
<span class="c">#      IP:           192.168.10.101</span>
<span class="c">#    Controlled By:  DaemonSet/kube-flannel-ds</span>
<span class="c">#    Init Containers:</span>
<span class="c">#      install-cni-plugin:</span>
<span class="c">#      ...</span>
<span class="c">#      install-cni:</span>
<span class="c">#      ....</span>
<span class="c">#    Containers:</span>
<span class="c">#      kube-flannel:</span>
<span class="c">#        Container ID:  containerd://c6a1e24ae6193491289908c4b10a8ce6f9a36e000114aaf61dc60da43bdc50ca</span>
<span class="c">#        Image:         ghcr.io/flannel-io/flannel:v0.27.1</span>
<span class="c">#        Image ID:      ghcr.io/flannel-io/flannel@sha256:0c95c822b690f83dc827189d691015f92ab7e249e238876b56442b580c492d85</span>
<span class="c">#        Port:          &lt;none&gt;</span>
<span class="c">#        Host Port:     &lt;none&gt;</span>
<span class="c">#    ...</span>
<span class="c">#    Name:                 kube-flannel-ds-dstmv</span>
<span class="c">#    Namespace:            kube-flannel</span>
<span class="c">#    Priority:             2000001000</span>
<span class="c">#    Priority Class Name:  system-node-critical</span>
<span class="c">#    Service Account:      flannel</span>
<span class="c">#    Node:                 &lt;span style="color: green;"&gt;k8s-w2/192.168.10.102&lt;/span&gt;</span>
<span class="c">#    Start Time:           Sat, 19 Jul 2025 13:52:05 +0900</span>
<span class="c">#    ...</span>
<span class="c">#    IP:                   192.168.10.102</span>
<span class="c">#    ...</span>
<span class="c">#    Name:                 kube-flannel-ds-lsf7h</span>
<span class="c">#    Namespace:            kube-flannel</span>
<span class="c">#    Priority:             2000001000</span>
<span class="c">#    Priority Class Name:  system-node-critical</span>
<span class="c">#    Service Account:      flannel</span>
<span class="c">#    Node:                 &lt;span style="color: green;"&gt;k8s-ctr/192.168.10.100&lt;/span&gt;</span>
<span class="c">#    Start Time:           Sat, 19 Jul 2025 13:52:04 +0900</span>
<span class="c">#    Labels:               app=flannel</span>
<span class="c">#                          controller-revision-hash=66c5c78475</span>
<span class="c">#                          pod-template-generation=1</span>
<span class="c">#                          tier=node</span>
<span class="c">#    Annotations:          &lt;none&gt;</span>
<span class="c">#    Status:               Running</span>
<span class="c">#    IP:                   192.168.10.100</span>
<span class="c">#    ...</span>

<span class="nv">$ </span>tree /opt/cni/bin/ <span class="c"># flannel</span>
<span class="c"># =&gt; /opt/cni/bin/</span>
<span class="c">#    ├── bandwidth</span>
<span class="c">#    ├── bridge</span>
<span class="c">#    ├── dhcp</span>
<span class="c">#    ├── dummy</span>
<span class="c">#    ├── firewall</span>
<span class="c">#    ├── flannel</span>
<span class="c">#    ├── host-device</span>
<span class="c">#    ├── host-local</span>
<span class="c">#    ├── ipvlan</span>
<span class="c">#    ├── LICENSE</span>
<span class="c">#    ├── loopback</span>
<span class="c">#    ├── macvlan</span>
<span class="c">#    ├── portmap</span>
<span class="c">#    ├── ptp</span>
<span class="c">#    ├── README.md</span>
<span class="c">#    ├── sbr</span>
<span class="c">#    ├── static</span>
<span class="c">#    ├── tap</span>
<span class="c">#    ├── tuning</span>
<span class="c">#    ├── vlan</span>
<span class="c">#    └── vrf</span>
<span class="c">#    </span>
<span class="c">#    1 directory, 21 files</span>
<span class="nv">$ </span>tree /etc/cni/net.d/
<span class="c"># =&gt; /etc/cni/net.d/</span>
<span class="c">#    └── 10-flannel.conflist</span>
<span class="c">#    </span>
<span class="c">#    1 directory, 1 file</span>
<span class="nv">$ </span><span class="nb">cat</span> /etc/cni/net.d/10-flannel.conflist | jq
<span class="c"># =&gt; {</span>
<span class="c">#      "name": "cbr0",</span>
<span class="c">#      "cniVersion": "0.3.1",</span>
<span class="c">#      "plugins": [</span>
<span class="c">#        {</span>
<span class="c">#          "type": "flannel",</span>
<span class="c">#          "delegate": {</span>
<span class="c">#            "hairpinMode": true,</span>
<span class="c">#            "isDefaultGateway": true</span>
<span class="c">#          }</span>
<span class="c">#        },</span>
<span class="c">#        {</span>
<span class="c">#          "type": "portmap",</span>
<span class="c">#          "capabilities": {</span>
<span class="c">#            "portMappings": true</span>
<span class="c">#          }</span>
<span class="c">#        }</span>
<span class="c">#      ]</span>
<span class="c">#    }</span>
<span class="nv">$ </span>kc describe cm <span class="nt">-n</span> kube-flannel kube-flannel-cfg
<span class="c"># =&gt; ...</span>
<span class="c">#    net-conf.json:</span>
<span class="c">#    ----</span>
<span class="c">#    {</span>
<span class="c">#      "Network": "10.244.0.0/16",</span>
<span class="c">#      "Backend": {</span>
<span class="c">#        "Type": "vxlan"</span>
<span class="c">#      }</span>
<span class="c">#    }</span>

<span class="c"># 설치 전과 비교해보겠습니다.</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> <span class="nb">link</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 08:00:27:71:19:d8 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 08:00:27:da:24:93 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    &lt;span style="color: green;"&gt;4: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default&lt;/span&gt;</span>
<span class="c">#    &lt;span style="color: green;"&gt;    link/ether aa:3f:e5:cd:ae:92 brd ff:ff:ff:ff:ff:ff&lt;/span&gt;</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route | <span class="nb">grep </span>10.244.
<span class="c"># =&gt; 10.244.1.0/24 via 10.244.1.0 dev flannel.1 onlink</span>
<span class="c">#    10.244.2.0/24 via 10.244.2.0 dev flannel.1 onlink</span>

<span class="nv">$ </span>ping <span class="nt">-c</span> 1 10.244.1.0
<span class="c"># =&gt; PING 10.244.1.0 (10.244.1.0) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 10.244.1.0: icmp_seq=1 ttl=64 time=1.31 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 10.244.1.0 ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 1.314/1.314/1.314/0.000 ms</span>
<span class="nv">$ </span>ping <span class="nt">-c</span> 1 10.244.2.0
<span class="c"># =&gt; PING 10.244.2.0 (10.244.2.0) 56(84) bytes of data.</span>
<span class="c">#    64 bytes from 10.244.2.0: icmp_seq=1 ttl=64 time=1.31 ms</span>
<span class="c">#    </span>
<span class="c">#    --- 10.244.2.0 ping statistics ---</span>
<span class="c">#    1 packets transmitted, 1 received, 0% packet loss, time 0ms</span>
<span class="c">#    rtt min/avg/max/mdev = 1.312/1.312/1.312/0.000 ms</span>

<span class="nv">$ </span>brctl show
<span class="nv">$ </span>iptables-save
<span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> filter <span class="nt">-S</span>
<span class="nv">$ </span>iptables-save <span class="o">&gt;</span> iptables-after-flannel.txt
<span class="c"># 설치 전과 후의 iptables 설정을 비교합니다.</span>
<span class="nv">$ </span>diff <span class="nt">-u</span> iptables-before-flannel.txt iptables-after-flannel.txt

<span class="c"># k8s-w1, k8s-w2 정보 확인</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> <span class="nb">link</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> route <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> brctl show <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
</code></pre></div></div>

<h3 id="샘플-애플리케이션-배포-및-확인">샘플 애플리케이션 배포 및 확인</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 샘플 애플리케이션 배포</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span> <span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: webpod
spec:
  replicas: 2
  selector:
    matchLabels:
      app: webpod
  template:
    metadata:
      labels:
        app: webpod
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - sample-app
            topologyKey: "kubernetes.io/hostname"
      containers:
      - name: webpod
        image: traefik/whoami
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: webpod
  labels:
    app: webpod
spec:
  selector:
    app: webpod
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
  type: ClusterIP
</span><span class="no">EOF
</span><span class="c"># =&gt; deployment.apps/webpod created</span>
<span class="c">#    service/webpod created</span>

<span class="c"># k8s-ctr 노드에 curl-pod 파드 배포</span>
<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: curl-pod
  labels:
    app: curl
spec:
  nodeName: k8s-ctr
  containers:
    - name: curl
      image: alpine/curl
      command: ["sleep", "36000"]
</span><span class="no">EOF
</span><span class="c"># =&gt; pod/curl-pod created</span>

<span class="c"># 컨트롤플레인 노드(k8s-ctr)에서 파드 확인</span>
<span class="nv">$ </span>crictl ps
<span class="c"># =&gt; CONTAINER     IMAGE         CREATED        STATE   NAME                    ATTEMPT POD ID        POD                               NAMESPACE</span>
<span class="c">#    ba7ddc59fa138 1fb7da88b3320 1 second ago   Running curl                    0       a87775d3d7098 &lt;span style="color: green;"&gt;curl-pod&lt;/span&gt;                          default</span>
<span class="c">#    2c095a0d795b7 83a2e3e54aa1e 19 minutes ago Running kube-flannel            0       49d7f057d7491 kube-flannel-ds-lsf7h             kube-flannel</span>
<span class="c">#    13ff95772dd16 738e99dbd7325 35 minutes ago Running kube-proxy              3       0ce95a5226767 kube-proxy-r96sz                  kube-system</span>
<span class="c">#    625a7ec089f93 c03972dff86ba 35 minutes ago Running kube-scheduler          3       7691ca47ac391 kube-scheduler-k8s-ctr            kube-system</span>
<span class="c">#    3b02267780926 ef439b94d49d4 35 minutes ago Running kube-controller-manager 3       232075758b77f kube-controller-manager-k8s-ctr   kube-system</span>
<span class="c">#    f956731d12744 31747a36ce712 35 minutes ago Running etcd                    3       7ac2514bac9cb etcd-k8s-ctr                      kube-system</span>
<span class="c">#    9f50506b3ca66 c0425f3fe3fbf 35 minutes ago Running kube-apiserver          3       d5246dd2d31b9 kube-apiserver-k8s-ctr            kube-system</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 curl-pod는 nodeName: 을 통해 컨트롤플레인 노드(k8s-ctr)에 배포되었습니다.&lt;/span&gt;</span>

<span class="c"># 워커 노드(k8s-w1, k8s-w2)에서 파드 확인</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>crictl ps <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; CONTAINER     IMAGE         CREATED        STATE   NAME                    ATTEMPT POD ID        POD                       NAMESPACE</span>
<span class="c">#    c934a221a4fec ab541801c8cc5 57 seconds ago Running webpod                  0       7323e0f4eced8 &lt;span style="color: green;"&gt;webpod-697b545f57-7j5vt&lt;/span&gt;   default</span>
<span class="c">#    c6a1e24ae6193 83a2e3e54aa1e 20 minutes ago Running kube-flannel            0       3a86bc505126a kube-flannel-ds-5fm6l     kube-flannel</span>
<span class="c">#    b55a66b5cd0a6 738e99dbd7325 35 minutes ago Running kube-proxy              2       8bc7a54488b35 kube-proxy-hdffr          kube-system</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w2 &lt;&lt;</span>
<span class="c">#    CONTAINER     IMAGE         CREATED        STATE   NAME                    ATTEMPT POD ID              POD                        NAMESPACE</span>
<span class="c">#    54658fa9cfc29 ab541801c8cc5 58 seconds ago Running webpod                  0       8dec7a5a7aed1 &lt;span style="color: green;"&gt;webpod-697b545f57-sdv4l&lt;/span&gt;    default</span>
<span class="c">#    9b2a414ee1acc f72407be9e08c 19 minutes ago Running coredns                 0       23071bf7a21e4 coredns-674b8bbfcf-rtx95   kube-system</span>
<span class="c">#    e1c86c4fa20fe f72407be9e08c 20 minutes ago Running coredns                 0       757397c6bcd8f coredns-674b8bbfcf-79mbb   kube-system</span>
<span class="c">#    eeac62c8beba7 83a2e3e54aa1e 20 minutes ago Running kube-flannel            0       1b4ba4f721424 kube-flannel-ds-dstmv      kube-flannel</span>
<span class="c">#    0a6112c11e948 738e99dbd7325 35 minutes ago Running kube-proxy              2       f9f19975aed04 kube-proxy-swgmb           kube-system</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 webpod는 별도로 nodeName: 을 지정하지 않았기 때문에 워커 노드(k8s-w1, k8s-w2)에 배포되었습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<ul>
  <li>확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 배포 확인</span>
<span class="nv">$ </span>kubectl get deploy,svc,ep webpod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                     READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES           SELECTOR</span>
<span class="c">#    deployment.apps/webpod   2/2     2            2           18m   webpod       traefik/whoami   app=webpod</span>
<span class="c">#    </span>
<span class="c">#    NAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE   SELECTOR</span>
<span class="c">#    service/webpod   ClusterIP   10.96.62.184   &lt;none&gt;        80/TCP    18m   app=webpod</span>
<span class="c">#    </span>
<span class="c">#    NAME               ENDPOINTS                     AGE</span>
<span class="c">#    endpoints/webpod   10.244.1.2:80,10.244.2.4:80   18m</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl api-resources | <span class="nb">grep</span> <span class="nt">-i</span> endpoint
<span class="c"># =&gt; endpoints                           ep           v1                                true         Endpoints</span>
<span class="c">#    endpointslices                                   discovery.k8s.io/v1               true         EndpointSlice</span>

<span class="nv">$ </span>kubectl get endpointslices <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>webpod
<span class="c"># =&gt; NAME           ADDRESSTYPE   PORTS   ENDPOINTS               AGE</span>
<span class="c">#    webpod-9pfs7   IPv4          80      10.244.2.4,10.244.1.2   18m</span>

<span class="c"># 배포 전과 비교해보겠습니다.</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> <span class="nb">link</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 08:00:27:71:19:d8 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 08:00:27:da:24:93 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    4: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default</span>
<span class="c">#        link/ether aa:3f:e5:cd:ae:92 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    5: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether b2:e2:a2:aa:4e:5c brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    &lt;span style="color: green;"&gt;6: veth0911be7c@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default qlen 1000&lt;/span&gt;</span>
<span class="c">#    &lt;span style="color: green;"&gt;    link/ether 6a:8b:92:5e:74:b3 brd ff:ff:ff:ff:ff:ff link-netns cni-15400ffe-d5f7-c6c2-78d9-dbbbc2f08db7&lt;/span&gt;</span>
<span class="nv">$ </span>brctl show
<span class="c"># =&gt; bridge name     bridge id               STP enabled     interfaces</span>
<span class="c">#    cni0            8000.b2e2a2aa4e5c       no              veth0911be7c</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 veth 인터페이스를 통해 파드와 연결된 cni0 브릿지가 생성되었습니다.&lt;/span&gt;</span>
<span class="nv">$ </span>iptables-save
<span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span>
<span class="nv">$ </span>iptables-save <span class="o">&gt;</span> iptables-after-deployment.txt
<span class="nv">$ </span>diff iptables-after-flannel.txt iptables-after-deployment.txt
<span class="c"># =&gt; ...</span>
<span class="c">#    62a63,64</span>
<span class="c">#    &gt; :KUBE-SEP-PQBQBGZJJ5FKN3TB - [0:0]</span>
<span class="c">#    &gt; :KUBE-SEP-R5LRHDMUTGTM635J - [0:0]</span>
<span class="c">#    66a69</span>
<span class="c">#    &gt; :KUBE-SVC-CNZCPOCNCNOROALA - [0:0]</span>
<span class="c">#    92a96,99</span>
<span class="c">#    &gt; -A KUBE-SEP-PQBQBGZJJ5FKN3TB -s 10.244.1.2/32 -m comment --comment "default/webpod" -j KUBE-MARK-MASQ</span>
<span class="c">#    &gt; -A KUBE-SEP-PQBQBGZJJ5FKN3TB -p tcp -m comment --comment "default/webpod" -m tcp -j DNAT --to-destination 10.244.1.2:80</span>
<span class="c">#    &gt; -A KUBE-SEP-R5LRHDMUTGTM635J -s 10.244.2.4/32 -m comment --comment "default/webpod" -j KUBE-MARK-MASQ</span>
<span class="c">#    &gt; -A KUBE-SEP-R5LRHDMUTGTM635J -p tcp -m comment --comment "default/webpod" -m tcp -j DNAT --to-destination 10.244.2.4:80</span>
<span class="c">#    98a106</span>
<span class="c">#    &gt; -A KUBE-SERVICES -d 10.96.62.184/32 -p tcp -m comment --comment "default/webpod cluster IP" -m tcp --dport 80 -j KUBE-SVC-CNZCPOCNCNOROALA</span>
<span class="c">#    103a112,114</span>
<span class="c">#    &gt; -A KUBE-SVC-CNZCPOCNCNOROALA ! -s 10.244.0.0/16 -d 10.96.62.184/32 -p tcp -m comment --comment "default/webpod cluster IP" -m tcp --dport 80 -j KUBE-MARK-MASQ</span>
<span class="c">#    &gt; -A KUBE-SVC-CNZCPOCNCNOROALA -m comment --comment "default/webpod -&gt; 10.244.1.2:80" -m statistic --mode random --probability 0.50000000000 -j KUBE-SEP-PQBQBGZJJ5FKN3TB</span>
<span class="c">#    &gt; -A KUBE-SVC-CNZCPOCNCNOROALA -m comment --comment "default/webpod -&gt; 10.244.2.4:80" -j KUBE-SEP-R5LRHDMUTGTM635J</span>
<span class="c">#    ...</span>

<span class="c"># k8s-w1, k8s-w2 정보 확인</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> <span class="nb">link</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    ...</span>
<span class="c">#    5: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 56:8b:b8:09:e1:a0 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    6: veth52205e86@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether ba:b1:d5:a8:5e:c6 brd ff:ff:ff:ff:ff:ff link-netns cni-42b4483c-e253-de82-a5c3-2cbf657cc6ed</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w2 &lt;&lt;</span>
<span class="c">#    ...</span>
<span class="c">#    5: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether b6:aa:16:04:b0:58 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    6: veth605dad7b@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 36:5a:70:ff:de:e9 brd ff:ff:ff:ff:ff:ff link-netns cni-e020c420-373a-900d-bf44-34fbe4622f7e</span>
<span class="c">#    7: veth002efe84@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether be:86:35:e2:1a:5d brd ff:ff:ff:ff:ff:ff link-netns cni-af271963-86ee-26b6-35b9-39173672cd1a</span>
<span class="c">#    8: veth1dce6530@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether fa:d9:af:04:69:e2 brd ff:ff:ff:ff:ff:ff link-netns cni-ca1eedc6-43ff-e346-318d-ba345e0ba532</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> route <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> brctl show <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
</code></pre></div></div>

<ul>
  <li>통신 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-l</span> <span class="nv">app</span><span class="o">=</span>webpod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                      READY   STATUS    RESTARTS   AGE   IP           NODE     NOMINATED NODE   READINESS GATES</span>
<span class="c">#    webpod-697b545f57-7j5vt   1/1     Running   0          24m   10.244.1.2   k8s-w1   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-697b545f57-sdv4l   1/1     Running   0          24m   10.244.2.4   k8s-w2   &lt;none&gt;           &lt;none&gt;</span>
<span class="nv">$ POD1IP</span><span class="o">=</span>10.244.1.2
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nv">$POD1IP</span>
<span class="c"># =&gt; Hostname: webpod-697b545f57-7j5vt</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: ::1</span>
<span class="c">#    IP: 10.244.1.2</span>
<span class="c">#    IP: fe80::dc28:1fff:fe46:abd0</span>
<span class="c">#    RemoteAddr: 10.244.0.2:46774</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: 10.244.1.2</span>
<span class="c">#    User-Agent: curl/8.14.1</span>
<span class="c">#    Accept: */*</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get svc,ep webpod
<span class="c"># =&gt; NAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE</span>
<span class="c">#    service/webpod   ClusterIP   10.96.62.184   &lt;none&gt;        80/TCP    25m</span>
<span class="c">#    </span>
<span class="c">#    NAME               ENDPOINTS                     AGE</span>
<span class="c">#    endpoints/webpod   10.244.1.2:80,10.244.2.4:80   25m</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl webpod
<span class="c"># =&gt; Hostname: webpod-697b545f57-7j5vt</span>
<span class="c">#    IP: 127.0.0.1</span>
<span class="c">#    IP: ::1</span>
<span class="c">#    IP: 10.244.1.2</span>
<span class="c">#    IP: fe80::dc28:1fff:fe46:abd0</span>
<span class="c">#    RemoteAddr: 10.244.0.2:55684</span>
<span class="c">#    GET / HTTP/1.1</span>
<span class="c">#    Host: webpod</span>
<span class="c">#    User-Agent: curl/8.14.1</span>
<span class="c">#    Accept: */*</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl webpod | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod-697b545f57-7j5vt</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> sh <span class="nt">-c</span> <span class="s1">'while true; do curl -s webpod | grep Hostname; sleep 1; done'</span>
<span class="c"># =&gt; Hostname: webpod-697b545f57-7j5vt</span>
<span class="c">#    Hostname: webpod-697b545f57-sdv4l</span>
<span class="c">#    Hostname: webpod-697b545f57-7j5vt</span>
<span class="c">#    ...</span>

<span class="c"># Service 동작 처리에 iptables 규칙 활용 확인 &gt;&gt; Service 가 100개 , 1000개 , 10000개 증가 되면???</span>
<span class="nv">$ </span>kubectl get svc webpod <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.spec.clusterIP}"</span>
<span class="c"># =&gt; 10.96.62.184</span>
<span class="nv">$ SVCIP</span><span class="o">=</span><span class="si">$(</span>kubectl get svc webpod <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s2">"{.spec.clusterIP}"</span><span class="si">)</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span> | <span class="nb">grep</span> <span class="nv">$SVCIP</span>
<span class="c"># =&gt; -A KUBE-SERVICES -d 10.96.62.184/32 -p tcp -m comment --comment "default/webpod cluster IP" -m tcp --dport 80 -j KUBE-SVC-CNZCPOCNCNOROALA</span>
<span class="c">#    -A KUBE-SVC-CNZCPOCNCNOROALA ! -s 10.244.0.0/16 -d 10.96.62.184/32 -p tcp -m comment --comment "default/webpod cluster IP" -m tcp --dport 80 -j KUBE-MARK-MASQ</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span> | <span class="nb">grep</span> <span class="nv">$SVCIP</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    -A KUBE-SERVICES -d 10.96.62.184/32 -p tcp -m comment --comment "default/webpod cluster IP" -m tcp --dport 80 -j KUBE-SVC-CNZCPOCNCNOROALA</span>
<span class="c">#    -A KUBE-SVC-CNZCPOCNCNOROALA ! -s 10.244.0.0/16 -d 10.96.62.184/32 -p tcp -m comment --comment "default/webpod cluster IP" -m tcp --dport 80 -j KUBE-MARK-MASQ</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w2 &lt;&lt;</span>
<span class="c">#    -A KUBE-SERVICES -d 10.96.62.184/32 -p tcp -m comment --comment "default/webpod cluster IP" -m tcp --dport 80 -j KUBE-SVC-CNZCPOCNCNOROALA</span>
<span class="c">#    -A KUBE-SVC-CNZCPOCNCNOROALA ! -s 10.244.0.0/16 -d 10.96.62.184/32 -p tcp -m comment --comment "default/webpod cluster IP" -m tcp --dport 80 -j KUBE-MARK-MASQ</span>
</code></pre></div></div>

<ul>
  <li>대규모 환경에서 iptables 단점
    <ul>
      <li>kube-proxy에 의해 생성되는 iptables 규칙이 많아질수록 성능 저하가 발생할 수 있습니다.</li>
      <li>특히, 많은 수의 서비스가 있는 경우 iptables 규칙이 급격히 증가하여 성능에 영향을 미칠 수 있습니다.</li>
      <li>테스트 클러스터에서 3800개 노드의 19000개 파드를 배포한 결과, iptables 규칙이 24,000개 이상 생성되었습니다.</li>
      <li>이로 인한 성능 저하는 다음과 같습니다.
        <ul>
          <li>통신 연결시 1.2ms의 지연이 발생했습니다.</li>
          <li>클러스터의 iptables 규칙 갱신이 5분 이상 소요되었습니다.</li>
          <li>53%의 CPU 오버헤드가 발생했습니다.</li>
        </ul>
      </li>
      <li>이러한 문제로 인해 iptables를 사용하지 않고 eBPF을 사용하는 cilium 과 같은 CNI 플러그인이 대안으로 인기를 얻고 있습니다.</li>
    </ul>
  </li>
</ul>

<h2 id="cilium-cni">Cilium CNI</h2>

<h3 id="cilium-cni-소개">Cilium CNI 소개</h3>

<ul>
  <li>
<strong>Cilium</strong>은 기존의 복잡한 네트워크 스택을 <strong>eBPF</strong>를 통해 <strong>간소화</strong>하고, <strong>빠르게 처리</strong>할 수 있도록 하는 CNI 플러그인입니다.</li>
  <li>iptables 기반의 kube-proxy를 대체하여, 앞서 살펴본 기존의 Iptables 기반의 CNI 플러그인 들의 단점을 대부분 해결할 수 있습니다.</li>
</ul>

<p><img src="/assets/2024/kans-3th/w8/20241026_kans_w8_5.png" alt="img.png" class="image-center w-80" loading="lazy" width="1600" height="1025">
<em class="image-caption"><a href="https://isovalent.com/blog/post/migrating-from-metallb-to-cilium/">https://isovalent.com/blog/post/migrating-from-metallb-to-cilium/</a></em></p>

<ul>
  <li>Cilium eBPF는 추가적인 코드 수정이나 설정 변경없이, 리눅스 커널에서 동작하는 Bytecode를 자유롭게 프로그래밍하여 커널에 로딩시켜 동작이 가능합니다. <a href="https://www.youtube.com/watch?v=qsnR-s4XuGo&amp;t=1059s">링크</a>
<img src="/assets/2025/cilium/w1/20250720_cilium_w1_19.png" alt="img.png" loading="lazy" width="1086" height="262">
</li>
  <li>또한 eBPF는 모든 패킷을 가로채기 위해서 수신 NIC의 ingress TC(<a href="https://netbeez.net/blog/how-to-use-the-linux-traffic-control/">Traffic Control</a>) hooks를 사용할 수 있습니다.
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_6.png" alt="img.png" class="image-center w-60" loading="lazy" width="1100" height="644">
<em class="image-caption">NIC의 TC Hooks에 eBPF 프로그램이 attach 된 예</em>
</li>
  <li>Cilium은 터널모드(VXLAN, GENEVE), 네이티브 라우팅 모드의 2가지 네트워크 모드를 제공합니다. <a href="https://docs.cilium.io/en/stable/network/concepts/routing/">Docs</a>
    <ul>
      <li>
<strong>터널모드</strong> : Cilium이 VXLAN(UDP 8472), GENEVE(UDP 6081) 인터페이스를 만들어서 이들을 통해 트래픽을 전달합니다. Encapsulation 모드라고도 합니다.</li>
      <li>
<strong>네이티브 라우팅 모드</strong> : Cilium가 패킷 전달을 위해 구성을 변경하지 않고, 외부에서 제공되는 패킷 전달 방법(클라우드 또는 BGP 라우팅등)을 사용합니다. Direct Routing 모드라고도 합니다.
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_7.png" alt="img.png" class="image-center w-80" loading="lazy" width="946" height="481">
<img src="/assets/2025/cilium/w1/20250720_cilium_w1_16.png" alt="img.png" loading="lazy" width="882" height="375">
</li>
    </ul>
  </li>
  <li>2021년 10월 Cilium은 CNCF에 채택되었습니다. <a href="https://cilium.io/blog/2021/10/13/cilium-joins-cncf/">링크</a>
</li>
  <li>Googke GKE dataplane과 AWS EKS Anywhere에서 기본 CNI로 Cilium을 사용하고 있습니다. <a href="https://isovalent.com/blog/post/2021-09-aws-eks-anywhere-chooses-cilium/">링크</a>
</li>
  <li>Cilium은 Kube-Proxy를 100% 대체 가능합니다.
    <ul>
      <li>iptables를 거의 사용하지 않고도 동작하며, 이를 통해 성능을 향상시킬 수 있습니다.</li>
      <li>하지만 istio, FHRP, VRRP 등과 같이 iptables 기능을 활용하는 동작들은 이슈가 발생할 수 있으며, 차츰 해결해 나가고 있습니다.</li>
      <li>동작 소개 1 - <a href="https://www.youtube.com/watch?v=yKPNmhckJHY">Youtube</a>
</li>
      <li>동작 소개 2 : ByteDance 사례 - <a href="https://www.youtube.com/watch?v=cKPW67D7X10">Youtube</a>, <a href="https://kccncchn2025.sched.com/event/1x5hK/simplifying-the-networking-and-security-stack-with-cilium-hubble-and-tetragon-liyi-huang-isovalent-at-cisco-kaixi-fan-bytedance">CNCF</a>
</li>
    </ul>
  </li>
  <li>구성요소 - <a href="https://ssup2.github.io/blog-software/docs/theory-analysis/kubernetes-cilium-plugin/">링크</a>
<img src="/assets/2024/kans-3th/w8/20241026_kans_w8_8.png" alt="img.png" class="image-center w-80" loading="lazy" width="2048" height="1664">
<em class="image-caption">Cilium 아키텍쳐 - <a href="https://github.com/cilium/cilium">출처</a></em>
    <ul>
      <li>Cilium <strong>Operator</strong> : K8S 클러스터에 대한 한 번씩 처리해야 하는 작업을 관리합니다.</li>
      <li>Cilium <strong>Agent</strong> : 데몬셋으로 실행, K8S API 설정으로 부터 ‘네트워크 설정, 네트워크 정책, 서비스 부하분산, 모니터링’ 등을 수행하며, eBPF 프로그램을 관리합니다.</li>
      <li>Cilium <strong>Client</strong> (CLI) : Cilium 커멘드툴로 eBPF maps 에 직접 접속하여 상태를 확인할 수 있습니다.</li>
      <li>
<strong>Hubble</strong> : 네트워크와 보안 모니터링 플랫폼 역할을 하여, Server, Relay, Client, Graphical UI 로 구성되어 있습니다.</li>
      <li>
<strong>Data Store</strong> : Cilium Agent 간의 상태를 저장하고 전파하는 데이터 저장소, 2가지 종류 중 선택(K8S CRDs, Key-Value Store)할 수 있습니다.
<img src="/assets/2025/cilium/w1/20250720_cilium_w1_17.png" alt="img.png" loading="lazy" width="651" height="435">
<img src="/assets/2025/cilium/w1/20250720_cilium_w1_18.png" alt="img_1.png" loading="lazy" width="767" height="527">
</li>
    </ul>
  </li>
</ul>

<h3 id="cilium-cni-설치">Cilium CNI 설치</h3>

<h4 id="cilium-시스템-요구-사항-확인---공식-문서">Cilium 시스템 요구 사항 확인 - <a href="https://docs.cilium.io/en/stable/operations/system_requirements/">공식 문서</a>
</h4>

<ul>
  <li>AMD64 또는 AArch64 CPU 아키텍처를 사용하는 호스트</li>
  <li>
<a href="https://docs.cilium.io/en/stable/operations/system_requirements/#linux-kernel">Linux 커널</a> 5.4 이상 또는 동등 버전(예: RHEL 8.6의 경우 4.18)
    <div class="language-bash highlighter-rouge">
<div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">arch</span>
<span class="c"># =&gt; aarch64</span>
      
<span class="nv">$ </span><span class="nb">uname</span> <span class="nt">-r</span>
<span class="c"># =&gt; 6.8.0-53-generic</span>
</code></pre></div>    </div>
  </li>
  <li>커널 구성 옵션 활성화
    <div class="language-bash highlighter-rouge">
<div class="highlight"><pre class="highlight"><code><span class="c"># [커널 구성 옵션] 기본 요구 사항 </span>
<span class="nv">$ </span><span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'CONFIG_BPF|CONFIG_BPF_SYSCALL|CONFIG_NET_CLS_BPF|CONFIG_BPF_JIT|CONFIG_NET_CLS_ACT|CONFIG_NET_SCH_INGRESS|CONFIG_CRYPTO_SHA1|CONFIG_CRYPTO_USER_API_HASH|CONFIG_CGROUPS|CONFIG_CGROUP_BPF|CONFIG_PERF_EVENTS|CONFIG_SCHEDSTATS'</span> /boot/config-<span class="si">$(</span><span class="nb">uname</span> <span class="nt">-r</span><span class="si">)</span>
<span class="c"># =&gt; CONFIG_BPF=y</span>
<span class="c">#    CONFIG_BPF_SYSCALL=y</span>
<span class="c">#    CONFIG_BPF_JIT=y</span>
<span class="c">#    CONFIG_BPF_JIT_ALWAYS_ON=y</span>
<span class="c">#    CONFIG_BPF_JIT_DEFAULT_ON=y</span>
<span class="c">#    CONFIG_BPF_UNPRIV_DEFAULT_OFF=y</span>
<span class="c">#    # CONFIG_BPF_PRELOAD is not set</span>
<span class="c">#    CONFIG_BPF_LSM=y</span>
<span class="c">#    CONFIG_CGROUPS=y</span>
<span class="c">#    CONFIG_CGROUP_BPF=y</span>
<span class="c">#    CONFIG_PERF_EVENTS=y</span>
<span class="c">#    CONFIG_NET_SCH_INGRESS=m</span>
<span class="c">#    CONFIG_NET_CLS_BPF=m</span>
<span class="c">#    CONFIG_NET_CLS_ACT=y</span>
<span class="c">#    CONFIG_BPF_STREAM_PARSER=y</span>
<span class="c">#    CONFIG_CRYPTO_SHA1=y</span>
<span class="c">#    CONFIG_CRYPTO_USER_API_HASH=m</span>
<span class="c">#    CONFIG_CRYPTO_SHA1_ARM64_CE=m</span>
<span class="c">#    CONFIG_SCHEDSTATS=y</span>
<span class="c">#    CONFIG_BPF_EVENTS=y</span>
<span class="c">#    CONFIG_BPF_KPROBE_OVERRIDE=y</span>
    
<span class="c"># [커널 구성 옵션] Requirements for Tunneling and Routing</span>
<span class="nv">$ </span><span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'CONFIG_VXLAN=y|CONFIG_VXLAN=m|CONFIG_GENEVE=y|CONFIG_GENEVE=m|CONFIG_FIB_RULES=y'</span> /boot/config-<span class="si">$(</span><span class="nb">uname</span> <span class="nt">-r</span><span class="si">)</span>
<span class="nv">$ CONFIG_FIB_RULES</span><span class="o">=</span>y <span class="c"># 커널에 내장됨</span>
<span class="nv">$ CONFIG_VXLAN</span><span class="o">=</span>m <span class="c"># 모듈로 컴파일됨 → 커널에 로드해서 사용</span>
<span class="nv">$ CONFIG_GENEVE</span><span class="o">=</span>m <span class="c"># 모듈로 컴파일됨 → 커널에 로드해서 사용</span>
    
<span class="c">## (참고) 커널 로드</span>
<span class="nv">$ </span>lsmod | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'vxlan|geneve'</span>
<span class="c"># =&gt; vxlan                 147456  0</span>
<span class="c">#    ip6_udp_tunnel         16384  1 vxlan</span>
<span class="c">#    udp_tunnel             36864  1 vxlan</span>
<span class="nv">$ </span>modprobe geneve
<span class="nv">$ </span>lsmod | <span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'vxlan|geneve'</span>
<span class="c"># =&gt; geneve                 45056  0</span>
<span class="c">#    vxlan                 147456  0</span>
<span class="c">#    ip6_udp_tunnel         16384  2 geneve,vxlan</span>
<span class="c">#    udp_tunnel             36864  2 geneve,vxlan</span>
    
<span class="c"># [커널 구성 옵션] Requirements for L7 and FQDN Policies</span>
<span class="nv">$ </span><span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'CONFIG_NETFILTER_XT_TARGET_TPROXY|CONFIG_NETFILTER_XT_TARGET_MARK|CONFIG_NETFILTER_XT_TARGET_CT|CONFIG_NETFILTER_XT_MATCH_MARK|CONFIG_NETFILTER_XT_MATCH_SOCKET'</span> /boot/config-<span class="si">$(</span><span class="nb">uname</span> <span class="nt">-r</span><span class="si">)</span>
<span class="c"># =&gt; CONFIG_NETFILTER_XT_TARGET_CT=m</span>
<span class="c">#    CONFIG_NETFILTER_XT_TARGET_MARK=m</span>
<span class="c">#    CONFIG_NETFILTER_XT_TARGET_TPROXY=m</span>
<span class="c">#    CONFIG_NETFILTER_XT_MATCH_MARK=m</span>
<span class="c">#    CONFIG_NETFILTER_XT_MATCH_SOCKET=m</span>
    
<span class="c"># [커널 구성 옵션] Requirements for Netkit Device Mode</span>
<span class="nv">$ </span><span class="nb">grep</span> <span class="nt">-E</span> <span class="s1">'CONFIG_NETKIT=y|CONFIG_NETKIT=m'</span> /boot/config-<span class="si">$(</span><span class="nb">uname</span> <span class="nt">-r</span><span class="si">)</span>
<span class="c"># =&gt; CONFIG_NETKIT=y</span>
</code></pre></div>    </div>
  </li>
  <li>
    <p>고급 기능 동작을 위한 최소 커널 버전 - <a href="https://docs.cilium.io/en/stable/operations/system_requirements/#required-kernel-versions-for-advanced-features">Docs</a></p>

    <table>
      <thead>
        <tr>
          <th><strong>Cilium Feature</strong></th>
          <th><strong>Minimum Kernel Version</strong></th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td><a href="https://docs.cilium.io/en/stable/security/network/encryption-wireguard/#encryption-wg">WireGuard Transparent Encryption</a></td>
          <td>&gt;= 5.6</td>
        </tr>
        <tr>
          <td>Full support for <a href="https://docs.cilium.io/en/stable/network/kubernetes/kubeproxy-free/#session-affinity">Session Affinity</a>
</td>
          <td>&gt;= 5.7</td>
        </tr>
        <tr>
          <td>BPF-based proxy redirection</td>
          <td>&gt;= 5.7</td>
        </tr>
        <tr>
          <td>Socket-level LB bypass in pod netns</td>
          <td>&gt;= 5.7</td>
        </tr>
        <tr>
          <td>L3 devices</td>
          <td>&gt;= 5.8</td>
        </tr>
        <tr>
          <td><strong>BPF-based host routing</strong></td>
          <td><strong>&gt;= 5.10</strong></td>
        </tr>
        <tr>
          <td>
<a href="https://docs.cilium.io/en/stable/network/multicast/#enable-multicast">Multicast Support in Cilium (Beta)</a> (AMD64)</td>
          <td>&gt;= 5.10</td>
        </tr>
        <tr>
          <td>IPv6 BIG TCP support</td>
          <td>&gt;= 5.19</td>
        </tr>
        <tr>
          <td>
<a href="https://docs.cilium.io/en/stable/network/multicast/#enable-multicast">Multicast Support in Cilium (Beta)</a> (AArch64)</td>
          <td>&gt;= 6.0</td>
        </tr>
        <tr>
          <td><strong>IPv4 BIG TCP support</strong></td>
          <td><strong>&gt;= 6.3</strong></td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>Cilium 동작(Node 간)을 위한 방화벽 규칙 : 해당 포트 인/아웃 허용 필요 - <a href="https://docs.cilium.io/en/stable/operations/system_requirements/#firewall-rules">Docs</a>
</li>
  <li>
<strong>Mounted eBPF filesystem</strong> : 일부 배포판 마운트되어 있음, 혹은 Cilium 설치 시 마운트 시도 - <a href="https://docs.cilium.io/en/stable/operations/system_requirements/#mounted-ebpf-filesystem">Docs</a>
    <div class="language-bash highlighter-rouge">
<div class="highlight"><pre class="highlight"><code><span class="c"># eBPF 파일 시스템 마운트 확인</span>
<span class="nv">$ </span>mount | <span class="nb">grep</span> /sys/fs/bpf
<span class="c"># =&gt; bpf on /sys/fs/bpf type bpf (rw,nosuid,nodev,noexec,relatime,mode=700)</span>
</code></pre></div>    </div>
  </li>
  <li>
<strong>Privileges</strong> : Cilium 동작을 위해서 관리자 수준 권한 필요 - <a href="https://docs.cilium.io/en/stable/operations/system_requirements/#privileges">Docs</a>
    <ul>
      <li>cilium은 네트워킹 작업과 보안 정책을 구현하는 eBPF 프로그램 설치를 위해 리눅스 커널과 상호작용합니다. 
이 작업은 관리자 권한이 필요하며, cilium은 이를 위해 <code class="language-plaintext highlighter-rouge">CAP_SYS_ADMIN</code> 권한을 사용합니다. 또한 해당 권한은 cilium-agent 컨테이너에 부여되어야 합니다.</li>
      <li>가장 편리한 방법은 cilium-agent를 <code class="language-plaintext highlighter-rouge">root</code> 사용자나 privileged 모드로 실행하는 것입니다.</li>
      <li>cilium은 또한 호스트 네트워킹 네임스페이스에 대한 접근을 필요로 합니다. 따라서 cilium 파드는 호스트 네트워킹 네임스페이스에 직접 사용할 수 있도록 설정되어야 합니다.</li>
    </ul>
  </li>
</ul>

<h4 id="kube-proxy-제거">kube-proxy 제거</h4>

<ul>
  <li>기존 Flannel CNI를 제거합니다.
    <div class="language-bash highlighter-rouge">
<div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>helm uninstall <span class="nt">-n</span> kube-flannel flannel
<span class="c"># =&gt; release "flannel" uninstalled</span>
<span class="nv">$ </span>helm list <span class="nt">-A</span>
<span class="c"># =&gt; NAME    NAMESPACE       REVISION        UPDATED STATUS  CHART   APP VERSION</span>
  
<span class="c">#</span>
<span class="nv">$ </span>kubectl get all <span class="nt">-n</span> kube-flannel
<span class="nv">$ </span><span class="o">=&gt;</span> No resources found <span class="k">in </span>kube-flannel namespace.
<span class="nv">$ </span>kubectl delete ns kube-flannel
<span class="c"># =&gt; namespace "kube-flannel" deleted</span>
  
<span class="nv">$ </span>kubectl get pod <span class="nt">-A</span> <span class="nt">-owide</span>
</code></pre></div>    </div>
  </li>
  <li>k8s-ctr, k8s-w1, k8s-w2 모든 노드에서 아래 실행하여 flannel 관련된 인터페이스를 제거합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 제거 전 확인</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> <span class="nb">link</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    4: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default</span>
<span class="c">#        link/ether aa:3f:e5:cd:ae:92 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    5: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 1e:a9:44:a0:00:e1 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    6: veth322e34b5@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 8e:ea:40:c5:46:a7 brd ff:ff:ff:ff:ff:ff link-netns cni-62beabc5-97a9-e6cf-7f8f-bd4de413d33c</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> <span class="nb">link</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    ...</span>
<span class="c">#    4: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default</span>
<span class="c">#        link/ether c2:b2:62:af:c2:93 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    5: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 06:8a:4c:62:12:de brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    6: vethd8fb7cb1@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether e2:3f:03:c3:be:a2 brd ff:ff:ff:ff:ff:ff link-netns cni-81f15ae4-4a35-bce7-f755-657f3b8e39ea</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w2 &lt;&lt;</span>
<span class="c">#    ...</span>
<span class="c">#    4: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default</span>
<span class="c">#        link/ether 02:dd:56:d3:f6:3f brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    5: cni0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 06:57:05:39:42:57 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#    6: veth390f8e9e@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 5a:23:ff:ba:28:90 brd ff:ff:ff:ff:ff:ff link-netns cni-a27cec88-43c0-acf5-0bc5-f64e945bded3</span>
<span class="c">#    7: veth357a49b9@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether b6:6c:69:43:29:a6 brd ff:ff:ff:ff:ff:ff link-netns cni-36af9b39-bcb8-ad52-beb5-4b67475b404f</span>
<span class="c">#    8: vethf9bb5584@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue master cni0 state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 4a:7c:ab:42:e7:ca brd ff:ff:ff:ff:ff:ff link-netns cni-29e132ee-4860-b74c-c4f5-d5d27b341b83</span>

<span class="nv">$ </span>brctl show
<span class="c"># =&gt; bridge name     bridge id               STP enabled     interfaces</span>
<span class="c">#    cni0            8000.1ea944a000e1       no              veth322e34b5</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> brctl show <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    bridge name     bridge id               STP enabled     interfaces</span>
<span class="c">#    cni0            8000.068a4c6212de       no              vethd8fb7cb1</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w2 &lt;&lt;</span>
<span class="c">#    bridge name     bridge id               STP enabled     interfaces</span>
<span class="c">#    cni0            8000.065705394257       no              veth357a49b9</span>
<span class="c">#                                                            veth390f8e9e</span>
<span class="c">#                                                            vethf9bb5584</span>

<span class="nv">$ </span>ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.244.0.0/24 dev cni0 proto kernel scope link src 10.244.0.1</span>
<span class="c">#    10.244.1.0/24 via 10.244.1.0 dev flannel.1 onlink</span>
<span class="c">#    10.244.2.0/24 via 10.244.2.0 dev flannel.1 onlink</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.100</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> route <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.244.0.0/24 via 10.244.0.0 dev flannel.1 onlink</span>
<span class="c">#    10.244.1.0/24 dev cni0 proto kernel scope link src 10.244.1.1</span>
<span class="c">#    10.244.2.0/24 via 10.244.2.0 dev flannel.1 onlink</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.101</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w2 &lt;&lt;</span>
<span class="c">#    default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.244.0.0/24 via 10.244.0.0 dev flannel.1 onlink</span>
<span class="c">#    10.244.1.0/24 via 10.244.1.0 dev flannel.1 onlink</span>
<span class="c">#    10.244.2.0/24 dev cni0 proto kernel scope link src 10.244.2.1</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.102</span>

<span class="c"># vnic 제거</span>
<span class="nv">$ </span>ip <span class="nb">link </span>del flannel.1
<span class="nv">$ </span>ip <span class="nb">link </span>del cni0

<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>ip <span class="nb">link </span>del flannel.1 <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>ip <span class="nb">link </span>del cni0 <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>

<span class="c"># 제거 확인</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> <span class="nb">link</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    6: veth322e34b5@if2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP mode DEFAULT group default qlen 1000</span>
<span class="c">#        link/ether 8e:ea:40:c5:46:a7 brd ff:ff:ff:ff:ff:ff link-netns cni-62beabc5-97a9-e6cf-7f8f-bd4de413d33c</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 flannel.1과 cni0가 삭제되었습니다.&lt;/span&gt;</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> <span class="nb">link</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>

<span class="nv">$ </span>brctl show
<span class="c"># =&gt; &lt;span style="color: green;"&gt;없음&lt;/span&gt;</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> brctl show <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    &gt;&gt; node : k8s-w2 &lt;&lt;</span>

<span class="nv">$ </span>ip <span class="nt">-c</span> route
<span class="c"># =&gt; default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.100</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh <span class="nt">-o</span> <span class="nv">StrictHostKeyChecking</span><span class="o">=</span>no vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> route <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="c"># =&gt; &gt;&gt; node : k8s-w1 &lt;&lt;</span>
<span class="c">#    default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.101</span>
<span class="c">#    </span>
<span class="c">#    &gt;&gt; node : k8s-w2 &lt;&lt;</span>
<span class="c">#    default via 10.0.2.2 dev eth0 proto dhcp src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.0/24 dev eth0 proto kernel scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.2 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    10.0.2.3 dev eth0 proto dhcp scope link src 10.0.2.15 metric 100</span>
<span class="c">#    192.168.10.0/24 dev eth1 proto kernel scope link src 192.168.10.102</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 flannel.1과 cni0가 삭제되어, 관련 라우팅 정보가 삭제되었습니다.&lt;/span&gt;</span>
</code></pre></div></div>

<ul>
  <li>기존 kube-proxy를 제거합니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system delete ds kube-proxy
<span class="c"># =&gt; daemonset.apps "kube-proxy" deleted</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system delete cm kube-proxy
<span class="c"># =&gt; configmap "kube-proxy" deleted</span>

<span class="c"># 배포된 파드의 IP는 남겨져 있습니다.</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-A</span> <span class="nt">-owide</span>
<span class="c"># =&gt; NAMESPACE     NAME                              READY   STATUS             RESTARTS         AGE     IP               NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    default       curl-pod                          1/1     Running            1 (143m ago)     3h1m    10.244.0.3       k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    default       webpod-697b545f57-7j5vt           1/1     Running            1 (142m ago)     3h2m    10.244.1.3       k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    default       webpod-697b545f57-sdv4l           1/1     Running            1 (142m ago)     3h2m    10.244.2.7       k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-79mbb          0/1     CrashLoopBackOff   27 (4m ago)      2d17h   10.244.2.5       k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-rtx95          0/1     CrashLoopBackOff   27 (4m26s ago)   2d17h   10.244.2.6       k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   etcd-k8s-ctr                      1/1     Running            4 (143m ago)     2d17h   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-apiserver-k8s-ctr            1/1     Running            4 (143m ago)     2d17h   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-controller-manager-k8s-ctr   1/1     Running            4 (143m ago)     2d17h   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    kube-system   kube-scheduler-k8s-ctr            1/1     Running            4 (143m ago)     2d17h   192.168.10.100   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl webpod
<span class="c"># =&gt; curl: (6) Could not resolve host: webpod</span>
<span class="c">#    command terminated with exit code 6</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 kube-proxy와 CNI의 삭제로 coredns가 동작하지 않아서 webpod 서비스에 접근할 수 없습니다.&lt;/span&gt;</span>

<span class="c">#</span>
<span class="nv">$ </span>iptables-save

<span class="c"># Run on each node with root permissions:</span>
<span class="nv">$ </span>iptables-save | <span class="nb">grep</span> <span class="nt">-v</span> KUBE | <span class="nb">grep</span> <span class="nt">-v</span> FLANNEL | iptables-restore
<span class="nv">$ </span>iptables-save

<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w1 <span class="s2">"sudo iptables-save | grep -v KUBE | grep -v FLANNEL | sudo iptables-restore"</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w1 <span class="nb">sudo </span>iptables-save

<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w2 <span class="s2">"sudo iptables-save | grep -v KUBE | grep -v FLANNEL | sudo iptables-restore"</span>
<span class="nv">$ </span>sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-w2 <span class="nb">sudo </span>iptables-save

<span class="c">#</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                      READY   STATUS    RESTARTS       AGE     IP           NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    curl-pod                  1/1     Running   1 (155m ago)   3h14m   10.244.0.3   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-697b545f57-7j5vt   1/1     Running   1 (155m ago)   3h14m   10.244.1.3   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-697b545f57-sdv4l   1/1     Running   1 (155m ago)   3h14m   10.244.2.7   k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
</code></pre></div></div>

<ul>
  <li>노드별 파드에 할당되는 IPAM(PodCIDR) 정보를 확인해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#--allocate-node-cidrs=true 로 설정된 kube-controller-manager에서 CIDR을 자동 할당함</span>
<span class="nv">$ </span>kubectl get nodes <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{range .items[*]}{.metadata.name}{"\t"}{.spec.podCIDR}{"\n"}{end}'</span>
<span class="c"># =&gt; k8s-ctr 10.244.0.0/24</span>
<span class="c">#    k8s-w1  10.244.1.0/24</span>
<span class="c">#    k8s-w2  10.244.2.0/24</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                      READY   STATUS    RESTARTS       AGE     IP           NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    curl-pod                  1/1     Running   1 (157m ago)   3h15m   10.244.0.3   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-697b545f57-7j5vt   1/1     Running   1 (156m ago)   3h16m   10.244.1.3   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-697b545f57-sdv4l   1/1     Running   1 (156m ago)   3h16m   10.244.2.7   k8s-w2    &lt;none&gt;           &lt;none&gt;</span>

<span class="c">#</span>
<span class="nv">$ </span>kc describe pod <span class="nt">-n</span> kube-system kube-controller-manager-k8s-ctr
<span class="c"># =&gt; ...</span>
<span class="c">#       Command:</span>
<span class="c">#          kube-controller-manager</span>
<span class="c">#          --allocate-node-cidrs=true</span>
<span class="c">#          --cluster-cidr=10.244.0.0/16</span>
<span class="c">#          --service-cluster-ip-range=10.96.0.0/16</span>
<span class="c">#    ... </span>
</code></pre></div></div>

<h4 id="cilium-cni-설치-with-helm">Cilium CNI 설치 with Helm</h4>

<ul>
  <li>관련 문서 : <a href="https://docs.cilium.io/en/stable/helm-reference/">Helm</a>, <a href="https://docs.cilium.io/en/stable/network/concepts/masquerading/">Masquering</a>, <a href="https://docs.cilium.io/en/stable/network/concepts/ipam/cluster-pool/">ClusterScope</a>, <a href="https://docs.cilium.io/en/stable/network/concepts/routing/">Routing</a>
</li>
  <li>Cilium 1.17.5 Helm Chart - <a href="https://artifacthub.io/packages/helm/cilium/cilium/1.17.5">ArtifactHub</a>를 사용하여 설치합니다.
<img src="/assets/2025/cilium/w1/20250720_cilium_w1_3.png" alt="img.png" loading="lazy" width="714" height="175">
</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Cilium 설치 with Helm</span>
<span class="nv">$ </span>helm repo add cilium https://helm.cilium.io/
<span class="c"># =&gt; "cilium" has been added to your repositories</span>

<span class="c"># 모든 NIC 지정 + bpf.masq=true + NoIptablesRules</span>
<span class="nv">$ </span>helm <span class="nb">install </span>cilium cilium/cilium <span class="nt">--version</span> 1.17.5 <span class="nt">--namespace</span> kube-system <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">k8sServiceHost</span><span class="o">=</span>192.168.10.100 <span class="nt">--set</span> <span class="nv">k8sServicePort</span><span class="o">=</span>6443 <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">kubeProxyReplacement</span><span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">routingMode</span><span class="o">=</span>native <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">autoDirectNodeRoutes</span><span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> ipam.mode<span class="o">=</span><span class="s2">"cluster-pool"</span> <span class="se">\</span>
  <span class="nt">--set</span> ipam.operator.clusterPoolIPv4PodCIDRList<span class="o">={</span><span class="s2">"172.20.0.0/16"</span><span class="o">}</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">ipv4NativeRoutingCIDR</span><span class="o">=</span>172.20.0.0/16 <span class="se">\</span>
  <span class="nt">--set</span> endpointRoutes.enabled<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> <span class="nv">installNoConntrackIptablesRules</span><span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> bpf.masquerade<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
  <span class="nt">--set</span> ipv6.enabled<span class="o">=</span><span class="nb">false</span>
<span class="c"># =&gt; NAME: cilium</span>
<span class="c">#    LAST DEPLOYED: Sat Jul 19 17:34:05 2025</span>
<span class="c">#    NAMESPACE: kube-system</span>
<span class="c">#    STATUS: deployed</span>
<span class="c">#    REVISION: 1</span>
<span class="c">#    TEST SUITE: None</span>
<span class="c">#    NOTES:</span>
<span class="c">#    You have successfully installed Cilium with Hubble.</span>
<span class="c">#    </span>
<span class="c">#    Your release version is 1.17.5.</span>

<span class="c"># 확인</span>
<span class="nv">$ </span>helm get values cilium <span class="nt">-n</span> kube-system
<span class="c"># =&gt; USER-SUPPLIED VALUES:</span>
<span class="c">#    autoDirectNodeRoutes: true</span>
<span class="c">#    bpf:</span>
<span class="c">#      masquerade: true</span>
<span class="c">#    endpointRoutes:</span>
<span class="c">#      enabled: true</span>
<span class="c">#    installNoConntrackIptablesRules: true</span>
<span class="c">#    ipam:</span>
<span class="c">#      mode: cluster-pool</span>
<span class="c">#      operator:</span>
<span class="c">#        clusterPoolIPv4PodCIDRList:</span>
<span class="c">#        - 172.20.0.0/16</span>
<span class="c">#    ipv4NativeRoutingCIDR: 172.20.0.0/16</span>
<span class="c">#    ipv6:</span>
<span class="c">#      enabled: false</span>
<span class="c">#    k8sServiceHost: 192.168.10.100</span>
<span class="c">#    k8sServicePort: 6443</span>
<span class="c">#    kubeProxyReplacement: true</span>
<span class="c">#    routingMode: native</span>
<span class="nv">$ </span>helm list <span class="nt">-A</span>
<span class="c"># =&gt; NAME    NAMESPACE       REVISION        UPDATED                                 STATUS          CHART           APP VERSION</span>
<span class="c">#    cilium  kube-system     1               2025-07-19 17:34:05.700270399 +0900 KST deployed        cilium-1.17.5   1.17.5</span>
<span class="nv">$ </span>kubectl get crd
<span class="c"># =&gt; No resources found</span>
<span class="nv">$ </span>watch <span class="nt">-d</span> kubectl get pod <span class="nt">-A</span>
<span class="c"># =&gt; Every 2.0s: kubectl get pod -A                                                                                                                 k8s-ctr: Sat Jul 19 17:36:42 2025</span>
<span class="c">#    </span>
<span class="c">#    NAMESPACE     NAME                               READY   STATUS    RESTARTS       AGE</span>
<span class="c">#    default       curl-pod                           1/1     Running   1 (166m ago)   3h24m</span>
<span class="c">#    default       webpod-697b545f57-7j5vt            1/1     Running   1 (165m ago)   3h25m</span>
<span class="c">#    default       webpod-697b545f57-sdv4l            1/1     Running   1 (165m ago)   3h25m</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-envoy-b2mn9&lt;/span&gt;                 1/1     Running   0              2m36s</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-envoy-dgdmn&lt;/span&gt;                 1/1     Running   0              2m36s</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-envoy-pjn95&lt;/span&gt;                 1/1     Running   0              2m36s</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-fl689&lt;/span&gt;                       1/1     Running   0              2m36s</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-mqnkn&lt;/span&gt;                       1/1     Running   0              2m36s</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-operator-865bc7f457-hpwvh&lt;/span&gt;   1/1     Running   0              2m36s</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-operator-865bc7f457-v5k84&lt;/span&gt;   1/1     Running   0              2m36s</span>
<span class="c">#    kube-system   &lt;span style="color: green;"&gt;cilium-zz9k4&lt;/span&gt;                       1/1     Running   0              2m36s</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-7q52c           1/1     &lt;span style="color: green;"&gt;Running&lt;/span&gt;   0              52s</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-bvsfb           1/1     &lt;span style="color: green;"&gt;Running&lt;/span&gt;   0              66s</span>
<span class="c">#    kube-system   etcd-k8s-ctr                       1/1     Running   4 (166m ago)   2d18h</span>
<span class="c">#    kube-system   kube-apiserver-k8s-ctr             1/1     Running   4 (166m ago)   2d18h</span>
<span class="c">#    kube-system   kube-controller-manager-k8s-ctr    1/1     Running   4 (166m ago)   2d18h</span>
<span class="c">#    kube-system   kube-scheduler-k8s-ctr             1/1     Running   4 (166m ago)   2d18h</span>
<span class="c"># &lt;span style="color: green;"&gt;👉 cilium 관련된 파드가 배포되었고 coredns 파드도 정상적으로 동작합니다.&lt;/span&gt;</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium-dbg status <span class="nt">--verbose</span>
<span class="c"># =&gt; KubeProxyReplacement:   True   [eth0    10.0.2.15 fd17:625c:f037:2:a00:27ff:fe71:19d8 fe80::a00:27ff:fe71:19d8, eth1   192.168.10.102 fe80::a00:27ff:fe79:58ac (Direct Routing)]</span>
<span class="c">#    ...</span>
<span class="c">#    Routing:                Network: Native   Host: BPF</span>
<span class="c">#    ...</span>
<span class="c">#    Masquerading:           BPF   [eth0, eth1]   172.20.0.0/16 [IPv4: Enabled, IPv6: Disabled]</span>
<span class="c">#    ...</span>

<span class="c"># 노드에 iptables 확인</span>
<span class="nv">$ </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span>
<span class="c"># =&gt; -P PREROUTING ACCEPT</span>
<span class="c">#    -P INPUT ACCEPT</span>
<span class="c">#    -P OUTPUT ACCEPT</span>
<span class="c">#    -P POSTROUTING ACCEPT</span>
<span class="c">#    -N CILIUM_OUTPUT_nat</span>
<span class="c">#    -N CILIUM_POST_nat</span>
<span class="c">#    -N CILIUM_PRE_nat</span>
<span class="c">#    -N KUBE-KUBELET-CANARY</span>
<span class="c">#    -A PREROUTING -m comment --comment "cilium-feeder: CILIUM_PRE_nat" -j CILIUM_PRE_nat</span>
<span class="c">#    -A OUTPUT -m comment --comment "cilium-feeder: CILIUM_OUTPUT_nat" -j CILIUM_OUTPUT_nat</span>
<span class="c">#    -A POSTROUTING -m comment --comment "cilium-feeder: CILIUM_POST_nat" -j CILIUM_POST_nat</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>iptables <span class="nt">-t</span> nat <span class="nt">-S</span> <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>

<span class="nv">$ </span>iptables-save
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> <span class="nb">sudo </span>iptables-save <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span> 
</code></pre></div></div>

<ul>
  <li>PodCIDR IPAM 확인해보겠습니다. - <a href="https://docs.cilium.io/en/stable/network/concepts/ipam/cluster-pool/">ClusterScope</a>
</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>kubectl get nodes <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{range .items[*]}{.metadata.name}{"\t"}{.spec.podCIDR}{"\n"}{end}'</span>
<span class="c"># =&gt; k8s-ctr 10.244.0.0/24</span>
<span class="c">#    k8s-w1  10.244.1.0/24</span>
<span class="c">#    k8s-w2  10.244.2.0/24</span>

<span class="c"># 파드 IP 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                      READY   STATUS    RESTARTS       AGE     IP           NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    curl-pod                  1/1     Running   1 (172m ago)   3h30m   10.244.0.3   k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-697b545f57-7j5vt   1/1     Running   1 (171m ago)   3h30m   10.244.1.3   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-697b545f57-sdv4l   1/1     Running   1 (171m ago)   3h30m   10.244.2.7   k8s-w2    &lt;none&gt;           &lt;none&gt;</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl get ciliumnodes
<span class="c"># =&gt; NAME      CILIUMINTERNALIP   INTERNALIP       AGE</span>
<span class="c">#    k8s-ctr   172.20.2.68        192.168.10.100   6m11s</span>
<span class="c">#    k8s-w1    172.20.1.88        192.168.10.101   6m50s</span>
<span class="c">#    k8s-w2    172.20.0.235       192.168.10.102   7m8s</span>
<span class="nv">$ </span>kubectl get ciliumnodes <span class="nt">-o</span> json | <span class="nb">grep </span>podCIDRs <span class="nt">-A2</span>
<span class="c"># =&gt;                     "podCIDRs": [</span>
<span class="c">#                            "172.20.2.0/24"</span>
<span class="c">#                        ],</span>
<span class="c">#    --</span>
<span class="c">#                        "podCIDRs": [</span>
<span class="c">#                            "172.20.1.0/24"</span>
<span class="c">#                        ],</span>
<span class="c">#    --</span>
<span class="c">#                        "podCIDRs": [</span>
<span class="c">#                            "172.20.0.0/24"</span>
<span class="c">#                        ],</span>

<span class="c">#</span>
<span class="nv">$ </span>kubectl rollout restart deployment webpod
<span class="c"># =&gt; deployment.apps/webpod restarted</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                      READY   STATUS    RESTARTS       AGE     IP             NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    curl-pod                  1/1     Running   1 (172m ago)   3h31m   10.244.0.3     k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-86f878c468-448pc   1/1     Running   0              11s     172.20.0.202   k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-86f878c468-ttbs2   1/1     Running   0              15s     172.20.1.123   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>

<span class="c"># k8s-ctr 노드에 curl-pod 파드 배포</span>
<span class="nv">$ </span>kubectl delete pod curl-pod <span class="nt">--grace-period</span><span class="o">=</span>0
<span class="c"># =&gt; pod "curl-pod" deleted</span>

<span class="nv">$ </span><span class="nb">cat</span> <span class="o">&lt;&lt;</span><span class="no">EOF</span><span class="sh"> | kubectl apply -f -
apiVersion: v1
kind: Pod
metadata:
  name: curl-pod
  labels:
    app: curl
spec:
  nodeName: k8s-ctr
  containers:
  - name: curl
    image: nicolaka/netshoot
    command: ["tail"]
    args: ["-f", "/dev/null"]
  terminationGracePeriodSeconds: 0
</span><span class="no">EOF
</span><span class="c"># =&gt; pod/curl-pod created</span>

<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                      READY   STATUS    RESTARTS   AGE   IP             NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    curl-pod                  1/1     Running   0          33s   172.20.2.15    k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-86f878c468-448pc   1/1     Running   0          66s   172.20.0.202   k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-86f878c468-ttbs2   1/1     Running   0          70s   172.20.1.123   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="nv">$ </span>kubectl get ciliumendpoints
<span class="c"># =&gt; NAME                      SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    curl-pod                  5180                ready            172.20.2.15</span>
<span class="c">#    webpod-86f878c468-448pc   34270               ready            172.20.0.202</span>
<span class="c">#    webpod-86f878c468-ttbs2   34270               ready            172.20.1.123</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium-dbg endpoint list
<span class="c"># =&gt; ENDPOINT   POLICY (ingress)   POLICY (egress)   IDENTITY   LABELS (source:key[=value])                                                  IPv6   IPv4           STATUS</span>
<span class="c">#               ENFORCEMENT        ENFORCEMENT</span>
<span class="c">#    60         Disabled           Disabled          20407      k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=kube-system          172.20.0.167   ready</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.cluster=default</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.serviceaccount=coredns</span>
<span class="c">#                                                               k8s:io.kubernetes.pod.namespace=kube-system</span>
<span class="c">#                                                               k8s:k8s-app=kube-dns</span>
<span class="c">#    71         Disabled           Disabled          4          reserved:health                                                                     172.20.0.114   ready</span>
<span class="c">#    1368       Disabled           Disabled          20407      k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=kube-system          172.20.0.92    ready</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.cluster=default</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.serviceaccount=coredns</span>
<span class="c">#                                                               k8s:io.kubernetes.pod.namespace=kube-system</span>
<span class="c">#                                                               k8s:k8s-app=kube-dns</span>
<span class="c">#    2533       Disabled           Disabled          1          reserved:host                                                                                      ready</span>
<span class="c">#    2605       Disabled           Disabled          34270      k8s:app=webpod                                                                      172.20.0.202   ready</span>
<span class="c">#                                                               k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name=default</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.cluster=default</span>
<span class="c">#                                                               k8s:io.cilium.k8s.policy.serviceaccount=default</span>
<span class="c">#                                                               k8s:io.kubernetes.pod.namespace=default</span>

<span class="c"># 통신 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl webpod | <span class="nb">grep </span>Hostname
<span class="c"># =&gt; Hostname: webpod-86f878c468-448pc</span>

</code></pre></div></div>

<h3 id="cilium-설치-확인">Cilium 설치 확인</h3>

<ul>
  <li>cilium cli를 설치하여 Cilium 상태를 확인해 보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># cilium cli 설치</span>
<span class="nv">$ CILIUM_CLI_VERSION</span><span class="o">=</span><span class="si">$(</span>curl <span class="nt">-s</span> https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt<span class="si">)</span>
<span class="nv">$ CLI_ARCH</span><span class="o">=</span>amd64
<span class="nv">$ </span><span class="k">if</span> <span class="o">[</span> <span class="s2">"</span><span class="si">$(</span><span class="nb">uname</span> <span class="nt">-m</span><span class="si">)</span><span class="s2">"</span> <span class="o">=</span> <span class="s2">"aarch64"</span> <span class="o">]</span><span class="p">;</span> <span class="k">then </span><span class="nv">CLI_ARCH</span><span class="o">=</span>arm64<span class="p">;</span> <span class="k">fi</span>
<span class="nv">$ </span>curl <span class="nt">-L</span> <span class="nt">--fail</span> <span class="nt">--remote-name-all</span> https://github.com/cilium/cilium-cli/releases/download/<span class="k">${</span><span class="nv">CILIUM_CLI_VERSION</span><span class="k">}</span>/cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz <span class="o">&gt;</span>/dev/null 2&gt;&amp;1
<span class="nv">$ </span><span class="nb">tar </span>xzvfC cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz /usr/local/bin
<span class="c"># =&gt; cilium</span>
<span class="nv">$ </span><span class="nb">rm </span>cilium-linux-<span class="k">${</span><span class="nv">CLI_ARCH</span><span class="k">}</span>.tar.gz

<span class="c"># cilium 상태 확인</span>
<span class="nv">$ </span>which cilium
<span class="c"># =&gt; /usr/local/bin/cilium</span>
<span class="nv">$ </span>cilium status
<span class="c"># =&gt;     /¯¯\</span>
<span class="c">#     /¯¯\__/¯¯\    Cilium:             OK</span>
<span class="c">#     \__/¯¯\__/    Operator:           OK</span>
<span class="c">#     /¯¯\__/¯¯\    Envoy DaemonSet:    OK</span>
<span class="c">#     \__/¯¯\__/    Hubble Relay:       disabled</span>
<span class="c">#        \__/       ClusterMesh:        disabled</span>
<span class="c">#    </span>
<span class="c">#    DaemonSet              cilium                   Desired: 3, Ready: 3/3, Available: 3/3</span>
<span class="c">#    DaemonSet              cilium-envoy             Desired: 3, Ready: 3/3, Available: 3/3</span>
<span class="c">#    Deployment             cilium-operator          Desired: 2, Ready: 2/2, Available: 2/2</span>
<span class="c">#    Containers:            cilium                   Running: 3</span>
<span class="c">#                           cilium-envoy             Running: 3</span>
<span class="c">#                           cilium-operator          Running: 2</span>
<span class="c">#                           clustermesh-apiserver</span>
<span class="c">#                           hubble-relay</span>
<span class="c">#    Cluster Pods:          5/5 managed by Cilium</span>
<span class="c">#    Helm chart version:    1.17.5</span>
<span class="c">#    Image versions         cilium             quay.io/cilium/cilium:v1.17.5@sha256:baf8541723ee0b72d6c489c741c81a6fdc5228940d66cb76ef5ea2ce3c639ea6: 3</span>
<span class="c">#                           cilium-envoy       quay.io/cilium/cilium-envoy:v1.32.6-1749271279-0864395884b263913eac200ee2048fd985f8e626@sha256:9f69e290a7ea3d4edf9192acd81694089af048ae0d8a67fb63bd62dc1d72203e: 3</span>
<span class="c">#                           cilium-operator    quay.io/cilium/operator-generic:v1.17.5@sha256:f954c97eeb1b47ed67d08cc8fb4108fb829f869373cbb3e698a7f8ef1085b09e: 2</span>
<span class="nv">$ </span>cilium config view
<span class="c"># =&gt; ...</span>
<span class="c">#    cluster-pool-ipv4-cidr                            172.20.0.0/16</span>
<span class="c">#    default-lb-service-ipam                           lbipam</span>
<span class="c">#    ipam                                              cluster-pool</span>
<span class="c">#    ipam-cilium-node-update-rate                      15s</span>
<span class="c">#    iptables-random-fully                             false</span>
<span class="c">#    ipv4-native-routing-cidr                          172.20.0.0/16</span>
<span class="c">#    kube-proxy-replacement                            true</span>
<span class="c">#    ...</span>
<span class="nv">$ </span>kubectl get cm <span class="nt">-n</span> kube-system cilium-config <span class="nt">-o</span> json | jq

<span class="c">#</span>
<span class="nv">$ </span>cilium config <span class="nb">set </span>debug <span class="nb">true</span> <span class="o">&amp;&amp;</span> watch kubectl get pod <span class="nt">-A</span>
<span class="c"># =&gt; ✨ Patching ConfigMap cilium-config with debug=true...</span>
<span class="c">#    ♻️  Restarted Cilium pods</span>
<span class="nv">$ </span>cilium config view | <span class="nb">grep</span> <span class="nt">-i</span> debug
<span class="c"># =&gt; debug                                             true</span>
<span class="c">#    debug-verbose</span>

<span class="c"># cilium daemon = cilium-dbg</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg config
<span class="c"># =&gt; ##### Read-write configurations #####</span>
<span class="c">#    ConntrackAccounting               : Disabled</span>
<span class="c">#    ConntrackLocal                    : Disabled</span>
<span class="c">#    Debug                             : Disabled</span>
<span class="c">#    DebugLB                           : Disabled</span>
<span class="c">#    DebugPolicy                       : Enabled</span>
<span class="c">#    DropNotification                  : Enabled</span>
<span class="c">#    MonitorAggregationLevel           : Medium</span>
<span class="c">#    PolicyAccounting                  : Enabled</span>
<span class="c">#    PolicyAuditMode                   : Disabled</span>
<span class="c">#    PolicyTracing                     : Disabled</span>
<span class="c">#    PolicyVerdictNotification         : Enabled</span>
<span class="c">#    SourceIPVerification              : Enabled</span>
<span class="c">#    TraceNotification                 : Enabled</span>
<span class="c">#    MonitorNumPages                   : 64</span>
<span class="c">#    PolicyEnforcement                 : default</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-n</span> kube-system <span class="nt">-c</span> cilium-agent <span class="nt">-it</span> ds/cilium <span class="nt">--</span> cilium-dbg status <span class="nt">--verbose</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    KubeProxyReplacement:   True   [eth0    10.0.2.15 fd17:625c:f037:2:a00:27ff:fe71:19d8 fe80::a00:27ff:fe71:19d8, eth1   192.168.10.102 fe80::a00:27ff:fe79:58ac (Direct Routing)]</span>
<span class="c">#    Routing:                Network: Native   Host: BPF</span>
<span class="c">#    Attach Mode:            TCX</span>
<span class="c">#    Device Mode:            veth</span>
<span class="c">#    ...</span>
<span class="c">#    KubeProxyReplacement Details:</span>
<span class="c">#      Status:                 True</span>
<span class="c">#      Socket LB:              Enabled</span>
<span class="c">#      Socket LB Tracing:      Enabled</span>
<span class="c">#      Socket LB Coverage:     Full</span>
<span class="c">#      Devices:                eth0    10.0.2.15 fd17:625c:f037:2:a00:27ff:fe71:19d8 fe80::a00:27ff:fe71:19d8, eth1   192.168.10.102 fe80::a00:27ff:fe79:58ac (Direct Routing)</span>
<span class="c">#      Mode:                   SNAT</span>
<span class="c">#      Backend Selection:      Random</span>
<span class="c">#      Session Affinity:       Enabled</span>
<span class="c">#      Graceful Termination:   Enabled</span>
<span class="c">#      NAT46/64 Support:       Disabled</span>
<span class="c">#      XDP Acceleration:       Disabled</span>
<span class="c">#      Services:</span>
<span class="c">#      - ClusterIP:      Enabled</span>
<span class="c">#      - NodePort:       Enabled (Range: 30000-32767)</span>
<span class="c">#      - LoadBalancer:   Enabled</span>
<span class="c">#      - externalIPs:    Enabled</span>
<span class="c">#      - HostPort:       Enabled</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<ul>
  <li>cilium_host, cilium_net, cilium_health 등의 네트워크 기본 정보를 확인해보겠습니다.</li>
</ul>

<p><img src="/assets/2025/cilium/w1/20250720_cilium_w1_4.png" alt="img.png" class="image-center" loading="lazy" width="996" height="377">
<img src="/assets/2025/cilium/w1/20250720_cilium_w1_5.png" alt="img_1.png" class="image-center w-50" loading="lazy" width="550" height="440">
<a href="https://arthurchiao.art/blog/ctrip-network-arch-evolution/" class="image-caption">출처 : https://arthurchiao.art/blog/ctrip-network-arch-evolution/</a></p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> addr
<span class="c"># =&gt; ...</span>
<span class="c">#    7: cilium_net@cilium_host: &lt;BROADCAST,MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span>
<span class="c">#        link/ether 4e:28:ea:3e:83:e0 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet6 fe80::4c28:eaff:fe3e:83e0/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    8: cilium_host@cilium_net: &lt;BROADCAST,MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span>
<span class="c">#        link/ether 22:ad:62:34:21:8e brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet 172.20.2.68/32 scope global cilium_host</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#        inet6 fe80::20ad:62ff:fe34:218e/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    12: lxcc4a3ffff7931@if11: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span>
<span class="c">#        link/ether 76:62:d3:8d:58:1f brd ff:ff:ff:ff:ff:ff link-netns cni-ca74ac02-08e1-9092-74ad-f60026576c19</span>
<span class="c">#        inet6 fe80::7462:d3ff:fe8d:581f/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#    14: lxc_health@if13: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span>
<span class="c">#        link/ether ca:67:c2:a6:88:89 brd ff:ff:ff:ff:ff:ff link-netnsid 2</span>
<span class="c">#        inet6 fe80::c867:c2ff:fea6:8889/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> addr <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>

<span class="c">#</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> addr show cilium_net
<span class="c"># =&gt; 7: cilium_net@cilium_host: &lt;BROADCAST,MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span>
<span class="c">#        link/ether 4e:28:ea:3e:83:e0 brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet6 fe80::4c28:eaff:fe3e:83e0/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> addr show cilium_host
<span class="c"># =&gt; 8: cilium_host@cilium_net: &lt;BROADCAST,MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span>
<span class="c">#        link/ether 22:ad:62:34:21:8e brd ff:ff:ff:ff:ff:ff</span>
<span class="c">#        inet 172.20.2.68/32 scope global cilium_host</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="c">#        inet6 fe80::20ad:62ff:fe34:218e/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> addr show cilium_net  <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> addr show cilium_host <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>

<span class="c"># lxc_health 인터페이스는 veth 로 cilium(NET NS 0, 호스트와 다름)과 veth pair 이다 - 링크</span>
<span class="c"># cilium 인터페이스에 파드 IP가 할당되어 있으며, cilium-health-responder 로 동작한다</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> addr show lxc_health
<span class="c"># =&gt; 14: lxc_health@if13: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span>
<span class="c">#        link/ether ca:67:c2:a6:88:89 brd ff:ff:ff:ff:ff:ff link-netnsid 2</span>
<span class="c">#        inet6 fe80::c867:c2ff:fea6:8889/64 scope link</span>
<span class="c">#           valid_lft forever preferred_lft forever</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> addr show lxc_health  <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>

<span class="c"># IP 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium-dbg status <span class="nt">--verbose</span>
<span class="c"># =&gt; ....</span>
<span class="c">#    Name              IP              Node   Endpoints</span>
<span class="c">#      k8s-w2 (localhost):</span>
<span class="c">#        Host connectivity to 192.168.10.102:   &lt;span style="color: green;"&gt;# &lt;-- NodeIP&lt;/span&gt;</span>
<span class="c">#          ICMP to stack:   OK, RTT=440.958µs</span>
<span class="c">#          HTTP to agent:   OK, RTT=539.708µs</span>
<span class="c">#        Endpoint connectivity to 172.20.0.114: &lt;span style="color: green;"&gt;# &lt;-- HealthIP&lt;/span&gt;</span>
<span class="c">#          ICMP to stack:   OK, RTT=189µs</span>
<span class="c">#          HTTP to agent:   OK, RTT=502µs</span>
<span class="c">#      k8s-ctr:</span>
<span class="c">#        Host connectivity to 192.168.10.100:   &lt;span style="color: green;"&gt;# &lt;-- NodeIP&lt;/span&gt;</span>
<span class="c">#          ICMP to stack:   OK, RTT=1.011167ms</span>
<span class="c">#          HTTP to agent:   OK, RTT=1.071083ms</span>
<span class="c">#        Endpoint connectivity to 172.20.2.223: &lt;span style="color: green;"&gt;# &lt;-- HealthIP&lt;/span&gt;</span>
<span class="c">#          ICMP to stack:   OK, RTT=1.027125ms</span>
<span class="c">#          HTTP to agent:   OK, RTT=7.677708ms</span>
<span class="c">#      k8s-w1:</span>
<span class="c">#        Host connectivity to 192.168.10.101:   &lt;span style="color: green;"&gt;# &lt;-- NodeIP&lt;/span&gt;</span>
<span class="c">#          ICMP to stack:   OK, RTT=888.417µs</span>
<span class="c">#          HTTP to agent:   OK, RTT=1.167333ms</span>
<span class="c">#        Endpoint connectivity to 172.20.1.229: &lt;span style="color: green;"&gt;# &lt;-- HealthIP&lt;/span&gt;</span>
<span class="c">#          ICMP to stack:   OK, RTT=1.806167ms</span>
<span class="c">#          HTTP to agent:   OK, RTT=1.903ms</span>
<span class="c">#    ....</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium-dbg endpoint list | <span class="nb">grep </span>health
<span class="c"># =&gt; 2955  Disabled  Disabled  4  reserved:health  172.20.0.114  ready                                                             172.20.1.40    ready </span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium-dbg status <span class="nt">--all-addresses</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    Allocated addresses:</span>
<span class="c">#      172.20.0.114 (health)</span>
<span class="c">#      172.20.0.167 (kube-system/coredns-674b8bbfcf-bvsfb [restored])</span>
<span class="c">#      172.20.0.202 (default/webpod-86f878c468-448pc [restored])</span>
<span class="c">#      172.20.0.235 (router)</span>
<span class="c">#      172.20.0.92 (kube-system/coredns-674b8bbfcf-7q52c [restored])</span>
<span class="c">#    ...</span>

<span class="c"># Check health info in CT/NAT tables : ICMP records in Conntrack (CT) table and NAT table</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium bpf ct list global | <span class="nb">grep </span>ICMP |head <span class="nt">-n4</span>
<span class="c"># =&gt; ICMP IN 192.168.10.101:19430 -&gt; 172.20.0.114:0 expires=11874 Packets=0 Bytes=0 RxFlagsSeen=0x00 LastRxReport=11814 TxFlagsSeen=0x00 LastTxReport=11814 Flags=0x0000 [ ] RevNAT=0 SourceSecurityID=6 IfIndex=0 BackendID=0</span>
<span class="c">#    ICMP IN 192.168.10.101:0 -&gt; 172.20.0.114:0 related expires=11874 Packets=0 Bytes=0 RxFlagsSeen=0x00 LastRxReport=11814 TxFlagsSeen=0x00 LastTxReport=0 Flags=0x0000 [ ] RevNAT=0 SourceSecurityID=6 IfIndex=0 BackendID=0</span>
<span class="c">#    ICMP IN 192.168.10.101:2374 -&gt; 172.20.0.114:0 expires=11535 Packets=0 Bytes=0 RxFlagsSeen=0x00 LastRxReport=11475 TxFlagsSeen=0x00 LastTxReport=11475 Flags=0x0000 [ ] RevNAT=0 SourceSecurityID=6 IfIndex=0 BackendID=0</span>
<span class="c">#    ICMP IN 192.168.10.101:47855 -&gt; 172.20.0.114:0 expires=11415 Packets=0 Bytes=0 RxFlagsSeen=0x00 LastRxReport=11355 TxFlagsSeen=0x00 LastTxReport=11355 Flags=0x0000 [ ] RevNAT=0 SourceSecurityID=6 IfIndex=0 BackendID=0</span>

<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> <span class="nt">-n</span> kube-system ds/cilium <span class="nt">-c</span> cilium-agent <span class="nt">--</span> cilium bpf nat list | <span class="nb">grep </span>ICMP |head <span class="nt">-n4</span>
<span class="c"># =&gt; ICMP OUT 192.168.10.102:35430 -&gt; 172.20.1.229:0 XLATE_SRC 192.168.10.102:35430 Created=164sec ago NeedsCT=1</span>
<span class="c">#    ICMP IN 172.20.2.223:0 -&gt; 192.168.10.102:47029 XLATE_DST 192.168.10.102:47029 Created=464sec ago NeedsCT=1</span>
<span class="c">#    ICMP IN 172.20.2.223:0 -&gt; 192.168.10.102:52326 XLATE_DST 192.168.10.102:52326 Created=54sec ago NeedsCT=1</span>
<span class="c">#    ICMP OUT 192.168.10.102:47029 -&gt; 172.20.2.223:0 XLATE_SRC 192.168.10.102:47029 Created=464sec ago NeedsCT=1</span>
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w1/20250720_cilium_w1_6.png" alt="img.png" class="image-center" loading="lazy" width="1980" height="1721">
<em class="image-caption"><a href="https://arthurchiao.art/blog/cilium-code-health-probe">node 및 endpoint health check 절차</a></em></p>

<ul>
  <li>routing 정보 확인해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Native-Routing + autoDirectNodeRoutes=true</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route | <span class="nb">grep </span>172.20 | <span class="nb">grep </span>eth1
<span class="c"># =&gt; 172.20.0.0/24 via 192.168.10.102 dev eth1 proto kernel</span>
<span class="c">#    172.20.1.0/24 via 192.168.10.101 dev eth1 proto kernel</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> route | <span class="nb">grep </span>172.20 | <span class="nb">grep </span>eth1 <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>

<span class="c"># hostNetwork 를 사용하지 않는 파드의 경우 endpointRoutes.enabled=true 설정으로 lxcY 인터페이스 생성됨</span>
<span class="nv">$ </span>kubectl get ciliumendpoints <span class="nt">-A</span>
<span class="c"># =&gt; NAMESPACE     NAME                       SECURITY IDENTITY   ENDPOINT STATE   IPV4           IPV6</span>
<span class="c">#    default       curl-pod                   5180                ready            172.20.2.15</span>
<span class="c">#    default       webpod-86f878c468-448pc    34270               ready            172.20.0.202</span>
<span class="c">#    default       webpod-86f878c468-ttbs2    34270               ready            172.20.1.123</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-7q52c   20407               ready            172.20.0.92</span>
<span class="c">#    kube-system   coredns-674b8bbfcf-bvsfb   20407               ready            172.20.0.167</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route | <span class="nb">grep </span>lxc
<span class="c"># =&gt; 172.20.2.15 dev lxcc4a3ffff7931 proto kernel scope link</span>
<span class="c">#    172.20.2.223 dev lxc_health proto kernel scope link</span>
<span class="nv">$ </span><span class="k">for </span>i <span class="k">in </span>w1 w2 <span class="p">;</span> <span class="k">do </span><span class="nb">echo</span> <span class="s2">"&gt;&gt; node : k8s-</span><span class="nv">$i</span><span class="s2"> &lt;&lt;"</span><span class="p">;</span> sshpass <span class="nt">-p</span> <span class="s1">'vagrant'</span> ssh vagrant@k8s-<span class="nv">$i</span> ip <span class="nt">-c</span> route | <span class="nb">grep </span>lxc <span class="p">;</span> <span class="nb">echo</span><span class="p">;</span> <span class="k">done</span>
</code></pre></div></div>

<ul>
  <li>보다 상세한 내용은 <a href="https://docs.cilium.io/en/stable/network/kubernetes/kubeproxy-free/">공식문서</a>를 참고하세요.</li>
</ul>

<hr>

<h2 id="통신-확인">통신 확인</h2>

<h3 id="노드간-파드---파드-통신">노드간 ‘파드 -&gt; 파드’ 통신</h3>

<ul>
  <li>
<a href="https://docs.cilium.io/en/stable/network/ebpf/lifeofapacket/">참고</a> <a href="https://velog.io/@_gyullbb/Cilium">추천 글</a>
</li>
</ul>

<p><img src="/assets/2025/cilium/w1/20250720_cilium_w1_7.png" alt="img.png" class="image-center" loading="lazy" width="1386" height="758">
<em class="image-caption">파드에서 빠져나갈 때</em></p>

<p><img src="/assets/2025/cilium/w1/20250720_cilium_w1_8.png" alt="img_1.png" class="image-center" loading="lazy" width="1626" height="783">
<em class="image-caption">파드로 들어올 때</em></p>

<ul>
  <li>cilium 정보 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 먼저 아래의 cheatsheet을 참고하여 c0, c0bpf 등의 단축키(alias)를 지정한 후에 진행합니다.</span>

<span class="c"># 엔드포인트 정보 확인</span>
<span class="nv">$ </span>kubectl get pod <span class="nt">-owide</span>
<span class="c"># =&gt; NAME                      READY   STATUS    RESTARTS   AGE     IP             NODE      NOMINATED NODE   READINESS GATES</span>
<span class="c">#    curl-pod                  1/1     Running   0          3h40m   172.20.2.15    k8s-ctr   &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-86f878c468-448pc   1/1     Running   0          3h41m   &lt;span style="color: green;"&gt;172.20.0.202&lt;/span&gt;   k8s-w2    &lt;none&gt;           &lt;none&gt;</span>
<span class="c">#    webpod-86f878c468-ttbs2   1/1     Running   0          3h41m   172.20.1.123   k8s-w1    &lt;none&gt;           &lt;none&gt;</span>
<span class="nv">$ </span>kubectl get svc,ep webpod
<span class="c"># =&gt; NAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE</span>
<span class="c">#    service/webpod   ClusterIP   10.96.62.184   &lt;none&gt;        80/TCP    7h12m</span>
<span class="c">#    </span>
<span class="c">#    NAME               ENDPOINTS                         AGE</span>
<span class="c">#    endpoints/webpod   172.20.0.202:80,172.20.1.123:80   7h12m</span>

<span class="c"># 첫번째 webpod의 IP 주소를 WEBPOD1IP 변수에 저장합니다.</span>
<span class="nv">$ WEBPOD1IP</span><span class="o">=</span>172.20.0.202

<span class="c"># BPF maps : 목적지 파드와 통신 시 어느곳으로 보내야 될지 확인할 수 있다</span>
<span class="nv">$ </span>c0 map get cilium_ipcache
<span class="nv">$ </span>c0 map get cilium_ipcache | <span class="nb">grep</span> <span class="nv">$WEBPOD1IP</span>
<span class="c"># =&gt; 172.20.0.202/32     identity=34270 encryptkey=0 tunnelendpoint=192.168.10.102 flags=&lt;none&gt;   sync</span>

<span class="c"># curl-pod 의 LXC 변수 지정</span>
<span class="c"># $ LXC=&lt;k8s-ctr의 가장 나중에 lxc 이름(lxc_health 제외)&gt;</span>
<span class="nv">$ </span>ip <span class="nt">-c</span> route | <span class="nb">grep </span>lxc
<span class="c"># =&gt; 172.20.2.15 dev &lt;span style="color: green;"&gt;lxcc4a3ffff7931&lt;/span&gt; proto kernel scope link</span>
<span class="c">#    172.20.2.223 dev lxc_health proto kernel scope link</span>
<span class="nv">$ LXC</span><span class="o">=</span>lxcc4a3ffff7931

<span class="c"># Node’s eBPF programs</span>
<span class="c">## list of eBPF programs</span>
<span class="nv">$ </span>c0bpf net show
<span class="nv">$ </span>c0bpf net show | <span class="nb">grep</span> <span class="nv">$LXC</span> 
<span class="c"># =&gt; lxcc4a3ffff7931(12) tcx/ingress cil_from_container prog_id 1212 link_id 22</span>
<span class="c">#    lxcc4a3ffff7931(12) tcx/egress cil_to_container prog_id 1214 link_id 23 </span>

<span class="c">## Use bpftool prog show id to view additional information about a program, including a list of attached eBPF maps:</span>
<span class="c"># $ c0bpf prog show id &lt;출력된 prog id 입력&gt;</span>
<span class="nv">$ </span>c0bpf prog show <span class="nb">id </span>1214
<span class="c"># =&gt; 1214: sched_cls  name cil_to_container  tag 0b3125767ba1861c  gpl</span>
<span class="c">#            loaded_at 2025-07-19T08:50:37+0000  uid 0</span>
<span class="c">#            xlated 1448B  jited 1144B  memlock 4096B  map_ids 219,41,218</span>
<span class="c">#            btf_id 468</span>

<span class="nv">$ </span>c0bpf map list
<span class="c"># =&gt; ...</span>
<span class="c">#    41: percpu_hash  name cilium_metrics  flags 0x1</span>
<span class="c">#            key 8B  value 16B  max_entries 1024  memlock 19024B</span>
<span class="c">#    ...</span>
<span class="c">#    227: array  name .rodata.config  flags 0x480</span>
<span class="c">#            key 4B  value 52B  max_entries 1  memlock 8192B</span>
<span class="c">#            btf_id 496  frozen</span>
<span class="c">#    228: prog_array  name cilium_calls_ne  flags 0x0</span>
<span class="c">#            key 4B  value 4B  max_entries 50  memlock 720B</span>
<span class="c">#            owner_prog_type sched_cls  owner jited</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<ul>
  <li>다른 노드 간 ‘파드 -&gt; 파드’ 통신을 확인해보겠습니다.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># vagrant ssh k8s-w1 , # vagrant ssh k8s-w2 각각 터미널 접속 후 아래 실행</span>
<span class="nv">$ </span>ngrep <span class="nt">-tW</span> byline <span class="nt">-d</span> eth1 <span class="s1">''</span> <span class="s1">'tcp port 80'</span>

<span class="c"># [k8s-ctr] curl-pod 에서 curl 요청 시도</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl <span class="nv">$WEBPOD1IP</span>
<span class="c"># 각각 터미널에서 출력 확인 : 파드의 소스 IP와 목적지 IP가 다른 노드의 서버 NIC에서 확인! : Native-Routung </span>
<span class="c"># =&gt; ####</span>
<span class="c">#    T 2025/07/19 21:36:42.198609 172.20.2.15:46708 -&gt; 172.20.0.202:80 [AP] #4</span>
<span class="c">#    GET / HTTP/1.1.</span>
<span class="c">#    ...</span>
<span class="c">#    ##</span>
<span class="c">#    T 2025/07/19 21:36:42.200368 172.20.0.202:80 -&gt; 172.20.2.15:46708 [AP] #6</span>
<span class="c">#    HTTP/1.1 200 OK.</span>
<span class="c">#    ...</span>
</code></pre></div></div>

<p><img src="/assets/2025/cilium/w1/20250720_cilium_w1_9.png" alt="img.png" class="image-center" loading="lazy" width="1306" height="783"></p>

<h3 id="노드간-파드---서비스-통신">노드간 ‘파드 -&gt; 서비스’ 통신</h3>

<ul>
  <li>참고 : <a href="https://velog.io/@haruband/K8SCilium-Socket-Based-LoadBalancing-%EA%B8%B0%EB%B2%95">[K8S/Cilium] Socket-Based LoadBalancing 기법</a>
</li>
</ul>

<p><img src="/assets/2025/cilium/w1/20250720_cilium_w1_10.png" alt="img.png" class="image-center" loading="lazy" width="897" height="378">
<em class="image-caption">네트워크기반 로드밸런싱 vs 소켓기반 로드밸런싱 비교</em></p>

<ul>
  <li>Pod1 안에서 동작하는 앱이 <strong>connect() 시스템콜</strong>을 이용하여 소켓을 연결할 때 목적지 주소가 서비스 주소(10.10.8.55)이면 소켓의 목적지 주소를 바로 백엔드 주소(10.0.0.31)로 설정합니다.</li>
  <li>이후 앱에서 해당 소켓을 통해 보내는 모든 패킷의 목적지 주소는 이미 백엔드 주소(10.0.0.31)로 설정되어 있기 때문에 중간에 <strong>DNAT 변환 및 역변환 과정이 필요없어집니다.</strong>
</li>
  <li>
<strong>Destination NAT</strong> 변환은 시스템 콜 레벨에서 발생하며, 패킷이 커널에 의해 생성되기도 전에 수행됩니다.</li>
  <li>
<strong>Socket operations</strong> : <strong>BPF socket operations program</strong> 은 <strong>root cgroup 에 연결</strong>되며 TCP <strong>event</strong>(ESTABLISHED) 에서 실행됩니다.</li>
  <li>
    <p><strong>Socket send/recv</strong> : Socket send/recv hook 은 <strong>TCP</strong> socket 의 모든 <strong>송수신</strong> 작업에서 실행되며, <strong>hook</strong> 에서 <strong>검사/삭제/리다이렉션</strong>을 할 수 있습니다.
<img src="/assets/2025/cilium/w1/20250720_cilium_w1_11.png" alt="img.png" class="image-center" loading="lazy" width="1008" height="297">
<em class="image-caption">https://cilium.io/blog/2020/11/10/ebpf-future-of-networking/</em></p>
  </li>
  <li>파드 네임스페이스에서 Socket-Based LoadBalancing 기법을 그림으로 정리해보면 아래와 같습니다.</li>
</ul>

<p><img src="/assets/2025/cilium/w1/20250720_cilium_w1_12.png" alt="img.png" class="image-center" loading="lazy" width="937" height="477">
<em class="image-caption">출처 : <a href="https://velog.io/@haruband/K8SCilium-Socket-Based-LoadBalancing-%EA%B8%B0%EB%B2%95">[K8S/Cilium] Socket-Based LoadBalancing 기법</a></em></p>

<ul>
  <li>그림상의 좌측은 네트워크 기반 로드밸런싱 기법을 사용한 경우이고, 우측은 소켓 기반 로드밸런싱 기법을 사용한 경우입니다.</li>
  <li>
    <p>소켓 기반 로드밸런싱 기법은 네트워크 기반 로드밸런싱 기법과 비교하여 DNAT 변환 및 역변환 과정이 필요 없기 때문에 성능이 향상됩니다.</p>
  </li>
  <li>connect() 와 sendto() 소켓 함수에 연결된 프로그램(connect4, sendmsg4)에서는 소켓의 목적지 주소를 백엔드 주소와 포트로 변환하고, cilium_lb4_backends 맵에 백엔드 주소와 포트를 등록해놓습니다.</li>
  <li>
    <p>이후 recvmsg() 소켓 함수에 연결된 프로그램(recvmsg4)에서는 cilium_lb4_reverse_nat 맵을 이용해서 목적지 주소와 포트를 다시 서비스 주소와 포트로 변환합니다.
<img src="/assets/2025/cilium/w1/20250720_cilium_w1_14.png" alt="img.png" class="image-center" loading="lazy" width="850" height="570">
<em class="image-caption">https://k8s.networkop.co.uk/services/clusterip/dataplane/ebpf/</em></p>
  </li>
  <li>실습 확인</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># curl 호출</span>
<span class="nv">$ </span>kubectl <span class="nb">exec</span> <span class="nt">-it</span> curl-pod <span class="nt">--</span> curl webpod

<span class="c"># 신규 터미널 : 파드에서 SVC(ClusterIP) 접속 시 tcpdump 로 확인 : ClusterIP가 소켓 레벨에서 이미 Endpoint 로 변경되었음을 확인!</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>curl-pod <span class="nt">--</span> tcpdump <span class="nt">-enni</span> any <span class="nt">-q</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    14:09:05.318403 eth0  Out ifindex 11 d6:ab:bb:21:3a:93 172.20.2.15.40982 &gt; 172.20.1.123.80: tcp 0</span>
<span class="c">#    14:09:05.319286 eth0  In  ifindex 11 76:62:d3:8d:58:1f 172.20.1.123.80 &gt; 172.20.2.15.40982: tcp 0</span>
<span class="c">#    ...</span>

<span class="c"># Socket-Based LoadBalancing 관련 설정들 확인</span>
<span class="nv">$ </span>c0 status <span class="nt">--verbose</span>
<span class="c"># =&gt; ...</span>
<span class="c">#    KubeProxyReplacement Details:</span>
<span class="c">#      Status:                 True</span>
<span class="c">#      Socket LB:              Enabled</span>
<span class="c">#      Socket LB Tracing:      Enabled</span>
<span class="c">#      Socket LB Coverage:     Full</span>
<span class="c">#      Devices:                eth0    10.0.2.15 fd17:625c:f037:2:a00:27ff:fe71:19d8 fe80::a00:27ff:fe71:19d8, eth1   192.168.10.100 fe80::a00:27ff:feda:2493 (Direct Routing)</span>
<span class="c">#      Mode:                   SNAT</span>
<span class="c">#      Backend Selection:      Random</span>
<span class="c">#      Session Affinity:       Enabled</span>
<span class="c">#      Graceful Termination:   Enabled</span>
<span class="c">#      NAT46/64 Support:       Disabled</span>
<span class="c">#      XDP Acceleration:       Disabled</span>
<span class="c">#      Services:</span>
<span class="c">#      - ClusterIP:      Enabled</span>
<span class="c">#      - NodePort:       Enabled (Range: 30000-32767)</span>
<span class="c">#      - LoadBalancer:   Enabled</span>
  
<span class="c"># syscall 호출 확인</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>curl-pod <span class="nt">--</span> strace <span class="nt">-c</span> curl <span class="nt">-s</span> webpod
<span class="c"># =&gt; ...</span>
<span class="c">#    % time     seconds  usecs/call     calls    errors syscall</span>
<span class="c">#    ------ ----------- ----------- --------- --------- ----------------</span>
<span class="c">#     &lt;span style="color: green;"&gt;19.00    0.001003         334         3         1 connect&lt;/span&gt;</span>
<span class="c">#     15.97    0.000843         281         3           sendto</span>
<span class="c">#     15.82    0.000835          23        35           munmap</span>
<span class="c">#     10.59    0.000559          93         6         3 recvfrom</span>
<span class="c">#     10.33    0.000545           8        63           mmap</span>
<span class="c">#      7.58    0.000400           8        47        30 openat</span>
<span class="c">#      4.32    0.000228          10        22           close</span>
<span class="c">#      3.87    0.000204          20        10           lseek</span>
<span class="c">#      2.94    0.000155           6        24           fcntl</span>
<span class="c">#      2.56    0.000135           4        28           rt_sigaction</span>
<span class="c">#      1.46    0.000077           8         9           ppoll</span>
<span class="c">#      1.23    0.000065          16         4           socket</span>
<span class="c">#      0.72    0.000038          12         3         3 ioctl</span>
<span class="c">#      0.68    0.000036          36         1           newfstatat</span>
<span class="c">#      0.63    0.000033           2        14           mprotect</span>
<span class="c">#      &lt;span style="color: green;"&gt;0.63    0.000033           1        27           read&lt;/span&gt;</span>
<span class="c">#      0.55    0.000029           9         3           readv</span>
<span class="c">#      0.21    0.000011           0        12           fstat</span>
<span class="c">#      0.21    0.000011           0        14           rt_sigprocmask</span>
<span class="c">#      0.17    0.000009           9         1           writev</span>
<span class="c">#      0.15    0.000008           1         5           setsockopt</span>
<span class="c">#      &lt;span style="color: green;"&gt;0.15    0.000008           1         5           getsockname&lt;/span&gt;</span>
<span class="c">#      0.09    0.000005           5         1           eventfd2</span>
<span class="c">#      0.06    0.000003           0         4           brk</span>
<span class="c">#      0.04    0.000002           2         1           getrandom</span>
<span class="c">#      &lt;span style="color: green;"&gt;0.04    0.000002           2         1           getsockopt&lt;/span&gt;</span>
<span class="c">#      0.02    0.000001           1         1           getgid</span>
<span class="c">#      0.00    0.000000           0         1           set_tid_address</span>
<span class="c">#      0.00    0.000000           0         1           getuid</span>
<span class="c">#      0.00    0.000000           0         2           geteuid</span>
<span class="c">#      0.00    0.000000           0         1           getegid</span>
<span class="c">#      0.00    0.000000           0         1           execve</span>
<span class="c">#    ------ ----------- ----------- --------- --------- ----------------</span>
<span class="c">#    100.00    0.005278          14       353        37 total</span>

<span class="c"># 상세 출력</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>curl-pod <span class="nt">--</span> strace <span class="nt">-s</span> 65535 <span class="nt">-f</span> <span class="nt">-tt</span> curl <span class="nt">-s</span> webpod

<span class="c"># 특정 이벤트 필터링 : -e</span>
<span class="c">## connect 로 출력되는 10.96.62.184 는 webpod Service 의 ClusterIP입니다.</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>curl-pod <span class="nt">--</span> strace <span class="nt">-e</span> <span class="nv">trace</span><span class="o">=</span>connect     curl <span class="nt">-s</span> webpod
<span class="c"># =&gt; connect(5, {sa_family=AF_INET, sin_port=htons(80), sin_addr=inet_addr("10.96.62.184")}, 16) = 0</span>
<span class="c">#    connect(4, {sa_family=AF_INET, sin_port=htons(80), sin_addr=inet_addr("10.96.62.184")}, 16) = -1 EINPROGRESS (Operation in progress)</span>
<span class="c">#    ...</span>

<span class="c">## connect 로 출력되는 172.20.2.15 는 curl-pod 의 파드 IP입니다. -&gt; 목적지 webpod 파드 IP가 아닙니다.</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>curl-pod <span class="nt">--</span> strace <span class="nt">-e</span> <span class="nv">trace</span><span class="o">=</span>getsockname curl <span class="nt">-s</span> webpod
<span class="c"># =&gt; getsockname(4, {sa_family=AF_INET, sin_port=htons(52951), sin_addr=inet_addr("172.20.2.15")}, [128 =&gt; 16]) = 0</span>
<span class="c">#    getsockname(5, {sa_family=AF_INET, sin_port=htons(42089), sin_addr=inet_addr("172.20.2.15")}, [16]) = 0</span>
<span class="c">#    getsockname(4, {sa_family=AF_INET, sin_port=htons(60934), sin_addr=inet_addr("172.20.2.15")}, [128 =&gt; 16]) = 0</span>
<span class="c">#    getsockname(4, {sa_family=AF_INET, sin_port=htons(60934), sin_addr=inet_addr("172.20.2.15")}, [128 =&gt; 16]) = 0</span>
<span class="c">#    getsockname(4, {sa_family=AF_INET, sin_port=htons(60934), sin_addr=inet_addr("172.20.2.15")}, [128 =&gt; 16]) = 0</span>

<span class="nv">$ </span>kubectl <span class="nb">exec </span>curl-pod <span class="nt">--</span> strace <span class="nt">-e</span> <span class="nv">trace</span><span class="o">=</span>getsockopt curl <span class="nt">-s</span> webpod
<span class="c"># =&gt; getsockopt(4, SOL_SOCKET, SO_ERROR, [0], [4]) = 0 # 소켓 연결 성공</span>
</code></pre></div></div>

<ul>
  <li>strace를 통해 위와 같이 IP 변환에 대해 알아보려 했지만 
실제로는 소켓 레벨에서 이미 변환이 완료되어 있기 때문에 strace로는 확인할 수 없습니다.</li>
  <li>이는 eBPF를 통해 시스템 콜을 줄여 성능을 향상시키는 Cilium의 특징 중 하나입니다.</li>
  <li>ℹ️ 참고로  strace는 시스템 콜을 추적하는 도구로 다음과 같은 기능들로 사용할 수 있습니다.
    <div class="language-bash highlighter-rouge">
<div class="highlight"><pre class="highlight"><code><span class="c"># 중단점 트레이싱 : -ttt(첫 열에 기준시간으로부터 흐른 시간 표시) , -T(마지막 필드 time에 시스템 콜에 걸린 시간을 표시) , -p PID(프로세스 ID가 PID 인 프로세스를 트레이싱)</span>
<span class="nv">$ </span>strace <span class="nt">-ttt</span> <span class="nt">-T</span> <span class="nt">-p</span> 1884
  
<span class="c"># 시스템 콜별 통계</span>
<span class="nv">$ </span>strace <span class="nt">-c</span> <span class="nt">-p</span> 1884
  
<span class="c"># 프로그램 실행시 시스템 콜 추적</span>
<span class="nv">$ </span>strace <span class="nb">ls</span>
  
<span class="c"># 옵션 사용해보기 : -s(출력 string 결과 최댓값 지정), -tt(첫 열에 기준시간으로부터 흐른 시간 표시, ms단위), -f(멀티 스레드,멀티 프로레스의 자식 프로세스의 시스템 콜 추적)</span>
<span class="nv">$ </span>strace <span class="nt">-s</span> 65535 <span class="nt">-f</span> <span class="nt">-T</span> <span class="nt">-tt</span> <span class="nt">-o</span> &lt;파일명&gt; <span class="nt">-p</span> &lt;pid&gt;
  
<span class="c"># hostname 명령 분석하기 : -o &lt;파일명&gt; 출력 결과를 파일로 떨구기</span>
<span class="nv">$ </span>strace <span class="nt">-s</span> 65535 <span class="nt">-f</span> <span class="nt">-T</span> <span class="nt">-tt</span> <span class="nt">-o</span> hostname_f_trace <span class="nb">hostname</span> <span class="nt">-f</span>
  
<span class="c"># 특정 이벤트 : -e</span>
<span class="nv">$ </span>strace <span class="nt">-e</span> <span class="nv">trace</span><span class="o">=</span>connect curl ipinfo.io
</code></pre></div>    </div>
  </li>
</ul>

<h3 id="cilium-사용시-주의사항">Cilium 사용시 주의사항</h3>

<ul>
  <li>소켓 기반 로드밸런싱 이용시 Istio(EnvoyProxy)와 같은 사이드카 우회문제가 있을 수 있습니다. <a href="https://velog.io/@haruband/K8S-Cilium-Socket-based-LoadBalancing-%EC%97%90-%EC%9D%98%ED%95%9C-Istio-Envoy-%EC%9A%B0%ED%9A%8C-%EB%AC%B8%EC%A0%9C-%EB%B6%84%EC%84%9D">링크</a>
<img src="/assets/2025/cilium/w1/20250720_cilium_w1_15.png" alt="img.png" loading="lazy" width="457" height="497">
    <ul>
      <li>앞서 확인한것 처럼 서비스의 IP가 이미 백엔드 IP로 변환되었기 때문에, 서비스 IP기반으로 동작하는 모든 필터가 우회되는 현상입니다.</li>
      <li>해결 방안은 파드 네임스페이스에서는 소켓 기반 로드밸런싱을 사용하지 않는 것입니다. 즉, 호스트 네임스페이스만 사용하게 설정하는 것입니다
        <ul>
          <li>HTTP의 경우 Envoy의 HTTP 필터가 HTTP 패킷의 host 헤더를 필터링하여 패킷의 목적지 주소를 서비스 IP에서 백엔드 IP로 변환을 잘 합니다.</li>
          <li>하지만, HTTP가 아닌 일반 TCP 서비스 (예) Telnet 등)은 위 환경에서 문제가 발생합니다.</li>
        </ul>

        <div class="language-bash highlighter-rouge">
<div class="highlight"><pre class="highlight"><code><span class="c"># 설정</span>
<span class="nv">$ VERSION</span><span class="o">=</span>1.17.5
<span class="nv">$ </span>helm upgrade cilium cilium/cilium <span class="nt">--version</span> <span class="nv">$VERSION</span> <span class="nt">--namespace</span> kube-system <span class="nt">--reuse-values</span> <span class="se">\</span>
  <span class="nt">--set</span> socketLB.hostNamespaceOnly<span class="o">=</span><span class="nb">true</span>
<span class="nv">$ </span>kubectl <span class="nt">-n</span> kube-system rollout restart ds/cilium
<span class="c"># =&gt; daemonset.apps/cilium restarted</span>
  
<span class="nv">$ </span>cilium config view | <span class="nb">grep </span>bpf-lb-sock-hostns-only
<span class="c"># =&gt; bpf-lb-sock-hostns-only                           true</span>
  
<span class="c"># 확인</span>
<span class="c"># 지속적으로 접속 트래픽 발생</span>
<span class="nv">$ </span><span class="k">while </span><span class="nb">true</span><span class="p">;</span> <span class="k">do </span>kubectl <span class="nb">exec </span>curl-pod <span class="nt">--</span> curl <span class="nt">-s</span> <span class="nv">$SVCIP</span> | <span class="nb">grep </span>Hostname<span class="p">;</span><span class="nb">echo</span> <span class="s2">"-----"</span><span class="p">;</span><span class="nb">sleep </span>1<span class="p">;</span><span class="k">done</span>
<span class="c"># =&gt; Hostname: webpod-86f878c468-448pc</span>
<span class="c">#    -----</span>
<span class="c">#    Hostname: webpod-86f878c468-ttbs2</span>
<span class="c">#    -----</span>
<span class="c">#    Hostname: webpod-86f878c468-ttbs2</span>
<span class="c">#    ...</span>
  
<span class="c"># 파드에서 SVC(ClusterIP) 접속 시 tcpdump 로 확인 &gt;&gt; 파드 내부 캡쳐인데, SVC(10.96.62.184) 트래픽이 보인다!</span>
<span class="nv">$ </span>kubectl <span class="nb">exec </span>curl-pod <span class="nt">--</span> tcpdump <span class="nt">-enni</span> any <span class="nt">-q</span>
<span class="c"># =&gt; 14:38:41.369005 eth0  Out ifindex 11 d6:ab:bb:21:3a:93 172.20.2.15.52976 &gt; &lt;span style="color: green;"&gt;10.96.62.184.80&lt;/span&gt;: tcp 0</span>
<span class="c">#    14:38:41.369050 eth0  Out ifindex 11 d6:ab:bb:21:3a:93 172.20.2.15.52976 &gt; &lt;span style="color: green;"&gt;10.96.62.184.80&lt;/span&gt;: tcp 76</span>
<span class="c">#    14:38:41.369767 eth0  In  ifindex 11 76:62:d3:8d:58:1f &lt;span style="color: green;"&gt;10.96.62.184.80&lt;/span&gt; &gt; 172.20.2.15.52976: tcp 0</span>
<span class="c">#    14:38:41.370802 eth0  In  ifindex 11 76:62:d3:8d:58:1f &lt;span style="color: green;"&gt;10.96.62.184.80&lt;/span&gt; &gt; 172.20.2.15.52976: tcp 327</span>
<span class="c">#    ...	</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
  <li>Service ClusterIP로 NFS나 SMB 같은 프로토콜을 사용하면 문제가 발생할 수 있습니다. (Longhorn, Portworx, Robin 등) - <a href="https://docs.cilium.io/en/stable/network/kubernetes/kubeproxy-free/#limitations">Docs</a>, <a href="https://github.com/cilium/cilium/issues/21541">Issue</a>
    <ul>
      <li>Cilium의 eBPF를 통한 kube-proxy 대체 기능은 socket기반 로드밸런싱을 사용하기 때문에, 앞서 살펴본것 처럼 서비스 IP가 백엔드 IP로 변환되어 사용됩니다.</li>
      <li>NFS나 SMB 프로토콜은 서비스 IP를 사용하여 통신하기 때문에, socket기반 로드밸런싱을 사용하면 문제가 발생할 수 있습니다.
이 문제는 Longhorn, Portworx, Robin 등과 같은 스토리지 시스템에서 발생할 수 있으며, <code class="language-plaintext highlighter-rouge">ReadWriteMany</code> 모드를 사용하는 다른 스토리지 시스템에서도 발생할 수 있습니다.</li>
      <li>이를 해결하기 위해서는 다음의 패치들이 커널에 포함되어있어야 합니다.
        <ul>
          <li><code class="language-plaintext highlighter-rouge">0bdf399342c5 ("net: Avoid address overwrite in kernel_connect")</code></li>
          <li><code class="language-plaintext highlighter-rouge">86a7e0b69bd5 ("net: prevent rewrite of msg_name in sock_sendmsg()")</code></li>
          <li><code class="language-plaintext highlighter-rouge">01b2885d9415 ("net: Save and restore msg_namelen in sock_sendmsg")</code></li>
          <li>
<code class="language-plaintext highlighter-rouge">cedc019b9f26 ("smb: use kernel_connect() and kernel_bind()")</code> (SMB only)</li>
        </ul>
      </li>
      <li>위의 패치들은 많은 안정화 커널버전에 백포트 되었으며, 아래의 배포판 중 해당 버전 이상에서는 해결되었습니다.
        <ul>
          <li>
<strong>Ubuntu</strong>: <code class="language-plaintext highlighter-rouge">5.4.0-187-generic</code>, <code class="language-plaintext highlighter-rouge">5.15.0-113-generic</code>, <code class="language-plaintext highlighter-rouge">6.5.0-41-generic</code> or newer.</li>
          <li>
<strong>RHEL 8</strong>: <code class="language-plaintext highlighter-rouge">4.18.0-553.8.1.el8_10.x86_64</code> or newer (RHEL 8.10+).</li>
          <li>
<strong>RHEL 9</strong>: <code class="language-plaintext highlighter-rouge">kernel-5.14.0-427.31.1.el9_4</code> or newer (RHEL 9.4+).</li>
        </ul>
      </li>
      <li>보다 자세한 사항은 <a href="https://github.com/cilium/cilium/issues/21541">Github Issue 21541</a>를 확인하세요.</li>
    </ul>
  </li>
  <li>Cilium은 kubernetes의 중추적인 역할을 하는 kube-proxy를 대체하기 때문에, Linux Network Stack을 사용하는 애플리케이션 등을
적용시 꼭 사전 검증이 필요합니다.</li>
</ul>

<hr>

<h2 id="마치며">마치며</h2>

<p>이번 주에는 가장 기본적인 CNI인 Flannel과 가장 고도화된 CNI 중의 하나인 Cilium을 살펴보았습니다.
한번에 두가지를 비교해 보면서 Cilium의 특징과 장점을 확인하는 시간이었습니다.
또한 Cilium이 기능적으로 혁신적이고 최근 기술인 만큼 아직 엣지 케이스가 많이 남아있다는 것도 알 수 있었습니다.</p>

<p>줌 영상 스터디로 한번 설명을 듣고, 정리된 실습자료를 따라하는데 시간이 쭉쭉 가고, 이해가 잘 안 가는 부분이 많은데, 
스터디를 준비해주시는 CloudNet@ 팀 분들이 얼마나 정성과 시간을 쏟았을지 감사한 마음이 듭니다.</p>

<p>마지막으로 실습환경을 삭제하며 마치겠습니다.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>vagrant destroy <span class="nt">-f</span> <span class="o">&amp;&amp;</span> <span class="nb">rm</span> <span class="nt">-rf</span> .vagrant
</code></pre></div></div>

<hr>

<ul>
  <li>💁 참고 : Cilium CMD Cheatsheet
    <ul>
      <li>Cheatsheet - <a href="https://docs.cilium.io/en/stable/cheatsheet/">Docs</a>
</li>
      <li>CMD References - <a href="https://docs.cilium.io/en/stable/cmdref/">Docs</a>
</li>
    </ul>

    <div class="language-bash highlighter-rouge">
<div class="highlight"><pre class="highlight"><code><span class="c"># cilium 파드 이름</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD0</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-ctr <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD1</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-w1  <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">export </span><span class="nv">CILIUMPOD2</span><span class="o">=</span><span class="si">$(</span>kubectl get <span class="nt">-l</span> k8s-app<span class="o">=</span>cilium pods <span class="nt">-n</span> kube-system <span class="nt">--field-selector</span> spec.nodeName<span class="o">=</span>k8s-w2  <span class="nt">-o</span> <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">'{.items[0].metadata.name}'</span><span class="si">)</span>
<span class="nv">$ </span><span class="nb">echo</span> <span class="nv">$CILIUMPOD0</span> <span class="nv">$CILIUMPOD1</span> <span class="nv">$CILIUMPOD2</span>
  
<span class="c"># 단축키(alias) 지정</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c0</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD0</span><span class="s2"> -n kube-system -c cilium-agent -- cilium"</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c1</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD1</span><span class="s2"> -n kube-system -c cilium-agent -- cilium"</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c2</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD2</span><span class="s2"> -n kube-system -c cilium-agent -- cilium"</span>
  
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c0bpf</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD0</span><span class="s2"> -n kube-system -c cilium-agent -- bpftool"</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c1bpf</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD1</span><span class="s2"> -n kube-system -c cilium-agent -- bpftool"</span>
<span class="nv">$ </span><span class="nb">alias </span><span class="nv">c2bpf</span><span class="o">=</span><span class="s2">"kubectl exec -it </span><span class="nv">$CILIUMPOD2</span><span class="s2"> -n kube-system -c cilium-agent -- bpftool"</span>
  
<span class="c"># endpoint</span>
<span class="nv">$ </span>c0 endpoint list
<span class="nv">$ </span>c0 endpoint list <span class="nt">-o</span> json
<span class="nv">$ </span>c1 endpoint list
<span class="nv">$ </span>c2 endpoint list
  
<span class="nv">$ </span>c1 endpoint get &lt;<span class="nb">id</span><span class="o">&gt;</span>
<span class="nv">$ </span>c1 endpoint log &lt;<span class="nb">id</span><span class="o">&gt;</span>
  
<span class="c">## Enable debugging output on the cilium-dbg monitor for this endpoint</span>
<span class="nv">$ </span>c1 endpoint config &lt;<span class="nb">id</span><span class="o">&gt;</span> <span class="nv">Debug</span><span class="o">=</span><span class="nb">true</span>
  
<span class="c"># monitor</span>
<span class="nv">$ </span>c1 monitor
<span class="nv">$ </span>c1 monitor <span class="nt">-v</span>
<span class="nv">$ </span>c1 monitor <span class="nt">-v</span> <span class="nt">-v</span>
  
<span class="c">## Filter for only the events related to endpoint</span>
<span class="nv">$ </span>c1 monitor <span class="nt">--related-to</span><span class="o">=</span>&lt;<span class="nb">id</span><span class="o">&gt;</span>
  
<span class="c">## Show notifications only for dropped packet events</span>
<span class="nv">$ </span>c1 monitor <span class="nt">--type</span> drop
  
<span class="c">## Don’t dissect packet payload, display payload in hex information</span>
<span class="nv">$ </span>c1 monitor <span class="nt">-v</span> <span class="nt">-v</span> <span class="nt">--hex</span>
  
<span class="c">## Layer7</span>
<span class="nv">$ </span>c1 monitor <span class="nt">-v</span> <span class="nt">--type</span> l7
  
<span class="c"># Manage IP addresses and associated information - IP List</span>
<span class="nv">$ </span>c0 ip list
  
<span class="c"># IDENTITY :  1(host), 2(world), 4(health), 6(remote), 파드마다 개별 ID</span>
<span class="nv">$ </span>c0 ip list <span class="nt">-n</span>
  
<span class="c"># Retrieve information about an identity</span>
<span class="nv">$ </span>c0 identity list
  
<span class="c"># 엔드포인트 기준 ID</span>
<span class="nv">$ </span>c0 identity list <span class="nt">--endpoints</span>
  
<span class="c"># 엔드포인트 설정 확인 및 변경</span>
<span class="nv">$ </span>c0 endpoint config &lt;엔트포인트ID&gt;
  
<span class="c"># 엔드포인트 상세 정보 확인</span>
<span class="nv">$ </span>c0 endpoint get &lt;엔트포인트ID&gt;
  
<span class="c"># 엔드포인트 로그 확인</span>
<span class="nv">$ </span>c0 endpoint log &lt;엔트포인트ID&gt;
  
<span class="c"># Show bpf filesystem mount details</span>
<span class="nv">$ </span>c0 bpf fs show
  
<span class="c"># bfp 마운트 폴더 확인</span>
<span class="nv">$ </span>tree /sys/fs/bpf
  
<span class="c"># Get list of loadbalancer services</span>
<span class="nv">$ </span>c0 service list
<span class="nv">$ </span>c1 service list
<span class="nv">$ </span>c2 service list
  
<span class="c">## Or you can get the loadbalancer information using bpf list</span>
<span class="nv">$ </span>c0 bpf lb list
<span class="nv">$ </span>c1 bpf lb list
<span class="nv">$ </span>c2 bpf lb list
  
<span class="c">## List reverse NAT entries</span>
<span class="nv">$ </span>c1 bpf lb list <span class="nt">--revnat</span>
<span class="nv">$ </span>c2 bpf lb list <span class="nt">--revnat</span>
  
<span class="c"># List connection tracking entries</span>
<span class="nv">$ </span>c0 bpf ct list global
<span class="nv">$ </span>c1 bpf ct list global
<span class="nv">$ </span>c2 bpf ct list global
  
<span class="c"># Flush connection tracking entries</span>
<span class="nv">$ </span>c0 bpf ct flush
<span class="nv">$ </span>c1 bpf ct flush
<span class="nv">$ </span>c2 bpf ct flush
  
<span class="c"># List all NAT mapping entries</span>
<span class="nv">$ </span>c0 bpf nat list
<span class="nv">$ </span>c1 bpf nat list
<span class="nv">$ </span>c2 bpf nat list
  
<span class="c"># Flush all NAT mapping entries</span>
<span class="nv">$ </span>c0 bpf nat flush
<span class="nv">$ </span>c1 bpf nat flush
<span class="nv">$ </span>c2 bpf nat flush
  
<span class="c"># Manage the IPCache mappings for IP/CIDR &lt;-&gt; Identity</span>
<span class="nv">$ </span>c0 bpf ipcache list# Display cgroup metadata maintained by Cilium
<span class="nv">$ </span>c0 cgroups list
<span class="nv">$ </span>c1 cgroups list
<span class="nv">$ </span>c2 cgroups list
  
<span class="c"># List all open BPF maps</span>
<span class="nv">$ </span>c0 map list
<span class="nv">$ </span>c1 map list <span class="nt">--verbose</span>
<span class="nv">$ </span>c2 map list <span class="nt">--verbose</span>
  
<span class="nv">$ </span>c1 map events cilium_lb4_services_v2
<span class="nv">$ </span>c1 map events cilium_lb4_reverse_nat
<span class="nv">$ </span>c1 map events cilium_lxc
<span class="nv">$ </span>c1 map events cilium_ipcache
  
<span class="c"># List all metrics</span>
<span class="nv">$ </span>c1 metrics list
  
<span class="c"># List contents of a policy BPF map : Dump all policy maps</span>
<span class="nv">$ </span>c0 bpf policy get <span class="nt">--all</span>
<span class="nv">$ </span>c1 bpf policy get <span class="nt">--all</span> <span class="nt">-n</span>
<span class="nv">$ </span>c2 bpf policy get <span class="nt">--all</span> <span class="nt">-n</span>
  
<span class="c"># Dump StateDB contents as JSON</span>
<span class="nv">$ </span>c0 statedb dump
  
<span class="c">#</span>
<span class="nv">$ </span>c0 shell <span class="nt">--</span> db/show devices
<span class="nv">$ </span>c1 shell <span class="nt">--</span> db/show devices
<span class="nv">$ </span>c2 shell <span class="nt">--</span> db/show devices 
</code></pre></div>    </div>
  </li>
</ul>

  </div>

  <div id="toc-minimap" class="toc-minimap collapsed">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h2"><a href="#%EB%93%A4%EC%96%B4%EA%B0%80%EB%A9%B0">들어가며</a></li>
<li class="toc-entry toc-h2">
<a href="#%EC%8B%A4%EC%8A%B5-%ED%99%98%EA%B2%BD-%EA%B5%AC%EC%84%B1">실습 환경 구성</a>
<ul>
<li class="toc-entry toc-h3"><a href="#%EC%8B%A4%EC%8A%B5-%ED%99%98%EA%B2%BD-%EA%B5%AC%EC%84%B1-%EC%A4%80%EB%B9%84">실습 환경 구성 준비</a></li>
<li class="toc-entry toc-h3"><a href="#%EC%8B%A4%EC%8A%B5-%ED%99%98%EA%B2%BD-%EC%86%8C%EA%B0%9C">실습 환경 소개</a></li>
<li class="toc-entry toc-h3">
<a href="#%EC%8B%A4%EC%8A%B5-%ED%99%98%EA%B2%BD-%EB%B0%B0%ED%8F%AC-%ED%8C%8C%EC%9D%BC-%EC%9E%91%EC%84%B1">실습 환경 배포 파일 작성</a>
<ul>
<li class="toc-entry toc-h4"><a href="#vagrantfile">Vagrantfile</a></li>
<li class="toc-entry toc-h4"><a href="#init_cfgsh">init_cfg.sh</a></li>
<li class="toc-entry toc-h4"><a href="#k8s-ctrsh">k8s-ctr.sh</a></li>
<li class="toc-entry toc-h4"><a href="#k8s-wsh">k8s-w.sh</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#%EC%8B%A4%EC%8A%B5-%ED%99%98%EA%B2%BD-%EB%B0%B0%ED%8F%AC">실습 환경 배포</a></li>
</ul>
</li>
<li class="toc-entry toc-h2">
<a href="#flannel-cni">Flannel CNI</a>
<ul>
<li class="toc-entry toc-h3"><a href="#flannel-%EC%86%8C%EA%B0%9C">Flannel 소개</a></li>
<li class="toc-entry toc-h3"><a href="#flannel-%EC%84%A4%EC%B9%98-%EB%B0%8F-%ED%99%95%EC%9D%B8">Flannel 설치 및 확인</a></li>
<li class="toc-entry toc-h3"><a href="#%EC%83%98%ED%94%8C-%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98-%EB%B0%B0%ED%8F%AC-%EB%B0%8F-%ED%99%95%EC%9D%B8">샘플 애플리케이션 배포 및 확인</a></li>
</ul>
</li>
<li class="toc-entry toc-h2">
<a href="#cilium-cni">Cilium CNI</a>
<ul>
<li class="toc-entry toc-h3"><a href="#cilium-cni-%EC%86%8C%EA%B0%9C">Cilium CNI 소개</a></li>
<li class="toc-entry toc-h3">
<a href="#cilium-cni-%EC%84%A4%EC%B9%98">Cilium CNI 설치</a>
<ul>
<li class="toc-entry toc-h4"><a href="#cilium-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%9A%94%EA%B5%AC-%EC%82%AC%ED%95%AD-%ED%99%95%EC%9D%B8---%EA%B3%B5%EC%8B%9D-%EB%AC%B8%EC%84%9C">Cilium 시스템 요구 사항 확인 - 공식 문서</a></li>
<li class="toc-entry toc-h4"><a href="#kube-proxy-%EC%A0%9C%EA%B1%B0">kube-proxy 제거</a></li>
<li class="toc-entry toc-h4"><a href="#cilium-cni-%EC%84%A4%EC%B9%98-with-helm">Cilium CNI 설치 with Helm</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#cilium-%EC%84%A4%EC%B9%98-%ED%99%95%EC%9D%B8">Cilium 설치 확인</a></li>
</ul>
</li>
<li class="toc-entry toc-h2">
<a href="#%ED%86%B5%EC%8B%A0-%ED%99%95%EC%9D%B8">통신 확인</a>
<ul>
<li class="toc-entry toc-h3"><a href="#%EB%85%B8%EB%93%9C%EA%B0%84-%ED%8C%8C%EB%93%9C---%ED%8C%8C%EB%93%9C-%ED%86%B5%EC%8B%A0">노드간 ‘파드 -&gt; 파드’ 통신</a></li>
<li class="toc-entry toc-h3"><a href="#%EB%85%B8%EB%93%9C%EA%B0%84-%ED%8C%8C%EB%93%9C---%EC%84%9C%EB%B9%84%EC%8A%A4-%ED%86%B5%EC%8B%A0">노드간 ‘파드 -&gt; 서비스’ 통신</a></li>
<li class="toc-entry toc-h3"><a href="#cilium-%EC%82%AC%EC%9A%A9%EC%8B%9C-%EC%A3%BC%EC%9D%98%EC%82%AC%ED%95%AD">Cilium 사용시 주의사항</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#%EB%A7%88%EC%B9%98%EB%A9%B0">마치며</a></li>
</ul>
  </div>
<a class="u-url" href="/posts/2025-07-20-Cilium-Week1/" hidden></a>
</article>



<div class="PageNavigation">
  
  <a class="prev" href="/posts/2025-06-28-MacOS-%EC%97%85%EB%8D%B0%EC%9D%B4%ED%8A%B8-%ED%9B%84-Magnet%EC%9D%B4-%EC%9E%90%EB%8F%99-%EC%8B%9C%EC%9E%91%EC%9D%B4-%EC%95%88-%EB%90%A0-%EB%95%8C-%ED%95%B4%EA%B2%B0-%EB%B0%A9%EB%B2%95/">« MacOS 업데이트 후 Magnet이 자동 시작이 안 될 때 해결 방법</a>
  
  
</div>

<div id="disqus_thread"></div>
<script>
var disqus_config = function () {
this.page.url = "https://sweetlittlebird.github.io/posts/2025-07-20-Cilium-Week1/";
this.page.identifier = "/posts/Cilium - Week1";
};
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
</noscript>
      </div>

<!--      <div class="adsbygoogle-side">-->
<!--        &lt;!&ndash; ad_side &ndash;&gt;-->
<!--        <ins class="adsbygoogle "-->
<!--             style="display: block"-->
<!--             data-ad-client="ca-pub-6564723532026864"-->
<!--             data-ad-slot="1339398797"-->
<!--             data-ad-format="auto"-->
<!--             data-full-width-responsive="true"></ins>-->
<!--      </div>-->
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Sweet Little Bird</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Sweet Little Bird</li>
</ul>
      </div>

      <div class="footer-col footer-col-2">
<ul class="social-media-list"><li><a href="https://github.com/sweetlittlebird"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">sweetlittlebird</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>공부 기록과 개발 이야기를 담은 블로그입니다.</p>
      </div>
    </div>

  </div>

</footer>
<!-- Root element of PhotoSwipe. Must have class pswp. -->
    <div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">
      <!-- Background of PhotoSwipe. 
           It's a separate element as animating opacity is faster than rgba(). -->
      <div class="pswp__bg"></div>
      <!-- Slides wrapper with overflow:hidden. -->
      <div class="pswp__scroll-wrap">
        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
          <div class="pswp__item"></div>
          <div class="pswp__item"></div>
          <div class="pswp__item"></div>
        </div>
        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">
          <div class="pswp__top-bar">
            <!--  Controls are self-explanatory. Order can be changed. -->
            <div class="pswp__counter"></div>
            <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
            <button class="pswp__button pswp__button--share" title="Share"></button>
            <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
            <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
            <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
            <!-- element will get class pswp__preloader--active when preloader is running -->
            <div class="pswp__preloader">
              <div class="pswp__preloader__icn">
                <div class="pswp__preloader__cut">
                  <div class="pswp__preloader__donut"></div>
                </div>
              </div>
            </div>
          </div>
          <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
            <div class="pswp__share-tooltip"></div>
          </div>
          <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
          </button>
          <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
          </button>
          <div class="pswp__caption">
            <div class="pswp__caption__center"></div>
          </div>
        </div>
      </div>
    </div>

    <script async src="https://www.googletagmanager.com/gtag/js?id=G-EWGY9N8QXY"></script>

    
    <script async src="/assets/dist/app.min.js"></script>
    
  
    <a href="#" id="back-to-top"><span>Back to Top</span></a>

    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-6564723532026864" crossorigin="anonymous"></script>
    <!--<script>
    (adsbygoogle = window.adsbygoogle || []).push({});
    </script>-->
  </body>

</html>
